From aa9d205228bcb4d0f07485b9c59d00f21950f2eb Mon Sep 17 00:00:00 2001
From: Peter Gilbert <petergilbert@gmail.com>
Date: Mon, 1 Oct 2012 12:59:03 -0400
Subject: [PATCH 01/15] initial commit of TaintDroid 4.1.1_r6

---
 Android.mk                                         |    4 +
 dexopt/Android.mk                                  |   17 +
 dexopt/OptMain.cpp                                 |   14 +
 libattr/Android.mk                                 |   46 +
 libattr/Makefile                                   |   36 +
 libattr/README.txt                                 |    3 +
 libattr/attr/attributes.h                          |  184 +
 libattr/attr/error_context.h                       |   36 +
 libattr/attr/libattr.h                             |   29 +
 libattr/attr/xattr.h                               |   61 +
 libattr/attr_copy_action.c                         |  163 +
 libattr/attr_copy_check.c                          |   29 +
 libattr/attr_copy_fd.c                             |  178 +
 libattr/attr_copy_file.c                           |  176 +
 libattr/libattr.c                                  |  434 ++
 libattr/libattr.h                                  |   12 +
 libattr/syscalls.c                                 |  263 +
 tools/tprop/Android.mk                             |   31 +
 tools/tprop/ftaint.c                               |  121 +
 vm/Atomic.h                                        |   20 +
 vm/Dalvik.h                                        |    5 +
 vm/DalvikVersion.h                                 |    5 +
 vm/Debugger.cpp                                    |   34 +
 vm/Dvm.mk                                          |   39 +-
 vm/Init.cpp                                        |   29 +
 vm/InlineNative.cpp                                |  174 +
 vm/InlineNative.h                                  |  169 +-
 vm/Jni.cpp                                         |   22 +
 vm/Native.cpp                                      |   12 +
 vm/Thread.h                                        |    6 +
 vm/UtfString.h                                     |    7 +
 vm/alloc/Copying.cpp                               |   16 +
 vm/alloc/Visit.cpp                                 |   10 +
 vm/compiler/codegen/CodegenFactory.cpp             |   72 +
 vm/compiler/codegen/RallocUtil.cpp                 |   17 +
 vm/compiler/codegen/arm/CodegenDriver.cpp          |  890 ++-
 vm/compiler/codegen/arm/FP/Thumb2VFP.cpp           |    6 +
 vm/compiler/codegen/arm/Thumb2/Gen.cpp             |   12 +
 .../codegen/arm/armv7-a-neon/ArchVariant.cpp       |   32 +
 vm/compiler/codegen/arm/armv7-a-neon/ArchVariant.h |    4 +
 .../arm/armv7-a-neon/MethodCodegenDriver.cpp       |   14 +
 vm/compiler/codegen/arm/armv7-a/ArchVariant.cpp    |   21 +
 vm/compiler/codegen/arm/armv7-a/ArchVariant.h      |    4 +
 .../armv5te-vfp_taint/TEMPLATE_ADD_DOUBLE_VFP.S    |    2 +
 .../armv5te-vfp_taint/TEMPLATE_ADD_FLOAT_VFP.S     |    2 +
 .../armv5te-vfp_taint/TEMPLATE_CMPG_DOUBLE_VFP.S   |   33 +
 .../armv5te-vfp_taint/TEMPLATE_CMPG_FLOAT_VFP.S    |   32 +
 .../armv5te-vfp_taint/TEMPLATE_CMPL_DOUBLE_VFP.S   |   32 +
 .../armv5te-vfp_taint/TEMPLATE_CMPL_FLOAT_VFP.S    |   32 +
 .../armv5te-vfp_taint/TEMPLATE_DIV_DOUBLE_VFP.S    |    2 +
 .../armv5te-vfp_taint/TEMPLATE_DIV_FLOAT_VFP.S     |    2 +
 .../TEMPLATE_DOUBLE_TO_FLOAT_VFP.S                 |    2 +
 .../armv5te-vfp_taint/TEMPLATE_DOUBLE_TO_INT_VFP.S |    2 +
 .../TEMPLATE_FLOAT_TO_DOUBLE_VFP.S                 |    2 +
 .../armv5te-vfp_taint/TEMPLATE_FLOAT_TO_INT_VFP.S  |    2 +
 .../armv5te-vfp_taint/TEMPLATE_INT_TO_DOUBLE_VFP.S |    2 +
 .../armv5te-vfp_taint/TEMPLATE_INT_TO_FLOAT_VFP.S  |    2 +
 .../armv5te-vfp_taint/TEMPLATE_MEM_OP_DECODE.S     |   19 +
 .../armv5te-vfp_taint/TEMPLATE_MUL_DOUBLE_VFP.S    |    2 +
 .../armv5te-vfp_taint/TEMPLATE_MUL_FLOAT_VFP.S     |    2 +
 .../armv5te-vfp_taint/TEMPLATE_RESTORE_STATE.S     |   11 +
 .../armv5te-vfp_taint/TEMPLATE_SAVE_STATE.S        |   23 +
 .../armv5te-vfp_taint/TEMPLATE_SQRT_DOUBLE_VFP.S   |   23 +
 .../armv5te-vfp_taint/TEMPLATE_SUB_DOUBLE_VFP.S    |    2 +
 .../armv5te-vfp_taint/TEMPLATE_SUB_FLOAT_VFP.S     |    2 +
 .../template/armv5te-vfp_taint/TemplateOpList.h    |   65 +
 vm/compiler/template/armv5te-vfp_taint/fbinop.S    |   14 +
 .../template/armv5te-vfp_taint/fbinopWide.S        |   14 +
 vm/compiler/template/armv5te-vfp_taint/funop.S     |   15 +
 .../template/armv5te-vfp_taint/funopNarrower.S     |   15 +
 .../template/armv5te-vfp_taint/funopWider.S        |   15 +
 vm/compiler/template/armv5te-vfp_taint/platform.S  |    5 +
 .../template/armv5te_taint/TEMPLATE_CMPG_DOUBLE.S  |    1 +
 .../template/armv5te_taint/TEMPLATE_CMPG_FLOAT.S   |    1 +
 .../template/armv5te_taint/TEMPLATE_CMPL_DOUBLE.S  |   38 +
 .../template/armv5te_taint/TEMPLATE_CMPL_FLOAT.S   |   56 +
 .../template/armv5te_taint/TEMPLATE_CMP_LONG.S     |   33 +
 .../template/armv5te_taint/TEMPLATE_INTERPRET.S    |   30 +
 .../armv5te_taint/TEMPLATE_INVOKE_METHOD_CHAIN.S   |   55 +
 .../TEMPLATE_INVOKE_METHOD_CHAIN_PROF.S            |    3 +
 .../armv5te_taint/TEMPLATE_INVOKE_METHOD_NATIVE.S  |   96 +
 .../armv5te_taint/TEMPLATE_INVOKE_METHOD_NATIVE.S~ |   96 +
 .../TEMPLATE_INVOKE_METHOD_NATIVE_PROF.S           |    3 +
 .../armv5te_taint/TEMPLATE_INVOKE_METHOD_NO_OPT.S  |   67 +
 .../armv5te_taint/TEMPLATE_INVOKE_METHOD_NO_OPT.S~ |   67 +
 .../TEMPLATE_INVOKE_METHOD_NO_OPT_PROF.S           |    3 +
 .../TEMPLATE_INVOKE_METHOD_PREDICTED_CHAIN.S       |   60 +
 .../TEMPLATE_INVOKE_METHOD_PREDICTED_CHAIN_PROF.S  |    3 +
 .../armv5te_taint/TEMPLATE_MEM_OP_DECODE.S         |   17 +
 .../armv5te_taint/TEMPLATE_MONITOR_ENTER.S         |   21 +
 .../armv5te_taint/TEMPLATE_MONITOR_ENTER_DEBUG.S   |   28 +
 .../template/armv5te_taint/TEMPLATE_MUL_LONG.S     |   28 +
 .../armv5te_taint/TEMPLATE_PERIODIC_PROFILING.S    |   26 +
 .../armv5te_taint/TEMPLATE_RESTORE_STATE.S         |    8 +
 .../template/armv5te_taint/TEMPLATE_RETURN.S       |   57 +
 .../template/armv5te_taint/TEMPLATE_RETURN_PROF.S  |    3 +
 .../template/armv5te_taint/TEMPLATE_SAVE_STATE.S   |   21 +
 .../template/armv5te_taint/TEMPLATE_SHL_LONG.S     |   15 +
 .../template/armv5te_taint/TEMPLATE_SHR_LONG.S     |   15 +
 .../armv5te_taint/TEMPLATE_STRING_COMPARETO.S      |  133 +
 .../armv5te_taint/TEMPLATE_STRING_INDEXOF.S        |  112 +
 .../TEMPLATE_THROW_EXCEPTION_COMMON.S              |    6 +
 .../template/armv5te_taint/TEMPLATE_USHR_LONG.S    |   15 +
 .../template/armv5te_taint/TemplateOpList.h        |   50 +
 vm/compiler/template/armv5te_taint/footer.S        |  139 +
 vm/compiler/template/armv5te_taint/header.S        |   95 +
 vm/compiler/template/armv5te_taint/platform.S      |    5 +
 vm/compiler/template/config-armv7-a                |   52 +-
 vm/compiler/template/config-armv7-a-neon           |   52 +-
 vm/compiler/template/config-armv7-a-neon.notaint   |   67 +
 vm/compiler/template/config-armv7-a.notaint        |   67 +
 .../out/CompilerTemplateAsm-armv7-a-neon.S         |  178 +-
 .../template/out/CompilerTemplateAsm-armv7-a.S     |  178 +-
 vm/compiler/template_notaint/Makefile-template     |   49 +
 vm/compiler/template_notaint/README.txt            |    1 +
 .../armv5te-vfp/TEMPLATE_ADD_DOUBLE_VFP.S          |    2 +
 .../armv5te-vfp/TEMPLATE_ADD_FLOAT_VFP.S           |    2 +
 .../armv5te-vfp/TEMPLATE_CMPG_DOUBLE_VFP.S         |   33 +
 .../armv5te-vfp/TEMPLATE_CMPG_FLOAT_VFP.S          |   32 +
 .../armv5te-vfp/TEMPLATE_CMPL_DOUBLE_VFP.S         |   32 +
 .../armv5te-vfp/TEMPLATE_CMPL_FLOAT_VFP.S          |   32 +
 .../armv5te-vfp/TEMPLATE_DIV_DOUBLE_VFP.S          |    2 +
 .../armv5te-vfp/TEMPLATE_DIV_FLOAT_VFP.S           |    2 +
 .../armv5te-vfp/TEMPLATE_DOUBLE_TO_FLOAT_VFP.S     |    2 +
 .../armv5te-vfp/TEMPLATE_DOUBLE_TO_INT_VFP.S       |    2 +
 .../armv5te-vfp/TEMPLATE_FLOAT_TO_DOUBLE_VFP.S     |    2 +
 .../armv5te-vfp/TEMPLATE_FLOAT_TO_INT_VFP.S        |    2 +
 .../armv5te-vfp/TEMPLATE_INT_TO_DOUBLE_VFP.S       |    2 +
 .../armv5te-vfp/TEMPLATE_INT_TO_FLOAT_VFP.S        |    2 +
 .../armv5te-vfp/TEMPLATE_MEM_OP_DECODE.S           |   19 +
 .../armv5te-vfp/TEMPLATE_MUL_DOUBLE_VFP.S          |    2 +
 .../armv5te-vfp/TEMPLATE_MUL_FLOAT_VFP.S           |    2 +
 .../armv5te-vfp/TEMPLATE_RESTORE_STATE.S           |   11 +
 .../armv5te-vfp/TEMPLATE_SAVE_STATE.S              |   23 +
 .../armv5te-vfp/TEMPLATE_SQRT_DOUBLE_VFP.S         |   23 +
 .../armv5te-vfp/TEMPLATE_SUB_DOUBLE_VFP.S          |    2 +
 .../armv5te-vfp/TEMPLATE_SUB_FLOAT_VFP.S           |    2 +
 .../template_notaint/armv5te-vfp/TemplateOpList.h  |   65 +
 vm/compiler/template_notaint/armv5te-vfp/fbinop.S  |   14 +
 .../template_notaint/armv5te-vfp/fbinopWide.S      |   14 +
 vm/compiler/template_notaint/armv5te-vfp/funop.S   |   15 +
 .../template_notaint/armv5te-vfp/funopNarrower.S   |   15 +
 .../template_notaint/armv5te-vfp/funopWider.S      |   15 +
 .../template_notaint/armv5te-vfp/platform.S        |    5 +
 .../armv5te/TEMPLATE_CMPG_DOUBLE.S                 |    1 +
 .../template_notaint/armv5te/TEMPLATE_CMPG_FLOAT.S |    1 +
 .../armv5te/TEMPLATE_CMPL_DOUBLE.S                 |   38 +
 .../template_notaint/armv5te/TEMPLATE_CMPL_FLOAT.S |   56 +
 .../template_notaint/armv5te/TEMPLATE_CMP_LONG.S   |   33 +
 .../template_notaint/armv5te/TEMPLATE_INTERPRET.S  |   30 +
 .../armv5te/TEMPLATE_INVOKE_METHOD_CHAIN.S         |   49 +
 .../armv5te/TEMPLATE_INVOKE_METHOD_CHAIN_PROF.S    |    3 +
 .../armv5te/TEMPLATE_INVOKE_METHOD_NATIVE.S        |   83 +
 .../armv5te/TEMPLATE_INVOKE_METHOD_NATIVE_PROF.S   |    3 +
 .../armv5te/TEMPLATE_INVOKE_METHOD_NO_OPT.S        |   60 +
 .../armv5te/TEMPLATE_INVOKE_METHOD_NO_OPT_PROF.S   |    3 +
 .../TEMPLATE_INVOKE_METHOD_PREDICTED_CHAIN.S       |   60 +
 .../TEMPLATE_INVOKE_METHOD_PREDICTED_CHAIN_PROF.S  |    3 +
 .../armv5te/TEMPLATE_MEM_OP_DECODE.S               |   17 +
 .../armv5te/TEMPLATE_MONITOR_ENTER.S               |   21 +
 .../armv5te/TEMPLATE_MONITOR_ENTER_DEBUG.S         |   28 +
 .../template_notaint/armv5te/TEMPLATE_MUL_LONG.S   |   28 +
 .../armv5te/TEMPLATE_PERIODIC_PROFILING.S          |   26 +
 .../armv5te/TEMPLATE_RESTORE_STATE.S               |    8 +
 .../template_notaint/armv5te/TEMPLATE_RETURN.S     |   57 +
 .../armv5te/TEMPLATE_RETURN_PROF.S                 |    3 +
 .../template_notaint/armv5te/TEMPLATE_SAVE_STATE.S |   21 +
 .../template_notaint/armv5te/TEMPLATE_SHL_LONG.S   |   15 +
 .../template_notaint/armv5te/TEMPLATE_SHR_LONG.S   |   15 +
 .../armv5te/TEMPLATE_STRING_COMPARETO.S            |  133 +
 .../armv5te/TEMPLATE_STRING_INDEXOF.S              |  112 +
 .../armv5te/TEMPLATE_THROW_EXCEPTION_COMMON.S      |    6 +
 .../template_notaint/armv5te/TEMPLATE_USHR_LONG.S  |   15 +
 .../template_notaint/armv5te/TemplateOpList.h      |   50 +
 vm/compiler/template_notaint/armv5te/footer.S      |  129 +
 vm/compiler/template_notaint/armv5te/header.S      |   95 +
 vm/compiler/template_notaint/armv5te/platform.S    |    5 +
 .../template_notaint/armv7-a-neon/TemplateOpList.h |   65 +
 .../template_notaint/armv7-a/TemplateOpList.h      |   65 +
 vm/compiler/template_notaint/config-armv5te        |   45 +
 vm/compiler/template_notaint/config-armv5te-vfp    |   68 +
 vm/compiler/template_notaint/config-armv7-a        |   67 +
 vm/compiler/template_notaint/config-armv7-a-neon   |   67 +
 vm/compiler/template_notaint/config-ia32           |   45 +
 vm/compiler/template_notaint/gen-template.py       |  423 ++
 .../template_notaint/ia32/TEMPLATE_INTERPRET.S     |   38 +
 vm/compiler/template_notaint/ia32/TemplateOpList.h |   24 +
 vm/compiler/template_notaint/ia32/footer.S         |   13 +
 vm/compiler/template_notaint/ia32/header.S         |   29 +
 vm/compiler/template_notaint/ia32/platform.S       |    7 +
 .../out/CompilerTemplateAsm-armv5te-vfp.S          | 1981 +++++++
 .../out/CompilerTemplateAsm-armv5te.S              | 1712 ++++++
 .../out/CompilerTemplateAsm-armv7-a-neon.S         | 1981 +++++++
 .../out/CompilerTemplateAsm-armv7-a.S              | 1981 +++++++
 .../out/CompilerTemplateAsm-ia32.S                 |  113 +
 vm/compiler/template_notaint/rebuild.sh            |   22 +
 vm/interp/Interp.cpp                               |   27 +
 vm/interp/Interp.h                                 |    4 +
 vm/interp/InterpDefs.h                             |    4 +
 vm/interp/InterpState.h                            |    7 +
 vm/interp/Jit.cpp                                  |   53 +-
 vm/interp/Jit.h                                    |    8 +
 vm/interp/Stack.cpp                                |  274 +-
 vm/interp/Stack.h                                  |   16 +-
 vm/interp/Taint.h                                  |   50 +
 vm/mterp/arm-vfp_taint/OP_ADD_DOUBLE.S             |    2 +
 vm/mterp/arm-vfp_taint/OP_ADD_DOUBLE_2ADDR.S       |    2 +
 vm/mterp/arm-vfp_taint/OP_ADD_FLOAT.S              |    2 +
 vm/mterp/arm-vfp_taint/OP_ADD_FLOAT_2ADDR.S        |    2 +
 vm/mterp/arm-vfp_taint/OP_CMPG_DOUBLE.S            |   54 +
 vm/mterp/arm-vfp_taint/OP_CMPG_FLOAT.S             |   48 +
 vm/mterp/arm-vfp_taint/OP_CMPL_DOUBLE.S            |   54 +
 vm/mterp/arm-vfp_taint/OP_CMPL_FLOAT.S             |   48 +
 vm/mterp/arm-vfp_taint/OP_DIV_DOUBLE.S             |    2 +
 vm/mterp/arm-vfp_taint/OP_DIV_DOUBLE_2ADDR.S       |    2 +
 vm/mterp/arm-vfp_taint/OP_DIV_FLOAT.S              |    2 +
 vm/mterp/arm-vfp_taint/OP_DIV_FLOAT_2ADDR.S        |    2 +
 vm/mterp/arm-vfp_taint/OP_DOUBLE_TO_FLOAT.S        |    2 +
 vm/mterp/arm-vfp_taint/OP_DOUBLE_TO_INT.S          |    2 +
 vm/mterp/arm-vfp_taint/OP_FLOAT_TO_DOUBLE.S        |    2 +
 vm/mterp/arm-vfp_taint/OP_FLOAT_TO_INT.S           |    2 +
 vm/mterp/arm-vfp_taint/OP_INT_TO_DOUBLE.S          |    2 +
 vm/mterp/arm-vfp_taint/OP_INT_TO_FLOAT.S           |    2 +
 vm/mterp/arm-vfp_taint/OP_MUL_DOUBLE.S             |    2 +
 vm/mterp/arm-vfp_taint/OP_MUL_DOUBLE_2ADDR.S       |    2 +
 vm/mterp/arm-vfp_taint/OP_MUL_FLOAT.S              |    2 +
 vm/mterp/arm-vfp_taint/OP_MUL_FLOAT_2ADDR.S        |    2 +
 vm/mterp/arm-vfp_taint/OP_SUB_DOUBLE.S             |    2 +
 vm/mterp/arm-vfp_taint/OP_SUB_DOUBLE_2ADDR.S       |    2 +
 vm/mterp/arm-vfp_taint/OP_SUB_FLOAT.S              |    2 +
 vm/mterp/arm-vfp_taint/OP_SUB_FLOAT_2ADDR.S        |    2 +
 vm/mterp/arm-vfp_taint/fbinop.S                    |   35 +
 vm/mterp/arm-vfp_taint/fbinop2addr.S               |   34 +
 vm/mterp/arm-vfp_taint/fbinopWide.S                |   41 +
 vm/mterp/arm-vfp_taint/fbinopWide2addr.S           |   42 +
 vm/mterp/arm-vfp_taint/funop.S                     |   24 +
 vm/mterp/arm-vfp_taint/funopNarrower.S             |   26 +
 vm/mterp/arm-vfp_taint/funopWider.S                |   27 +
 vm/mterp/armv5te_taint/OP_ADD_DOUBLE.S             |    2 +
 vm/mterp/armv5te_taint/OP_ADD_DOUBLE_2ADDR.S       |    2 +
 vm/mterp/armv5te_taint/OP_ADD_FLOAT.S              |    2 +
 vm/mterp/armv5te_taint/OP_ADD_FLOAT_2ADDR.S        |    2 +
 vm/mterp/armv5te_taint/OP_ADD_INT.S                |    2 +
 vm/mterp/armv5te_taint/OP_ADD_INT_2ADDR.S          |    2 +
 vm/mterp/armv5te_taint/OP_ADD_INT_LIT16.S          |    2 +
 vm/mterp/armv5te_taint/OP_ADD_INT_LIT8.S           |    2 +
 vm/mterp/armv5te_taint/OP_ADD_LONG.S               |    2 +
 vm/mterp/armv5te_taint/OP_ADD_LONG_2ADDR.S         |    2 +
 vm/mterp/armv5te_taint/OP_AGET.S                   |   49 +
 vm/mterp/armv5te_taint/OP_AGET_BOOLEAN.S           |    2 +
 vm/mterp/armv5te_taint/OP_AGET_BYTE.S              |    2 +
 vm/mterp/armv5te_taint/OP_AGET_CHAR.S              |    2 +
 vm/mterp/armv5te_taint/OP_AGET_OBJECT.S            |    2 +
 vm/mterp/armv5te_taint/OP_AGET_SHORT.S             |    2 +
 vm/mterp/armv5te_taint/OP_AGET_WIDE.S              |   49 +
 vm/mterp/armv5te_taint/OP_AND_INT.S                |    2 +
 vm/mterp/armv5te_taint/OP_AND_INT_2ADDR.S          |    2 +
 vm/mterp/armv5te_taint/OP_AND_INT_LIT16.S          |    2 +
 vm/mterp/armv5te_taint/OP_AND_INT_LIT8.S           |    2 +
 vm/mterp/armv5te_taint/OP_AND_LONG.S               |    2 +
 vm/mterp/armv5te_taint/OP_AND_LONG_2ADDR.S         |    2 +
 vm/mterp/armv5te_taint/OP_APUT.S                   |   41 +
 vm/mterp/armv5te_taint/OP_APUT_BOOLEAN.S           |    2 +
 vm/mterp/armv5te_taint/OP_APUT_BYTE.S              |    2 +
 vm/mterp/armv5te_taint/OP_APUT_CHAR.S              |    2 +
 vm/mterp/armv5te_taint/OP_APUT_OBJECT.S            |   75 +
 vm/mterp/armv5te_taint/OP_APUT_SHORT.S             |    2 +
 vm/mterp/armv5te_taint/OP_APUT_WIDE.S              |   48 +
 vm/mterp/armv5te_taint/OP_ARRAY_LENGTH.S           |   21 +
 vm/mterp/armv5te_taint/OP_BREAKPOINT.S             |   15 +
 vm/mterp/armv5te_taint/OP_CHECK_CAST.S             |   68 +
 vm/mterp/armv5te_taint/OP_CMPG_DOUBLE.S            |    2 +
 vm/mterp/armv5te_taint/OP_CMPG_FLOAT.S             |    2 +
 vm/mterp/armv5te_taint/OP_CMP_LONG.S               |   80 +
 vm/mterp/armv5te_taint/OP_CONST.S                  |   16 +
 vm/mterp/armv5te_taint/OP_CONST_16.S               |   14 +
 vm/mterp/armv5te_taint/OP_CONST_4.S                |   16 +
 vm/mterp/armv5te_taint/OP_CONST_CLASS.S            |   45 +
 vm/mterp/armv5te_taint/OP_CONST_HIGH16.S           |   15 +
 vm/mterp/armv5te_taint/OP_CONST_STRING.S           |   44 +
 vm/mterp/armv5te_taint/OP_CONST_STRING_JUMBO.S     |   46 +
 vm/mterp/armv5te_taint/OP_CONST_WIDE.S             |   23 +
 vm/mterp/armv5te_taint/OP_CONST_WIDE_16.S          |   19 +
 vm/mterp/armv5te_taint/OP_CONST_WIDE_32.S          |   19 +
 vm/mterp/armv5te_taint/OP_CONST_WIDE_HIGH16.S      |   20 +
 vm/mterp/armv5te_taint/OP_DIV_DOUBLE.S             |    2 +
 vm/mterp/armv5te_taint/OP_DIV_DOUBLE_2ADDR.S       |    2 +
 vm/mterp/armv5te_taint/OP_DIV_FLOAT.S              |    2 +
 vm/mterp/armv5te_taint/OP_DIV_FLOAT_2ADDR.S        |    2 +
 vm/mterp/armv5te_taint/OP_DIV_INT.S                |    2 +
 vm/mterp/armv5te_taint/OP_DIV_INT_2ADDR.S          |    2 +
 vm/mterp/armv5te_taint/OP_DIV_INT_LIT16.S          |    2 +
 vm/mterp/armv5te_taint/OP_DIV_INT_LIT8.S           |    2 +
 vm/mterp/armv5te_taint/OP_DIV_LONG.S               |    2 +
 vm/mterp/armv5te_taint/OP_DIV_LONG_2ADDR.S         |    2 +
 vm/mterp/armv5te_taint/OP_DOUBLE_TO_FLOAT.S        |    2 +
 vm/mterp/armv5te_taint/OP_DOUBLE_TO_INT.S          |   55 +
 vm/mterp/armv5te_taint/OP_DOUBLE_TO_LONG.S         |   54 +
 vm/mterp/armv5te_taint/OP_EXECUTE_INLINE.S         |  131 +
 vm/mterp/armv5te_taint/OP_EXECUTE_INLINE_RANGE.S   |  123 +
 vm/mterp/armv5te_taint/OP_FILLED_NEW_ARRAY.S       |  116 +
 vm/mterp/armv5te_taint/OP_FILLED_NEW_ARRAY_RANGE.S |    2 +
 vm/mterp/armv5te_taint/OP_FILL_ARRAY_DATA.S        |   15 +
 vm/mterp/armv5te_taint/OP_FLOAT_TO_DOUBLE.S        |    2 +
 vm/mterp/armv5te_taint/OP_FLOAT_TO_INT.S           |   41 +
 vm/mterp/armv5te_taint/OP_FLOAT_TO_LONG.S          |   41 +
 vm/mterp/armv5te_taint/OP_GOTO.S                   |   22 +
 vm/mterp/armv5te_taint/OP_GOTO_16.S                |   19 +
 vm/mterp/armv5te_taint/OP_GOTO_32.S                |   29 +
 vm/mterp/armv5te_taint/OP_IF_EQ.S                  |    2 +
 vm/mterp/armv5te_taint/OP_IF_EQZ.S                 |    2 +
 vm/mterp/armv5te_taint/OP_IF_GE.S                  |    2 +
 vm/mterp/armv5te_taint/OP_IF_GEZ.S                 |    2 +
 vm/mterp/armv5te_taint/OP_IF_GT.S                  |    2 +
 vm/mterp/armv5te_taint/OP_IF_GTZ.S                 |    2 +
 vm/mterp/armv5te_taint/OP_IF_LE.S                  |    2 +
 vm/mterp/armv5te_taint/OP_IF_LEZ.S                 |    2 +
 vm/mterp/armv5te_taint/OP_IF_LT.S                  |    2 +
 vm/mterp/armv5te_taint/OP_IF_LTZ.S                 |    2 +
 vm/mterp/armv5te_taint/OP_IF_NE.S                  |    2 +
 vm/mterp/armv5te_taint/OP_IF_NEZ.S                 |    2 +
 vm/mterp/armv5te_taint/OP_IGET.S                   |   72 +
 vm/mterp/armv5te_taint/OP_IGET_BOOLEAN.S           |    3 +
 vm/mterp/armv5te_taint/OP_IGET_BYTE.S              |    4 +
 vm/mterp/armv5te_taint/OP_IGET_CHAR.S              |    5 +
 vm/mterp/armv5te_taint/OP_IGET_OBJECT.S            |    2 +
 vm/mterp/armv5te_taint/OP_IGET_OBJECT_QUICK.S      |    2 +
 vm/mterp/armv5te_taint/OP_IGET_OBJECT_VOLATILE.S   |    2 +
 vm/mterp/armv5te_taint/OP_IGET_QUICK.S             |   36 +
 vm/mterp/armv5te_taint/OP_IGET_SHORT.S             |    4 +
 vm/mterp/armv5te_taint/OP_IGET_VOLATILE.S          |    2 +
 vm/mterp/armv5te_taint/OP_IGET_WIDE.S              |   70 +
 vm/mterp/armv5te_taint/OP_IGET_WIDE_QUICK.S        |   37 +
 vm/mterp/armv5te_taint/OP_IGET_WIDE_VOLATILE.S     |    2 +
 vm/mterp/armv5te_taint/OP_INSTANCE_OF.S            |   95 +
 vm/mterp/armv5te_taint/OP_INT_TO_BYTE.S            |    2 +
 vm/mterp/armv5te_taint/OP_INT_TO_CHAR.S            |    2 +
 vm/mterp/armv5te_taint/OP_INT_TO_DOUBLE.S          |    2 +
 vm/mterp/armv5te_taint/OP_INT_TO_FLOAT.S           |    2 +
 vm/mterp/armv5te_taint/OP_INT_TO_LONG.S            |    2 +
 vm/mterp/armv5te_taint/OP_INT_TO_SHORT.S           |    2 +
 vm/mterp/armv5te_taint/OP_INVOKE_DIRECT.S          |   46 +
 vm/mterp/armv5te_taint/OP_INVOKE_DIRECT_RANGE.S    |    2 +
 vm/mterp/armv5te_taint/OP_INVOKE_INTERFACE.S       |   27 +
 vm/mterp/armv5te_taint/OP_INVOKE_INTERFACE_RANGE.S |    2 +
 .../armv5te_taint/OP_INVOKE_OBJECT_INIT_RANGE.S    |   44 +
 vm/mterp/armv5te_taint/OP_INVOKE_STATIC.S          |   54 +
 vm/mterp/armv5te_taint/OP_INVOKE_STATIC_RANGE.S    |    2 +
 vm/mterp/armv5te_taint/OP_INVOKE_SUPER.S           |   60 +
 vm/mterp/armv5te_taint/OP_INVOKE_SUPER_QUICK.S     |   25 +
 .../armv5te_taint/OP_INVOKE_SUPER_QUICK_RANGE.S    |    2 +
 vm/mterp/armv5te_taint/OP_INVOKE_SUPER_RANGE.S     |    2 +
 vm/mterp/armv5te_taint/OP_INVOKE_VIRTUAL.S         |   45 +
 vm/mterp/armv5te_taint/OP_INVOKE_VIRTUAL_QUICK.S   |   23 +
 .../armv5te_taint/OP_INVOKE_VIRTUAL_QUICK_RANGE.S  |    2 +
 vm/mterp/armv5te_taint/OP_INVOKE_VIRTUAL_RANGE.S   |    2 +
 vm/mterp/armv5te_taint/OP_IPUT.S                   |   65 +
 vm/mterp/armv5te_taint/OP_IPUT_BOOLEAN.S           |    3 +
 vm/mterp/armv5te_taint/OP_IPUT_BYTE.S              |    3 +
 vm/mterp/armv5te_taint/OP_IPUT_CHAR.S              |    3 +
 vm/mterp/armv5te_taint/OP_IPUT_OBJECT.S            |   67 +
 vm/mterp/armv5te_taint/OP_IPUT_OBJECT_QUICK.S      |   33 +
 vm/mterp/armv5te_taint/OP_IPUT_OBJECT_VOLATILE.S   |    2 +
 vm/mterp/armv5te_taint/OP_IPUT_QUICK.S             |   25 +
 vm/mterp/armv5te_taint/OP_IPUT_SHORT.S             |    3 +
 vm/mterp/armv5te_taint/OP_IPUT_VOLATILE.S          |    2 +
 vm/mterp/armv5te_taint/OP_IPUT_WIDE.S              |   60 +
 vm/mterp/armv5te_taint/OP_IPUT_WIDE_QUICK.S        |   31 +
 vm/mterp/armv5te_taint/OP_IPUT_WIDE_VOLATILE.S     |    2 +
 vm/mterp/armv5te_taint/OP_LONG_TO_DOUBLE.S         |    2 +
 vm/mterp/armv5te_taint/OP_LONG_TO_FLOAT.S          |    2 +
 vm/mterp/armv5te_taint/OP_LONG_TO_INT.S            |    3 +
 vm/mterp/armv5te_taint/OP_MONITOR_ENTER.S          |   16 +
 vm/mterp/armv5te_taint/OP_MONITOR_EXIT.S           |   26 +
 vm/mterp/armv5te_taint/OP_MOVE.S                   |   17 +
 vm/mterp/armv5te_taint/OP_MOVE_16.S                |   16 +
 vm/mterp/armv5te_taint/OP_MOVE_EXCEPTION.S         |   15 +
 vm/mterp/armv5te_taint/OP_MOVE_FROM16.S            |   16 +
 vm/mterp/armv5te_taint/OP_MOVE_OBJECT.S            |    2 +
 vm/mterp/armv5te_taint/OP_MOVE_OBJECT_16.S         |    2 +
 vm/mterp/armv5te_taint/OP_MOVE_OBJECT_FROM16.S     |    2 +
 vm/mterp/armv5te_taint/OP_MOVE_RESULT.S            |   14 +
 vm/mterp/armv5te_taint/OP_MOVE_RESULT_OBJECT.S     |    2 +
 vm/mterp/armv5te_taint/OP_MOVE_RESULT_WIDE.S       |   20 +
 vm/mterp/armv5te_taint/OP_MOVE_WIDE.S              |   18 +
 vm/mterp/armv5te_taint/OP_MOVE_WIDE_16.S           |   17 +
 vm/mterp/armv5te_taint/OP_MOVE_WIDE_FROM16.S       |   17 +
 vm/mterp/armv5te_taint/OP_MUL_DOUBLE.S             |    2 +
 vm/mterp/armv5te_taint/OP_MUL_DOUBLE_2ADDR.S       |    2 +
 vm/mterp/armv5te_taint/OP_MUL_FLOAT.S              |    2 +
 vm/mterp/armv5te_taint/OP_MUL_FLOAT_2ADDR.S        |    2 +
 vm/mterp/armv5te_taint/OP_MUL_INT.S                |    3 +
 vm/mterp/armv5te_taint/OP_MUL_INT_2ADDR.S          |    3 +
 vm/mterp/armv5te_taint/OP_MUL_INT_LIT16.S          |    3 +
 vm/mterp/armv5te_taint/OP_MUL_INT_LIT8.S           |    3 +
 vm/mterp/armv5te_taint/OP_MUL_LONG.S               |   64 +
 vm/mterp/armv5te_taint/OP_MUL_LONG_2ADDR.S         |   49 +
 vm/mterp/armv5te_taint/OP_NEG_DOUBLE.S             |    2 +
 vm/mterp/armv5te_taint/OP_NEG_FLOAT.S              |    2 +
 vm/mterp/armv5te_taint/OP_NEG_INT.S                |    2 +
 vm/mterp/armv5te_taint/OP_NEG_LONG.S               |    2 +
 vm/mterp/armv5te_taint/OP_NEW_ARRAY.S              |   66 +
 vm/mterp/armv5te_taint/OP_NEW_INSTANCE.S           |  111 +
 vm/mterp/armv5te_taint/OP_NOP.S                    |   15 +
 vm/mterp/armv5te_taint/OP_NOT_INT.S                |    2 +
 vm/mterp/armv5te_taint/OP_NOT_LONG.S               |    2 +
 vm/mterp/armv5te_taint/OP_OR_INT.S                 |    2 +
 vm/mterp/armv5te_taint/OP_OR_INT_2ADDR.S           |    2 +
 vm/mterp/armv5te_taint/OP_OR_INT_LIT16.S           |    2 +
 vm/mterp/armv5te_taint/OP_OR_INT_LIT8.S            |    2 +
 vm/mterp/armv5te_taint/OP_OR_LONG.S                |    2 +
 vm/mterp/armv5te_taint/OP_OR_LONG_2ADDR.S          |    2 +
 vm/mterp/armv5te_taint/OP_PACKED_SWITCH.S          |   35 +
 vm/mterp/armv5te_taint/OP_REM_DOUBLE.S             |    3 +
 vm/mterp/armv5te_taint/OP_REM_DOUBLE_2ADDR.S       |    3 +
 vm/mterp/armv5te_taint/OP_REM_FLOAT.S              |    3 +
 vm/mterp/armv5te_taint/OP_REM_FLOAT_2ADDR.S        |    3 +
 vm/mterp/armv5te_taint/OP_REM_INT.S                |    3 +
 vm/mterp/armv5te_taint/OP_REM_INT_2ADDR.S          |    3 +
 vm/mterp/armv5te_taint/OP_REM_INT_LIT16.S          |    3 +
 vm/mterp/armv5te_taint/OP_REM_INT_LIT8.S           |    3 +
 vm/mterp/armv5te_taint/OP_REM_LONG.S               |    3 +
 vm/mterp/armv5te_taint/OP_REM_LONG_2ADDR.S         |    3 +
 vm/mterp/armv5te_taint/OP_RETURN.S                 |   17 +
 vm/mterp/armv5te_taint/OP_RETURN_OBJECT.S          |    2 +
 vm/mterp/armv5te_taint/OP_RETURN_VOID.S            |    5 +
 vm/mterp/armv5te_taint/OP_RETURN_VOID_BARRIER.S    |    5 +
 vm/mterp/armv5te_taint/OP_RETURN_WIDE.S            |   20 +
 vm/mterp/armv5te_taint/OP_RSUB_INT.S               |    3 +
 vm/mterp/armv5te_taint/OP_RSUB_INT_LIT8.S          |    2 +
 vm/mterp/armv5te_taint/OP_SGET.S                   |   67 +
 vm/mterp/armv5te_taint/OP_SGET_BOOLEAN.S           |    2 +
 vm/mterp/armv5te_taint/OP_SGET_BYTE.S              |    2 +
 vm/mterp/armv5te_taint/OP_SGET_CHAR.S              |    2 +
 vm/mterp/armv5te_taint/OP_SGET_OBJECT.S            |    2 +
 vm/mterp/armv5te_taint/OP_SGET_OBJECT_VOLATILE.S   |    2 +
 vm/mterp/armv5te_taint/OP_SGET_SHORT.S             |    2 +
 vm/mterp/armv5te_taint/OP_SGET_VOLATILE.S          |    2 +
 vm/mterp/armv5te_taint/OP_SGET_WIDE.S              |   68 +
 vm/mterp/armv5te_taint/OP_SGET_WIDE_VOLATILE.S     |    2 +
 vm/mterp/armv5te_taint/OP_SHL_INT.S                |    2 +
 vm/mterp/armv5te_taint/OP_SHL_INT_2ADDR.S          |    2 +
 vm/mterp/armv5te_taint/OP_SHL_INT_LIT8.S           |    2 +
 vm/mterp/armv5te_taint/OP_SHL_LONG.S               |   50 +
 vm/mterp/armv5te_taint/OP_SHL_LONG_2ADDR.S         |   46 +
 vm/mterp/armv5te_taint/OP_SHR_INT.S                |    2 +
 vm/mterp/armv5te_taint/OP_SHR_INT_2ADDR.S          |    2 +
 vm/mterp/armv5te_taint/OP_SHR_INT_LIT8.S           |    2 +
 vm/mterp/armv5te_taint/OP_SHR_LONG.S               |   50 +
 vm/mterp/armv5te_taint/OP_SHR_LONG_2ADDR.S         |   47 +
 vm/mterp/armv5te_taint/OP_SPARSE_SWITCH.S          |    2 +
 vm/mterp/armv5te_taint/OP_SPUT.S                   |   72 +
 vm/mterp/armv5te_taint/OP_SPUT_BOOLEAN.S           |    2 +
 vm/mterp/armv5te_taint/OP_SPUT_BYTE.S              |    2 +
 vm/mterp/armv5te_taint/OP_SPUT_CHAR.S              |    2 +
 vm/mterp/armv5te_taint/OP_SPUT_OBJECT.S            |   79 +
 vm/mterp/armv5te_taint/OP_SPUT_OBJECT_VOLATILE.S   |    2 +
 vm/mterp/armv5te_taint/OP_SPUT_SHORT.S             |    2 +
 vm/mterp/armv5te_taint/OP_SPUT_VOLATILE.S          |    2 +
 vm/mterp/armv5te_taint/OP_SPUT_WIDE.S              |   72 +
 vm/mterp/armv5te_taint/OP_SPUT_WIDE_VOLATILE.S     |    2 +
 vm/mterp/armv5te_taint/OP_SUB_DOUBLE.S             |    2 +
 vm/mterp/armv5te_taint/OP_SUB_DOUBLE_2ADDR.S       |    2 +
 vm/mterp/armv5te_taint/OP_SUB_FLOAT.S              |    2 +
 vm/mterp/armv5te_taint/OP_SUB_FLOAT_2ADDR.S        |    2 +
 vm/mterp/armv5te_taint/OP_SUB_INT.S                |    2 +
 vm/mterp/armv5te_taint/OP_SUB_INT_2ADDR.S          |    2 +
 vm/mterp/armv5te_taint/OP_SUB_LONG.S               |    2 +
 vm/mterp/armv5te_taint/OP_SUB_LONG_2ADDR.S         |    2 +
 vm/mterp/armv5te_taint/OP_THROW.S                  |   14 +
 .../armv5te_taint/OP_THROW_VERIFICATION_ERROR.S    |   13 +
 vm/mterp/armv5te_taint/OP_UNUSED_3E.S              |    1 +
 vm/mterp/armv5te_taint/OP_UNUSED_3F.S              |    1 +
 vm/mterp/armv5te_taint/OP_UNUSED_40.S              |    1 +
 vm/mterp/armv5te_taint/OP_UNUSED_41.S              |    1 +
 vm/mterp/armv5te_taint/OP_UNUSED_42.S              |    1 +
 vm/mterp/armv5te_taint/OP_UNUSED_43.S              |    1 +
 vm/mterp/armv5te_taint/OP_UNUSED_73.S              |    1 +
 vm/mterp/armv5te_taint/OP_UNUSED_79.S              |    1 +
 vm/mterp/armv5te_taint/OP_UNUSED_7A.S              |    1 +
 vm/mterp/armv5te_taint/OP_UNUSED_FF.S              |    1 +
 vm/mterp/armv5te_taint/OP_USHR_INT.S               |    2 +
 vm/mterp/armv5te_taint/OP_USHR_INT_2ADDR.S         |    2 +
 vm/mterp/armv5te_taint/OP_USHR_INT_LIT8.S          |    2 +
 vm/mterp/armv5te_taint/OP_USHR_LONG.S              |   50 +
 vm/mterp/armv5te_taint/OP_USHR_LONG_2ADDR.S        |   46 +
 vm/mterp/armv5te_taint/OP_XOR_INT.S                |    2 +
 vm/mterp/armv5te_taint/OP_XOR_INT_2ADDR.S          |    2 +
 vm/mterp/armv5te_taint/OP_XOR_INT_LIT16.S          |    2 +
 vm/mterp/armv5te_taint/OP_XOR_INT_LIT8.S           |    2 +
 vm/mterp/armv5te_taint/OP_XOR_LONG.S               |    2 +
 vm/mterp/armv5te_taint/OP_XOR_LONG_2ADDR.S         |    2 +
 vm/mterp/armv5te_taint/alt_stub.S                  |   18 +
 vm/mterp/armv5te_taint/bincmp.S                    |   30 +
 vm/mterp/armv5te_taint/binop.S                     |   48 +
 vm/mterp/armv5te_taint/binop2addr.S                |   47 +
 vm/mterp/armv5te_taint/binopLit16.S                |   36 +
 vm/mterp/armv5te_taint/binopLit8.S                 |   38 +
 vm/mterp/armv5te_taint/binopWide.S                 |   61 +
 vm/mterp/armv5te_taint/binopWide2addr.S            |   58 +
 vm/mterp/armv5te_taint/debug.cpp                   |   82 +
 vm/mterp/armv5te_taint/debug.cpp~                  |   81 +
 vm/mterp/armv5te_taint/entry.S                     |  130 +
 vm/mterp/armv5te_taint/footer.S                    | 1365 +++++
 vm/mterp/armv5te_taint/header.S                    |  210 +
 vm/mterp/armv5te_taint/stub.S                      |    8 +
 vm/mterp/armv5te_taint/unop.S                      |   26 +
 vm/mterp/armv5te_taint/unopNarrower.S              |   33 +
 vm/mterp/armv5te_taint/unopWide.S                  |   37 +
 vm/mterp/armv5te_taint/unopWider.S                 |   35 +
 vm/mterp/armv5te_taint/unused.S                    |    2 +
 vm/mterp/armv5te_taint/zcmp.S                      |   27 +
 vm/mterp/armv6t2_taint/OP_ADD_FLOAT_2ADDR.S        |    2 +
 vm/mterp/armv6t2_taint/OP_ADD_INT_2ADDR.S          |    2 +
 vm/mterp/armv6t2_taint/OP_ADD_INT_LIT16.S          |    2 +
 vm/mterp/armv6t2_taint/OP_ADD_LONG_2ADDR.S         |    2 +
 vm/mterp/armv6t2_taint/OP_AND_INT_2ADDR.S          |    2 +
 vm/mterp/armv6t2_taint/OP_AND_INT_LIT16.S          |    2 +
 vm/mterp/armv6t2_taint/OP_AND_LONG_2ADDR.S         |    2 +
 vm/mterp/armv6t2_taint/OP_ARRAY_LENGTH.S           |   19 +
 vm/mterp/armv6t2_taint/OP_CONST_4.S                |   14 +
 vm/mterp/armv6t2_taint/OP_DIV_FLOAT_2ADDR.S        |    2 +
 vm/mterp/armv6t2_taint/OP_DIV_INT_2ADDR.S          |    2 +
 vm/mterp/armv6t2_taint/OP_DIV_INT_LIT16.S          |    2 +
 vm/mterp/armv6t2_taint/OP_DIV_LONG_2ADDR.S         |    2 +
 vm/mterp/armv6t2_taint/OP_DOUBLE_TO_LONG.S         |   54 +
 vm/mterp/armv6t2_taint/OP_FLOAT_TO_INT.S           |   41 +
 vm/mterp/armv6t2_taint/OP_FLOAT_TO_LONG.S          |   41 +
 vm/mterp/armv6t2_taint/OP_IF_EQ.S                  |    2 +
 vm/mterp/armv6t2_taint/OP_IF_GE.S                  |    2 +
 vm/mterp/armv6t2_taint/OP_IF_GT.S                  |    2 +
 vm/mterp/armv6t2_taint/OP_IF_LE.S                  |    2 +
 vm/mterp/armv6t2_taint/OP_IF_LT.S                  |    2 +
 vm/mterp/armv6t2_taint/OP_IF_NE.S                  |    2 +
 vm/mterp/armv6t2_taint/OP_IGET.S                   |   62 +
 vm/mterp/armv6t2_taint/OP_IGET_QUICK.S             |   36 +
 vm/mterp/armv6t2_taint/OP_IGET_WIDE.S              |   61 +
 vm/mterp/armv6t2_taint/OP_IGET_WIDE_QUICK.S        |   36 +
 vm/mterp/armv6t2_taint/OP_INT_TO_BYTE.S            |    2 +
 vm/mterp/armv6t2_taint/OP_INT_TO_CHAR.S            |    2 +
 vm/mterp/armv6t2_taint/OP_INT_TO_DOUBLE.S          |    2 +
 vm/mterp/armv6t2_taint/OP_INT_TO_FLOAT.S           |    2 +
 vm/mterp/armv6t2_taint/OP_INT_TO_LONG.S            |    2 +
 vm/mterp/armv6t2_taint/OP_INT_TO_SHORT.S           |    2 +
 vm/mterp/armv6t2_taint/OP_IPUT.S                   |   54 +
 vm/mterp/armv6t2_taint/OP_IPUT_QUICK.S             |   24 +
 vm/mterp/armv6t2_taint/OP_IPUT_WIDE.S              |   51 +
 vm/mterp/armv6t2_taint/OP_IPUT_WIDE_QUICK.S        |   30 +
 vm/mterp/armv6t2_taint/OP_LONG_TO_DOUBLE.S         |    2 +
 vm/mterp/armv6t2_taint/OP_LONG_TO_FLOAT.S          |    2 +
 vm/mterp/armv6t2_taint/OP_MOVE.S                   |   16 +
 vm/mterp/armv6t2_taint/OP_MOVE_WIDE.S              |   17 +
 vm/mterp/armv6t2_taint/OP_MUL_FLOAT_2ADDR.S        |    2 +
 vm/mterp/armv6t2_taint/OP_MUL_INT_2ADDR.S          |    3 +
 vm/mterp/armv6t2_taint/OP_MUL_INT_LIT16.S          |    3 +
 vm/mterp/armv6t2_taint/OP_MUL_LONG_2ADDR.S         |   48 +
 vm/mterp/armv6t2_taint/OP_NEG_DOUBLE.S             |    2 +
 vm/mterp/armv6t2_taint/OP_NEG_FLOAT.S              |    2 +
 vm/mterp/armv6t2_taint/OP_NEG_INT.S                |    2 +
 vm/mterp/armv6t2_taint/OP_NEG_LONG.S               |    2 +
 vm/mterp/armv6t2_taint/OP_NOT_INT.S                |    2 +
 vm/mterp/armv6t2_taint/OP_NOT_LONG.S               |    2 +
 vm/mterp/armv6t2_taint/OP_OR_INT_2ADDR.S           |    2 +
 vm/mterp/armv6t2_taint/OP_OR_INT_LIT16.S           |    2 +
 vm/mterp/armv6t2_taint/OP_OR_LONG_2ADDR.S          |    2 +
 vm/mterp/armv6t2_taint/OP_REM_DOUBLE_2ADDR.S       |    3 +
 vm/mterp/armv6t2_taint/OP_REM_FLOAT_2ADDR.S        |    3 +
 vm/mterp/armv6t2_taint/OP_REM_INT_2ADDR.S          |    3 +
 vm/mterp/armv6t2_taint/OP_REM_INT_LIT16.S          |    3 +
 vm/mterp/armv6t2_taint/OP_REM_LONG_2ADDR.S         |    3 +
 vm/mterp/armv6t2_taint/OP_RSUB_INT.S               |    3 +
 vm/mterp/armv6t2_taint/OP_SHL_INT_2ADDR.S          |    2 +
 vm/mterp/armv6t2_taint/OP_SHL_LONG_2ADDR.S         |   45 +
 vm/mterp/armv6t2_taint/OP_SHR_INT_2ADDR.S          |    2 +
 vm/mterp/armv6t2_taint/OP_SHR_LONG_2ADDR.S         |   46 +
 vm/mterp/armv6t2_taint/OP_SUB_FLOAT_2ADDR.S        |    2 +
 vm/mterp/armv6t2_taint/OP_SUB_INT_2ADDR.S          |    2 +
 vm/mterp/armv6t2_taint/OP_SUB_LONG_2ADDR.S         |    2 +
 vm/mterp/armv6t2_taint/OP_USHR_INT_2ADDR.S         |    2 +
 vm/mterp/armv6t2_taint/OP_USHR_LONG_2ADDR.S        |   45 +
 vm/mterp/armv6t2_taint/OP_XOR_INT_2ADDR.S          |    2 +
 vm/mterp/armv6t2_taint/OP_XOR_INT_LIT16.S          |    2 +
 vm/mterp/armv6t2_taint/OP_XOR_LONG_2ADDR.S         |    2 +
 vm/mterp/armv6t2_taint/bincmp.S                    |   29 +
 vm/mterp/armv6t2_taint/binop2addr.S                |   46 +
 vm/mterp/armv6t2_taint/binopLit16.S                |   35 +
 vm/mterp/armv6t2_taint/binopWide2addr.S            |   57 +
 vm/mterp/armv6t2_taint/unop.S                      |   25 +
 vm/mterp/armv6t2_taint/unopNarrower.S              |   32 +
 vm/mterp/armv6t2_taint/unopWide.S                  |   36 +
 vm/mterp/armv6t2_taint/unopWider.S                 |   34 +
 vm/mterp/c/OP_APUT_OBJECT.cpp                      |    7 +-
 vm/mterp/c/OP_ARRAY_LENGTH.cpp                     |    3 +
 vm/mterp/c/OP_CONST.cpp                            |    3 +
 vm/mterp/c/OP_CONST_16.cpp                         |    3 +
 vm/mterp/c/OP_CONST_4.cpp                          |    3 +
 vm/mterp/c/OP_CONST_CLASS.cpp                      |    3 +
 vm/mterp/c/OP_CONST_HIGH16.cpp                     |    3 +
 vm/mterp/c/OP_CONST_STRING.cpp                     |    3 +
 vm/mterp/c/OP_CONST_STRING_JUMBO.cpp               |    3 +
 vm/mterp/c/OP_CONST_WIDE.cpp                       |    3 +
 vm/mterp/c/OP_CONST_WIDE_16.cpp                    |    3 +
 vm/mterp/c/OP_CONST_WIDE_32.cpp                    |    3 +
 vm/mterp/c/OP_CONST_WIDE_HIGH16.cpp                |    3 +
 vm/mterp/c/OP_EXECUTE_INLINE.cpp                   |   21 +
 vm/mterp/c/OP_EXECUTE_INLINE_RANGE.cpp             |   21 +
 vm/mterp/c/OP_INSTANCE_OF.cpp                      |    6 +
 vm/mterp/c/OP_MOVE.cpp                             |    3 +
 vm/mterp/c/OP_MOVE_16.cpp                          |    3 +
 vm/mterp/c/OP_MOVE_EXCEPTION.cpp                   |    3 +
 vm/mterp/c/OP_MOVE_FROM16.cpp                      |    3 +
 vm/mterp/c/OP_MOVE_RESULT.cpp                      |    3 +
 vm/mterp/c/OP_MOVE_RESULT_WIDE.cpp                 |    3 +
 vm/mterp/c/OP_MOVE_WIDE.cpp                        |    3 +
 vm/mterp/c/OP_MOVE_WIDE_16.cpp                     |    3 +
 vm/mterp/c/OP_MOVE_WIDE_FROM16.cpp                 |    3 +
 vm/mterp/c/OP_NEW_ARRAY.cpp                        |    3 +
 vm/mterp/c/OP_NEW_INSTANCE.cpp                     |    3 +
 vm/mterp/c/OP_REM_DOUBLE.cpp                       |    4 +
 vm/mterp/c/OP_REM_DOUBLE_2ADDR.cpp                 |    4 +
 vm/mterp/c/OP_REM_FLOAT.cpp                        |    6 +
 vm/mterp/c/OP_REM_FLOAT_2ADDR.cpp                  |    6 +
 vm/mterp/c/OP_RETURN.cpp                           |    3 +
 vm/mterp/c/OP_RETURN_VOID.cpp                      |    3 +
 vm/mterp/c/OP_RETURN_VOID_BARRIER.cpp              |    3 +
 vm/mterp/c/OP_RETURN_WIDE.cpp                      |    3 +
 vm/mterp/c/OP_RSUB_INT.cpp                         |    3 +
 vm/mterp/c/OP_RSUB_INT_LIT8.cpp                    |    3 +
 vm/mterp/c/gotoTargets.cpp                         |  104 +
 vm/mterp/c/header.cpp                              |  172 +
 vm/mterp/c/opcommon.cpp                            |  116 +-
 vm/mterp/c_notaint/OP_ADD_DOUBLE.cpp               |    2 +
 vm/mterp/c_notaint/OP_ADD_DOUBLE_2ADDR.cpp         |    2 +
 vm/mterp/c_notaint/OP_ADD_FLOAT.cpp                |    2 +
 vm/mterp/c_notaint/OP_ADD_FLOAT_2ADDR.cpp          |    2 +
 vm/mterp/c_notaint/OP_ADD_INT.cpp                  |    2 +
 vm/mterp/c_notaint/OP_ADD_INT_2ADDR.cpp            |    2 +
 vm/mterp/c_notaint/OP_ADD_INT_LIT16.cpp            |    2 +
 vm/mterp/c_notaint/OP_ADD_INT_LIT8.cpp             |    2 +
 vm/mterp/c_notaint/OP_ADD_LONG.cpp                 |    2 +
 vm/mterp/c_notaint/OP_ADD_LONG_2ADDR.cpp           |    2 +
 vm/mterp/c_notaint/OP_AGET.cpp                     |    2 +
 vm/mterp/c_notaint/OP_AGET_BOOLEAN.cpp             |    2 +
 vm/mterp/c_notaint/OP_AGET_BYTE.cpp                |    2 +
 vm/mterp/c_notaint/OP_AGET_CHAR.cpp                |    2 +
 vm/mterp/c_notaint/OP_AGET_OBJECT.cpp              |    2 +
 vm/mterp/c_notaint/OP_AGET_SHORT.cpp               |    2 +
 vm/mterp/c_notaint/OP_AGET_WIDE.cpp                |    2 +
 vm/mterp/c_notaint/OP_AND_INT.cpp                  |    2 +
 vm/mterp/c_notaint/OP_AND_INT_2ADDR.cpp            |    2 +
 vm/mterp/c_notaint/OP_AND_INT_LIT16.cpp            |    2 +
 vm/mterp/c_notaint/OP_AND_INT_LIT8.cpp             |    2 +
 vm/mterp/c_notaint/OP_AND_LONG.cpp                 |    2 +
 vm/mterp/c_notaint/OP_AND_LONG_2ADDR.cpp           |    2 +
 vm/mterp/c_notaint/OP_APUT.cpp                     |    2 +
 vm/mterp/c_notaint/OP_APUT_BOOLEAN.cpp             |    2 +
 vm/mterp/c_notaint/OP_APUT_BYTE.cpp                |    2 +
 vm/mterp/c_notaint/OP_APUT_CHAR.cpp                |    2 +
 vm/mterp/c_notaint/OP_APUT_OBJECT.cpp              |   38 +
 vm/mterp/c_notaint/OP_APUT_SHORT.cpp               |    2 +
 vm/mterp/c_notaint/OP_APUT_WIDE.cpp                |    2 +
 vm/mterp/c_notaint/OP_ARRAY_LENGTH.cpp             |   15 +
 vm/mterp/c_notaint/OP_BREAKPOINT.cpp               |   24 +
 vm/mterp/c_notaint/OP_CHECK_CAST.cpp               |   31 +
 vm/mterp/c_notaint/OP_CMPG_DOUBLE.cpp              |    2 +
 vm/mterp/c_notaint/OP_CMPG_FLOAT.cpp               |    2 +
 vm/mterp/c_notaint/OP_CMPL_DOUBLE.cpp              |    2 +
 vm/mterp/c_notaint/OP_CMPL_FLOAT.cpp               |    2 +
 vm/mterp/c_notaint/OP_CMP_LONG.cpp                 |    2 +
 vm/mterp/c_notaint/OP_CONST.cpp                    |   12 +
 vm/mterp/c_notaint/OP_CONST_16.cpp                 |    7 +
 vm/mterp/c_notaint/OP_CONST_4.cpp                  |   11 +
 vm/mterp/c_notaint/OP_CONST_CLASS.cpp              |   18 +
 vm/mterp/c_notaint/OP_CONST_HIGH16.cpp             |    7 +
 vm/mterp/c_notaint/OP_CONST_STRING.cpp             |   18 +
 vm/mterp/c_notaint/OP_CONST_STRING_JUMBO.cpp       |   20 +
 vm/mterp/c_notaint/OP_CONST_WIDE.cpp               |   14 +
 vm/mterp/c_notaint/OP_CONST_WIDE_16.cpp            |    7 +
 vm/mterp/c_notaint/OP_CONST_WIDE_32.cpp            |   12 +
 vm/mterp/c_notaint/OP_CONST_WIDE_HIGH16.cpp        |    7 +
 vm/mterp/c_notaint/OP_DIV_DOUBLE.cpp               |    2 +
 vm/mterp/c_notaint/OP_DIV_DOUBLE_2ADDR.cpp         |    2 +
 vm/mterp/c_notaint/OP_DIV_FLOAT.cpp                |    2 +
 vm/mterp/c_notaint/OP_DIV_FLOAT_2ADDR.cpp          |    2 +
 vm/mterp/c_notaint/OP_DIV_INT.cpp                  |    2 +
 vm/mterp/c_notaint/OP_DIV_INT_2ADDR.cpp            |    2 +
 vm/mterp/c_notaint/OP_DIV_INT_LIT16.cpp            |    2 +
 vm/mterp/c_notaint/OP_DIV_INT_LIT8.cpp             |    2 +
 vm/mterp/c_notaint/OP_DIV_LONG.cpp                 |    2 +
 vm/mterp/c_notaint/OP_DIV_LONG_2ADDR.cpp           |    2 +
 vm/mterp/c_notaint/OP_DOUBLE_TO_FLOAT.cpp          |    2 +
 vm/mterp/c_notaint/OP_DOUBLE_TO_INT.cpp            |    3 +
 vm/mterp/c_notaint/OP_DOUBLE_TO_LONG.cpp           |    3 +
 vm/mterp/c_notaint/OP_EXECUTE_INLINE.cpp           |   59 +
 vm/mterp/c_notaint/OP_EXECUTE_INLINE_RANGE.cpp     |   43 +
 vm/mterp/c_notaint/OP_FILLED_NEW_ARRAY.cpp         |    3 +
 vm/mterp/c_notaint/OP_FILLED_NEW_ARRAY_RANGE.cpp   |    3 +
 vm/mterp/c_notaint/OP_FILL_ARRAY_DATA.cpp          |   27 +
 vm/mterp/c_notaint/OP_FLOAT_TO_DOUBLE.cpp          |    2 +
 vm/mterp/c_notaint/OP_FLOAT_TO_INT.cpp             |    3 +
 vm/mterp/c_notaint/OP_FLOAT_TO_LONG.cpp            |    3 +
 vm/mterp/c_notaint/OP_GOTO.cpp                     |   11 +
 vm/mterp/c_notaint/OP_GOTO_16.cpp                  |   14 +
 vm/mterp/c_notaint/OP_GOTO_32.cpp                  |   15 +
 vm/mterp/c_notaint/OP_IF_EQ.cpp                    |    2 +
 vm/mterp/c_notaint/OP_IF_EQZ.cpp                   |    2 +
 vm/mterp/c_notaint/OP_IF_GE.cpp                    |    2 +
 vm/mterp/c_notaint/OP_IF_GEZ.cpp                   |    2 +
 vm/mterp/c_notaint/OP_IF_GT.cpp                    |    2 +
 vm/mterp/c_notaint/OP_IF_GTZ.cpp                   |    2 +
 vm/mterp/c_notaint/OP_IF_LE.cpp                    |    2 +
 vm/mterp/c_notaint/OP_IF_LEZ.cpp                   |    2 +
 vm/mterp/c_notaint/OP_IF_LT.cpp                    |    2 +
 vm/mterp/c_notaint/OP_IF_LTZ.cpp                   |    2 +
 vm/mterp/c_notaint/OP_IF_NE.cpp                    |    2 +
 vm/mterp/c_notaint/OP_IF_NEZ.cpp                   |    2 +
 vm/mterp/c_notaint/OP_IGET.cpp                     |    2 +
 vm/mterp/c_notaint/OP_IGET_BOOLEAN.cpp             |    2 +
 vm/mterp/c_notaint/OP_IGET_BYTE.cpp                |    2 +
 vm/mterp/c_notaint/OP_IGET_CHAR.cpp                |    2 +
 vm/mterp/c_notaint/OP_IGET_OBJECT.cpp              |    2 +
 vm/mterp/c_notaint/OP_IGET_OBJECT_QUICK.cpp        |    2 +
 vm/mterp/c_notaint/OP_IGET_OBJECT_VOLATILE.cpp     |    2 +
 vm/mterp/c_notaint/OP_IGET_QUICK.cpp               |    2 +
 vm/mterp/c_notaint/OP_IGET_SHORT.cpp               |    2 +
 vm/mterp/c_notaint/OP_IGET_VOLATILE.cpp            |    2 +
 vm/mterp/c_notaint/OP_IGET_WIDE.cpp                |    2 +
 vm/mterp/c_notaint/OP_IGET_WIDE_QUICK.cpp          |    2 +
 vm/mterp/c_notaint/OP_IGET_WIDE_VOLATILE.cpp       |    2 +
 vm/mterp/c_notaint/OP_INSTANCE_OF.cpp              |   30 +
 vm/mterp/c_notaint/OP_INT_TO_BYTE.cpp              |    2 +
 vm/mterp/c_notaint/OP_INT_TO_CHAR.cpp              |    2 +
 vm/mterp/c_notaint/OP_INT_TO_DOUBLE.cpp            |    2 +
 vm/mterp/c_notaint/OP_INT_TO_FLOAT.cpp             |    2 +
 vm/mterp/c_notaint/OP_INT_TO_LONG.cpp              |    2 +
 vm/mterp/c_notaint/OP_INT_TO_SHORT.cpp             |    2 +
 vm/mterp/c_notaint/OP_INVOKE_DIRECT.cpp            |    3 +
 vm/mterp/c_notaint/OP_INVOKE_DIRECT_RANGE.cpp      |    3 +
 vm/mterp/c_notaint/OP_INVOKE_INTERFACE.cpp         |    3 +
 vm/mterp/c_notaint/OP_INVOKE_INTERFACE_RANGE.cpp   |    3 +
 vm/mterp/c_notaint/OP_INVOKE_OBJECT_INIT_RANGE.cpp |   29 +
 vm/mterp/c_notaint/OP_INVOKE_STATIC.cpp            |    3 +
 vm/mterp/c_notaint/OP_INVOKE_STATIC_RANGE.cpp      |    3 +
 vm/mterp/c_notaint/OP_INVOKE_SUPER.cpp             |    3 +
 vm/mterp/c_notaint/OP_INVOKE_SUPER_QUICK.cpp       |    3 +
 vm/mterp/c_notaint/OP_INVOKE_SUPER_QUICK_RANGE.cpp |    3 +
 vm/mterp/c_notaint/OP_INVOKE_SUPER_RANGE.cpp       |    3 +
 vm/mterp/c_notaint/OP_INVOKE_VIRTUAL.cpp           |    3 +
 vm/mterp/c_notaint/OP_INVOKE_VIRTUAL_QUICK.cpp     |    3 +
 .../c_notaint/OP_INVOKE_VIRTUAL_QUICK_RANGE.cpp    |    3 +
 vm/mterp/c_notaint/OP_INVOKE_VIRTUAL_RANGE.cpp     |    3 +
 vm/mterp/c_notaint/OP_IPUT.cpp                     |    2 +
 vm/mterp/c_notaint/OP_IPUT_BOOLEAN.cpp             |    2 +
 vm/mterp/c_notaint/OP_IPUT_BYTE.cpp                |    2 +
 vm/mterp/c_notaint/OP_IPUT_CHAR.cpp                |    2 +
 vm/mterp/c_notaint/OP_IPUT_OBJECT.cpp              |   13 +
 vm/mterp/c_notaint/OP_IPUT_OBJECT_QUICK.cpp        |    2 +
 vm/mterp/c_notaint/OP_IPUT_OBJECT_VOLATILE.cpp     |    2 +
 vm/mterp/c_notaint/OP_IPUT_QUICK.cpp               |    2 +
 vm/mterp/c_notaint/OP_IPUT_SHORT.cpp               |    2 +
 vm/mterp/c_notaint/OP_IPUT_VOLATILE.cpp            |    2 +
 vm/mterp/c_notaint/OP_IPUT_WIDE.cpp                |    2 +
 vm/mterp/c_notaint/OP_IPUT_WIDE_QUICK.cpp          |    2 +
 vm/mterp/c_notaint/OP_IPUT_WIDE_VOLATILE.cpp       |    2 +
 vm/mterp/c_notaint/OP_LONG_TO_DOUBLE.cpp           |    2 +
 vm/mterp/c_notaint/OP_LONG_TO_FLOAT.cpp            |    2 +
 vm/mterp/c_notaint/OP_LONG_TO_INT.cpp              |    2 +
 vm/mterp/c_notaint/OP_MONITOR_ENTER.cpp            |   16 +
 vm/mterp/c_notaint/OP_MONITOR_EXIT.cpp             |   30 +
 vm/mterp/c_notaint/OP_MOVE.cpp                     |    9 +
 vm/mterp/c_notaint/OP_MOVE_16.cpp                  |    9 +
 vm/mterp/c_notaint/OP_MOVE_EXCEPTION.cpp           |    8 +
 vm/mterp/c_notaint/OP_MOVE_FROM16.cpp              |    9 +
 vm/mterp/c_notaint/OP_MOVE_OBJECT.cpp              |    1 +
 vm/mterp/c_notaint/OP_MOVE_OBJECT_16.cpp           |    1 +
 vm/mterp/c_notaint/OP_MOVE_OBJECT_FROM16.cpp       |    1 +
 vm/mterp/c_notaint/OP_MOVE_RESULT.cpp              |    8 +
 vm/mterp/c_notaint/OP_MOVE_RESULT_OBJECT.cpp       |    1 +
 vm/mterp/c_notaint/OP_MOVE_RESULT_WIDE.cpp         |    6 +
 vm/mterp/c_notaint/OP_MOVE_WIDE.cpp                |   10 +
 vm/mterp/c_notaint/OP_MOVE_WIDE_16.cpp             |    8 +
 vm/mterp/c_notaint/OP_MOVE_WIDE_FROM16.cpp         |    8 +
 vm/mterp/c_notaint/OP_MUL_DOUBLE.cpp               |    2 +
 vm/mterp/c_notaint/OP_MUL_DOUBLE_2ADDR.cpp         |    2 +
 vm/mterp/c_notaint/OP_MUL_FLOAT.cpp                |    2 +
 vm/mterp/c_notaint/OP_MUL_FLOAT_2ADDR.cpp          |    2 +
 vm/mterp/c_notaint/OP_MUL_INT.cpp                  |    2 +
 vm/mterp/c_notaint/OP_MUL_INT_2ADDR.cpp            |    2 +
 vm/mterp/c_notaint/OP_MUL_INT_LIT16.cpp            |    2 +
 vm/mterp/c_notaint/OP_MUL_INT_LIT8.cpp             |    2 +
 vm/mterp/c_notaint/OP_MUL_LONG.cpp                 |    2 +
 vm/mterp/c_notaint/OP_MUL_LONG_2ADDR.cpp           |    2 +
 vm/mterp/c_notaint/OP_NEG_DOUBLE.cpp               |    2 +
 vm/mterp/c_notaint/OP_NEG_FLOAT.cpp                |    2 +
 vm/mterp/c_notaint/OP_NEG_INT.cpp                  |    2 +
 vm/mterp/c_notaint/OP_NEG_LONG.cpp                 |    2 +
 vm/mterp/c_notaint/OP_NEW_ARRAY.cpp                |   35 +
 vm/mterp/c_notaint/OP_NEW_INSTANCE.cpp             |   48 +
 vm/mterp/c_notaint/OP_NOP.cpp                      |    3 +
 vm/mterp/c_notaint/OP_NOT_INT.cpp                  |    2 +
 vm/mterp/c_notaint/OP_NOT_LONG.cpp                 |    2 +
 vm/mterp/c_notaint/OP_OR_INT.cpp                   |    2 +
 vm/mterp/c_notaint/OP_OR_INT_2ADDR.cpp             |    2 +
 vm/mterp/c_notaint/OP_OR_INT_LIT16.cpp             |    2 +
 vm/mterp/c_notaint/OP_OR_INT_LIT8.cpp              |    2 +
 vm/mterp/c_notaint/OP_OR_LONG.cpp                  |    2 +
 vm/mterp/c_notaint/OP_OR_LONG_2ADDR.cpp            |    2 +
 vm/mterp/c_notaint/OP_PACKED_SWITCH.cpp            |   29 +
 vm/mterp/c_notaint/OP_REM_DOUBLE.cpp               |   13 +
 vm/mterp/c_notaint/OP_REM_DOUBLE_2ADDR.cpp         |    8 +
 vm/mterp/c_notaint/OP_REM_FLOAT.cpp                |   13 +
 vm/mterp/c_notaint/OP_REM_FLOAT_2ADDR.cpp          |    8 +
 vm/mterp/c_notaint/OP_REM_INT.cpp                  |    2 +
 vm/mterp/c_notaint/OP_REM_INT_2ADDR.cpp            |    2 +
 vm/mterp/c_notaint/OP_REM_INT_LIT16.cpp            |    2 +
 vm/mterp/c_notaint/OP_REM_INT_LIT8.cpp             |    2 +
 vm/mterp/c_notaint/OP_REM_LONG.cpp                 |    2 +
 vm/mterp/c_notaint/OP_REM_LONG_2ADDR.cpp           |    2 +
 vm/mterp/c_notaint/OP_RETURN.cpp                   |    7 +
 vm/mterp/c_notaint/OP_RETURN_OBJECT.cpp            |    1 +
 vm/mterp/c_notaint/OP_RETURN_VOID.cpp              |    7 +
 vm/mterp/c_notaint/OP_RETURN_VOID_BARRIER.cpp      |    8 +
 vm/mterp/c_notaint/OP_RETURN_WIDE.cpp              |    6 +
 vm/mterp/c_notaint/OP_RSUB_INT.cpp                 |   10 +
 vm/mterp/c_notaint/OP_RSUB_INT_LIT8.cpp            |   12 +
 vm/mterp/c_notaint/OP_SGET.cpp                     |    2 +
 vm/mterp/c_notaint/OP_SGET_BOOLEAN.cpp             |    2 +
 vm/mterp/c_notaint/OP_SGET_BYTE.cpp                |    2 +
 vm/mterp/c_notaint/OP_SGET_CHAR.cpp                |    2 +
 vm/mterp/c_notaint/OP_SGET_OBJECT.cpp              |    2 +
 vm/mterp/c_notaint/OP_SGET_OBJECT_VOLATILE.cpp     |    2 +
 vm/mterp/c_notaint/OP_SGET_SHORT.cpp               |    2 +
 vm/mterp/c_notaint/OP_SGET_VOLATILE.cpp            |    2 +
 vm/mterp/c_notaint/OP_SGET_WIDE.cpp                |    2 +
 vm/mterp/c_notaint/OP_SGET_WIDE_VOLATILE.cpp       |    2 +
 vm/mterp/c_notaint/OP_SHL_INT.cpp                  |    2 +
 vm/mterp/c_notaint/OP_SHL_INT_2ADDR.cpp            |    2 +
 vm/mterp/c_notaint/OP_SHL_INT_LIT8.cpp             |    2 +
 vm/mterp/c_notaint/OP_SHL_LONG.cpp                 |    2 +
 vm/mterp/c_notaint/OP_SHL_LONG_2ADDR.cpp           |    2 +
 vm/mterp/c_notaint/OP_SHR_INT.cpp                  |    2 +
 vm/mterp/c_notaint/OP_SHR_INT_2ADDR.cpp            |    2 +
 vm/mterp/c_notaint/OP_SHR_INT_LIT8.cpp             |    2 +
 vm/mterp/c_notaint/OP_SHR_LONG.cpp                 |    2 +
 vm/mterp/c_notaint/OP_SHR_LONG_2ADDR.cpp           |    2 +
 vm/mterp/c_notaint/OP_SPARSE_SWITCH.cpp            |   29 +
 vm/mterp/c_notaint/OP_SPUT.cpp                     |    2 +
 vm/mterp/c_notaint/OP_SPUT_BOOLEAN.cpp             |    2 +
 vm/mterp/c_notaint/OP_SPUT_BYTE.cpp                |    2 +
 vm/mterp/c_notaint/OP_SPUT_CHAR.cpp                |    2 +
 vm/mterp/c_notaint/OP_SPUT_OBJECT.cpp              |    2 +
 vm/mterp/c_notaint/OP_SPUT_OBJECT_VOLATILE.cpp     |    2 +
 vm/mterp/c_notaint/OP_SPUT_SHORT.cpp               |    2 +
 vm/mterp/c_notaint/OP_SPUT_VOLATILE.cpp            |    2 +
 vm/mterp/c_notaint/OP_SPUT_WIDE.cpp                |    2 +
 vm/mterp/c_notaint/OP_SPUT_WIDE_VOLATILE.cpp       |    2 +
 vm/mterp/c_notaint/OP_SUB_DOUBLE.cpp               |    2 +
 vm/mterp/c_notaint/OP_SUB_DOUBLE_2ADDR.cpp         |    2 +
 vm/mterp/c_notaint/OP_SUB_FLOAT.cpp                |    2 +
 vm/mterp/c_notaint/OP_SUB_FLOAT_2ADDR.cpp          |    2 +
 vm/mterp/c_notaint/OP_SUB_INT.cpp                  |    2 +
 vm/mterp/c_notaint/OP_SUB_INT_2ADDR.cpp            |    2 +
 vm/mterp/c_notaint/OP_SUB_LONG.cpp                 |    2 +
 vm/mterp/c_notaint/OP_SUB_LONG_2ADDR.cpp           |    2 +
 vm/mterp/c_notaint/OP_THROW.cpp                    |   24 +
 vm/mterp/c_notaint/OP_THROW_VERIFICATION_ERROR.cpp |    7 +
 vm/mterp/c_notaint/OP_UNUSED_3E.cpp                |    2 +
 vm/mterp/c_notaint/OP_UNUSED_3F.cpp                |    2 +
 vm/mterp/c_notaint/OP_UNUSED_40.cpp                |    2 +
 vm/mterp/c_notaint/OP_UNUSED_41.cpp                |    2 +
 vm/mterp/c_notaint/OP_UNUSED_42.cpp                |    2 +
 vm/mterp/c_notaint/OP_UNUSED_43.cpp                |    2 +
 vm/mterp/c_notaint/OP_UNUSED_73.cpp                |    2 +
 vm/mterp/c_notaint/OP_UNUSED_79.cpp                |    2 +
 vm/mterp/c_notaint/OP_UNUSED_7A.cpp                |    2 +
 vm/mterp/c_notaint/OP_UNUSED_FF.cpp                |    8 +
 vm/mterp/c_notaint/OP_USHR_INT.cpp                 |    2 +
 vm/mterp/c_notaint/OP_USHR_INT_2ADDR.cpp           |    2 +
 vm/mterp/c_notaint/OP_USHR_INT_LIT8.cpp            |    2 +
 vm/mterp/c_notaint/OP_USHR_LONG.cpp                |    2 +
 vm/mterp/c_notaint/OP_USHR_LONG_2ADDR.cpp          |    2 +
 vm/mterp/c_notaint/OP_XOR_INT.cpp                  |    2 +
 vm/mterp/c_notaint/OP_XOR_INT_2ADDR.cpp            |    2 +
 vm/mterp/c_notaint/OP_XOR_INT_LIT16.cpp            |    2 +
 vm/mterp/c_notaint/OP_XOR_INT_LIT8.cpp             |    2 +
 vm/mterp/c_notaint/OP_XOR_LONG.cpp                 |    2 +
 vm/mterp/c_notaint/OP_XOR_LONG_2ADDR.cpp           |    2 +
 vm/mterp/c_notaint/gotoTargets.cpp                 |  970 ++++
 vm/mterp/c_notaint/header.cpp                      |  361 ++
 vm/mterp/c_notaint/opcommon.cpp                    |  647 +++
 vm/mterp/common/asm-constants.h                    |  134 +-
 vm/mterp/config-armv7-a                            |  209 +-
 vm/mterp/config-armv7-a-neon                       |  209 +-
 vm/mterp/config-armv7-a-neon.notaint               |  170 +
 vm/mterp/config-armv7-a.notaint                    |  172 +
 vm/mterp/cstubs/enddefs.cpp                        |    5 +
 vm/mterp/cstubs/stubdefs.cpp                       |    4 +
 vm/mterp/out/InterpAsm-armv7-a-neon.S              | 5814 +++++++++++++++-----
 vm/mterp/out/InterpAsm-armv7-a.S                   | 5814 +++++++++++++++-----
 vm/mterp/out/InterpC-allstubs.cpp                  |  578 +-
 vm/mterp/out/InterpC-armv5te-vfp.cpp               |  297 +-
 vm/mterp/out/InterpC-armv5te.cpp                   |  297 +-
 vm/mterp/out/InterpC-armv7-a-neon.cpp              |  299 +-
 vm/mterp/out/InterpC-armv7-a.cpp                   |  299 +-
 vm/mterp/out/InterpC-portable.cpp                  |  578 +-
 vm/mterp/out/InterpC-x86-atom.cpp                  |  425 +-
 vm/mterp/out/InterpC-x86.cpp                       |  425 +-
 vm/mterp/portable/enddefs.cpp                      |    3 +
 vm/mterp/portable/entry.cpp                        |    6 +
 vm/native/InternalNative.cpp                       |    3 +
 vm/native/InternalNativePriv.h                     |   21 +-
 vm/native/dalvik_system_Taint.cpp                  |  751 +++
 vm/native/java_lang_Double.cpp                     |    9 +
 vm/native/java_lang_Float.cpp                      |    9 +
 vm/native/java_lang_Math.cpp                       |   15 +
 vm/native/java_lang_String.cpp                     |   13 +
 vm/native/java_lang_System.cpp                     |   27 +
 vm/native/java_lang_reflect_Field.cpp              |  129 +
 vm/oo/Array.cpp                                    |    3 +
 vm/oo/Class.cpp                                    |   22 +-
 vm/oo/Object.h                                     |   15 +
 vm/oo/ObjectInlines.h                              |  207 +
 vm/reflect/Reflect.cpp                             |   63 +
 vm/reflect/Reflect.h                               |   13 +
 vm/tprop/TaintPolicy.cpp                           |   74 +
 vm/tprop/TaintPolicyPriv.h                         |   69 +
 vm/tprop/TaintProp.cpp                             |  774 +++
 vm/tprop/TaintProp.h                               |   15 +
 928 files changed, 43159 insertions(+), 3187 deletions(-)
 create mode 100644 libattr/Android.mk
 create mode 100644 libattr/Makefile
 create mode 100644 libattr/README.txt
 create mode 100644 libattr/attr/attributes.h
 create mode 100644 libattr/attr/error_context.h
 create mode 100644 libattr/attr/libattr.h
 create mode 100644 libattr/attr/xattr.h
 create mode 100644 libattr/attr_copy_action.c
 create mode 100644 libattr/attr_copy_check.c
 create mode 100644 libattr/attr_copy_fd.c
 create mode 100644 libattr/attr_copy_file.c
 create mode 100644 libattr/libattr.c
 create mode 100644 libattr/libattr.h
 create mode 100644 libattr/syscalls.c
 create mode 100644 tools/tprop/Android.mk
 create mode 100644 tools/tprop/ftaint.c
 create mode 100644 vm/compiler/template/armv5te-vfp_taint/TEMPLATE_ADD_DOUBLE_VFP.S
 create mode 100644 vm/compiler/template/armv5te-vfp_taint/TEMPLATE_ADD_FLOAT_VFP.S
 create mode 100644 vm/compiler/template/armv5te-vfp_taint/TEMPLATE_CMPG_DOUBLE_VFP.S
 create mode 100644 vm/compiler/template/armv5te-vfp_taint/TEMPLATE_CMPG_FLOAT_VFP.S
 create mode 100644 vm/compiler/template/armv5te-vfp_taint/TEMPLATE_CMPL_DOUBLE_VFP.S
 create mode 100644 vm/compiler/template/armv5te-vfp_taint/TEMPLATE_CMPL_FLOAT_VFP.S
 create mode 100644 vm/compiler/template/armv5te-vfp_taint/TEMPLATE_DIV_DOUBLE_VFP.S
 create mode 100644 vm/compiler/template/armv5te-vfp_taint/TEMPLATE_DIV_FLOAT_VFP.S
 create mode 100644 vm/compiler/template/armv5te-vfp_taint/TEMPLATE_DOUBLE_TO_FLOAT_VFP.S
 create mode 100644 vm/compiler/template/armv5te-vfp_taint/TEMPLATE_DOUBLE_TO_INT_VFP.S
 create mode 100644 vm/compiler/template/armv5te-vfp_taint/TEMPLATE_FLOAT_TO_DOUBLE_VFP.S
 create mode 100644 vm/compiler/template/armv5te-vfp_taint/TEMPLATE_FLOAT_TO_INT_VFP.S
 create mode 100644 vm/compiler/template/armv5te-vfp_taint/TEMPLATE_INT_TO_DOUBLE_VFP.S
 create mode 100644 vm/compiler/template/armv5te-vfp_taint/TEMPLATE_INT_TO_FLOAT_VFP.S
 create mode 100644 vm/compiler/template/armv5te-vfp_taint/TEMPLATE_MEM_OP_DECODE.S
 create mode 100644 vm/compiler/template/armv5te-vfp_taint/TEMPLATE_MUL_DOUBLE_VFP.S
 create mode 100644 vm/compiler/template/armv5te-vfp_taint/TEMPLATE_MUL_FLOAT_VFP.S
 create mode 100644 vm/compiler/template/armv5te-vfp_taint/TEMPLATE_RESTORE_STATE.S
 create mode 100644 vm/compiler/template/armv5te-vfp_taint/TEMPLATE_SAVE_STATE.S
 create mode 100644 vm/compiler/template/armv5te-vfp_taint/TEMPLATE_SQRT_DOUBLE_VFP.S
 create mode 100644 vm/compiler/template/armv5te-vfp_taint/TEMPLATE_SUB_DOUBLE_VFP.S
 create mode 100644 vm/compiler/template/armv5te-vfp_taint/TEMPLATE_SUB_FLOAT_VFP.S
 create mode 100644 vm/compiler/template/armv5te-vfp_taint/TemplateOpList.h
 create mode 100644 vm/compiler/template/armv5te-vfp_taint/fbinop.S
 create mode 100644 vm/compiler/template/armv5te-vfp_taint/fbinopWide.S
 create mode 100644 vm/compiler/template/armv5te-vfp_taint/funop.S
 create mode 100644 vm/compiler/template/armv5te-vfp_taint/funopNarrower.S
 create mode 100644 vm/compiler/template/armv5te-vfp_taint/funopWider.S
 create mode 100644 vm/compiler/template/armv5te-vfp_taint/platform.S
 create mode 100644 vm/compiler/template/armv5te_taint/TEMPLATE_CMPG_DOUBLE.S
 create mode 100644 vm/compiler/template/armv5te_taint/TEMPLATE_CMPG_FLOAT.S
 create mode 100644 vm/compiler/template/armv5te_taint/TEMPLATE_CMPL_DOUBLE.S
 create mode 100644 vm/compiler/template/armv5te_taint/TEMPLATE_CMPL_FLOAT.S
 create mode 100644 vm/compiler/template/armv5te_taint/TEMPLATE_CMP_LONG.S
 create mode 100644 vm/compiler/template/armv5te_taint/TEMPLATE_INTERPRET.S
 create mode 100644 vm/compiler/template/armv5te_taint/TEMPLATE_INVOKE_METHOD_CHAIN.S
 create mode 100644 vm/compiler/template/armv5te_taint/TEMPLATE_INVOKE_METHOD_CHAIN_PROF.S
 create mode 100644 vm/compiler/template/armv5te_taint/TEMPLATE_INVOKE_METHOD_NATIVE.S
 create mode 100644 vm/compiler/template/armv5te_taint/TEMPLATE_INVOKE_METHOD_NATIVE.S~
 create mode 100644 vm/compiler/template/armv5te_taint/TEMPLATE_INVOKE_METHOD_NATIVE_PROF.S
 create mode 100644 vm/compiler/template/armv5te_taint/TEMPLATE_INVOKE_METHOD_NO_OPT.S
 create mode 100644 vm/compiler/template/armv5te_taint/TEMPLATE_INVOKE_METHOD_NO_OPT.S~
 create mode 100644 vm/compiler/template/armv5te_taint/TEMPLATE_INVOKE_METHOD_NO_OPT_PROF.S
 create mode 100644 vm/compiler/template/armv5te_taint/TEMPLATE_INVOKE_METHOD_PREDICTED_CHAIN.S
 create mode 100644 vm/compiler/template/armv5te_taint/TEMPLATE_INVOKE_METHOD_PREDICTED_CHAIN_PROF.S
 create mode 100644 vm/compiler/template/armv5te_taint/TEMPLATE_MEM_OP_DECODE.S
 create mode 100644 vm/compiler/template/armv5te_taint/TEMPLATE_MONITOR_ENTER.S
 create mode 100644 vm/compiler/template/armv5te_taint/TEMPLATE_MONITOR_ENTER_DEBUG.S
 create mode 100644 vm/compiler/template/armv5te_taint/TEMPLATE_MUL_LONG.S
 create mode 100644 vm/compiler/template/armv5te_taint/TEMPLATE_PERIODIC_PROFILING.S
 create mode 100644 vm/compiler/template/armv5te_taint/TEMPLATE_RESTORE_STATE.S
 create mode 100644 vm/compiler/template/armv5te_taint/TEMPLATE_RETURN.S
 create mode 100644 vm/compiler/template/armv5te_taint/TEMPLATE_RETURN_PROF.S
 create mode 100644 vm/compiler/template/armv5te_taint/TEMPLATE_SAVE_STATE.S
 create mode 100644 vm/compiler/template/armv5te_taint/TEMPLATE_SHL_LONG.S
 create mode 100644 vm/compiler/template/armv5te_taint/TEMPLATE_SHR_LONG.S
 create mode 100644 vm/compiler/template/armv5te_taint/TEMPLATE_STRING_COMPARETO.S
 create mode 100644 vm/compiler/template/armv5te_taint/TEMPLATE_STRING_INDEXOF.S
 create mode 100644 vm/compiler/template/armv5te_taint/TEMPLATE_THROW_EXCEPTION_COMMON.S
 create mode 100644 vm/compiler/template/armv5te_taint/TEMPLATE_USHR_LONG.S
 create mode 100644 vm/compiler/template/armv5te_taint/TemplateOpList.h
 create mode 100644 vm/compiler/template/armv5te_taint/footer.S
 create mode 100644 vm/compiler/template/armv5te_taint/header.S
 create mode 100644 vm/compiler/template/armv5te_taint/platform.S
 create mode 100644 vm/compiler/template/config-armv7-a-neon.notaint
 create mode 100644 vm/compiler/template/config-armv7-a.notaint
 create mode 100644 vm/compiler/template_notaint/Makefile-template
 create mode 100644 vm/compiler/template_notaint/README.txt
 create mode 100644 vm/compiler/template_notaint/armv5te-vfp/TEMPLATE_ADD_DOUBLE_VFP.S
 create mode 100644 vm/compiler/template_notaint/armv5te-vfp/TEMPLATE_ADD_FLOAT_VFP.S
 create mode 100644 vm/compiler/template_notaint/armv5te-vfp/TEMPLATE_CMPG_DOUBLE_VFP.S
 create mode 100644 vm/compiler/template_notaint/armv5te-vfp/TEMPLATE_CMPG_FLOAT_VFP.S
 create mode 100644 vm/compiler/template_notaint/armv5te-vfp/TEMPLATE_CMPL_DOUBLE_VFP.S
 create mode 100644 vm/compiler/template_notaint/armv5te-vfp/TEMPLATE_CMPL_FLOAT_VFP.S
 create mode 100644 vm/compiler/template_notaint/armv5te-vfp/TEMPLATE_DIV_DOUBLE_VFP.S
 create mode 100644 vm/compiler/template_notaint/armv5te-vfp/TEMPLATE_DIV_FLOAT_VFP.S
 create mode 100644 vm/compiler/template_notaint/armv5te-vfp/TEMPLATE_DOUBLE_TO_FLOAT_VFP.S
 create mode 100644 vm/compiler/template_notaint/armv5te-vfp/TEMPLATE_DOUBLE_TO_INT_VFP.S
 create mode 100644 vm/compiler/template_notaint/armv5te-vfp/TEMPLATE_FLOAT_TO_DOUBLE_VFP.S
 create mode 100644 vm/compiler/template_notaint/armv5te-vfp/TEMPLATE_FLOAT_TO_INT_VFP.S
 create mode 100644 vm/compiler/template_notaint/armv5te-vfp/TEMPLATE_INT_TO_DOUBLE_VFP.S
 create mode 100644 vm/compiler/template_notaint/armv5te-vfp/TEMPLATE_INT_TO_FLOAT_VFP.S
 create mode 100644 vm/compiler/template_notaint/armv5te-vfp/TEMPLATE_MEM_OP_DECODE.S
 create mode 100644 vm/compiler/template_notaint/armv5te-vfp/TEMPLATE_MUL_DOUBLE_VFP.S
 create mode 100644 vm/compiler/template_notaint/armv5te-vfp/TEMPLATE_MUL_FLOAT_VFP.S
 create mode 100644 vm/compiler/template_notaint/armv5te-vfp/TEMPLATE_RESTORE_STATE.S
 create mode 100644 vm/compiler/template_notaint/armv5te-vfp/TEMPLATE_SAVE_STATE.S
 create mode 100644 vm/compiler/template_notaint/armv5te-vfp/TEMPLATE_SQRT_DOUBLE_VFP.S
 create mode 100644 vm/compiler/template_notaint/armv5te-vfp/TEMPLATE_SUB_DOUBLE_VFP.S
 create mode 100644 vm/compiler/template_notaint/armv5te-vfp/TEMPLATE_SUB_FLOAT_VFP.S
 create mode 100644 vm/compiler/template_notaint/armv5te-vfp/TemplateOpList.h
 create mode 100644 vm/compiler/template_notaint/armv5te-vfp/fbinop.S
 create mode 100644 vm/compiler/template_notaint/armv5te-vfp/fbinopWide.S
 create mode 100644 vm/compiler/template_notaint/armv5te-vfp/funop.S
 create mode 100644 vm/compiler/template_notaint/armv5te-vfp/funopNarrower.S
 create mode 100644 vm/compiler/template_notaint/armv5te-vfp/funopWider.S
 create mode 100644 vm/compiler/template_notaint/armv5te-vfp/platform.S
 create mode 100644 vm/compiler/template_notaint/armv5te/TEMPLATE_CMPG_DOUBLE.S
 create mode 100644 vm/compiler/template_notaint/armv5te/TEMPLATE_CMPG_FLOAT.S
 create mode 100644 vm/compiler/template_notaint/armv5te/TEMPLATE_CMPL_DOUBLE.S
 create mode 100644 vm/compiler/template_notaint/armv5te/TEMPLATE_CMPL_FLOAT.S
 create mode 100644 vm/compiler/template_notaint/armv5te/TEMPLATE_CMP_LONG.S
 create mode 100644 vm/compiler/template_notaint/armv5te/TEMPLATE_INTERPRET.S
 create mode 100644 vm/compiler/template_notaint/armv5te/TEMPLATE_INVOKE_METHOD_CHAIN.S
 create mode 100644 vm/compiler/template_notaint/armv5te/TEMPLATE_INVOKE_METHOD_CHAIN_PROF.S
 create mode 100644 vm/compiler/template_notaint/armv5te/TEMPLATE_INVOKE_METHOD_NATIVE.S
 create mode 100644 vm/compiler/template_notaint/armv5te/TEMPLATE_INVOKE_METHOD_NATIVE_PROF.S
 create mode 100644 vm/compiler/template_notaint/armv5te/TEMPLATE_INVOKE_METHOD_NO_OPT.S
 create mode 100644 vm/compiler/template_notaint/armv5te/TEMPLATE_INVOKE_METHOD_NO_OPT_PROF.S
 create mode 100644 vm/compiler/template_notaint/armv5te/TEMPLATE_INVOKE_METHOD_PREDICTED_CHAIN.S
 create mode 100644 vm/compiler/template_notaint/armv5te/TEMPLATE_INVOKE_METHOD_PREDICTED_CHAIN_PROF.S
 create mode 100644 vm/compiler/template_notaint/armv5te/TEMPLATE_MEM_OP_DECODE.S
 create mode 100644 vm/compiler/template_notaint/armv5te/TEMPLATE_MONITOR_ENTER.S
 create mode 100644 vm/compiler/template_notaint/armv5te/TEMPLATE_MONITOR_ENTER_DEBUG.S
 create mode 100644 vm/compiler/template_notaint/armv5te/TEMPLATE_MUL_LONG.S
 create mode 100644 vm/compiler/template_notaint/armv5te/TEMPLATE_PERIODIC_PROFILING.S
 create mode 100644 vm/compiler/template_notaint/armv5te/TEMPLATE_RESTORE_STATE.S
 create mode 100644 vm/compiler/template_notaint/armv5te/TEMPLATE_RETURN.S
 create mode 100644 vm/compiler/template_notaint/armv5te/TEMPLATE_RETURN_PROF.S
 create mode 100644 vm/compiler/template_notaint/armv5te/TEMPLATE_SAVE_STATE.S
 create mode 100644 vm/compiler/template_notaint/armv5te/TEMPLATE_SHL_LONG.S
 create mode 100644 vm/compiler/template_notaint/armv5te/TEMPLATE_SHR_LONG.S
 create mode 100644 vm/compiler/template_notaint/armv5te/TEMPLATE_STRING_COMPARETO.S
 create mode 100644 vm/compiler/template_notaint/armv5te/TEMPLATE_STRING_INDEXOF.S
 create mode 100644 vm/compiler/template_notaint/armv5te/TEMPLATE_THROW_EXCEPTION_COMMON.S
 create mode 100644 vm/compiler/template_notaint/armv5te/TEMPLATE_USHR_LONG.S
 create mode 100644 vm/compiler/template_notaint/armv5te/TemplateOpList.h
 create mode 100644 vm/compiler/template_notaint/armv5te/footer.S
 create mode 100644 vm/compiler/template_notaint/armv5te/header.S
 create mode 100644 vm/compiler/template_notaint/armv5te/platform.S
 create mode 100644 vm/compiler/template_notaint/armv7-a-neon/TemplateOpList.h
 create mode 100644 vm/compiler/template_notaint/armv7-a/TemplateOpList.h
 create mode 100644 vm/compiler/template_notaint/config-armv5te
 create mode 100644 vm/compiler/template_notaint/config-armv5te-vfp
 create mode 100644 vm/compiler/template_notaint/config-armv7-a
 create mode 100644 vm/compiler/template_notaint/config-armv7-a-neon
 create mode 100644 vm/compiler/template_notaint/config-ia32
 create mode 100644 vm/compiler/template_notaint/gen-template.py
 create mode 100644 vm/compiler/template_notaint/ia32/TEMPLATE_INTERPRET.S
 create mode 100644 vm/compiler/template_notaint/ia32/TemplateOpList.h
 create mode 100644 vm/compiler/template_notaint/ia32/footer.S
 create mode 100644 vm/compiler/template_notaint/ia32/header.S
 create mode 100644 vm/compiler/template_notaint/ia32/platform.S
 create mode 100644 vm/compiler/template_notaint/out/CompilerTemplateAsm-armv5te-vfp.S
 create mode 100644 vm/compiler/template_notaint/out/CompilerTemplateAsm-armv5te.S
 create mode 100644 vm/compiler/template_notaint/out/CompilerTemplateAsm-armv7-a-neon.S
 create mode 100644 vm/compiler/template_notaint/out/CompilerTemplateAsm-armv7-a.S
 create mode 100644 vm/compiler/template_notaint/out/CompilerTemplateAsm-ia32.S
 create mode 100644 vm/compiler/template_notaint/rebuild.sh
 create mode 100644 vm/interp/Taint.h
 create mode 100644 vm/mterp/arm-vfp_taint/OP_ADD_DOUBLE.S
 create mode 100644 vm/mterp/arm-vfp_taint/OP_ADD_DOUBLE_2ADDR.S
 create mode 100644 vm/mterp/arm-vfp_taint/OP_ADD_FLOAT.S
 create mode 100644 vm/mterp/arm-vfp_taint/OP_ADD_FLOAT_2ADDR.S
 create mode 100644 vm/mterp/arm-vfp_taint/OP_CMPG_DOUBLE.S
 create mode 100644 vm/mterp/arm-vfp_taint/OP_CMPG_FLOAT.S
 create mode 100644 vm/mterp/arm-vfp_taint/OP_CMPL_DOUBLE.S
 create mode 100644 vm/mterp/arm-vfp_taint/OP_CMPL_FLOAT.S
 create mode 100644 vm/mterp/arm-vfp_taint/OP_DIV_DOUBLE.S
 create mode 100644 vm/mterp/arm-vfp_taint/OP_DIV_DOUBLE_2ADDR.S
 create mode 100644 vm/mterp/arm-vfp_taint/OP_DIV_FLOAT.S
 create mode 100644 vm/mterp/arm-vfp_taint/OP_DIV_FLOAT_2ADDR.S
 create mode 100644 vm/mterp/arm-vfp_taint/OP_DOUBLE_TO_FLOAT.S
 create mode 100644 vm/mterp/arm-vfp_taint/OP_DOUBLE_TO_INT.S
 create mode 100644 vm/mterp/arm-vfp_taint/OP_FLOAT_TO_DOUBLE.S
 create mode 100644 vm/mterp/arm-vfp_taint/OP_FLOAT_TO_INT.S
 create mode 100644 vm/mterp/arm-vfp_taint/OP_INT_TO_DOUBLE.S
 create mode 100644 vm/mterp/arm-vfp_taint/OP_INT_TO_FLOAT.S
 create mode 100644 vm/mterp/arm-vfp_taint/OP_MUL_DOUBLE.S
 create mode 100644 vm/mterp/arm-vfp_taint/OP_MUL_DOUBLE_2ADDR.S
 create mode 100644 vm/mterp/arm-vfp_taint/OP_MUL_FLOAT.S
 create mode 100644 vm/mterp/arm-vfp_taint/OP_MUL_FLOAT_2ADDR.S
 create mode 100644 vm/mterp/arm-vfp_taint/OP_SUB_DOUBLE.S
 create mode 100644 vm/mterp/arm-vfp_taint/OP_SUB_DOUBLE_2ADDR.S
 create mode 100644 vm/mterp/arm-vfp_taint/OP_SUB_FLOAT.S
 create mode 100644 vm/mterp/arm-vfp_taint/OP_SUB_FLOAT_2ADDR.S
 create mode 100644 vm/mterp/arm-vfp_taint/fbinop.S
 create mode 100644 vm/mterp/arm-vfp_taint/fbinop2addr.S
 create mode 100644 vm/mterp/arm-vfp_taint/fbinopWide.S
 create mode 100644 vm/mterp/arm-vfp_taint/fbinopWide2addr.S
 create mode 100644 vm/mterp/arm-vfp_taint/funop.S
 create mode 100644 vm/mterp/arm-vfp_taint/funopNarrower.S
 create mode 100644 vm/mterp/arm-vfp_taint/funopWider.S
 create mode 100644 vm/mterp/armv5te_taint/OP_ADD_DOUBLE.S
 create mode 100644 vm/mterp/armv5te_taint/OP_ADD_DOUBLE_2ADDR.S
 create mode 100644 vm/mterp/armv5te_taint/OP_ADD_FLOAT.S
 create mode 100644 vm/mterp/armv5te_taint/OP_ADD_FLOAT_2ADDR.S
 create mode 100644 vm/mterp/armv5te_taint/OP_ADD_INT.S
 create mode 100644 vm/mterp/armv5te_taint/OP_ADD_INT_2ADDR.S
 create mode 100644 vm/mterp/armv5te_taint/OP_ADD_INT_LIT16.S
 create mode 100644 vm/mterp/armv5te_taint/OP_ADD_INT_LIT8.S
 create mode 100644 vm/mterp/armv5te_taint/OP_ADD_LONG.S
 create mode 100644 vm/mterp/armv5te_taint/OP_ADD_LONG_2ADDR.S
 create mode 100644 vm/mterp/armv5te_taint/OP_AGET.S
 create mode 100644 vm/mterp/armv5te_taint/OP_AGET_BOOLEAN.S
 create mode 100644 vm/mterp/armv5te_taint/OP_AGET_BYTE.S
 create mode 100644 vm/mterp/armv5te_taint/OP_AGET_CHAR.S
 create mode 100644 vm/mterp/armv5te_taint/OP_AGET_OBJECT.S
 create mode 100644 vm/mterp/armv5te_taint/OP_AGET_SHORT.S
 create mode 100644 vm/mterp/armv5te_taint/OP_AGET_WIDE.S
 create mode 100644 vm/mterp/armv5te_taint/OP_AND_INT.S
 create mode 100644 vm/mterp/armv5te_taint/OP_AND_INT_2ADDR.S
 create mode 100644 vm/mterp/armv5te_taint/OP_AND_INT_LIT16.S
 create mode 100644 vm/mterp/armv5te_taint/OP_AND_INT_LIT8.S
 create mode 100644 vm/mterp/armv5te_taint/OP_AND_LONG.S
 create mode 100644 vm/mterp/armv5te_taint/OP_AND_LONG_2ADDR.S
 create mode 100644 vm/mterp/armv5te_taint/OP_APUT.S
 create mode 100644 vm/mterp/armv5te_taint/OP_APUT_BOOLEAN.S
 create mode 100644 vm/mterp/armv5te_taint/OP_APUT_BYTE.S
 create mode 100644 vm/mterp/armv5te_taint/OP_APUT_CHAR.S
 create mode 100644 vm/mterp/armv5te_taint/OP_APUT_OBJECT.S
 create mode 100644 vm/mterp/armv5te_taint/OP_APUT_SHORT.S
 create mode 100644 vm/mterp/armv5te_taint/OP_APUT_WIDE.S
 create mode 100644 vm/mterp/armv5te_taint/OP_ARRAY_LENGTH.S
 create mode 100644 vm/mterp/armv5te_taint/OP_BREAKPOINT.S
 create mode 100644 vm/mterp/armv5te_taint/OP_CHECK_CAST.S
 create mode 100644 vm/mterp/armv5te_taint/OP_CMPG_DOUBLE.S
 create mode 100644 vm/mterp/armv5te_taint/OP_CMPG_FLOAT.S
 create mode 100644 vm/mterp/armv5te_taint/OP_CMP_LONG.S
 create mode 100644 vm/mterp/armv5te_taint/OP_CONST.S
 create mode 100644 vm/mterp/armv5te_taint/OP_CONST_16.S
 create mode 100644 vm/mterp/armv5te_taint/OP_CONST_4.S
 create mode 100644 vm/mterp/armv5te_taint/OP_CONST_CLASS.S
 create mode 100644 vm/mterp/armv5te_taint/OP_CONST_HIGH16.S
 create mode 100644 vm/mterp/armv5te_taint/OP_CONST_STRING.S
 create mode 100644 vm/mterp/armv5te_taint/OP_CONST_STRING_JUMBO.S
 create mode 100644 vm/mterp/armv5te_taint/OP_CONST_WIDE.S
 create mode 100644 vm/mterp/armv5te_taint/OP_CONST_WIDE_16.S
 create mode 100644 vm/mterp/armv5te_taint/OP_CONST_WIDE_32.S
 create mode 100644 vm/mterp/armv5te_taint/OP_CONST_WIDE_HIGH16.S
 create mode 100644 vm/mterp/armv5te_taint/OP_DIV_DOUBLE.S
 create mode 100644 vm/mterp/armv5te_taint/OP_DIV_DOUBLE_2ADDR.S
 create mode 100644 vm/mterp/armv5te_taint/OP_DIV_FLOAT.S
 create mode 100644 vm/mterp/armv5te_taint/OP_DIV_FLOAT_2ADDR.S
 create mode 100644 vm/mterp/armv5te_taint/OP_DIV_INT.S
 create mode 100644 vm/mterp/armv5te_taint/OP_DIV_INT_2ADDR.S
 create mode 100644 vm/mterp/armv5te_taint/OP_DIV_INT_LIT16.S
 create mode 100644 vm/mterp/armv5te_taint/OP_DIV_INT_LIT8.S
 create mode 100644 vm/mterp/armv5te_taint/OP_DIV_LONG.S
 create mode 100644 vm/mterp/armv5te_taint/OP_DIV_LONG_2ADDR.S
 create mode 100644 vm/mterp/armv5te_taint/OP_DOUBLE_TO_FLOAT.S
 create mode 100644 vm/mterp/armv5te_taint/OP_DOUBLE_TO_INT.S
 create mode 100644 vm/mterp/armv5te_taint/OP_DOUBLE_TO_LONG.S
 create mode 100644 vm/mterp/armv5te_taint/OP_EXECUTE_INLINE.S
 create mode 100644 vm/mterp/armv5te_taint/OP_EXECUTE_INLINE_RANGE.S
 create mode 100644 vm/mterp/armv5te_taint/OP_FILLED_NEW_ARRAY.S
 create mode 100644 vm/mterp/armv5te_taint/OP_FILLED_NEW_ARRAY_RANGE.S
 create mode 100644 vm/mterp/armv5te_taint/OP_FILL_ARRAY_DATA.S
 create mode 100644 vm/mterp/armv5te_taint/OP_FLOAT_TO_DOUBLE.S
 create mode 100644 vm/mterp/armv5te_taint/OP_FLOAT_TO_INT.S
 create mode 100644 vm/mterp/armv5te_taint/OP_FLOAT_TO_LONG.S
 create mode 100644 vm/mterp/armv5te_taint/OP_GOTO.S
 create mode 100644 vm/mterp/armv5te_taint/OP_GOTO_16.S
 create mode 100644 vm/mterp/armv5te_taint/OP_GOTO_32.S
 create mode 100644 vm/mterp/armv5te_taint/OP_IF_EQ.S
 create mode 100644 vm/mterp/armv5te_taint/OP_IF_EQZ.S
 create mode 100644 vm/mterp/armv5te_taint/OP_IF_GE.S
 create mode 100644 vm/mterp/armv5te_taint/OP_IF_GEZ.S
 create mode 100644 vm/mterp/armv5te_taint/OP_IF_GT.S
 create mode 100644 vm/mterp/armv5te_taint/OP_IF_GTZ.S
 create mode 100644 vm/mterp/armv5te_taint/OP_IF_LE.S
 create mode 100644 vm/mterp/armv5te_taint/OP_IF_LEZ.S
 create mode 100644 vm/mterp/armv5te_taint/OP_IF_LT.S
 create mode 100644 vm/mterp/armv5te_taint/OP_IF_LTZ.S
 create mode 100644 vm/mterp/armv5te_taint/OP_IF_NE.S
 create mode 100644 vm/mterp/armv5te_taint/OP_IF_NEZ.S
 create mode 100644 vm/mterp/armv5te_taint/OP_IGET.S
 create mode 100644 vm/mterp/armv5te_taint/OP_IGET_BOOLEAN.S
 create mode 100644 vm/mterp/armv5te_taint/OP_IGET_BYTE.S
 create mode 100644 vm/mterp/armv5te_taint/OP_IGET_CHAR.S
 create mode 100644 vm/mterp/armv5te_taint/OP_IGET_OBJECT.S
 create mode 100644 vm/mterp/armv5te_taint/OP_IGET_OBJECT_QUICK.S
 create mode 100644 vm/mterp/armv5te_taint/OP_IGET_OBJECT_VOLATILE.S
 create mode 100644 vm/mterp/armv5te_taint/OP_IGET_QUICK.S
 create mode 100644 vm/mterp/armv5te_taint/OP_IGET_SHORT.S
 create mode 100644 vm/mterp/armv5te_taint/OP_IGET_VOLATILE.S
 create mode 100644 vm/mterp/armv5te_taint/OP_IGET_WIDE.S
 create mode 100644 vm/mterp/armv5te_taint/OP_IGET_WIDE_QUICK.S
 create mode 100644 vm/mterp/armv5te_taint/OP_IGET_WIDE_VOLATILE.S
 create mode 100644 vm/mterp/armv5te_taint/OP_INSTANCE_OF.S
 create mode 100644 vm/mterp/armv5te_taint/OP_INT_TO_BYTE.S
 create mode 100644 vm/mterp/armv5te_taint/OP_INT_TO_CHAR.S
 create mode 100644 vm/mterp/armv5te_taint/OP_INT_TO_DOUBLE.S
 create mode 100644 vm/mterp/armv5te_taint/OP_INT_TO_FLOAT.S
 create mode 100644 vm/mterp/armv5te_taint/OP_INT_TO_LONG.S
 create mode 100644 vm/mterp/armv5te_taint/OP_INT_TO_SHORT.S
 create mode 100644 vm/mterp/armv5te_taint/OP_INVOKE_DIRECT.S
 create mode 100644 vm/mterp/armv5te_taint/OP_INVOKE_DIRECT_RANGE.S
 create mode 100644 vm/mterp/armv5te_taint/OP_INVOKE_INTERFACE.S
 create mode 100644 vm/mterp/armv5te_taint/OP_INVOKE_INTERFACE_RANGE.S
 create mode 100644 vm/mterp/armv5te_taint/OP_INVOKE_OBJECT_INIT_RANGE.S
 create mode 100644 vm/mterp/armv5te_taint/OP_INVOKE_STATIC.S
 create mode 100644 vm/mterp/armv5te_taint/OP_INVOKE_STATIC_RANGE.S
 create mode 100644 vm/mterp/armv5te_taint/OP_INVOKE_SUPER.S
 create mode 100644 vm/mterp/armv5te_taint/OP_INVOKE_SUPER_QUICK.S
 create mode 100644 vm/mterp/armv5te_taint/OP_INVOKE_SUPER_QUICK_RANGE.S
 create mode 100644 vm/mterp/armv5te_taint/OP_INVOKE_SUPER_RANGE.S
 create mode 100644 vm/mterp/armv5te_taint/OP_INVOKE_VIRTUAL.S
 create mode 100644 vm/mterp/armv5te_taint/OP_INVOKE_VIRTUAL_QUICK.S
 create mode 100644 vm/mterp/armv5te_taint/OP_INVOKE_VIRTUAL_QUICK_RANGE.S
 create mode 100644 vm/mterp/armv5te_taint/OP_INVOKE_VIRTUAL_RANGE.S
 create mode 100644 vm/mterp/armv5te_taint/OP_IPUT.S
 create mode 100644 vm/mterp/armv5te_taint/OP_IPUT_BOOLEAN.S
 create mode 100644 vm/mterp/armv5te_taint/OP_IPUT_BYTE.S
 create mode 100644 vm/mterp/armv5te_taint/OP_IPUT_CHAR.S
 create mode 100644 vm/mterp/armv5te_taint/OP_IPUT_OBJECT.S
 create mode 100644 vm/mterp/armv5te_taint/OP_IPUT_OBJECT_QUICK.S
 create mode 100644 vm/mterp/armv5te_taint/OP_IPUT_OBJECT_VOLATILE.S
 create mode 100644 vm/mterp/armv5te_taint/OP_IPUT_QUICK.S
 create mode 100644 vm/mterp/armv5te_taint/OP_IPUT_SHORT.S
 create mode 100644 vm/mterp/armv5te_taint/OP_IPUT_VOLATILE.S
 create mode 100644 vm/mterp/armv5te_taint/OP_IPUT_WIDE.S
 create mode 100644 vm/mterp/armv5te_taint/OP_IPUT_WIDE_QUICK.S
 create mode 100644 vm/mterp/armv5te_taint/OP_IPUT_WIDE_VOLATILE.S
 create mode 100644 vm/mterp/armv5te_taint/OP_LONG_TO_DOUBLE.S
 create mode 100644 vm/mterp/armv5te_taint/OP_LONG_TO_FLOAT.S
 create mode 100644 vm/mterp/armv5te_taint/OP_LONG_TO_INT.S
 create mode 100644 vm/mterp/armv5te_taint/OP_MONITOR_ENTER.S
 create mode 100644 vm/mterp/armv5te_taint/OP_MONITOR_EXIT.S
 create mode 100644 vm/mterp/armv5te_taint/OP_MOVE.S
 create mode 100644 vm/mterp/armv5te_taint/OP_MOVE_16.S
 create mode 100644 vm/mterp/armv5te_taint/OP_MOVE_EXCEPTION.S
 create mode 100644 vm/mterp/armv5te_taint/OP_MOVE_FROM16.S
 create mode 100644 vm/mterp/armv5te_taint/OP_MOVE_OBJECT.S
 create mode 100644 vm/mterp/armv5te_taint/OP_MOVE_OBJECT_16.S
 create mode 100644 vm/mterp/armv5te_taint/OP_MOVE_OBJECT_FROM16.S
 create mode 100644 vm/mterp/armv5te_taint/OP_MOVE_RESULT.S
 create mode 100644 vm/mterp/armv5te_taint/OP_MOVE_RESULT_OBJECT.S
 create mode 100644 vm/mterp/armv5te_taint/OP_MOVE_RESULT_WIDE.S
 create mode 100644 vm/mterp/armv5te_taint/OP_MOVE_WIDE.S
 create mode 100644 vm/mterp/armv5te_taint/OP_MOVE_WIDE_16.S
 create mode 100644 vm/mterp/armv5te_taint/OP_MOVE_WIDE_FROM16.S
 create mode 100644 vm/mterp/armv5te_taint/OP_MUL_DOUBLE.S
 create mode 100644 vm/mterp/armv5te_taint/OP_MUL_DOUBLE_2ADDR.S
 create mode 100644 vm/mterp/armv5te_taint/OP_MUL_FLOAT.S
 create mode 100644 vm/mterp/armv5te_taint/OP_MUL_FLOAT_2ADDR.S
 create mode 100644 vm/mterp/armv5te_taint/OP_MUL_INT.S
 create mode 100644 vm/mterp/armv5te_taint/OP_MUL_INT_2ADDR.S
 create mode 100644 vm/mterp/armv5te_taint/OP_MUL_INT_LIT16.S
 create mode 100644 vm/mterp/armv5te_taint/OP_MUL_INT_LIT8.S
 create mode 100644 vm/mterp/armv5te_taint/OP_MUL_LONG.S
 create mode 100644 vm/mterp/armv5te_taint/OP_MUL_LONG_2ADDR.S
 create mode 100644 vm/mterp/armv5te_taint/OP_NEG_DOUBLE.S
 create mode 100644 vm/mterp/armv5te_taint/OP_NEG_FLOAT.S
 create mode 100644 vm/mterp/armv5te_taint/OP_NEG_INT.S
 create mode 100644 vm/mterp/armv5te_taint/OP_NEG_LONG.S
 create mode 100644 vm/mterp/armv5te_taint/OP_NEW_ARRAY.S
 create mode 100644 vm/mterp/armv5te_taint/OP_NEW_INSTANCE.S
 create mode 100644 vm/mterp/armv5te_taint/OP_NOP.S
 create mode 100644 vm/mterp/armv5te_taint/OP_NOT_INT.S
 create mode 100644 vm/mterp/armv5te_taint/OP_NOT_LONG.S
 create mode 100644 vm/mterp/armv5te_taint/OP_OR_INT.S
 create mode 100644 vm/mterp/armv5te_taint/OP_OR_INT_2ADDR.S
 create mode 100644 vm/mterp/armv5te_taint/OP_OR_INT_LIT16.S
 create mode 100644 vm/mterp/armv5te_taint/OP_OR_INT_LIT8.S
 create mode 100644 vm/mterp/armv5te_taint/OP_OR_LONG.S
 create mode 100644 vm/mterp/armv5te_taint/OP_OR_LONG_2ADDR.S
 create mode 100644 vm/mterp/armv5te_taint/OP_PACKED_SWITCH.S
 create mode 100644 vm/mterp/armv5te_taint/OP_REM_DOUBLE.S
 create mode 100644 vm/mterp/armv5te_taint/OP_REM_DOUBLE_2ADDR.S
 create mode 100644 vm/mterp/armv5te_taint/OP_REM_FLOAT.S
 create mode 100644 vm/mterp/armv5te_taint/OP_REM_FLOAT_2ADDR.S
 create mode 100644 vm/mterp/armv5te_taint/OP_REM_INT.S
 create mode 100644 vm/mterp/armv5te_taint/OP_REM_INT_2ADDR.S
 create mode 100644 vm/mterp/armv5te_taint/OP_REM_INT_LIT16.S
 create mode 100644 vm/mterp/armv5te_taint/OP_REM_INT_LIT8.S
 create mode 100644 vm/mterp/armv5te_taint/OP_REM_LONG.S
 create mode 100644 vm/mterp/armv5te_taint/OP_REM_LONG_2ADDR.S
 create mode 100644 vm/mterp/armv5te_taint/OP_RETURN.S
 create mode 100644 vm/mterp/armv5te_taint/OP_RETURN_OBJECT.S
 create mode 100644 vm/mterp/armv5te_taint/OP_RETURN_VOID.S
 create mode 100644 vm/mterp/armv5te_taint/OP_RETURN_VOID_BARRIER.S
 create mode 100644 vm/mterp/armv5te_taint/OP_RETURN_WIDE.S
 create mode 100644 vm/mterp/armv5te_taint/OP_RSUB_INT.S
 create mode 100644 vm/mterp/armv5te_taint/OP_RSUB_INT_LIT8.S
 create mode 100644 vm/mterp/armv5te_taint/OP_SGET.S
 create mode 100644 vm/mterp/armv5te_taint/OP_SGET_BOOLEAN.S
 create mode 100644 vm/mterp/armv5te_taint/OP_SGET_BYTE.S
 create mode 100644 vm/mterp/armv5te_taint/OP_SGET_CHAR.S
 create mode 100644 vm/mterp/armv5te_taint/OP_SGET_OBJECT.S
 create mode 100644 vm/mterp/armv5te_taint/OP_SGET_OBJECT_VOLATILE.S
 create mode 100644 vm/mterp/armv5te_taint/OP_SGET_SHORT.S
 create mode 100644 vm/mterp/armv5te_taint/OP_SGET_VOLATILE.S
 create mode 100644 vm/mterp/armv5te_taint/OP_SGET_WIDE.S
 create mode 100644 vm/mterp/armv5te_taint/OP_SGET_WIDE_VOLATILE.S
 create mode 100644 vm/mterp/armv5te_taint/OP_SHL_INT.S
 create mode 100644 vm/mterp/armv5te_taint/OP_SHL_INT_2ADDR.S
 create mode 100644 vm/mterp/armv5te_taint/OP_SHL_INT_LIT8.S
 create mode 100644 vm/mterp/armv5te_taint/OP_SHL_LONG.S
 create mode 100644 vm/mterp/armv5te_taint/OP_SHL_LONG_2ADDR.S
 create mode 100644 vm/mterp/armv5te_taint/OP_SHR_INT.S
 create mode 100644 vm/mterp/armv5te_taint/OP_SHR_INT_2ADDR.S
 create mode 100644 vm/mterp/armv5te_taint/OP_SHR_INT_LIT8.S
 create mode 100644 vm/mterp/armv5te_taint/OP_SHR_LONG.S
 create mode 100644 vm/mterp/armv5te_taint/OP_SHR_LONG_2ADDR.S
 create mode 100644 vm/mterp/armv5te_taint/OP_SPARSE_SWITCH.S
 create mode 100644 vm/mterp/armv5te_taint/OP_SPUT.S
 create mode 100644 vm/mterp/armv5te_taint/OP_SPUT_BOOLEAN.S
 create mode 100644 vm/mterp/armv5te_taint/OP_SPUT_BYTE.S
 create mode 100644 vm/mterp/armv5te_taint/OP_SPUT_CHAR.S
 create mode 100644 vm/mterp/armv5te_taint/OP_SPUT_OBJECT.S
 create mode 100644 vm/mterp/armv5te_taint/OP_SPUT_OBJECT_VOLATILE.S
 create mode 100644 vm/mterp/armv5te_taint/OP_SPUT_SHORT.S
 create mode 100644 vm/mterp/armv5te_taint/OP_SPUT_VOLATILE.S
 create mode 100644 vm/mterp/armv5te_taint/OP_SPUT_WIDE.S
 create mode 100644 vm/mterp/armv5te_taint/OP_SPUT_WIDE_VOLATILE.S
 create mode 100644 vm/mterp/armv5te_taint/OP_SUB_DOUBLE.S
 create mode 100644 vm/mterp/armv5te_taint/OP_SUB_DOUBLE_2ADDR.S
 create mode 100644 vm/mterp/armv5te_taint/OP_SUB_FLOAT.S
 create mode 100644 vm/mterp/armv5te_taint/OP_SUB_FLOAT_2ADDR.S
 create mode 100644 vm/mterp/armv5te_taint/OP_SUB_INT.S
 create mode 100644 vm/mterp/armv5te_taint/OP_SUB_INT_2ADDR.S
 create mode 100644 vm/mterp/armv5te_taint/OP_SUB_LONG.S
 create mode 100644 vm/mterp/armv5te_taint/OP_SUB_LONG_2ADDR.S
 create mode 100644 vm/mterp/armv5te_taint/OP_THROW.S
 create mode 100644 vm/mterp/armv5te_taint/OP_THROW_VERIFICATION_ERROR.S
 create mode 100644 vm/mterp/armv5te_taint/OP_UNUSED_3E.S
 create mode 100644 vm/mterp/armv5te_taint/OP_UNUSED_3F.S
 create mode 100644 vm/mterp/armv5te_taint/OP_UNUSED_40.S
 create mode 100644 vm/mterp/armv5te_taint/OP_UNUSED_41.S
 create mode 100644 vm/mterp/armv5te_taint/OP_UNUSED_42.S
 create mode 100644 vm/mterp/armv5te_taint/OP_UNUSED_43.S
 create mode 100644 vm/mterp/armv5te_taint/OP_UNUSED_73.S
 create mode 100644 vm/mterp/armv5te_taint/OP_UNUSED_79.S
 create mode 100644 vm/mterp/armv5te_taint/OP_UNUSED_7A.S
 create mode 100644 vm/mterp/armv5te_taint/OP_UNUSED_FF.S
 create mode 100644 vm/mterp/armv5te_taint/OP_USHR_INT.S
 create mode 100644 vm/mterp/armv5te_taint/OP_USHR_INT_2ADDR.S
 create mode 100644 vm/mterp/armv5te_taint/OP_USHR_INT_LIT8.S
 create mode 100644 vm/mterp/armv5te_taint/OP_USHR_LONG.S
 create mode 100644 vm/mterp/armv5te_taint/OP_USHR_LONG_2ADDR.S
 create mode 100644 vm/mterp/armv5te_taint/OP_XOR_INT.S
 create mode 100644 vm/mterp/armv5te_taint/OP_XOR_INT_2ADDR.S
 create mode 100644 vm/mterp/armv5te_taint/OP_XOR_INT_LIT16.S
 create mode 100644 vm/mterp/armv5te_taint/OP_XOR_INT_LIT8.S
 create mode 100644 vm/mterp/armv5te_taint/OP_XOR_LONG.S
 create mode 100644 vm/mterp/armv5te_taint/OP_XOR_LONG_2ADDR.S
 create mode 100644 vm/mterp/armv5te_taint/alt_stub.S
 create mode 100644 vm/mterp/armv5te_taint/bincmp.S
 create mode 100644 vm/mterp/armv5te_taint/binop.S
 create mode 100644 vm/mterp/armv5te_taint/binop2addr.S
 create mode 100644 vm/mterp/armv5te_taint/binopLit16.S
 create mode 100644 vm/mterp/armv5te_taint/binopLit8.S
 create mode 100644 vm/mterp/armv5te_taint/binopWide.S
 create mode 100644 vm/mterp/armv5te_taint/binopWide2addr.S
 create mode 100644 vm/mterp/armv5te_taint/debug.cpp
 create mode 100644 vm/mterp/armv5te_taint/debug.cpp~
 create mode 100644 vm/mterp/armv5te_taint/entry.S
 create mode 100644 vm/mterp/armv5te_taint/footer.S
 create mode 100644 vm/mterp/armv5te_taint/header.S
 create mode 100644 vm/mterp/armv5te_taint/stub.S
 create mode 100644 vm/mterp/armv5te_taint/unop.S
 create mode 100644 vm/mterp/armv5te_taint/unopNarrower.S
 create mode 100644 vm/mterp/armv5te_taint/unopWide.S
 create mode 100644 vm/mterp/armv5te_taint/unopWider.S
 create mode 100644 vm/mterp/armv5te_taint/unused.S
 create mode 100644 vm/mterp/armv5te_taint/zcmp.S
 create mode 100644 vm/mterp/armv6t2_taint/OP_ADD_FLOAT_2ADDR.S
 create mode 100644 vm/mterp/armv6t2_taint/OP_ADD_INT_2ADDR.S
 create mode 100644 vm/mterp/armv6t2_taint/OP_ADD_INT_LIT16.S
 create mode 100644 vm/mterp/armv6t2_taint/OP_ADD_LONG_2ADDR.S
 create mode 100644 vm/mterp/armv6t2_taint/OP_AND_INT_2ADDR.S
 create mode 100644 vm/mterp/armv6t2_taint/OP_AND_INT_LIT16.S
 create mode 100644 vm/mterp/armv6t2_taint/OP_AND_LONG_2ADDR.S
 create mode 100644 vm/mterp/armv6t2_taint/OP_ARRAY_LENGTH.S
 create mode 100644 vm/mterp/armv6t2_taint/OP_CONST_4.S
 create mode 100644 vm/mterp/armv6t2_taint/OP_DIV_FLOAT_2ADDR.S
 create mode 100644 vm/mterp/armv6t2_taint/OP_DIV_INT_2ADDR.S
 create mode 100644 vm/mterp/armv6t2_taint/OP_DIV_INT_LIT16.S
 create mode 100644 vm/mterp/armv6t2_taint/OP_DIV_LONG_2ADDR.S
 create mode 100644 vm/mterp/armv6t2_taint/OP_DOUBLE_TO_LONG.S
 create mode 100644 vm/mterp/armv6t2_taint/OP_FLOAT_TO_INT.S
 create mode 100644 vm/mterp/armv6t2_taint/OP_FLOAT_TO_LONG.S
 create mode 100644 vm/mterp/armv6t2_taint/OP_IF_EQ.S
 create mode 100644 vm/mterp/armv6t2_taint/OP_IF_GE.S
 create mode 100644 vm/mterp/armv6t2_taint/OP_IF_GT.S
 create mode 100644 vm/mterp/armv6t2_taint/OP_IF_LE.S
 create mode 100644 vm/mterp/armv6t2_taint/OP_IF_LT.S
 create mode 100644 vm/mterp/armv6t2_taint/OP_IF_NE.S
 create mode 100644 vm/mterp/armv6t2_taint/OP_IGET.S
 create mode 100644 vm/mterp/armv6t2_taint/OP_IGET_QUICK.S
 create mode 100644 vm/mterp/armv6t2_taint/OP_IGET_WIDE.S
 create mode 100644 vm/mterp/armv6t2_taint/OP_IGET_WIDE_QUICK.S
 create mode 100644 vm/mterp/armv6t2_taint/OP_INT_TO_BYTE.S
 create mode 100644 vm/mterp/armv6t2_taint/OP_INT_TO_CHAR.S
 create mode 100644 vm/mterp/armv6t2_taint/OP_INT_TO_DOUBLE.S
 create mode 100644 vm/mterp/armv6t2_taint/OP_INT_TO_FLOAT.S
 create mode 100644 vm/mterp/armv6t2_taint/OP_INT_TO_LONG.S
 create mode 100644 vm/mterp/armv6t2_taint/OP_INT_TO_SHORT.S
 create mode 100644 vm/mterp/armv6t2_taint/OP_IPUT.S
 create mode 100644 vm/mterp/armv6t2_taint/OP_IPUT_QUICK.S
 create mode 100644 vm/mterp/armv6t2_taint/OP_IPUT_WIDE.S
 create mode 100644 vm/mterp/armv6t2_taint/OP_IPUT_WIDE_QUICK.S
 create mode 100644 vm/mterp/armv6t2_taint/OP_LONG_TO_DOUBLE.S
 create mode 100644 vm/mterp/armv6t2_taint/OP_LONG_TO_FLOAT.S
 create mode 100644 vm/mterp/armv6t2_taint/OP_MOVE.S
 create mode 100644 vm/mterp/armv6t2_taint/OP_MOVE_WIDE.S
 create mode 100644 vm/mterp/armv6t2_taint/OP_MUL_FLOAT_2ADDR.S
 create mode 100644 vm/mterp/armv6t2_taint/OP_MUL_INT_2ADDR.S
 create mode 100644 vm/mterp/armv6t2_taint/OP_MUL_INT_LIT16.S
 create mode 100644 vm/mterp/armv6t2_taint/OP_MUL_LONG_2ADDR.S
 create mode 100644 vm/mterp/armv6t2_taint/OP_NEG_DOUBLE.S
 create mode 100644 vm/mterp/armv6t2_taint/OP_NEG_FLOAT.S
 create mode 100644 vm/mterp/armv6t2_taint/OP_NEG_INT.S
 create mode 100644 vm/mterp/armv6t2_taint/OP_NEG_LONG.S
 create mode 100644 vm/mterp/armv6t2_taint/OP_NOT_INT.S
 create mode 100644 vm/mterp/armv6t2_taint/OP_NOT_LONG.S
 create mode 100644 vm/mterp/armv6t2_taint/OP_OR_INT_2ADDR.S
 create mode 100644 vm/mterp/armv6t2_taint/OP_OR_INT_LIT16.S
 create mode 100644 vm/mterp/armv6t2_taint/OP_OR_LONG_2ADDR.S
 create mode 100644 vm/mterp/armv6t2_taint/OP_REM_DOUBLE_2ADDR.S
 create mode 100644 vm/mterp/armv6t2_taint/OP_REM_FLOAT_2ADDR.S
 create mode 100644 vm/mterp/armv6t2_taint/OP_REM_INT_2ADDR.S
 create mode 100644 vm/mterp/armv6t2_taint/OP_REM_INT_LIT16.S
 create mode 100644 vm/mterp/armv6t2_taint/OP_REM_LONG_2ADDR.S
 create mode 100644 vm/mterp/armv6t2_taint/OP_RSUB_INT.S
 create mode 100644 vm/mterp/armv6t2_taint/OP_SHL_INT_2ADDR.S
 create mode 100644 vm/mterp/armv6t2_taint/OP_SHL_LONG_2ADDR.S
 create mode 100644 vm/mterp/armv6t2_taint/OP_SHR_INT_2ADDR.S
 create mode 100644 vm/mterp/armv6t2_taint/OP_SHR_LONG_2ADDR.S
 create mode 100644 vm/mterp/armv6t2_taint/OP_SUB_FLOAT_2ADDR.S
 create mode 100644 vm/mterp/armv6t2_taint/OP_SUB_INT_2ADDR.S
 create mode 100644 vm/mterp/armv6t2_taint/OP_SUB_LONG_2ADDR.S
 create mode 100644 vm/mterp/armv6t2_taint/OP_USHR_INT_2ADDR.S
 create mode 100644 vm/mterp/armv6t2_taint/OP_USHR_LONG_2ADDR.S
 create mode 100644 vm/mterp/armv6t2_taint/OP_XOR_INT_2ADDR.S
 create mode 100644 vm/mterp/armv6t2_taint/OP_XOR_INT_LIT16.S
 create mode 100644 vm/mterp/armv6t2_taint/OP_XOR_LONG_2ADDR.S
 create mode 100644 vm/mterp/armv6t2_taint/bincmp.S
 create mode 100644 vm/mterp/armv6t2_taint/binop2addr.S
 create mode 100644 vm/mterp/armv6t2_taint/binopLit16.S
 create mode 100644 vm/mterp/armv6t2_taint/binopWide2addr.S
 create mode 100644 vm/mterp/armv6t2_taint/unop.S
 create mode 100644 vm/mterp/armv6t2_taint/unopNarrower.S
 create mode 100644 vm/mterp/armv6t2_taint/unopWide.S
 create mode 100644 vm/mterp/armv6t2_taint/unopWider.S
 create mode 100644 vm/mterp/c_notaint/OP_ADD_DOUBLE.cpp
 create mode 100644 vm/mterp/c_notaint/OP_ADD_DOUBLE_2ADDR.cpp
 create mode 100644 vm/mterp/c_notaint/OP_ADD_FLOAT.cpp
 create mode 100644 vm/mterp/c_notaint/OP_ADD_FLOAT_2ADDR.cpp
 create mode 100644 vm/mterp/c_notaint/OP_ADD_INT.cpp
 create mode 100644 vm/mterp/c_notaint/OP_ADD_INT_2ADDR.cpp
 create mode 100644 vm/mterp/c_notaint/OP_ADD_INT_LIT16.cpp
 create mode 100644 vm/mterp/c_notaint/OP_ADD_INT_LIT8.cpp
 create mode 100644 vm/mterp/c_notaint/OP_ADD_LONG.cpp
 create mode 100644 vm/mterp/c_notaint/OP_ADD_LONG_2ADDR.cpp
 create mode 100644 vm/mterp/c_notaint/OP_AGET.cpp
 create mode 100644 vm/mterp/c_notaint/OP_AGET_BOOLEAN.cpp
 create mode 100644 vm/mterp/c_notaint/OP_AGET_BYTE.cpp
 create mode 100644 vm/mterp/c_notaint/OP_AGET_CHAR.cpp
 create mode 100644 vm/mterp/c_notaint/OP_AGET_OBJECT.cpp
 create mode 100644 vm/mterp/c_notaint/OP_AGET_SHORT.cpp
 create mode 100644 vm/mterp/c_notaint/OP_AGET_WIDE.cpp
 create mode 100644 vm/mterp/c_notaint/OP_AND_INT.cpp
 create mode 100644 vm/mterp/c_notaint/OP_AND_INT_2ADDR.cpp
 create mode 100644 vm/mterp/c_notaint/OP_AND_INT_LIT16.cpp
 create mode 100644 vm/mterp/c_notaint/OP_AND_INT_LIT8.cpp
 create mode 100644 vm/mterp/c_notaint/OP_AND_LONG.cpp
 create mode 100644 vm/mterp/c_notaint/OP_AND_LONG_2ADDR.cpp
 create mode 100644 vm/mterp/c_notaint/OP_APUT.cpp
 create mode 100644 vm/mterp/c_notaint/OP_APUT_BOOLEAN.cpp
 create mode 100644 vm/mterp/c_notaint/OP_APUT_BYTE.cpp
 create mode 100644 vm/mterp/c_notaint/OP_APUT_CHAR.cpp
 create mode 100644 vm/mterp/c_notaint/OP_APUT_OBJECT.cpp
 create mode 100644 vm/mterp/c_notaint/OP_APUT_SHORT.cpp
 create mode 100644 vm/mterp/c_notaint/OP_APUT_WIDE.cpp
 create mode 100644 vm/mterp/c_notaint/OP_ARRAY_LENGTH.cpp
 create mode 100644 vm/mterp/c_notaint/OP_BREAKPOINT.cpp
 create mode 100644 vm/mterp/c_notaint/OP_CHECK_CAST.cpp
 create mode 100644 vm/mterp/c_notaint/OP_CMPG_DOUBLE.cpp
 create mode 100644 vm/mterp/c_notaint/OP_CMPG_FLOAT.cpp
 create mode 100644 vm/mterp/c_notaint/OP_CMPL_DOUBLE.cpp
 create mode 100644 vm/mterp/c_notaint/OP_CMPL_FLOAT.cpp
 create mode 100644 vm/mterp/c_notaint/OP_CMP_LONG.cpp
 create mode 100644 vm/mterp/c_notaint/OP_CONST.cpp
 create mode 100644 vm/mterp/c_notaint/OP_CONST_16.cpp
 create mode 100644 vm/mterp/c_notaint/OP_CONST_4.cpp
 create mode 100644 vm/mterp/c_notaint/OP_CONST_CLASS.cpp
 create mode 100644 vm/mterp/c_notaint/OP_CONST_HIGH16.cpp
 create mode 100644 vm/mterp/c_notaint/OP_CONST_STRING.cpp
 create mode 100644 vm/mterp/c_notaint/OP_CONST_STRING_JUMBO.cpp
 create mode 100644 vm/mterp/c_notaint/OP_CONST_WIDE.cpp
 create mode 100644 vm/mterp/c_notaint/OP_CONST_WIDE_16.cpp
 create mode 100644 vm/mterp/c_notaint/OP_CONST_WIDE_32.cpp
 create mode 100644 vm/mterp/c_notaint/OP_CONST_WIDE_HIGH16.cpp
 create mode 100644 vm/mterp/c_notaint/OP_DIV_DOUBLE.cpp
 create mode 100644 vm/mterp/c_notaint/OP_DIV_DOUBLE_2ADDR.cpp
 create mode 100644 vm/mterp/c_notaint/OP_DIV_FLOAT.cpp
 create mode 100644 vm/mterp/c_notaint/OP_DIV_FLOAT_2ADDR.cpp
 create mode 100644 vm/mterp/c_notaint/OP_DIV_INT.cpp
 create mode 100644 vm/mterp/c_notaint/OP_DIV_INT_2ADDR.cpp
 create mode 100644 vm/mterp/c_notaint/OP_DIV_INT_LIT16.cpp
 create mode 100644 vm/mterp/c_notaint/OP_DIV_INT_LIT8.cpp
 create mode 100644 vm/mterp/c_notaint/OP_DIV_LONG.cpp
 create mode 100644 vm/mterp/c_notaint/OP_DIV_LONG_2ADDR.cpp
 create mode 100644 vm/mterp/c_notaint/OP_DOUBLE_TO_FLOAT.cpp
 create mode 100644 vm/mterp/c_notaint/OP_DOUBLE_TO_INT.cpp
 create mode 100644 vm/mterp/c_notaint/OP_DOUBLE_TO_LONG.cpp
 create mode 100644 vm/mterp/c_notaint/OP_EXECUTE_INLINE.cpp
 create mode 100644 vm/mterp/c_notaint/OP_EXECUTE_INLINE_RANGE.cpp
 create mode 100644 vm/mterp/c_notaint/OP_FILLED_NEW_ARRAY.cpp
 create mode 100644 vm/mterp/c_notaint/OP_FILLED_NEW_ARRAY_RANGE.cpp
 create mode 100644 vm/mterp/c_notaint/OP_FILL_ARRAY_DATA.cpp
 create mode 100644 vm/mterp/c_notaint/OP_FLOAT_TO_DOUBLE.cpp
 create mode 100644 vm/mterp/c_notaint/OP_FLOAT_TO_INT.cpp
 create mode 100644 vm/mterp/c_notaint/OP_FLOAT_TO_LONG.cpp
 create mode 100644 vm/mterp/c_notaint/OP_GOTO.cpp
 create mode 100644 vm/mterp/c_notaint/OP_GOTO_16.cpp
 create mode 100644 vm/mterp/c_notaint/OP_GOTO_32.cpp
 create mode 100644 vm/mterp/c_notaint/OP_IF_EQ.cpp
 create mode 100644 vm/mterp/c_notaint/OP_IF_EQZ.cpp
 create mode 100644 vm/mterp/c_notaint/OP_IF_GE.cpp
 create mode 100644 vm/mterp/c_notaint/OP_IF_GEZ.cpp
 create mode 100644 vm/mterp/c_notaint/OP_IF_GT.cpp
 create mode 100644 vm/mterp/c_notaint/OP_IF_GTZ.cpp
 create mode 100644 vm/mterp/c_notaint/OP_IF_LE.cpp
 create mode 100644 vm/mterp/c_notaint/OP_IF_LEZ.cpp
 create mode 100644 vm/mterp/c_notaint/OP_IF_LT.cpp
 create mode 100644 vm/mterp/c_notaint/OP_IF_LTZ.cpp
 create mode 100644 vm/mterp/c_notaint/OP_IF_NE.cpp
 create mode 100644 vm/mterp/c_notaint/OP_IF_NEZ.cpp
 create mode 100644 vm/mterp/c_notaint/OP_IGET.cpp
 create mode 100644 vm/mterp/c_notaint/OP_IGET_BOOLEAN.cpp
 create mode 100644 vm/mterp/c_notaint/OP_IGET_BYTE.cpp
 create mode 100644 vm/mterp/c_notaint/OP_IGET_CHAR.cpp
 create mode 100644 vm/mterp/c_notaint/OP_IGET_OBJECT.cpp
 create mode 100644 vm/mterp/c_notaint/OP_IGET_OBJECT_QUICK.cpp
 create mode 100644 vm/mterp/c_notaint/OP_IGET_OBJECT_VOLATILE.cpp
 create mode 100644 vm/mterp/c_notaint/OP_IGET_QUICK.cpp
 create mode 100644 vm/mterp/c_notaint/OP_IGET_SHORT.cpp
 create mode 100644 vm/mterp/c_notaint/OP_IGET_VOLATILE.cpp
 create mode 100644 vm/mterp/c_notaint/OP_IGET_WIDE.cpp
 create mode 100644 vm/mterp/c_notaint/OP_IGET_WIDE_QUICK.cpp
 create mode 100644 vm/mterp/c_notaint/OP_IGET_WIDE_VOLATILE.cpp
 create mode 100644 vm/mterp/c_notaint/OP_INSTANCE_OF.cpp
 create mode 100644 vm/mterp/c_notaint/OP_INT_TO_BYTE.cpp
 create mode 100644 vm/mterp/c_notaint/OP_INT_TO_CHAR.cpp
 create mode 100644 vm/mterp/c_notaint/OP_INT_TO_DOUBLE.cpp
 create mode 100644 vm/mterp/c_notaint/OP_INT_TO_FLOAT.cpp
 create mode 100644 vm/mterp/c_notaint/OP_INT_TO_LONG.cpp
 create mode 100644 vm/mterp/c_notaint/OP_INT_TO_SHORT.cpp
 create mode 100644 vm/mterp/c_notaint/OP_INVOKE_DIRECT.cpp
 create mode 100644 vm/mterp/c_notaint/OP_INVOKE_DIRECT_RANGE.cpp
 create mode 100644 vm/mterp/c_notaint/OP_INVOKE_INTERFACE.cpp
 create mode 100644 vm/mterp/c_notaint/OP_INVOKE_INTERFACE_RANGE.cpp
 create mode 100644 vm/mterp/c_notaint/OP_INVOKE_OBJECT_INIT_RANGE.cpp
 create mode 100644 vm/mterp/c_notaint/OP_INVOKE_STATIC.cpp
 create mode 100644 vm/mterp/c_notaint/OP_INVOKE_STATIC_RANGE.cpp
 create mode 100644 vm/mterp/c_notaint/OP_INVOKE_SUPER.cpp
 create mode 100644 vm/mterp/c_notaint/OP_INVOKE_SUPER_QUICK.cpp
 create mode 100644 vm/mterp/c_notaint/OP_INVOKE_SUPER_QUICK_RANGE.cpp
 create mode 100644 vm/mterp/c_notaint/OP_INVOKE_SUPER_RANGE.cpp
 create mode 100644 vm/mterp/c_notaint/OP_INVOKE_VIRTUAL.cpp
 create mode 100644 vm/mterp/c_notaint/OP_INVOKE_VIRTUAL_QUICK.cpp
 create mode 100644 vm/mterp/c_notaint/OP_INVOKE_VIRTUAL_QUICK_RANGE.cpp
 create mode 100644 vm/mterp/c_notaint/OP_INVOKE_VIRTUAL_RANGE.cpp
 create mode 100644 vm/mterp/c_notaint/OP_IPUT.cpp
 create mode 100644 vm/mterp/c_notaint/OP_IPUT_BOOLEAN.cpp
 create mode 100644 vm/mterp/c_notaint/OP_IPUT_BYTE.cpp
 create mode 100644 vm/mterp/c_notaint/OP_IPUT_CHAR.cpp
 create mode 100644 vm/mterp/c_notaint/OP_IPUT_OBJECT.cpp
 create mode 100644 vm/mterp/c_notaint/OP_IPUT_OBJECT_QUICK.cpp
 create mode 100644 vm/mterp/c_notaint/OP_IPUT_OBJECT_VOLATILE.cpp
 create mode 100644 vm/mterp/c_notaint/OP_IPUT_QUICK.cpp
 create mode 100644 vm/mterp/c_notaint/OP_IPUT_SHORT.cpp
 create mode 100644 vm/mterp/c_notaint/OP_IPUT_VOLATILE.cpp
 create mode 100644 vm/mterp/c_notaint/OP_IPUT_WIDE.cpp
 create mode 100644 vm/mterp/c_notaint/OP_IPUT_WIDE_QUICK.cpp
 create mode 100644 vm/mterp/c_notaint/OP_IPUT_WIDE_VOLATILE.cpp
 create mode 100644 vm/mterp/c_notaint/OP_LONG_TO_DOUBLE.cpp
 create mode 100644 vm/mterp/c_notaint/OP_LONG_TO_FLOAT.cpp
 create mode 100644 vm/mterp/c_notaint/OP_LONG_TO_INT.cpp
 create mode 100644 vm/mterp/c_notaint/OP_MONITOR_ENTER.cpp
 create mode 100644 vm/mterp/c_notaint/OP_MONITOR_EXIT.cpp
 create mode 100644 vm/mterp/c_notaint/OP_MOVE.cpp
 create mode 100644 vm/mterp/c_notaint/OP_MOVE_16.cpp
 create mode 100644 vm/mterp/c_notaint/OP_MOVE_EXCEPTION.cpp
 create mode 100644 vm/mterp/c_notaint/OP_MOVE_FROM16.cpp
 create mode 100644 vm/mterp/c_notaint/OP_MOVE_OBJECT.cpp
 create mode 100644 vm/mterp/c_notaint/OP_MOVE_OBJECT_16.cpp
 create mode 100644 vm/mterp/c_notaint/OP_MOVE_OBJECT_FROM16.cpp
 create mode 100644 vm/mterp/c_notaint/OP_MOVE_RESULT.cpp
 create mode 100644 vm/mterp/c_notaint/OP_MOVE_RESULT_OBJECT.cpp
 create mode 100644 vm/mterp/c_notaint/OP_MOVE_RESULT_WIDE.cpp
 create mode 100644 vm/mterp/c_notaint/OP_MOVE_WIDE.cpp
 create mode 100644 vm/mterp/c_notaint/OP_MOVE_WIDE_16.cpp
 create mode 100644 vm/mterp/c_notaint/OP_MOVE_WIDE_FROM16.cpp
 create mode 100644 vm/mterp/c_notaint/OP_MUL_DOUBLE.cpp
 create mode 100644 vm/mterp/c_notaint/OP_MUL_DOUBLE_2ADDR.cpp
 create mode 100644 vm/mterp/c_notaint/OP_MUL_FLOAT.cpp
 create mode 100644 vm/mterp/c_notaint/OP_MUL_FLOAT_2ADDR.cpp
 create mode 100644 vm/mterp/c_notaint/OP_MUL_INT.cpp
 create mode 100644 vm/mterp/c_notaint/OP_MUL_INT_2ADDR.cpp
 create mode 100644 vm/mterp/c_notaint/OP_MUL_INT_LIT16.cpp
 create mode 100644 vm/mterp/c_notaint/OP_MUL_INT_LIT8.cpp
 create mode 100644 vm/mterp/c_notaint/OP_MUL_LONG.cpp
 create mode 100644 vm/mterp/c_notaint/OP_MUL_LONG_2ADDR.cpp
 create mode 100644 vm/mterp/c_notaint/OP_NEG_DOUBLE.cpp
 create mode 100644 vm/mterp/c_notaint/OP_NEG_FLOAT.cpp
 create mode 100644 vm/mterp/c_notaint/OP_NEG_INT.cpp
 create mode 100644 vm/mterp/c_notaint/OP_NEG_LONG.cpp
 create mode 100644 vm/mterp/c_notaint/OP_NEW_ARRAY.cpp
 create mode 100644 vm/mterp/c_notaint/OP_NEW_INSTANCE.cpp
 create mode 100644 vm/mterp/c_notaint/OP_NOP.cpp
 create mode 100644 vm/mterp/c_notaint/OP_NOT_INT.cpp
 create mode 100644 vm/mterp/c_notaint/OP_NOT_LONG.cpp
 create mode 100644 vm/mterp/c_notaint/OP_OR_INT.cpp
 create mode 100644 vm/mterp/c_notaint/OP_OR_INT_2ADDR.cpp
 create mode 100644 vm/mterp/c_notaint/OP_OR_INT_LIT16.cpp
 create mode 100644 vm/mterp/c_notaint/OP_OR_INT_LIT8.cpp
 create mode 100644 vm/mterp/c_notaint/OP_OR_LONG.cpp
 create mode 100644 vm/mterp/c_notaint/OP_OR_LONG_2ADDR.cpp
 create mode 100644 vm/mterp/c_notaint/OP_PACKED_SWITCH.cpp
 create mode 100644 vm/mterp/c_notaint/OP_REM_DOUBLE.cpp
 create mode 100644 vm/mterp/c_notaint/OP_REM_DOUBLE_2ADDR.cpp
 create mode 100644 vm/mterp/c_notaint/OP_REM_FLOAT.cpp
 create mode 100644 vm/mterp/c_notaint/OP_REM_FLOAT_2ADDR.cpp
 create mode 100644 vm/mterp/c_notaint/OP_REM_INT.cpp
 create mode 100644 vm/mterp/c_notaint/OP_REM_INT_2ADDR.cpp
 create mode 100644 vm/mterp/c_notaint/OP_REM_INT_LIT16.cpp
 create mode 100644 vm/mterp/c_notaint/OP_REM_INT_LIT8.cpp
 create mode 100644 vm/mterp/c_notaint/OP_REM_LONG.cpp
 create mode 100644 vm/mterp/c_notaint/OP_REM_LONG_2ADDR.cpp
 create mode 100644 vm/mterp/c_notaint/OP_RETURN.cpp
 create mode 100644 vm/mterp/c_notaint/OP_RETURN_OBJECT.cpp
 create mode 100644 vm/mterp/c_notaint/OP_RETURN_VOID.cpp
 create mode 100644 vm/mterp/c_notaint/OP_RETURN_VOID_BARRIER.cpp
 create mode 100644 vm/mterp/c_notaint/OP_RETURN_WIDE.cpp
 create mode 100644 vm/mterp/c_notaint/OP_RSUB_INT.cpp
 create mode 100644 vm/mterp/c_notaint/OP_RSUB_INT_LIT8.cpp
 create mode 100644 vm/mterp/c_notaint/OP_SGET.cpp
 create mode 100644 vm/mterp/c_notaint/OP_SGET_BOOLEAN.cpp
 create mode 100644 vm/mterp/c_notaint/OP_SGET_BYTE.cpp
 create mode 100644 vm/mterp/c_notaint/OP_SGET_CHAR.cpp
 create mode 100644 vm/mterp/c_notaint/OP_SGET_OBJECT.cpp
 create mode 100644 vm/mterp/c_notaint/OP_SGET_OBJECT_VOLATILE.cpp
 create mode 100644 vm/mterp/c_notaint/OP_SGET_SHORT.cpp
 create mode 100644 vm/mterp/c_notaint/OP_SGET_VOLATILE.cpp
 create mode 100644 vm/mterp/c_notaint/OP_SGET_WIDE.cpp
 create mode 100644 vm/mterp/c_notaint/OP_SGET_WIDE_VOLATILE.cpp
 create mode 100644 vm/mterp/c_notaint/OP_SHL_INT.cpp
 create mode 100644 vm/mterp/c_notaint/OP_SHL_INT_2ADDR.cpp
 create mode 100644 vm/mterp/c_notaint/OP_SHL_INT_LIT8.cpp
 create mode 100644 vm/mterp/c_notaint/OP_SHL_LONG.cpp
 create mode 100644 vm/mterp/c_notaint/OP_SHL_LONG_2ADDR.cpp
 create mode 100644 vm/mterp/c_notaint/OP_SHR_INT.cpp
 create mode 100644 vm/mterp/c_notaint/OP_SHR_INT_2ADDR.cpp
 create mode 100644 vm/mterp/c_notaint/OP_SHR_INT_LIT8.cpp
 create mode 100644 vm/mterp/c_notaint/OP_SHR_LONG.cpp
 create mode 100644 vm/mterp/c_notaint/OP_SHR_LONG_2ADDR.cpp
 create mode 100644 vm/mterp/c_notaint/OP_SPARSE_SWITCH.cpp
 create mode 100644 vm/mterp/c_notaint/OP_SPUT.cpp
 create mode 100644 vm/mterp/c_notaint/OP_SPUT_BOOLEAN.cpp
 create mode 100644 vm/mterp/c_notaint/OP_SPUT_BYTE.cpp
 create mode 100644 vm/mterp/c_notaint/OP_SPUT_CHAR.cpp
 create mode 100644 vm/mterp/c_notaint/OP_SPUT_OBJECT.cpp
 create mode 100644 vm/mterp/c_notaint/OP_SPUT_OBJECT_VOLATILE.cpp
 create mode 100644 vm/mterp/c_notaint/OP_SPUT_SHORT.cpp
 create mode 100644 vm/mterp/c_notaint/OP_SPUT_VOLATILE.cpp
 create mode 100644 vm/mterp/c_notaint/OP_SPUT_WIDE.cpp
 create mode 100644 vm/mterp/c_notaint/OP_SPUT_WIDE_VOLATILE.cpp
 create mode 100644 vm/mterp/c_notaint/OP_SUB_DOUBLE.cpp
 create mode 100644 vm/mterp/c_notaint/OP_SUB_DOUBLE_2ADDR.cpp
 create mode 100644 vm/mterp/c_notaint/OP_SUB_FLOAT.cpp
 create mode 100644 vm/mterp/c_notaint/OP_SUB_FLOAT_2ADDR.cpp
 create mode 100644 vm/mterp/c_notaint/OP_SUB_INT.cpp
 create mode 100644 vm/mterp/c_notaint/OP_SUB_INT_2ADDR.cpp
 create mode 100644 vm/mterp/c_notaint/OP_SUB_LONG.cpp
 create mode 100644 vm/mterp/c_notaint/OP_SUB_LONG_2ADDR.cpp
 create mode 100644 vm/mterp/c_notaint/OP_THROW.cpp
 create mode 100644 vm/mterp/c_notaint/OP_THROW_VERIFICATION_ERROR.cpp
 create mode 100644 vm/mterp/c_notaint/OP_UNUSED_3E.cpp
 create mode 100644 vm/mterp/c_notaint/OP_UNUSED_3F.cpp
 create mode 100644 vm/mterp/c_notaint/OP_UNUSED_40.cpp
 create mode 100644 vm/mterp/c_notaint/OP_UNUSED_41.cpp
 create mode 100644 vm/mterp/c_notaint/OP_UNUSED_42.cpp
 create mode 100644 vm/mterp/c_notaint/OP_UNUSED_43.cpp
 create mode 100644 vm/mterp/c_notaint/OP_UNUSED_73.cpp
 create mode 100644 vm/mterp/c_notaint/OP_UNUSED_79.cpp
 create mode 100644 vm/mterp/c_notaint/OP_UNUSED_7A.cpp
 create mode 100644 vm/mterp/c_notaint/OP_UNUSED_FF.cpp
 create mode 100644 vm/mterp/c_notaint/OP_USHR_INT.cpp
 create mode 100644 vm/mterp/c_notaint/OP_USHR_INT_2ADDR.cpp
 create mode 100644 vm/mterp/c_notaint/OP_USHR_INT_LIT8.cpp
 create mode 100644 vm/mterp/c_notaint/OP_USHR_LONG.cpp
 create mode 100644 vm/mterp/c_notaint/OP_USHR_LONG_2ADDR.cpp
 create mode 100644 vm/mterp/c_notaint/OP_XOR_INT.cpp
 create mode 100644 vm/mterp/c_notaint/OP_XOR_INT_2ADDR.cpp
 create mode 100644 vm/mterp/c_notaint/OP_XOR_INT_LIT16.cpp
 create mode 100644 vm/mterp/c_notaint/OP_XOR_INT_LIT8.cpp
 create mode 100644 vm/mterp/c_notaint/OP_XOR_LONG.cpp
 create mode 100644 vm/mterp/c_notaint/OP_XOR_LONG_2ADDR.cpp
 create mode 100644 vm/mterp/c_notaint/gotoTargets.cpp
 create mode 100644 vm/mterp/c_notaint/header.cpp
 create mode 100644 vm/mterp/c_notaint/opcommon.cpp
 create mode 100644 vm/mterp/config-armv7-a-neon.notaint
 create mode 100644 vm/mterp/config-armv7-a.notaint
 create mode 100644 vm/native/dalvik_system_Taint.cpp
 create mode 100644 vm/tprop/TaintPolicy.cpp
 create mode 100644 vm/tprop/TaintPolicyPriv.h
 create mode 100644 vm/tprop/TaintProp.cpp
 create mode 100644 vm/tprop/TaintProp.h

diff --git a/Android.mk b/Android.mk
index 73ec342..b965d93 100644
--- a/Android.mk
+++ b/Android.mk
@@ -27,6 +27,10 @@ subdirs := $(addprefix $(LOCAL_PATH)/,$(addsuffix /Android.mk, \
 		tools \
 		unit-tests \
 	))
+# Taint propagation with file propagation
+ifeq ($(WITH_TAINT_TRACKING),true)
+    subdirs += $(LOCAL_PATH)/libattr/Android.mk
+endif
 
 include $(subdirs)
 
diff --git a/dexopt/Android.mk b/dexopt/Android.mk
index 81fa1c8..a165f85 100644
--- a/dexopt/Android.mk
+++ b/dexopt/Android.mk
@@ -47,6 +47,14 @@ LOCAL_SHARED_LIBRARIES := $(local_shared_libraries) libcutils libexpat liblog li
 LOCAL_MODULE_TAGS := optional
 LOCAL_MODULE := dexopt
 
+# Turn on Taint Tracking
+ifeq ($(WITH_TAINT_TRACKING),true)
+  LOCAL_CFLAGS += -DWITH_TAINT_TRACKING
+endif
+ifeq ($(WITH_TAINT_ODEX),true)
+  LOCAL_CFLAGS += -DWITH_TAINT_ODEX
+endif
+
 LOCAL_C_INCLUDES += external/stlport/stlport bionic/ bionic/libstdc++/include
 LOCAL_SHARED_LIBRARIES += libstlport
 
@@ -62,5 +70,14 @@ ifeq ($(WITH_HOST_DALVIK),true)
     LOCAL_CFLAGS += -DANDROID_SMP=1
     LOCAL_MODULE_TAGS := optional
     LOCAL_MODULE := dexopt
+
+    # Turn on Taint Tracking
+    ifeq ($(WITH_TAINT_TRACKING),true)
+      LOCAL_CFLAGS += -DWITH_TAINT_TRACKING
+    endif
+    ifeq ($(WITH_TAINT_ODEX),true)
+      LOCAL_CFLAGS += -DWITH_TAINT_ODEX
+    endif
+
     include $(BUILD_HOST_EXECUTABLE)
 endif
diff --git a/dexopt/OptMain.cpp b/dexopt/OptMain.cpp
index 3cdf5be..c980d17 100644
--- a/dexopt/OptMain.cpp
+++ b/dexopt/OptMain.cpp
@@ -67,7 +67,11 @@ static int extractAndProcessZip(int zipFd, int cacheFd,
     int result = -1;
     int dexoptFlags = 0;        /* bit flags, from enum DexoptFlags */
     DexClassVerifyMode verifyMode = VERIFY_MODE_ALL;
+#if defined(WITH_TAINT_TRACKING) && !defined(WITH_TAINT_ODEX)
+    DexOptimizerMode dexOptMode = OPTIMIZE_MODE_NONE;
+#else
     DexOptimizerMode dexOptMode = OPTIMIZE_MODE_VERIFIED;
+#endif
 
     memset(&zippy, 0, sizeof(zippy));
 
@@ -143,6 +147,10 @@ static int extractAndProcessZip(int zipFd, int cacheFd,
             }
         }
 
+#if defined(WITH_TAINT_TRACKING) && !defined(WITH_TAINT_ODEX)
+        /* No choices */
+        dexOptMode = OPTIMIZE_MODE_NONE;
+#else
         opc = strstr(dexoptFlagStr, "o=");      /* optimization */
         if (opc != NULL) {
             switch (*(opc+2)) {
@@ -153,6 +161,7 @@ static int extractAndProcessZip(int zipFd, int cacheFd,
             default:                                            break;
             }
         }
+#endif
 
         opc = strstr(dexoptFlagStr, "m=y");     /* register map */
         if (opc != NULL) {
@@ -501,6 +510,10 @@ static int fromDex(int argc, char* const argv[])
     } else {
         verifyMode = VERIFY_MODE_NONE;
     }
+#if defined(WITH_TAINT_TRACKING) && !defined(WITH_TAINT_ODEX)
+    /* no choices */
+    dexOptMode = OPTIMIZE_MODE_NONE;
+#else
     if ((flags & DEXOPT_OPT_ENABLED) != 0) {
         if ((flags & DEXOPT_OPT_ALL) != 0)
             dexOptMode = OPTIMIZE_MODE_ALL;
@@ -509,6 +522,7 @@ static int fromDex(int argc, char* const argv[])
     } else {
         dexOptMode = OPTIMIZE_MODE_NONE;
     }
+#endif
 
     if (dvmPrepForDexOpt(bootClassPath, dexOptMode, verifyMode, flags) != 0) {
         ALOGE("VM init failed");
diff --git a/libattr/Android.mk b/libattr/Android.mk
new file mode 100644
index 0000000..2a05aed
--- /dev/null
+++ b/libattr/Android.mk
@@ -0,0 +1,46 @@
+# Copyright (c) 2010 The Pennsylvania State University
+# Systems and Internet Infrastructure Security Laboratory
+#
+# Authors: William Enck <enck@cse.psu.edu>
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#      http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+
+#
+# Android.mk for libattr
+#
+# This makefile builds libattr to allow XATTR support required for
+# file propagation in the TaintDroid project
+#
+
+LOCAL_PATH:= $(call my-dir)
+
+#
+# Build for the target (device).
+#
+
+include $(CLEAR_VARS)
+
+LOCAL_SRC_FILES := \
+	attr_copy_action.c \
+	attr_copy_check.c \
+	attr_copy_fd.c \
+	attr_copy_file.c \
+	libattr.c \
+	syscalls.c
+
+LOCAL_C_INCLUDES := $(LOCAL_PATH)/attr
+
+LOCAL_MODULE := libattr
+
+include $(BUILD_STATIC_LIBRARY)
diff --git a/libattr/Makefile b/libattr/Makefile
new file mode 100644
index 0000000..b09efb1
--- /dev/null
+++ b/libattr/Makefile
@@ -0,0 +1,36 @@
+#
+# Copyright (c) 2000-2002 Silicon Graphics, Inc.  All Rights Reserved.
+#
+
+TOPDIR = ..
+
+LTLDFLAGS += -Wl,--version-script,$(TOPDIR)/exports
+include $(TOPDIR)/include/builddefs
+
+LTLIBRARY = libattr.la
+LT_CURRENT = 2
+LT_REVISION = 0
+LT_AGE = 1
+
+CFILES = libattr.c attr_copy_fd.c attr_copy_file.c attr_copy_check.c attr_copy_action.c
+HFILES = libattr.h
+
+ifeq ($(PKG_PLATFORM),linux)
+CFILES += syscalls.c
+else
+LSRCFILES = syscalls.c
+endif
+
+LCFLAGS = -include libattr.h
+
+default: $(LTLIBRARY)
+
+include $(BUILDRULES)
+
+install:
+
+install-lib: default
+	$(INSTALL_LTLIB)
+
+install-dev: default
+	$(INSTALL_LTLIB_DEV)
diff --git a/libattr/README.txt b/libattr/README.txt
new file mode 100644
index 0000000..90a1cf8
--- /dev/null
+++ b/libattr/README.txt
@@ -0,0 +1,3 @@
+This is libattr from attr-2.4.43
+
+ftp://oss.sgi.com/projects/xfs/cmd_tars/attr_2.4.43-1.tar.gz
diff --git a/libattr/attr/attributes.h b/libattr/attr/attributes.h
new file mode 100644
index 0000000..006114b
--- /dev/null
+++ b/libattr/attr/attributes.h
@@ -0,0 +1,184 @@
+/*
+ * Copyright (c) 2001-2002,2004 Silicon Graphics, Inc.
+ * All Rights Reserved.
+ *
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public License
+ * as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it would be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public License
+ * along with this program; if not, write the Free Software Foundation,
+ * Inc.,  51 Franklin St, Fifth Floor, Boston, MA  02110-1301  USA
+ */
+#ifndef __ATTRIBUTES_H__
+#define	__ATTRIBUTES_H__
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+/*
+ *	An almost-IRIX-compatible extended attributes API
+ *	(the IRIX attribute "list" operation is missing, added ATTR_SECURE).
+ */
+
+/*
+ * The maximum size (into the kernel or returned from the kernel) of an
+ * attribute value or the buffer used for an attr_list() call.  Larger
+ * sizes will result in an E2BIG return code.
+ */
+#define ATTR_MAX_VALUELEN	(64*1024)	/* max length of a value */
+
+
+/*
+ * Flags that can be used with any of the simple attribute calls.
+ * All desired flags should be bit-wise OR'ed together.
+ */
+#define ATTR_DONTFOLLOW	0x0001	/* do not follow symlinks for a pathname */
+#define ATTR_ROOT	0x0002	/* use root namespace attributes in op */
+#define ATTR_TRUST	0x0004	/* tell server we can be trusted to properly
+				   handle extended attributes */
+#define ATTR_SECURE	0x0008	/* use security namespace attributes in op */
+
+/*
+ * Additional flags that can be used with the set() attribute call.
+ * All desired flags (from both lists) should be bit-wise OR'ed together.
+ */
+#define ATTR_CREATE	0x0010	/* pure create: fail if attr already exists */
+#define ATTR_REPLACE	0x0020	/* pure set: fail if attr does not exist */
+
+/*
+ * Define how lists of attribute names are returned to the user from
+ * the attr_list() call.  A large, 32bit aligned, buffer is passed in
+ * along with its size.  We put an array of offsets at the top that each
+ * reference an attrlist_ent_t and pack the attrlist_ent_t's at the bottom.
+ */
+typedef struct attrlist {
+	int32_t		al_count;	/* number of entries in attrlist */
+	int32_t		al_more;	/* T/F: more attrs (do call again) */
+	int32_t		al_offset[1];	/* byte offsets of attrs [var-sized] */
+} attrlist_t;
+
+/*
+ * Show the interesting info about one attribute.  This is what the
+ * al_offset[i] entry points to.
+ */
+typedef struct attrlist_ent {	/* data from attr_list() */
+	u_int32_t	a_valuelen;	/* number bytes in value of attr */
+	char		a_name[1];	/* attr name (NULL terminated) */
+} attrlist_ent_t;
+
+/*
+ * Given a pointer to the (char*) buffer containing the attr_list() result,
+ * and an index, return a pointer to the indicated attribute in the buffer.
+ */
+#define	ATTR_ENTRY(buffer, index)		\
+	((attrlist_ent_t *)			\
+	 &((char *)buffer)[ ((attrlist_t *)(buffer))->al_offset[index] ])
+
+/*
+ * Implement a "cursor" for use in successive attr_list() calls.
+ * It provides a way to find the last attribute that was returned in the
+ * last attr_list() call so that we can get the next one without missing
+ * any.  This should be bzero()ed before use and whenever it is desired to
+ * start over from the beginning of the attribute list.  The only valid
+ * operation on a cursor is to bzero() it.
+ */
+typedef struct attrlist_cursor {
+	u_int32_t	opaque[4];	/* an opaque cookie */
+} attrlist_cursor_t;
+
+/*
+ * Multi-attribute operation vector.
+ */
+typedef struct attr_multiop {
+	int32_t	am_opcode;	/* operation to perform (ATTR_OP_GET, etc.) */
+	int32_t	am_error;	/* [out arg] result of this sub-op (an errno) */
+	char	*am_attrname;	/* attribute name to work with */
+	char	*am_attrvalue;	/* [in/out arg] attribute value (raw bytes) */
+	int32_t	am_length;	/* [in/out arg] length of value */
+	int32_t	am_flags;	/* flags (bit-wise OR of #defines above) */
+} attr_multiop_t;
+#define	ATTR_MAX_MULTIOPS	128	/* max number ops in an oplist array */
+
+/*
+ * Valid values of am_opcode.
+ */
+#define ATTR_OP_GET	1	/* return the indicated attr's value */
+#define ATTR_OP_SET	2	/* set/create the indicated attr/value pair */
+#define ATTR_OP_REMOVE	3	/* remove the indicated attr */
+
+/*
+ * Get the value of an attribute.
+ * Valuelength must be set to the maximum size of the value buffer, it will
+ * be set to the actual number of bytes used in the value buffer upon return.
+ * The return value is -1 on error (w/errno set appropriately), 0 on success.
+ */
+extern int attr_get (const char *__path, const char *__attrname,
+			char *__attrvalue, int *__valuelength, int __flags);
+extern int attr_getf (int __fd, const char *__attrname, char *__attrvalue,
+			int *__valuelength, int __flags);
+
+/*
+ * Set the value of an attribute, creating the attribute if necessary.
+ * The return value is -1 on error (w/errno set appropriately), 0 on success.
+ */
+extern int attr_set (const char *__path, const char *__attrname,
+			const char *__attrvalue, const int __valuelength,
+			int __flags);
+extern int attr_setf (int __fd, const char *__attrname,
+			const char *__attrvalue, const int __valuelength,
+			int __flags);
+
+/*
+ * Remove an attribute.
+ * The return value is -1 on error (w/errno set appropriately), 0 on success.
+ */
+extern int attr_remove (const char *__path, const char *__attrname,
+			int __flags);
+extern int attr_removef (int __fd, const char *__attrname, int __flags);
+
+/*
+ * List the names and sizes of the values of all the attributes of an object.
+ * "Cursor" must be allocated and zeroed before the first call, it is used
+ * to maintain context between system calls if all the attribute names won't
+ * fit into the buffer on the first system call.
+ * The return value is -1 on error (w/errno set appropriately), 0 on success.
+ */
+int attr_list(const char *__path, char *__buffer, const int __buffersize,
+		int __flags, attrlist_cursor_t *__cursor);
+int attr_listf(int __fd, char *__buffer, const int __buffersize,
+		int __flags, attrlist_cursor_t *__cursor);
+
+/*
+ * Operate on multiple attributes of the same object simultaneously.
+ *
+ * This call will save on system call overhead when many attributes are
+ * going to be operated on.
+ *
+ * The return value is -1 on error (w/errno set appropriately), 0 on success.
+ * Note that this call will not return -1 as a result of failure of any
+ * of the sub-operations, their return value is stored in each element
+ * of the operation array.  This call will return -1 for a failure of the
+ * call as a whole, eg: if the pathname doesn't exist, or the fd is bad.
+ *
+ * The semantics and allowable values for the fields in a attr_multiop_t
+ * are the same as the semantics and allowable values for the arguments to
+ * the corresponding "simple" attribute interface.  For example: the args
+ * to a ATTR_OP_GET are the same as the args to an attr_get() call.
+ */
+extern int attr_multi (const char *__path, attr_multiop_t *__oplist,
+			int __count, int __flags);
+extern int attr_multif (int __fd, attr_multiop_t *__oplist,
+			int __count, int __flags);
+
+#ifdef __cplusplus
+}
+#endif
+
+#endif	/* __ATTRIBUTES_H__ */
diff --git a/libattr/attr/error_context.h b/libattr/attr/error_context.h
new file mode 100644
index 0000000..f3c54e9
--- /dev/null
+++ b/libattr/attr/error_context.h
@@ -0,0 +1,36 @@
+#ifndef __ERROR_CONTEXT_T
+#define __ERROR_CONTEXT_T
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+struct error_context {
+	/* Process an error message */
+	void (*error) (struct error_context *, const char *, ...);
+
+	/* Quote a file name for including in an error message */
+	const char *(*quote) (struct error_context *, const char *);
+
+	/* Free a quoted name */
+	void (*quote_free) (struct error_context *, const char *);
+};
+
+#ifdef ERROR_CONTEXT_MACROS
+# define error(ctx, args...) do { \
+	if ((ctx) && (ctx)->error) \
+		(ctx)->error((ctx), args); \
+	} while(0)
+# define quote(ctx, name) \
+	( ((ctx) && (ctx)->quote) ? (ctx)->quote((ctx), (name)) : (name) )
+# define quote_free(ctx, name) do { \
+	if ((ctx) && (ctx)->quote_free) \
+		(ctx)->quote_free((ctx), (name)); \
+	} while(0)
+#endif
+
+#ifdef __cplusplus
+}
+#endif
+
+#endif  /* __ERROR_CONTEXT_T */
diff --git a/libattr/attr/libattr.h b/libattr/attr/libattr.h
new file mode 100644
index 0000000..904b846
--- /dev/null
+++ b/libattr/attr/libattr.h
@@ -0,0 +1,29 @@
+#ifndef __LIBATTR_H
+#define __LIBATTR_H
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+struct error_context;
+
+extern int attr_copy_file (const char *, const char *,
+			   int (*) (const char *, struct error_context *),
+			   struct error_context *);
+extern int attr_copy_fd (const char *, int, const char *, int,
+			 int (*) (const char *, struct error_context *),
+			 struct error_context *);
+
+/* Keep this function for backwards compatibility. */
+extern int attr_copy_check_permissions(const char *, struct error_context *);
+
+#define ATTR_ACTION_SKIP	1
+#define ATTR_ACTION_PERMISSIONS	2
+
+extern int attr_copy_action(const char *, struct error_context *);
+
+#ifdef __cplusplus
+}
+#endif
+
+#endif
diff --git a/libattr/attr/xattr.h b/libattr/attr/xattr.h
new file mode 100644
index 0000000..05491e7
--- /dev/null
+++ b/libattr/attr/xattr.h
@@ -0,0 +1,61 @@
+/*
+ * Copyright (c) 2001-2002 Silicon Graphics, Inc.
+ * All Rights Reserved.
+ *
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public License
+ * as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it would be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public License
+ * along with this program; if not, write the Free Software Foundation,
+ * Inc.,  51 Franklin St, Fifth Floor, Boston, MA  02110-1301  USA
+ */
+#ifndef __XATTR_H__
+#define __XATTR_H__
+
+#include <features.h>
+
+#include <errno.h>
+#ifndef ENOATTR
+# define ENOATTR ENODATA        /* No such attribute */
+#endif
+
+#define XATTR_CREATE  0x1       /* set value, fail if attr already exists */
+#define XATTR_REPLACE 0x2       /* set value, fail if attr does not exist */
+
+
+__BEGIN_DECLS
+
+extern int setxattr (const char *__path, const char *__name,
+		      const void *__value, size_t __size, int __flags);
+extern int lsetxattr (const char *__path, const char *__name,
+		      const void *__value, size_t __size, int __flags);
+extern int fsetxattr (int __filedes, const char *__name,
+		      const void *__value, size_t __size, int __flags);
+
+extern ssize_t getxattr (const char *__path, const char *__name,
+				void *__value, size_t __size);
+extern ssize_t lgetxattr (const char *__path, const char *__name,
+				void *__value, size_t __size);
+extern ssize_t fgetxattr (int __filedes, const char *__name,
+				void *__value, size_t __size);
+
+extern ssize_t listxattr (const char *__path, char *__list,
+				size_t __size);
+extern ssize_t llistxattr (const char *__path, char *__list,
+				size_t __size);
+extern ssize_t flistxattr (int __filedes, char *__list,
+				size_t __size);
+
+extern int removexattr (const char *__path, const char *__name);
+extern int lremovexattr (const char *__path, const char *__name);
+extern int fremovexattr (int __filedes,   const char *__name);
+
+__END_DECLS
+
+#endif	/* __XATTR_H__ */
diff --git a/libattr/attr_copy_action.c b/libattr/attr_copy_action.c
new file mode 100644
index 0000000..296057a
--- /dev/null
+++ b/libattr/attr_copy_action.c
@@ -0,0 +1,163 @@
+/* Copyright (C) 2006 Andreas Gruenbacher <agruen@xxxxxxx>, SuSE Linux AG.
+
+  This program is free software; you can redistribute it and/or
+  modify it under the terms of the GNU Lesser General Public
+  License as published by the Free Software Foundation; either
+  version 2 of the License, or (at your option) any later version.
+
+  This program is distributed in the hope that it will be useful,
+  but WITHOUT ANY WARRANTY; without even the implied warranty of
+  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+  Lesser General Public License for more details.
+
+  You should have received a copy of the GNU Lesser General Public
+  License along with this library; if not, write to the Free Software
+  Foundation, Inc., 59 Temple Place - Suite 330, Boston, MA 02111-1307, USA.
+*/
+
+#include <alloca.h>
+#include <stdio.h>
+#include <stdlib.h>
+#include <errno.h>
+#include <string.h>
+#include <stdarg.h>
+#include <fnmatch.h>
+
+#include "attr/libattr.h"
+#define ERROR_CONTEXT_MACROS
+#include "error_context.h"
+
+#define ATTR_CONF "/etc/xattr.conf"
+
+struct attr_action {
+	struct attr_action *next;
+	char *pattern;
+	int action;
+};
+
+static struct attr_action *attr_actions;
+
+static void
+free_attr_actions(void)
+{
+	struct attr_action *tmp;
+
+	while (attr_actions) {
+		tmp = attr_actions->next;
+		free(attr_actions->pattern);
+		free(attr_actions);
+		attr_actions = tmp;
+	}
+}
+
+static int
+attr_parse_attr_conf(struct error_context *ctx)
+{
+	char *text, *t;
+	size_t size_guess = 4096, len;
+	FILE *file;
+	char *pattern = NULL;
+	struct attr_action *new;
+	int action;
+
+	if (attr_actions)
+		return 0;
+
+repeat:
+	text = malloc(size_guess + 1);
+	if (!text)
+		goto fail;
+
+	if ((file = fopen(ATTR_CONF, "r")) == NULL) {
+		if (errno == ENOENT)
+			return 0;
+		goto fail;
+	}
+	len = fread(text, 1, size_guess, file);
+	if (ferror(file))
+		goto fail;
+	if (!feof(file)) {
+		fclose(file);
+		file = NULL;
+		free(text);
+		size_guess *= 2;
+		goto repeat;
+	}
+	fclose(file);
+	file = NULL;
+
+	text[len] = 0;
+	t = text;
+	for (;;) {
+		t += strspn(t, " \t\n");
+		len = strcspn(t, " \t\n#");
+		if (t[len] == '#') {
+			if (len)
+				goto parse_error;
+			t += strcspn(t, "\n");
+			continue;
+		} else if (t[len] == 0)
+			break;
+		else if (t[len] == '\n')
+			goto parse_error;
+		pattern = strndup(t, len);
+		if (!pattern)
+			goto fail;
+		t += len;
+
+		t += strspn(t, " \t");
+		len = strcspn(t, " \t\n#");
+		if (len == 4 && !strncmp(t, "skip", 4))
+			action = ATTR_ACTION_SKIP;
+		else if (len == 11 && !strncmp(t, "permissions", 11))
+			action = ATTR_ACTION_PERMISSIONS;
+		else
+			goto parse_error;
+		t += len;
+		t += strspn(t, " \t");
+		if (*t != '#' && *t != '\n')
+			goto parse_error;
+
+		new = malloc(sizeof(struct attr_action));
+		if (!new)
+			goto parse_error;
+		new->next = attr_actions;
+		new->pattern = pattern;
+		new->action = action;
+		attr_actions = new;
+
+		t += strcspn(t, "\n");
+	}
+	return 0;
+
+parse_error:
+	errno = EINVAL;
+
+fail:
+	{
+		const char *q = quote (ctx, ATTR_CONF);
+		error (ctx, "%s", q);
+		quote_free (ctx, q);
+	}
+
+	free(pattern);
+	if (file)
+		fclose(file);
+	free(text);
+	free_attr_actions();
+	return -1;
+}
+
+int
+attr_copy_action(const char *name, struct error_context *ctx)
+{
+	struct attr_action *action = attr_actions;
+
+	if (!attr_parse_attr_conf(ctx)) {
+		for (action = attr_actions; action; action = action->next) {
+			if (!fnmatch(action->pattern, name, 0))
+				return action->action;
+		}
+	}
+	return 0;
+}
diff --git a/libattr/attr_copy_check.c b/libattr/attr_copy_check.c
new file mode 100644
index 0000000..e8a058e
--- /dev/null
+++ b/libattr/attr_copy_check.c
@@ -0,0 +1,29 @@
+/* Copy extended attributes between files - default check callback */
+
+/* Copyright (C) 2003 Andreas Gruenbacher <agruen@suse.de>, SuSE Linux AG.
+
+  This program is free software; you can redistribute it and/or
+  modify it under the terms of the GNU Lesser General Public
+  License as published by the Free Software Foundation; either
+  version 2 of the License, or (at your option) any later version.
+
+  This program is distributed in the hope that it will be useful,
+  but WITHOUT ANY WARRANTY; without even the implied warranty of
+  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+  Lesser General Public License for more details.
+
+  You should have received a copy of the GNU Lesser General Public
+  License along with this library; if not, write to the Free Software
+  Foundation, Inc., 59 Temple Place - Suite 330, Boston, MA 02111-1307, USA.
+*/
+
+#include <string.h>
+#include "error_context.h"
+#include "attr/libattr.h"
+
+int
+attr_copy_check_permissions(const char *name, struct error_context *ctx)
+{
+	return attr_copy_action(name, ctx) == 0;
+}
+
diff --git a/libattr/attr_copy_fd.c b/libattr/attr_copy_fd.c
new file mode 100644
index 0000000..67a7043
--- /dev/null
+++ b/libattr/attr_copy_fd.c
@@ -0,0 +1,178 @@
+/* Copy extended attributes between files. */
+ 
+/* Copyright (C) 2002 Andreas Gruenbacher <agruen@suse.de>, SuSE Linux AG.
+
+  This program is free software; you can redistribute it and/or
+  modify it under the terms of the GNU Lesser General Public
+  License as published by the Free Software Foundation; either
+  version 2 of the License, or (at your option) any later version.
+
+  This program is distributed in the hope that it will be useful,
+  but WITHOUT ANY WARRANTY; without even the implied warranty of
+  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+  Lesser General Public License for more details.
+
+  You should have received a copy of the GNU Lesser General Public
+  License along with this library; if not, write to the Free Software
+  Foundation, Inc., 59 Temple Place - Suite 330, Boston, MA 02111-1307, USA.
+*/
+
+#if defined (HAVE_CONFIG_H)
+#include "config.h"
+#endif
+
+#include <sys/types.h>
+#include <stdlib.h>
+#include <string.h>
+#include <errno.h>
+
+#if defined(HAVE_ALLOCA_H)
+# include <alloca.h>
+#endif
+
+#if defined(HAVE_ATTR_XATTR_H)
+# include <attr/xattr.h>
+#endif
+
+#if defined(HAVE_ATTR_LIBATTR_H)
+# include "attr/libattr.h"
+#endif
+
+#define ERROR_CONTEXT_MACROS
+#include "error_context.h"
+
+#if !defined(ENOTSUP)
+# define ENOTSUP (-1)
+#endif
+
+#if defined(HAVE_ALLOCA)
+# define my_alloc(size) alloca (size)
+# define my_free(ptr) do { } while(0)
+#else
+# define my_alloc(size) malloc (size)
+# define my_free(ptr) free (ptr)
+#endif
+
+/* Copy extended attributes from src_path to dst_path. If the file
+   has an extended Access ACL (system.posix_acl_access) and that is
+   copied successfully, the file mode permission bits are copied as
+   a side effect. This may not always the case, so the file mode
+   and/or ownership must be copied separately. */
+int
+attr_copy_fd(const char *src_path, int src_fd,
+	     const char *dst_path, int dst_fd,
+	     int (*check) (const char *, struct error_context *),
+	     struct error_context *ctx)
+{
+#if defined(HAVE_FLISTXATTR) && defined(HAVE_FGETXATTR) && \
+    defined(HAVE_FSETXATTR)
+	int ret = 0;
+	ssize_t size;
+	char *names = NULL, *end_names, *name, *value = NULL;
+	unsigned int setxattr_ENOTSUP = 0;
+
+	/* ignore acls by default */
+	if (check == NULL)
+		check = attr_copy_check_permissions;
+
+	size = flistxattr (src_fd, NULL, 0);
+	if (size < 0) {
+		if (errno != ENOSYS && errno != ENOTSUP) {
+			const char *qpath = quote (ctx, src_path);
+			error (ctx, _("listing attributes of %s"), qpath);
+			quote_free (ctx, qpath);
+			ret = -1;
+		}
+		goto getout;
+	}
+	names = (char *) my_alloc (size+1);
+	if (names == NULL) {
+		error (ctx, "");
+		ret = -1;
+		goto getout;
+	}
+	size = flistxattr (src_fd, names, size);
+	if (size < 0) {
+		const char *qpath = quote (ctx, src_path);
+		error (ctx, _("listing attributes of %s"), qpath);
+		quote_free (ctx, qpath);
+		ret = -1;
+		goto getout;
+	} else {
+		names[size] = '\0';
+		end_names = names + size;
+	}
+
+	for (name = names; name != end_names; name = strchr(name, '\0') + 1) {
+		void *old_value;
+
+		/* check if this attribute shall be preserved */
+		if (!*name || !check(name, ctx))
+			continue;
+
+		size = fgetxattr (src_fd, name, NULL, 0);
+		if (size < 0) {
+			const char *qpath = quote (ctx, src_path);
+			const char *qname = quote (ctx, name);
+			error (ctx, _("getting attribute %s of %s"),
+			       qpath, qname);
+			quote_free (ctx, qname);
+			quote_free (ctx, qpath);
+			ret = -1;
+			continue;
+		}
+		value = (char *) realloc (old_value = value, size);
+		if (size != 0 && value == NULL) {
+			free(old_value);
+			error (ctx, "");
+			ret = -1;
+		}
+		size = fgetxattr (src_fd, name, value, size);
+		if (size < 0) {
+			const char *qpath = quote (ctx, src_path);
+			const char *qname = quote (ctx, name);
+			error (ctx, _("getting attribute %s of %s"),
+			       qname, qpath);
+			quote_free (ctx, qname);
+			quote_free (ctx, qpath);
+			ret = -1;
+			continue;
+		}
+		if (fsetxattr (dst_fd, name, value, size, 0) != 0) {
+			if (errno == ENOTSUP)
+				setxattr_ENOTSUP++;
+			else {
+				const char *qpath = quote (ctx, dst_path);
+
+				if (errno == ENOSYS) {
+					error (ctx, _("setting attributes for "
+					       "%s"), qpath);
+					ret = -1;
+					break;  /* no hope of getting any further */
+				} else {
+					const char *qname = quote (ctx, name);
+					error (ctx, _("setting attribute %s for %s"),
+					       qname, qpath);
+					quote_free (ctx, qname);
+					ret = -1;
+				}
+				quote_free (ctx, qpath);
+			}
+		}
+	}
+	if (setxattr_ENOTSUP) {
+		const char *qpath = quote (ctx, dst_path);
+		errno = ENOTSUP;
+		error (ctx, _("setting attributes for %s"), qpath);
+		ret = -1;
+		quote_free (ctx, qpath);
+	}
+getout:
+	free (value);
+	my_free (names);
+	return ret;
+#else
+	return 0;
+#endif
+}
+
diff --git a/libattr/attr_copy_file.c b/libattr/attr_copy_file.c
new file mode 100644
index 0000000..cd10b31
--- /dev/null
+++ b/libattr/attr_copy_file.c
@@ -0,0 +1,176 @@
+/* Copy extended attributes between files. */
+ 
+/* Copyright (C) 2002 Andreas Gruenbacher <agruen@suse.de>, SuSE Linux AG.
+
+  This program is free software; you can redistribute it and/or
+  modify it under the terms of the GNU Lesser General Public
+  License as published by the Free Software Foundation; either
+  version 2 of the License, or (at your option) any later version.
+
+  This program is distributed in the hope that it will be useful,
+  but WITHOUT ANY WARRANTY; without even the implied warranty of
+  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+  Lesser General Public License for more details.
+
+  You should have received a copy of the GNU Lesser General Public
+  License along with this library; if not, write to the Free Software
+  Foundation, Inc., 59 Temple Place - Suite 330, Boston, MA 02111-1307, USA.
+*/
+
+#if defined (HAVE_CONFIG_H)
+#include "config.h"
+#endif
+
+#include <sys/types.h>
+#include <stdlib.h>
+#include <string.h>
+#include <errno.h>
+
+#if defined(HAVE_ALLOCA_H)
+# include <alloca.h>
+#endif
+
+#if defined(HAVE_ATTR_XATTR_H)
+# include <attr/xattr.h>
+#endif
+
+#if defined(HAVE_ATTR_LIBATTR_H)
+# include "attr/libattr.h"
+#endif
+
+#define ERROR_CONTEXT_MACROS
+#include "error_context.h"
+
+#if !defined(ENOTSUP)
+# define ENOTSUP (-1)
+#endif
+
+#if defined(HAVE_ALLOCA)
+# define my_alloc(size) alloca (size)
+# define my_free(ptr) do { } while(0)
+#else
+# define my_alloc(size) malloc (size)
+# define my_free(ptr) free (ptr)
+#endif
+
+/* Copy extended attributes from src_path to dst_path. If the file
+   has an extended Access ACL (system.posix_acl_access) and that is
+   copied successfully, the file mode permission bits are copied as
+   a side effect. This may not always the case, so the file mode
+   and/or ownership must be copied separately. */
+int
+attr_copy_file(const char *src_path, const char *dst_path,
+	       int (*check) (const char *, struct error_context *),
+	       struct error_context *ctx)
+{
+#if defined(HAVE_LISTXATTR) && defined(HAVE_GETXATTR) && defined(HAVE_SETXATTR)
+  	int ret = 0;
+	ssize_t size;
+	char *names = NULL, *end_names, *name, *value = NULL;
+	unsigned int setxattr_ENOTSUP = 0;
+
+	/* ignore acls by default */
+	if (check == NULL)
+		check = attr_copy_check_permissions;
+
+	size = llistxattr (src_path, NULL, 0);
+	if (size < 0) {
+		if (errno != ENOSYS && errno != ENOTSUP) {
+			const char *qpath = quote (ctx, src_path);
+			error (ctx, _("listing attributes of %s"), qpath);
+			quote_free (ctx, qpath);
+			ret = -1;
+		}
+		goto getout;
+	}
+	names = (char *) my_alloc (size+1);
+	if (names == NULL) {
+		error (ctx, "");
+		ret = -1;
+		goto getout;
+	}
+	size = llistxattr (src_path, names, size);
+	if (size < 0) {
+		const char *qpath = quote (ctx, src_path);
+		error (ctx, _("listing attributes of %s"), qpath);
+		quote_free (ctx, qpath);
+		ret = -1;
+		goto getout;
+	} else {
+		names[size] = '\0';
+		end_names = names + size;
+	}
+
+	for (name = names; name != end_names; name = strchr(name, '\0') + 1) {
+		void *old_value;
+
+		/* check if this attribute shall be preserved */
+		if (!*name || !check(name, ctx))
+			continue;
+
+		size = lgetxattr (src_path, name, NULL, 0);
+		if (size < 0) {
+			const char *qpath = quote (ctx, src_path);
+			const char *qname = quote (ctx, name);
+			error (ctx, _("getting attribute %s of %s"),
+			       qname, qpath);
+			quote_free (ctx, qname);
+			quote_free (ctx, qpath);
+			ret = -1;
+			continue;
+		}
+		value = (char *) realloc (old_value = value, size);
+		if (size != 0 && value == NULL) {
+			free(old_value);
+			error (ctx, "");
+			ret = -1;
+		}
+		size = lgetxattr (src_path, name, value, size);
+		if (size < 0) {
+			const char *qpath = quote (ctx, src_path);
+			const char *qname = quote (ctx, name);
+			error (ctx, _("getting attribute %s of %s"),
+			       qname, qpath);
+			quote_free (ctx, qname);
+			quote_free (ctx, qpath);
+			ret = -1;
+			continue;
+		}
+		if (lsetxattr (dst_path, name, value, size, 0) != 0) {
+			if (errno == ENOTSUP)
+				setxattr_ENOTSUP++;
+			else {
+				const char *qpath = quote (ctx, dst_path);
+				if (errno == ENOSYS) {
+					error (ctx, _("setting attributes for "
+					       "%s"), qpath);
+					ret = -1;
+					/* no hope of getting any further */
+					break;
+				} else {
+					const char *qname = quote (ctx, name);
+					error (ctx, _("setting attribute %s for "
+					       "%s"), qname, qpath);
+					quote_free (ctx, qname);
+					ret = -1;
+				}
+				quote_free (ctx, qpath);
+			}
+		}
+	}
+	if (setxattr_ENOTSUP) {
+		const char *qpath = quote (ctx, dst_path);
+		errno = ENOTSUP;
+		error (ctx, _("setting attributes for %s"), qpath);
+		ret = -1;
+		quote_free (ctx, qpath);
+	}
+getout:
+	free (value);
+	my_free (names);
+	return ret;
+#else
+	return 0;
+#endif
+}
+
diff --git a/libattr/libattr.c b/libattr/libattr.c
new file mode 100644
index 0000000..a77dd84
--- /dev/null
+++ b/libattr/libattr.c
@@ -0,0 +1,434 @@
+/*
+ * Copyright (c) 2001-2003,2005 Silicon Graphics, Inc.
+ * All Rights Reserved.
+ *
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU General Public License as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it would be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write the Free Software Foundation,
+ * Inc.,  51 Franklin St, Fifth Floor, Boston, MA  02110-1301  USA
+ */
+
+#include <errno.h>
+#include <stdlib.h>
+#include <string.h>
+#include <unistd.h>
+#include <sys/types.h>
+
+#include <attr/xattr.h>
+#include <attr/attributes.h>
+
+#undef MAXNAMELEN
+#define MAXNAMELEN 256
+#undef MAXLISTLEN
+#define MAXLISTLEN 65536
+
+#undef roundup
+#define roundup(x,y) ((((x)+((y)-1))/(y))*(y))
+
+static const char *user_name = "user.";
+static const char *secure_name = "security.";
+static const char *trusted_name = "trusted.";
+static const char *xfsroot_name = "xfsroot.";
+
+/*
+ * Convert IRIX API components into Linux/XFS API components,
+ * and vice-versa.
+ */
+static int
+api_convert(char *name, const char *irixname, int irixflags, int compat)
+{
+	if (strlen(irixname) >= MAXNAMELEN) {
+		errno = EINVAL;
+		return -1;
+	}
+	if (irixflags & ATTR_ROOT) {
+		if (compat)
+			strcpy(name, xfsroot_name);
+		else
+			strcpy(name, trusted_name);
+	} else if (irixflags & ATTR_SECURE) {
+		strcpy(name, secure_name);
+	} else {
+		strcpy(name, user_name);
+	}
+	strcat(name, irixname);
+	return 0;
+}
+
+static int
+api_unconvert(char *name, const char *linuxname, int irixflags)
+{
+	int type, length;
+
+	length = strlen(user_name);
+	if (strncmp(linuxname, user_name, length) == 0) {
+		type = 0; /*ATTR_USER*/
+		goto found;
+	}
+	length = strlen(secure_name);
+	if (strncmp(linuxname, secure_name, length) == 0) {
+		type = ATTR_SECURE;
+		goto found;
+	}
+	length = strlen(trusted_name);
+	if (strncmp(linuxname, trusted_name, length) == 0) {
+		type = ATTR_ROOT;
+		goto found;
+	}
+	length = strlen(xfsroot_name);
+	if (strncmp(linuxname, xfsroot_name, length) == 0) {
+		type = ATTR_ROOT;
+		goto found;
+	}
+	return 1;
+
+found:
+	if ((irixflags & ATTR_SECURE) != 0 && (type != ATTR_SECURE))
+		return 1;
+	if ((irixflags & ATTR_ROOT) != 0 && (type != ATTR_ROOT))
+		return 1;
+	strcpy(name, linuxname + length);
+	return 0;
+}
+
+
+int
+attr_get(const char *path, const char *attrname, char *attrvalue,
+	 int *valuelength, int flags)
+{
+	int c, compat;
+	char name[MAXNAMELEN+16];
+
+	for (compat = 0; compat < 2; compat++) {
+		if ((c = api_convert(name, attrname, flags, compat)) < 0)
+			return c;
+		if (flags & ATTR_DONTFOLLOW)
+			c = lgetxattr(path, name, attrvalue, *valuelength);
+		else
+			c =  getxattr(path, name, attrvalue, *valuelength);
+		if (c < 0 && (errno == ENOATTR || errno == ENOTSUP))
+			continue;
+		break;
+	}
+	if (c < 0)
+		return c;
+	*valuelength = c;
+	return 0;
+}
+
+int
+attr_getf(int fd, const char *attrname, char *attrvalue,
+	  int *valuelength, int flags)
+{
+	int c, compat;
+	char name[MAXNAMELEN+16];
+
+	for (compat = 0; compat < 2; compat++) {
+		if ((c = api_convert(name, attrname, flags, compat)) < 0)
+			return c;
+		c = fgetxattr(fd, name, attrvalue, *valuelength);
+		if (c < 0 && (errno == ENOATTR || errno == ENOTSUP))
+			continue;
+		break;
+	}
+	if (c < 0)
+		return c;
+	*valuelength = c;
+	return 0;
+}
+
+int
+attr_set(const char *path, const char *attrname, const char *attrvalue,
+	 const int valuelength, int flags)
+{
+	int c, compat, lflags = 0;
+	char name[MAXNAMELEN+16];
+	void *buffer = (void *)attrvalue;
+
+	if (flags & ATTR_CREATE)
+		lflags = XATTR_CREATE;
+	else if (flags & ATTR_REPLACE)
+		lflags = XATTR_REPLACE;
+
+	for (compat = 0; compat < 2; compat++) {
+		if ((c = api_convert(name, attrname, flags, compat)) < 0)
+			return c;
+		if (flags & ATTR_DONTFOLLOW)
+			c = lsetxattr(path, name, buffer, valuelength, lflags);
+		else
+			c = setxattr(path, name, buffer, valuelength, lflags);
+		if (c < 0 && (errno == ENOATTR || errno == ENOTSUP))
+			continue;
+		break;
+	}
+	return c;
+}
+
+int
+attr_setf(int fd, const char *attrname,
+	  const char *attrvalue, const int valuelength, int flags)
+{
+	int c, compat, lflags = 0;
+	char name[MAXNAMELEN+16];
+	void *buffer = (void *)attrvalue;
+
+	if (flags & ATTR_CREATE)
+		lflags = XATTR_CREATE;
+	else if (flags & ATTR_REPLACE)
+		lflags = XATTR_REPLACE;
+
+	for (compat = 0; compat < 2; compat++) {
+		if ((c = api_convert(name, attrname, flags, compat)) < 0)
+			return c;
+		c = fsetxattr(fd, name, buffer, valuelength, lflags);
+		if (c < 0 && (errno == ENOATTR || errno == ENOTSUP))
+			continue;
+		break;
+	}
+	return c;
+}
+
+int
+attr_remove(const char *path, const char *attrname, int flags)
+{
+	int c, compat;
+	char name[MAXNAMELEN+16];
+
+	for (compat = 0; compat < 2; compat++) {
+		if ((c = api_convert(name, attrname, flags, compat)) < 0)
+			return c;
+		if (flags & ATTR_DONTFOLLOW)
+			c = lremovexattr(path, name);
+		else
+			c = removexattr(path, name);
+		if (c < 0 && (errno == ENOATTR || errno == ENOTSUP))
+			continue;
+		break;
+	}
+	return c;
+}
+
+int
+attr_removef(int fd, const char *attrname, int flags)
+{
+	int c, compat;
+	char name[MAXNAMELEN+16];
+
+	for (compat = 0; compat < 2; compat++) {
+		if ((c = api_convert(name, attrname, flags, compat)) < 0)
+			return c;
+		c = fremovexattr(fd, name);
+		if (c < 0 && (errno == ENOATTR || errno == ENOTSUP))
+			continue;
+		break;
+	}
+	return c;
+}
+
+
+/*
+ * Helper routine for attr_list functions.
+ */
+
+static int
+attr_list_pack(const char *name, const int valuelen,
+		char *buffer, const int buffersize,
+		int *start_offset, int *end_offset)
+{
+	attrlist_ent_t *aentp;
+	attrlist_t *alist = (attrlist_t *)buffer;
+	int size = roundup(strlen(name) + 1 + sizeof(aentp->a_valuelen), 8);
+
+	if ((*end_offset - size) < (*start_offset + sizeof(alist->al_count))) {
+		alist->al_more = 1;
+		return 1;
+	}
+
+	*end_offset -= size;
+	aentp = (attrlist_ent_t *)&buffer[ *end_offset ];
+	aentp->a_valuelen = valuelen;
+	strncpy(aentp->a_name, name, size - sizeof(aentp->a_valuelen));
+
+	*start_offset += sizeof(alist->al_offset);
+	alist->al_offset[alist->al_count] = *end_offset;
+	alist->al_count++;
+	return 0;
+}
+
+int
+attr_list(const char *path, char *buffer, const int buffersize, int flags,
+	  attrlist_cursor_t *cursor)
+{
+	const char *l;
+	int length, vlength, count = 0;
+	char lbuf[MAXLISTLEN];
+	char name[MAXNAMELEN+16];
+	int start_offset, end_offset;
+
+	if (buffersize < sizeof(attrlist_t)) {
+		errno = EINVAL;
+		return -1;
+	}
+	bzero(buffer, sizeof(attrlist_t));
+
+	if (flags & ATTR_DONTFOLLOW)
+		length = llistxattr(path, lbuf, sizeof(lbuf));
+	else
+		length = listxattr(path, lbuf, sizeof(lbuf));
+	if (length <= 0)
+		return length;
+
+	start_offset = sizeof(attrlist_t);
+	end_offset = buffersize & ~(8-1);	/* 8 byte align */
+
+	for (l = lbuf; l != lbuf + length; l = strchr(l, '\0') + 1) {
+		if (api_unconvert(name, l, flags))
+			continue;
+		if (flags & ATTR_DONTFOLLOW)
+			vlength = lgetxattr(path, l, NULL, 0);
+		else
+			vlength =  getxattr(path, l, NULL, 0);
+		if (vlength < 0 && (errno == ENOATTR || errno == ENOTSUP))
+			continue;
+		if (count++ < cursor->opaque[0])
+			continue;
+		if (attr_list_pack(name, vlength, buffer, buffersize,
+				   &start_offset, &end_offset)) {
+			cursor->opaque[0] = count;
+			break;
+		}
+	}
+	return 0;
+}
+
+int
+attr_listf(int fd, char *buffer, const int buffersize, int flags,
+	   attrlist_cursor_t *cursor)
+{
+	const char *l;
+	int length, vlength, count = 0;
+	char lbuf[MAXLISTLEN];
+	char name[MAXNAMELEN+16];
+	int start_offset, end_offset;
+
+	if (buffersize < sizeof(attrlist_t)) {
+		errno = EINVAL;
+		return -1;
+	}
+	bzero(buffer, sizeof(attrlist_t));
+
+	length = flistxattr(fd, lbuf, sizeof(lbuf));
+	if (length < 0)
+		return length;
+
+	start_offset = sizeof(attrlist_t);
+	end_offset = buffersize & ~(8-1);	/* 8 byte align */
+
+	for (l = lbuf; l != lbuf + length; l = strchr(l, '\0') + 1) {
+		if (api_unconvert(name, l, flags))
+			continue;
+		vlength = fgetxattr(fd, l, NULL, 0);
+		if (vlength < 0 && (errno == ENOATTR || errno == ENOTSUP))
+			continue;
+		if (count++ < cursor->opaque[0])
+			continue;
+		if (attr_list_pack(name, vlength, buffer, buffersize,
+				   &start_offset, &end_offset)) {
+			cursor->opaque[0] = count;
+			break;
+		}
+	}
+	return 0;
+}
+
+
+/*
+ * Helper routines for the attr_multi functions.  In IRIX, the
+ * multi routines are a single syscall - in Linux, we break em
+ * apart in userspace and make individual syscalls for each.
+ */
+
+static int
+attr_single(const char *path, attr_multiop_t *op, int flags)
+{
+	int r = -1;
+
+	errno = -EINVAL;
+	flags |= op->am_flags;
+	if (op->am_opcode & ATTR_OP_GET)
+		r = attr_get(path, op->am_attrname, op->am_attrvalue,
+				&op->am_length, flags);
+	else if (op->am_opcode & ATTR_OP_SET)
+		r = attr_set(path, op->am_attrname, op->am_attrvalue,
+				op->am_length, flags);
+	else if (op->am_opcode & ATTR_OP_REMOVE)
+		r = attr_remove(path, op->am_attrname, flags);
+	return r;
+}
+
+static int
+attr_singlef(const int fd, attr_multiop_t *op, int flags)
+{
+	int r = -1;
+
+	errno = -EINVAL;
+	flags |= op->am_flags;
+	if (op->am_opcode & ATTR_OP_GET)
+		r = attr_getf(fd, op->am_attrname, op->am_attrvalue,
+				&op->am_length, flags);
+	else if (op->am_opcode & ATTR_OP_SET)
+		r = attr_setf(fd, op->am_attrname, op->am_attrvalue,
+				op->am_length, flags);
+	else if (op->am_opcode & ATTR_OP_REMOVE)
+		r = attr_removef(fd, op->am_attrname, flags);
+	return r;
+}
+
+/*
+ * Operate on multiple attributes of the same object simultaneously
+ *
+ * From the manpage: "attr_multi will fail if ... a bit other than
+ * ATTR_DONTFOLLOW was set in the flag argument." flags must be
+ * checked here as they are not passed into the kernel.
+ */
+int
+attr_multi(const char *path, attr_multiop_t *multiops, int count, int flags)
+{
+	int i, tmp, r = -1;
+
+	errno = EINVAL;
+	if ((flags & ATTR_DONTFOLLOW) != flags)
+		return r;
+
+	r = errno = 0;
+	for (i = 0; i < count; i++) {
+		tmp = attr_single(path, &multiops[i], flags);
+		if (tmp) r = tmp;
+	}
+	return r;
+}
+
+int
+attr_multif(int fd, attr_multiop_t *multiops, int count, int flags)
+{
+	int i, tmp, r = -1;
+
+	errno = EINVAL;
+	if ((flags & ATTR_DONTFOLLOW) != flags)
+		return r;
+
+	r = errno = 0;
+	for (i = 0; i < count; i++) {
+		tmp = attr_singlef(fd, &multiops[i], flags);
+		if (tmp) r = tmp;
+	}
+	return r;
+}
diff --git a/libattr/libattr.h b/libattr/libattr.h
new file mode 100644
index 0000000..8973b00
--- /dev/null
+++ b/libattr/libattr.h
@@ -0,0 +1,12 @@
+/* Features we provide ourself. */
+
+#define HAVE_ATTR_XATTR_H 1
+#define HAVE_ATTR_LIBATTR_H 1
+#define HAVE_CONFIG_H 1
+
+#define HAVE_FGETXATTR 1
+#define HAVE_FLISTXATTR 1
+#define HAVE_FSETXATTR 1
+#define HAVE_GETXATTR 1
+#define HAVE_LISTXATTR 1
+#define HAVE_SETXATTR 1
diff --git a/libattr/syscalls.c b/libattr/syscalls.c
new file mode 100644
index 0000000..6ab0ca3
--- /dev/null
+++ b/libattr/syscalls.c
@@ -0,0 +1,263 @@
+/*
+ * Copyright (c) 2001-2002 Silicon Graphics, Inc.
+ * All Rights Reserved.
+ *
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU General Public License as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it would be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write the Free Software Foundation,
+ * Inc.,  51 Franklin St, Fifth Floor, Boston, MA  02110-1301  USA
+ */
+
+/*
+ * The use of the syscall() function is an additional level of
+ * indirection.  This avoids the dependency on kernel sources.
+ */
+
+#include <errno.h>
+#include <unistd.h>
+
+#if defined (__i386__)
+# define HAVE_XATTR_SYSCALLS 1
+# define __NR_setxattr		226
+# define __NR_lsetxattr		227
+# define __NR_fsetxattr		228
+# define __NR_getxattr		229
+# define __NR_lgetxattr		230
+# define __NR_fgetxattr		231
+# define __NR_listxattr		232
+# define __NR_llistxattr	233
+# define __NR_flistxattr	234
+# define __NR_removexattr	235
+# define __NR_lremovexattr	236
+# define __NR_fremovexattr	237
+#elif defined (__sparc__)
+# define HAVE_XATTR_SYSCALLS 1
+# define __NR_setxattr		169
+# define __NR_lsetxattr		170
+# define __NR_fsetxattr		171
+# define __NR_getxattr		172
+# define __NR_lgetxattr		173
+# define __NR_fgetxattr		177
+# define __NR_listxattr		178
+# define __NR_llistxattr	179
+# define __NR_flistxattr	180
+# define __NR_removexattr	181
+# define __NR_lremovexattr	182
+# define __NR_fremovexattr	186
+#elif defined (__ia64__)
+# define HAVE_XATTR_SYSCALLS 1
+# define __NR_setxattr		1217
+# define __NR_lsetxattr		1218
+# define __NR_fsetxattr		1219
+# define __NR_getxattr		1220
+# define __NR_lgetxattr		1221
+# define __NR_fgetxattr		1222
+# define __NR_listxattr		1223
+# define __NR_llistxattr	1224
+# define __NR_flistxattr	1225
+# define __NR_removexattr	1226
+# define __NR_lremovexattr	1227
+# define __NR_fremovexattr	1228
+#elif defined (__powerpc__)
+# define HAVE_XATTR_SYSCALLS 1
+# define __NR_setxattr		209
+# define __NR_lsetxattr		210
+# define __NR_fsetxattr		211
+# define __NR_getxattr		212
+# define __NR_lgetxattr		213
+# define __NR_fgetxattr		214
+# define __NR_listxattr		215
+# define __NR_llistxattr	216
+# define __NR_flistxattr	217
+# define __NR_removexattr	218
+# define __NR_lremovexattr	219
+# define __NR_fremovexattr	220
+#elif defined (__x86_64__)
+# define HAVE_XATTR_SYSCALLS 1
+# define __NR_setxattr		188
+# define __NR_lsetxattr		189
+# define __NR_fsetxattr		190
+# define __NR_getxattr		191
+# define __NR_lgetxattr		192
+# define __NR_fgetxattr		193
+# define __NR_listxattr		194
+# define __NR_llistxattr	195
+# define __NR_flistxattr	196
+# define __NR_removexattr	197
+# define __NR_lremovexattr	198
+# define __NR_fremovexattr	199
+#elif defined (__s390__)
+# define HAVE_XATTR_SYSCALLS 1
+# define __NR_setxattr		224
+# define __NR_lsetxattr		225
+# define __NR_fsetxattr		226
+# define __NR_getxattr		227
+# define __NR_lgetxattr		228
+# define __NR_fgetxattr		229
+# define __NR_listxattr		230
+# define __NR_llistxattr	231
+# define __NR_flistxattr	232
+# define __NR_removexattr	233
+# define __NR_lremovexattr	234
+# define __NR_fremovexattr	235
+#elif defined (__arm__)
+# define HAVE_XATTR_SYSCALLS 1
+# if defined(__ARM_EABI__) || defined(__thumb__)
+#  define __NR_SYSCALL_BASE 0
+# else
+#  define __NR_SYSCALL_BASE 0x900000
+# endif
+# define __NR_setxattr		(__NR_SYSCALL_BASE+226)
+# define __NR_lsetxattr		(__NR_SYSCALL_BASE+227)
+# define __NR_fsetxattr		(__NR_SYSCALL_BASE+228)
+# define __NR_getxattr		(__NR_SYSCALL_BASE+229)
+# define __NR_lgetxattr		(__NR_SYSCALL_BASE+230)
+# define __NR_fgetxattr		(__NR_SYSCALL_BASE+231)
+# define __NR_listxattr		(__NR_SYSCALL_BASE+232)
+# define __NR_llistxattr	(__NR_SYSCALL_BASE+233)
+# define __NR_flistxattr	(__NR_SYSCALL_BASE+234)
+# define __NR_removexattr	(__NR_SYSCALL_BASE+235)
+# define __NR_lremovexattr	(__NR_SYSCALL_BASE+236)
+# define __NR_fremovexattr	(__NR_SYSCALL_BASE+237)
+#elif defined (__mips64__)
+# define HAVE_XATTR_SYSCALLS 1
+# define __NR_Linux 5000
+# define __NR_setxattr		(__NR_Linux + 217)
+# define __NR_lsetxattr		(__NR_Linux + 218)
+# define __NR_fsetxattr		(__NR_Linux + 219)
+# define __NR_getxattr		(__NR_Linux + 220)
+# define __NR_lgetxattr		(__NR_Linux + 221)
+# define __NR_fgetxattr		(__NR_Linux + 222)
+# define __NR_listxattr		(__NR_Linux + 223)
+# define __NR_llistxattr	(__NR_Linux + 224)
+# define __NR_flistxattr	(__NR_Linux + 225)
+# define __NR_removexattr	(__NR_Linux + 226)
+# define __NR_lremovexattr	(__NR_Linux + 227)
+# define __NR_fremovexattr	(__NR_Linux + 228)
+#elif defined (__mips__)
+# define HAVE_XATTR_SYSCALLS 1
+# define __NR_Linux 4000
+# define __NR_setxattr		(__NR_Linux + 224)
+# define __NR_lsetxattr		(__NR_Linux + 225)
+# define __NR_fsetxattr		(__NR_Linux + 226)
+# define __NR_getxattr		(__NR_Linux + 227)
+# define __NR_lgetxattr		(__NR_Linux + 228)
+# define __NR_fgetxattr		(__NR_Linux + 229)
+# define __NR_listxattr		(__NR_Linux + 230)
+# define __NR_llistxattr	(__NR_Linux + 231)
+# define __NR_flistxattr	(__NR_Linux + 232)
+# define __NR_removexattr	(__NR_Linux + 233)
+# define __NR_lremovexattr	(__NR_Linux + 234)
+# define __NR_fremovexattr	(__NR_Linux + 235)
+#elif defined (__alpha__)
+# define HAVE_XATTR_SYSCALLS 1
+# define __NR_setxattr		382
+# define __NR_lsetxattr		383
+# define __NR_fsetxattr		384
+# define __NR_getxattr		385
+# define __NR_lgetxattr		386
+# define __NR_fgetxattr		387
+# define __NR_listxattr		388
+# define __NR_llistxattr	389
+# define __NR_flistxattr	390
+# define __NR_removexattr	391
+# define __NR_lremovexattr	392
+# define __NR_fremovexattr	393
+#elif defined (__mc68000__)
+# define HAVE_XATTR_SYSCALLS 1
+# define __NR_setxattr		223
+# define __NR_lsetxattr		224
+# define __NR_fsetxattr		225
+# define __NR_getxattr		226
+# define __NR_lgetxattr		227
+# define __NR_fgetxattr		228
+# define __NR_listxattr		229
+# define __NR_llistxattr	230
+# define __NR_flistxattr	231
+# define __NR_removexattr	232
+# define __NR_lremovexattr	233
+# define __NR_fremovexattr	234
+#else
+# warning "Extended attribute syscalls undefined for this architecture"
+# define HAVE_XATTR_SYSCALLS 0
+#endif
+
+#if HAVE_XATTR_SYSCALLS
+# define SYSCALL(args...)	syscall(args)
+#else
+# define SYSCALL(args...)	( errno = ENOSYS, -1 )
+#endif
+
+int setxattr (const char *path, const char *name,
+			void *value, size_t size, int flags)
+{
+	return SYSCALL(__NR_setxattr, path, name, value, size, flags);
+}
+
+int lsetxattr (const char *path, const char *name,
+			void *value, size_t size, int flags)
+{
+	return SYSCALL(__NR_lsetxattr, path, name, value, size, flags);
+}
+
+int fsetxattr (int filedes, const char *name,
+			void *value, size_t size, int flags)
+{
+	return SYSCALL(__NR_fsetxattr, filedes, name, value, size, flags);
+}
+
+ssize_t getxattr (const char *path, const char *name,
+				void *value, size_t size)
+{
+	return SYSCALL(__NR_getxattr, path, name, value, size);
+}
+
+ssize_t lgetxattr (const char *path, const char *name,
+				void *value, size_t size)
+{
+	return SYSCALL(__NR_lgetxattr, path, name, value, size);
+}
+
+ssize_t fgetxattr (int filedes, const char *name,
+				void *value, size_t size)
+{
+	return SYSCALL(__NR_fgetxattr, filedes, name, value, size);
+}
+
+ssize_t listxattr (const char *path, char *list, size_t size)
+{
+	return SYSCALL(__NR_listxattr, path, list, size);
+}
+
+ssize_t llistxattr (const char *path, char *list, size_t size)
+{
+	return SYSCALL(__NR_llistxattr, path, list, size);
+}
+
+ssize_t flistxattr (int filedes, char *list, size_t size)
+{
+	return SYSCALL(__NR_flistxattr, filedes, list, size);
+}
+
+int removexattr (const char *path, const char *name)
+{
+	return SYSCALL(__NR_removexattr, path, name);
+}
+
+int lremovexattr (const char *path, const char *name)
+{
+	return SYSCALL(__NR_lremovexattr, path, name);
+}
+
+int fremovexattr (int filedes, const char *name)
+{
+	return SYSCALL(__NR_fremovexattr, filedes, name);
+}
diff --git a/tools/tprop/Android.mk b/tools/tprop/Android.mk
new file mode 100644
index 0000000..1b29399
--- /dev/null
+++ b/tools/tprop/Android.mk
@@ -0,0 +1,31 @@
+# Copyright (c) 2010 The Pennsylvania State University
+# Systems and Internet Infrastructure Security Laboratory
+#
+# Authors: William Enck <enck@cse.psu.edu>
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#      http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+LOCAL_PATH := $(my-dir)
+
+ifeq ($(WITH_TAINT_TRACKING),true)
+    # Add ftaint only for "eng"
+    include $(CLEAR_VARS)
+    LOCAL_MODULE := ftaint
+    #LOCAL_MODULE_CLASS := EXECUTABLES
+    LOCAL_MODULE_TAGS := eng
+    LOCAL_SRC_FILES := ftaint.c
+    LOCAL_STATIC_LIBRARIES := libattr
+    LOCAL_C_INCLUDES := dalvik/libattr
+    include $(BUILD_EXECUTABLE)
+endif
+
diff --git a/tools/tprop/ftaint.c b/tools/tprop/ftaint.c
new file mode 100644
index 0000000..6a68292
--- /dev/null
+++ b/tools/tprop/ftaint.c
@@ -0,0 +1,121 @@
+/*
+ * Copyright (c) 2010 The Pennsylvania State University
+ * Systems and Internet Infrastructure Security Laboratory
+ *
+ * Authors: William Enck <enck@cse.psu.edu>
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#include <stdio.h>
+#include <string.h>
+#include <stdlib.h>
+#include <errno.h>
+
+#include "attr/xattr.h"
+
+#define TAINT_XATTR_NAME "user.taint"
+
+#define USAGE "Usage: %s [g|s|a] <file> [<hex>]\n"
+#define TAINT_CLEAR 0x0
+
+typedef unsigned int u4;
+
+static u4 getTaintXattr(const char *path)
+{
+    int ret;
+    u4 buf;
+    u4 tag = TAINT_CLEAR;
+
+    ret = getxattr(path, TAINT_XATTR_NAME, &buf, sizeof(buf)); 
+    if (ret > 0) {
+	tag = buf;
+    } else {
+	if (errno == ENOATTR) {
+	    fprintf(stdout, "getxattr(%s): no taint tag\n", path);
+	} else if (errno == ERANGE) {
+	    fprintf(stderr, "Error: getxattr(%s) contents to large\n", path);
+	} else if (errno == ENOTSUP) {
+	    fprintf(stderr, "Error: getxattr(%s) not supported\n", path);
+	} else {
+	    fprintf(stderr, "Errro: getxattr(%s): unknown error code %d\n", path, errno);
+	}
+    }
+
+    return tag;
+}
+
+static void setTaintXattr(const char *path, u4 tag)
+{
+    int ret;
+
+    ret = setxattr(path, TAINT_XATTR_NAME, &tag, sizeof(tag), 0);
+
+    if (ret < 0) {
+	if (errno == ENOSPC || errno == EDQUOT) {
+	    fprintf(stderr, "Error: setxattr(%s): not enough room to set xattr\n", path);
+	} else if (errno == ENOTSUP) {
+	    fprintf(stderr, "Error: setxattr(%s) not supported\n", path);
+	} else {
+	    fprintf(stderr, "Errro: setxattr(%s): unknown error code %d\n", path, errno);
+	}
+    }
+
+}
+
+void usage(const char *prog)
+{
+    fprintf(stderr, USAGE, prog);
+    exit(1);
+}
+
+int main(int argc, char *argv[])
+{
+    u4 tag;
+
+    if (argc != 3 && argc != 4) {
+	usage(argv[0]);
+    }
+
+    if (strlen(argv[1]) != 1) {
+	usage(argv[0]);
+    }
+
+    // Get the taint
+    if (argc == 3) {
+	if (argv[1][0] == 'g') {
+	    tag = getTaintXattr(argv[2]);
+	    fprintf(stdout, "0x%08x\n", tag);
+	    return 0;
+	} else {
+	    usage(argv[0]);
+	}
+    }
+
+    // Set the taint
+    tag = strtol(argv[3], NULL, 16);
+    if (tag == 0 && errno == EINVAL) {
+	usage(argv[0]);
+    }
+
+    if (argv[1][0] == 's') {
+	setTaintXattr(argv[2], tag);
+    } else if (argv[1][0] == 'a') {
+	u4 old = getTaintXattr(argv[2]);
+	setTaintXattr(argv[2], tag | old);
+    } else {
+	usage(argv[0]);
+    }
+
+    return 0;
+}
diff --git a/vm/Atomic.h b/vm/Atomic.h
index 6f7100b..1674140 100644
--- a/vm/Atomic.h
+++ b/vm/Atomic.h
@@ -52,6 +52,26 @@ extern "C" int64_t dvmQuasiAtomicSwap64Sync(int64_t value,
  */
 extern "C" int64_t dvmQuasiAtomicRead64(volatile const int64_t* addr);
 
+#ifdef WITH_TAINT_TRACKING
+
+// to return 64-bit value and taint tag on stack
+typedef int v4si __attribute__ ((vector_size (16)));
+union Vec4 {
+    v4si vec4;
+    struct {
+        uint64_t val;
+        uint32_t taint;
+        uint32_t unused;
+    } uint64_with_taint;
+};
+
+extern "C" int64_t dvmQuasiAtomicSwap64FieldTaint(int64_t value, volatile int64_t* addr, uint32_t taint);
+extern "C" int64_t dvmQuasiAtomicRead32SfieldTaint(volatile const int32_t* addr);
+extern "C" int32_t dvmQuasiAtomicSwap32SfieldTaint(int32_t value, volatile int32_t* addr, uint32_t taint);
+extern "C" v4si dvmQuasiAtomicRead64FieldTaint(volatile const int64_t* addr);
+
+#endif /*WITH_TAINT_TRACKING*/
+
 /*
  * If the value at "addr" is equal to "oldvalue", replace it with "newvalue"
  * and return 0.  Otherwise, don't swap, and return nonzero.
diff --git a/vm/Dalvik.h b/vm/Dalvik.h
index eecbf8d..a99f201 100644
--- a/vm/Dalvik.h
+++ b/vm/Dalvik.h
@@ -84,4 +84,9 @@
 #include "InlineNative.h"
 #include "oo/ObjectInlines.h"
 
+#ifdef WITH_TAINT_TRACKING
+#include "interp/Taint.h"
+#include "tprop/TaintProp.h"
+#endif
+
 #endif  // DALVIK_DALVIK_H_
diff --git a/vm/DalvikVersion.h b/vm/DalvikVersion.h
index e71c839..e33538c 100644
--- a/vm/DalvikVersion.h
+++ b/vm/DalvikVersion.h
@@ -32,6 +32,11 @@
  * way classes load changes, e.g. field ordering or vtable layout.  Changing
  * this guarantees that the optimized form of the DEX file is regenerated.
  */
+#ifdef WITH_TAINT_TRACKING
+// just to be safe, make sure odex is regenerated
+#define DALVIK_VM_BUILD         28
+#else
 #define DALVIK_VM_BUILD         27
+#endif /*WITH_TAINT_TRACKING*/
 
 #endif  // DALVIK_VERSION_H_
diff --git a/vm/Debugger.cpp b/vm/Debugger.cpp
index 5c44f93..6e09185 100644
--- a/vm/Debugger.cpp
+++ b/vm/Debugger.cpp
@@ -2197,7 +2197,12 @@ static Object* getThisObject(const u4* framePtr)
 {
     const StackSaveArea* saveArea = SAVEAREA_FROM_FP(framePtr);
     const Method* method = saveArea->method;
+#ifdef WITH_TAINT_TRACKING
+    /* taint tags are interleaved */
+    int argOffset = (method->registersSize - method->insSize) <<1;
+#else
     int argOffset = method->registersSize - method->insSize;
+#endif
     Object* thisObj;
 
     if (method == NULL) {
@@ -2263,7 +2268,12 @@ void dvmDbgGetLocalValue(ObjectId threadId, FrameId frameId, int slot,
 
     UNUSED_PARAMETER(threadId);
 
+#ifdef WITH_TAINT_TRACKING
+    /* Taint tags are interleaved */
+    slot = untweakSlot(slot, framePtr) <<1;     // Eclipse workaround
+#else
     slot = untweakSlot(slot, framePtr);     // Eclipse workaround
+#endif
 
     switch (tag) {
     case JT_BOOLEAN:
@@ -2322,7 +2332,16 @@ void dvmDbgGetLocalValue(ObjectId threadId, FrameId frameId, int slot,
     case JT_DOUBLE:
     case JT_LONG:
         assert(expectedLen == 8);
+#ifdef WITH_TAINT_TRACKING
+	{
+	    union { u8 ll; u4 parts[2]; } conv;
+	    conv.parts[0] = framePtr[slot];
+	    conv.parts[1] = framePtr[slot+2];
+	    longVal = conv.ll;
+	}
+#else
         memcpy(&longVal, &framePtr[slot], 8);
+#endif
         set8BE(buf+1, longVal);
         break;
     default:
@@ -2345,7 +2364,12 @@ void dvmDbgSetLocalValue(ObjectId threadId, FrameId frameId, int slot, u1 tag,
 
     UNUSED_PARAMETER(threadId);
 
+#ifdef WITH_TAINT_TRACKING
+    /* taint tag is interleaved */
+    slot = untweakSlot(slot, framePtr)<<1;     // Eclipse workaround
+#else
     slot = untweakSlot(slot, framePtr);     // Eclipse workaround
+#endif
 
     switch (tag) {
     case JT_BOOLEAN:
@@ -2378,7 +2402,17 @@ void dvmDbgSetLocalValue(ObjectId threadId, FrameId frameId, int slot, u1 tag,
     case JT_DOUBLE:
     case JT_LONG:
         assert(width == 8);
+#ifdef WITH_TAINT_TRACKING
+        /* taint tag is interleaved */
+        {
+        	union { u8 ll; u4 parts[2]; } conv;
+        	conv.ll = value;
+        	framePtr[slot] = conv.parts[0];
+        	framePtr[slot+2] = conv.parts[1];
+        }
+#else
         memcpy(&framePtr[slot], &value, 8);
+#endif
         break;
     case JT_VOID:
     case JT_CLASS_OBJECT:
diff --git a/vm/Dvm.mk b/vm/Dvm.mk
index 4aa054d..6f29a2e 100644
--- a/vm/Dvm.mk
+++ b/vm/Dvm.mk
@@ -28,6 +28,17 @@ LOCAL_CFLAGS += -fstrict-aliasing -Wstrict-aliasing=2 -fno-align-jumps
 LOCAL_CFLAGS += -Wall -Wextra -Wno-unused-parameter
 LOCAL_CFLAGS += -DARCH_VARIANT=\"$(dvm_arch_variant)\"
 
+# Turn on Taint Tracking
+ifeq ($(WITH_TAINT_TRACKING),true)
+  LOCAL_CFLAGS += -DWITH_TAINT_TRACKING
+endif
+ifeq ($(TAINT_JNI_LOG),true)
+  LOCAL_CFLAGS += -DTAINT_JNI_LOG
+endif
+ifeq ($(WITH_TAINT_FAST),true)
+  LOCAL_CFLAGS += -DWITH_TAINT_FAST
+endif
+
 #
 # Optional features.  These may impact the size or performance of the VM.
 #
@@ -184,6 +195,12 @@ LOCAL_SRC_FILES := \
 	test/TestHash.cpp \
 	test/TestIndirectRefTable.cpp
 
+ifeq ($(WITH_TAINT_TRACKING), true)
+	LOCAL_SRC_FILES += native/dalvik_system_Taint.cpp
+	LOCAL_SRC_FILES += tprop/TaintProp.cpp
+	LOCAL_SRC_FILES += tprop/TaintPolicy.cpp
+endif
+
 # TODO: this is the wrong test, but what's the right one?
 ifeq ($(dvm_arch),arm)
   LOCAL_SRC_FILES += os/android.cpp
@@ -227,12 +244,22 @@ LOCAL_C_INCLUDES += \
 	external/zlib \
 	libcore/include \
 
+# Taint tracking with file propagation
+ifeq ($(WITH_TAINT_TRACKING),true)
+    LOCAL_C_INCLUDES += dalvik/libattr
+endif
+
 MTERP_ARCH_KNOWN := false
 
 ifeq ($(dvm_arch),arm)
   #dvm_arch_variant := armv7-a
   #LOCAL_CFLAGS += -march=armv7-a -mfloat-abi=softfp -mfpu=vfp
-  LOCAL_CFLAGS += -Werror
+  #LOCAL_CFLAGS += -march=armv7-a -mfloat-abi=softfp -mfpu=neon
+
+  # begin WITH_TAINT_TRACKING
+  # don't treat warnings as errors
+  #LOCAL_CFLAGS += -Werror
+  # end WITH_TAINT_TRACKING
   MTERP_ARCH_KNOWN := true
   # Select architecture-specific sources (armv5te, armv7-a, etc.)
   LOCAL_SRC_FILES += \
@@ -254,9 +281,19 @@ ifeq ($(dvm_arch),arm)
 		compiler/codegen/arm/ArmRallocUtil.cpp \
 		compiler/template/out/CompilerTemplateAsm-$(dvm_arch_variant).S
   endif
+
+  # Taint tracking with file propagation
+  ifeq ($(WITH_TAINT_TRACKING),true)
+  		LOCAL_STATIC_LIBRARIES += libattr
+  endif
 endif
 
 ifeq ($(dvm_arch),x86)
+# begin WITH_TAINT_TRACKING
+# for TaintDroid: need to know so we can force portable interp
+   LOCAL_CFLAGS += -DTAINT_IS_86
+# end WITH_TAINT_TRACKING
+
   ifeq ($(dvm_os),linux)
     MTERP_ARCH_KNOWN := true
     LOCAL_CFLAGS += -DDVM_JMP_TABLE_MTERP=1
diff --git a/vm/Init.cpp b/vm/Init.cpp
index 48cc6c1..6fe2697 100644
--- a/vm/Init.cpp
+++ b/vm/Init.cpp
@@ -177,6 +177,9 @@ static void usage(const char* progName)
 #if ANDROID_SMP != 0
         " smp"
 #endif
+#ifdef WITH_TAINT_TRACKING
+    	" taint_tracking"
+#endif
     );
 #ifdef DVM_SHOW_EXCEPTION
     dvmFprintf(stderr, " show_exception=%d", DVM_SHOW_EXCEPTION);
@@ -895,11 +898,23 @@ static int processOptions(int argc, const char* const argv[],
             if (strcmp(argv[i] + 9, "none") == 0)
                 gDvm.dexOptMode = OPTIMIZE_MODE_NONE;
             else if (strcmp(argv[i] + 9, "verified") == 0)
+#if defined(WITH_TAINT_TRACKING) && !defined(WITH_TAINT_ODEX)
+                gDvm.dexOptMode = OPTIMIZE_MODE_NONE;
+#else
                 gDvm.dexOptMode = OPTIMIZE_MODE_VERIFIED;
+#endif
             else if (strcmp(argv[i] + 9, "all") == 0)
+#if defined(WITH_TAINT_TRACKING) && !defined(WITH_TAINT_ODEX)
+                gDvm.dexOptMode = OPTIMIZE_MODE_NONE;
+#else
                 gDvm.dexOptMode = OPTIMIZE_MODE_ALL;
+#endif
             else if (strcmp(argv[i] + 9, "full") == 0)
+#if defined(WITH_TAINT_TRACKING) && !defined(WITH_TAINT_ODEX)
+                gDvm.dexOptMode = OPTIMIZE_MODE_NONE;
+#else
                 gDvm.dexOptMode = OPTIMIZE_MODE_FULL;
+#endif
             else {
                 dvmFprintf(stderr, "Unrecognized dexopt option '%s'\n",argv[i]);
                 return -1;
@@ -1085,7 +1100,11 @@ static void setCommandLineDefaults()
 
     /* default verification and optimization modes */
     gDvm.classVerifyMode = VERIFY_MODE_ALL;
+#if defined(WITH_TAINT_TRACKING) && !defined(WITH_TAINT_ODEX)
+    gDvm.dexOptMode = OPTIMIZE_MODE_NONE;
+#else
     gDvm.dexOptMode = OPTIMIZE_MODE_VERIFIED;
+#endif
     gDvm.monitorVerification = false;
     gDvm.generateRegisterMaps = true;
     gDvm.registerMapMode = kRegisterMapModeTypePrecise;
@@ -1101,6 +1120,16 @@ static void setCommandLineDefaults()
     gDvm.executionMode = kExecutionModeJit;
 #else
     gDvm.executionMode = kExecutionModeInterpFast;
+#if defined(WITH_TAINT_TRACKING)
+#if defined(WITH_TAINT_FAST)
+    gDvm.executionMode = kExecutionModeInterpFast;
+#else
+    gDvm.executionMode = kExecutionModeInterpPortable;
+#endif /*WITH_TAINT_FAST*/
+#if defined(TAINT_IS_86)
+    gDvm.executionMode = kExecutionModeInterpPortable;
+#endif /*TAINT_IS_X86*/
+#endif /*WITH_TAINT_TRACKING*/
 #endif
 
     /*
diff --git a/vm/InlineNative.cpp b/vm/InlineNative.cpp
index 80d522a..4e5337a 100644
--- a/vm/InlineNative.cpp
+++ b/vm/InlineNative.cpp
@@ -107,8 +107,13 @@ extern "C" u4 __memcmp16(const u2* s0, const u2* s1, size_t count);
  *
  * This exists only for benchmarks.
  */
+#ifdef WITH_TAINT_TRACKING
+static bool org_apache_harmony_dalvik_NativeTestTarget_emptyInlineMethod(
+    u4 arg0, u4 arg1, u4 arg2, u4 arg3, u4 arg0_taint, u4 arg1_taint, struct Taint* rtaint, JValue* pResult)
+#else
 static bool org_apache_harmony_dalvik_NativeTestTarget_emptyInlineMethod(
     u4 arg0, u4 arg1, u4 arg2, u4 arg3, JValue* pResult)
+#endif /*WITH_TAINT_TRACKING*/
 {
     // do nothing
     return true;
@@ -124,8 +129,13 @@ static bool org_apache_harmony_dalvik_NativeTestTarget_emptyInlineMethod(
 /*
  * public char charAt(int index)
  */
+#ifdef WITH_TAINT_TRACKING
+bool javaLangString_charAt(u4 arg0, u4 arg1, u4 arg2, u4 arg3,
+    u4 arg0_taint, u4 arg1_taint, struct Taint* rtaint, JValue* pResult)
+#else
 bool javaLangString_charAt(u4 arg0, u4 arg1, u4 arg2, u4 arg3,
     JValue* pResult)
+#endif /*WITH_TAINT_TRACKING*/
 {
     int count, offset;
     ArrayObject* chars;
@@ -147,6 +157,10 @@ bool javaLangString_charAt(u4 arg0, u4 arg1, u4 arg2, u4 arg3,
             dvmGetFieldObject((Object*) arg0, STRING_FIELDOFF_VALUE);
 
         pResult->i = ((const u2*)(void*)chars->contents)[arg1 + offset];
+#ifdef WITH_TAINT_TRACKING
+	// rtaint <- taint(string) | taint(index)
+	rtaint->tag = chars->taint.tag | arg1_taint;
+#endif /*WITH_TAINT_TRACKING*/
         return true;
     }
 }
@@ -196,8 +210,13 @@ static void badMatch(StringObject* thisStrObj, StringObject* compStrObj,
 /*
  * public int compareTo(String s)
  */
+#ifdef WITH_TAINT_TRACKING
+bool javaLangString_compareTo(u4 arg0, u4 arg1, u4 arg2, u4 arg3,
+    u4 arg0_taint, u4 arg1_taint, struct Taint* rtaint, JValue* pResult)
+#else
 bool javaLangString_compareTo(u4 arg0, u4 arg1, u4 arg2, u4 arg3,
     JValue* pResult)
+#endif /*WITH_TAINT_TRACKING*/
 {
     /*
      * Null reference check on "this".  Normally this is performed during
@@ -291,8 +310,13 @@ bool javaLangString_compareTo(u4 arg0, u4 arg1, u4 arg2, u4 arg3,
 /*
  * public boolean equals(Object anObject)
  */
+#ifdef WITH_TAINT_TRACKING
+bool javaLangString_equals(u4 arg0, u4 arg1, u4 arg2, u4 arg3,
+    u4 arg0_taint, u4 arg1_taint, struct Taint* rtaint, JValue* pResult)
+#else
 bool javaLangString_equals(u4 arg0, u4 arg1, u4 arg2, u4 arg3,
     JValue* pResult)
+#endif /*WITH_TAINT_TRACKING*/
 {
     /*
      * Null reference check on "this".
@@ -400,8 +424,13 @@ bool javaLangString_equals(u4 arg0, u4 arg1, u4 arg2, u4 arg3,
 /*
  * public int length()
  */
+#ifdef WITH_TAINT_TRACKING
+bool javaLangString_length(u4 arg0, u4 arg1, u4 arg2, u4 arg3,
+    u4 arg0_taint, u4 arg1_taint, struct Taint* rtaint, JValue* pResult)
+#else
 bool javaLangString_length(u4 arg0, u4 arg1, u4 arg2, u4 arg3,
     JValue* pResult)
+#endif /*WITH_TAINT_TRACKING*/
 {
     //ALOGI("String.length this=0x%08x pResult=%p", arg0, pResult);
 
@@ -418,8 +447,13 @@ bool javaLangString_length(u4 arg0, u4 arg1, u4 arg2, u4 arg3,
 /*
  * public boolean isEmpty()
  */
+#ifdef WITH_TAINT_TRACKING
+bool javaLangString_isEmpty(u4 arg0, u4 arg1, u4 arg2, u4 arg3,
+    u4 arg0_taint, u4 arg1_taint, struct Taint* rtaint, JValue* pResult)
+#else
 bool javaLangString_isEmpty(u4 arg0, u4 arg1, u4 arg2, u4 arg3,
     JValue* pResult)
+#endif /*WITH_TAINT_TRACKING*/
 {
     //ALOGI("String.isEmpty this=0x%08x pResult=%p", arg0, pResult);
 
@@ -493,8 +527,13 @@ static inline int indexOfCommon(Object* strObj, int ch, int start)
  * The character must be <= 0xffff; this method does not handle supplementary
  * characters.
  */
+#ifdef WITH_TAINT_TRACKING
+bool javaLangString_fastIndexOf_II(u4 arg0, u4 arg1, u4 arg2, u4 arg3,
+    u4 arg0_taint, u4 arg1_taint, struct Taint* rtaint, JValue* pResult)
+#else
 bool javaLangString_fastIndexOf_II(u4 arg0, u4 arg1, u4 arg2, u4 arg3,
     JValue* pResult)
+#endif /*WITH_TAINT_TRACKING*/
 {
     /* null reference check on "this" */
     if ((Object*) arg0 == NULL) {
@@ -527,46 +566,75 @@ union Convert64 {
 /*
  * public static int abs(int)
  */
+#ifdef WITH_TAINT_TRACKING
+bool javaLangMath_abs_int(u4 arg0, u4 arg1, u4 arg2, u4 arg3,
+    u4 arg0_taint, u4 arg1_taint, struct Taint* rtaint, JValue* pResult)
+#else
 bool javaLangMath_abs_int(u4 arg0, u4 arg1, u4 arg2, u4 arg3,
     JValue* pResult)
+#endif /*WITH_TAINT_TRACKING*/
 {
     s4 val = (s4) arg0;
     pResult->i = (val >= 0) ? val : -val;
+#ifdef WITH_TAINT_TRACKING
+    rtaint->tag = arg0_taint;
+#endif /*WITH_TAINT_TRACKING*/
     return true;
 }
 
 /*
  * public static long abs(long)
  */
+#ifdef WITH_TAINT_TRACKING
+bool javaLangMath_abs_long(u4 arg0, u4 arg1, u4 arg2, u4 arg3,
+    u4 arg0_taint, u4 arg1_taint, struct Taint* rtaint, JValue* pResult)
+#else
 bool javaLangMath_abs_long(u4 arg0, u4 arg1, u4 arg2, u4 arg3,
     JValue* pResult)
+#endif /*WITH_TAINT_TRACKING*/
 {
     Convert64 convert;
     convert.arg[0] = arg0;
     convert.arg[1] = arg1;
     s8 val = convert.ll;
     pResult->j = (val >= 0) ? val : -val;
+#ifdef WITH_TAINT_TRACKING
+    rtaint->tag = arg0_taint;
+#endif /*WITH_TAINT_TRACKING*/
     return true;
 }
 
 /*
  * public static float abs(float)
  */
+#ifdef WITH_TAINT_TRACKING
+bool javaLangMath_abs_float(u4 arg0, u4 arg1, u4 arg2, u4 arg3,
+    u4 arg0_taint, u4 arg1_taint, struct Taint* rtaint, JValue* pResult)
+#else
 bool javaLangMath_abs_float(u4 arg0, u4 arg1, u4 arg2, u4 arg3,
     JValue* pResult)
+#endif /*WITH_TAINT_TRACKING*/
 {
     Convert32 convert;
     /* clear the sign bit; assumes a fairly common fp representation */
     convert.arg = arg0 & 0x7fffffff;
     pResult->f = convert.ff;
+#ifdef WITH_TAINT_TRACKING
+    rtaint->tag = arg0_taint;
+#endif /*WITH_TAINT_TRACKING*/
     return true;
 }
 
 /*
  * public static double abs(double)
  */
+#ifdef WITH_TAINT_TRACKING
+bool javaLangMath_abs_double(u4 arg0, u4 arg1, u4 arg2, u4 arg3,
+    u4 arg0_taint, u4 arg1_taint, struct Taint* rtaint, JValue* pResult)
+#else
 bool javaLangMath_abs_double(u4 arg0, u4 arg1, u4 arg2, u4 arg3,
     JValue* pResult)
+#endif /*WITH_TAINT_TRACKING*/
 {
     Convert64 convert;
     convert.arg[0] = arg0;
@@ -574,26 +642,45 @@ bool javaLangMath_abs_double(u4 arg0, u4 arg1, u4 arg2, u4 arg3,
     /* clear the sign bit in the (endian-dependent) high word */
     convert.ll &= 0x7fffffffffffffffULL;
     pResult->d = convert.dd;
+#ifdef WITH_TAINT_TRACKING
+    rtaint->tag = arg0_taint;
+#endif /*WITH_TAINT_TRACKING*/
     return true;
 }
 
 /*
  * public static int min(int)
  */
+#ifdef WITH_TAINT_TRACKING
+bool javaLangMath_min_int(u4 arg0, u4 arg1, u4 arg2, u4 arg3,
+    u4 arg0_taint, u4 arg1_taint, struct Taint* rtaint, JValue* pResult)
+#else
 bool javaLangMath_min_int(u4 arg0, u4 arg1, u4 arg2, u4 arg3,
     JValue* pResult)
+#endif /*WITH_TAINT_TRACKING*/
 {
     pResult->i = ((s4) arg0 < (s4) arg1) ? arg0 : arg1;
+#ifdef WITH_TAINT_TRACKING
+    rtaint->tag = arg0_taint | arg1_taint;
+#endif /*WITH_TAINT_TRACKING*/
     return true;
 }
 
 /*
  * public static int max(int)
  */
+#ifdef WITH_TAINT_TRACKING
+bool javaLangMath_max_int(u4 arg0, u4 arg1, u4 arg2, u4 arg3,
+    u4 arg0_taint, u4 arg1_taint, struct Taint* rtaint, JValue* pResult)
+#else
 bool javaLangMath_max_int(u4 arg0, u4 arg1, u4 arg2, u4 arg3,
     JValue* pResult)
+#endif /*WITH_TAINT_TRACKING*/
 {
     pResult->i = ((s4) arg0 > (s4) arg1) ? arg0 : arg1;
+#ifdef WITH_TAINT_TRACKING
+    rtaint->tag = arg0_taint | arg1_taint;
+#endif /*WITH_TAINT_TRACKING*/
     return true;
 }
 
@@ -604,39 +691,63 @@ bool javaLangMath_max_int(u4 arg0, u4 arg1, u4 arg2, u4 arg3,
  * by an fcmpd of the result against itself.  If it doesn't match (i.e.
  * it's NaN), the libm sqrt() is invoked.
  */
+#ifdef WITH_TAINT_TRACKING
+bool javaLangMath_sqrt(u4 arg0, u4 arg1, u4 arg2, u4 arg3,
+    u4 arg0_taint, u4 arg1_taint, struct Taint* rtaint, JValue* pResult)
+#else
 bool javaLangMath_sqrt(u4 arg0, u4 arg1, u4 arg2, u4 arg3,
     JValue* pResult)
+#endif /*WITH_TAINT_TRACKING*/
 {
     Convert64 convert;
     convert.arg[0] = arg0;
     convert.arg[1] = arg1;
     pResult->d = sqrt(convert.dd);
+#ifdef WITH_TAINT_TRACKING
+    rtaint->tag = arg0_taint;
+#endif /*WITH_TAINT_TRACKING*/
     return true;
 }
 
 /*
  * public static double cos(double)
  */
+#ifdef WITH_TAINT_TRACKING
+bool javaLangMath_cos(u4 arg0, u4 arg1, u4 arg2, u4 arg3,
+    u4 arg0_taint, u4 arg1_taint, struct Taint* rtaint, JValue* pResult)
+#else
 bool javaLangMath_cos(u4 arg0, u4 arg1, u4 arg2, u4 arg3,
     JValue* pResult)
+#endif /*WITH_TAINT_TRACKING*/
 {
     Convert64 convert;
     convert.arg[0] = arg0;
     convert.arg[1] = arg1;
     pResult->d = cos(convert.dd);
+#ifdef WITH_TAINT_TRACKING
+    rtaint->tag = arg0_taint;
+#endif /*WITH_TAINT_TRACKING*/
     return true;
 }
 
 /*
  * public static double sin(double)
  */
+#ifdef WITH_TAINT_TRACKING
+bool javaLangMath_sin(u4 arg0, u4 arg1, u4 arg2, u4 arg3,
+    u4 arg0_taint, u4 arg1_taint, struct Taint* rtaint, JValue* pResult)
+#else
 bool javaLangMath_sin(u4 arg0, u4 arg1, u4 arg2, u4 arg3,
     JValue* pResult)
+#endif /*WITH_TAINT_TRACKING*/
 {
     Convert64 convert;
     convert.arg[0] = arg0;
     convert.arg[1] = arg1;
     pResult->d = sin(convert.dd);
+#ifdef WITH_TAINT_TRACKING
+    rtaint->tag = arg0_taint;
+#endif /*WITH_TAINT_TRACKING*/
     return true;
 }
 
@@ -646,28 +757,52 @@ bool javaLangMath_sin(u4 arg0, u4 arg1, u4 arg2, u4 arg3,
  * ===========================================================================
  */
 
+#ifdef WITH_TAINT_TRACKING
+bool javaLangFloat_floatToIntBits(u4 arg0, u4 arg1, u4 arg2, u4 arg,
+    u4 arg0_taint, u4 arg1_taint, struct Taint* rtaint, JValue* pResult)
+#else
 bool javaLangFloat_floatToIntBits(u4 arg0, u4 arg1, u4 arg2, u4 arg,
     JValue* pResult)
+#endif /*WITH_TAINT_TRACKING*/
 {
     Convert32 convert;
     convert.arg = arg0;
     pResult->i = isnanf(convert.ff) ? 0x7fc00000 : arg0;
+#ifdef WITH_TAINT_TRACKING
+    rtaint->tag = arg0_taint;
+#endif /*WITH_TAINT_TRACKING*/
     return true;
 }
 
+#ifdef WITH_TAINT_TRACKING
+bool javaLangFloat_floatToRawIntBits(u4 arg0, u4 arg1, u4 arg2, u4 arg,
+    u4 arg0_taint, u4 arg1_taint, struct Taint* rtaint, JValue* pResult)
+#else
 bool javaLangFloat_floatToRawIntBits(u4 arg0, u4 arg1, u4 arg2, u4 arg,
     JValue* pResult)
+#endif /*WITH_TAINT_TRACKING*/
 {
     pResult->i = arg0;
+#ifdef WITH_TAINT_TRACKING
+    rtaint->tag = arg0_taint;
+#endif /*WITH_TAINT_TRACKING*/
     return true;
 }
 
+#ifdef WITH_TAINT_TRACKING
+bool javaLangFloat_intBitsToFloat(u4 arg0, u4 arg1, u4 arg2, u4 arg,
+    u4 arg0_taint, u4 arg1_taint, struct Taint* rtaint, JValue* pResult)
+#else
 bool javaLangFloat_intBitsToFloat(u4 arg0, u4 arg1, u4 arg2, u4 arg,
     JValue* pResult)
+#endif /*WITH_TAINT_TRACKING*/
 {
     Convert32 convert;
     convert.arg = arg0;
     pResult->f = convert.ff;
+#ifdef WITH_TAINT_TRACKING
+    rtaint->tag = arg0_taint;
+#endif /*WITH_TAINT_TRACKING*/
     return true;
 }
 
@@ -677,33 +812,57 @@ bool javaLangFloat_intBitsToFloat(u4 arg0, u4 arg1, u4 arg2, u4 arg,
  * ===========================================================================
  */
 
+#ifdef WITH_TAINT_TRACKING
+bool javaLangDouble_doubleToLongBits(u4 arg0, u4 arg1, u4 arg2, u4 arg,
+    u4 arg0_taint, u4 arg1_taint, struct Taint* rtaint, JValue* pResult)
+#else
 bool javaLangDouble_doubleToLongBits(u4 arg0, u4 arg1, u4 arg2, u4 arg,
     JValue* pResult)
+#endif /*WITH_TAINT_TRACKING*/
 {
     Convert64 convert;
     convert.arg[0] = arg0;
     convert.arg[1] = arg1;
     pResult->j = isnan(convert.dd) ? 0x7ff8000000000000LL : convert.ll;
+#ifdef WITH_TAINT_TRACKING
+    rtaint->tag = arg0_taint;
+#endif /*WITH_TAINT_TRACKING*/
     return true;
 }
 
+#ifdef WITH_TAINT_TRACKING
+bool javaLangDouble_doubleToRawLongBits(u4 arg0, u4 arg1, u4 arg2,
+    u4 arg, u4 arg0_taint, u4 arg1_taint, struct Taint* rtaint, JValue* pResult)
+#else
 bool javaLangDouble_doubleToRawLongBits(u4 arg0, u4 arg1, u4 arg2,
     u4 arg, JValue* pResult)
+#endif /*WITH_TAINT_TRACKING*/
 {
     Convert64 convert;
     convert.arg[0] = arg0;
     convert.arg[1] = arg1;
     pResult->j = convert.ll;
+#ifdef WITH_TAINT_TRACKING
+    rtaint->tag = arg0_taint;
+#endif /*WITH_TAINT_TRACKING*/
     return true;
 }
 
+#ifdef WITH_TAINT_TRACKING
+bool javaLangDouble_longBitsToDouble(u4 arg0, u4 arg1, u4 arg2, u4 arg,
+    u4 arg0_taint, u4 arg1_taint, struct Taint* rtaint, JValue* pResult)
+#else
 bool javaLangDouble_longBitsToDouble(u4 arg0, u4 arg1, u4 arg2, u4 arg,
     JValue* pResult)
+#endif /*WITH_TAINT_TRACKING*/
 {
     Convert64 convert;
     convert.arg[0] = arg0;
     convert.arg[1] = arg1;
     pResult->d = convert.dd;
+#ifdef WITH_TAINT_TRACKING
+    rtaint->tag = arg0_taint;
+#endif /*WITH_TAINT_TRACKING*/
     return true;
 }
 
@@ -907,19 +1066,34 @@ Method* dvmResolveInlineNative(int opIndex)
  * Make an inline call for the "debug" interpreter, used when the debugger
  * or profiler is active.
  */
+#ifdef WITH_TAINT_TRACKING
+bool dvmPerformInlineOp4Dbg(u4 arg0, u4 arg1, u4 arg2, u4 arg3,
+    u4 arg0_taint, u4 arg1_taint, struct Taint* rtaint, JValue* pResult, int opIndex)
+#else
 bool dvmPerformInlineOp4Dbg(u4 arg0, u4 arg1, u4 arg2, u4 arg3,
     JValue* pResult, int opIndex)
+#endif /*WITH_TAINT_TRACKING*/
 {
     Method* method = dvmResolveInlineNative(opIndex);
     if (method == NULL) {
+#ifdef WITH_TAINT_TRACKING
+        return (*gDvmInlineOpsTable[opIndex].func)(arg0, arg1, arg2, arg3,
+                arg0_taint, arg1_taint, rtaint, pResult);
+#else
         return (*gDvmInlineOpsTable[opIndex].func)(arg0, arg1, arg2, arg3,
             pResult);
+#endif /*WITH_TAINT_TRACKING*/
     }
 
     Thread* self = dvmThreadSelf();
     TRACE_METHOD_ENTER(self, method);
+#ifdef WITH_TAINT_TRACKING
+    bool result = (*gDvmInlineOpsTable[opIndex].func)(arg0, arg1, arg2, arg3,
+                arg0_taint, arg1_taint, rtaint, pResult);
+#else
     bool result = (*gDvmInlineOpsTable[opIndex].func)(arg0, arg1, arg2, arg3,
         pResult);
+#endif /*WITH_TAINT_TRACKING*/
     TRACE_METHOD_EXIT(self, method);
     return result;
 }
diff --git a/vm/InlineNative.h b/vm/InlineNative.h
index 101ddd1..e939b6f 100644
--- a/vm/InlineNative.h
+++ b/vm/InlineNative.h
@@ -30,8 +30,13 @@ Method* dvmFindInlinableMethod(const char* classDescriptor,
 /*
  * Basic 4-argument inline operation handler.
  */
+#ifdef WITH_TAINT_TRACKING
+typedef bool (*InlineOp4Func)(u4 arg0, u4 arg1, u4 arg2, u4 arg3,
+    u4 arg0_taint, u4 arg1_taint, struct Taint* rtaint, JValue* pResult);
+#else
 typedef bool (*InlineOp4Func)(u4 arg0, u4 arg1, u4 arg2, u4 arg3,
     JValue* pResult);
+#endif /*WITH_TAINT_TRACKING*/
 
 /*
  * Table of inline operations.
@@ -104,17 +109,31 @@ extern const InlineOperation gDvmInlineOpsTable[];
  * Returns "true" if everything went normally, "false" if an exception
  * was thrown.
  */
+#ifdef WITH_TAINT_TRACKING
+INLINE bool dvmPerformInlineOp4Std(u4 arg0, u4 arg1, u4 arg2, u4 arg3,
+    u4 arg0_taint, u4 arg1_taint, struct Taint* rtaint, JValue* pResult, int opIndex)
+#else
 INLINE bool dvmPerformInlineOp4Std(u4 arg0, u4 arg1, u4 arg2, u4 arg3,
     JValue* pResult, int opIndex)
+#endif /*WITH_TAINT_TRACKING*/
 {
+#ifdef WITH_TAINT_TRACKING
+    return (*gDvmInlineOpsTable[opIndex].func)(arg0, arg1, arg2, arg3, arg0_taint, arg1_taint, rtaint, pResult);
+#else
     return (*gDvmInlineOpsTable[opIndex].func)(arg0, arg1, arg2, arg3, pResult);
+#endif /*WITH_TAINT_TRACKING*/
 }
 
 /*
  * Like the "std" version, but will emit profiling info.
  */
+#ifdef WITH_TAINT_TRACKING
+bool dvmPerformInlineOp4Dbg(u4 arg0, u4 arg1, u4 arg2, u4 arg3,
+    u4 arg0_taint, u4 arg1_taint, struct Taint* rtaint, JValue* pResult, int opIndex);
+#else
 bool dvmPerformInlineOp4Dbg(u4 arg0, u4 arg1, u4 arg2, u4 arg3,
     JValue* pResult, int opIndex);
+#endif /*WITH_TAINT_TRACKING*/
 
 /*
  * Return method & populate the table on first use.
@@ -124,70 +143,172 @@ extern "C" Method* dvmResolveInlineNative(int opIndex);
 /*
  * The actual inline native definitions.
  */
+#ifdef WITH_TAINT_TRACKING
 bool javaLangString_charAt(u4 arg0, u4 arg1, u4 arg2, u4 arg3,
-                           JValue* pResult);
+    u4 arg0_taint, u4 arg1_taint, struct Taint* rtaint, JValue* pResult);
+#else
+bool javaLangString_charAt(u4 arg0, u4 arg1, u4 arg2, u4 arg3,
+    JValue* pResult);
+#endif /*WITH_TAINT_TRACKING*/
 
+#ifdef WITH_TAINT_TRACKING
+bool javaLangString_compareTo(u4 arg0, u4 arg1, u4 arg2, u4 arg3,
+    u4 arg0_taint, u4 arg1_taint, struct Taint* rtaint, JValue* pResult);
+#else
 bool javaLangString_compareTo(u4 arg0, u4 arg1, u4 arg2, u4 arg3,
-                              JValue* pResult);
+    JValue* pResult);
+#endif /*WITH_TAINT_TRACKING*/
 
+#ifdef WITH_TAINT_TRACKING
+bool javaLangString_equals(u4 arg0, u4 arg1, u4 arg2, u4 arg3,
+    u4 arg0_taint, u4 arg1_taint, struct Taint* rtaint, JValue* pResult);
+#else
 bool javaLangString_equals(u4 arg0, u4 arg1, u4 arg2, u4 arg3,
-                           JValue* pResult);
+    JValue* pResult);
+#endif /*WITH_TAINT_TRACKING*/
 
+#ifdef WITH_TAINT_TRACKING
 bool javaLangString_length(u4 arg0, u4 arg1, u4 arg2, u4 arg3,
-                           JValue* pResult);
+    u4 arg0_taint, u4 arg1_taint, struct Taint* rtaint, JValue* pResult);
+#else
+bool javaLangString_length(u4 arg0, u4 arg1, u4 arg2, u4 arg3,
+    JValue* pResult);
+#endif /*WITH_TAINT_TRACKING*/
 
+#ifdef WITH_TAINT_TRACKING
+bool javaLangString_isEmpty(u4 arg0, u4 arg1, u4 arg2, u4 arg3,
+    u4 arg0_taint, u4 arg1_taint, struct Taint* rtaint, JValue* pResult);
+#else
 bool javaLangString_isEmpty(u4 arg0, u4 arg1, u4 arg2, u4 arg3,
-                            JValue* pResult);
+    JValue* pResult);
+#endif /*WITH_TAINT_TRACKING*/
 
+#ifdef WITH_TAINT_TRACKING
+bool javaLangString_fastIndexOf_II(u4 arg0, u4 arg1, u4 arg2, u4 arg3,
+    u4 arg0_taint, u4 arg1_taint, struct Taint* rtaint, JValue* pResult);
+#else
 bool javaLangString_fastIndexOf_II(u4 arg0, u4 arg1, u4 arg2, u4 arg3,
-                                   JValue* pResult);
+    JValue* pResult);
+#endif /*WITH_TAINT_TRACKING*/
 
+#ifdef WITH_TAINT_TRACKING
 bool javaLangMath_abs_int(u4 arg0, u4 arg1, u4 arg2, u4 arg3,
-                          JValue* pResult);
+    u4 arg0_taint, u4 arg1_taint, struct Taint* rtaint, JValue* pResult);
+#else
+bool javaLangMath_abs_int(u4 arg0, u4 arg1, u4 arg2, u4 arg3,
+    JValue* pResult);
+#endif /*WITH_TAINT_TRACKING*/
 
+#ifdef WITH_TAINT_TRACKING
+bool javaLangMath_abs_long(u4 arg0, u4 arg1, u4 arg2, u4 arg3,
+    u4 arg0_taint, u4 arg1_taint, struct Taint* rtaint, JValue* pResult);
+#else
 bool javaLangMath_abs_long(u4 arg0, u4 arg1, u4 arg2, u4 arg3,
-                           JValue* pResult);
+    JValue* pResult);
+#endif /*WITH_TAINT_TRACKING*/
 
+#ifdef WITH_TAINT_TRACKING
+bool javaLangMath_abs_float(u4 arg0, u4 arg1, u4 arg2, u4 arg3,
+    u4 arg0_taint, u4 arg1_taint, struct Taint* rtaint, JValue* pResult);
+#else
 bool javaLangMath_abs_float(u4 arg0, u4 arg1, u4 arg2, u4 arg3,
-                            JValue* pResult);
+    JValue* pResult);
+#endif /*WITH_TAINT_TRACKING*/
 
+#ifdef WITH_TAINT_TRACKING
 bool javaLangMath_abs_double(u4 arg0, u4 arg1, u4 arg2, u4 arg3,
-                             JValue* pResult);
+    u4 arg0_taint, u4 arg1_taint, struct Taint* rtaint, JValue* pResult);
+#else
+bool javaLangMath_abs_double(u4 arg0, u4 arg1, u4 arg2, u4 arg3,
+    JValue* pResult);
+#endif /*WITH_TAINT_TRACKING*/
 
+#ifdef WITH_TAINT_TRACKING
 bool javaLangMath_min_int(u4 arg0, u4 arg1, u4 arg2, u4 arg3,
-                          JValue* pResult);
+    u4 arg0_taint, u4 arg1_taint, struct Taint* rtaint, JValue* pResult);
+#else
+bool javaLangMath_min_int(u4 arg0, u4 arg1, u4 arg2, u4 arg3,
+    JValue* pResult);
+#endif /*WITH_TAINT_TRACKING*/
 
+#ifdef WITH_TAINT_TRACKING
+bool javaLangMath_max_int(u4 arg0, u4 arg1, u4 arg2, u4 arg3,
+    u4 arg0_taint, u4 arg1_taint, struct Taint* rtaint, JValue* pResult);
+#else
 bool javaLangMath_max_int(u4 arg0, u4 arg1, u4 arg2, u4 arg3,
-                          JValue* pResult);
+    JValue* pResult);
+#endif /*WITH_TAINT_TRACKING*/
 
+#ifdef WITH_TAINT_TRACKING
+bool javaLangMath_sqrt(u4 arg0, u4 arg1, u4 arg2, u4 arg3,
+    u4 arg0_taint, u4 arg1_taint, struct Taint* rtaint, JValue* pResult);
+#else
 bool javaLangMath_sqrt(u4 arg0, u4 arg1, u4 arg2, u4 arg3,
-                       JValue* pResult);
+    JValue* pResult);
+#endif /*WITH_TAINT_TRACKING*/
 
+#ifdef WITH_TAINT_TRACKING
 bool javaLangMath_cos(u4 arg0, u4 arg1, u4 arg2, u4 arg3,
-                      JValue* pResult);
+    u4 arg0_taint, u4 arg1_taint, struct Taint* rtaint, JValue* pResult);
+#else
+bool javaLangMath_cos(u4 arg0, u4 arg1, u4 arg2, u4 arg3,
+    JValue* pResult);
+#endif /*WITH_TAINT_TRACKING*/
 
+#ifdef WITH_TAINT_TRACKING
+bool javaLangMath_sin(u4 arg0, u4 arg1, u4 arg2, u4 arg3,
+    u4 arg0_taint, u4 arg1_taint, struct Taint* rtaint, JValue* pResult);
+#else
 bool javaLangMath_sin(u4 arg0, u4 arg1, u4 arg2, u4 arg3,
-                      JValue* pResult);
+    JValue* pResult);
+#endif /*WITH_TAINT_TRACKING*/
 
+#ifdef WITH_TAINT_TRACKING
+bool javaLangFloat_floatToIntBits(u4 arg0, u4 arg1, u4 arg2, u4 arg,
+    u4 arg0_taint, u4 arg1_taint, struct Taint* rtaint, JValue* pResult);
+#else
 bool javaLangFloat_floatToIntBits(u4 arg0, u4 arg1, u4 arg2, u4 arg,
-                                  JValue* pResult);
+    JValue* pResult);
+#endif /*WITH_TAINT_TRACKING*/
 
+#ifdef WITH_TAINT_TRACKING
 bool javaLangFloat_floatToRawIntBits(u4 arg0, u4 arg1, u4 arg2, u4 arg,
-                                     JValue* pResult);
+    u4 arg0_taint, u4 arg1_taint, struct Taint* rtaint, JValue* pResult);
+#else
+bool javaLangFloat_floatToRawIntBits(u4 arg0, u4 arg1, u4 arg2, u4 arg,
+    JValue* pResult);
+#endif /*WITH_TAINT_TRACKING*/
 
+#ifdef WITH_TAINT_TRACKING
+bool javaLangFloat_intBitsToFloat(u4 arg0, u4 arg1, u4 arg2, u4 arg,
+    u4 arg0_taint, u4 arg1_taint, struct Taint* rtaint, JValue* pResult);
+#else
 bool javaLangFloat_intBitsToFloat(u4 arg0, u4 arg1, u4 arg2, u4 arg,
-                                  JValue* pResult);
+    JValue* pResult);
+#endif /*WITH_TAINT_TRACKING*/
 
+#ifdef WITH_TAINT_TRACKING
+bool javaLangDouble_doubleToLongBits(u4 arg0, u4 arg1, u4 arg2, u4 arg,
+    u4 arg0_taint, u4 arg1_taint, struct Taint* rtaint, JValue* pResult);
+#else
 bool javaLangDouble_doubleToLongBits(u4 arg0, u4 arg1, u4 arg2, u4 arg,
-                                     JValue* pResult);
+    JValue* pResult);
+#endif /*WITH_TAINT_TRACKING*/
 
+#ifdef WITH_TAINT_TRACKING
 bool javaLangDouble_longBitsToDouble(u4 arg0, u4 arg1, u4 arg2, u4 arg,
-                                     JValue* pResult);
+    u4 arg0_taint, u4 arg1_taint, struct Taint* rtaint, JValue* pResult);
+#else
+bool javaLangDouble_longBitsToDouble(u4 arg0, u4 arg1, u4 arg2, u4 arg,
+    JValue* pResult);
+#endif /*WITH_TAINT_TRACKING*/
 
+#ifdef WITH_TAINT_TRACKING
 bool javaLangDouble_doubleToRawLongBits(u4 arg0, u4 arg1, u4 arg2,
-                                        u4 arg, JValue* pResult);
-
-bool javaLangDouble_longBitsToDouble(u4 arg0, u4 arg1, u4 arg2, u4 arg,
-                                     JValue* pResult);
+    u4 arg, u4 arg0_taint, u4 arg1_taint, struct Taint* rtaint, JValue* pResult);
+#else
+bool javaLangDouble_doubleToRawLongBits(u4 arg0, u4 arg1, u4 arg2,
+    u4 arg, JValue* pResult);
+#endif /*WITH_TAINT_TRACKING*/
 
 #endif  // DALVIK_INLINENATIVE_H_
diff --git a/vm/Jni.cpp b/vm/Jni.cpp
index 8593505..ab62e30 100644
--- a/vm/Jni.cpp
+++ b/vm/Jni.cpp
@@ -274,6 +274,10 @@ bool dvmJniStartup() {
 
     dvmInitMutex(&gDvm.jniPinRefLock);
 
+#ifdef WITH_TAINT_TRACKING
+    dvmTaintPropJniStartup();
+#endif
+
     return true;
 }
 
@@ -1088,6 +1092,20 @@ static inline void convertReferenceResult(JNIEnv* env, JValue* pResult,
  * General form, handles all cases.
  */
 void dvmCallJNIMethod(const u4* args, JValue* pResult, const Method* method, Thread* self) {
+#ifdef WITH_TAINT_TRACKING
+    // Copy the list of args in another array, to avoid any change in args which can cause the problem in taint propagation
+    u4 oldArgs[20];
+    int j = 0;
+    int nArgs = method->insSize * 2 + 1;
+    while (j < nArgs) {
+        oldArgs[j] = (u4) args[j];
+        j++;
+    }
+    while (j < 20) {
+        oldArgs[j] = 0;
+        j++;
+    }
+#endif
     u4* modArgs = (u4*) args;
     jclass staticMethodClass = NULL;
 
@@ -1159,6 +1177,10 @@ void dvmCallJNIMethod(const u4* args, JValue* pResult, const Method* method, Thr
 
     convertReferenceResult(env, pResult, method, self);
 
+#ifdef WITH_TAINT_TRACKING
+     dvmTaintPropJniMethod(oldArgs, pResult, method);
+#endif
+
     if (UNLIKELY(isSynchronized)) {
         dvmUnlockObject(self, lockObj);
     }
diff --git a/vm/Native.cpp b/vm/Native.cpp
index be719a7..db90383 100644
--- a/vm/Native.cpp
+++ b/vm/Native.cpp
@@ -329,6 +329,18 @@ bool dvmLoadNativeCode(const char* pathName, Object* classLoader,
     if (verbose)
         ALOGD("Trying to load lib %s %p", pathName, classLoader);
 
+#ifdef WITH_TAINT_TRACKING
+    // PJG: TODO: factor out this check
+    if (strncmp(pathName, "/system", sizeof("/system")-1) != 0 && strcmp(pathName, "libjavacore.so") !=0 && strcmp(pathName, "libnativehelper.so") !=0) {
+    	ALOGW("Denying lib %s (not \"/system\" prefix)\n", pathName);
+    	return false;
+    }
+    if (strstr(pathName, "/../") != NULL) {
+    	ALOGW("Denying lib %s (contains \"/../\")\n", pathName);
+    	return false;
+    }
+#endif
+
     *detail = NULL;
 
     /*
diff --git a/vm/Thread.h b/vm/Thread.h
index 7f14ce5..38c77ef 100644
--- a/vm/Thread.h
+++ b/vm/Thread.h
@@ -75,9 +75,15 @@ void dvmSlayDaemons(void);
 #define kInternalRefDefault     32      /* equally arbitrary */
 #define kInternalRefMax         4096    /* mainly a sanity check */
 
+#ifdef WITH_TAINT_TRACKING
+# define kMinStackSize       (1024 + STACK_OVERFLOW_RESERVE)
+# define kDefaultStackSize   (32*1024)    /* eight 4K pages */
+# define kMaxStackSize       (512*1024 + STACK_OVERFLOW_RESERVE)
+#else
 #define kMinStackSize       (512 + STACK_OVERFLOW_RESERVE)
 #define kDefaultStackSize   (16*1024)   /* four 4K pages */
 #define kMaxStackSize       (256*1024 + STACK_OVERFLOW_RESERVE)
+#endif
 
 /*
  * Interpreter control struction.  Packed into a long long to enable
diff --git a/vm/UtfString.h b/vm/UtfString.h
index 352948c..5ffab75 100644
--- a/vm/UtfString.h
+++ b/vm/UtfString.h
@@ -42,10 +42,17 @@
 # define STRING_FIELDOFF_COUNT      gDvm.offJavaLangString_count
 # define STRING_FIELDOFF_HASHCODE   gDvm.offJavaLangString_hashCode
 #else
+#ifdef WITH_TAINT_TRACKING
+# define STRING_FIELDOFF_VALUE      8
+# define STRING_FIELDOFF_HASHCODE   16
+# define STRING_FIELDOFF_OFFSET     24
+# define STRING_FIELDOFF_COUNT      32
+#else
 # define STRING_FIELDOFF_VALUE      8
 # define STRING_FIELDOFF_HASHCODE   12
 # define STRING_FIELDOFF_OFFSET     16
 # define STRING_FIELDOFF_COUNT      20
+#endif /* WITH_TAINT_TRACKING */
 #endif
 
 /*
diff --git a/vm/alloc/Copying.cpp b/vm/alloc/Copying.cpp
index ad5b8fc..31950ff 100644
--- a/vm/alloc/Copying.cpp
+++ b/vm/alloc/Copying.cpp
@@ -1637,7 +1637,11 @@ static void scavengeThreadStack(Thread *thread)
                 /*
                  * There are no roots to scavenge.  Skip over the entire frame.
                  */
+#ifdef WITH_TAINT_TRACKING
+            	framePtr += (method->registersSize)<<1;
+#else
                 framePtr += method->registersSize;
+#endif /*WITH_TAINT_TRACKING*/
             } else {
                 /*
                  * Precise scan.  v0 is at the lowest address on the
@@ -1687,6 +1691,10 @@ static void scavengeThreadStack(Thread *thread)
                         }
 #endif
                     }
+#ifdef WITH_TAINT_TRACKING
+                    /* taint tags are interleaved, jump over the tag */
+                    framePtr++;
+#endif
                     ++framePtr;
                 }
                 dvmReleaseRegisterMapLine(pMap, regVector);
@@ -1805,6 +1813,10 @@ static void pinThreadStack(const Thread *thread)
                     }
                     break;
                 }
+#ifdef WITH_TAINT_TRACKING
+                /* taint tags are interleaved, jump over the tag */
+                framePtr++;
+#endif
             }
         } else if (method != NULL && !dvmIsNativeMethod(method)) {
             const RegisterMap* pMap = dvmGetExpandedRegisterMap(method);
@@ -1821,7 +1833,11 @@ static void pinThreadStack(const Thread *thread)
                  * No register info for this frame, conservatively pin.
                  */
                 for (int i = 0; i < method->registersSize; ++i) {
+#ifdef WITH_TAINT_TRACKING
+                    u4 regValue = framePtr[i<<1];
+#else
                     u4 regValue = framePtr[i];
+#endif
                     if (regValue != 0 && (regValue & 0x3) == 0 && dvmIsValidObject((Object *)regValue)) {
                         pinObject((Object *)regValue);
                     }
diff --git a/vm/alloc/Visit.cpp b/vm/alloc/Visit.cpp
index 410b66e..0022c3d 100644
--- a/vm/alloc/Visit.cpp
+++ b/vm/alloc/Visit.cpp
@@ -107,9 +107,15 @@ static void visitThreadStack(RootVisitor *visitor, Thread *thread, void *arg)
                  * scan.
                  */
                 for (size_t i = 0; i < method->registersSize; ++i) {
+#ifdef WITH_TAINT_TRACKING
+                    if (dvmIsValidObject((Object *)fp[i<<1])) {
+			(*visitor)(&fp[i<<1], threadId, ROOT_JAVA_FRAME, arg);
+                    }
+#else
                     if (dvmIsValidObject((Object *)fp[i])) {
                         (*visitor)(&fp[i], threadId, ROOT_JAVA_FRAME, arg);
                     }
+#endif
                 }
             } else {
                 /*
@@ -142,7 +148,11 @@ static void visitThreadStack(RootVisitor *visitor, Thread *thread, void *arg)
                             continue;
                         }
 #endif
+#ifdef WITH_TAINT_TRACKING
+			(*visitor)(&fp[i<<1], threadId, ROOT_JAVA_FRAME, arg);
+#else
                         (*visitor)(&fp[i], threadId, ROOT_JAVA_FRAME, arg);
+#endif
                     }
                 }
                 dvmReleaseRegisterMapLine(pMap, regVector);
diff --git a/vm/compiler/codegen/CodegenFactory.cpp b/vm/compiler/codegen/CodegenFactory.cpp
index f42ae74..589299c 100644
--- a/vm/compiler/codegen/CodegenFactory.cpp
+++ b/vm/compiler/codegen/CodegenFactory.cpp
@@ -60,8 +60,14 @@ static void loadValueDirect(CompilationUnit *cUnit, RegLocation rlSrc,
         loadWordDisp(cUnit, rSELF, offsetof(Thread, interpSave.retval), reg1);
     } else {
         assert(rlSrc.location == kLocDalvikFrame);
+#ifdef WITH_TAINT_TRACKING
+        // interleaved taint tags
+        loadWordDisp(cUnit, rFP, dvmCompilerS2VReg(cUnit, rlSrc.sRegLow) << 3,
+                     reg1);
+#else
         loadWordDisp(cUnit, rFP, dvmCompilerS2VReg(cUnit, rlSrc.sRegLow) << 2,
                      reg1);
+#endif /*WITH_TAINT_TRACKING*/
     }
 }
 
@@ -95,9 +101,15 @@ static void loadValueDirectWide(CompilationUnit *cUnit, RegLocation rlSrc,
                          regLo, regHi, INVALID_SREG);
     } else {
         assert(rlSrc.location == kLocDalvikFrame);
+#ifdef WITH_TAINT_TRACKING
+        // interleaved taint tags
+        loadWordDisp(cUnit, rFP, dvmCompilerS2VReg(cUnit, rlSrc.sRegLow) << 3, regLo);
+        loadWordDisp(cUnit, rFP, (dvmCompilerS2VReg(cUnit, rlSrc.sRegLow) << 3) + 8, regHi);
+#else
             loadBaseDispWide(cUnit, NULL, rFP,
                              dvmCompilerS2VReg(cUnit, rlSrc.sRegLow) << 2,
                              regLo, regHi, INVALID_SREG);
+#endif /*WITH_TAINT_TRACKING*/
     }
 }
 
@@ -174,7 +186,11 @@ static void storeValue(CompilationUnit *cUnit, RegLocation rlDest,
         if (dvmCompilerLiveOut(cUnit, rlDest.sRegLow)) {
             defStart = (LIR *)cUnit->lastLIRInsn;
             int vReg = dvmCompilerS2VReg(cUnit, rlDest.sRegLow);
+#ifdef WITH_TAINT_TRACKING
+            storeBaseDisp(cUnit, rFP, vReg << 3, rlDest.lowReg, kWord);
+#else
             storeBaseDisp(cUnit, rFP, vReg << 2, rlDest.lowReg, kWord);
+#endif /*WITH_TAINT_TRACKING*/
             dvmCompilerMarkClean(cUnit, rlDest.lowReg);
             defEnd = (LIR *)cUnit->lastLIRInsn;
             dvmCompilerMarkDef(cUnit, rlDest, defStart, defEnd);
@@ -182,6 +198,56 @@ static void storeValue(CompilationUnit *cUnit, RegLocation rlDest,
     }
 }
 
+#ifdef WITH_TAINT_TRACKING
+static void storeTaintDirect(CompilationUnit *cUnit, RegLocation rlDest, int reg1)
+{
+    int vReg = dvmCompilerS2VReg(cUnit, rlDest.sRegLow);
+    storeBaseDisp(cUnit, rFP, (vReg << 3) + 4, reg1, kWord);
+}
+
+static void storeTaintDirectWide(CompilationUnit *cUnit, RegLocation rlDest, int reg1)
+{
+    int vReg = dvmCompilerS2VReg(cUnit, rlDest.sRegLow);
+    storeBaseDisp(cUnit, rFP, (vReg << 3) + 4, reg1, kWord);
+    storeBaseDisp(cUnit, rFP, (vReg << 3) + 12, reg1, kWord);
+}
+
+static void loadTaintDirect(CompilationUnit *cUnit, RegLocation rlSrc, int reg1)
+{
+    rlSrc = dvmCompilerUpdateLoc(cUnit, rlSrc);
+// PJG: this was incorrect
+//    assert(rlSrc.location == kLocDalvikFrame);
+    loadWordDisp(cUnit, rFP, (dvmCompilerS2VReg(cUnit, rlSrc.sRegLow) << 3) + 4, reg1);
+}
+
+static void loadTaintDirectWide(CompilationUnit *cUnit, RegLocation rlSrc, int reg1)
+{
+    rlSrc = dvmCompilerUpdateLocWide(cUnit, rlSrc);
+    loadWordDisp(cUnit, rFP, (dvmCompilerS2VReg(cUnit, rlSrc.sRegLow) << 3) + 4, reg1);
+}
+
+static void loadTaintDirectFixed(CompilationUnit *cUnit, RegLocation rlSrc, int reg1)
+{
+    dvmCompilerClobber(cUnit, reg1);
+    dvmCompilerMarkInUse(cUnit, reg1);
+    loadTaintDirect(cUnit, rlSrc, reg1);
+}
+
+static void setTaintClear(CompilationUnit *cUnit, RegLocation rlDest) {
+    int taintClear = dvmCompilerAllocTemp(cUnit);
+    loadConstant(cUnit, taintClear, TAINT_CLEAR);
+    storeTaintDirect(cUnit, rlDest, taintClear);
+    dvmCompilerFreeTemp(cUnit, taintClear);
+}
+
+static void setTaintClearWide(CompilationUnit *cUnit, RegLocation rlDest) {
+    int taintClear = dvmCompilerAllocTemp(cUnit);
+    loadConstant(cUnit, taintClear, TAINT_CLEAR);
+    storeTaintDirectWide(cUnit, rlDest, taintClear);
+    dvmCompilerFreeTemp(cUnit, taintClear);
+}
+#endif /*WITH_TAINT_TRACKING*/
+
 static RegLocation loadValueWide(CompilationUnit *cUnit, RegLocation rlSrc,
                                  RegisterClass opKind)
 {
@@ -257,8 +323,14 @@ static void storeValueWide(CompilationUnit *cUnit, RegLocation rlDest,
             int vReg = dvmCompilerS2VReg(cUnit, rlDest.sRegLow);
             assert((vReg+1) == dvmCompilerS2VReg(cUnit,
                                      dvmCompilerSRegHi(rlDest.sRegLow)));
+#ifdef WITH_TAINT_TRACKING
+            // interleaved taint tags
+            storeBaseDisp(cUnit, rFP, vReg << 3, rlDest.lowReg, kWord);
+            storeBaseDisp(cUnit, rFP, (vReg << 3) + 8, rlDest.highReg, kWord);
+#else
             storeBaseDispWide(cUnit, rFP, vReg << 2, rlDest.lowReg,
                               rlDest.highReg);
+#endif /*WITH_TAINT_TRACKING*/
             dvmCompilerMarkClean(cUnit, rlDest.lowReg);
             dvmCompilerMarkClean(cUnit, rlDest.highReg);
             defEnd = (LIR *)cUnit->lastLIRInsn;
diff --git a/vm/compiler/codegen/RallocUtil.cpp b/vm/compiler/codegen/RallocUtil.cpp
index f4a46f0..1b8baf2 100644
--- a/vm/compiler/codegen/RallocUtil.cpp
+++ b/vm/compiler/codegen/RallocUtil.cpp
@@ -115,9 +115,19 @@ void dvmCompilerFlushRegWide(CompilationUnit *cUnit, int reg1, int reg2)
         if (dvmCompilerS2VReg(cUnit, info2->sReg) <
             dvmCompilerS2VReg(cUnit, info1->sReg))
             info1 = info2;
+#ifdef WITH_TAINT_TRACKING
+        // interleaved taint tag
+        dvmCompilerFlushRegImpl(cUnit, rFP,
+                                dvmCompilerS2VReg(cUnit, info1->sReg) << 3,
+                                info1->reg, kWord);
+        dvmCompilerFlushRegImpl(cUnit, rFP,
+                                (dvmCompilerS2VReg(cUnit, info1->sReg) << 3) + 8,
+                                info1->partner, kWord);
+#else
         dvmCompilerFlushRegWideImpl(cUnit, rFP,
                                     dvmCompilerS2VReg(cUnit, info1->sReg) << 2,
                                     info1->reg, info1->partner);
+#endif /*WITH_TAINT_TRACKING*/
     }
 }
 
@@ -126,9 +136,16 @@ void dvmCompilerFlushReg(CompilationUnit *cUnit, int reg)
     RegisterInfo *info = getRegInfo(cUnit, reg);
     if (info->live && info->dirty) {
         info->dirty = false;
+#ifdef WITH_TAINT_TRACKING
+        // interleaved taint tag
+        dvmCompilerFlushRegImpl(cUnit, rFP,
+                                dvmCompilerS2VReg(cUnit, info->sReg) << 3,
+                                reg, kWord);
+#else
         dvmCompilerFlushRegImpl(cUnit, rFP,
                                 dvmCompilerS2VReg(cUnit, info->sReg) << 2,
                                 reg, kWord);
+#endif /*WITH_TAINT_TRACKING*/
     }
 }
 
diff --git a/vm/compiler/codegen/arm/CodegenDriver.cpp b/vm/compiler/codegen/arm/CodegenDriver.cpp
index d7017b0..e3e350b 100644
--- a/vm/compiler/codegen/arm/CodegenDriver.cpp
+++ b/vm/compiler/codegen/arm/CodegenDriver.cpp
@@ -24,6 +24,10 @@
  * applicable directory below this one.
  */
 
+#ifdef WITH_TAINT_TRACKING
+#include "interp/Taint.h"
+#endif /*WITH_TAINT_TRACKING*/
+
 /*
  * Mark garbage collection card. Skip if the value we're storing is null.
  */
@@ -304,6 +308,11 @@ static void genIGetWide(CompilationUnit *cUnit, MIR *mir, int fieldOffset)
     RegLocation rlDest = dvmCompilerGetDestWide(cUnit, mir, 0, 1);
     RegLocation rlResult;
     rlObj = loadValue(cUnit, rlObj, kCoreReg);
+#ifdef WITH_TAINT_TRACKING
+    int fieldTaint = dvmCompilerAllocTemp(cUnit);
+    int objTaint = dvmCompilerAllocTemp(cUnit);
+    loadTaintDirect(cUnit, rlObj, objTaint);
+#endif /*WITH_TAINT_TRACKING*/
     int regPtr = dvmCompilerAllocTemp(cUnit);
 
     assert(rlDest.wide);
@@ -315,10 +324,19 @@ static void genIGetWide(CompilationUnit *cUnit, MIR *mir, int fieldOffset)
 
     HEAP_ACCESS_SHADOW(true);
     loadPair(cUnit, regPtr, rlResult.lowReg, rlResult.highReg);
+#ifdef WITH_TAINT_TRACKING
+    loadWordDisp(cUnit, regPtr, 8, fieldTaint);
+    opRegRegReg(cUnit, kOpOr, fieldTaint, objTaint, fieldTaint);
+    dvmCompilerFreeTemp(cUnit, objTaint);
+#endif /*WITH_TAINT_TRACKING*/
     HEAP_ACCESS_SHADOW(false);
 
     dvmCompilerFreeTemp(cUnit, regPtr);
     storeValueWide(cUnit, rlDest, rlResult);
+#ifdef WITH_TAINT_TRACKING
+    storeTaintDirectWide(cUnit, rlDest, fieldTaint);
+    dvmCompilerFreeTemp(cUnit, fieldTaint);
+#endif /*WITH_TAINT_TRACKING*/
 }
 
 /* Store a wide field to an object instance */
@@ -327,6 +345,10 @@ static void genIPutWide(CompilationUnit *cUnit, MIR *mir, int fieldOffset)
     RegLocation rlSrc = dvmCompilerGetSrcWide(cUnit, mir, 0, 1);
     RegLocation rlObj = dvmCompilerGetSrc(cUnit, mir, 2);
     rlObj = loadValue(cUnit, rlObj, kCoreReg);
+#ifdef WITH_TAINT_TRACKING
+    int taint = dvmCompilerAllocTemp(cUnit);
+    loadTaintDirectWide(cUnit, rlSrc, taint);
+#endif /*WITH_TAINT_TRACKING*/
     int regPtr;
     rlSrc = loadValueWide(cUnit, rlSrc, kAnyReg);
     genNullCheck(cUnit, rlObj.sRegLow, rlObj.lowReg, mir->offset,
@@ -336,6 +358,10 @@ static void genIPutWide(CompilationUnit *cUnit, MIR *mir, int fieldOffset)
 
     HEAP_ACCESS_SHADOW(true);
     storePair(cUnit, regPtr, rlSrc.lowReg, rlSrc.highReg);
+#ifdef WITH_TAINT_TRACKING
+    storeWordDisp(cUnit, regPtr, 8, taint);
+    dvmCompilerFreeTemp(cUnit, taint);
+#endif /*WITH_TAINT_TRACKING*/
     HEAP_ACCESS_SHADOW(false);
 
     dvmCompilerFreeTemp(cUnit, regPtr);
@@ -357,15 +383,31 @@ static void genIGet(CompilationUnit *cUnit, MIR *mir, OpSize size,
     genNullCheck(cUnit, rlObj.sRegLow, rlObj.lowReg, mir->offset,
                  NULL);/* null object? */
 
+#ifdef WITH_TAINT_TRACKING
+    int fieldTaint = dvmCompilerAllocTemp(cUnit);
+    int objTaint = dvmCompilerAllocTemp(cUnit);
+    loadTaintDirect(cUnit, rlObj, objTaint);
+    opRegRegImm(cUnit, kOpAdd, fieldTaint, rlObj.lowReg, fieldOffset);
+#endif /*WITH_TAINT_TRACKING*/
+
     HEAP_ACCESS_SHADOW(true);
     loadBaseDisp(cUnit, mir, rlObj.lowReg, fieldOffset, rlResult.lowReg,
                  size, rlObj.sRegLow);
+#ifdef WITH_TAINT_TRACKING
+    loadWordDisp(cUnit, fieldTaint, 4, fieldTaint);
+    opRegRegReg(cUnit, kOpOr, fieldTaint, objTaint, fieldTaint);
+    dvmCompilerFreeTemp(cUnit, objTaint);
+#endif /*WITH_TAINT_TRACKING*/
     HEAP_ACCESS_SHADOW(false);
     if (isVolatile) {
         dvmCompilerGenMemBarrier(cUnit, kSY);
     }
 
     storeValue(cUnit, rlDest, rlResult);
+#ifdef WITH_TAINT_TRACKING
+    storeTaintDirect(cUnit, rlDest, fieldTaint);
+    dvmCompilerFreeTemp(cUnit, fieldTaint);
+#endif /*WITH_TAINT_TRACKING*/
 }
 
 /*
@@ -383,11 +425,20 @@ static void genIPut(CompilationUnit *cUnit, MIR *mir, OpSize size,
     genNullCheck(cUnit, rlObj.sRegLow, rlObj.lowReg, mir->offset,
                  NULL);/* null object? */
 
+#ifdef WITH_TAINT_TRACKING
+    int taint = dvmCompilerAllocTemp(cUnit);
+    loadTaintDirect(cUnit, rlSrc, taint);
+#endif /*WITH_TAINT_TRACKING*/
+
     if (isVolatile) {
         dvmCompilerGenMemBarrier(cUnit, kST);
     }
     HEAP_ACCESS_SHADOW(true);
     storeBaseDisp(cUnit, rlObj.lowReg, fieldOffset, rlSrc.lowReg, size);
+#ifdef WITH_TAINT_TRACKING
+    storeWordDisp(cUnit, rlObj.lowReg, fieldOffset+4, taint);
+    dvmCompilerFreeTemp(cUnit, taint);
+#endif /*WITH_TAINT_TRACKING*/
     HEAP_ACCESS_SHADOW(false);
     if (isVolatile) {
         dvmCompilerGenMemBarrier(cUnit, kSY);
@@ -409,6 +460,11 @@ static void genArrayGet(CompilationUnit *cUnit, MIR *mir, OpSize size,
     RegisterClass regClass = dvmCompilerRegClassBySize(size);
     int lenOffset = OFFSETOF_MEMBER(ArrayObject, length);
     int dataOffset = OFFSETOF_MEMBER(ArrayObject, contents);
+#ifdef WITH_TAINT_TRACKING
+    int indexTaint = dvmCompilerAllocTemp(cUnit);
+    loadTaintDirect(cUnit, rlIndex, indexTaint);
+    int taintOffset = OFFSETOF_MEMBER(ArrayObject, taint);
+#endif /*WITH_TAINT_TRACKING*/
     RegLocation rlResult;
     rlArray = loadValue(cUnit, rlArray, kCoreReg);
     rlIndex = loadValue(cUnit, rlIndex, kCoreReg);
@@ -422,6 +478,13 @@ static void genArrayGet(CompilationUnit *cUnit, MIR *mir, OpSize size,
                                 rlArray.lowReg, mir->offset, NULL);
     }
 
+#ifdef WITH_TAINT_TRACKING
+    int arrayTaint = dvmCompilerAllocTemp(cUnit);
+    loadWordDisp(cUnit, rlArray.lowReg, taintOffset, arrayTaint);
+    opRegRegReg(cUnit, kOpOr, indexTaint, indexTaint, arrayTaint);
+    dvmCompilerFreeTemp(cUnit, arrayTaint);
+#endif /*WITH_TAINT_TRACKING*/
+
     regPtr = dvmCompilerAllocTemp(cUnit);
 
     if (!(mir->OptimizationFlags & MIR_IGNORE_RANGE_CHECK)) {
@@ -454,6 +517,10 @@ static void genArrayGet(CompilationUnit *cUnit, MIR *mir, OpSize size,
 
         dvmCompilerFreeTemp(cUnit, regPtr);
         storeValueWide(cUnit, rlDest, rlResult);
+#ifdef WITH_TAINT_TRACKING
+        storeTaintDirectWide(cUnit, rlDest, indexTaint);
+        dvmCompilerFreeTemp(cUnit, indexTaint);
+#endif /*WITH_TAINT_TRACKING*/
     } else {
         rlResult = dvmCompilerEvalLoc(cUnit, rlDest, regClass, true);
 
@@ -464,6 +531,10 @@ static void genArrayGet(CompilationUnit *cUnit, MIR *mir, OpSize size,
 
         dvmCompilerFreeTemp(cUnit, regPtr);
         storeValue(cUnit, rlDest, rlResult);
+#ifdef WITH_TAINT_TRACKING
+        storeTaintDirect(cUnit, rlDest, indexTaint);
+        dvmCompilerFreeTemp(cUnit, indexTaint);
+#endif /*WITH_TAINT_TRACKING*/
     }
 }
 
@@ -478,6 +549,11 @@ static void genArrayPut(CompilationUnit *cUnit, MIR *mir, OpSize size,
     RegisterClass regClass = dvmCompilerRegClassBySize(size);
     int lenOffset = OFFSETOF_MEMBER(ArrayObject, length);
     int dataOffset = OFFSETOF_MEMBER(ArrayObject, contents);
+#ifdef WITH_TAINT_TRACKING
+    int argTaint = dvmCompilerAllocTemp(cUnit);
+    loadTaintDirect(cUnit, rlArray, argTaint);
+    int taintOffset = OFFSETOF_MEMBER(ArrayObject, taint);
+#endif /*WITH_TAINT_TRACKING*/
 
     int regPtr;
     rlArray = loadValue(cUnit, rlArray, kCoreReg);
@@ -499,6 +575,15 @@ static void genArrayPut(CompilationUnit *cUnit, MIR *mir, OpSize size,
                                 mir->offset, NULL);
     }
 
+#ifdef WITH_TAINT_TRACKING
+    int arrayTaint = dvmCompilerAllocTemp(cUnit);
+    loadWordDisp(cUnit, rlArray.lowReg, taintOffset, arrayTaint);
+    opRegRegReg(cUnit, kOpOr, argTaint, argTaint, arrayTaint);
+    storeWordDisp(cUnit, rlArray.lowReg, taintOffset, argTaint);
+    dvmCompilerFreeTemp(cUnit, arrayTaint);
+    dvmCompilerFreeTemp(cUnit, argTaint);
+#endif /*WITH_TAINT_TRACKING*/
+
     if (!(mir->OptimizationFlags & MIR_IGNORE_RANGE_CHECK)) {
         int regLen = dvmCompilerAllocTemp(cUnit);
         //NOTE: max live temps(4) here.
@@ -571,6 +656,21 @@ static void genArrayObjectPut(CompilationUnit *cUnit, MIR *mir,
                                 mir->offset, NULL);
     }
 
+#ifdef WITH_TAINT_TRACKING
+    int argTaint = dvmCompilerAllocTemp(cUnit);
+    int arrayTaint = dvmCompilerAllocTemp(cUnit);
+
+    int taintOffset = OFFSETOF_MEMBER(ArrayObject, taint);
+
+    loadTaintDirect(cUnit, rlArray, argTaint);
+    loadWordDisp(cUnit, regArray, taintOffset, arrayTaint);
+    opRegRegReg(cUnit, kOpOr, argTaint, argTaint, arrayTaint);
+    storeWordDisp(cUnit, regArray, taintOffset, argTaint);
+
+    dvmCompilerFreeTemp(cUnit, argTaint);
+    dvmCompilerFreeTemp(cUnit, arrayTaint);
+#endif /*WITH_TAINT_TRACKING*/
+
     if (!(mir->OptimizationFlags & MIR_IGNORE_RANGE_CHECK)) {
         /* Get len */
         loadWordDisp(cUnit, regArray, lenOffset, regLen);
@@ -659,6 +759,16 @@ static bool genShiftOpLong(CompilationUnit *cUnit, MIR *mir,
     }
     rlResult = dvmCompilerGetReturnWide(cUnit);
     storeValueWide(cUnit, rlDest, rlResult);
+#ifdef WITH_TAINT_TRACKING
+    int taint1 = dvmCompilerAllocTemp(cUnit);
+    int taint2 = dvmCompilerAllocTemp(cUnit);
+    loadTaintDirectWide(cUnit, rlSrc1, taint1);
+    loadTaintDirect(cUnit, rlShift, taint2);
+    opRegRegReg(cUnit, kOpOr, taint1, taint1, taint2);
+    storeTaintDirectWide(cUnit, rlDest, taint1);
+    dvmCompilerFreeTemp(cUnit, taint1);
+    dvmCompilerFreeTemp(cUnit, taint2);
+#endif /*WITH_TAINT_TRACKING*/
     return false;
 }
 
@@ -674,14 +784,21 @@ static bool genArithOpLong(CompilationUnit *cUnit, MIR *mir,
     int retReg = r0;
 
     switch (mir->dalvikInsn.opcode) {
-        case OP_NOT_LONG:
+        case OP_NOT_LONG: {
             rlSrc2 = loadValueWide(cUnit, rlSrc2, kCoreReg);
             rlResult = dvmCompilerEvalLoc(cUnit, rlDest, kCoreReg, true);
             opRegReg(cUnit, kOpMvn, rlResult.lowReg, rlSrc2.lowReg);
             opRegReg(cUnit, kOpMvn, rlResult.highReg, rlSrc2.highReg);
             storeValueWide(cUnit, rlDest, rlResult);
+#ifdef WITH_TAINT_TRACKING
+    	    int taint = dvmCompilerAllocTemp(cUnit);
+            loadTaintDirectWide(cUnit, rlSrc2, taint);
+            storeTaintDirectWide(cUnit, rlDest, taint);
+            dvmCompilerFreeTemp(cUnit, taint);
+#endif /*WITH_TAINT_TRACKING*/
             return false;
             break;
+        }
         case OP_ADD_LONG:
         case OP_ADD_LONG_2ADDR:
             firstOp = kOpAdd;
@@ -693,9 +810,20 @@ static bool genArithOpLong(CompilationUnit *cUnit, MIR *mir,
             secondOp = kOpSbc;
             break;
         case OP_MUL_LONG:
-        case OP_MUL_LONG_2ADDR:
+        case OP_MUL_LONG_2ADDR: {
             genMulLong(cUnit, rlDest, rlSrc1, rlSrc2);
+#ifdef WITH_TAINT_TRACKING
+     	    int taint1 = dvmCompilerAllocTemp(cUnit);
+     	    int taint2 = dvmCompilerAllocTemp(cUnit);
+            loadTaintDirectWide(cUnit, rlSrc1, taint1);
+            loadTaintDirectWide(cUnit, rlSrc2, taint2);
+            opRegRegReg(cUnit, kOpOr, taint1, taint1, taint2);
+            storeTaintDirectWide(cUnit, rlDest, taint1);
+            dvmCompilerFreeTemp(cUnit, taint1);
+            dvmCompilerFreeTemp(cUnit, taint2);
+#endif /*WITH_TAINT_TRACKING*/
             return false;
+        }
         case OP_DIV_LONG:
         case OP_DIV_LONG_2ADDR:
             callOut = true;
@@ -735,6 +863,12 @@ static bool genArithOpLong(CompilationUnit *cUnit, MIR *mir,
             opRegReg(cUnit, kOpSbc, tReg, rlSrc2.highReg);
             genRegCopy(cUnit, rlResult.highReg, tReg);
             storeValueWide(cUnit, rlDest, rlResult);
+#ifdef WITH_TAINT_TRACKING
+    	    int taint = dvmCompilerAllocTemp(cUnit);
+            loadTaintDirectWide(cUnit, rlSrc2, taint);
+            storeTaintDirectWide(cUnit, rlDest, taint);
+            dvmCompilerFreeTemp(cUnit, taint);
+#endif /*WITH_TAINT_TRACKING*/
             return false;
         }
         default:
@@ -743,6 +877,17 @@ static bool genArithOpLong(CompilationUnit *cUnit, MIR *mir,
     }
     if (!callOut) {
         genLong3Addr(cUnit, mir, firstOp, secondOp, rlDest, rlSrc1, rlSrc2);
+#ifdef WITH_TAINT_TRACKING
+        // taint(dest) <- taint(src1) | taint(src2)
+    	int taint1 = dvmCompilerAllocTemp(cUnit);
+    	int taint2 = dvmCompilerAllocTemp(cUnit);
+        loadTaintDirectWide(cUnit, rlSrc1, taint1);
+        loadTaintDirectWide(cUnit, rlSrc2, taint2);
+        opRegRegReg(cUnit, kOpOr, taint1, taint1, taint2);
+        storeTaintDirectWide(cUnit, rlDest, taint1);
+        dvmCompilerFreeTemp(cUnit, taint1);
+        dvmCompilerFreeTemp(cUnit, taint2);
+#endif /*WITH_TAINT_TRACKING*/
     } else {
         // Adjust return regs in to handle case of rem returning r2/r3
         dvmCompilerFlushAllRegs(cUnit);   /* Send everything to home location */
@@ -756,6 +901,17 @@ static bool genArithOpLong(CompilationUnit *cUnit, MIR *mir,
         else
             rlResult = dvmCompilerGetReturnWideAlt(cUnit);
         storeValueWide(cUnit, rlDest, rlResult);
+#ifdef WITH_TAINT_TRACKING
+        // taint(dest) <- taint(src1) | taint(src2)
+    	int taint1 = dvmCompilerAllocTemp(cUnit);
+    	int taint2 = dvmCompilerAllocTemp(cUnit);
+        loadTaintDirectWide(cUnit, rlSrc1, taint1);
+        loadTaintDirectWide(cUnit, rlSrc2, taint2);
+        opRegRegReg(cUnit, kOpOr, taint1, taint1, taint2);
+        storeTaintDirectWide(cUnit, rlDest, taint1);
+        dvmCompilerFreeTemp(cUnit, taint1);
+        dvmCompilerFreeTemp(cUnit, taint2);
+#endif /*WITH_TAINT_TRACKING*/
 #if defined(WITH_SELF_VERIFICATION)
         cUnit->usesLinkRegister = true;
 #endif
@@ -845,11 +1001,17 @@ static bool genArithOpInt(CompilationUnit *cUnit, MIR *mir,
             dvmCompilerAbort(cUnit);
     }
     if (!callOut) {
+#ifdef WITH_TAINT_TRACKING
+    	int taint = dvmCompilerAllocTemp(cUnit);
+#endif /*WITH_TAINT_TRACKING*/
         rlSrc1 = loadValue(cUnit, rlSrc1, kCoreReg);
         if (unary) {
             rlResult = dvmCompilerEvalLoc(cUnit, rlDest, kCoreReg, true);
             opRegReg(cUnit, op, rlResult.lowReg,
                      rlSrc1.lowReg);
+#ifdef WITH_TAINT_TRACKING
+            loadTaintDirect(cUnit, rlSrc1, taint);
+#endif /*WITH_TAINT_TRACKING*/
         } else {
             rlSrc2 = loadValue(cUnit, rlSrc2, kCoreReg);
             if (shiftOp) {
@@ -864,8 +1026,19 @@ static bool genArithOpInt(CompilationUnit *cUnit, MIR *mir,
                 opRegRegReg(cUnit, op, rlResult.lowReg,
                             rlSrc1.lowReg, rlSrc2.lowReg);
             }
+#ifdef WITH_TAINT_TRACKING
+	    int taint2 = dvmCompilerAllocTemp(cUnit);
+	    loadTaintDirect(cUnit, rlSrc1, taint);
+	    loadTaintDirect(cUnit, rlSrc2, taint2);
+	    opRegRegReg(cUnit, kOpOr, taint, taint, taint2);
+            dvmCompilerFreeTemp(cUnit, taint2);
+#endif /*WITH_TAINT_TRACKING*/
         }
         storeValue(cUnit, rlDest, rlResult);
+#ifdef WITH_TAINT_TRACKING
+        storeTaintDirect(cUnit, rlDest, taint);
+        dvmCompilerFreeTemp(cUnit, taint);
+#endif /*WITH_TAINT_TRACKING*/
     } else {
         RegLocation rlResult;
         dvmCompilerFlushAllRegs(cUnit);   /* Send everything to home location */
@@ -882,6 +1055,16 @@ static bool genArithOpInt(CompilationUnit *cUnit, MIR *mir,
         else
             rlResult = dvmCompilerGetReturnAlt(cUnit);
         storeValue(cUnit, rlDest, rlResult);
+#ifdef WITH_TAINT_TRACKING
+    	int taint1 = dvmCompilerAllocTemp(cUnit);
+    	int taint2 = dvmCompilerAllocTemp(cUnit);
+        loadTaintDirect(cUnit, rlSrc1, taint1);
+        loadTaintDirect(cUnit, rlSrc2, taint2);
+        opRegRegReg(cUnit, kOpOr, taint1, taint1, taint2);
+        storeTaintDirect(cUnit, rlDest, taint1);
+        dvmCompilerFreeTemp(cUnit, taint1);
+        dvmCompilerFreeTemp(cUnit, taint2);
+#endif /*WITH_TAINT_TRACKING*/
     }
     return false;
 }
@@ -930,16 +1113,72 @@ static bool genArithOp(CompilationUnit *cUnit, MIR *mir)
         return genArithOpInt(cUnit,mir, rlDest, rlSrc1, rlSrc2);
     }
     if ((opcode >= OP_ADD_FLOAT_2ADDR) && (opcode <= OP_REM_FLOAT_2ADDR)) {
+#ifdef WITH_TAINT_TRACKING
+    	bool success;
+    	success = genArithOpFloat(cUnit,mir, rlDest, rlSrc1, rlSrc2);
+    	int taint1 = dvmCompilerAllocTemp(cUnit);
+    	int taint2 = dvmCompilerAllocTemp(cUnit);
+    	loadTaintDirect(cUnit, rlSrc1, taint1);
+    	loadTaintDirect(cUnit, rlSrc2, taint2);
+    	opRegRegReg(cUnit, kOpOr, taint1, taint1, taint2);
+    	storeTaintDirect(cUnit, rlDest, taint1);
+        dvmCompilerFreeTemp(cUnit, taint1);
+        dvmCompilerFreeTemp(cUnit, taint2);
+    	return success;
+#else
         return genArithOpFloat(cUnit,mir, rlDest, rlSrc1, rlSrc2);
+#endif /*WITH_TAINT_TRACKING*/
     }
     if ((opcode >= OP_ADD_FLOAT) && (opcode <= OP_REM_FLOAT)) {
+#ifdef WITH_TAINT_TRACKING
+    	bool success;
+    	success = genArithOpFloat(cUnit,mir, rlDest, rlSrc1, rlSrc2);
+    	int taint1 = dvmCompilerAllocTemp(cUnit);
+    	int taint2 = dvmCompilerAllocTemp(cUnit);
+        loadTaintDirect(cUnit, rlSrc1, taint1);
+        loadTaintDirect(cUnit, rlSrc2, taint2);
+        opRegRegReg(cUnit, kOpOr, taint1, taint1, taint2);
+        storeTaintDirect(cUnit, rlDest, taint1);
+        dvmCompilerFreeTemp(cUnit, taint1);
+        dvmCompilerFreeTemp(cUnit, taint2);
+        return success;
+#else
         return genArithOpFloat(cUnit, mir, rlDest, rlSrc1, rlSrc2);
+#endif /*WITH_TAINT_TRACKING*/
     }
     if ((opcode >= OP_ADD_DOUBLE_2ADDR) && (opcode <= OP_REM_DOUBLE_2ADDR)) {
+#ifdef WITH_TAINT_TRACKING
+    	bool success;
+    	success = genArithOpDouble(cUnit,mir, rlDest, rlSrc1, rlSrc2);
+    	int taint1 = dvmCompilerAllocTemp(cUnit);
+    	int taint2 = dvmCompilerAllocTemp(cUnit);
+    	loadTaintDirectWide(cUnit, rlSrc1, taint1);
+    	loadTaintDirectWide(cUnit, rlSrc2, taint2);
+    	opRegRegReg(cUnit, kOpOr, taint1, taint1, taint2);
+    	storeTaintDirectWide(cUnit, rlDest, taint1);
+        dvmCompilerFreeTemp(cUnit, taint1);
+        dvmCompilerFreeTemp(cUnit, taint2);
+    	return success;
+#else
         return genArithOpDouble(cUnit,mir, rlDest, rlSrc1, rlSrc2);
+#endif /*WITH_TAINT_TRACKING*/
     }
     if ((opcode >= OP_ADD_DOUBLE) && (opcode <= OP_REM_DOUBLE)) {
+#ifdef WITH_TAINT_TRACKING
+    	bool success;
+    	success = genArithOpDouble(cUnit,mir, rlDest, rlSrc1, rlSrc2);
+    	int taint1 = dvmCompilerAllocTemp(cUnit);
+    	int taint2 = dvmCompilerAllocTemp(cUnit);
+    	loadTaintDirectWide(cUnit, rlSrc1, taint1);
+    	loadTaintDirectWide(cUnit, rlSrc2, taint2);
+        opRegRegReg(cUnit, kOpOr, taint1, taint1, taint2);
+        storeTaintDirectWide(cUnit, rlDest, taint1);
+        dvmCompilerFreeTemp(cUnit, taint1);
+        dvmCompilerFreeTemp(cUnit, taint2);        
+        return success;
+#else
         return genArithOpDouble(cUnit,mir, rlDest, rlSrc1, rlSrc2);
+#endif /*WITH_TAINT_TRACKING*/
     }
     return true;
 }
@@ -974,10 +1213,94 @@ static void genReturnCommon(CompilationUnit *cUnit, MIR *mir)
     branch->generic.target = (LIR *) pcrLabel;
 }
 
+#ifdef WITH_TAINT_TRACKING
+static int genProcessArgsNoRange(CompilationUnit *cUnit, MIR *mir,
+                                  DecodedInstruction *dInsn,
+				  bool isNative, ArmLIR **pcrLabel)
+#else
 static void genProcessArgsNoRange(CompilationUnit *cUnit, MIR *mir,
                                   DecodedInstruction *dInsn,
                                   ArmLIR **pcrLabel)
+#endif /*WITH_TAINT_TRACKING*/
 {
+#ifdef WITH_TAINT_TRACKING
+    unsigned int i;
+    RegLocation rlArg;
+
+    unsigned int numArgs = dInsn->vA;
+    dvmCompilerLockAllTemps(cUnit);
+
+    // save numArgs to StackSaveArea
+    opRegRegImm(cUnit, kOpSub, r7, r5FP, sizeof(StackSaveArea));
+    loadConstant(cUnit, r9, numArgs);
+    storeWordDisp(cUnit, r7, offsetof(StackSaveArea, argCount), r9);
+
+    if (isNative) {
+        // clear native taint hack
+        opRegRegImm(cUnit, kOpSub, r7, r5FP,
+	            sizeof(StackSaveArea) + (numArgs << 2) + 4);
+        loadConstant(cUnit, r9, 0);
+        storeWordDisp(cUnit, r7, 0, r9);
+
+        if (numArgs > 0) {
+            /* Up to 5 args are pushed on top of FP - sizeofStackSaveArea */
+            opRegRegImm(cUnit, kOpSub, r7, r5FP,
+                        sizeof(StackSaveArea) + (numArgs << 3) + 4);
+
+            // r0 <- this
+            rlArg = dvmCompilerGetSrc(cUnit, mir, 0);
+            loadValueDirectFixed(cUnit, rlArg, 0);
+
+            /* generate null check */
+            if (pcrLabel) {
+                *pcrLabel = genNullCheck(cUnit, dvmCompilerSSASrc(mir, 0), r0,
+                                mir->offset, NULL);
+            }
+
+            for (i = 0; i < numArgs; i++) {
+                rlArg = dvmCompilerGetSrc(cUnit, mir, i);
+                loadValueDirectFixed(cUnit, rlArg, 1);
+                loadTaintDirectFixed(cUnit, rlArg, 2);
+
+                storeWordDisp(cUnit, r7, i<<2, 1);
+                storeWordDisp(cUnit, r7, (i<<2)+(numArgs<<2)+4, 2);
+            }
+        }
+    }
+    else {
+        // clear native taint hack
+        opRegRegImm(cUnit, kOpSub, r7, r5FP, sizeof(StackSaveArea) + 4);
+        loadConstant(cUnit, r9, 0);
+        storeWordDisp(cUnit, r7, 0, r9);
+
+        if (numArgs > 0) {
+            /* Up to 5 args are pushed on top of FP - sizeofStackSaveArea */
+            opRegRegImm(cUnit, kOpSub, r7, r5FP,
+            sizeof(StackSaveArea) + (numArgs << 3) + 4);
+
+            // r0 <- this
+            rlArg = dvmCompilerGetSrc(cUnit, mir, 0);
+            loadValueDirectFixed(cUnit, rlArg, 0);
+
+            /* generate null check */
+            if (pcrLabel) {
+                *pcrLabel = genNullCheck(cUnit, dvmCompilerSSASrc(mir, 0), r0,
+                                         mir->offset, NULL);
+            }
+
+            for (i = 0; i < numArgs; i++) {
+                rlArg = dvmCompilerGetSrc(cUnit, mir, i);
+                loadValueDirectFixed(cUnit, rlArg, 1);
+                loadTaintDirectFixed(cUnit, rlArg, 2);
+
+                storeWordDisp(cUnit, r7, i<<3, 1);
+                storeWordDisp(cUnit, r7, (i<<3) + 4, 2);
+            }
+        }
+    }
+
+    return numArgs;
+#else
     unsigned int i;
     unsigned int regMask = 0;
     RegLocation rlArg;
@@ -1005,12 +1328,111 @@ static void genProcessArgsNoRange(CompilationUnit *cUnit, MIR *mir,
         }
         storeMultiple(cUnit, r7, regMask);
     }
+#endif /*WITH_TAINT_TRACKING*/
 }
 
+#ifdef WITH_TAINT_TRACKING
+static int genProcessArgsRange(CompilationUnit *cUnit, MIR *mir,
+                                DecodedInstruction *dInsn,
+                                bool isNative, ArmLIR **pcrLabel)
+#else
 static void genProcessArgsRange(CompilationUnit *cUnit, MIR *mir,
                                 DecodedInstruction *dInsn,
                                 ArmLIR **pcrLabel)
+#endif /*WITH_TAINT_TRACKING*/
 {
+#ifdef WITH_TAINT_TRACKING
+    int srcOffset = dInsn->vC << 3;
+    int numArgs = dInsn->vA;
+    int regMask;
+
+    /*
+     * Note: here, all promoted registers will have been flushed
+     * back to the Dalvik base locations, so register usage restrictins
+     * are lifted.  All parms loaded from original Dalvik register
+     * region - even though some might conceivably have valid copies
+     * cached in a preserved register.
+     */
+    dvmCompilerLockAllTemps(cUnit);
+
+    /*
+     * r4PC     : &r5FP[vC]
+     * r7: &newFP[0]
+     */
+    opRegRegImm(cUnit, kOpAdd, r4PC, r5FP, srcOffset);
+
+    // save numArgs to StackSaveArea
+    opRegRegImm(cUnit, kOpSub, r7, r5FP, sizeof(StackSaveArea));
+    loadConstant(cUnit, r9, numArgs);
+    storeWordDisp(cUnit, r7, offsetof(StackSaveArea, argCount), r9);
+
+    opRegRegImm(cUnit, kOpSub, r7, r5FP,
+                sizeof(StackSaveArea) + (numArgs << 3) + 4);
+    /* generate null check */
+    if (pcrLabel) {
+        *pcrLabel = genNullCheck(cUnit, dvmCompilerSSASrc(mir, 0), r0,
+                                 mir->offset, NULL);
+    }
+
+    if (isNative) {
+        // clear native taint hack
+        loadConstant(cUnit, r9, 0);
+        storeBaseDisp(cUnit, r7, numArgs << 2, r9, kWord);
+
+        if (numArgs>0) {
+            // save first arg in r0
+            loadWordDisp(cUnit, r4PC, 0, r0);
+
+            // push r0
+            opImm(cUnit, kOpPush, (1 << r0 | 1 << r5FP));
+
+            // taint index
+            opRegRegImm(cUnit, kOpAdd, r9, r7, (numArgs << 2) + 4);
+
+            regMask = 0x3;
+            int i;
+            for (i = 0; i < numArgs; i++) {
+                // value+taint
+                loadMultiple(cUnit, r4PC, regMask);
+
+                storeBaseDisp(cUnit, r7, 0, r0, kWord);
+                storeBaseDisp(cUnit, r9, 0, r1, kWord);
+
+                opRegRegImm(cUnit, kOpAdd, r7, r7, 4);
+                opRegRegImm(cUnit, kOpAdd, r9, r9, 4);
+            }
+
+            // pop r0
+            opImm(cUnit, kOpPop, (1 << r0 | 1 << r5FP));
+        }
+    }
+    else {
+        if (numArgs>0) {
+            // save first arg in r0
+            loadWordDisp(cUnit, r4PC, 0, r0);
+
+            // push r0
+            opImm(cUnit, kOpPush, (1 << r0 | 1 << r5FP));
+
+            regMask = 0x3;
+            int i;
+            for (i = 0; i < numArgs; i++) {
+                // value+taint
+                loadMultiple(cUnit, r4PC, regMask);
+                storeMultiple(cUnit, r7, regMask);
+            }
+
+            // pop r0
+            opImm(cUnit, kOpPop, (1 << r0 | 1 << r5FP));
+        }
+
+        // clear native taint hack
+        loadConstant(cUnit, r9, 0);
+        storeBaseDisp(cUnit, r7, 0, r9, kWord);
+    }
+
+    return numArgs;
+#else
     int srcOffset = dInsn->vC << 2;
     int numArgs = dInsn->vA;
     int regMask;
@@ -1053,7 +1475,7 @@ static void genProcessArgsRange(CompilationUnit *cUnit, MIR *mir,
         ArmLIR *loopLabel = NULL;
         /*
          * r0 contains "this" and it will be used later, so push it to the stack
-         * first. Pushing r5FP is just for stack alignment purposes.
+         * first. Pushing r5 (r5FP) is just for stack alignment purposes.
          */
         opImm(cUnit, kOpPush, (1 << r0 | 1 << r5FP));
         /* No need to generate the loop structure if numArgs <= 11 */
@@ -1094,6 +1516,7 @@ static void genProcessArgsRange(CompilationUnit *cUnit, MIR *mir,
     if ((numArgs > 4) && (numArgs % 4)) {
         storeMultiple(cUnit, r7, regMask);
     }
+#endif /*WITH_TAINT_TRACKING*/
 }
 
 /*
@@ -1484,9 +1907,16 @@ static bool handleFmt10x(CompilationUnit *cUnit, MIR *mir)
         case OP_RETURN_VOID_BARRIER:
             dvmCompilerGenMemBarrier(cUnit, kST);
             // Intentional fallthrough
-        case OP_RETURN_VOID:
+        case OP_RETURN_VOID: {
+#ifdef WITH_TAINT_TRACKING
+    	    int taintClear = dvmCompilerAllocTemp(cUnit);
+    	    loadConstant(cUnit, taintClear, TAINT_CLEAR);
+            storeWordDisp(cUnit, r6SELF, offsetof(Thread, interpSave.rtaint), taintClear);
+            dvmCompilerFreeTemp(cUnit, taintClear);
+#endif /*WITH_TAINT_TRACKING*/
             genReturnCommon(cUnit,mir);
             break;
+        }
         case OP_UNUSED_73:
         case OP_UNUSED_79:
         case OP_UNUSED_7A:
@@ -1517,6 +1947,9 @@ static bool handleFmt11n_Fmt31i(CompilationUnit *cUnit, MIR *mir)
             rlResult = dvmCompilerEvalLoc(cUnit, rlDest, kAnyReg, true);
             loadConstantNoClobber(cUnit, rlResult.lowReg, mir->dalvikInsn.vB);
             storeValue(cUnit, rlDest, rlResult);
+#ifdef WITH_TAINT_TRACKING
+            setTaintClear(cUnit, rlDest);
+#endif /*WITH_TAINT_TRACKING*/
             break;
         }
         case OP_CONST_WIDE_32: {
@@ -1527,6 +1960,9 @@ static bool handleFmt11n_Fmt31i(CompilationUnit *cUnit, MIR *mir)
             opRegRegImm(cUnit, kOpAsr, rlResult.highReg,
                         rlResult.lowReg, 31);
             storeValueWide(cUnit, rlDest, rlResult);
+#ifdef WITH_TAINT_TRACKING
+            setTaintClearWide(cUnit, rlDest);
+#endif /*WITH_TAINT_TRACKING*/
             break;
         }
         default:
@@ -1551,12 +1987,18 @@ static bool handleFmt21h(CompilationUnit *cUnit, MIR *mir)
             loadConstantNoClobber(cUnit, rlResult.lowReg,
                                   mir->dalvikInsn.vB << 16);
             storeValue(cUnit, rlDest, rlResult);
+#ifdef WITH_TAINT_TRACKING
+            setTaintClear(cUnit, rlDest);
+#endif /*WITH_TAINT_TRACKING*/
             break;
         }
         case OP_CONST_WIDE_HIGH16: {
             loadConstantValueWide(cUnit, rlResult.lowReg, rlResult.highReg,
                                   0, mir->dalvikInsn.vB << 16);
             storeValueWide(cUnit, rlDest, rlResult);
+#ifdef WITH_TAINT_TRACKING
+            setTaintClearWide(cUnit, rlDest);
+#endif /*WITH_TAINT_TRACKING*/
             break;
         }
         default:
@@ -1594,6 +2036,9 @@ static bool handleFmt21c_Fmt31c(CompilationUnit *cUnit, MIR *mir)
             rlResult = dvmCompilerEvalLoc(cUnit, rlDest, kCoreReg, true);
             loadConstantNoClobber(cUnit, rlResult.lowReg, (int) strPtr );
             storeValue(cUnit, rlDest, rlResult);
+#ifdef WITH_TAINT_TRACKING
+            setTaintClear(cUnit, rlDest);
+#endif /*WITH_TAINT_TRACKING*/
             break;
         }
         case OP_CONST_CLASS: {
@@ -1610,12 +2055,15 @@ static bool handleFmt21c_Fmt31c(CompilationUnit *cUnit, MIR *mir)
             rlResult = dvmCompilerEvalLoc(cUnit, rlDest, kCoreReg, true);
             loadConstantNoClobber(cUnit, rlResult.lowReg, (int) classPtr );
             storeValue(cUnit, rlDest, rlResult);
+#ifdef WITH_TAINT_TRACKING
+            setTaintClear(cUnit, rlDest);
+#endif /*WITH_TAINT_TRACKING*/
             break;
         }
-        case OP_SGET:
         case OP_SGET_VOLATILE:
-        case OP_SGET_OBJECT:
         case OP_SGET_OBJECT_VOLATILE:
+        case OP_SGET:
+        case OP_SGET_OBJECT:
         case OP_SGET_BOOLEAN:
         case OP_SGET_CHAR:
         case OP_SGET_BYTE:
@@ -1653,16 +2101,29 @@ static bool handleFmt21c_Fmt31c(CompilationUnit *cUnit, MIR *mir)
 
             rlDest = dvmCompilerGetDest(cUnit, mir, 0);
             rlResult = dvmCompilerEvalLoc(cUnit, rlDest, kAnyReg, true);
+#ifdef WITH_TAINT_TRACKING
+            int taintOffset = OFFSETOF_MEMBER(StaticField, taint);
+            loadConstant(cUnit, tReg,  (int) fieldPtr);
+#else
             loadConstant(cUnit, tReg,  (int) fieldPtr + valOffset);
+#endif /*WITH_TAINT_TRACKING*/
 
             if (isVolatile) {
                 dvmCompilerGenMemBarrier(cUnit, kSY);
             }
             HEAP_ACCESS_SHADOW(true);
+#ifdef WITH_TAINT_TRACKING
+            loadWordDisp(cUnit, tReg, valOffset, rlResult.lowReg);
+            loadWordDisp(cUnit, tReg, taintOffset, tReg);
+#else
             loadWordDisp(cUnit, tReg, 0, rlResult.lowReg);
+#endif /*WITH_TAINT_TRACKING*/
             HEAP_ACCESS_SHADOW(false);
 
             storeValue(cUnit, rlDest, rlResult);
+#ifdef WITH_TAINT_TRACKING
+            storeTaintDirect(cUnit, rlDest, tReg);
+#endif /*WITH_TAINT_TRACKING*/
             break;
         }
         case OP_SGET_WIDE: {
@@ -1683,17 +2144,30 @@ static bool handleFmt21c_Fmt31c(CompilationUnit *cUnit, MIR *mir)
             rlResult = dvmCompilerEvalLoc(cUnit, rlDest, kAnyReg, true);
             loadConstant(cUnit, tReg,  (int) fieldPtr + valOffset);
 
+#ifdef WITH_TAINT_TRACKING
+            int taintOffset = OFFSETOF_MEMBER(StaticField, taint);
+            int taint = dvmCompilerAllocTemp(cUnit);
+            loadConstant(cUnit, taint,  (int) fieldPtr + taintOffset);
+#endif /*WITH_TAINT_TRACKING*/
+
             HEAP_ACCESS_SHADOW(true);
             loadPair(cUnit, tReg, rlResult.lowReg, rlResult.highReg);
+#ifdef WITH_TAINT_TRACKING
+            loadWordDisp(cUnit, taint, 0, taint);
+#endif /*WITH_TAINT_TRACKING*/
             HEAP_ACCESS_SHADOW(false);
 
             storeValueWide(cUnit, rlDest, rlResult);
+#ifdef WITH_TAINT_TRACKING
+            storeTaintDirectWide(cUnit, rlDest, taint);
+            dvmCompilerFreeTemp(cUnit, taint);
+#endif /*WITH_TAINT_TRACKING*/
             break;
         }
-        case OP_SPUT:
         case OP_SPUT_VOLATILE:
-        case OP_SPUT_OBJECT:
         case OP_SPUT_OBJECT_VOLATILE:
+        case OP_SPUT:
+        case OP_SPUT_OBJECT:
         case OP_SPUT_BOOLEAN:
         case OP_SPUT_CHAR:
         case OP_SPUT_BYTE:
@@ -1729,6 +2203,11 @@ static bool handleFmt21c_Fmt31c(CompilationUnit *cUnit, MIR *mir)
             rlSrc = dvmCompilerGetSrc(cUnit, mir, 0);
             rlSrc = loadValue(cUnit, rlSrc, kAnyReg);
             loadConstant(cUnit, tReg,  (int) fieldPtr);
+#ifdef WITH_TAINT_TRACKING
+            int taintOffset = OFFSETOF_MEMBER(StaticField, taint);
+            int taint = dvmCompilerAllocTemp(cUnit);
+            loadTaintDirect(cUnit, rlSrc, taint);
+#endif /*WITH_TAINT_TRACKING*/
             if (isSputObject) {
                 objHead = dvmCompilerAllocTemp(cUnit);
                 loadWordDisp(cUnit, tReg, OFFSETOF_MEMBER(Field, clazz), objHead);
@@ -1739,6 +2218,10 @@ static bool handleFmt21c_Fmt31c(CompilationUnit *cUnit, MIR *mir)
             HEAP_ACCESS_SHADOW(true);
             storeWordDisp(cUnit, tReg, valOffset ,rlSrc.lowReg);
             dvmCompilerFreeTemp(cUnit, tReg);
+#ifdef WITH_TAINT_TRACKING
+            storeWordDisp(cUnit, tReg, taintOffset, taint);
+            dvmCompilerFreeTemp(cUnit, taint);
+#endif /*WITH_TAINT_TRACKING*/
             HEAP_ACCESS_SHADOW(false);
             if (isVolatile) {
                 dvmCompilerGenMemBarrier(cUnit, kSY);
@@ -1768,9 +2251,19 @@ static bool handleFmt21c_Fmt31c(CompilationUnit *cUnit, MIR *mir)
             rlSrc = dvmCompilerGetSrcWide(cUnit, mir, 0, 1);
             rlSrc = loadValueWide(cUnit, rlSrc, kAnyReg);
             loadConstant(cUnit, tReg,  (int) fieldPtr + valOffset);
+#ifdef WITH_TAINT_TRACKING
+            int taintOffset = OFFSETOF_MEMBER(StaticField, taint);
+            int taint = dvmCompilerAllocTemp(cUnit);
+            loadTaintDirectWide(cUnit, rlSrc, taint);
+#endif /*WITH_TAINT_TRACKING*/
 
             HEAP_ACCESS_SHADOW(true);
             storePair(cUnit, tReg, rlSrc.lowReg, rlSrc.highReg);
+#ifdef WITH_TAINT_TRACKING
+            loadConstant(cUnit, tReg,  (int) fieldPtr + taintOffset);
+            storeWordDisp(cUnit, tReg, 0, taint);
+            dvmCompilerFreeTemp(cUnit, taint);
+#endif /*WITH_TAINT_TRACKING*/
             HEAP_ACCESS_SHADOW(false);
             break;
         }
@@ -1816,6 +2309,9 @@ static bool handleFmt21c_Fmt31c(CompilationUnit *cUnit, MIR *mir)
             rlDest = dvmCompilerGetDest(cUnit, mir, 0);
             rlResult = dvmCompilerGetReturn(cUnit);
             storeValue(cUnit, rlDest, rlResult);
+#ifdef WITH_TAINT_TRACKING
+            setTaintClear(cUnit, rlDest);
+#endif /*WITH_TAINT_TRACKING*/
             break;
         }
         case OP_CHECK_CAST: {
@@ -1911,6 +2407,9 @@ static bool handleFmt11x(CompilationUnit *cUnit, MIR *mir)
             loadConstant(cUnit, resetReg, 0);
             storeWordDisp(cUnit, r6SELF, exOffset, resetReg);
             storeValue(cUnit, rlDest, rlResult);
+#ifdef WITH_TAINT_TRACKING
+            setTaintClear(cUnit, rlDest);
+#endif /*WITH_TAINT_TRACKING*/
            break;
         }
         case OP_MOVE_RESULT:
@@ -1922,6 +2421,12 @@ static bool handleFmt11x(CompilationUnit *cUnit, MIR *mir)
             RegLocation rlSrc = LOC_DALVIK_RETURN_VAL;
             rlSrc.fp = rlDest.fp;
             storeValue(cUnit, rlDest, rlSrc);
+#ifdef WITH_TAINT_TRACKING
+            int taint = dvmCompilerAllocTemp(cUnit);
+            loadWordDisp(cUnit, r6SELF, offsetof(Thread, interpSave.rtaint), taint);
+            storeTaintDirect(cUnit, rlDest, taint);
+            dvmCompilerFreeTemp(cUnit, taint);
+#endif /*WITH_TAINT_TRACKING*/
             break;
         }
         case OP_MOVE_RESULT_WIDE: {
@@ -1932,6 +2437,12 @@ static bool handleFmt11x(CompilationUnit *cUnit, MIR *mir)
             RegLocation rlSrc = LOC_DALVIK_RETURN_VAL_WIDE;
             rlSrc.fp = rlDest.fp;
             storeValueWide(cUnit, rlDest, rlSrc);
+#ifdef WITH_TAINT_TRACKING
+            int taint = dvmCompilerAllocTemp(cUnit);
+            loadWordDisp(cUnit, r6SELF, offsetof(Thread, interpSave.rtaint), taint);
+            storeTaintDirectWide(cUnit, rlDest, taint);
+            dvmCompilerFreeTemp(cUnit, taint);
+#endif /*WITH_TAINT_TRACKING*/
             break;
         }
         case OP_RETURN_WIDE: {
@@ -1939,6 +2450,12 @@ static bool handleFmt11x(CompilationUnit *cUnit, MIR *mir)
             RegLocation rlDest = LOC_DALVIK_RETURN_VAL_WIDE;
             rlDest.fp = rlSrc.fp;
             storeValueWide(cUnit, rlDest, rlSrc);
+#ifdef WITH_TAINT_TRACKING
+            int taint = dvmCompilerAllocTemp(cUnit);
+            loadTaintDirectWide(cUnit, rlSrc, taint);
+            storeWordDisp(cUnit, r6SELF, offsetof(Thread, interpSave.rtaint), taint);
+            dvmCompilerFreeTemp(cUnit, taint);
+#endif /*WITH_TAINT_TRACKING*/
             genReturnCommon(cUnit,mir);
             break;
         }
@@ -1948,6 +2465,12 @@ static bool handleFmt11x(CompilationUnit *cUnit, MIR *mir)
             RegLocation rlDest = LOC_DALVIK_RETURN_VAL;
             rlDest.fp = rlSrc.fp;
             storeValue(cUnit, rlDest, rlSrc);
+#ifdef WITH_TAINT_TRACKING
+            int taint = dvmCompilerAllocTemp(cUnit);
+            loadTaintDirect(cUnit, rlSrc, taint);
+            storeWordDisp(cUnit, r6SELF, offsetof(Thread, interpSave.rtaint), taint);
+            dvmCompilerFreeTemp(cUnit, taint);
+#endif /*WITH_TAINT_TRACKING*/
             genReturnCommon(cUnit, mir);
             break;
         }
@@ -1970,17 +2493,29 @@ static bool handleFmt12x(CompilationUnit *cUnit, MIR *mir)
     RegLocation rlDest;
     RegLocation rlSrc;
     RegLocation rlResult;
+#ifdef WITH_TAINT_TRACKING
+    bool wideSrc = false;
+    bool wideDest = false;
+#endif /*WITH_TAINT_TRACKING*/
 
     if ( (opcode >= OP_ADD_INT_2ADDR) && (opcode <= OP_REM_DOUBLE_2ADDR)) {
         return genArithOp( cUnit, mir );
     }
 
-    if (mir->ssaRep->numUses == 2)
+    if (mir->ssaRep->numUses == 2) {
         rlSrc = dvmCompilerGetSrcWide(cUnit, mir, 0, 1);
+#ifdef WITH_TAINT_TRACKING
+        wideSrc = true;
+#endif /*WITH_TAINT_TRACKING*/
+    }
     else
         rlSrc = dvmCompilerGetSrc(cUnit, mir, 0);
-    if (mir->ssaRep->numDefs == 2)
+    if (mir->ssaRep->numDefs == 2) {
         rlDest = dvmCompilerGetDestWide(cUnit, mir, 0, 1);
+#ifdef WITH_TAINT_TRACKING
+        wideDest = true;
+#endif /*WITH_TAINT_TRACKING*/
+    }
     else
         rlDest = dvmCompilerGetDest(cUnit, mir, 0);
 
@@ -1994,22 +2529,65 @@ static bool handleFmt12x(CompilationUnit *cUnit, MIR *mir)
         case OP_FLOAT_TO_LONG:
         case OP_LONG_TO_FLOAT:
         case OP_DOUBLE_TO_LONG:
-        case OP_LONG_TO_DOUBLE:
+        case OP_LONG_TO_DOUBLE: {
+#ifdef WITH_TAINT_TRACKING
+            bool success = genConversion(cUnit, mir);
+            int taint = dvmCompilerAllocTemp(cUnit);
+            if (wideSrc)
+                loadTaintDirectWide(cUnit, rlSrc, taint);
+            else
+                loadTaintDirect(cUnit, rlSrc, taint);
+            if (wideDest)
+                storeTaintDirectWide(cUnit, rlDest, taint);
+            else
+                storeTaintDirect(cUnit, rlDest, taint);
+            dvmCompilerFreeTemp(cUnit, taint);
+            return success;
+#else
             return genConversion(cUnit, mir);
+#endif /*WITH_TAINT_TRACKING*/
+	}
         case OP_NEG_INT:
         case OP_NOT_INT:
             return genArithOpInt(cUnit, mir, rlDest, rlSrc, rlSrc);
         case OP_NEG_LONG:
         case OP_NOT_LONG:
             return genArithOpLong(cUnit, mir, rlDest, rlSrc, rlSrc);
-        case OP_NEG_FLOAT:
+        case OP_NEG_FLOAT: {
+#ifdef WITH_TAINT_TRACKING
+            bool success = genArithOpFloat(cUnit, mir, rlDest, rlSrc, rlSrc);
+            int taint = dvmCompilerAllocTemp(cUnit);
+            loadTaintDirect(cUnit, rlSrc, taint);
+            storeTaintDirect(cUnit, rlDest, taint);
+            dvmCompilerFreeTemp(cUnit, taint);
+            return success;
+#else
             return genArithOpFloat(cUnit, mir, rlDest, rlSrc, rlSrc);
-        case OP_NEG_DOUBLE:
+#endif /*WITH_TAINT_TRACKING*/
+	}
+        case OP_NEG_DOUBLE: {
+#ifdef WITH_TAINT_TRACKING
+            bool success = genArithOpDouble(cUnit, mir, rlDest, rlSrc, rlSrc);
+            int taint = dvmCompilerAllocTemp(cUnit);
+            loadTaintDirectWide(cUnit, rlSrc, taint);
+            storeTaintDirectWide(cUnit, rlDest, taint);
+            dvmCompilerFreeTemp(cUnit, taint);
+            return success;
+#else
             return genArithOpDouble(cUnit, mir, rlDest, rlSrc, rlSrc);
-        case OP_MOVE_WIDE:
+#endif /*WITH_TAINT_TRACKING*/
+	}
+        case OP_MOVE_WIDE: {
             storeValueWide(cUnit, rlDest, rlSrc);
-            break;
-        case OP_INT_TO_LONG:
+#ifdef WITH_TAINT_TRACKING
+            int taint = dvmCompilerAllocTemp(cUnit);
+            loadTaintDirectWide(cUnit, rlSrc, taint);
+            storeTaintDirectWide(cUnit, rlDest, taint);
+            dvmCompilerFreeTemp(cUnit, taint);
+#endif /*WITH_TAINT_TRACKING*/
+            break;
+	}
+        case OP_INT_TO_LONG: {
             rlSrc = dvmCompilerUpdateLoc(cUnit, rlSrc);
             rlResult = dvmCompilerEvalLoc(cUnit, rlDest, kCoreReg, true);
             //TUNING: shouldn't loadValueDirect already check for phys reg?
@@ -2021,33 +2599,68 @@ static bool handleFmt12x(CompilationUnit *cUnit, MIR *mir)
             opRegRegImm(cUnit, kOpAsr, rlResult.highReg,
                         rlResult.lowReg, 31);
             storeValueWide(cUnit, rlDest, rlResult);
+#ifdef WITH_TAINT_TRACKING
+            int taint = dvmCompilerAllocTemp(cUnit);
+            loadTaintDirect(cUnit, rlSrc, taint);
+            storeTaintDirectWide(cUnit, rlDest, taint);
+            dvmCompilerFreeTemp(cUnit, taint);
+#endif /*WITH_TAINT_TRACKING*/
             break;
+        }
         case OP_LONG_TO_INT:
             rlSrc = dvmCompilerUpdateLocWide(cUnit, rlSrc);
             rlSrc = dvmCompilerWideToNarrow(cUnit, rlSrc);
             // Intentional fallthrough
         case OP_MOVE:
-        case OP_MOVE_OBJECT:
+        case OP_MOVE_OBJECT: {
             storeValue(cUnit, rlDest, rlSrc);
-            break;
-        case OP_INT_TO_BYTE:
+#ifdef WITH_TAINT_TRACKING
+            int taint = dvmCompilerAllocTemp(cUnit);
+            loadTaintDirect(cUnit, rlSrc, taint);
+            storeTaintDirect(cUnit, rlDest, taint);
+            dvmCompilerFreeTemp(cUnit, taint);
+#endif /*WITH_TAINT_TRACKING*/
+            break;
+	}
+        case OP_INT_TO_BYTE: {
             rlSrc = loadValue(cUnit, rlSrc, kCoreReg);
             rlResult = dvmCompilerEvalLoc(cUnit, rlDest, kCoreReg, true);
             opRegReg(cUnit, kOp2Byte, rlResult.lowReg, rlSrc.lowReg);
             storeValue(cUnit, rlDest, rlResult);
+#ifdef WITH_TAINT_TRACKING
+            int taint = dvmCompilerAllocTemp(cUnit);
+            loadTaintDirect(cUnit, rlSrc, taint);
+            storeTaintDirect(cUnit, rlDest, taint);
+            dvmCompilerFreeTemp(cUnit, taint);
+#endif /*WITH_TAINT_TRACKING*/
             break;
-        case OP_INT_TO_SHORT:
+        }
+        case OP_INT_TO_SHORT: {
             rlSrc = loadValue(cUnit, rlSrc, kCoreReg);
             rlResult = dvmCompilerEvalLoc(cUnit, rlDest, kCoreReg, true);
             opRegReg(cUnit, kOp2Short, rlResult.lowReg, rlSrc.lowReg);
             storeValue(cUnit, rlDest, rlResult);
+#ifdef WITH_TAINT_TRACKING
+            int taint = dvmCompilerAllocTemp(cUnit);
+            loadTaintDirect(cUnit, rlSrc, taint);
+            storeTaintDirect(cUnit, rlDest, taint);
+            dvmCompilerFreeTemp(cUnit, taint);
+#endif /*WITH_TAINT_TRACKING*/
             break;
-        case OP_INT_TO_CHAR:
+        }
+        case OP_INT_TO_CHAR: {
             rlSrc = loadValue(cUnit, rlSrc, kCoreReg);
             rlResult = dvmCompilerEvalLoc(cUnit, rlDest, kCoreReg, true);
             opRegReg(cUnit, kOp2Char, rlResult.lowReg, rlSrc.lowReg);
             storeValue(cUnit, rlDest, rlResult);
+#ifdef WITH_TAINT_TRACKING
+            int taint = dvmCompilerAllocTemp(cUnit);
+            loadTaintDirect(cUnit, rlSrc, taint);
+            storeTaintDirect(cUnit, rlDest, taint);
+            dvmCompilerFreeTemp(cUnit, taint);
+#endif /*WITH_TAINT_TRACKING*/
             break;
+        }
         case OP_ARRAY_LENGTH: {
             int lenOffset = OFFSETOF_MEMBER(ArrayObject, length);
             rlSrc = loadValue(cUnit, rlSrc, kCoreReg);
@@ -2057,6 +2670,9 @@ static bool handleFmt12x(CompilationUnit *cUnit, MIR *mir)
             loadWordDisp(cUnit, rlSrc.lowReg, lenOffset,
                          rlResult.lowReg);
             storeValue(cUnit, rlDest, rlResult);
+#ifdef WITH_TAINT_TRACKING
+            setTaintClear(cUnit, rlDest);
+#endif /*WITH_TAINT_TRACKING*/
             break;
         }
         default:
@@ -2078,11 +2694,17 @@ static bool handleFmt21s(CompilationUnit *cUnit, MIR *mir)
         //TUNING: do high separately to avoid load dependency
         opRegRegImm(cUnit, kOpAsr, rlResult.highReg, rlResult.lowReg, 31);
         storeValueWide(cUnit, rlDest, rlResult);
+#ifdef WITH_TAINT_TRACKING
+        setTaintClearWide(cUnit, rlDest);
+#endif /*WITH_TAINT_TRACKING*/
     } else if (dalvikOpcode == OP_CONST_16) {
         rlDest = dvmCompilerGetDest(cUnit, mir, 0);
         rlResult = dvmCompilerEvalLoc(cUnit, rlDest, kAnyReg, true);
         loadConstantNoClobber(cUnit, rlResult.lowReg, BBBB);
         storeValue(cUnit, rlDest, rlResult);
+#ifdef WITH_TAINT_TRACKING
+        setTaintClear(cUnit, rlDest);
+#endif /*WITH_TAINT_TRACKING*/
     } else
         return true;
     return false;
@@ -2283,6 +2905,12 @@ static bool handleFmt22b_Fmt22s(CompilationUnit *cUnit, MIR *mir)
             opRegRegReg(cUnit, kOpSub, rlResult.lowReg,
                         tReg, rlSrc.lowReg);
             storeValue(cUnit, rlDest, rlResult);
+#ifdef WITH_TAINT_TRACKING
+            int taint = dvmCompilerAllocTemp(cUnit);
+            loadTaintDirect(cUnit, rlSrc, taint);
+            storeTaintDirect(cUnit, rlDest, taint);
+            dvmCompilerFreeTemp(cUnit, taint);
+#endif /*WITH_TAINT_TRACKING*/
             return false;
             break;
         }
@@ -2294,6 +2922,12 @@ static bool handleFmt22b_Fmt22s(CompilationUnit *cUnit, MIR *mir)
         case OP_MUL_INT_LIT8:
         case OP_MUL_INT_LIT16: {
             if (handleEasyMultiply(cUnit, rlSrc, rlDest, lit)) {
+#ifdef WITH_TAINT_TRACKING
+                int taint = dvmCompilerAllocTemp(cUnit);
+                loadTaintDirect(cUnit, rlSrc, taint);
+                storeTaintDirect(cUnit, rlDest, taint);
+                dvmCompilerFreeTemp(cUnit, taint);
+#endif /*WITH_TAINT_TRACKING*/
                 return false;
             }
             op = kOpMul;
@@ -2330,13 +2964,19 @@ static bool handleFmt22b_Fmt22s(CompilationUnit *cUnit, MIR *mir)
         case OP_DIV_INT_LIT8:
         case OP_DIV_INT_LIT16:
         case OP_REM_INT_LIT8:
-        case OP_REM_INT_LIT16:
+        case OP_REM_INT_LIT16: {
             if (lit == 0) {
                 /* Let the interpreter deal with div by 0 */
                 genInterpSingleStep(cUnit, mir);
                 return false;
             }
             if (handleEasyDivide(cUnit, dalvikOpcode, rlSrc, rlDest, lit)) {
+#ifdef WITH_TAINT_TRACKING
+                int taint = dvmCompilerAllocTemp(cUnit);
+                loadTaintDirect(cUnit, rlSrc, taint);
+                storeTaintDirect(cUnit, rlDest, taint);
+                dvmCompilerFreeTemp(cUnit, taint);
+#endif /*WITH_TAINT_TRACKING*/
                 return false;
             }
             dvmCompilerFlushAllRegs(cUnit);   /* Everything to home location */
@@ -2358,8 +2998,15 @@ static bool handleFmt22b_Fmt22s(CompilationUnit *cUnit, MIR *mir)
             else
                 rlResult = dvmCompilerGetReturnAlt(cUnit);
             storeValue(cUnit, rlDest, rlResult);
+#ifdef WITH_TAINT_TRACKING
+    	    int taint = dvmCompilerAllocTemp(cUnit);
+            loadTaintDirect(cUnit, rlSrc, taint);
+            storeTaintDirect(cUnit, rlDest, taint);
+            dvmCompilerFreeTemp(cUnit, taint);
+#endif /*WITH_TAINT_TRACKING*/
             return false;
             break;
+        }
         default:
             return true;
     }
@@ -2372,6 +3019,12 @@ static bool handleFmt22b_Fmt22s(CompilationUnit *cUnit, MIR *mir)
         opRegRegImm(cUnit, op, rlResult.lowReg, rlSrc.lowReg, lit);
     }
     storeValue(cUnit, rlDest, rlResult);
+#ifdef WITH_TAINT_TRACKING
+    int taint = dvmCompilerAllocTemp(cUnit);
+    loadTaintDirect(cUnit, rlSrc, taint);
+    storeTaintDirect(cUnit, rlDest, taint);
+    dvmCompilerFreeTemp(cUnit, taint);
+#endif /*WITH_TAINT_TRACKING*/
     return false;
 }
 
@@ -2475,6 +3128,9 @@ static bool handleFmt22c(CompilationUnit *cUnit, MIR *mir)
             branchOver->generic.target = (LIR *) target;
             rlResult = dvmCompilerGetReturn(cUnit);
             storeValue(cUnit, rlDest, rlResult);
+#ifdef WITH_TAINT_TRACKING
+            setTaintClear(cUnit, rlDest);
+#endif /*WITH_TAINT_TRACKING*/
             break;
         }
         case OP_INSTANCE_OF: {
@@ -2519,6 +3175,9 @@ static bool handleFmt22c(CompilationUnit *cUnit, MIR *mir)
             target->defMask = ENCODE_ALL;
             rlResult = dvmCompilerGetReturn(cUnit);
             storeValue(cUnit, rlDest, rlResult);
+#ifdef WITH_TAINT_TRACKING
+            setTaintClear(cUnit, rlDest);
+#endif /*WITH_TAINT_TRACKING*/
             branch1->generic.target = (LIR *)target;
             branch2->generic.target = (LIR *)target;
             break;
@@ -2652,12 +3311,24 @@ static bool handleFmt22x_Fmt32x(CompilationUnit *cUnit, MIR *mir)
         case OP_MOVE_OBJECT_FROM16: {
             storeValue(cUnit, dvmCompilerGetDest(cUnit, mir, 0),
                        dvmCompilerGetSrc(cUnit, mir, 0));
+#ifdef WITH_TAINT_TRACKING
+            int taint = dvmCompilerAllocTemp(cUnit);
+            loadTaintDirect(cUnit, dvmCompilerGetSrc(cUnit, mir, 0), taint);
+            storeTaintDirect(cUnit, dvmCompilerGetDest(cUnit, mir, 0), taint);
+            dvmCompilerFreeTemp(cUnit, taint);
+#endif /*WITH_TAINT_TRACKING*/
             break;
         }
         case OP_MOVE_WIDE_16:
         case OP_MOVE_WIDE_FROM16: {
             storeValueWide(cUnit, dvmCompilerGetDestWide(cUnit, mir, 0, 1),
                            dvmCompilerGetSrcWide(cUnit, mir, 0, 1));
+#ifdef WITH_TAINT_TRACKING
+            int taint = dvmCompilerAllocTemp(cUnit);
+            loadTaintDirectWide(cUnit, dvmCompilerGetSrcWide(cUnit, mir, 0, 1), taint);
+            storeTaintDirectWide(cUnit, dvmCompilerGetDestWide(cUnit, mir, 0, 1), taint);
+            dvmCompilerFreeTemp(cUnit, taint);
+#endif /*WITH_TAINT_TRACKING*/
             break;
         }
         default:
@@ -2712,11 +3383,23 @@ static bool handleFmt23x(CompilationUnit *cUnit, MIR *mir)
         case OP_CMPL_FLOAT:
         case OP_CMPG_FLOAT:
         case OP_CMPL_DOUBLE:
-        case OP_CMPG_DOUBLE:
+        case OP_CMPG_DOUBLE: {
+#ifdef WITH_TAINT_TRACKING
+            bool success;
+            success = genCmpFP(cUnit, mir, rlDest, rlSrc1, rlSrc2);
+            setTaintClear(cUnit, rlDest);
+    	    return success;
+#else
             return genCmpFP(cUnit, mir, rlDest, rlSrc1, rlSrc2);
-        case OP_CMP_LONG:
+#endif /*WITH_TAINT_TRACKING*/
+	}
+        case OP_CMP_LONG: {
             genCmpLong(cUnit, mir, rlDest, rlSrc1, rlSrc2);
+#ifdef WITH_TAINT_TRACKING
+            setTaintClear(cUnit, rlDest);
+#endif /*WITH_TAINT_TRACKING*/
             break;
+	}
         case OP_AGET_WIDE:
             genArrayGet(cUnit, mir, kLong, rlSrc1, rlSrc2, rlDest, 3);
             break;
@@ -3005,6 +3688,11 @@ static bool handleFmt35c_3rc(CompilationUnit *cUnit, MIR *mir,
                 cUnit->method->clazz->pDvmDex->pResMethods[dInsn->vB]->
                 methodIndex;
 
+#ifdef WITH_TAINT_TRACKING
+            const Method *calleeMethod = mir->meta.callsiteInfo->method;
+            bool nativeTarget = dvmIsNativeMethod(calleeMethod);
+#endif /*WITH_TAINT_TRACKING*/
+
             /*
              * If the invoke has non-null misPredBranchOver, we need to generate
              * the non-inlined version of the invoke here to handle the
@@ -3014,10 +3702,18 @@ static bool handleFmt35c_3rc(CompilationUnit *cUnit, MIR *mir,
                 genLandingPadForMispredictedCallee(cUnit, mir, bb, labelList);
             }
 
+#ifdef WITH_TAINT_TRACKING
+            int numArgs = 0;
+            if (mir->dalvikInsn.opcode == OP_INVOKE_VIRTUAL)
+                numArgs = genProcessArgsNoRange(cUnit, mir, dInsn, nativeTarget, &pcrLabel);
+            else
+                numArgs = genProcessArgsRange(cUnit, mir, dInsn, nativeTarget, &pcrLabel);
+#else
             if (mir->dalvikInsn.opcode == OP_INVOKE_VIRTUAL)
                 genProcessArgsNoRange(cUnit, mir, dInsn, &pcrLabel);
             else
                 genProcessArgsRange(cUnit, mir, dInsn, &pcrLabel);
+#endif /*WITH_TAINT_TRACKING*/
 
             genInvokeVirtualCommon(cUnit, mir, methodIndex,
                                    retChainingCell,
@@ -3037,10 +3733,20 @@ static bool handleFmt35c_3rc(CompilationUnit *cUnit, MIR *mir,
                                      cUnit->method->clazz->pDvmDex->
                                        pResMethods[dInsn->vB]->methodIndex]);
 
+#ifdef WITH_TAINT_TRACKING
+            bool nativeTarget = dvmIsNativeMethod(calleeMethod);
+
+            int numArgs = 0;
+            if (mir->dalvikInsn.opcode == OP_INVOKE_SUPER)
+                numArgs = genProcessArgsNoRange(cUnit, mir, dInsn, nativeTarget, &pcrLabel);
+            else
+                numArgs = genProcessArgsRange(cUnit, mir, dInsn, nativeTarget, &pcrLabel);
+#else
             if (mir->dalvikInsn.opcode == OP_INVOKE_SUPER)
                 genProcessArgsNoRange(cUnit, mir, dInsn, &pcrLabel);
             else
                 genProcessArgsRange(cUnit, mir, dInsn, &pcrLabel);
+#endif /*WITH_TAINT_TRACKING*/
 
             if (mir->OptimizationFlags & MIR_INVOKE_METHOD_JIT) {
                 const Method *calleeMethod = mir->meta.callsiteInfo->method;
@@ -3065,10 +3771,20 @@ static bool handleFmt35c_3rc(CompilationUnit *cUnit, MIR *mir,
             assert(calleeMethod ==
                    cUnit->method->clazz->pDvmDex->pResMethods[dInsn->vB]);
 
+#ifdef WITH_TAINT_TRACKING
+            bool nativeTarget = dvmIsNativeMethod(calleeMethod);
+
+            int numArgs = 0;
+            if (mir->dalvikInsn.opcode == OP_INVOKE_DIRECT)
+                numArgs = genProcessArgsNoRange(cUnit, mir, dInsn, nativeTarget, &pcrLabel);
+            else
+                numArgs = genProcessArgsRange(cUnit, mir, dInsn, nativeTarget, &pcrLabel);
+#else
             if (mir->dalvikInsn.opcode == OP_INVOKE_DIRECT)
                 genProcessArgsNoRange(cUnit, mir, dInsn, &pcrLabel);
             else
                 genProcessArgsRange(cUnit, mir, dInsn, &pcrLabel);
+#endif /*WITH_TAINT_TRACKING*/
 
             /* r0 = calleeMethod */
             loadConstant(cUnit, r0, (int) calleeMethod);
@@ -3085,12 +3801,24 @@ static bool handleFmt35c_3rc(CompilationUnit *cUnit, MIR *mir,
             assert(calleeMethod ==
                    cUnit->method->clazz->pDvmDex->pResMethods[dInsn->vB]);
 
+#ifdef WITH_TAINT_TRACKING
+            bool nativeTarget = dvmIsNativeMethod(calleeMethod);
+
+            int numArgs = 0;
+            if (mir->dalvikInsn.opcode == OP_INVOKE_STATIC)
+                numArgs = genProcessArgsNoRange(cUnit, mir, dInsn, nativeTarget,
+                                      NULL /* no null check */);
+            else
+                numArgs = genProcessArgsRange(cUnit, mir, dInsn, nativeTarget,
+                                    NULL /* no null check */);
+#else
             if (mir->dalvikInsn.opcode == OP_INVOKE_STATIC)
                 genProcessArgsNoRange(cUnit, mir, dInsn,
                                       NULL /* no null check */);
             else
                 genProcessArgsRange(cUnit, mir, dInsn,
                                     NULL /* no null check */);
+#endif /*WITH_TAINT_TRACKING*/
 
             if (mir->OptimizationFlags & MIR_INVOKE_METHOD_JIT) {
                 const Method *calleeMethod = mir->meta.callsiteInfo->method;
@@ -3191,10 +3919,21 @@ static bool handleFmt35c_3rc(CompilationUnit *cUnit, MIR *mir,
                 genLandingPadForMispredictedCallee(cUnit, mir, bb, labelList);
             }
 
+#ifdef WITH_TAINT_TRACKING
+            const Method *calleeMethod = mir->meta.callsiteInfo->method;
+            bool nativeTarget = dvmIsNativeMethod(calleeMethod);
+
+            int numArgs = 0;
+            if (mir->dalvikInsn.opcode == OP_INVOKE_INTERFACE)
+                numArgs = genProcessArgsNoRange(cUnit, mir, dInsn, nativeTarget, &pcrLabel);
+            else
+                numArgs = genProcessArgsRange(cUnit, mir, dInsn, nativeTarget, &pcrLabel);
+#else
             if (mir->dalvikInsn.opcode == OP_INVOKE_INTERFACE)
                 genProcessArgsNoRange(cUnit, mir, dInsn, &pcrLabel);
             else
                 genProcessArgsRange(cUnit, mir, dInsn, &pcrLabel);
+#endif /*WITH_TAINT_TRACKING*/
 
             /* "this" is already left in r0 by genProcessArgs* */
 
@@ -3367,11 +4106,21 @@ static bool handleFmt35ms_3rms(CompilationUnit *cUnit, MIR *mir,
                 genLandingPadForMispredictedCallee(cUnit, mir, bb, labelList);
             }
 
+#ifdef WITH_TAINT_TRACKING
+            const Method *calleeMethod = mir->meta.callsiteInfo->method;
+            bool nativeTarget = dvmIsNativeMethod(calleeMethod);
+
+            int numArgs = 0;
+            if (mir->dalvikInsn.opcode == OP_INVOKE_VIRTUAL_QUICK)
+                numArgs = genProcessArgsNoRange(cUnit, mir, dInsn, nativeTarget, &pcrLabel);
+            else
+                numArgs = genProcessArgsRange(cUnit, mir, dInsn, nativeTarget, &pcrLabel);
+#else
             if (mir->dalvikInsn.opcode == OP_INVOKE_VIRTUAL_QUICK)
                 genProcessArgsNoRange(cUnit, mir, dInsn, &pcrLabel);
             else
                 genProcessArgsRange(cUnit, mir, dInsn, &pcrLabel);
-
+#endif /*WITH_TAINT_TRACKING*/
 
             if (mir->OptimizationFlags & MIR_INVOKE_METHOD_JIT) {
                 const Method *calleeMethod = mir->meta.callsiteInfo->method;
@@ -3395,10 +4144,20 @@ static bool handleFmt35ms_3rms(CompilationUnit *cUnit, MIR *mir,
             assert(calleeMethod ==
                    cUnit->method->clazz->super->vtable[dInsn->vB]);
 
+#ifdef WITH_TAINT_TRACKING
+            bool nativeTarget = dvmIsNativeMethod(calleeMethod);
+
+            int numArgs = 0;
+            if (mir->dalvikInsn.opcode == OP_INVOKE_SUPER_QUICK)
+                numArgs = genProcessArgsNoRange(cUnit, mir, dInsn, nativeTarget, &pcrLabel);
+            else
+                numArgs = genProcessArgsRange(cUnit, mir, dInsn, nativeTarget, &pcrLabel);
+#else
             if (mir->dalvikInsn.opcode == OP_INVOKE_SUPER_QUICK)
                 genProcessArgsNoRange(cUnit, mir, dInsn, &pcrLabel);
             else
                 genProcessArgsRange(cUnit, mir, dInsn, &pcrLabel);
+#endif /*WITH_TAINT_TRACKING*/
 
             /* r0 = calleeMethod */
             loadConstant(cUnit, r0, (int) calleeMethod);
@@ -3439,8 +4198,15 @@ static bool genInlinedCompareTo(CompilationUnit *cUnit, MIR *mir)
      * expansion.
      */
     genDispatchToHandler(cUnit, TEMPLATE_STRING_COMPARETO);
+#ifdef WITH_TAINT_TRACKING
+    RegLocation rlDest = inlinedTarget(cUnit, mir, false);
+    storeValue(cUnit, rlDest,
+               dvmCompilerGetReturn(cUnit));
+    setTaintClear(cUnit, rlDest);
+#else
     storeValue(cUnit, inlinedTarget(cUnit, mir, false),
                dvmCompilerGetReturn(cUnit));
+#endif /*WITH_TAINT_TRACKING*/
     return false;
 #endif
 }
@@ -3460,8 +4226,15 @@ static bool genInlinedFastIndexOf(CompilationUnit *cUnit, MIR *mir)
     /* Test objects for NULL */
     genNullCheck(cUnit, rlThis.sRegLow, r0, mir->offset, NULL);
     genDispatchToHandler(cUnit, TEMPLATE_STRING_INDEXOF);
+#ifdef WITH_TAINT_TRACKING
+    RegLocation rlDest = inlinedTarget(cUnit, mir, false);
+    storeValue(cUnit, rlDest,
+               dvmCompilerGetReturn(cUnit));
+    setTaintClear(cUnit, rlDest);
+#else
     storeValue(cUnit, inlinedTarget(cUnit, mir, false),
                dvmCompilerGetReturn(cUnit));
+#endif /*WITH_TAINT_TRACKING*/
     return false;
 #endif
 }
@@ -3485,6 +4258,9 @@ static bool genInlinedStringIsEmptyOrLength(CompilationUnit *cUnit, MIR *mir,
         opRegRegReg(cUnit, kOpAdc, rlResult.lowReg, rlResult.lowReg, tReg);
     }
     storeValue(cUnit, rlDest, rlResult);
+#ifdef WITH_TAINT_TRACKING
+    setTaintClear(cUnit, rlDest);
+#endif /*WITH_TAINT_TRACKING*/
     return false;
 }
 
@@ -3515,12 +4291,25 @@ static bool genInlinedStringCharAt(CompilationUnit *cUnit, MIR *mir)
     loadWordDisp(cUnit, rlObj.lowReg, gDvm.offJavaLangString_count, regMax);
     loadWordDisp(cUnit, rlObj.lowReg, gDvm.offJavaLangString_offset, regOff);
     loadWordDisp(cUnit, rlObj.lowReg, gDvm.offJavaLangString_value, regPtr);
+#ifdef WITH_TAINT_TRACKING
+    int strTaint = dvmCompilerAllocTemp(cUnit);
+    int idxTaint = dvmCompilerAllocTemp(cUnit);
+    int taintOffset = OFFSETOF_MEMBER(ArrayObject, taint);
+    loadWordDisp(cUnit, regPtr, taintOffset, strTaint);
+    loadTaintDirect(cUnit, rlIdx, idxTaint);
+#endif /*WITH_TAINT_TRACKING*/
     genBoundsCheck(cUnit, rlIdx.lowReg, regMax, mir->offset, pcrLabel);
     dvmCompilerFreeTemp(cUnit, regMax);
     opRegImm(cUnit, kOpAdd, regPtr, contents);
     opRegReg(cUnit, kOpAdd, regOff, rlIdx.lowReg);
     rlResult = dvmCompilerEvalLoc(cUnit, rlDest, kCoreReg, true);
     loadBaseIndexed(cUnit, regPtr, regOff, rlResult.lowReg, 1, kUnsignedHalf);
+#ifdef WITH_TAINT_TRACKING
+    opRegRegReg(cUnit, kOpOr, strTaint, idxTaint, strTaint);
+    storeTaintDirect(cUnit, rlDest, strTaint);
+    dvmCompilerFreeTemp(cUnit, strTaint);
+    dvmCompilerFreeTemp(cUnit, idxTaint);
+#endif /*WITH_TAINT_TRACKING*/
     storeValue(cUnit, rlDest, rlResult);
     return false;
 }
@@ -3541,6 +4330,12 @@ static bool genInlinedAbsInt(CompilationUnit *cUnit, MIR *mir)
     opRegRegReg(cUnit, kOpAdd, rlResult.lowReg, rlSrc.lowReg, signReg);
     opRegReg(cUnit, kOpXor, rlResult.lowReg, signReg);
     storeValue(cUnit, rlDest, rlResult);
+#ifdef WITH_TAINT_TRACKING
+    int taint = dvmCompilerAllocTemp(cUnit);
+    loadTaintDirect(cUnit, rlSrc, taint);
+    storeTaintDirect(cUnit, rlDest, taint);
+    dvmCompilerFreeTemp(cUnit, taint);
+#endif /*WITH_TAINT_TRACKING*/
     return false;
 }
 
@@ -3563,6 +4358,12 @@ static bool genInlinedAbsLong(CompilationUnit *cUnit, MIR *mir)
     opRegReg(cUnit, kOpXor, rlResult.lowReg, signReg);
     opRegReg(cUnit, kOpXor, rlResult.highReg, signReg);
     storeValueWide(cUnit, rlDest, rlResult);
+#ifdef WITH_TAINT_TRACKING
+    int taint = dvmCompilerAllocTemp(cUnit);
+    loadTaintDirectWide(cUnit, rlSrc, taint);
+    storeTaintDirectWide(cUnit, rlDest, taint);
+    dvmCompilerFreeTemp(cUnit, taint);
+#endif /*WITH_TAINT_TRACKING*/
     return false;
 }
 
@@ -3572,6 +4373,12 @@ static bool genInlinedIntFloatConversion(CompilationUnit *cUnit, MIR *mir)
     RegLocation rlSrc = dvmCompilerGetSrc(cUnit, mir, 0);
     RegLocation rlDest = inlinedTarget(cUnit, mir, false);
     storeValue(cUnit, rlDest, rlSrc);
+#ifdef WITH_TAINT_TRACKING
+    int taint = dvmCompilerAllocTemp(cUnit);
+    loadTaintDirect(cUnit, rlSrc, taint);
+    storeTaintDirect(cUnit, rlDest, taint);
+    dvmCompilerFreeTemp(cUnit, taint);
+#endif /*WITH_TAINT_TRACKING*/
     return false;
 }
 
@@ -3581,6 +4388,12 @@ static bool genInlinedLongDoubleConversion(CompilationUnit *cUnit, MIR *mir)
     RegLocation rlSrc = dvmCompilerGetSrcWide(cUnit, mir, 0, 1);
     RegLocation rlDest = inlinedTargetWide(cUnit, mir, false);
     storeValueWide(cUnit, rlDest, rlSrc);
+#ifdef WITH_TAINT_TRACKING
+    int taint = dvmCompilerAllocTemp(cUnit);
+    loadTaintDirectWide(cUnit, rlSrc, taint);
+    storeTaintDirectWide(cUnit, rlDest, taint);
+    dvmCompilerFreeTemp(cUnit, taint);
+#endif /*WITH_TAINT_TRACKING*/
     return false;
 }
 
@@ -3604,15 +4417,33 @@ static bool handleExecuteInlineC(CompilationUnit *cUnit, MIR *mir)
     dvmCompilerClobber(cUnit, r4PC);
     dvmCompilerClobber(cUnit, r7);
     int offset = offsetof(Thread, interpSave.retval);
-    opRegRegImm(cUnit, kOpAdd, r4PC, r6SELF, offset);
-    opImm(cUnit, kOpPush, (1<<r4PC) | (1<<r7));
+#ifdef WITH_TAINT_TRACKING
+    int offset_rtaint = offsetof(Thread, interpSave.rtaint);
+
+//    opRegRegImm(cUnit, kOpAdd, r4PC, r6SELF, offset);
+//    opImm(cUnit, kOpPush, (1<<r4PC) | (1<<r7));
+    // using r2, r3, r4PC, r7 as temps
+    opRegRegImm(cUnit, kOpAdd, r7, r6SELF, offset);
+    opRegRegImm(cUnit, kOpAdd, r4PC, r6SELF, offset_rtaint);
+    loadConstant(cUnit, r2, 0);
+    loadConstant(cUnit, r3, 0);
+    if (dInsn->vA > 1)
+        loadTaintDirect(cUnit, dvmCompilerGetSrc(cUnit, mir, 1), r3);
+    if (dInsn->vA > 0)
+        loadTaintDirect(cUnit, dvmCompilerGetSrc(cUnit, mir, 0), r2);
+    opImm(cUnit, kOpPush, (1<<r2) | (1<<r3) | (1<<r4PC) | (1<<r7) );    // push arg0_taint, arg1_taint, push rtaint, retval
+#endif /*WITH_TAINT_TRACKING*/
     LOAD_FUNC_ADDR(cUnit, r4PC, fn);
     genExportPC(cUnit, mir);
     for (i=0; i < dInsn->vA; i++) {
         loadValueDirect(cUnit, dvmCompilerGetSrc(cUnit, mir, i), i);
     }
     opReg(cUnit, kOpBlx, r4PC);
-    opRegImm(cUnit, kOpAdd, r13sp, 8);
+#ifdef WITH_TAINT_TRACKING
+     opRegImm(cUnit, kOpAdd, r13sp, 16);
+#else
+     opRegImm(cUnit, kOpAdd, r13sp, 8);
+#endif /*WITH_TAINT_TRACKING*/
     /* NULL? */
     ArmLIR *branchOver = genCmpImmBranch(cUnit, kArmCondNe, r0, 0);
     loadConstant(cUnit, r0, (int) (cUnit->method->insns + mir->offset));
@@ -3693,6 +4524,9 @@ static bool handleFmt51l(CompilationUnit *cUnit, MIR *mir)
     loadConstantNoClobber(cUnit, rlResult.highReg,
                           (mir->dalvikInsn.vB_wide>>32) & 0xFFFFFFFFUL);
     storeValueWide(cUnit, rlDest, rlResult);
+#ifdef WITH_TAINT_TRACKING
+    setTaintClearWide(cUnit, rlDest);
+#endif /*WITH_TAINT_TRACKING*/
     return false;
 }
 
diff --git a/vm/compiler/codegen/arm/FP/Thumb2VFP.cpp b/vm/compiler/codegen/arm/FP/Thumb2VFP.cpp
index abbf2c9..dba5443 100644
--- a/vm/compiler/codegen/arm/FP/Thumb2VFP.cpp
+++ b/vm/compiler/codegen/arm/FP/Thumb2VFP.cpp
@@ -205,6 +205,12 @@ static bool genInlineSqrt(CompilationUnit *cUnit, MIR *mir)
     label->defMask = ENCODE_ALL;
     branch->generic.target = (LIR *)label;
     storeValueWide(cUnit, rlDest, rlResult);
+#ifdef WITH_TAINT_TRACKING
+    int taint = dvmCompilerAllocTemp(cUnit);
+    loadTaintDirect(cUnit, rlSrc, taint);
+    storeTaintDirectWide(cUnit, rlDest, taint);
+    dvmCompilerFreeTemp(cUnit, taint);
+#endif /*WITH_TAINT_TRACKING*/
     return false;
 }
 
diff --git a/vm/compiler/codegen/arm/Thumb2/Gen.cpp b/vm/compiler/codegen/arm/Thumb2/Gen.cpp
index ea64547..6a8989f 100644
--- a/vm/compiler/codegen/arm/Thumb2/Gen.cpp
+++ b/vm/compiler/codegen/arm/Thumb2/Gen.cpp
@@ -411,6 +411,12 @@ static bool genInlinedAbsFloat(CompilationUnit *cUnit, MIR *mir)
     RegLocation rlResult = dvmCompilerEvalLoc(cUnit, rlDest, kFPReg, true);
     newLIR2(cUnit, kThumb2Vabss, rlResult.lowReg, rlSrc.lowReg);
     storeValue(cUnit, rlDest, rlResult);
+#ifdef WITH_TAINT_TRACKING
+    int taint = dvmCompilerAllocTemp(cUnit);
+    loadTaintDirect(cUnit, rlSrc, taint);
+    storeTaintDirect(cUnit, rlDest, taint);
+    dvmCompilerFreeTemp(cUnit, taint);
+#endif /*WITH_TAINT_TRACKING*/
     return false;
 }
 
@@ -423,6 +429,12 @@ static bool genInlinedAbsDouble(CompilationUnit *cUnit, MIR *mir)
     newLIR2(cUnit, kThumb2Vabsd, S2D(rlResult.lowReg, rlResult.highReg),
             S2D(rlSrc.lowReg, rlSrc.highReg));
     storeValueWide(cUnit, rlDest, rlResult);
+#ifdef WITH_TAINT_TRACKING
+    int taint = dvmCompilerAllocTemp(cUnit);
+    loadTaintDirect(cUnit, rlSrc, taint);
+    storeTaintDirectWide(cUnit, rlDest, taint);
+    dvmCompilerFreeTemp(cUnit, taint);
+#endif /*WITH_TAINT_TRACKING*/
     return false;
 }
 
diff --git a/vm/compiler/codegen/arm/armv7-a-neon/ArchVariant.cpp b/vm/compiler/codegen/arm/armv7-a-neon/ArchVariant.cpp
index e3b2724..5e2c35e 100644
--- a/vm/compiler/codegen/arm/armv7-a-neon/ArchVariant.cpp
+++ b/vm/compiler/codegen/arm/armv7-a-neon/ArchVariant.cpp
@@ -27,7 +27,11 @@ JitInstructionSetType dvmCompilerInstructionSet(void)
 
 /* First, declare dvmCompiler_TEMPLATE_XXX for each template */
 #define JIT_TEMPLATE(X) extern "C" void dvmCompiler_TEMPLATE_##X();
+#ifdef WITH_TAINT_TRACKING
+#include "../../../template/armv5te-vfp_taint/TemplateOpList.h"
+#else
 #include "../../../template/armv5te-vfp/TemplateOpList.h"
+#endif /*WITH_TAINT_TRACKING*/
 #undef JIT_TEMPLATE
 
 /* Architecture-specific initializations and checks go here */
@@ -41,7 +45,11 @@ bool dvmCompilerArchVariantInit(void)
      */
 #define JIT_TEMPLATE(X) templateEntryOffsets[i++] = \
     (intptr_t) dvmCompiler_TEMPLATE_##X - (intptr_t) dvmCompilerTemplateStart;
+#ifdef WITH_TAINT_TRACKING
+#include "../../../template/armv5te-vfp_taint/TemplateOpList.h"
+#else
 #include "../../../template/armv5te-vfp/TemplateOpList.h"
+#endif /*WITH_TAINT_TRACKING*/
 #undef JIT_TEMPLATE
 
     /* Target-specific configuration */
@@ -57,11 +65,20 @@ bool dvmCompilerArchVariantInit(void)
 #endif
 
     /* Codegen-specific assumptions */
+#ifdef WITH_TAINT_TRACKING
+    assert(OFFSETOF_MEMBER(ClassObject, vtable) < 144 &&
+           (OFFSETOF_MEMBER(ClassObject, vtable) & 0x3) == 0);
+    assert(OFFSETOF_MEMBER(ArrayObject, length) < 128 &&
+           (OFFSETOF_MEMBER(ArrayObject, length) & 0x3) == 0);
+    assert(OFFSETOF_MEMBER(ArrayObject, contents) < 256);
+#else
+    /* Codegen-specific assumptions */
     assert(OFFSETOF_MEMBER(ClassObject, vtable) < 128 &&
            (OFFSETOF_MEMBER(ClassObject, vtable) & 0x3) == 0);
     assert(OFFSETOF_MEMBER(ArrayObject, length) < 128 &&
            (OFFSETOF_MEMBER(ArrayObject, length) & 0x3) == 0);
     assert(OFFSETOF_MEMBER(ArrayObject, contents) < 256);
+#endif /*WITH_TAINT_TRACKING*/
 
     /* Up to 5 args are pushed on top of FP - sizeofStackSaveArea */
     assert(sizeof(StackSaveArea) < 236);
@@ -71,7 +88,11 @@ bool dvmCompilerArchVariantInit(void)
      * offset from the struct is less than 128.
      */
     if ((offsetof(Thread, jitToInterpEntries) +
+#ifdef WITH_TAINT_TRACKING
+         sizeof(struct JitToInterpEntries)) >= 136) {
+#else
          sizeof(struct JitToInterpEntries)) >= 128) {
+#endif /*WITH_TAINT_TRACKING*/
         ALOGE("Thread.jitToInterpEntries size overflow");
         dvmAbort();
     }
@@ -79,6 +100,17 @@ bool dvmCompilerArchVariantInit(void)
     /* FIXME - comment out the following to enable method-based JIT */
     gDvmJit.disableOpt |= (1 << kMethodJit);
 
+    // PJG: uncomment to disable JIT optimizations
+    //gDvmJit.disableOpt |= (1 << kLoadStoreElimination);
+    //gDvmJit.disableOpt |= (1 << kLoadHoisting);
+    //gDvmJit.disableOpt |= (1 << kTrackLiveTemps);
+    //gDvmJit.disableOpt |= (1 << kSuppressLoads);
+    //gDvmJit.disableOpt |= (1 << kMethodInlining);
+    //gDvmJit.disableOpt |= (1 << kMethodJit);
+
+    // PJG: uncomment to enable JIT debug printing
+    //gDvmJit.printMe = true;
+
     // Make sure all threads have current values
     dvmJitUpdateThreadStateAll();
 
diff --git a/vm/compiler/codegen/arm/armv7-a-neon/ArchVariant.h b/vm/compiler/codegen/arm/armv7-a-neon/ArchVariant.h
index 33e262c..77b1fb3 100644
--- a/vm/compiler/codegen/arm/armv7-a-neon/ArchVariant.h
+++ b/vm/compiler/codegen/arm/armv7-a-neon/ArchVariant.h
@@ -20,7 +20,11 @@
 /* Create the TemplateOpcode enum */
 #define JIT_TEMPLATE(X) TEMPLATE_##X,
 typedef enum {
+#ifdef WITH_TAINT_TRACKING
+#include "../../../template/armv5te-vfp_taint/TemplateOpList.h"
+#else
 #include "../../../template/armv5te-vfp/TemplateOpList.h"
+#endif /*WITH_TAINT_TRACKING*/
 /*
  * For example,
  *     TEMPLATE_CMP_LONG,
diff --git a/vm/compiler/codegen/arm/armv7-a-neon/MethodCodegenDriver.cpp b/vm/compiler/codegen/arm/armv7-a-neon/MethodCodegenDriver.cpp
index 222b880..fd9f716 100644
--- a/vm/compiler/codegen/arm/armv7-a-neon/MethodCodegenDriver.cpp
+++ b/vm/compiler/codegen/arm/armv7-a-neon/MethodCodegenDriver.cpp
@@ -55,9 +55,16 @@ static void genMethodInflateAndPunt(CompilationUnit *cUnit, MIR *mir,
     /* Send everything to home location */
     dvmCompilerFlushAllRegs(cUnit);
 
+#ifdef WITH_TAINT_TRACKING
+    // PJG: FIXME: is this correct?
+    /* oldStackSave = r5FP + sizeof(current frame) */
+    opRegRegImm(cUnit, kOpAdd, oldStackSave, r5FP,
+                cUnit->method->registersSize * 8 + 4);
+#else
     /* oldStackSave = r5FP + sizeof(current frame) */
     opRegRegImm(cUnit, kOpAdd, oldStackSave, r5FP,
                 cUnit->method->registersSize * 4);
+#endif /*WITH_TAINT_TRACKING*/
     /* oldFP = oldStackSave + sizeof(stackSaveArea) */
     opRegRegImm(cUnit, kOpAdd, oldFP, oldStackSave, sizeof(StackSaveArea));
     /* newStackSave = r5FP - sizeof(StackSaveArea) */
@@ -121,6 +128,7 @@ static bool handleMethodFmt10t_Fmt20t_Fmt30t(CompilationUnit *cUnit, MIR *mir,
 static bool handleMethodFmt10x(CompilationUnit *cUnit, MIR *mir)
 {
     Opcode dalvikOpcode = mir->dalvikInsn.opcode;
+// PJG: TODO: clear return taint?
     switch (dalvikOpcode) {
         case OP_RETURN_VOID:
             return false;
@@ -258,8 +266,14 @@ static bool methodBlockCodeGen(CompilationUnit *cUnit, BasicBlock *bb)
     if (bb->blockType == kEntryBlock) {
         /* r0 = callsitePC */
         opImm(cUnit, kOpPush, (1 << r0 | 1 << r1 | 1 << r5FP | 1 << r14lr));
+#ifdef WITH_TAINT_TRACKING
+        // PJG: FIXME: is this correct?
+        opRegImm(cUnit, kOpSub, r5FP,
+                 sizeof(StackSaveArea) + cUnit->method->registersSize * 8 + 4);
+#else
         opRegImm(cUnit, kOpSub, r5FP,
                  sizeof(StackSaveArea) + cUnit->method->registersSize * 4);
+#endif /*WITH_TAINT_TRACKING*/
 
     } else if (bb->blockType == kExitBlock) {
         /* No need to pop r0 and r1 */
diff --git a/vm/compiler/codegen/arm/armv7-a/ArchVariant.cpp b/vm/compiler/codegen/arm/armv7-a/ArchVariant.cpp
index e3b2724..2d6e5a9 100644
--- a/vm/compiler/codegen/arm/armv7-a/ArchVariant.cpp
+++ b/vm/compiler/codegen/arm/armv7-a/ArchVariant.cpp
@@ -27,7 +27,11 @@ JitInstructionSetType dvmCompilerInstructionSet(void)
 
 /* First, declare dvmCompiler_TEMPLATE_XXX for each template */
 #define JIT_TEMPLATE(X) extern "C" void dvmCompiler_TEMPLATE_##X();
+#ifdef WITH_TAINT_TRACKING
+#include "../../../template/armv5te-vfp_taint/TemplateOpList.h"
+#else
 #include "../../../template/armv5te-vfp/TemplateOpList.h"
+#endif /*WITH_TAINT_TRACKING*/
 #undef JIT_TEMPLATE
 
 /* Architecture-specific initializations and checks go here */
@@ -41,7 +45,11 @@ bool dvmCompilerArchVariantInit(void)
      */
 #define JIT_TEMPLATE(X) templateEntryOffsets[i++] = \
     (intptr_t) dvmCompiler_TEMPLATE_##X - (intptr_t) dvmCompilerTemplateStart;
+#ifdef WITH_TAINT_TRACKING
+#include "../../../template/armv5te-vfp_taint/TemplateOpList.h"
+#else
 #include "../../../template/armv5te-vfp/TemplateOpList.h"
+#endif /*WITH_TAINT_TRACKING*/
 #undef JIT_TEMPLATE
 
     /* Target-specific configuration */
@@ -57,11 +65,20 @@ bool dvmCompilerArchVariantInit(void)
 #endif
 
     /* Codegen-specific assumptions */
+#ifdef WITH_TAINT_TRACKING
+    assert(OFFSETOF_MEMBER(ClassObject, vtable) < 144 &&
+           (OFFSETOF_MEMBER(ClassObject, vtable) & 0x3) == 0);
+    assert(OFFSETOF_MEMBER(ArrayObject, length) < 128 &&
+           (OFFSETOF_MEMBER(ArrayObject, length) & 0x3) == 0);
+    assert(OFFSETOF_MEMBER(ArrayObject, contents) < 256);
+#else
+    /* Codegen-specific assumptions */
     assert(OFFSETOF_MEMBER(ClassObject, vtable) < 128 &&
            (OFFSETOF_MEMBER(ClassObject, vtable) & 0x3) == 0);
     assert(OFFSETOF_MEMBER(ArrayObject, length) < 128 &&
            (OFFSETOF_MEMBER(ArrayObject, length) & 0x3) == 0);
     assert(OFFSETOF_MEMBER(ArrayObject, contents) < 256);
+#endif /*WITH_TAINT_TRACKING*/
 
     /* Up to 5 args are pushed on top of FP - sizeofStackSaveArea */
     assert(sizeof(StackSaveArea) < 236);
@@ -71,7 +88,11 @@ bool dvmCompilerArchVariantInit(void)
      * offset from the struct is less than 128.
      */
     if ((offsetof(Thread, jitToInterpEntries) +
+#ifdef WITH_TAINT_TRACKING
+         sizeof(struct JitToInterpEntries)) >= 136) {
+#else
          sizeof(struct JitToInterpEntries)) >= 128) {
+#endif /*WITH_TAINT_TRACKING*/
         ALOGE("Thread.jitToInterpEntries size overflow");
         dvmAbort();
     }
diff --git a/vm/compiler/codegen/arm/armv7-a/ArchVariant.h b/vm/compiler/codegen/arm/armv7-a/ArchVariant.h
index b4f4eb7..ca616c9 100644
--- a/vm/compiler/codegen/arm/armv7-a/ArchVariant.h
+++ b/vm/compiler/codegen/arm/armv7-a/ArchVariant.h
@@ -20,7 +20,11 @@
 /* Create the TemplateOpcode enum */
 #define JIT_TEMPLATE(X) TEMPLATE_##X,
 enum TemplateOpcode {
+#ifdef WITH_TAINT_TRACKING
+#include "../../../template/armv5te-vfp_taint/TemplateOpList.h"
+#else
 #include "../../../template/armv5te-vfp/TemplateOpList.h"
+#endif /*WITH_TAINT_TRACKING*/
 /*
  * For example,
  *     TEMPLATE_CMP_LONG,
diff --git a/vm/compiler/template/armv5te-vfp_taint/TEMPLATE_ADD_DOUBLE_VFP.S b/vm/compiler/template/armv5te-vfp_taint/TEMPLATE_ADD_DOUBLE_VFP.S
new file mode 100644
index 0000000..51693fa
--- /dev/null
+++ b/vm/compiler/template/armv5te-vfp_taint/TEMPLATE_ADD_DOUBLE_VFP.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te-vfp/fbinopWide.S" {"instr":"faddd   d2, d0, d1"}
diff --git a/vm/compiler/template/armv5te-vfp_taint/TEMPLATE_ADD_FLOAT_VFP.S b/vm/compiler/template/armv5te-vfp_taint/TEMPLATE_ADD_FLOAT_VFP.S
new file mode 100644
index 0000000..ad1e122
--- /dev/null
+++ b/vm/compiler/template/armv5te-vfp_taint/TEMPLATE_ADD_FLOAT_VFP.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te-vfp/fbinop.S" {"instr":"fadds   s2, s0, s1"}
diff --git a/vm/compiler/template/armv5te-vfp_taint/TEMPLATE_CMPG_DOUBLE_VFP.S b/vm/compiler/template/armv5te-vfp_taint/TEMPLATE_CMPG_DOUBLE_VFP.S
new file mode 100644
index 0000000..992c894
--- /dev/null
+++ b/vm/compiler/template/armv5te-vfp_taint/TEMPLATE_CMPG_DOUBLE_VFP.S
@@ -0,0 +1,33 @@
+%verify "executed"
+%verify "basic lt, gt, eq */
+%verify "left arg NaN"
+%verify "right arg NaN"
+    /*
+     * Compare two floating-point values.  Puts 0, 1, or -1 into the
+     * destination register based on the results of the comparison.
+     *
+     * int compare(x, y) {
+     *     if (x == y) {
+     *         return 0;
+     *     } else if (x < y) {
+     *         return -1;
+     *     } else if (x > y) {
+     *         return 1;
+     *     } else {
+     *         return 1;
+     *     }
+     * }
+     *
+     * On entry:
+     *    r0 = &op1 [vBB]
+     *    r1 = &op2 [vCC]
+     */
+    /* op vAA, vBB, vCC */
+    fldd    d0, [r0]                    @ d0<- vBB
+    fldd    d1, [r1]                    @ d1<- vCC
+    fcmpd  d0, d1                       @ compare (vBB, vCC)
+    mov     r0, #1                      @ r0<- 1 (default)
+    fmstat                              @ export status flags
+    mvnmi   r0, #0                      @ (less than) r0<- -1
+    moveq   r0, #0                      @ (equal) r0<- 0
+    bx      lr
diff --git a/vm/compiler/template/armv5te-vfp_taint/TEMPLATE_CMPG_FLOAT_VFP.S b/vm/compiler/template/armv5te-vfp_taint/TEMPLATE_CMPG_FLOAT_VFP.S
new file mode 100644
index 0000000..0510ef6
--- /dev/null
+++ b/vm/compiler/template/armv5te-vfp_taint/TEMPLATE_CMPG_FLOAT_VFP.S
@@ -0,0 +1,32 @@
+%verify "executed"
+%verify "basic lt, gt, eq */
+%verify "left arg NaN"
+%verify "right arg NaN"
+    /*
+     * Compare two floating-point values.  Puts 0, 1, or -1 into the
+     * destination register based on the results of the comparison.
+     *
+     * int compare(x, y) {
+     *     if (x == y) {
+     *         return 0;
+     *     } else if (x < y) {
+     *         return -1;
+     *     } else if (x > y) {
+     *         return 1;
+     *     } else {
+     *         return 1;
+     *     }
+     * }
+     * On entry:
+     *    r0 = &op1 [vBB]
+     *    r1 = &op2 [vCC]
+     */
+    /* op vAA, vBB, vCC */
+    flds    s0, [r0]                    @ d0<- vBB
+    flds    s1, [r1]                    @ d1<- vCC
+    fcmps  s0, s1                      @ compare (vBB, vCC)
+    mov     r0, #1                      @ r0<- 1 (default)
+    fmstat                              @ export status flags
+    mvnmi   r0, #0                      @ (less than) r0<- -1
+    moveq   r0, #0                      @ (equal) r0<- 0
+    bx      lr
diff --git a/vm/compiler/template/armv5te-vfp_taint/TEMPLATE_CMPL_DOUBLE_VFP.S b/vm/compiler/template/armv5te-vfp_taint/TEMPLATE_CMPL_DOUBLE_VFP.S
new file mode 100644
index 0000000..7241af1
--- /dev/null
+++ b/vm/compiler/template/armv5te-vfp_taint/TEMPLATE_CMPL_DOUBLE_VFP.S
@@ -0,0 +1,32 @@
+%verify "executed"
+%verify "basic lt, gt, eq */
+%verify "left arg NaN"
+%verify "right arg NaN"
+    /*
+     * Compare two floating-point values.  Puts 0, 1, or -1 into the
+     * destination register based on the results of the comparison.
+     *
+     * int compare(x, y) {
+     *     if (x == y) {
+     *         return 0;
+     *     } else if (x > y) {
+     *         return 1;
+     *     } else if (x < y) {
+     *         return -1;
+     *     } else {
+     *         return -1;
+     *     }
+     * }
+     * On entry:
+     *    r0 = &op1 [vBB]
+     *    r1 = &op2 [vCC]
+     */
+    /* op vAA, vBB, vCC */
+    fldd    d0, [r0]                    @ d0<- vBB
+    fldd    d1, [r1]                    @ d1<- vCC
+    fcmped  d0, d1                      @ compare (vBB, vCC)
+    mvn     r0, #0                      @ r0<- -1 (default)
+    fmstat                              @ export status flags
+    movgt   r0, #1                      @ (greater than) r0<- 1
+    moveq   r0, #0                      @ (equal) r0<- 0
+    bx      lr
diff --git a/vm/compiler/template/armv5te-vfp_taint/TEMPLATE_CMPL_FLOAT_VFP.S b/vm/compiler/template/armv5te-vfp_taint/TEMPLATE_CMPL_FLOAT_VFP.S
new file mode 100644
index 0000000..bdb42d6
--- /dev/null
+++ b/vm/compiler/template/armv5te-vfp_taint/TEMPLATE_CMPL_FLOAT_VFP.S
@@ -0,0 +1,32 @@
+%verify "executed"
+%verify "basic lt, gt, eq */
+%verify "left arg NaN"
+%verify "right arg NaN"
+    /*
+     * Compare two floating-point values.  Puts 0, 1, or -1 into the
+     * destination register based on the results of the comparison.
+     *
+     * int compare(x, y) {
+     *     if (x == y) {
+     *         return 0;
+     *     } else if (x > y) {
+     *         return 1;
+     *     } else if (x < y) {
+     *         return -1;
+     *     } else {
+     *         return -1;
+     *     }
+     * }
+     * On entry:
+     *    r0 = &op1 [vBB]
+     *    r1 = &op2 [vCC]
+     */
+    /* op vAA, vBB, vCC */
+    flds    s0, [r0]                    @ d0<- vBB
+    flds    s1, [r1]                    @ d1<- vCC
+    fcmps  s0, s1                      @ compare (vBB, vCC)
+    mvn     r0, #0                      @ r0<- -1 (default)
+    fmstat                              @ export status flags
+    movgt   r0, #1                      @ (greater than) r0<- 1
+    moveq   r0, #0                      @ (equal) r0<- 0
+    bx      lr
diff --git a/vm/compiler/template/armv5te-vfp_taint/TEMPLATE_DIV_DOUBLE_VFP.S b/vm/compiler/template/armv5te-vfp_taint/TEMPLATE_DIV_DOUBLE_VFP.S
new file mode 100644
index 0000000..8fa58b8
--- /dev/null
+++ b/vm/compiler/template/armv5te-vfp_taint/TEMPLATE_DIV_DOUBLE_VFP.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te-vfp/fbinopWide.S" {"instr":"fdivd   d2, d0, d1"}
diff --git a/vm/compiler/template/armv5te-vfp_taint/TEMPLATE_DIV_FLOAT_VFP.S b/vm/compiler/template/armv5te-vfp_taint/TEMPLATE_DIV_FLOAT_VFP.S
new file mode 100644
index 0000000..fc125ce
--- /dev/null
+++ b/vm/compiler/template/armv5te-vfp_taint/TEMPLATE_DIV_FLOAT_VFP.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te-vfp/fbinop.S" {"instr":"fdivs   s2, s0, s1"}
diff --git a/vm/compiler/template/armv5te-vfp_taint/TEMPLATE_DOUBLE_TO_FLOAT_VFP.S b/vm/compiler/template/armv5te-vfp_taint/TEMPLATE_DOUBLE_TO_FLOAT_VFP.S
new file mode 100644
index 0000000..dba3b08
--- /dev/null
+++ b/vm/compiler/template/armv5te-vfp_taint/TEMPLATE_DOUBLE_TO_FLOAT_VFP.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te-vfp/funopNarrower.S" {"instr":"fcvtsd  s0, d0"}
diff --git a/vm/compiler/template/armv5te-vfp_taint/TEMPLATE_DOUBLE_TO_INT_VFP.S b/vm/compiler/template/armv5te-vfp_taint/TEMPLATE_DOUBLE_TO_INT_VFP.S
new file mode 100644
index 0000000..4d910aa
--- /dev/null
+++ b/vm/compiler/template/armv5te-vfp_taint/TEMPLATE_DOUBLE_TO_INT_VFP.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te-vfp/funopNarrower.S" {"instr":"ftosizd  s0, d0"}
diff --git a/vm/compiler/template/armv5te-vfp_taint/TEMPLATE_FLOAT_TO_DOUBLE_VFP.S b/vm/compiler/template/armv5te-vfp_taint/TEMPLATE_FLOAT_TO_DOUBLE_VFP.S
new file mode 100644
index 0000000..a5157dd
--- /dev/null
+++ b/vm/compiler/template/armv5te-vfp_taint/TEMPLATE_FLOAT_TO_DOUBLE_VFP.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te-vfp/funopWider.S" {"instr":"fcvtds  d0, s0"}
diff --git a/vm/compiler/template/armv5te-vfp_taint/TEMPLATE_FLOAT_TO_INT_VFP.S b/vm/compiler/template/armv5te-vfp_taint/TEMPLATE_FLOAT_TO_INT_VFP.S
new file mode 100644
index 0000000..90900aa
--- /dev/null
+++ b/vm/compiler/template/armv5te-vfp_taint/TEMPLATE_FLOAT_TO_INT_VFP.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te-vfp/funop.S" {"instr":"ftosizs s1, s0"}
diff --git a/vm/compiler/template/armv5te-vfp_taint/TEMPLATE_INT_TO_DOUBLE_VFP.S b/vm/compiler/template/armv5te-vfp_taint/TEMPLATE_INT_TO_DOUBLE_VFP.S
new file mode 100644
index 0000000..c9f4fd6
--- /dev/null
+++ b/vm/compiler/template/armv5te-vfp_taint/TEMPLATE_INT_TO_DOUBLE_VFP.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te-vfp/funopWider.S" {"instr":"fsitod  d0, s0"}
diff --git a/vm/compiler/template/armv5te-vfp_taint/TEMPLATE_INT_TO_FLOAT_VFP.S b/vm/compiler/template/armv5te-vfp_taint/TEMPLATE_INT_TO_FLOAT_VFP.S
new file mode 100644
index 0000000..a8f57b5
--- /dev/null
+++ b/vm/compiler/template/armv5te-vfp_taint/TEMPLATE_INT_TO_FLOAT_VFP.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te-vfp/funop.S" {"instr":"fsitos  s1, s0"}
diff --git a/vm/compiler/template/armv5te-vfp_taint/TEMPLATE_MEM_OP_DECODE.S b/vm/compiler/template/armv5te-vfp_taint/TEMPLATE_MEM_OP_DECODE.S
new file mode 100644
index 0000000..8bee853
--- /dev/null
+++ b/vm/compiler/template/armv5te-vfp_taint/TEMPLATE_MEM_OP_DECODE.S
@@ -0,0 +1,19 @@
+#if defined(WITH_SELF_VERIFICATION)
+    /*
+     * This handler encapsulates heap memory ops for selfVerification mode.
+     *
+     * The call to the handler is inserted prior to a heap memory operation.
+     * This handler then calls a function to decode the memory op, and process
+     * it accordingly. Afterwards, the handler changes the return address to
+     * skip the memory op so it never gets executed.
+     */
+    vpush   {d0-d15}                    @ save out all fp registers
+    push    {r0-r12,lr}                 @ save out all registers
+    ldr     r2, .LdvmSelfVerificationMemOpDecode @ defined in footer.S
+    mov     r0, lr                      @ arg0 <- link register
+    mov     r1, sp                      @ arg1 <- stack pointer
+    blx     r2                          @ decode and handle the mem op
+    pop     {r0-r12,lr}                 @ restore all registers
+    vpop    {d0-d15}                    @ restore all fp registers
+    bx      lr                          @ return to compiled code
+#endif
diff --git a/vm/compiler/template/armv5te-vfp_taint/TEMPLATE_MUL_DOUBLE_VFP.S b/vm/compiler/template/armv5te-vfp_taint/TEMPLATE_MUL_DOUBLE_VFP.S
new file mode 100644
index 0000000..459e796
--- /dev/null
+++ b/vm/compiler/template/armv5te-vfp_taint/TEMPLATE_MUL_DOUBLE_VFP.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te-vfp/fbinopWide.S" {"instr":"fmuld   d2, d0, d1"}
diff --git a/vm/compiler/template/armv5te-vfp_taint/TEMPLATE_MUL_FLOAT_VFP.S b/vm/compiler/template/armv5te-vfp_taint/TEMPLATE_MUL_FLOAT_VFP.S
new file mode 100644
index 0000000..301fa84
--- /dev/null
+++ b/vm/compiler/template/armv5te-vfp_taint/TEMPLATE_MUL_FLOAT_VFP.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te-vfp/fbinop.S" {"instr":"fmuls   s2, s0, s1"}
diff --git a/vm/compiler/template/armv5te-vfp_taint/TEMPLATE_RESTORE_STATE.S b/vm/compiler/template/armv5te-vfp_taint/TEMPLATE_RESTORE_STATE.S
new file mode 100644
index 0000000..196d082
--- /dev/null
+++ b/vm/compiler/template/armv5te-vfp_taint/TEMPLATE_RESTORE_STATE.S
@@ -0,0 +1,11 @@
+    /*
+     * This handler restores state following a selfVerification memory access.
+     * On entry:
+     *    r0 - offset from rSELF to the 1st element of the coreRegs save array.
+     */
+    add     r0, r0, rSELF               @ pointer to heapArgSpace.coreRegs[0]
+    add     r0, #64                     @ pointer to heapArgSpace.fpRegs[0]
+    vldmia  r0, {d0-d15}
+    sub     r0, #64                     @ pointer to heapArgSpace.coreRegs[0]
+    ldmia   r0, {r0-r12}
+    bx      lr
diff --git a/vm/compiler/template/armv5te-vfp_taint/TEMPLATE_SAVE_STATE.S b/vm/compiler/template/armv5te-vfp_taint/TEMPLATE_SAVE_STATE.S
new file mode 100644
index 0000000..11f62b7
--- /dev/null
+++ b/vm/compiler/template/armv5te-vfp_taint/TEMPLATE_SAVE_STATE.S
@@ -0,0 +1,23 @@
+    /*
+     * This handler performs a register save for selfVerification mode.
+     * On entry:
+     *    Top of stack + 4: r7 value to save
+     *    Top of stack + 0: r0 value to save
+     *    r0 - offset from rSELF to the beginning of the heapArgSpace record
+     *    r7 - the value of regMap
+     *
+     * The handler must save regMap, r0-r12 and then return with r0-r12
+     * with their original values (note that this means r0 and r7 must take
+     * the values on the stack - not the ones in those registers on entry.
+     * Finally, the two registers previously pushed must be popped.
+     */
+    add     r0, r0, rSELF               @ pointer to heapArgSpace
+    stmia   r0!, {r7}                   @ save regMap
+    ldr     r7, [r13, #0]               @ recover r0 value
+    stmia   r0!, {r7}                   @ save r0
+    ldr     r7, [r13, #4]               @ recover r7 value
+    stmia   r0!, {r1-r12}
+    add     r0, #12                     @ move to start of FP save regio
+    vstmia  r0, {d0-d15}
+    pop     {r0, r7}                    @ recover r0, r7
+    bx      lr
diff --git a/vm/compiler/template/armv5te-vfp_taint/TEMPLATE_SQRT_DOUBLE_VFP.S b/vm/compiler/template/armv5te-vfp_taint/TEMPLATE_SQRT_DOUBLE_VFP.S
new file mode 100644
index 0000000..1c6bb46
--- /dev/null
+++ b/vm/compiler/template/armv5te-vfp_taint/TEMPLATE_SQRT_DOUBLE_VFP.S
@@ -0,0 +1,23 @@
+%verify "executed"
+    /*
+     * 64-bit floating point vfp sqrt operation.
+     * If the result is a NaN, bail out to library code to do
+     * the right thing.
+     *
+     * On entry:
+     *     r2 src addr of op1
+     * On exit:
+     *     r0,r1 = res
+     */
+    fldd    d0, [r2]
+    fsqrtd  d1, d0
+    fcmpd   d1, d1
+    fmstat
+    fmrrd   r0, r1, d1
+    bxeq    lr   @ Result OK - return
+    ldr     r2, .Lsqrt
+    fmrrd   r0, r1, d0   @ reload orig operand
+    bx      r2   @ tail call to sqrt library routine
+
+.Lsqrt:
+    .word   sqrt
diff --git a/vm/compiler/template/armv5te-vfp_taint/TEMPLATE_SUB_DOUBLE_VFP.S b/vm/compiler/template/armv5te-vfp_taint/TEMPLATE_SUB_DOUBLE_VFP.S
new file mode 100644
index 0000000..8fa20a0
--- /dev/null
+++ b/vm/compiler/template/armv5te-vfp_taint/TEMPLATE_SUB_DOUBLE_VFP.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te-vfp/fbinopWide.S" {"instr":"fsubd   d2, d0, d1"}
diff --git a/vm/compiler/template/armv5te-vfp_taint/TEMPLATE_SUB_FLOAT_VFP.S b/vm/compiler/template/armv5te-vfp_taint/TEMPLATE_SUB_FLOAT_VFP.S
new file mode 100644
index 0000000..5e17e51
--- /dev/null
+++ b/vm/compiler/template/armv5te-vfp_taint/TEMPLATE_SUB_FLOAT_VFP.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te-vfp/fbinop.S" {"instr":"fsubs   s2, s0, s1"}
diff --git a/vm/compiler/template/armv5te-vfp_taint/TemplateOpList.h b/vm/compiler/template/armv5te-vfp_taint/TemplateOpList.h
new file mode 100644
index 0000000..0365ba4
--- /dev/null
+++ b/vm/compiler/template/armv5te-vfp_taint/TemplateOpList.h
@@ -0,0 +1,65 @@
+/*
+ * Copyright (C) 2009 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+/*
+ * Dalvik opcode list that uses additional templates to complete JIT execution.
+ */
+#ifndef JIT_TEMPLATE
+#define JIT_TEMPLATE(X)
+#endif
+
+JIT_TEMPLATE(CMP_LONG)
+JIT_TEMPLATE(RETURN)
+JIT_TEMPLATE(INVOKE_METHOD_NO_OPT)
+JIT_TEMPLATE(INVOKE_METHOD_CHAIN)
+JIT_TEMPLATE(INVOKE_METHOD_PREDICTED_CHAIN)
+JIT_TEMPLATE(INVOKE_METHOD_NATIVE)
+JIT_TEMPLATE(MUL_LONG)
+JIT_TEMPLATE(SHL_LONG)
+JIT_TEMPLATE(SHR_LONG)
+JIT_TEMPLATE(USHR_LONG)
+JIT_TEMPLATE(ADD_FLOAT_VFP)
+JIT_TEMPLATE(SUB_FLOAT_VFP)
+JIT_TEMPLATE(MUL_FLOAT_VFP)
+JIT_TEMPLATE(DIV_FLOAT_VFP)
+JIT_TEMPLATE(ADD_DOUBLE_VFP)
+JIT_TEMPLATE(SUB_DOUBLE_VFP)
+JIT_TEMPLATE(MUL_DOUBLE_VFP)
+JIT_TEMPLATE(DIV_DOUBLE_VFP)
+JIT_TEMPLATE(DOUBLE_TO_FLOAT_VFP)
+JIT_TEMPLATE(DOUBLE_TO_INT_VFP)
+JIT_TEMPLATE(FLOAT_TO_DOUBLE_VFP)
+JIT_TEMPLATE(FLOAT_TO_INT_VFP)
+JIT_TEMPLATE(INT_TO_DOUBLE_VFP)
+JIT_TEMPLATE(INT_TO_FLOAT_VFP)
+JIT_TEMPLATE(CMPG_DOUBLE_VFP)
+JIT_TEMPLATE(CMPL_DOUBLE_VFP)
+JIT_TEMPLATE(CMPG_FLOAT_VFP)
+JIT_TEMPLATE(CMPL_FLOAT_VFP)
+JIT_TEMPLATE(SQRT_DOUBLE_VFP)
+JIT_TEMPLATE(THROW_EXCEPTION_COMMON)
+JIT_TEMPLATE(MEM_OP_DECODE)
+JIT_TEMPLATE(STRING_COMPARETO)
+JIT_TEMPLATE(STRING_INDEXOF)
+JIT_TEMPLATE(INTERPRET)
+JIT_TEMPLATE(MONITOR_ENTER)
+JIT_TEMPLATE(MONITOR_ENTER_DEBUG)
+JIT_TEMPLATE(PERIODIC_PROFILING)
+JIT_TEMPLATE(RETURN_PROF)
+JIT_TEMPLATE(INVOKE_METHOD_NO_OPT_PROF)
+JIT_TEMPLATE(INVOKE_METHOD_CHAIN_PROF)
+JIT_TEMPLATE(INVOKE_METHOD_PREDICTED_CHAIN_PROF)
+JIT_TEMPLATE(INVOKE_METHOD_NATIVE_PROF)
diff --git a/vm/compiler/template/armv5te-vfp_taint/fbinop.S b/vm/compiler/template/armv5te-vfp_taint/fbinop.S
new file mode 100644
index 0000000..3bc4b52
--- /dev/null
+++ b/vm/compiler/template/armv5te-vfp_taint/fbinop.S
@@ -0,0 +1,14 @@
+    /*
+     * Generic 32-bit floating point operation.  Provide an "instr" line that
+     * specifies an instruction that performs s2 = s0 op s1.
+     *
+     * On entry:
+     *     r0 = target dalvik register address
+     *     r1 = op1 address
+     *     r2 = op2 address
+     */
+     flds    s0,[r1]
+     flds    s1,[r2]
+     $instr
+     fsts    s2,[r0]
+     bx      lr
diff --git a/vm/compiler/template/armv5te-vfp_taint/fbinopWide.S b/vm/compiler/template/armv5te-vfp_taint/fbinopWide.S
new file mode 100644
index 0000000..3774646
--- /dev/null
+++ b/vm/compiler/template/armv5te-vfp_taint/fbinopWide.S
@@ -0,0 +1,14 @@
+    /*
+     * Generic 64-bit floating point operation.  Provide an "instr" line that
+     * specifies an instruction that performs s2 = s0 op s1.
+     *
+     * On entry:
+     *     r0 = target dalvik register address
+     *     r1 = op1 address
+     *     r2 = op2 address
+     */
+     fldd    d0,[r1]
+     fldd    d1,[r2]
+     $instr
+     fstd    d2,[r0]
+     bx      lr
diff --git a/vm/compiler/template/armv5te-vfp_taint/funop.S b/vm/compiler/template/armv5te-vfp_taint/funop.S
new file mode 100644
index 0000000..8409c28
--- /dev/null
+++ b/vm/compiler/template/armv5te-vfp_taint/funop.S
@@ -0,0 +1,15 @@
+    /*
+     * Generic 32bit-to-32bit floating point unary operation.  Provide an
+     * "instr" line that specifies an instruction that performs "s1 = op s0".
+     *
+     * For: float-to-int, int-to-float
+     *
+     * On entry:
+     *     r0 = target dalvik register address
+     *     r1 = src dalvik register address
+     */
+    /* unop vA, vB */
+    flds    s0, [r1]                    @ s0<- vB
+    $instr                              @ s1<- op s0
+    fsts    s1, [r0]                    @ vA<- s1
+    bx      lr
diff --git a/vm/compiler/template/armv5te-vfp_taint/funopNarrower.S b/vm/compiler/template/armv5te-vfp_taint/funopNarrower.S
new file mode 100644
index 0000000..8566fca
--- /dev/null
+++ b/vm/compiler/template/armv5te-vfp_taint/funopNarrower.S
@@ -0,0 +1,15 @@
+    /*
+     * Generic 64bit-to-32bit floating point unary operation.  Provide an
+     * "instr" line that specifies an instruction that performs "s0 = op d0".
+     *
+     * For: double-to-int, double-to-float
+     *
+     * On entry:
+     *     r0 = target dalvik register address
+     *     r1 = src dalvik register address
+     */
+    /* unop vA, vB */
+    fldd    d0, [r1]                    @ d0<- vB
+    $instr                              @ s0<- op d0
+    fsts    s0, [r0]                    @ vA<- s0
+    bx      lr
diff --git a/vm/compiler/template/armv5te-vfp_taint/funopWider.S b/vm/compiler/template/armv5te-vfp_taint/funopWider.S
new file mode 100644
index 0000000..dbe745c
--- /dev/null
+++ b/vm/compiler/template/armv5te-vfp_taint/funopWider.S
@@ -0,0 +1,15 @@
+    /*
+     * Generic 32bit-to-64bit floating point unary operation.  Provide an
+     * "instr" line that specifies an instruction that performs "d0 = op s0".
+     *
+     * For: int-to-double, float-to-double
+     *
+     * On entry:
+     *     r0 = target dalvik register address
+     *     r1 = src dalvik register address
+     */
+    /* unop vA, vB */
+    flds    s0, [r1]                    @ s0<- vB
+    $instr                              @ d0<- op s0
+    fstd    d0, [r0]                    @ vA<- d0
+    bx      lr
diff --git a/vm/compiler/template/armv5te-vfp_taint/platform.S b/vm/compiler/template/armv5te-vfp_taint/platform.S
new file mode 100644
index 0000000..e0666a5
--- /dev/null
+++ b/vm/compiler/template/armv5te-vfp_taint/platform.S
@@ -0,0 +1,5 @@
+/*
+ * ===========================================================================
+ *  CPU-version-specific defines and utility
+ * ===========================================================================
+ */
diff --git a/vm/compiler/template/armv5te_taint/TEMPLATE_CMPG_DOUBLE.S b/vm/compiler/template/armv5te_taint/TEMPLATE_CMPG_DOUBLE.S
new file mode 100644
index 0000000..f18f6d3
--- /dev/null
+++ b/vm/compiler/template/armv5te_taint/TEMPLATE_CMPG_DOUBLE.S
@@ -0,0 +1 @@
+%include "armv5te/TEMPLATE_CMPL_DOUBLE.S" { "naninst":"mov     r0, #1" }
diff --git a/vm/compiler/template/armv5te_taint/TEMPLATE_CMPG_FLOAT.S b/vm/compiler/template/armv5te_taint/TEMPLATE_CMPG_FLOAT.S
new file mode 100644
index 0000000..02887e5
--- /dev/null
+++ b/vm/compiler/template/armv5te_taint/TEMPLATE_CMPG_FLOAT.S
@@ -0,0 +1 @@
+%include "armv5te/TEMPLATE_CMPL_FLOAT.S" { "naninst":"mov     r0, #1" }
diff --git a/vm/compiler/template/armv5te_taint/TEMPLATE_CMPL_DOUBLE.S b/vm/compiler/template/armv5te_taint/TEMPLATE_CMPL_DOUBLE.S
new file mode 100644
index 0000000..4fd5a71
--- /dev/null
+++ b/vm/compiler/template/armv5te_taint/TEMPLATE_CMPL_DOUBLE.S
@@ -0,0 +1,38 @@
+%default { "naninst":"mvn     r0, #0" }
+    /*
+     * For the JIT: incoming arguments in r0-r1, r2-r3
+     *              result in r0
+     *
+     * Compare two floating-point values.  Puts 0, 1, or -1 into the
+     * destination register based on the results of the comparison.
+     *
+     * Provide a "naninst" instruction that puts 1 or -1 into r1 depending
+     * on what value we'd like to return when one of the operands is NaN.
+     *
+     * See OP_CMPL_FLOAT for an explanation.
+     *
+     * For: cmpl-double, cmpg-double
+     */
+    /* op vAA, vBB, vCC */
+    push    {r0-r3}                     @ save operands
+    mov     r11, lr                     @ save return address
+    mov     lr, pc
+    ldr     pc, .L__aeabi_cdcmple       @ PIC way of "bl __aeabi_cdcmple"
+    bhi     .L${opcode}_gt_or_nan       @ C set and Z clear, disambiguate
+    mvncc   r0, #0                      @ (less than) r1<- -1
+    moveq   r0, #0                      @ (equal) r1<- 0, trumps less than
+    add     sp, #16                     @ drop unused operands
+    bx      r11
+
+    @ Test for NaN with a second comparison.  EABI forbids testing bit
+    @ patterns, and we can't represent 0x7fc00000 in immediate form, so
+    @ make the library call.
+.L${opcode}_gt_or_nan:
+    pop     {r2-r3}                     @ restore operands in reverse order
+    pop     {r0-r1}                     @ restore operands in reverse order
+    mov     lr, pc
+    ldr     pc, .L__aeabi_cdcmple       @ r0<- Z set if eq, C clear if <
+    movcc   r0, #1                      @ (greater than) r1<- 1
+    bxcc    r11
+    $naninst                            @ r1<- 1 or -1 for NaN
+    bx      r11
diff --git a/vm/compiler/template/armv5te_taint/TEMPLATE_CMPL_FLOAT.S b/vm/compiler/template/armv5te_taint/TEMPLATE_CMPL_FLOAT.S
new file mode 100644
index 0000000..d0f2bec
--- /dev/null
+++ b/vm/compiler/template/armv5te_taint/TEMPLATE_CMPL_FLOAT.S
@@ -0,0 +1,56 @@
+%default { "naninst":"mvn     r0, #0" }
+    /*
+     * For the JIT: incoming arguments in r0-r1, r2-r3
+     *              result in r0
+     *
+     * Compare two floating-point values.  Puts 0, 1, or -1 into the
+     * destination register based on the results of the comparison.
+     *
+     * Provide a "naninst" instruction that puts 1 or -1 into r1 depending
+     * on what value we'd like to return when one of the operands is NaN.
+     *
+     * The operation we're implementing is:
+     *   if (x == y)
+     *     return 0;
+     *   else if (x < y)
+     *     return -1;
+     *   else if (x > y)
+     *     return 1;
+     *   else
+     *     return {-1,1};  // one or both operands was NaN
+     *
+     * The straightforward implementation requires 3 calls to functions
+     * that return a result in r0.  We can do it with two calls if our
+     * EABI library supports __aeabi_cfcmple (only one if we want to check
+     * for NaN directly):
+     *   check x <= y
+     *     if <, return -1
+     *     if ==, return 0
+     *   check y <= x
+     *     if <, return 1
+     *   return {-1,1}
+     *
+     * for: cmpl-float, cmpg-float
+     */
+    /* op vAA, vBB, vCC */
+    mov     r9, r0                      @ Save copies - we may need to redo
+    mov     r10, r1
+    mov     r11, lr                     @ save return address
+    mov     lr, pc
+    ldr     pc, .L__aeabi_cfcmple       @ cmp <=: C clear if <, Z set if eq
+    bhi     .L${opcode}_gt_or_nan       @ C set and Z clear, disambiguate
+    mvncc   r0, #0                      @ (less than) r0<- -1
+    moveq   r0, #0                      @ (equal) r0<- 0, trumps less than
+    bx      r11
+    @ Test for NaN with a second comparison.  EABI forbids testing bit
+    @ patterns, and we can't represent 0x7fc00000 in immediate form, so
+    @ make the library call.
+.L${opcode}_gt_or_nan:
+    mov     r0, r10                     @ restore in reverse order
+    mov     r1, r9
+    mov     lr, pc
+    ldr     pc, .L__aeabi_cfcmple       @ r0<- Z set if eq, C clear if <
+    movcc   r0, #1                      @ (greater than) r1<- 1
+    bxcc    r11
+    $naninst                            @ r1<- 1 or -1 for NaN
+    bx      r11
diff --git a/vm/compiler/template/armv5te_taint/TEMPLATE_CMP_LONG.S b/vm/compiler/template/armv5te_taint/TEMPLATE_CMP_LONG.S
new file mode 100644
index 0000000..e5e8196
--- /dev/null
+++ b/vm/compiler/template/armv5te_taint/TEMPLATE_CMP_LONG.S
@@ -0,0 +1,33 @@
+    /*
+     * Compare two 64-bit values.  Puts 0, 1, or -1 into the destination
+     * register based on the results of the comparison.
+     *
+     * We load the full values with LDM, but in practice many values could
+     * be resolved by only looking at the high word.  This could be made
+     * faster or slower by splitting the LDM into a pair of LDRs.
+     *
+     * If we just wanted to set condition flags, we could do this:
+     *  subs    ip, r0, r2
+     *  sbcs    ip, r1, r3
+     *  subeqs  ip, r0, r2
+     * Leaving { <0, 0, >0 } in ip.  However, we have to set it to a specific
+     * integer value, which we can do with 2 conditional mov/mvn instructions
+     * (set 1, set -1; if they're equal we already have 0 in ip), giving
+     * us a constant 5-cycle path plus a branch at the end to the
+     * instruction epilogue code.  The multi-compare approach below needs
+     * 2 or 3 cycles + branch if the high word doesn't match, 6 + branch
+     * in the worst case (the 64-bit values are equal).
+     */
+    /* cmp-long vAA, vBB, vCC */
+    cmp     r1, r3                      @ compare (vBB+1, vCC+1)
+    blt     .L${opcode}_less            @ signed compare on high part
+    bgt     .L${opcode}_greater
+    subs    r0, r0, r2                  @ r0<- r0 - r2
+    bxeq     lr
+    bhi     .L${opcode}_greater         @ unsigned compare on low part
+.L${opcode}_less:
+    mvn     r0, #0                      @ r0<- -1
+    bx      lr
+.L${opcode}_greater:
+    mov     r0, #1                      @ r0<- 1
+    bx      lr
diff --git a/vm/compiler/template/armv5te_taint/TEMPLATE_INTERPRET.S b/vm/compiler/template/armv5te_taint/TEMPLATE_INTERPRET.S
new file mode 100644
index 0000000..9f24887
--- /dev/null
+++ b/vm/compiler/template/armv5te_taint/TEMPLATE_INTERPRET.S
@@ -0,0 +1,30 @@
+    /*
+     * This handler transfers control to the interpeter without performing
+     * any lookups.  It may be called either as part of a normal chaining
+     * operation, or from the transition code in header.S.  We distinquish
+     * the two cases by looking at the link register.  If called from a
+     * translation chain, it will point to the chaining Dalvik PC -3.
+     * On entry:
+     *    lr - if NULL:
+     *        r1 - the Dalvik PC to begin interpretation.
+     *    else
+     *        [lr, #3] contains Dalvik PC to begin interpretation
+     *    rSELF - pointer to thread
+     *    rFP - Dalvik frame pointer
+     */
+    cmp     lr, #0
+#if defined(WORKAROUND_CORTEX_A9_745320)
+    /* Don't use conditional loads if the HW defect exists */
+    beq     101f
+    ldr     r1,[lr, #3]
+101:
+#else
+    ldrne   r1,[lr, #3]
+#endif
+    ldr     r2, .LinterpPunt
+    mov     r0, r1                       @ set Dalvik PC
+    bx      r2
+    @ doesn't return
+
+.LinterpPunt:
+    .word   dvmJitToInterpPunt
diff --git a/vm/compiler/template/armv5te_taint/TEMPLATE_INVOKE_METHOD_CHAIN.S b/vm/compiler/template/armv5te_taint/TEMPLATE_INVOKE_METHOD_CHAIN.S
new file mode 100644
index 0000000..4bf86b4
--- /dev/null
+++ b/vm/compiler/template/armv5te_taint/TEMPLATE_INVOKE_METHOD_CHAIN.S
@@ -0,0 +1,55 @@
+%default { "chaintgt" : ".LinvokeChain" }
+    /*
+     * For monomorphic callsite, setup the Dalvik frame and return to the
+     * Thumb code through the link register to transfer control to the callee
+     * method through a dedicated chaining cell.
+     */
+    @ r0 = methodToCall, r1 = returnCell, r2 = methodToCall->outsSize
+    @ rPC = dalvikCallsite, r7 = methodToCall->registersSize
+    @ methodToCall is guaranteed to be non-native
+$chaintgt:
+    ldr     r9, [rSELF, #offThread_interpStackEnd]    @ r9<- interpStackEnd
+    ldrb    r8, [rSELF, #offThread_breakFlags]        @ r8<- breakFlags
+    add     r3, r1, #1  @ Thumb addr is odd
+    SAVEAREA_FROM_FP(r1, rFP)           @ r1<- stack save area
+// begin WITH_TAINT_TRACKING
+    sub     r1, r1, r7, lsl #3
+    sub     r1, r1, #4                  @ r1<- newFp (old savearea - 2*regsSize - 4)
+// end WITH_TAINT_TRACKING
+    SAVEAREA_FROM_FP(r10, r1)           @ r10<- stack save area
+    add     r12, lr, #2                 @ setup the punt-to-interp address
+// begin WITH_TAINT_TRACKING
+    sub     r10, r10, r2, lsl #2
+    sub	    r10, r10, #4                @ r10<- bottom (newsave - outsSize - 4)
+// end WITH_TAINT_TRACKING
+    cmp     r10, r9                     @ bottom < interpStackEnd?
+    bxlo    r12                         @ return to raise stack overflow excep.
+    @ r1 = newFP, r0 = methodToCall, r3 = returnCell, rPC = dalvikCallsite
+    ldr     r9, [r0, #offMethod_clazz]      @ r9<- method->clazz
+    str     rPC, [rFP, #(offStackSaveArea_currentPc - sizeofStackSaveArea)]
+    str     rPC, [r1, #(offStackSaveArea_savedPc - sizeofStackSaveArea)]
+
+    @ set up newSaveArea
+    str     rFP, [r1, #(offStackSaveArea_prevFrame - sizeofStackSaveArea)]
+    str     r3, [r1, #(offStackSaveArea_returnAddr - sizeofStackSaveArea)]
+    str     r0, [r1, #(offStackSaveArea_method - sizeofStackSaveArea)]
+    cmp     r8, #0                      @ breakFlags != 0
+    bxne    r12                         @ bail to the interpreter
+
+    ldr     r3, [r9, #offClassObject_pDvmDex] @ r3<- method->clazz->pDvmDex
+
+    @ Update "thread" values for the new method
+    str     r0, [rSELF, #offThread_method]    @ self->method = methodToCall
+    str     r3, [rSELF, #offThread_methodClassDex] @ self->methodClassDex = ...
+    mov     rFP, r1                         @ fp = newFp
+    str     rFP, [rSELF, #offThread_curFrame]  @ curFrame = newFp
+#if defined(TEMPLATE_INLINE_PROFILING)
+    stmfd   sp!, {r0-r2,lr}             @ preserve clobbered live registers
+    mov     r1, r6
+    @ r0=methodToCall, r1=rSELF
+    mov     lr, pc
+    ldr     pc, .LdvmFastMethodTraceEnter
+    ldmfd   sp!, {r0-r2,lr}             @ restore registers
+#endif
+
+    bx      lr                              @ return to the callee-chaining cell
diff --git a/vm/compiler/template/armv5te_taint/TEMPLATE_INVOKE_METHOD_CHAIN_PROF.S b/vm/compiler/template/armv5te_taint/TEMPLATE_INVOKE_METHOD_CHAIN_PROF.S
new file mode 100644
index 0000000..629e9d8
--- /dev/null
+++ b/vm/compiler/template/armv5te_taint/TEMPLATE_INVOKE_METHOD_CHAIN_PROF.S
@@ -0,0 +1,3 @@
+#define TEMPLATE_INLINE_PROFILING
+%include "armv5te_taint/TEMPLATE_INVOKE_METHOD_CHAIN.S" { "chaintgt" : ".LinvokeChainProf" }
+#undef TEMPLATE_INLINE_PROFILING
diff --git a/vm/compiler/template/armv5te_taint/TEMPLATE_INVOKE_METHOD_NATIVE.S b/vm/compiler/template/armv5te_taint/TEMPLATE_INVOKE_METHOD_NATIVE.S
new file mode 100644
index 0000000..83df858
--- /dev/null
+++ b/vm/compiler/template/armv5te_taint/TEMPLATE_INVOKE_METHOD_NATIVE.S
@@ -0,0 +1,96 @@
+    @ r0 = methodToCall, r1 = returnCell, rPC = dalvikCallsite
+    @ r7 = methodToCall->registersSize
+    ldr     r9, [rSELF, #offThread_interpStackEnd]    @ r9<- interpStackEnd
+    ldrb    r8, [rSELF, #offThread_breakFlags]        @ r8<- breakFlags
+    add     r3, r1, #1  @ Thumb addr is odd
+    SAVEAREA_FROM_FP(r1, rFP)           @ r1<- stack save area
+// begin WITH_TAINT_TRACKING
+    sub     r1, r1, r7, lsl #3
+    sub	    r1, r1, #4                  @ r1<- newFp (old savearea - 2*regsSize - 4)
+// end WITH_TAINT_TRACKING
+    SAVEAREA_FROM_FP(r10, r1)           @ r10<- stack save area
+    cmp     r10, r9                     @ bottom < interpStackEnd?
+    bxlo    lr                          @ return to raise stack overflow excep.
+    @ r1 = newFP, r0 = methodToCall, r3 = returnCell, rPC = dalvikCallsite
+    str     rPC, [rFP, #(offStackSaveArea_currentPc - sizeofStackSaveArea)]
+    str     rPC, [r1, #(offStackSaveArea_savedPc - sizeofStackSaveArea)]
+
+    @ set up newSaveArea
+    str     rFP, [r1, #(offStackSaveArea_prevFrame - sizeofStackSaveArea)]
+    str     r3, [r1, #(offStackSaveArea_returnAddr - sizeofStackSaveArea)]
+    str     r0, [r1, #(offStackSaveArea_method - sizeofStackSaveArea)]
+    cmp     r8, #0                      @ breakFlags != 0
+    ldr     r8, [r0, #offMethod_nativeFunc] @ r8<- method->nativeFunc
+#if !defined(WITH_SELF_VERIFICATION)
+    bxne    lr                          @ bail to the interpreter
+#else
+    bx      lr                          @ bail to interpreter unconditionally
+#endif
+
+    @ go ahead and transfer control to the native code
+    ldr     r9, [rSELF, #offThread_jniLocal_topCookie]@r9<-thread->localRef->...
+    mov     r2, #0
+    str     r1, [rSELF, #offThread_curFrame]   @ curFrame = newFp
+    str     r2, [rSELF, #offThread_inJitCodeCache] @ not in the jit code cache
+    str     r9, [r1, #(offStackSaveArea_localRefCookie - sizeofStackSaveArea)]
+                                        @ newFp->localRefCookie=top
+    SAVEAREA_FROM_FP(r10, r1)           @ r10<- new stack save area
+
+    mov     r2, r0                        @ arg2<- methodToCall
+    mov     r0, r1                        @ arg0<- newFP
+    add     r1, rSELF, #offThread_retval  @ arg1<- &retval
+    mov     r3, rSELF                     @ arg3<- self
+#if defined(TEMPLATE_INLINE_PROFILING)
+    @ r2=methodToCall, r6=rSELF
+    stmfd   sp!, {r2,r6}                @ to be consumed after JNI return
+    stmfd   sp!, {r0-r3}                @ preserve r0-r3
+    mov     r0, r2
+    mov     r1, r6
+    @ r0=JNIMethod, r1=rSELF
+    mov     lr, pc
+    ldr     pc, .LdvmFastMethodTraceEnter
+    ldmfd   sp!, {r0-r3}                @ restore r0-r3
+#endif
+
+    blx     r8                          @ off to the native code
+
+#if defined(TEMPLATE_INLINE_PROFILING)
+    ldmfd   sp!, {r0-r1}                @ restore r2 and r6
+    @ r0=JNIMethod, r1=rSELF
+    mov     lr, pc
+    ldr     pc, .LdvmFastNativeMethodTraceExit
+#endif
+    @ native return; r10=newSaveArea
+
+// begin WITH_TAINT_TRACKING
+    // set return taint
+    SAVEAREA_FROM_FP(r0, rFP)                       @ r0<- stack save area
+    ldr     r1, [r0, #offStackSaveArea_argCount]    @ r1<- arg count
+    sub     r0, r0, r1, lsl #2
+    ldr     r2, [r0, #-4]                           @ r2<- return taint
+    str	    r2, [rSELF, #offThread_rtaint]
+// end WITH_TAINT_TRACKING
+
+    @ equivalent to dvmPopJniLocals
+    ldr     r2, [r10, #offStackSaveArea_returnAddr] @ r2 = chaining cell ret
+    ldr     r0, [r10, #offStackSaveArea_localRefCookie] @ r0<- saved->top
+    ldr     r1, [rSELF, #offThread_exception] @ check for exception
+    str     rFP, [rSELF, #offThread_curFrame]  @ curFrame = fp
+    cmp     r1, #0                      @ null?
+    str     r0, [rSELF, #offThread_jniLocal_topCookie] @ new top <- old top
+    ldr     r0, [rFP, #(offStackSaveArea_currentPc - sizeofStackSaveArea)]
+
+    @ r0 = dalvikCallsitePC
+    bne     .LhandleException           @ no, handle exception
+
+    str     r2, [rSELF, #offThread_inJitCodeCache] @ set the mode properly
+    cmp     r2, #0                      @ return chaining cell still exists?
+    bxne    r2                          @ yes - go ahead
+
+    @ continue executing the next instruction through the interpreter
+    ldr     r1, .LdvmJitToInterpTraceSelectNoChain @ defined in footer.S
+    add     rPC, r0, #6                 @ reconstruct new rPC (advance 6 bytes)
+#if defined(WITH_JIT_TUNING)
+    mov     r0, #kCallsiteInterpreted
+#endif
+    mov     pc, r1
diff --git a/vm/compiler/template/armv5te_taint/TEMPLATE_INVOKE_METHOD_NATIVE.S~ b/vm/compiler/template/armv5te_taint/TEMPLATE_INVOKE_METHOD_NATIVE.S~
new file mode 100644
index 0000000..83df858
--- /dev/null
+++ b/vm/compiler/template/armv5te_taint/TEMPLATE_INVOKE_METHOD_NATIVE.S~
@@ -0,0 +1,96 @@
+    @ r0 = methodToCall, r1 = returnCell, rPC = dalvikCallsite
+    @ r7 = methodToCall->registersSize
+    ldr     r9, [rSELF, #offThread_interpStackEnd]    @ r9<- interpStackEnd
+    ldrb    r8, [rSELF, #offThread_breakFlags]        @ r8<- breakFlags
+    add     r3, r1, #1  @ Thumb addr is odd
+    SAVEAREA_FROM_FP(r1, rFP)           @ r1<- stack save area
+// begin WITH_TAINT_TRACKING
+    sub     r1, r1, r7, lsl #3
+    sub	    r1, r1, #4                  @ r1<- newFp (old savearea - 2*regsSize - 4)
+// end WITH_TAINT_TRACKING
+    SAVEAREA_FROM_FP(r10, r1)           @ r10<- stack save area
+    cmp     r10, r9                     @ bottom < interpStackEnd?
+    bxlo    lr                          @ return to raise stack overflow excep.
+    @ r1 = newFP, r0 = methodToCall, r3 = returnCell, rPC = dalvikCallsite
+    str     rPC, [rFP, #(offStackSaveArea_currentPc - sizeofStackSaveArea)]
+    str     rPC, [r1, #(offStackSaveArea_savedPc - sizeofStackSaveArea)]
+
+    @ set up newSaveArea
+    str     rFP, [r1, #(offStackSaveArea_prevFrame - sizeofStackSaveArea)]
+    str     r3, [r1, #(offStackSaveArea_returnAddr - sizeofStackSaveArea)]
+    str     r0, [r1, #(offStackSaveArea_method - sizeofStackSaveArea)]
+    cmp     r8, #0                      @ breakFlags != 0
+    ldr     r8, [r0, #offMethod_nativeFunc] @ r8<- method->nativeFunc
+#if !defined(WITH_SELF_VERIFICATION)
+    bxne    lr                          @ bail to the interpreter
+#else
+    bx      lr                          @ bail to interpreter unconditionally
+#endif
+
+    @ go ahead and transfer control to the native code
+    ldr     r9, [rSELF, #offThread_jniLocal_topCookie]@r9<-thread->localRef->...
+    mov     r2, #0
+    str     r1, [rSELF, #offThread_curFrame]   @ curFrame = newFp
+    str     r2, [rSELF, #offThread_inJitCodeCache] @ not in the jit code cache
+    str     r9, [r1, #(offStackSaveArea_localRefCookie - sizeofStackSaveArea)]
+                                        @ newFp->localRefCookie=top
+    SAVEAREA_FROM_FP(r10, r1)           @ r10<- new stack save area
+
+    mov     r2, r0                        @ arg2<- methodToCall
+    mov     r0, r1                        @ arg0<- newFP
+    add     r1, rSELF, #offThread_retval  @ arg1<- &retval
+    mov     r3, rSELF                     @ arg3<- self
+#if defined(TEMPLATE_INLINE_PROFILING)
+    @ r2=methodToCall, r6=rSELF
+    stmfd   sp!, {r2,r6}                @ to be consumed after JNI return
+    stmfd   sp!, {r0-r3}                @ preserve r0-r3
+    mov     r0, r2
+    mov     r1, r6
+    @ r0=JNIMethod, r1=rSELF
+    mov     lr, pc
+    ldr     pc, .LdvmFastMethodTraceEnter
+    ldmfd   sp!, {r0-r3}                @ restore r0-r3
+#endif
+
+    blx     r8                          @ off to the native code
+
+#if defined(TEMPLATE_INLINE_PROFILING)
+    ldmfd   sp!, {r0-r1}                @ restore r2 and r6
+    @ r0=JNIMethod, r1=rSELF
+    mov     lr, pc
+    ldr     pc, .LdvmFastNativeMethodTraceExit
+#endif
+    @ native return; r10=newSaveArea
+
+// begin WITH_TAINT_TRACKING
+    // set return taint
+    SAVEAREA_FROM_FP(r0, rFP)                       @ r0<- stack save area
+    ldr     r1, [r0, #offStackSaveArea_argCount]    @ r1<- arg count
+    sub     r0, r0, r1, lsl #2
+    ldr     r2, [r0, #-4]                           @ r2<- return taint
+    str	    r2, [rSELF, #offThread_rtaint]
+// end WITH_TAINT_TRACKING
+
+    @ equivalent to dvmPopJniLocals
+    ldr     r2, [r10, #offStackSaveArea_returnAddr] @ r2 = chaining cell ret
+    ldr     r0, [r10, #offStackSaveArea_localRefCookie] @ r0<- saved->top
+    ldr     r1, [rSELF, #offThread_exception] @ check for exception
+    str     rFP, [rSELF, #offThread_curFrame]  @ curFrame = fp
+    cmp     r1, #0                      @ null?
+    str     r0, [rSELF, #offThread_jniLocal_topCookie] @ new top <- old top
+    ldr     r0, [rFP, #(offStackSaveArea_currentPc - sizeofStackSaveArea)]
+
+    @ r0 = dalvikCallsitePC
+    bne     .LhandleException           @ no, handle exception
+
+    str     r2, [rSELF, #offThread_inJitCodeCache] @ set the mode properly
+    cmp     r2, #0                      @ return chaining cell still exists?
+    bxne    r2                          @ yes - go ahead
+
+    @ continue executing the next instruction through the interpreter
+    ldr     r1, .LdvmJitToInterpTraceSelectNoChain @ defined in footer.S
+    add     rPC, r0, #6                 @ reconstruct new rPC (advance 6 bytes)
+#if defined(WITH_JIT_TUNING)
+    mov     r0, #kCallsiteInterpreted
+#endif
+    mov     pc, r1
diff --git a/vm/compiler/template/armv5te_taint/TEMPLATE_INVOKE_METHOD_NATIVE_PROF.S b/vm/compiler/template/armv5te_taint/TEMPLATE_INVOKE_METHOD_NATIVE_PROF.S
new file mode 100644
index 0000000..ef33995
--- /dev/null
+++ b/vm/compiler/template/armv5te_taint/TEMPLATE_INVOKE_METHOD_NATIVE_PROF.S
@@ -0,0 +1,3 @@
+#define TEMPLATE_INLINE_PROFILING
+%include "armv5te_taint/TEMPLATE_INVOKE_METHOD_NATIVE.S"
+#undef TEMPLATE_INLINE_PROFILING
diff --git a/vm/compiler/template/armv5te_taint/TEMPLATE_INVOKE_METHOD_NO_OPT.S b/vm/compiler/template/armv5te_taint/TEMPLATE_INVOKE_METHOD_NO_OPT.S
new file mode 100644
index 0000000..790ee50
--- /dev/null
+++ b/vm/compiler/template/armv5te_taint/TEMPLATE_INVOKE_METHOD_NO_OPT.S
@@ -0,0 +1,67 @@
+    /*
+     * For polymorphic callsites - setup the Dalvik frame and load Dalvik PC
+     * into rPC then jump to dvmJitToInterpNoChain to dispatch the
+     * runtime-resolved callee.
+     */
+    @ r0 = methodToCall, r1 = returnCell, rPC = dalvikCallsite
+    ldrh    r7, [r0, #offMethod_registersSize]  @ r7<- methodToCall->regsSize
+    ldrh    r2, [r0, #offMethod_outsSize]  @ r2<- methodToCall->outsSize
+    ldr     r9, [rSELF, #offThread_interpStackEnd]    @ r9<- interpStackEnd
+    ldrb    r8, [rSELF, #offThread_breakFlags] @ r8<- breakFlags
+    add     r3, r1, #1  @ Thumb addr is odd
+    SAVEAREA_FROM_FP(r1, rFP)           @ r1<- stack save area
+// begin WITH_TAINT_TRACKING
+    sub     r1, r1, r7, lsl #3
+    sub     r1, r1, #4                  @ r1<- newFp (old savearea - 2*regsSize - 4)
+// end WITH_TAINT_TRACKING
+    SAVEAREA_FROM_FP(r10, r1)           @ r10<- stack save area
+// begin WITH_TAINT_TRACKING
+    // PJG: typo fixed from 2.3.4
+    sub     r10, r10, r2, lsl #2
+    sub	    r10, r10, #4		@ r10<- bottom (newsave - outsSize - 4)
+// end WITH_TAINT_TRACKING
+    cmp     r10, r9                     @ bottom < interpStackEnd?
+    bxlo    lr                          @ return to raise stack overflow excep.
+    @ r1 = newFP, r0 = methodToCall, r3 = returnCell, rPC = dalvikCallsite
+    ldr     r9, [r0, #offMethod_clazz]      @ r9<- method->clazz
+    ldr     r10, [r0, #offMethod_accessFlags] @ r10<- methodToCall->accessFlags
+    str     rPC, [rFP, #(offStackSaveArea_currentPc - sizeofStackSaveArea)]
+    str     rPC, [r1, #(offStackSaveArea_savedPc - sizeofStackSaveArea)]
+    ldr     rPC, [r0, #offMethod_insns]     @ rPC<- methodToCall->insns
+
+
+    @ set up newSaveArea
+    str     rFP, [r1, #(offStackSaveArea_prevFrame - sizeofStackSaveArea)]
+    str     r3, [r1, #(offStackSaveArea_returnAddr - sizeofStackSaveArea)]
+    str     r0, [r1, #(offStackSaveArea_method - sizeofStackSaveArea)]
+    cmp     r8, #0                      @ breakFlags != 0
+    bxne    lr                          @ bail to the interpreter
+    tst     r10, #ACC_NATIVE
+#if !defined(WITH_SELF_VERIFICATION)
+    bne     .LinvokeNative
+#else
+    bxne    lr                          @ bail to the interpreter
+#endif
+
+    ldr     r10, .LdvmJitToInterpTraceSelectNoChain
+    ldr     r3, [r9, #offClassObject_pDvmDex] @ r3<- method->clazz->pDvmDex
+
+    @ Update "thread" values for the new method
+    str     r0, [rSELF, #offThread_method]    @ self->method = methodToCall
+    str     r3, [rSELF, #offThread_methodClassDex] @ self->methodClassDex = ...
+    mov     rFP, r1                         @ fp = newFp
+    str     rFP, [rSELF, #offThread_curFrame]  @ curFrame = newFp
+#if defined(TEMPLATE_INLINE_PROFILING)
+    stmfd   sp!, {r0-r3}                    @ preserve r0-r3
+    mov     r1, r6
+    @ r0=methodToCall, r1=rSELF
+    mov     lr, pc
+    ldr     pc, .LdvmFastMethodTraceEnter
+    ldmfd   sp!, {r0-r3}                    @ restore r0-r3
+#endif
+
+    @ Start executing the callee
+#if defined(WITH_JIT_TUNING)
+    mov     r0, #kInlineCacheMiss
+#endif
+    mov     pc, r10                         @ dvmJitToInterpTraceSelectNoChain
diff --git a/vm/compiler/template/armv5te_taint/TEMPLATE_INVOKE_METHOD_NO_OPT.S~ b/vm/compiler/template/armv5te_taint/TEMPLATE_INVOKE_METHOD_NO_OPT.S~
new file mode 100644
index 0000000..0a36178
--- /dev/null
+++ b/vm/compiler/template/armv5te_taint/TEMPLATE_INVOKE_METHOD_NO_OPT.S~
@@ -0,0 +1,67 @@
+    /*
+     * For polymorphic callsites - setup the Dalvik frame and load Dalvik PC
+     * into rPC then jump to dvmJitToInterpNoChain to dispatch the
+     * runtime-resolved callee.
+     */
+    @ r0 = methodToCall, r1 = returnCell, rPC = dalvikCallsite
+    ldrh    r7, [r0, #offMethod_registersSize]  @ r7<- methodToCall->regsSize
+    ldrh    r2, [r0, #offMethod_outsSize]  @ r2<- methodToCall->outsSize
+    ldr     r9, [rSELF, #offThread_interpStackEnd]    @ r9<- interpStackEnd
+    ldrb    r8, [rSELF, #offThread_breakFlags] @ r8<- breakFlags
+    add     r3, r1, #1  @ Thumb addr is odd
+    SAVEAREA_FROM_FP(r1, rFP)           @ r1<- stack save area
+// begin WITH_TAINT_TRACKING
+    sub     r1, r1, r7, lsl #3
+    sub     r1, r1, #4                  @ r1<- newFp (old savearea - 2*regsSize - 4)
+// end WITH_TAINT_TRACKING
+    SAVEAREA_FROM_FP(r10, r1)           @ r10<- stack save area
+// begin WITH_TAINT_TRACKING
+    // PJG: typo fixed from 2.3.4
+    sub     r10, r10, r2, lsl #2
+    sub	    r10, r10, #4		@ r10<- bottom (newsave - outsSize - 4)
+// end WITH_TAINT_TRACKING
+    cmp     r10, r9                     @ bottom < interpStackEnd?
+    bxlo    lr                          @ return to raise stack overflow excep.
+    @ r1 = newFP, r0 = methodToCall, r3 = returnCell, rPC = dalvikCallsite
+    ldr     r9, [r0, #offMethod_clazz]      @ r9<- method->clazz
+    ldr     r10, [r0, #offMethod_accessFlags] @ r10<- methodToCall->accessFlags
+    str     rPC, [rFP, #(offStackSaveArea_currentPc - sizeofStackSaveArea)]
+    str     rPC, [r1, #(offStackSaveArea_savedPc - sizeofStackSaveArea)]
+    ldr     rPC, [r0, #offMethod_insns]     @ rPC<- methodToCall->insns
+
+
+    @ set up newSaveArea
+    str     rFP, [r1, #(offStackSaveArea_prevFrame - sizeofStackSaveArea)]
+    str     r3, [r1, #(offStackSaveArea_returnAddr - sizeofStackSaveArea)]
+    str     r0, [r1, #(offStackSaveArea_method - sizeofStackSaveArea)]
+    cmp     r8, #0                      @ breakFlags != 0
+    bxne    lr                          @ bail to the interpreter
+    tst     r10, #ACC_NATIVE
+z#if !defined(WITH_SELF_VERIFICATION)
+    bne     .LinvokeNative
+#else
+    bxne    lr                          @ bail to the interpreter
+#endif
+
+    ldr     r10, .LdvmJitToInterpTraceSelectNoChain
+    ldr     r3, [r9, #offClassObject_pDvmDex] @ r3<- method->clazz->pDvmDex
+
+    @ Update "thread" values for the new method
+    str     r0, [rSELF, #offThread_method]    @ self->method = methodToCall
+    str     r3, [rSELF, #offThread_methodClassDex] @ self->methodClassDex = ...
+    mov     rFP, r1                         @ fp = newFp
+    str     rFP, [rSELF, #offThread_curFrame]  @ curFrame = newFp
+#if defined(TEMPLATE_INLINE_PROFILING)
+    stmfd   sp!, {r0-r3}                    @ preserve r0-r3
+    mov     r1, r6
+    @ r0=methodToCall, r1=rSELF
+    mov     lr, pc
+    ldr     pc, .LdvmFastMethodTraceEnter
+    ldmfd   sp!, {r0-r3}                    @ restore r0-r3
+#endif
+
+    @ Start executing the callee
+#if defined(WITH_JIT_TUNING)
+    mov     r0, #kInlineCacheMiss
+#endif
+    mov     pc, r10                         @ dvmJitToInterpTraceSelectNoChain
diff --git a/vm/compiler/template/armv5te_taint/TEMPLATE_INVOKE_METHOD_NO_OPT_PROF.S b/vm/compiler/template/armv5te_taint/TEMPLATE_INVOKE_METHOD_NO_OPT_PROF.S
new file mode 100644
index 0000000..1cfc9fa
--- /dev/null
+++ b/vm/compiler/template/armv5te_taint/TEMPLATE_INVOKE_METHOD_NO_OPT_PROF.S
@@ -0,0 +1,3 @@
+#define TEMPLATE_INLINE_PROFILING
+%include "armv5te_taint/TEMPLATE_INVOKE_METHOD_NO_OPT.S"
+#undef TEMPLATE_INLINE_PROFILING
diff --git a/vm/compiler/template/armv5te_taint/TEMPLATE_INVOKE_METHOD_PREDICTED_CHAIN.S b/vm/compiler/template/armv5te_taint/TEMPLATE_INVOKE_METHOD_PREDICTED_CHAIN.S
new file mode 100644
index 0000000..9dd4ff8
--- /dev/null
+++ b/vm/compiler/template/armv5te_taint/TEMPLATE_INVOKE_METHOD_PREDICTED_CHAIN.S
@@ -0,0 +1,60 @@
+%default { "chaintgt" : ".LinvokeChain" }
+    /*
+     * For polymorphic callsite, check whether the cached class pointer matches
+     * the current one. If so setup the Dalvik frame and return to the
+     * Thumb code through the link register to transfer control to the callee
+     * method through a dedicated chaining cell.
+     *
+     * The predicted chaining cell is declared in ArmLIR.h with the
+     * following layout:
+     *
+     *  typedef struct PredictedChainingCell {
+     *      u4 branch;
+     *      const ClassObject *clazz;
+     *      const Method *method;
+     *      u4 counter;
+     *  } PredictedChainingCell;
+     *
+     * Upon returning to the callsite:
+     *    - lr  : to branch to the chaining cell
+     *    - lr+2: to punt to the interpreter
+     *    - lr+4: to fully resolve the callee and may rechain.
+     *            r3 <- class
+     *            r9 <- counter
+     */
+    @ r0 = this, r1 = returnCell, r2 = predictedChainCell, rPC = dalvikCallsite
+    ldr     r3, [r0, #offObject_clazz]  @ r3 <- this->class
+    ldr     r8, [r2, #4]    @ r8 <- predictedChainCell->clazz
+    ldr     r0, [r2, #8]    @ r0 <- predictedChainCell->method
+    ldr     r9, [rSELF, #offThread_icRechainCount] @ r1 <- shared rechainCount
+    cmp     r3, r8          @ predicted class == actual class?
+#if defined(WITH_JIT_TUNING)
+    ldr     r7, .LdvmICHitCount
+#if defined(WORKAROUND_CORTEX_A9_745320)
+    /* Don't use conditional loads if the HW defect exists */
+    bne     101f
+    ldr     r10, [r7, #0]
+101:
+#else
+    ldreq   r10, [r7, #0]
+#endif
+    add     r10, r10, #1
+    streq   r10, [r7, #0]
+#endif
+    ldreqh  r7, [r0, #offMethod_registersSize]  @ r7<- methodToCall->regsSize
+    ldreqh  r2, [r0, #offMethod_outsSize]  @ r2<- methodToCall->outsSize
+    beq     $chaintgt   @ predicted chain is valid
+    ldr     r7, [r3, #offClassObject_vtable] @ r7 <- this->class->vtable
+    cmp     r8, #0          @ initialized class or not
+    moveq   r1, #0
+    subne   r1, r9, #1      @ count--
+    strne   r1, [rSELF, #offThread_icRechainCount]  @ write back to thread
+    add     lr, lr, #4      @ return to fully-resolve landing pad
+    /*
+     * r1 <- count
+     * r2 <- &predictedChainCell
+     * r3 <- this->class
+     * r4 <- dPC
+     * r7 <- this->class->vtable
+     */
+    bx      lr
diff --git a/vm/compiler/template/armv5te_taint/TEMPLATE_INVOKE_METHOD_PREDICTED_CHAIN_PROF.S b/vm/compiler/template/armv5te_taint/TEMPLATE_INVOKE_METHOD_PREDICTED_CHAIN_PROF.S
new file mode 100644
index 0000000..3cdf32b
--- /dev/null
+++ b/vm/compiler/template/armv5te_taint/TEMPLATE_INVOKE_METHOD_PREDICTED_CHAIN_PROF.S
@@ -0,0 +1,3 @@
+#define TEMPLATE_INLINE_PROFILING
+%include "armv5te_taint/TEMPLATE_INVOKE_METHOD_PREDICTED_CHAIN.S" { "chaintgt" : ".LinvokeChainProf" }
+#undef TEMPLATE_INLINE_PROFILING
diff --git a/vm/compiler/template/armv5te_taint/TEMPLATE_MEM_OP_DECODE.S b/vm/compiler/template/armv5te_taint/TEMPLATE_MEM_OP_DECODE.S
new file mode 100644
index 0000000..03926b6
--- /dev/null
+++ b/vm/compiler/template/armv5te_taint/TEMPLATE_MEM_OP_DECODE.S
@@ -0,0 +1,17 @@
+#if defined(WITH_SELF_VERIFICATION)
+    /*
+     * This handler encapsulates heap memory ops for selfVerification mode.
+     *
+     * The call to the handler is inserted prior to a heap memory operation.
+     * This handler then calls a function to decode the memory op, and process
+     * it accordingly. Afterwards, the handler changes the return address to
+     * skip the memory op so it never gets executed.
+     */
+    push    {r0-r12,lr}                 @ save out all registers
+    ldr     r2, .LdvmSelfVerificationMemOpDecode @ defined in footer.S
+    mov     r0, lr                      @ arg0 <- link register
+    mov     r1, sp                      @ arg1 <- stack pointer
+    blx     r2                          @ decode and handle the mem op
+    pop     {r0-r12,lr}                 @ restore all registers
+    bx      lr                          @ return to compiled code
+#endif
diff --git a/vm/compiler/template/armv5te_taint/TEMPLATE_MONITOR_ENTER.S b/vm/compiler/template/armv5te_taint/TEMPLATE_MONITOR_ENTER.S
new file mode 100644
index 0000000..1ed3fb1
--- /dev/null
+++ b/vm/compiler/template/armv5te_taint/TEMPLATE_MONITOR_ENTER.S
@@ -0,0 +1,21 @@
+    /*
+     * Call out to the runtime to lock an object.  Because this thread
+     * may have been suspended in THREAD_MONITOR state and the Jit's
+     * translation cache subsequently cleared, we cannot return directly.
+     * Instead, unconditionally transition to the interpreter to resume.
+     *
+     * On entry:
+     *    r0 - self pointer
+     *    r1 - the object (which has already been null-checked by the caller
+     *    r4 - the Dalvik PC of the following instruction.
+     */
+    ldr     r2, .LdvmLockObject
+    mov     r3, #0                       @ Record that we're not returning
+    str     r3, [r0, #offThread_inJitCodeCache]
+    blx     r2                           @ dvmLockObject(self, obj)
+    ldr     r2, .LdvmJitToInterpNoChain
+    @ Bail to interpreter - no chain [note - r4 still contains rPC]
+#if defined(WITH_JIT_TUNING)
+    mov     r0, #kHeavyweightMonitor
+#endif
+    bx      r2
diff --git a/vm/compiler/template/armv5te_taint/TEMPLATE_MONITOR_ENTER_DEBUG.S b/vm/compiler/template/armv5te_taint/TEMPLATE_MONITOR_ENTER_DEBUG.S
new file mode 100644
index 0000000..2695483
--- /dev/null
+++ b/vm/compiler/template/armv5te_taint/TEMPLATE_MONITOR_ENTER_DEBUG.S
@@ -0,0 +1,28 @@
+    /*
+     * To support deadlock prediction, this version of MONITOR_ENTER
+     * will always call the heavyweight dvmLockObject, check for an
+     * exception and then bail out to the interpreter.
+     *
+     * On entry:
+     *    r0 - self pointer
+     *    r1 - the object (which has already been null-checked by the caller
+     *    r4 - the Dalvik PC of the following instruction.
+     *
+     */
+    ldr     r2, .LdvmLockObject
+    mov     r3, #0                       @ Record that we're not returning
+    str     r3, [r0, #offThread_inJitCodeCache]
+    blx     r2             @ dvmLockObject(self, obj)
+    @ test for exception
+    ldr     r1, [rSELF, #offThread_exception]
+    cmp     r1, #0
+    beq     1f
+    ldr     r2, .LhandleException
+    sub     r0, r4, #2     @ roll dPC back to this monitor instruction
+    bx      r2
+1:
+    @ Bail to interpreter - no chain [note - r4 still contains rPC]
+#if defined(WITH_JIT_TUNING)
+    mov     r0, #kHeavyweightMonitor
+#endif
+    ldr     pc, .LdvmJitToInterpNoChain
diff --git a/vm/compiler/template/armv5te_taint/TEMPLATE_MUL_LONG.S b/vm/compiler/template/armv5te_taint/TEMPLATE_MUL_LONG.S
new file mode 100644
index 0000000..8a9b115
--- /dev/null
+++ b/vm/compiler/template/armv5te_taint/TEMPLATE_MUL_LONG.S
@@ -0,0 +1,28 @@
+    /*
+     * Signed 64-bit integer multiply.
+     *
+     * For JIT: op1 in r0/r1, op2 in r2/r3, return in r0/r1
+     *
+     * Consider WXxYZ (r1r0 x r3r2) with a long multiply:
+     *        WX
+     *      x YZ
+     *  --------
+     *     ZW ZX
+     *  YW YX
+     *
+     * The low word of the result holds ZX, the high word holds
+     * (ZW+YX) + (the high overflow from ZX).  YW doesn't matter because
+     * it doesn't fit in the low 64 bits.
+     *
+     * Unlike most ARM math operations, multiply instructions have
+     * restrictions on using the same register more than once (Rd and Rm
+     * cannot be the same).
+     */
+    /* mul-long vAA, vBB, vCC */
+    mul     ip, r2, r1                  @  ip<- ZxW
+    umull   r9, r10, r2, r0             @  r9/r10 <- ZxX
+    mla     r2, r0, r3, ip              @  r2<- YxX + (ZxW)
+    add     r10, r2, r10                @  r10<- r10 + low(ZxW + (YxX))
+    mov     r0,r9
+    mov     r1,r10
+    bx      lr
diff --git a/vm/compiler/template/armv5te_taint/TEMPLATE_PERIODIC_PROFILING.S b/vm/compiler/template/armv5te_taint/TEMPLATE_PERIODIC_PROFILING.S
new file mode 100644
index 0000000..c0f7d6e
--- /dev/null
+++ b/vm/compiler/template/armv5te_taint/TEMPLATE_PERIODIC_PROFILING.S
@@ -0,0 +1,26 @@
+    /*
+     * Increment profile counter for this trace, and decrement
+     * sample counter.  If sample counter goes below zero, turn
+     * off profiling.
+     *
+     * On entry
+     * (lr-11) is address of pointer to counter.  Note: the counter
+     *    actually exists 10 bytes before the return target, but because
+     *    we are arriving from thumb mode, lr will have its low bit set.
+     */
+     ldr    r0, [lr,#-11]
+     ldr    r1, [rSELF, #offThread_pProfileCountdown]
+     ldr    r2, [r0]                    @ get counter
+     ldr    r3, [r1]                    @ get countdown timer
+     add    r2, #1
+     subs   r2, #1
+     blt    .L${opcode}_disable_profiling
+     str    r2, [r0]
+     str    r3, [r1]
+     bx     lr
+
+.L${opcode}_disable_profiling:
+     mov    r4, lr                     @ preserve lr
+     ldr    r0, .LdvmJitTraceProfilingOff
+     blx    r0
+     bx     r4
diff --git a/vm/compiler/template/armv5te_taint/TEMPLATE_RESTORE_STATE.S b/vm/compiler/template/armv5te_taint/TEMPLATE_RESTORE_STATE.S
new file mode 100644
index 0000000..25b4ffa
--- /dev/null
+++ b/vm/compiler/template/armv5te_taint/TEMPLATE_RESTORE_STATE.S
@@ -0,0 +1,8 @@
+    /*
+     * This handler restores state following a selfVerification memory access.
+     * On entry:
+     *    r0 - offset from rSELF to the 1st element of the coreRegs save array.
+     */
+    add     r0, r0, rSELF               @ pointer to heapArgSpace.coreRegs[0]
+    ldmia   r0, {r0-r12}
+    bx      lr
diff --git a/vm/compiler/template/armv5te_taint/TEMPLATE_RETURN.S b/vm/compiler/template/armv5te_taint/TEMPLATE_RETURN.S
new file mode 100644
index 0000000..d074c9e
--- /dev/null
+++ b/vm/compiler/template/armv5te_taint/TEMPLATE_RETURN.S
@@ -0,0 +1,57 @@
+    /*
+     * Unwind a frame from the Dalvik stack for compiled OP_RETURN_XXX.
+     * If the stored value in returnAddr
+     * is non-zero, the caller is compiled by the JIT thus return to the
+     * address in the code cache following the invoke instruction. Otherwise
+     * return to the special dvmJitToInterpNoChain entry point.
+     */
+#if defined(TEMPLATE_INLINE_PROFILING)
+    stmfd   sp!, {r0-r2,lr}             @ preserve live registers
+    mov     r0, r6
+    @ r0=rSELF
+    mov     lr, pc
+    ldr     pc, .LdvmFastMethodTraceExit
+    ldmfd   sp!, {r0-r2,lr}             @ restore live registers
+#endif
+    SAVEAREA_FROM_FP(r0, rFP)           @ r0<- saveArea (old)
+    ldr     r10, [r0, #offStackSaveArea_prevFrame] @ r10<- saveArea->prevFrame
+    ldrb    r8, [rSELF, #offThread_breakFlags] @ r8<- breakFlags
+    ldr     rPC, [r0, #offStackSaveArea_savedPc] @ rPC<- saveArea->savedPc
+#if !defined(WITH_SELF_VERIFICATION)
+    ldr     r9,  [r0, #offStackSaveArea_returnAddr] @ r9<- chaining cell ret
+#else
+    mov     r9, #0                      @ disable chaining
+#endif
+    ldr     r2, [r10, #(offStackSaveArea_method - sizeofStackSaveArea)]
+                                        @ r2<- method we're returning to
+    cmp     r2, #0                      @ break frame?
+#if !defined(WITH_SELF_VERIFICATION)
+    beq     1f                          @ bail to interpreter
+#else
+    blxeq   lr                          @ punt to interpreter and compare state
+#endif
+    ldr     r1, .LdvmJitToInterpNoChainNoProfile @ defined in footer.S
+    mov     rFP, r10                    @ publish new FP
+    ldr     r10, [r2, #offMethod_clazz] @ r10<- method->clazz
+
+    str     r2, [rSELF, #offThread_method]@ self->method = newSave->method
+    ldr     r0, [r10, #offClassObject_pDvmDex] @ r0<- method->clazz->pDvmDex
+    str     rFP, [rSELF, #offThread_curFrame] @ curFrame = fp
+    add     rPC, rPC, #6                @ publish new rPC (advance 6 bytes)
+    str     r0, [rSELF, #offThread_methodClassDex]
+    cmp     r8, #0                      @ check the break flags
+    movne   r9, #0                      @ clear the chaining cell address
+    str     r9, [rSELF, #offThread_inJitCodeCache] @ in code cache or not
+    cmp     r9, #0                      @ chaining cell exists?
+    blxne   r9                          @ jump to the chaining cell
+#if defined(WITH_JIT_TUNING)
+    mov     r0, #kCallsiteInterpreted
+#endif
+    mov     pc, r1                      @ callsite is interpreted
+1:
+    mov     r0, #0
+    str     r0, [rSELF, #offThread_inJitCodeCache] @ reset inJitCodeCache
+    stmia   rSELF, {rPC, rFP}           @ SAVE_PC_FP_TO_SELF()
+    ldr     r2, .LdvmMterpStdBail       @ defined in footer.S
+    mov     r0, rSELF                   @ Expecting rSELF in r0
+    blx     r2                          @ exit the interpreter
diff --git a/vm/compiler/template/armv5te_taint/TEMPLATE_RETURN_PROF.S b/vm/compiler/template/armv5te_taint/TEMPLATE_RETURN_PROF.S
new file mode 100644
index 0000000..49982f8
--- /dev/null
+++ b/vm/compiler/template/armv5te_taint/TEMPLATE_RETURN_PROF.S
@@ -0,0 +1,3 @@
+#define TEMPLATE_INLINE_PROFILING
+%include "armv5te_taint/TEMPLATE_RETURN.S"
+#undef TEMPLATE_INLINE_PROFILING
diff --git a/vm/compiler/template/armv5te_taint/TEMPLATE_SAVE_STATE.S b/vm/compiler/template/armv5te_taint/TEMPLATE_SAVE_STATE.S
new file mode 100644
index 0000000..1c3aa4d
--- /dev/null
+++ b/vm/compiler/template/armv5te_taint/TEMPLATE_SAVE_STATE.S
@@ -0,0 +1,21 @@
+    /*
+     * This handler performs a register save for selfVerification mode.
+     * On entry:
+     *    Top of stack + 4: r7 value to save
+     *    Top of stack + 0: r0 value to save
+     *    r0 - offset from rSELF to the beginning of the heapArgSpace record
+     *    r7 - the value of regMap
+     *
+     * The handler must save regMap, r0-r12 and then return with r0-r12
+     * with their original values (note that this means r0 and r7 must take
+     * the values on the stack - not the ones in those registers on entry.
+     * Finally, the two registers previously pushed must be popped.
+     */
+    add     r0, r0, rSELF               @ pointer to heapArgSpace
+    stmia   r0!, {r7}                   @ save regMap
+    ldr     r7, [r13, #0]               @ recover r0 value
+    stmia   r0!, {r7}                   @ save r0
+    ldr     r7, [r13, #4]               @ recover r7 value
+    stmia   r0!, {r1-r12}
+    pop     {r0, r7}                    @ recover r0, r7
+    bx      lr
diff --git a/vm/compiler/template/armv5te_taint/TEMPLATE_SHL_LONG.S b/vm/compiler/template/armv5te_taint/TEMPLATE_SHL_LONG.S
new file mode 100644
index 0000000..532f8a4
--- /dev/null
+++ b/vm/compiler/template/armv5te_taint/TEMPLATE_SHL_LONG.S
@@ -0,0 +1,15 @@
+    /*
+     * Long integer shift.  This is different from the generic 32/64-bit
+     * binary operations because vAA/vBB are 64-bit but vCC (the shift
+     * distance) is 32-bit.  Also, Dalvik requires us to ignore all but the low
+     * 6 bits.
+     */
+    /* shl-long vAA, vBB, vCC */
+    and     r2, r2, #63                 @ r2<- r2 & 0x3f
+    mov     r1, r1, asl r2              @  r1<- r1 << r2
+    rsb     r3, r2, #32                 @  r3<- 32 - r2
+    orr     r1, r1, r0, lsr r3          @  r1<- r1 | (r0 << (32-r2))
+    subs    ip, r2, #32                 @  ip<- r2 - 32
+    movpl   r1, r0, asl ip              @  if r2 >= 32, r1<- r0 << (r2-32)
+    mov     r0, r0, asl r2              @  r0<- r0 << r2
+    bx      lr
diff --git a/vm/compiler/template/armv5te_taint/TEMPLATE_SHR_LONG.S b/vm/compiler/template/armv5te_taint/TEMPLATE_SHR_LONG.S
new file mode 100644
index 0000000..c737840
--- /dev/null
+++ b/vm/compiler/template/armv5te_taint/TEMPLATE_SHR_LONG.S
@@ -0,0 +1,15 @@
+    /*
+     * Long integer shift.  This is different from the generic 32/64-bit
+     * binary operations because vAA/vBB are 64-bit but vCC (the shift
+     * distance) is 32-bit.  Also, Dalvik requires us to ignore all but the low
+     * 6 bits.
+     */
+    /* shr-long vAA, vBB, vCC */
+    and     r2, r2, #63                 @ r0<- r0 & 0x3f
+    mov     r0, r0, lsr r2              @  r0<- r2 >> r2
+    rsb     r3, r2, #32                 @  r3<- 32 - r2
+    orr     r0, r0, r1, asl r3          @  r0<- r0 | (r1 << (32-r2))
+    subs    ip, r2, #32                 @  ip<- r2 - 32
+    movpl   r0, r1, asr ip              @  if r2 >= 32, r0<-r1 >> (r2-32)
+    mov     r1, r1, asr r2              @  r1<- r1 >> r2
+    bx      lr
diff --git a/vm/compiler/template/armv5te_taint/TEMPLATE_STRING_COMPARETO.S b/vm/compiler/template/armv5te_taint/TEMPLATE_STRING_COMPARETO.S
new file mode 100644
index 0000000..54bde47
--- /dev/null
+++ b/vm/compiler/template/armv5te_taint/TEMPLATE_STRING_COMPARETO.S
@@ -0,0 +1,133 @@
+    /*
+     * String's compareTo.
+     *
+     * Requires r0/r1 to have been previously checked for null.  Will
+     * return negative if this's string is < comp, 0 if they are the
+     * same and positive if >.
+     *
+     * IMPORTANT NOTE:
+     *
+     * This code relies on hard-coded offsets for string objects, and must be
+     * kept in sync with definitions in UtfString.h.  See asm-constants.h
+     *
+     * On entry:
+     *    r0:   this object pointer
+     *    r1:   comp object pointer
+     *
+     */
+
+    mov    r2, r0         @ this to r2, opening up r0 for return value
+    subs   r0, r2, r1     @ Same?
+    bxeq   lr
+
+    ldr    r4, [r2, #STRING_FIELDOFF_OFFSET]
+    ldr    r9, [r1, #STRING_FIELDOFF_OFFSET]
+    ldr    r7, [r2, #STRING_FIELDOFF_COUNT]
+    ldr    r10, [r1, #STRING_FIELDOFF_COUNT]
+    ldr    r2, [r2, #STRING_FIELDOFF_VALUE]
+    ldr    r1, [r1, #STRING_FIELDOFF_VALUE]
+
+    /*
+     * At this point, we have:
+     *    value:  r2/r1
+     *    offset: r4/r9
+     *    count:  r7/r10
+     * We're going to compute
+     *    r11 <- countDiff
+     *    r10 <- minCount
+     */
+     subs  r11, r7, r10
+     movls r10, r7
+
+     /* Now, build pointers to the string data */
+     add   r2, r2, r4, lsl #1
+     add   r1, r1, r9, lsl #1
+     /*
+      * Note: data pointers point to previous element so we can use pre-index
+      * mode with base writeback.
+      */
+     add   r2, #16-2   @ offset to contents[-1]
+     add   r1, #16-2   @ offset to contents[-1]
+
+     /*
+      * At this point we have:
+      *   r2: *this string data
+      *   r1: *comp string data
+      *   r10: iteration count for comparison
+      *   r11: value to return if the first part of the string is equal
+      *   r0: reserved for result
+      *   r3, r4, r7, r8, r9, r12 available for loading string data
+      */
+
+    subs  r10, #2
+    blt   do_remainder2
+
+      /*
+       * Unroll the first two checks so we can quickly catch early mismatch
+       * on long strings (but preserve incoming alignment)
+       */
+
+    ldrh  r3, [r2, #2]!
+    ldrh  r4, [r1, #2]!
+    ldrh  r7, [r2, #2]!
+    ldrh  r8, [r1, #2]!
+    subs  r0, r3, r4
+    subeqs  r0, r7, r8
+    bxne  lr
+    cmp   r10, #28
+    bgt   do_memcmp16
+    subs  r10, #3
+    blt   do_remainder
+
+loopback_triple:
+    ldrh  r3, [r2, #2]!
+    ldrh  r4, [r1, #2]!
+    ldrh  r7, [r2, #2]!
+    ldrh  r8, [r1, #2]!
+    ldrh  r9, [r2, #2]!
+    ldrh  r12,[r1, #2]!
+    subs  r0, r3, r4
+    subeqs  r0, r7, r8
+    subeqs  r0, r9, r12
+    bxne  lr
+    subs  r10, #3
+    bge   loopback_triple
+
+do_remainder:
+    adds  r10, #3
+    beq   returnDiff
+
+loopback_single:
+    ldrh  r3, [r2, #2]!
+    ldrh  r4, [r1, #2]!
+    subs  r0, r3, r4
+    bxne  lr
+    subs  r10, #1
+    bne     loopback_single
+
+returnDiff:
+    mov   r0, r11
+    bx    lr
+
+do_remainder2:
+    adds  r10, #2
+    bne   loopback_single
+    mov   r0, r11
+    bx    lr
+
+    /* Long string case */
+do_memcmp16:
+    mov   r4, lr
+    ldr   lr, .Lmemcmp16
+    mov   r7, r11
+    add   r0, r2, #2
+    add   r1, r1, #2
+    mov   r2, r10
+    blx   lr
+    cmp   r0, #0
+    bxne  r4
+    mov   r0, r7
+    bx    r4
+
+.Lmemcmp16:
+    .word __memcmp16
diff --git a/vm/compiler/template/armv5te_taint/TEMPLATE_STRING_INDEXOF.S b/vm/compiler/template/armv5te_taint/TEMPLATE_STRING_INDEXOF.S
new file mode 100644
index 0000000..bdfdf28
--- /dev/null
+++ b/vm/compiler/template/armv5te_taint/TEMPLATE_STRING_INDEXOF.S
@@ -0,0 +1,112 @@
+    /*
+     * String's indexOf.
+     *
+     * Requires r0 to have been previously checked for null.  Will
+     * return index of match of r1 in r0.
+     *
+     * IMPORTANT NOTE:
+     *
+     * This code relies on hard-coded offsets for string objects, and must be
+     * kept in sync wth definitions in UtfString.h  See asm-constants.h
+     *
+     * On entry:
+     *    r0:   string object pointer
+     *    r1:   char to match
+     *    r2:   Starting offset in string data
+     */
+
+    ldr    r7, [r0, #STRING_FIELDOFF_OFFSET]
+    ldr    r8, [r0, #STRING_FIELDOFF_COUNT]
+    ldr    r0, [r0, #STRING_FIELDOFF_VALUE]
+
+    /*
+     * At this point, we have:
+     *    r0: object pointer
+     *    r1: char to match
+     *    r2: starting offset
+     *    r7: offset
+     *    r8: string length
+     */
+
+     /* Build pointer to start of string data */
+     add   r0, #16
+     add   r0, r0, r7, lsl #1
+
+     /* Save a copy of starting data in r7 */
+     mov   r7, r0
+
+     /* Clamp start to [0..count] */
+     cmp   r2, #0
+     movlt r2, #0
+     cmp   r2, r8
+     movgt r2, r8
+
+     /* Build pointer to start of data to compare and pre-bias */
+     add   r0, r0, r2, lsl #1
+     sub   r0, #2
+
+     /* Compute iteration count */
+     sub   r8, r2
+
+     /*
+      * At this point we have:
+      *   r0: start of data to test
+      *   r1: chat to compare
+      *   r8: iteration count
+      *   r7: original start of string
+      *   r3, r4, r9, r10, r11, r12 available for loading string data
+      */
+
+    subs  r8, #4
+    blt   indexof_remainder
+
+indexof_loop4:
+    ldrh  r3, [r0, #2]!
+    ldrh  r4, [r0, #2]!
+    ldrh  r10, [r0, #2]!
+    ldrh  r11, [r0, #2]!
+    cmp   r3, r1
+    beq   match_0
+    cmp   r4, r1
+    beq   match_1
+    cmp   r10, r1
+    beq   match_2
+    cmp   r11, r1
+    beq   match_3
+    subs  r8, #4
+    bge   indexof_loop4
+
+indexof_remainder:
+    adds    r8, #4
+    beq     indexof_nomatch
+
+indexof_loop1:
+    ldrh  r3, [r0, #2]!
+    cmp   r3, r1
+    beq   match_3
+    subs  r8, #1
+    bne   indexof_loop1
+
+indexof_nomatch:
+    mov   r0, #-1
+    bx    lr
+
+match_0:
+    sub   r0, #6
+    sub   r0, r7
+    asr   r0, r0, #1
+    bx    lr
+match_1:
+    sub   r0, #4
+    sub   r0, r7
+    asr   r0, r0, #1
+    bx    lr
+match_2:
+    sub   r0, #2
+    sub   r0, r7
+    asr   r0, r0, #1
+    bx    lr
+match_3:
+    sub   r0, r7
+    asr   r0, r0, #1
+    bx    lr
diff --git a/vm/compiler/template/armv5te_taint/TEMPLATE_THROW_EXCEPTION_COMMON.S b/vm/compiler/template/armv5te_taint/TEMPLATE_THROW_EXCEPTION_COMMON.S
new file mode 100644
index 0000000..b737798
--- /dev/null
+++ b/vm/compiler/template/armv5te_taint/TEMPLATE_THROW_EXCEPTION_COMMON.S
@@ -0,0 +1,6 @@
+    /*
+     * Throw an exception from JIT'ed code.
+     * On entry:
+     *    r0    Dalvik PC that raises the exception
+     */
+    b       .LhandleException
diff --git a/vm/compiler/template/armv5te_taint/TEMPLATE_USHR_LONG.S b/vm/compiler/template/armv5te_taint/TEMPLATE_USHR_LONG.S
new file mode 100644
index 0000000..8a48df2
--- /dev/null
+++ b/vm/compiler/template/armv5te_taint/TEMPLATE_USHR_LONG.S
@@ -0,0 +1,15 @@
+    /*
+     * Long integer shift.  This is different from the generic 32/64-bit
+     * binary operations because vAA/vBB are 64-bit but vCC (the shift
+     * distance) is 32-bit.  Also, Dalvik requires us to ignore all but the low
+     * 6 bits.
+     */
+    /* ushr-long vAA, vBB, vCC */
+    and     r2, r2, #63                 @ r0<- r0 & 0x3f
+    mov     r0, r0, lsr r2              @  r0<- r2 >> r2
+    rsb     r3, r2, #32                 @  r3<- 32 - r2
+    orr     r0, r0, r1, asl r3          @  r0<- r0 | (r1 << (32-r2))
+    subs    ip, r2, #32                 @  ip<- r2 - 32
+    movpl   r0, r1, lsr ip              @  if r2 >= 32, r0<-r1 >>> (r2-32)
+    mov     r1, r1, lsr r2              @  r1<- r1 >>> r2
+    bx      lr
diff --git a/vm/compiler/template/armv5te_taint/TemplateOpList.h b/vm/compiler/template/armv5te_taint/TemplateOpList.h
new file mode 100644
index 0000000..abfec4b
--- /dev/null
+++ b/vm/compiler/template/armv5te_taint/TemplateOpList.h
@@ -0,0 +1,50 @@
+/*
+ * Copyright (C) 2009 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+/*
+ * Dalvik opcode list that uses additional templates to complete JIT execution.
+ */
+#ifndef JIT_TEMPLATE
+#define JIT_TEMPLATE(X)
+#endif
+
+JIT_TEMPLATE(CMP_LONG)
+JIT_TEMPLATE(RETURN)
+JIT_TEMPLATE(INVOKE_METHOD_NO_OPT)
+JIT_TEMPLATE(INVOKE_METHOD_CHAIN)
+JIT_TEMPLATE(INVOKE_METHOD_PREDICTED_CHAIN)
+JIT_TEMPLATE(INVOKE_METHOD_NATIVE)
+JIT_TEMPLATE(CMPG_DOUBLE)
+JIT_TEMPLATE(CMPL_DOUBLE)
+JIT_TEMPLATE(CMPG_FLOAT)
+JIT_TEMPLATE(CMPL_FLOAT)
+JIT_TEMPLATE(MUL_LONG)
+JIT_TEMPLATE(SHL_LONG)
+JIT_TEMPLATE(SHR_LONG)
+JIT_TEMPLATE(USHR_LONG)
+JIT_TEMPLATE(THROW_EXCEPTION_COMMON)
+JIT_TEMPLATE(MEM_OP_DECODE)
+JIT_TEMPLATE(STRING_COMPARETO)
+JIT_TEMPLATE(STRING_INDEXOF)
+JIT_TEMPLATE(INTERPRET)
+JIT_TEMPLATE(MONITOR_ENTER)
+JIT_TEMPLATE(MONITOR_ENTER_DEBUG)
+JIT_TEMPLATE(PERIODIC_PROFILING)
+JIT_TEMPLATE(RETURN_PROF)
+JIT_TEMPLATE(INVOKE_METHOD_NO_OPT_PROF)
+JIT_TEMPLATE(INVOKE_METHOD_CHAIN_PROF)
+JIT_TEMPLATE(INVOKE_METHOD_PREDICTED_CHAIN_PROF)
+JIT_TEMPLATE(INVOKE_METHOD_NATIVE_PROF)
diff --git a/vm/compiler/template/armv5te_taint/footer.S b/vm/compiler/template/armv5te_taint/footer.S
new file mode 100644
index 0000000..295273e
--- /dev/null
+++ b/vm/compiler/template/armv5te_taint/footer.S
@@ -0,0 +1,139 @@
+/*
+ * ===========================================================================
+ *  Common subroutines and data
+ * ===========================================================================
+ */
+
+    .text
+    .align  2
+.LinvokeNative:
+    @ Prep for the native call
+    @ r1 = newFP, r0 = methodToCall
+    mov     r2, #0
+    ldr     r9, [rSELF, #offThread_jniLocal_topCookie]@r9<-thread->localRef->...
+    str     r2, [rSELF, #offThread_inJitCodeCache] @ not in jit code cache
+    str     r1, [rSELF, #offThread_curFrame]   @ curFrame = newFp
+    str     r9, [r1, #(offStackSaveArea_localRefCookie - sizeofStackSaveArea)]
+                                        @ newFp->localRefCookie=top
+    ldrh    lr, [rSELF, #offThread_subMode]
+    SAVEAREA_FROM_FP(r10, r1)           @ r10<- new stack save area
+
+    mov     r2, r0                      @ r2<- methodToCall
+    mov     r0, r1                      @ r0<- newFP
+    add     r1, rSELF, #offThread_retval  @ r1<- &retval
+    mov     r3, rSELF                   @ arg3<- self
+    ands    lr, #kSubModeMethodTrace
+    beq     121f                        @ hop if not profiling
+    @ r2: methodToCall, r6: rSELF
+    stmfd   sp!, {r2,r6}
+    stmfd   sp!, {r0-r3}
+    mov     r0, r2
+    mov     r1, r6
+    mov     lr, pc
+    ldr     pc, .LdvmFastMethodTraceEnter
+    ldmfd   sp!, {r0-r3}
+
+    mov     lr, pc
+    ldr     pc, [r2, #offMethod_nativeFunc]
+
+    ldmfd   sp!, {r0-r1}
+    mov     lr, pc
+    ldr     pc, .LdvmFastNativeMethodTraceExit
+    b       212f
+121:
+    mov     lr, pc
+    ldr     pc, [r2, #offMethod_nativeFunc]
+212:
+
+    @ native return; r10=newSaveArea
+
+// begin WITH_TAINT_TRACKING
+    // set return taint
+    SAVEAREA_FROM_FP(r0, rFP)                       @ r0<- stack save area
+    ldr     r1, [r0, #offStackSaveArea_argCount]    @ r1<- arg count
+    sub     r0, r0, r1, lsl #2
+    ldr     r2, [r0, #-4]                           @ r2<- return taint
+    str	    r2, [rSELF, #offThread_rtaint]
+// end WITH_TAINT_TRACKING
+
+    @ equivalent to dvmPopJniLocals
+    ldr     r2, [r10, #offStackSaveArea_returnAddr] @ r2 = chaining cell ret
+    ldr     r0, [r10, #offStackSaveArea_localRefCookie] @ r0<- saved->top
+    ldr     r1, [rSELF, #offThread_exception] @ check for exception
+    str     rFP, [rSELF, #offThread_curFrame]  @ curFrame = fp
+    cmp     r1, #0                      @ null?
+    str     r0, [rSELF, #offThread_jniLocal_topCookie] @ new top <- old top
+    ldr     r0, [r10, #offStackSaveArea_savedPc] @ reload rPC
+
+    @ r0 = dalvikCallsitePC
+    bne     .LhandleException           @ no, handle exception
+
+    str     r2, [rSELF, #offThread_inJitCodeCache] @ set the new mode
+    cmp     r2, #0                      @ return chaining cell still exists?
+    bxne    r2                          @ yes - go ahead
+
+    @ continue executing the next instruction through the interpreter
+    ldr     r1, .LdvmJitToInterpTraceSelectNoChain @ defined in footer.S
+    add     rPC, r0, #6                 @ reconstruct new rPC (advance 6 bytes)
+#if defined(WITH_JIT_TUNING)
+    mov     r0, #kCallsiteInterpreted
+#endif
+    mov     pc, r1
+
+/*
+ * On entry:
+ * r0  Faulting Dalvik PC
+ */
+.LhandleException:
+#if defined(WITH_SELF_VERIFICATION)
+    ldr     pc, .LdeadFood @ should not see this under self-verification mode
+.LdeadFood:
+    .word   0xdeadf00d
+#endif
+    mov     r2, #0
+    str     r2, [rSELF, #offThread_inJitCodeCache] @ in interpreter land
+    ldr     r1, .LdvmMterpCommonExceptionThrown @ PIC way of getting &func
+    ldr     rIBASE, .LdvmAsmInstructionStart    @ same as above
+    mov     rPC, r0                 @ reload the faulting Dalvik address
+    mov     pc, r1                  @ branch to dvmMterpCommonExceptionThrown
+
+    .align  2
+.LdvmAsmInstructionStart:
+    .word   dvmAsmInstructionStart
+.LdvmJitToInterpNoChainNoProfile:
+    .word   dvmJitToInterpNoChainNoProfile
+.LdvmJitToInterpTraceSelectNoChain:
+    .word   dvmJitToInterpTraceSelectNoChain
+.LdvmJitToInterpNoChain:
+    .word   dvmJitToInterpNoChain
+.LdvmMterpStdBail:
+    .word   dvmMterpStdBail
+.LdvmMterpCommonExceptionThrown:
+    .word   dvmMterpCommonExceptionThrown
+.LdvmLockObject:
+    .word   dvmLockObject
+.LdvmJitTraceProfilingOff:
+    .word   dvmJitTraceProfilingOff
+#if defined(WITH_JIT_TUNING)
+.LdvmICHitCount:
+    .word   gDvmICHitCount
+#endif
+#if defined(WITH_SELF_VERIFICATION)
+.LdvmSelfVerificationMemOpDecode:
+    .word   dvmSelfVerificationMemOpDecode
+#endif
+.LdvmFastMethodTraceEnter:
+    .word   dvmFastMethodTraceEnter
+.LdvmFastNativeMethodTraceExit:
+    .word   dvmFastNativeMethodTraceExit
+.LdvmFastMethodTraceExit:
+    .word   dvmFastMethodTraceExit
+.L__aeabi_cdcmple:
+    .word   __aeabi_cdcmple
+.L__aeabi_cfcmple:
+    .word   __aeabi_cfcmple
+
+    .global dmvCompilerTemplateEnd
+dmvCompilerTemplateEnd:
+
+#endif /* WITH_JIT */
diff --git a/vm/compiler/template/armv5te_taint/header.S b/vm/compiler/template/armv5te_taint/header.S
new file mode 100644
index 0000000..6dcf5b9
--- /dev/null
+++ b/vm/compiler/template/armv5te_taint/header.S
@@ -0,0 +1,95 @@
+/*
+ * Copyright (C) 2008 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#if defined(WITH_JIT)
+
+/*
+ * ARMv5 definitions and declarations.
+ */
+
+/*
+ARM EABI general notes:
+
+r0-r3 hold first 4 args to a method; they are not preserved across method calls
+r4-r8 are available for general use
+r9 is given special treatment in some situations, but not for us
+r10 (sl) seems to be generally available
+r11 (fp) is used by gcc (unless -fomit-frame-pointer is set)
+r12 (ip) is scratch -- not preserved across method calls
+r13 (sp) should be managed carefully in case a signal arrives
+r14 (lr) must be preserved
+r15 (pc) can be tinkered with directly
+
+r0 holds returns of <= 4 bytes
+r0-r1 hold returns of 8 bytes, low word in r0
+
+Callee must save/restore r4+ (except r12) if it modifies them.
+
+Stack is "full descending".  Only the arguments that don't fit in the first 4
+registers are placed on the stack.  "sp" points at the first stacked argument
+(i.e. the 5th arg).
+
+VFP: single-precision results in s0, double-precision results in d0.
+
+In the EABI, "sp" must be 64-bit aligned on entry to a function, and any
+64-bit quantities (long long, double) must be 64-bit aligned.
+*/
+
+/*
+JIT and ARM notes:
+
+The following registers have fixed assignments:
+
+  reg nick      purpose
+  r5  rFP       interpreted frame pointer, used for accessing locals and args
+  r6  rSELF     thread pointer
+
+The following registers have fixed assignments in mterp but are scratch
+registers in compiled code
+
+  reg nick      purpose
+  r4  rPC       interpreted program counter, used for fetching instructions
+  r7  rINST     first 16-bit code unit of current instruction
+  r8  rIBASE    interpreted instruction base pointer, used for computed goto
+
+Macros are provided for common operations.  Each macro MUST emit only
+one instruction to make instruction-counting easier.  They MUST NOT alter
+unspecified registers or condition codes.
+*/
+
+/* single-purpose registers, given names for clarity */
+#define rPC     r4
+#define rFP     r5
+#define rSELF   r6
+#define rINST   r7
+#define rIBASE  r8
+
+/*
+ * Given a frame pointer, find the stack save area.
+ *
+ * In C this is "((StackSaveArea*)(_fp) -1)".
+ */
+#define SAVEAREA_FROM_FP(_reg, _fpreg) \
+    sub     _reg, _fpreg, #sizeofStackSaveArea
+
+#define EXPORT_PC() \
+    str     rPC, [rFP, #(-sizeofStackSaveArea + offStackSaveArea_currentPc)]
+
+/*
+ * This is a #include, not a %include, because we want the C pre-processor
+ * to expand the macros into assembler assignment statements.
+ */
+#include "../../../mterp/common/asm-constants.h"
diff --git a/vm/compiler/template/armv5te_taint/platform.S b/vm/compiler/template/armv5te_taint/platform.S
new file mode 100644
index 0000000..e0666a5
--- /dev/null
+++ b/vm/compiler/template/armv5te_taint/platform.S
@@ -0,0 +1,5 @@
+/*
+ * ===========================================================================
+ *  CPU-version-specific defines and utility
+ * ===========================================================================
+ */
diff --git a/vm/compiler/template/config-armv7-a b/vm/compiler/template/config-armv7-a
index 9d66e55..b7cf2ea 100644
--- a/vm/compiler/template/config-armv7-a
+++ b/vm/compiler/template/config-armv7-a
@@ -19,40 +19,42 @@
 
 # file header and basic definitions
 #import c/header.c
-import armv5te/header.S
+import armv5te_taint/header.S
 
 # C pre-processor defines for stub C instructions
 #import cstubs/stubdefs.c
 
 # highly-platform-specific defs
-import armv5te-vfp/platform.S
+import armv5te-vfp_taint/platform.S
 
 # common defs for the C helpers; include this before the instruction handlers
 #import c/opcommon.c
 
 # opcode list; argument to op-start is default directory
-op-start armv5te-vfp
-    op TEMPLATE_CMP_LONG armv5te
-    op TEMPLATE_INVOKE_METHOD_CHAIN armv5te
-    op TEMPLATE_INVOKE_METHOD_NATIVE armv5te
-    op TEMPLATE_INVOKE_METHOD_NO_OPT armv5te
-    op TEMPLATE_INVOKE_METHOD_PREDICTED_CHAIN armv5te
-    op TEMPLATE_MUL_LONG armv5te
-    op TEMPLATE_RETURN armv5te
-    op TEMPLATE_SHL_LONG armv5te
-    op TEMPLATE_SHR_LONG armv5te
-    op TEMPLATE_USHR_LONG armv5te
-    op TEMPLATE_THROW_EXCEPTION_COMMON armv5te
-    op TEMPLATE_STRING_COMPARETO armv5te
-    op TEMPLATE_STRING_INDEXOF armv5te
-    op TEMPLATE_INTERPRET armv5te
-    op TEMPLATE_MONITOR_ENTER armv5te
-    op TEMPLATE_MONITOR_ENTER_DEBUG armv5te
-    op TEMPLATE_PERIODIC_PROFILING armv5te
-    op TEMPLATE_INVOKE_METHOD_CHAIN_PROF armv5te
-    op TEMPLATE_INVOKE_METHOD_PREDICTED_CHAIN_PROF armv5te
-    op TEMPLATE_INVOKE_METHOD_NATIVE_PROF armv5te
-    op TEMPLATE_INVOKE_METHOD_NO_OPT_PROF armv5te
+op-start armv5te-vfp_taint
+    op TEMPLATE_CMP_LONG armv5te_taint
+    op TEMPLATE_INVOKE_METHOD_CHAIN armv5te_taint
+    op TEMPLATE_INVOKE_METHOD_NATIVE armv5te_taint
+    op TEMPLATE_INVOKE_METHOD_NO_OPT armv5te_taint
+    op TEMPLATE_INVOKE_METHOD_PREDICTED_CHAIN armv5te_taint
+    op TEMPLATE_MUL_LONG armv5te_taint
+    op TEMPLATE_RETURN armv5te_taint
+    op TEMPLATE_SHL_LONG armv5te_taint
+    op TEMPLATE_SHR_LONG armv5te_taint
+    op TEMPLATE_USHR_LONG armv5te_taint
+    op TEMPLATE_THROW_EXCEPTION_COMMON armv5te_taint
+    op TEMPLATE_STRING_COMPARETO armv5te_taint
+    op TEMPLATE_STRING_INDEXOF armv5te_taint
+    op TEMPLATE_INTERPRET armv5te_taint
+    op TEMPLATE_MONITOR_ENTER armv5te_taint
+    op TEMPLATE_MONITOR_ENTER_DEBUG armv5te_taint
+
+    # PJG: FIXME: new!
+    op TEMPLATE_PERIODIC_PROFILING armv5te_taint
+    op TEMPLATE_INVOKE_METHOD_CHAIN_PROF armv5te_taint
+    op TEMPLATE_INVOKE_METHOD_PREDICTED_CHAIN_PROF armv5te_taint
+    op TEMPLATE_INVOKE_METHOD_NATIVE_PROF armv5te_taint
+    op TEMPLATE_INVOKE_METHOD_NO_OPT_PROF armv5te_taint
     op TEMPLATE_RETURN_PROF armv5te
 op-end
 
@@ -64,4 +66,4 @@ op-end
 #import cstubs/enddefs.c
 
 # common subroutines for asm
-import armv5te/footer.S
+import armv5te_taint/footer.S
diff --git a/vm/compiler/template/config-armv7-a-neon b/vm/compiler/template/config-armv7-a-neon
index 9d66e55..b7cf2ea 100644
--- a/vm/compiler/template/config-armv7-a-neon
+++ b/vm/compiler/template/config-armv7-a-neon
@@ -19,40 +19,42 @@
 
 # file header and basic definitions
 #import c/header.c
-import armv5te/header.S
+import armv5te_taint/header.S
 
 # C pre-processor defines for stub C instructions
 #import cstubs/stubdefs.c
 
 # highly-platform-specific defs
-import armv5te-vfp/platform.S
+import armv5te-vfp_taint/platform.S
 
 # common defs for the C helpers; include this before the instruction handlers
 #import c/opcommon.c
 
 # opcode list; argument to op-start is default directory
-op-start armv5te-vfp
-    op TEMPLATE_CMP_LONG armv5te
-    op TEMPLATE_INVOKE_METHOD_CHAIN armv5te
-    op TEMPLATE_INVOKE_METHOD_NATIVE armv5te
-    op TEMPLATE_INVOKE_METHOD_NO_OPT armv5te
-    op TEMPLATE_INVOKE_METHOD_PREDICTED_CHAIN armv5te
-    op TEMPLATE_MUL_LONG armv5te
-    op TEMPLATE_RETURN armv5te
-    op TEMPLATE_SHL_LONG armv5te
-    op TEMPLATE_SHR_LONG armv5te
-    op TEMPLATE_USHR_LONG armv5te
-    op TEMPLATE_THROW_EXCEPTION_COMMON armv5te
-    op TEMPLATE_STRING_COMPARETO armv5te
-    op TEMPLATE_STRING_INDEXOF armv5te
-    op TEMPLATE_INTERPRET armv5te
-    op TEMPLATE_MONITOR_ENTER armv5te
-    op TEMPLATE_MONITOR_ENTER_DEBUG armv5te
-    op TEMPLATE_PERIODIC_PROFILING armv5te
-    op TEMPLATE_INVOKE_METHOD_CHAIN_PROF armv5te
-    op TEMPLATE_INVOKE_METHOD_PREDICTED_CHAIN_PROF armv5te
-    op TEMPLATE_INVOKE_METHOD_NATIVE_PROF armv5te
-    op TEMPLATE_INVOKE_METHOD_NO_OPT_PROF armv5te
+op-start armv5te-vfp_taint
+    op TEMPLATE_CMP_LONG armv5te_taint
+    op TEMPLATE_INVOKE_METHOD_CHAIN armv5te_taint
+    op TEMPLATE_INVOKE_METHOD_NATIVE armv5te_taint
+    op TEMPLATE_INVOKE_METHOD_NO_OPT armv5te_taint
+    op TEMPLATE_INVOKE_METHOD_PREDICTED_CHAIN armv5te_taint
+    op TEMPLATE_MUL_LONG armv5te_taint
+    op TEMPLATE_RETURN armv5te_taint
+    op TEMPLATE_SHL_LONG armv5te_taint
+    op TEMPLATE_SHR_LONG armv5te_taint
+    op TEMPLATE_USHR_LONG armv5te_taint
+    op TEMPLATE_THROW_EXCEPTION_COMMON armv5te_taint
+    op TEMPLATE_STRING_COMPARETO armv5te_taint
+    op TEMPLATE_STRING_INDEXOF armv5te_taint
+    op TEMPLATE_INTERPRET armv5te_taint
+    op TEMPLATE_MONITOR_ENTER armv5te_taint
+    op TEMPLATE_MONITOR_ENTER_DEBUG armv5te_taint
+
+    # PJG: FIXME: new!
+    op TEMPLATE_PERIODIC_PROFILING armv5te_taint
+    op TEMPLATE_INVOKE_METHOD_CHAIN_PROF armv5te_taint
+    op TEMPLATE_INVOKE_METHOD_PREDICTED_CHAIN_PROF armv5te_taint
+    op TEMPLATE_INVOKE_METHOD_NATIVE_PROF armv5te_taint
+    op TEMPLATE_INVOKE_METHOD_NO_OPT_PROF armv5te_taint
     op TEMPLATE_RETURN_PROF armv5te
 op-end
 
@@ -64,4 +66,4 @@ op-end
 #import cstubs/enddefs.c
 
 # common subroutines for asm
-import armv5te/footer.S
+import armv5te_taint/footer.S
diff --git a/vm/compiler/template/config-armv7-a-neon.notaint b/vm/compiler/template/config-armv7-a-neon.notaint
new file mode 100644
index 0000000..9d66e55
--- /dev/null
+++ b/vm/compiler/template/config-armv7-a-neon.notaint
@@ -0,0 +1,67 @@
+
+# Copyright (C) 2009 The Android Open Source Project
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#      http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+#
+# Configuration for ARMv7-a architecture targets.
+#
+
+# file header and basic definitions
+#import c/header.c
+import armv5te/header.S
+
+# C pre-processor defines for stub C instructions
+#import cstubs/stubdefs.c
+
+# highly-platform-specific defs
+import armv5te-vfp/platform.S
+
+# common defs for the C helpers; include this before the instruction handlers
+#import c/opcommon.c
+
+# opcode list; argument to op-start is default directory
+op-start armv5te-vfp
+    op TEMPLATE_CMP_LONG armv5te
+    op TEMPLATE_INVOKE_METHOD_CHAIN armv5te
+    op TEMPLATE_INVOKE_METHOD_NATIVE armv5te
+    op TEMPLATE_INVOKE_METHOD_NO_OPT armv5te
+    op TEMPLATE_INVOKE_METHOD_PREDICTED_CHAIN armv5te
+    op TEMPLATE_MUL_LONG armv5te
+    op TEMPLATE_RETURN armv5te
+    op TEMPLATE_SHL_LONG armv5te
+    op TEMPLATE_SHR_LONG armv5te
+    op TEMPLATE_USHR_LONG armv5te
+    op TEMPLATE_THROW_EXCEPTION_COMMON armv5te
+    op TEMPLATE_STRING_COMPARETO armv5te
+    op TEMPLATE_STRING_INDEXOF armv5te
+    op TEMPLATE_INTERPRET armv5te
+    op TEMPLATE_MONITOR_ENTER armv5te
+    op TEMPLATE_MONITOR_ENTER_DEBUG armv5te
+    op TEMPLATE_PERIODIC_PROFILING armv5te
+    op TEMPLATE_INVOKE_METHOD_CHAIN_PROF armv5te
+    op TEMPLATE_INVOKE_METHOD_PREDICTED_CHAIN_PROF armv5te
+    op TEMPLATE_INVOKE_METHOD_NATIVE_PROF armv5te
+    op TEMPLATE_INVOKE_METHOD_NO_OPT_PROF armv5te
+    op TEMPLATE_RETURN_PROF armv5te
+op-end
+
+# "helper" code for C; include if you use any of the C stubs (this generates
+# object code, so it's normally excluded)
+##import c/gotoTargets.c
+
+# end of defs; include this when cstubs/stubdefs.c is included
+#import cstubs/enddefs.c
+
+# common subroutines for asm
+import armv5te/footer.S
diff --git a/vm/compiler/template/config-armv7-a.notaint b/vm/compiler/template/config-armv7-a.notaint
new file mode 100644
index 0000000..9d66e55
--- /dev/null
+++ b/vm/compiler/template/config-armv7-a.notaint
@@ -0,0 +1,67 @@
+
+# Copyright (C) 2009 The Android Open Source Project
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#      http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+#
+# Configuration for ARMv7-a architecture targets.
+#
+
+# file header and basic definitions
+#import c/header.c
+import armv5te/header.S
+
+# C pre-processor defines for stub C instructions
+#import cstubs/stubdefs.c
+
+# highly-platform-specific defs
+import armv5te-vfp/platform.S
+
+# common defs for the C helpers; include this before the instruction handlers
+#import c/opcommon.c
+
+# opcode list; argument to op-start is default directory
+op-start armv5te-vfp
+    op TEMPLATE_CMP_LONG armv5te
+    op TEMPLATE_INVOKE_METHOD_CHAIN armv5te
+    op TEMPLATE_INVOKE_METHOD_NATIVE armv5te
+    op TEMPLATE_INVOKE_METHOD_NO_OPT armv5te
+    op TEMPLATE_INVOKE_METHOD_PREDICTED_CHAIN armv5te
+    op TEMPLATE_MUL_LONG armv5te
+    op TEMPLATE_RETURN armv5te
+    op TEMPLATE_SHL_LONG armv5te
+    op TEMPLATE_SHR_LONG armv5te
+    op TEMPLATE_USHR_LONG armv5te
+    op TEMPLATE_THROW_EXCEPTION_COMMON armv5te
+    op TEMPLATE_STRING_COMPARETO armv5te
+    op TEMPLATE_STRING_INDEXOF armv5te
+    op TEMPLATE_INTERPRET armv5te
+    op TEMPLATE_MONITOR_ENTER armv5te
+    op TEMPLATE_MONITOR_ENTER_DEBUG armv5te
+    op TEMPLATE_PERIODIC_PROFILING armv5te
+    op TEMPLATE_INVOKE_METHOD_CHAIN_PROF armv5te
+    op TEMPLATE_INVOKE_METHOD_PREDICTED_CHAIN_PROF armv5te
+    op TEMPLATE_INVOKE_METHOD_NATIVE_PROF armv5te
+    op TEMPLATE_INVOKE_METHOD_NO_OPT_PROF armv5te
+    op TEMPLATE_RETURN_PROF armv5te
+op-end
+
+# "helper" code for C; include if you use any of the C stubs (this generates
+# object code, so it's normally excluded)
+##import c/gotoTargets.c
+
+# end of defs; include this when cstubs/stubdefs.c is included
+#import cstubs/enddefs.c
+
+# common subroutines for asm
+import armv5te/footer.S
diff --git a/vm/compiler/template/out/CompilerTemplateAsm-armv7-a-neon.S b/vm/compiler/template/out/CompilerTemplateAsm-armv7-a-neon.S
index ba798e0..f1396db 100644
--- a/vm/compiler/template/out/CompilerTemplateAsm-armv7-a-neon.S
+++ b/vm/compiler/template/out/CompilerTemplateAsm-armv7-a-neon.S
@@ -4,7 +4,7 @@
  * --> DO NOT EDIT <--
  */
 
-/* File: armv5te/header.S */
+/* File: armv5te_taint/header.S */
 /*
  * Copyright (C) 2008 The Android Open Source Project
  *
@@ -101,7 +101,7 @@ unspecified registers or condition codes.
  */
 #include "../../../mterp/common/asm-constants.h"
 
-/* File: armv5te-vfp/platform.S */
+/* File: armv5te-vfp_taint/platform.S */
 /*
  * ===========================================================================
  *  CPU-version-specific defines and utility
@@ -119,7 +119,7 @@ dvmCompilerTemplateStart:
     .balign 4
     .global dvmCompiler_TEMPLATE_CMP_LONG
 dvmCompiler_TEMPLATE_CMP_LONG:
-/* File: armv5te/TEMPLATE_CMP_LONG.S */
+/* File: armv5te_taint/TEMPLATE_CMP_LONG.S */
     /*
      * Compare two 64-bit values.  Puts 0, 1, or -1 into the destination
      * register based on the results of the comparison.
@@ -158,7 +158,7 @@ dvmCompiler_TEMPLATE_CMP_LONG:
     .balign 4
     .global dvmCompiler_TEMPLATE_RETURN
 dvmCompiler_TEMPLATE_RETURN:
-/* File: armv5te/TEMPLATE_RETURN.S */
+/* File: armv5te_taint/TEMPLATE_RETURN.S */
     /*
      * Unwind a frame from the Dalvik stack for compiled OP_RETURN_XXX.
      * If the stored value in returnAddr
@@ -221,7 +221,7 @@ dvmCompiler_TEMPLATE_RETURN:
     .balign 4
     .global dvmCompiler_TEMPLATE_INVOKE_METHOD_NO_OPT
 dvmCompiler_TEMPLATE_INVOKE_METHOD_NO_OPT:
-/* File: armv5te/TEMPLATE_INVOKE_METHOD_NO_OPT.S */
+/* File: armv5te_taint/TEMPLATE_INVOKE_METHOD_NO_OPT.S */
     /*
      * For polymorphic callsites - setup the Dalvik frame and load Dalvik PC
      * into rPC then jump to dvmJitToInterpNoChain to dispatch the
@@ -234,9 +234,16 @@ dvmCompiler_TEMPLATE_INVOKE_METHOD_NO_OPT:
     ldrb    r8, [rSELF, #offThread_breakFlags] @ r8<- breakFlags
     add     r3, r1, #1  @ Thumb addr is odd
     SAVEAREA_FROM_FP(r1, rFP)           @ r1<- stack save area
-    sub     r1, r1, r7, lsl #2          @ r1<- newFp (old savearea - regsSize)
+// begin WITH_TAINT_TRACKING
+    sub     r1, r1, r7, lsl #3
+    sub     r1, r1, #4                  @ r1<- newFp (old savearea - 2*regsSize - 4)
+// end WITH_TAINT_TRACKING
     SAVEAREA_FROM_FP(r10, r1)           @ r10<- stack save area
-    sub     r10, r10, r2, lsl #2        @ r10<- bottom (newsave - outsSize)
+// begin WITH_TAINT_TRACKING
+    // PJG: typo fixed from 2.3.4
+    sub     r10, r10, r2, lsl #2
+    sub	    r10, r10, #4		@ r10<- bottom (newsave - outsSize - 4)
+// end WITH_TAINT_TRACKING
     cmp     r10, r9                     @ bottom < interpStackEnd?
     bxlo    lr                          @ return to raise stack overflow excep.
     @ r1 = newFP, r0 = methodToCall, r3 = returnCell, rPC = dalvikCallsite
@@ -287,7 +294,7 @@ dvmCompiler_TEMPLATE_INVOKE_METHOD_NO_OPT:
     .balign 4
     .global dvmCompiler_TEMPLATE_INVOKE_METHOD_CHAIN
 dvmCompiler_TEMPLATE_INVOKE_METHOD_CHAIN:
-/* File: armv5te/TEMPLATE_INVOKE_METHOD_CHAIN.S */
+/* File: armv5te_taint/TEMPLATE_INVOKE_METHOD_CHAIN.S */
     /*
      * For monomorphic callsite, setup the Dalvik frame and return to the
      * Thumb code through the link register to transfer control to the callee
@@ -301,10 +308,16 @@ dvmCompiler_TEMPLATE_INVOKE_METHOD_CHAIN:
     ldrb    r8, [rSELF, #offThread_breakFlags]        @ r8<- breakFlags
     add     r3, r1, #1  @ Thumb addr is odd
     SAVEAREA_FROM_FP(r1, rFP)           @ r1<- stack save area
-    sub     r1, r1, r7, lsl #2          @ r1<- newFp (old savearea - regsSize)
+// begin WITH_TAINT_TRACKING
+    sub     r1, r1, r7, lsl #3
+    sub     r1, r1, #4                  @ r1<- newFp (old savearea - 2*regsSize - 4)
+// end WITH_TAINT_TRACKING
     SAVEAREA_FROM_FP(r10, r1)           @ r10<- stack save area
     add     r12, lr, #2                 @ setup the punt-to-interp address
-    sub     r10, r10, r2, lsl #2        @ r10<- bottom (newsave - outsSize)
+// begin WITH_TAINT_TRACKING
+    sub     r10, r10, r2, lsl #2
+    sub	    r10, r10, #4                @ r10<- bottom (newsave - outsSize - 4)
+// end WITH_TAINT_TRACKING
     cmp     r10, r9                     @ bottom < interpStackEnd?
     bxlo    r12                         @ return to raise stack overflow excep.
     @ r1 = newFP, r0 = methodToCall, r3 = returnCell, rPC = dalvikCallsite
@@ -341,7 +354,7 @@ dvmCompiler_TEMPLATE_INVOKE_METHOD_CHAIN:
     .balign 4
     .global dvmCompiler_TEMPLATE_INVOKE_METHOD_PREDICTED_CHAIN
 dvmCompiler_TEMPLATE_INVOKE_METHOD_PREDICTED_CHAIN:
-/* File: armv5te/TEMPLATE_INVOKE_METHOD_PREDICTED_CHAIN.S */
+/* File: armv5te_taint/TEMPLATE_INVOKE_METHOD_PREDICTED_CHAIN.S */
     /*
      * For polymorphic callsite, check whether the cached class pointer matches
      * the current one. If so setup the Dalvik frame and return to the
@@ -406,14 +419,17 @@ dvmCompiler_TEMPLATE_INVOKE_METHOD_PREDICTED_CHAIN:
     .balign 4
     .global dvmCompiler_TEMPLATE_INVOKE_METHOD_NATIVE
 dvmCompiler_TEMPLATE_INVOKE_METHOD_NATIVE:
-/* File: armv5te/TEMPLATE_INVOKE_METHOD_NATIVE.S */
+/* File: armv5te_taint/TEMPLATE_INVOKE_METHOD_NATIVE.S */
     @ r0 = methodToCall, r1 = returnCell, rPC = dalvikCallsite
     @ r7 = methodToCall->registersSize
     ldr     r9, [rSELF, #offThread_interpStackEnd]    @ r9<- interpStackEnd
     ldrb    r8, [rSELF, #offThread_breakFlags]        @ r8<- breakFlags
     add     r3, r1, #1  @ Thumb addr is odd
     SAVEAREA_FROM_FP(r1, rFP)           @ r1<- stack save area
-    sub     r1, r1, r7, lsl #2          @ r1<- newFp (old savearea - regsSize)
+// begin WITH_TAINT_TRACKING
+    sub     r1, r1, r7, lsl #3
+    sub	    r1, r1, #4                  @ r1<- newFp (old savearea - 2*regsSize - 4)
+// end WITH_TAINT_TRACKING
     SAVEAREA_FROM_FP(r10, r1)           @ r10<- stack save area
     cmp     r10, r9                     @ bottom < interpStackEnd?
     bxlo    lr                          @ return to raise stack overflow excep.
@@ -467,6 +483,16 @@ dvmCompiler_TEMPLATE_INVOKE_METHOD_NATIVE:
     ldr     pc, .LdvmFastNativeMethodTraceExit
 #endif
     @ native return; r10=newSaveArea
+
+// begin WITH_TAINT_TRACKING
+    // set return taint
+    SAVEAREA_FROM_FP(r0, rFP)                       @ r0<- stack save area
+    ldr     r1, [r0, #offStackSaveArea_argCount]    @ r1<- arg count
+    sub     r0, r0, r1, lsl #2
+    ldr     r2, [r0, #-4]                           @ r2<- return taint
+    str	    r2, [rSELF, #offThread_rtaint]
+// end WITH_TAINT_TRACKING
+
     @ equivalent to dvmPopJniLocals
     ldr     r2, [r10, #offStackSaveArea_returnAddr] @ r2 = chaining cell ret
     ldr     r0, [r10, #offStackSaveArea_localRefCookie] @ r0<- saved->top
@@ -495,7 +521,7 @@ dvmCompiler_TEMPLATE_INVOKE_METHOD_NATIVE:
     .balign 4
     .global dvmCompiler_TEMPLATE_MUL_LONG
 dvmCompiler_TEMPLATE_MUL_LONG:
-/* File: armv5te/TEMPLATE_MUL_LONG.S */
+/* File: armv5te_taint/TEMPLATE_MUL_LONG.S */
     /*
      * Signed 64-bit integer multiply.
      *
@@ -529,7 +555,7 @@ dvmCompiler_TEMPLATE_MUL_LONG:
     .balign 4
     .global dvmCompiler_TEMPLATE_SHL_LONG
 dvmCompiler_TEMPLATE_SHL_LONG:
-/* File: armv5te/TEMPLATE_SHL_LONG.S */
+/* File: armv5te_taint/TEMPLATE_SHL_LONG.S */
     /*
      * Long integer shift.  This is different from the generic 32/64-bit
      * binary operations because vAA/vBB are 64-bit but vCC (the shift
@@ -550,7 +576,7 @@ dvmCompiler_TEMPLATE_SHL_LONG:
     .balign 4
     .global dvmCompiler_TEMPLATE_SHR_LONG
 dvmCompiler_TEMPLATE_SHR_LONG:
-/* File: armv5te/TEMPLATE_SHR_LONG.S */
+/* File: armv5te_taint/TEMPLATE_SHR_LONG.S */
     /*
      * Long integer shift.  This is different from the generic 32/64-bit
      * binary operations because vAA/vBB are 64-bit but vCC (the shift
@@ -571,7 +597,7 @@ dvmCompiler_TEMPLATE_SHR_LONG:
     .balign 4
     .global dvmCompiler_TEMPLATE_USHR_LONG
 dvmCompiler_TEMPLATE_USHR_LONG:
-/* File: armv5te/TEMPLATE_USHR_LONG.S */
+/* File: armv5te_taint/TEMPLATE_USHR_LONG.S */
     /*
      * Long integer shift.  This is different from the generic 32/64-bit
      * binary operations because vAA/vBB are 64-bit but vCC (the shift
@@ -592,7 +618,7 @@ dvmCompiler_TEMPLATE_USHR_LONG:
     .balign 4
     .global dvmCompiler_TEMPLATE_ADD_FLOAT_VFP
 dvmCompiler_TEMPLATE_ADD_FLOAT_VFP:
-/* File: armv5te-vfp/TEMPLATE_ADD_FLOAT_VFP.S */
+/* File: armv5te-vfp_taint/TEMPLATE_ADD_FLOAT_VFP.S */
 /* File: armv5te-vfp/fbinop.S */
     /*
      * Generic 32-bit floating point operation.  Provide an "instr" line that
@@ -614,7 +640,7 @@ dvmCompiler_TEMPLATE_ADD_FLOAT_VFP:
     .balign 4
     .global dvmCompiler_TEMPLATE_SUB_FLOAT_VFP
 dvmCompiler_TEMPLATE_SUB_FLOAT_VFP:
-/* File: armv5te-vfp/TEMPLATE_SUB_FLOAT_VFP.S */
+/* File: armv5te-vfp_taint/TEMPLATE_SUB_FLOAT_VFP.S */
 /* File: armv5te-vfp/fbinop.S */
     /*
      * Generic 32-bit floating point operation.  Provide an "instr" line that
@@ -636,7 +662,7 @@ dvmCompiler_TEMPLATE_SUB_FLOAT_VFP:
     .balign 4
     .global dvmCompiler_TEMPLATE_MUL_FLOAT_VFP
 dvmCompiler_TEMPLATE_MUL_FLOAT_VFP:
-/* File: armv5te-vfp/TEMPLATE_MUL_FLOAT_VFP.S */
+/* File: armv5te-vfp_taint/TEMPLATE_MUL_FLOAT_VFP.S */
 /* File: armv5te-vfp/fbinop.S */
     /*
      * Generic 32-bit floating point operation.  Provide an "instr" line that
@@ -658,7 +684,7 @@ dvmCompiler_TEMPLATE_MUL_FLOAT_VFP:
     .balign 4
     .global dvmCompiler_TEMPLATE_DIV_FLOAT_VFP
 dvmCompiler_TEMPLATE_DIV_FLOAT_VFP:
-/* File: armv5te-vfp/TEMPLATE_DIV_FLOAT_VFP.S */
+/* File: armv5te-vfp_taint/TEMPLATE_DIV_FLOAT_VFP.S */
 /* File: armv5te-vfp/fbinop.S */
     /*
      * Generic 32-bit floating point operation.  Provide an "instr" line that
@@ -680,7 +706,7 @@ dvmCompiler_TEMPLATE_DIV_FLOAT_VFP:
     .balign 4
     .global dvmCompiler_TEMPLATE_ADD_DOUBLE_VFP
 dvmCompiler_TEMPLATE_ADD_DOUBLE_VFP:
-/* File: armv5te-vfp/TEMPLATE_ADD_DOUBLE_VFP.S */
+/* File: armv5te-vfp_taint/TEMPLATE_ADD_DOUBLE_VFP.S */
 /* File: armv5te-vfp/fbinopWide.S */
     /*
      * Generic 64-bit floating point operation.  Provide an "instr" line that
@@ -702,7 +728,7 @@ dvmCompiler_TEMPLATE_ADD_DOUBLE_VFP:
     .balign 4
     .global dvmCompiler_TEMPLATE_SUB_DOUBLE_VFP
 dvmCompiler_TEMPLATE_SUB_DOUBLE_VFP:
-/* File: armv5te-vfp/TEMPLATE_SUB_DOUBLE_VFP.S */
+/* File: armv5te-vfp_taint/TEMPLATE_SUB_DOUBLE_VFP.S */
 /* File: armv5te-vfp/fbinopWide.S */
     /*
      * Generic 64-bit floating point operation.  Provide an "instr" line that
@@ -724,7 +750,7 @@ dvmCompiler_TEMPLATE_SUB_DOUBLE_VFP:
     .balign 4
     .global dvmCompiler_TEMPLATE_MUL_DOUBLE_VFP
 dvmCompiler_TEMPLATE_MUL_DOUBLE_VFP:
-/* File: armv5te-vfp/TEMPLATE_MUL_DOUBLE_VFP.S */
+/* File: armv5te-vfp_taint/TEMPLATE_MUL_DOUBLE_VFP.S */
 /* File: armv5te-vfp/fbinopWide.S */
     /*
      * Generic 64-bit floating point operation.  Provide an "instr" line that
@@ -746,7 +772,7 @@ dvmCompiler_TEMPLATE_MUL_DOUBLE_VFP:
     .balign 4
     .global dvmCompiler_TEMPLATE_DIV_DOUBLE_VFP
 dvmCompiler_TEMPLATE_DIV_DOUBLE_VFP:
-/* File: armv5te-vfp/TEMPLATE_DIV_DOUBLE_VFP.S */
+/* File: armv5te-vfp_taint/TEMPLATE_DIV_DOUBLE_VFP.S */
 /* File: armv5te-vfp/fbinopWide.S */
     /*
      * Generic 64-bit floating point operation.  Provide an "instr" line that
@@ -768,7 +794,7 @@ dvmCompiler_TEMPLATE_DIV_DOUBLE_VFP:
     .balign 4
     .global dvmCompiler_TEMPLATE_DOUBLE_TO_FLOAT_VFP
 dvmCompiler_TEMPLATE_DOUBLE_TO_FLOAT_VFP:
-/* File: armv5te-vfp/TEMPLATE_DOUBLE_TO_FLOAT_VFP.S */
+/* File: armv5te-vfp_taint/TEMPLATE_DOUBLE_TO_FLOAT_VFP.S */
 /* File: armv5te-vfp/funopNarrower.S */
     /*
      * Generic 64bit-to-32bit floating point unary operation.  Provide an
@@ -791,7 +817,7 @@ dvmCompiler_TEMPLATE_DOUBLE_TO_FLOAT_VFP:
     .balign 4
     .global dvmCompiler_TEMPLATE_DOUBLE_TO_INT_VFP
 dvmCompiler_TEMPLATE_DOUBLE_TO_INT_VFP:
-/* File: armv5te-vfp/TEMPLATE_DOUBLE_TO_INT_VFP.S */
+/* File: armv5te-vfp_taint/TEMPLATE_DOUBLE_TO_INT_VFP.S */
 /* File: armv5te-vfp/funopNarrower.S */
     /*
      * Generic 64bit-to-32bit floating point unary operation.  Provide an
@@ -814,7 +840,7 @@ dvmCompiler_TEMPLATE_DOUBLE_TO_INT_VFP:
     .balign 4
     .global dvmCompiler_TEMPLATE_FLOAT_TO_DOUBLE_VFP
 dvmCompiler_TEMPLATE_FLOAT_TO_DOUBLE_VFP:
-/* File: armv5te-vfp/TEMPLATE_FLOAT_TO_DOUBLE_VFP.S */
+/* File: armv5te-vfp_taint/TEMPLATE_FLOAT_TO_DOUBLE_VFP.S */
 /* File: armv5te-vfp/funopWider.S */
     /*
      * Generic 32bit-to-64bit floating point unary operation.  Provide an
@@ -837,7 +863,7 @@ dvmCompiler_TEMPLATE_FLOAT_TO_DOUBLE_VFP:
     .balign 4
     .global dvmCompiler_TEMPLATE_FLOAT_TO_INT_VFP
 dvmCompiler_TEMPLATE_FLOAT_TO_INT_VFP:
-/* File: armv5te-vfp/TEMPLATE_FLOAT_TO_INT_VFP.S */
+/* File: armv5te-vfp_taint/TEMPLATE_FLOAT_TO_INT_VFP.S */
 /* File: armv5te-vfp/funop.S */
     /*
      * Generic 32bit-to-32bit floating point unary operation.  Provide an
@@ -860,7 +886,7 @@ dvmCompiler_TEMPLATE_FLOAT_TO_INT_VFP:
     .balign 4
     .global dvmCompiler_TEMPLATE_INT_TO_DOUBLE_VFP
 dvmCompiler_TEMPLATE_INT_TO_DOUBLE_VFP:
-/* File: armv5te-vfp/TEMPLATE_INT_TO_DOUBLE_VFP.S */
+/* File: armv5te-vfp_taint/TEMPLATE_INT_TO_DOUBLE_VFP.S */
 /* File: armv5te-vfp/funopWider.S */
     /*
      * Generic 32bit-to-64bit floating point unary operation.  Provide an
@@ -883,7 +909,7 @@ dvmCompiler_TEMPLATE_INT_TO_DOUBLE_VFP:
     .balign 4
     .global dvmCompiler_TEMPLATE_INT_TO_FLOAT_VFP
 dvmCompiler_TEMPLATE_INT_TO_FLOAT_VFP:
-/* File: armv5te-vfp/TEMPLATE_INT_TO_FLOAT_VFP.S */
+/* File: armv5te-vfp_taint/TEMPLATE_INT_TO_FLOAT_VFP.S */
 /* File: armv5te-vfp/funop.S */
     /*
      * Generic 32bit-to-32bit floating point unary operation.  Provide an
@@ -906,7 +932,7 @@ dvmCompiler_TEMPLATE_INT_TO_FLOAT_VFP:
     .balign 4
     .global dvmCompiler_TEMPLATE_CMPG_DOUBLE_VFP
 dvmCompiler_TEMPLATE_CMPG_DOUBLE_VFP:
-/* File: armv5te-vfp/TEMPLATE_CMPG_DOUBLE_VFP.S */
+/* File: armv5te-vfp_taint/TEMPLATE_CMPG_DOUBLE_VFP.S */
     /*
      * Compare two floating-point values.  Puts 0, 1, or -1 into the
      * destination register based on the results of the comparison.
@@ -941,7 +967,7 @@ dvmCompiler_TEMPLATE_CMPG_DOUBLE_VFP:
     .balign 4
     .global dvmCompiler_TEMPLATE_CMPL_DOUBLE_VFP
 dvmCompiler_TEMPLATE_CMPL_DOUBLE_VFP:
-/* File: armv5te-vfp/TEMPLATE_CMPL_DOUBLE_VFP.S */
+/* File: armv5te-vfp_taint/TEMPLATE_CMPL_DOUBLE_VFP.S */
     /*
      * Compare two floating-point values.  Puts 0, 1, or -1 into the
      * destination register based on the results of the comparison.
@@ -975,7 +1001,7 @@ dvmCompiler_TEMPLATE_CMPL_DOUBLE_VFP:
     .balign 4
     .global dvmCompiler_TEMPLATE_CMPG_FLOAT_VFP
 dvmCompiler_TEMPLATE_CMPG_FLOAT_VFP:
-/* File: armv5te-vfp/TEMPLATE_CMPG_FLOAT_VFP.S */
+/* File: armv5te-vfp_taint/TEMPLATE_CMPG_FLOAT_VFP.S */
     /*
      * Compare two floating-point values.  Puts 0, 1, or -1 into the
      * destination register based on the results of the comparison.
@@ -1009,7 +1035,7 @@ dvmCompiler_TEMPLATE_CMPG_FLOAT_VFP:
     .balign 4
     .global dvmCompiler_TEMPLATE_CMPL_FLOAT_VFP
 dvmCompiler_TEMPLATE_CMPL_FLOAT_VFP:
-/* File: armv5te-vfp/TEMPLATE_CMPL_FLOAT_VFP.S */
+/* File: armv5te-vfp_taint/TEMPLATE_CMPL_FLOAT_VFP.S */
     /*
      * Compare two floating-point values.  Puts 0, 1, or -1 into the
      * destination register based on the results of the comparison.
@@ -1043,7 +1069,7 @@ dvmCompiler_TEMPLATE_CMPL_FLOAT_VFP:
     .balign 4
     .global dvmCompiler_TEMPLATE_SQRT_DOUBLE_VFP
 dvmCompiler_TEMPLATE_SQRT_DOUBLE_VFP:
-/* File: armv5te-vfp/TEMPLATE_SQRT_DOUBLE_VFP.S */
+/* File: armv5te-vfp_taint/TEMPLATE_SQRT_DOUBLE_VFP.S */
     /*
      * 64-bit floating point vfp sqrt operation.
      * If the result is a NaN, bail out to library code to do
@@ -1071,7 +1097,7 @@ dvmCompiler_TEMPLATE_SQRT_DOUBLE_VFP:
     .balign 4
     .global dvmCompiler_TEMPLATE_THROW_EXCEPTION_COMMON
 dvmCompiler_TEMPLATE_THROW_EXCEPTION_COMMON:
-/* File: armv5te/TEMPLATE_THROW_EXCEPTION_COMMON.S */
+/* File: armv5te_taint/TEMPLATE_THROW_EXCEPTION_COMMON.S */
     /*
      * Throw an exception from JIT'ed code.
      * On entry:
@@ -1083,7 +1109,7 @@ dvmCompiler_TEMPLATE_THROW_EXCEPTION_COMMON:
     .balign 4
     .global dvmCompiler_TEMPLATE_MEM_OP_DECODE
 dvmCompiler_TEMPLATE_MEM_OP_DECODE:
-/* File: armv5te-vfp/TEMPLATE_MEM_OP_DECODE.S */
+/* File: armv5te-vfp_taint/TEMPLATE_MEM_OP_DECODE.S */
 #if defined(WITH_SELF_VERIFICATION)
     /*
      * This handler encapsulates heap memory ops for selfVerification mode.
@@ -1108,7 +1134,7 @@ dvmCompiler_TEMPLATE_MEM_OP_DECODE:
     .balign 4
     .global dvmCompiler_TEMPLATE_STRING_COMPARETO
 dvmCompiler_TEMPLATE_STRING_COMPARETO:
-/* File: armv5te/TEMPLATE_STRING_COMPARETO.S */
+/* File: armv5te_taint/TEMPLATE_STRING_COMPARETO.S */
     /*
      * String's compareTo.
      *
@@ -1247,7 +1273,7 @@ do_memcmp16:
     .balign 4
     .global dvmCompiler_TEMPLATE_STRING_INDEXOF
 dvmCompiler_TEMPLATE_STRING_INDEXOF:
-/* File: armv5te/TEMPLATE_STRING_INDEXOF.S */
+/* File: armv5te_taint/TEMPLATE_STRING_INDEXOF.S */
     /*
      * String's indexOf.
      *
@@ -1365,7 +1391,7 @@ match_3:
     .balign 4
     .global dvmCompiler_TEMPLATE_INTERPRET
 dvmCompiler_TEMPLATE_INTERPRET:
-/* File: armv5te/TEMPLATE_INTERPRET.S */
+/* File: armv5te_taint/TEMPLATE_INTERPRET.S */
     /*
      * This handler transfers control to the interpeter without performing
      * any lookups.  It may be called either as part of a normal chaining
@@ -1401,7 +1427,7 @@ dvmCompiler_TEMPLATE_INTERPRET:
     .balign 4
     .global dvmCompiler_TEMPLATE_MONITOR_ENTER
 dvmCompiler_TEMPLATE_MONITOR_ENTER:
-/* File: armv5te/TEMPLATE_MONITOR_ENTER.S */
+/* File: armv5te_taint/TEMPLATE_MONITOR_ENTER.S */
     /*
      * Call out to the runtime to lock an object.  Because this thread
      * may have been suspended in THREAD_MONITOR state and the Jit's
@@ -1428,7 +1454,7 @@ dvmCompiler_TEMPLATE_MONITOR_ENTER:
     .balign 4
     .global dvmCompiler_TEMPLATE_MONITOR_ENTER_DEBUG
 dvmCompiler_TEMPLATE_MONITOR_ENTER_DEBUG:
-/* File: armv5te/TEMPLATE_MONITOR_ENTER_DEBUG.S */
+/* File: armv5te_taint/TEMPLATE_MONITOR_ENTER_DEBUG.S */
     /*
      * To support deadlock prediction, this version of MONITOR_ENTER
      * will always call the heavyweight dvmLockObject, check for an
@@ -1462,7 +1488,7 @@ dvmCompiler_TEMPLATE_MONITOR_ENTER_DEBUG:
     .balign 4
     .global dvmCompiler_TEMPLATE_PERIODIC_PROFILING
 dvmCompiler_TEMPLATE_PERIODIC_PROFILING:
-/* File: armv5te/TEMPLATE_PERIODIC_PROFILING.S */
+/* File: armv5te_taint/TEMPLATE_PERIODIC_PROFILING.S */
     /*
      * Increment profile counter for this trace, and decrement
      * sample counter.  If sample counter goes below zero, turn
@@ -1561,9 +1587,9 @@ dvmCompiler_TEMPLATE_RETURN_PROF:
     .balign 4
     .global dvmCompiler_TEMPLATE_INVOKE_METHOD_NO_OPT_PROF
 dvmCompiler_TEMPLATE_INVOKE_METHOD_NO_OPT_PROF:
-/* File: armv5te/TEMPLATE_INVOKE_METHOD_NO_OPT_PROF.S */
+/* File: armv5te_taint/TEMPLATE_INVOKE_METHOD_NO_OPT_PROF.S */
 #define TEMPLATE_INLINE_PROFILING
-/* File: armv5te/TEMPLATE_INVOKE_METHOD_NO_OPT.S */
+/* File: armv5te_taint/TEMPLATE_INVOKE_METHOD_NO_OPT.S */
     /*
      * For polymorphic callsites - setup the Dalvik frame and load Dalvik PC
      * into rPC then jump to dvmJitToInterpNoChain to dispatch the
@@ -1576,9 +1602,16 @@ dvmCompiler_TEMPLATE_INVOKE_METHOD_NO_OPT_PROF:
     ldrb    r8, [rSELF, #offThread_breakFlags] @ r8<- breakFlags
     add     r3, r1, #1  @ Thumb addr is odd
     SAVEAREA_FROM_FP(r1, rFP)           @ r1<- stack save area
-    sub     r1, r1, r7, lsl #2          @ r1<- newFp (old savearea - regsSize)
+// begin WITH_TAINT_TRACKING
+    sub     r1, r1, r7, lsl #3
+    sub     r1, r1, #4                  @ r1<- newFp (old savearea - 2*regsSize - 4)
+// end WITH_TAINT_TRACKING
     SAVEAREA_FROM_FP(r10, r1)           @ r10<- stack save area
-    sub     r10, r10, r2, lsl #2        @ r10<- bottom (newsave - outsSize)
+// begin WITH_TAINT_TRACKING
+    // PJG: typo fixed from 2.3.4
+    sub     r10, r10, r2, lsl #2
+    sub	    r10, r10, #4		@ r10<- bottom (newsave - outsSize - 4)
+// end WITH_TAINT_TRACKING
     cmp     r10, r9                     @ bottom < interpStackEnd?
     bxlo    lr                          @ return to raise stack overflow excep.
     @ r1 = newFP, r0 = methodToCall, r3 = returnCell, rPC = dalvikCallsite
@@ -1631,9 +1664,9 @@ dvmCompiler_TEMPLATE_INVOKE_METHOD_NO_OPT_PROF:
     .balign 4
     .global dvmCompiler_TEMPLATE_INVOKE_METHOD_CHAIN_PROF
 dvmCompiler_TEMPLATE_INVOKE_METHOD_CHAIN_PROF:
-/* File: armv5te/TEMPLATE_INVOKE_METHOD_CHAIN_PROF.S */
+/* File: armv5te_taint/TEMPLATE_INVOKE_METHOD_CHAIN_PROF.S */
 #define TEMPLATE_INLINE_PROFILING
-/* File: armv5te/TEMPLATE_INVOKE_METHOD_CHAIN.S */
+/* File: armv5te_taint/TEMPLATE_INVOKE_METHOD_CHAIN.S */
     /*
      * For monomorphic callsite, setup the Dalvik frame and return to the
      * Thumb code through the link register to transfer control to the callee
@@ -1647,10 +1680,16 @@ dvmCompiler_TEMPLATE_INVOKE_METHOD_CHAIN_PROF:
     ldrb    r8, [rSELF, #offThread_breakFlags]        @ r8<- breakFlags
     add     r3, r1, #1  @ Thumb addr is odd
     SAVEAREA_FROM_FP(r1, rFP)           @ r1<- stack save area
-    sub     r1, r1, r7, lsl #2          @ r1<- newFp (old savearea - regsSize)
+// begin WITH_TAINT_TRACKING
+    sub     r1, r1, r7, lsl #3
+    sub     r1, r1, #4                  @ r1<- newFp (old savearea - 2*regsSize - 4)
+// end WITH_TAINT_TRACKING
     SAVEAREA_FROM_FP(r10, r1)           @ r10<- stack save area
     add     r12, lr, #2                 @ setup the punt-to-interp address
-    sub     r10, r10, r2, lsl #2        @ r10<- bottom (newsave - outsSize)
+// begin WITH_TAINT_TRACKING
+    sub     r10, r10, r2, lsl #2
+    sub	    r10, r10, #4                @ r10<- bottom (newsave - outsSize - 4)
+// end WITH_TAINT_TRACKING
     cmp     r10, r9                     @ bottom < interpStackEnd?
     bxlo    r12                         @ return to raise stack overflow excep.
     @ r1 = newFP, r0 = methodToCall, r3 = returnCell, rPC = dalvikCallsite
@@ -1689,9 +1728,9 @@ dvmCompiler_TEMPLATE_INVOKE_METHOD_CHAIN_PROF:
     .balign 4
     .global dvmCompiler_TEMPLATE_INVOKE_METHOD_PREDICTED_CHAIN_PROF
 dvmCompiler_TEMPLATE_INVOKE_METHOD_PREDICTED_CHAIN_PROF:
-/* File: armv5te/TEMPLATE_INVOKE_METHOD_PREDICTED_CHAIN_PROF.S */
+/* File: armv5te_taint/TEMPLATE_INVOKE_METHOD_PREDICTED_CHAIN_PROF.S */
 #define TEMPLATE_INLINE_PROFILING
-/* File: armv5te/TEMPLATE_INVOKE_METHOD_PREDICTED_CHAIN.S */
+/* File: armv5te_taint/TEMPLATE_INVOKE_METHOD_PREDICTED_CHAIN.S */
     /*
      * For polymorphic callsite, check whether the cached class pointer matches
      * the current one. If so setup the Dalvik frame and return to the
@@ -1758,16 +1797,19 @@ dvmCompiler_TEMPLATE_INVOKE_METHOD_PREDICTED_CHAIN_PROF:
     .balign 4
     .global dvmCompiler_TEMPLATE_INVOKE_METHOD_NATIVE_PROF
 dvmCompiler_TEMPLATE_INVOKE_METHOD_NATIVE_PROF:
-/* File: armv5te/TEMPLATE_INVOKE_METHOD_NATIVE_PROF.S */
+/* File: armv5te_taint/TEMPLATE_INVOKE_METHOD_NATIVE_PROF.S */
 #define TEMPLATE_INLINE_PROFILING
-/* File: armv5te/TEMPLATE_INVOKE_METHOD_NATIVE.S */
+/* File: armv5te_taint/TEMPLATE_INVOKE_METHOD_NATIVE.S */
     @ r0 = methodToCall, r1 = returnCell, rPC = dalvikCallsite
     @ r7 = methodToCall->registersSize
     ldr     r9, [rSELF, #offThread_interpStackEnd]    @ r9<- interpStackEnd
     ldrb    r8, [rSELF, #offThread_breakFlags]        @ r8<- breakFlags
     add     r3, r1, #1  @ Thumb addr is odd
     SAVEAREA_FROM_FP(r1, rFP)           @ r1<- stack save area
-    sub     r1, r1, r7, lsl #2          @ r1<- newFp (old savearea - regsSize)
+// begin WITH_TAINT_TRACKING
+    sub     r1, r1, r7, lsl #3
+    sub	    r1, r1, #4                  @ r1<- newFp (old savearea - 2*regsSize - 4)
+// end WITH_TAINT_TRACKING
     SAVEAREA_FROM_FP(r10, r1)           @ r10<- stack save area
     cmp     r10, r9                     @ bottom < interpStackEnd?
     bxlo    lr                          @ return to raise stack overflow excep.
@@ -1821,6 +1863,16 @@ dvmCompiler_TEMPLATE_INVOKE_METHOD_NATIVE_PROF:
     ldr     pc, .LdvmFastNativeMethodTraceExit
 #endif
     @ native return; r10=newSaveArea
+
+// begin WITH_TAINT_TRACKING
+    // set return taint
+    SAVEAREA_FROM_FP(r0, rFP)                       @ r0<- stack save area
+    ldr     r1, [r0, #offStackSaveArea_argCount]    @ r1<- arg count
+    sub     r0, r0, r1, lsl #2
+    ldr     r2, [r0, #-4]                           @ r2<- return taint
+    str	    r2, [rSELF, #offThread_rtaint]
+// end WITH_TAINT_TRACKING
+
     @ equivalent to dvmPopJniLocals
     ldr     r2, [r10, #offStackSaveArea_returnAddr] @ r2 = chaining cell ret
     ldr     r0, [r10, #offStackSaveArea_localRefCookie] @ r0<- saved->top
@@ -1848,7 +1900,7 @@ dvmCompiler_TEMPLATE_INVOKE_METHOD_NATIVE_PROF:
 #undef TEMPLATE_INLINE_PROFILING
 
     .size   dvmCompilerTemplateStart, .-dvmCompilerTemplateStart
-/* File: armv5te/footer.S */
+/* File: armv5te_taint/footer.S */
 /*
  * ===========================================================================
  *  Common subroutines and data
@@ -1897,6 +1949,16 @@ dvmCompiler_TEMPLATE_INVOKE_METHOD_NATIVE_PROF:
 212:
 
     @ native return; r10=newSaveArea
+
+// begin WITH_TAINT_TRACKING
+    // set return taint
+    SAVEAREA_FROM_FP(r0, rFP)                       @ r0<- stack save area
+    ldr     r1, [r0, #offStackSaveArea_argCount]    @ r1<- arg count
+    sub     r0, r0, r1, lsl #2
+    ldr     r2, [r0, #-4]                           @ r2<- return taint
+    str	    r2, [rSELF, #offThread_rtaint]
+// end WITH_TAINT_TRACKING
+
     @ equivalent to dvmPopJniLocals
     ldr     r2, [r10, #offStackSaveArea_returnAddr] @ r2 = chaining cell ret
     ldr     r0, [r10, #offStackSaveArea_localRefCookie] @ r0<- saved->top
diff --git a/vm/compiler/template/out/CompilerTemplateAsm-armv7-a.S b/vm/compiler/template/out/CompilerTemplateAsm-armv7-a.S
index 825ac40..514e315 100644
--- a/vm/compiler/template/out/CompilerTemplateAsm-armv7-a.S
+++ b/vm/compiler/template/out/CompilerTemplateAsm-armv7-a.S
@@ -4,7 +4,7 @@
  * --> DO NOT EDIT <--
  */
 
-/* File: armv5te/header.S */
+/* File: armv5te_taint/header.S */
 /*
  * Copyright (C) 2008 The Android Open Source Project
  *
@@ -101,7 +101,7 @@ unspecified registers or condition codes.
  */
 #include "../../../mterp/common/asm-constants.h"
 
-/* File: armv5te-vfp/platform.S */
+/* File: armv5te-vfp_taint/platform.S */
 /*
  * ===========================================================================
  *  CPU-version-specific defines and utility
@@ -119,7 +119,7 @@ dvmCompilerTemplateStart:
     .balign 4
     .global dvmCompiler_TEMPLATE_CMP_LONG
 dvmCompiler_TEMPLATE_CMP_LONG:
-/* File: armv5te/TEMPLATE_CMP_LONG.S */
+/* File: armv5te_taint/TEMPLATE_CMP_LONG.S */
     /*
      * Compare two 64-bit values.  Puts 0, 1, or -1 into the destination
      * register based on the results of the comparison.
@@ -158,7 +158,7 @@ dvmCompiler_TEMPLATE_CMP_LONG:
     .balign 4
     .global dvmCompiler_TEMPLATE_RETURN
 dvmCompiler_TEMPLATE_RETURN:
-/* File: armv5te/TEMPLATE_RETURN.S */
+/* File: armv5te_taint/TEMPLATE_RETURN.S */
     /*
      * Unwind a frame from the Dalvik stack for compiled OP_RETURN_XXX.
      * If the stored value in returnAddr
@@ -221,7 +221,7 @@ dvmCompiler_TEMPLATE_RETURN:
     .balign 4
     .global dvmCompiler_TEMPLATE_INVOKE_METHOD_NO_OPT
 dvmCompiler_TEMPLATE_INVOKE_METHOD_NO_OPT:
-/* File: armv5te/TEMPLATE_INVOKE_METHOD_NO_OPT.S */
+/* File: armv5te_taint/TEMPLATE_INVOKE_METHOD_NO_OPT.S */
     /*
      * For polymorphic callsites - setup the Dalvik frame and load Dalvik PC
      * into rPC then jump to dvmJitToInterpNoChain to dispatch the
@@ -234,9 +234,16 @@ dvmCompiler_TEMPLATE_INVOKE_METHOD_NO_OPT:
     ldrb    r8, [rSELF, #offThread_breakFlags] @ r8<- breakFlags
     add     r3, r1, #1  @ Thumb addr is odd
     SAVEAREA_FROM_FP(r1, rFP)           @ r1<- stack save area
-    sub     r1, r1, r7, lsl #2          @ r1<- newFp (old savearea - regsSize)
+// begin WITH_TAINT_TRACKING
+    sub     r1, r1, r7, lsl #3
+    sub     r1, r1, #4                  @ r1<- newFp (old savearea - 2*regsSize - 4)
+// end WITH_TAINT_TRACKING
     SAVEAREA_FROM_FP(r10, r1)           @ r10<- stack save area
-    sub     r10, r10, r2, lsl #2        @ r10<- bottom (newsave - outsSize)
+// begin WITH_TAINT_TRACKING
+    // PJG: typo fixed from 2.3.4
+    sub     r10, r10, r2, lsl #2
+    sub	    r10, r10, #4		@ r10<- bottom (newsave - outsSize - 4)
+// end WITH_TAINT_TRACKING
     cmp     r10, r9                     @ bottom < interpStackEnd?
     bxlo    lr                          @ return to raise stack overflow excep.
     @ r1 = newFP, r0 = methodToCall, r3 = returnCell, rPC = dalvikCallsite
@@ -287,7 +294,7 @@ dvmCompiler_TEMPLATE_INVOKE_METHOD_NO_OPT:
     .balign 4
     .global dvmCompiler_TEMPLATE_INVOKE_METHOD_CHAIN
 dvmCompiler_TEMPLATE_INVOKE_METHOD_CHAIN:
-/* File: armv5te/TEMPLATE_INVOKE_METHOD_CHAIN.S */
+/* File: armv5te_taint/TEMPLATE_INVOKE_METHOD_CHAIN.S */
     /*
      * For monomorphic callsite, setup the Dalvik frame and return to the
      * Thumb code through the link register to transfer control to the callee
@@ -301,10 +308,16 @@ dvmCompiler_TEMPLATE_INVOKE_METHOD_CHAIN:
     ldrb    r8, [rSELF, #offThread_breakFlags]        @ r8<- breakFlags
     add     r3, r1, #1  @ Thumb addr is odd
     SAVEAREA_FROM_FP(r1, rFP)           @ r1<- stack save area
-    sub     r1, r1, r7, lsl #2          @ r1<- newFp (old savearea - regsSize)
+// begin WITH_TAINT_TRACKING
+    sub     r1, r1, r7, lsl #3
+    sub     r1, r1, #4                  @ r1<- newFp (old savearea - 2*regsSize - 4)
+// end WITH_TAINT_TRACKING
     SAVEAREA_FROM_FP(r10, r1)           @ r10<- stack save area
     add     r12, lr, #2                 @ setup the punt-to-interp address
-    sub     r10, r10, r2, lsl #2        @ r10<- bottom (newsave - outsSize)
+// begin WITH_TAINT_TRACKING
+    sub     r10, r10, r2, lsl #2
+    sub	    r10, r10, #4                @ r10<- bottom (newsave - outsSize - 4)
+// end WITH_TAINT_TRACKING
     cmp     r10, r9                     @ bottom < interpStackEnd?
     bxlo    r12                         @ return to raise stack overflow excep.
     @ r1 = newFP, r0 = methodToCall, r3 = returnCell, rPC = dalvikCallsite
@@ -341,7 +354,7 @@ dvmCompiler_TEMPLATE_INVOKE_METHOD_CHAIN:
     .balign 4
     .global dvmCompiler_TEMPLATE_INVOKE_METHOD_PREDICTED_CHAIN
 dvmCompiler_TEMPLATE_INVOKE_METHOD_PREDICTED_CHAIN:
-/* File: armv5te/TEMPLATE_INVOKE_METHOD_PREDICTED_CHAIN.S */
+/* File: armv5te_taint/TEMPLATE_INVOKE_METHOD_PREDICTED_CHAIN.S */
     /*
      * For polymorphic callsite, check whether the cached class pointer matches
      * the current one. If so setup the Dalvik frame and return to the
@@ -406,14 +419,17 @@ dvmCompiler_TEMPLATE_INVOKE_METHOD_PREDICTED_CHAIN:
     .balign 4
     .global dvmCompiler_TEMPLATE_INVOKE_METHOD_NATIVE
 dvmCompiler_TEMPLATE_INVOKE_METHOD_NATIVE:
-/* File: armv5te/TEMPLATE_INVOKE_METHOD_NATIVE.S */
+/* File: armv5te_taint/TEMPLATE_INVOKE_METHOD_NATIVE.S */
     @ r0 = methodToCall, r1 = returnCell, rPC = dalvikCallsite
     @ r7 = methodToCall->registersSize
     ldr     r9, [rSELF, #offThread_interpStackEnd]    @ r9<- interpStackEnd
     ldrb    r8, [rSELF, #offThread_breakFlags]        @ r8<- breakFlags
     add     r3, r1, #1  @ Thumb addr is odd
     SAVEAREA_FROM_FP(r1, rFP)           @ r1<- stack save area
-    sub     r1, r1, r7, lsl #2          @ r1<- newFp (old savearea - regsSize)
+// begin WITH_TAINT_TRACKING
+    sub     r1, r1, r7, lsl #3
+    sub	    r1, r1, #4                  @ r1<- newFp (old savearea - 2*regsSize - 4)
+// end WITH_TAINT_TRACKING
     SAVEAREA_FROM_FP(r10, r1)           @ r10<- stack save area
     cmp     r10, r9                     @ bottom < interpStackEnd?
     bxlo    lr                          @ return to raise stack overflow excep.
@@ -467,6 +483,16 @@ dvmCompiler_TEMPLATE_INVOKE_METHOD_NATIVE:
     ldr     pc, .LdvmFastNativeMethodTraceExit
 #endif
     @ native return; r10=newSaveArea
+
+// begin WITH_TAINT_TRACKING
+    // set return taint
+    SAVEAREA_FROM_FP(r0, rFP)                       @ r0<- stack save area
+    ldr     r1, [r0, #offStackSaveArea_argCount]    @ r1<- arg count
+    sub     r0, r0, r1, lsl #2
+    ldr     r2, [r0, #-4]                           @ r2<- return taint
+    str	    r2, [rSELF, #offThread_rtaint]
+// end WITH_TAINT_TRACKING
+
     @ equivalent to dvmPopJniLocals
     ldr     r2, [r10, #offStackSaveArea_returnAddr] @ r2 = chaining cell ret
     ldr     r0, [r10, #offStackSaveArea_localRefCookie] @ r0<- saved->top
@@ -495,7 +521,7 @@ dvmCompiler_TEMPLATE_INVOKE_METHOD_NATIVE:
     .balign 4
     .global dvmCompiler_TEMPLATE_MUL_LONG
 dvmCompiler_TEMPLATE_MUL_LONG:
-/* File: armv5te/TEMPLATE_MUL_LONG.S */
+/* File: armv5te_taint/TEMPLATE_MUL_LONG.S */
     /*
      * Signed 64-bit integer multiply.
      *
@@ -529,7 +555,7 @@ dvmCompiler_TEMPLATE_MUL_LONG:
     .balign 4
     .global dvmCompiler_TEMPLATE_SHL_LONG
 dvmCompiler_TEMPLATE_SHL_LONG:
-/* File: armv5te/TEMPLATE_SHL_LONG.S */
+/* File: armv5te_taint/TEMPLATE_SHL_LONG.S */
     /*
      * Long integer shift.  This is different from the generic 32/64-bit
      * binary operations because vAA/vBB are 64-bit but vCC (the shift
@@ -550,7 +576,7 @@ dvmCompiler_TEMPLATE_SHL_LONG:
     .balign 4
     .global dvmCompiler_TEMPLATE_SHR_LONG
 dvmCompiler_TEMPLATE_SHR_LONG:
-/* File: armv5te/TEMPLATE_SHR_LONG.S */
+/* File: armv5te_taint/TEMPLATE_SHR_LONG.S */
     /*
      * Long integer shift.  This is different from the generic 32/64-bit
      * binary operations because vAA/vBB are 64-bit but vCC (the shift
@@ -571,7 +597,7 @@ dvmCompiler_TEMPLATE_SHR_LONG:
     .balign 4
     .global dvmCompiler_TEMPLATE_USHR_LONG
 dvmCompiler_TEMPLATE_USHR_LONG:
-/* File: armv5te/TEMPLATE_USHR_LONG.S */
+/* File: armv5te_taint/TEMPLATE_USHR_LONG.S */
     /*
      * Long integer shift.  This is different from the generic 32/64-bit
      * binary operations because vAA/vBB are 64-bit but vCC (the shift
@@ -592,7 +618,7 @@ dvmCompiler_TEMPLATE_USHR_LONG:
     .balign 4
     .global dvmCompiler_TEMPLATE_ADD_FLOAT_VFP
 dvmCompiler_TEMPLATE_ADD_FLOAT_VFP:
-/* File: armv5te-vfp/TEMPLATE_ADD_FLOAT_VFP.S */
+/* File: armv5te-vfp_taint/TEMPLATE_ADD_FLOAT_VFP.S */
 /* File: armv5te-vfp/fbinop.S */
     /*
      * Generic 32-bit floating point operation.  Provide an "instr" line that
@@ -614,7 +640,7 @@ dvmCompiler_TEMPLATE_ADD_FLOAT_VFP:
     .balign 4
     .global dvmCompiler_TEMPLATE_SUB_FLOAT_VFP
 dvmCompiler_TEMPLATE_SUB_FLOAT_VFP:
-/* File: armv5te-vfp/TEMPLATE_SUB_FLOAT_VFP.S */
+/* File: armv5te-vfp_taint/TEMPLATE_SUB_FLOAT_VFP.S */
 /* File: armv5te-vfp/fbinop.S */
     /*
      * Generic 32-bit floating point operation.  Provide an "instr" line that
@@ -636,7 +662,7 @@ dvmCompiler_TEMPLATE_SUB_FLOAT_VFP:
     .balign 4
     .global dvmCompiler_TEMPLATE_MUL_FLOAT_VFP
 dvmCompiler_TEMPLATE_MUL_FLOAT_VFP:
-/* File: armv5te-vfp/TEMPLATE_MUL_FLOAT_VFP.S */
+/* File: armv5te-vfp_taint/TEMPLATE_MUL_FLOAT_VFP.S */
 /* File: armv5te-vfp/fbinop.S */
     /*
      * Generic 32-bit floating point operation.  Provide an "instr" line that
@@ -658,7 +684,7 @@ dvmCompiler_TEMPLATE_MUL_FLOAT_VFP:
     .balign 4
     .global dvmCompiler_TEMPLATE_DIV_FLOAT_VFP
 dvmCompiler_TEMPLATE_DIV_FLOAT_VFP:
-/* File: armv5te-vfp/TEMPLATE_DIV_FLOAT_VFP.S */
+/* File: armv5te-vfp_taint/TEMPLATE_DIV_FLOAT_VFP.S */
 /* File: armv5te-vfp/fbinop.S */
     /*
      * Generic 32-bit floating point operation.  Provide an "instr" line that
@@ -680,7 +706,7 @@ dvmCompiler_TEMPLATE_DIV_FLOAT_VFP:
     .balign 4
     .global dvmCompiler_TEMPLATE_ADD_DOUBLE_VFP
 dvmCompiler_TEMPLATE_ADD_DOUBLE_VFP:
-/* File: armv5te-vfp/TEMPLATE_ADD_DOUBLE_VFP.S */
+/* File: armv5te-vfp_taint/TEMPLATE_ADD_DOUBLE_VFP.S */
 /* File: armv5te-vfp/fbinopWide.S */
     /*
      * Generic 64-bit floating point operation.  Provide an "instr" line that
@@ -702,7 +728,7 @@ dvmCompiler_TEMPLATE_ADD_DOUBLE_VFP:
     .balign 4
     .global dvmCompiler_TEMPLATE_SUB_DOUBLE_VFP
 dvmCompiler_TEMPLATE_SUB_DOUBLE_VFP:
-/* File: armv5te-vfp/TEMPLATE_SUB_DOUBLE_VFP.S */
+/* File: armv5te-vfp_taint/TEMPLATE_SUB_DOUBLE_VFP.S */
 /* File: armv5te-vfp/fbinopWide.S */
     /*
      * Generic 64-bit floating point operation.  Provide an "instr" line that
@@ -724,7 +750,7 @@ dvmCompiler_TEMPLATE_SUB_DOUBLE_VFP:
     .balign 4
     .global dvmCompiler_TEMPLATE_MUL_DOUBLE_VFP
 dvmCompiler_TEMPLATE_MUL_DOUBLE_VFP:
-/* File: armv5te-vfp/TEMPLATE_MUL_DOUBLE_VFP.S */
+/* File: armv5te-vfp_taint/TEMPLATE_MUL_DOUBLE_VFP.S */
 /* File: armv5te-vfp/fbinopWide.S */
     /*
      * Generic 64-bit floating point operation.  Provide an "instr" line that
@@ -746,7 +772,7 @@ dvmCompiler_TEMPLATE_MUL_DOUBLE_VFP:
     .balign 4
     .global dvmCompiler_TEMPLATE_DIV_DOUBLE_VFP
 dvmCompiler_TEMPLATE_DIV_DOUBLE_VFP:
-/* File: armv5te-vfp/TEMPLATE_DIV_DOUBLE_VFP.S */
+/* File: armv5te-vfp_taint/TEMPLATE_DIV_DOUBLE_VFP.S */
 /* File: armv5te-vfp/fbinopWide.S */
     /*
      * Generic 64-bit floating point operation.  Provide an "instr" line that
@@ -768,7 +794,7 @@ dvmCompiler_TEMPLATE_DIV_DOUBLE_VFP:
     .balign 4
     .global dvmCompiler_TEMPLATE_DOUBLE_TO_FLOAT_VFP
 dvmCompiler_TEMPLATE_DOUBLE_TO_FLOAT_VFP:
-/* File: armv5te-vfp/TEMPLATE_DOUBLE_TO_FLOAT_VFP.S */
+/* File: armv5te-vfp_taint/TEMPLATE_DOUBLE_TO_FLOAT_VFP.S */
 /* File: armv5te-vfp/funopNarrower.S */
     /*
      * Generic 64bit-to-32bit floating point unary operation.  Provide an
@@ -791,7 +817,7 @@ dvmCompiler_TEMPLATE_DOUBLE_TO_FLOAT_VFP:
     .balign 4
     .global dvmCompiler_TEMPLATE_DOUBLE_TO_INT_VFP
 dvmCompiler_TEMPLATE_DOUBLE_TO_INT_VFP:
-/* File: armv5te-vfp/TEMPLATE_DOUBLE_TO_INT_VFP.S */
+/* File: armv5te-vfp_taint/TEMPLATE_DOUBLE_TO_INT_VFP.S */
 /* File: armv5te-vfp/funopNarrower.S */
     /*
      * Generic 64bit-to-32bit floating point unary operation.  Provide an
@@ -814,7 +840,7 @@ dvmCompiler_TEMPLATE_DOUBLE_TO_INT_VFP:
     .balign 4
     .global dvmCompiler_TEMPLATE_FLOAT_TO_DOUBLE_VFP
 dvmCompiler_TEMPLATE_FLOAT_TO_DOUBLE_VFP:
-/* File: armv5te-vfp/TEMPLATE_FLOAT_TO_DOUBLE_VFP.S */
+/* File: armv5te-vfp_taint/TEMPLATE_FLOAT_TO_DOUBLE_VFP.S */
 /* File: armv5te-vfp/funopWider.S */
     /*
      * Generic 32bit-to-64bit floating point unary operation.  Provide an
@@ -837,7 +863,7 @@ dvmCompiler_TEMPLATE_FLOAT_TO_DOUBLE_VFP:
     .balign 4
     .global dvmCompiler_TEMPLATE_FLOAT_TO_INT_VFP
 dvmCompiler_TEMPLATE_FLOAT_TO_INT_VFP:
-/* File: armv5te-vfp/TEMPLATE_FLOAT_TO_INT_VFP.S */
+/* File: armv5te-vfp_taint/TEMPLATE_FLOAT_TO_INT_VFP.S */
 /* File: armv5te-vfp/funop.S */
     /*
      * Generic 32bit-to-32bit floating point unary operation.  Provide an
@@ -860,7 +886,7 @@ dvmCompiler_TEMPLATE_FLOAT_TO_INT_VFP:
     .balign 4
     .global dvmCompiler_TEMPLATE_INT_TO_DOUBLE_VFP
 dvmCompiler_TEMPLATE_INT_TO_DOUBLE_VFP:
-/* File: armv5te-vfp/TEMPLATE_INT_TO_DOUBLE_VFP.S */
+/* File: armv5te-vfp_taint/TEMPLATE_INT_TO_DOUBLE_VFP.S */
 /* File: armv5te-vfp/funopWider.S */
     /*
      * Generic 32bit-to-64bit floating point unary operation.  Provide an
@@ -883,7 +909,7 @@ dvmCompiler_TEMPLATE_INT_TO_DOUBLE_VFP:
     .balign 4
     .global dvmCompiler_TEMPLATE_INT_TO_FLOAT_VFP
 dvmCompiler_TEMPLATE_INT_TO_FLOAT_VFP:
-/* File: armv5te-vfp/TEMPLATE_INT_TO_FLOAT_VFP.S */
+/* File: armv5te-vfp_taint/TEMPLATE_INT_TO_FLOAT_VFP.S */
 /* File: armv5te-vfp/funop.S */
     /*
      * Generic 32bit-to-32bit floating point unary operation.  Provide an
@@ -906,7 +932,7 @@ dvmCompiler_TEMPLATE_INT_TO_FLOAT_VFP:
     .balign 4
     .global dvmCompiler_TEMPLATE_CMPG_DOUBLE_VFP
 dvmCompiler_TEMPLATE_CMPG_DOUBLE_VFP:
-/* File: armv5te-vfp/TEMPLATE_CMPG_DOUBLE_VFP.S */
+/* File: armv5te-vfp_taint/TEMPLATE_CMPG_DOUBLE_VFP.S */
     /*
      * Compare two floating-point values.  Puts 0, 1, or -1 into the
      * destination register based on the results of the comparison.
@@ -941,7 +967,7 @@ dvmCompiler_TEMPLATE_CMPG_DOUBLE_VFP:
     .balign 4
     .global dvmCompiler_TEMPLATE_CMPL_DOUBLE_VFP
 dvmCompiler_TEMPLATE_CMPL_DOUBLE_VFP:
-/* File: armv5te-vfp/TEMPLATE_CMPL_DOUBLE_VFP.S */
+/* File: armv5te-vfp_taint/TEMPLATE_CMPL_DOUBLE_VFP.S */
     /*
      * Compare two floating-point values.  Puts 0, 1, or -1 into the
      * destination register based on the results of the comparison.
@@ -975,7 +1001,7 @@ dvmCompiler_TEMPLATE_CMPL_DOUBLE_VFP:
     .balign 4
     .global dvmCompiler_TEMPLATE_CMPG_FLOAT_VFP
 dvmCompiler_TEMPLATE_CMPG_FLOAT_VFP:
-/* File: armv5te-vfp/TEMPLATE_CMPG_FLOAT_VFP.S */
+/* File: armv5te-vfp_taint/TEMPLATE_CMPG_FLOAT_VFP.S */
     /*
      * Compare two floating-point values.  Puts 0, 1, or -1 into the
      * destination register based on the results of the comparison.
@@ -1009,7 +1035,7 @@ dvmCompiler_TEMPLATE_CMPG_FLOAT_VFP:
     .balign 4
     .global dvmCompiler_TEMPLATE_CMPL_FLOAT_VFP
 dvmCompiler_TEMPLATE_CMPL_FLOAT_VFP:
-/* File: armv5te-vfp/TEMPLATE_CMPL_FLOAT_VFP.S */
+/* File: armv5te-vfp_taint/TEMPLATE_CMPL_FLOAT_VFP.S */
     /*
      * Compare two floating-point values.  Puts 0, 1, or -1 into the
      * destination register based on the results of the comparison.
@@ -1043,7 +1069,7 @@ dvmCompiler_TEMPLATE_CMPL_FLOAT_VFP:
     .balign 4
     .global dvmCompiler_TEMPLATE_SQRT_DOUBLE_VFP
 dvmCompiler_TEMPLATE_SQRT_DOUBLE_VFP:
-/* File: armv5te-vfp/TEMPLATE_SQRT_DOUBLE_VFP.S */
+/* File: armv5te-vfp_taint/TEMPLATE_SQRT_DOUBLE_VFP.S */
     /*
      * 64-bit floating point vfp sqrt operation.
      * If the result is a NaN, bail out to library code to do
@@ -1071,7 +1097,7 @@ dvmCompiler_TEMPLATE_SQRT_DOUBLE_VFP:
     .balign 4
     .global dvmCompiler_TEMPLATE_THROW_EXCEPTION_COMMON
 dvmCompiler_TEMPLATE_THROW_EXCEPTION_COMMON:
-/* File: armv5te/TEMPLATE_THROW_EXCEPTION_COMMON.S */
+/* File: armv5te_taint/TEMPLATE_THROW_EXCEPTION_COMMON.S */
     /*
      * Throw an exception from JIT'ed code.
      * On entry:
@@ -1083,7 +1109,7 @@ dvmCompiler_TEMPLATE_THROW_EXCEPTION_COMMON:
     .balign 4
     .global dvmCompiler_TEMPLATE_MEM_OP_DECODE
 dvmCompiler_TEMPLATE_MEM_OP_DECODE:
-/* File: armv5te-vfp/TEMPLATE_MEM_OP_DECODE.S */
+/* File: armv5te-vfp_taint/TEMPLATE_MEM_OP_DECODE.S */
 #if defined(WITH_SELF_VERIFICATION)
     /*
      * This handler encapsulates heap memory ops for selfVerification mode.
@@ -1108,7 +1134,7 @@ dvmCompiler_TEMPLATE_MEM_OP_DECODE:
     .balign 4
     .global dvmCompiler_TEMPLATE_STRING_COMPARETO
 dvmCompiler_TEMPLATE_STRING_COMPARETO:
-/* File: armv5te/TEMPLATE_STRING_COMPARETO.S */
+/* File: armv5te_taint/TEMPLATE_STRING_COMPARETO.S */
     /*
      * String's compareTo.
      *
@@ -1247,7 +1273,7 @@ do_memcmp16:
     .balign 4
     .global dvmCompiler_TEMPLATE_STRING_INDEXOF
 dvmCompiler_TEMPLATE_STRING_INDEXOF:
-/* File: armv5te/TEMPLATE_STRING_INDEXOF.S */
+/* File: armv5te_taint/TEMPLATE_STRING_INDEXOF.S */
     /*
      * String's indexOf.
      *
@@ -1365,7 +1391,7 @@ match_3:
     .balign 4
     .global dvmCompiler_TEMPLATE_INTERPRET
 dvmCompiler_TEMPLATE_INTERPRET:
-/* File: armv5te/TEMPLATE_INTERPRET.S */
+/* File: armv5te_taint/TEMPLATE_INTERPRET.S */
     /*
      * This handler transfers control to the interpeter without performing
      * any lookups.  It may be called either as part of a normal chaining
@@ -1401,7 +1427,7 @@ dvmCompiler_TEMPLATE_INTERPRET:
     .balign 4
     .global dvmCompiler_TEMPLATE_MONITOR_ENTER
 dvmCompiler_TEMPLATE_MONITOR_ENTER:
-/* File: armv5te/TEMPLATE_MONITOR_ENTER.S */
+/* File: armv5te_taint/TEMPLATE_MONITOR_ENTER.S */
     /*
      * Call out to the runtime to lock an object.  Because this thread
      * may have been suspended in THREAD_MONITOR state and the Jit's
@@ -1428,7 +1454,7 @@ dvmCompiler_TEMPLATE_MONITOR_ENTER:
     .balign 4
     .global dvmCompiler_TEMPLATE_MONITOR_ENTER_DEBUG
 dvmCompiler_TEMPLATE_MONITOR_ENTER_DEBUG:
-/* File: armv5te/TEMPLATE_MONITOR_ENTER_DEBUG.S */
+/* File: armv5te_taint/TEMPLATE_MONITOR_ENTER_DEBUG.S */
     /*
      * To support deadlock prediction, this version of MONITOR_ENTER
      * will always call the heavyweight dvmLockObject, check for an
@@ -1462,7 +1488,7 @@ dvmCompiler_TEMPLATE_MONITOR_ENTER_DEBUG:
     .balign 4
     .global dvmCompiler_TEMPLATE_PERIODIC_PROFILING
 dvmCompiler_TEMPLATE_PERIODIC_PROFILING:
-/* File: armv5te/TEMPLATE_PERIODIC_PROFILING.S */
+/* File: armv5te_taint/TEMPLATE_PERIODIC_PROFILING.S */
     /*
      * Increment profile counter for this trace, and decrement
      * sample counter.  If sample counter goes below zero, turn
@@ -1561,9 +1587,9 @@ dvmCompiler_TEMPLATE_RETURN_PROF:
     .balign 4
     .global dvmCompiler_TEMPLATE_INVOKE_METHOD_NO_OPT_PROF
 dvmCompiler_TEMPLATE_INVOKE_METHOD_NO_OPT_PROF:
-/* File: armv5te/TEMPLATE_INVOKE_METHOD_NO_OPT_PROF.S */
+/* File: armv5te_taint/TEMPLATE_INVOKE_METHOD_NO_OPT_PROF.S */
 #define TEMPLATE_INLINE_PROFILING
-/* File: armv5te/TEMPLATE_INVOKE_METHOD_NO_OPT.S */
+/* File: armv5te_taint/TEMPLATE_INVOKE_METHOD_NO_OPT.S */
     /*
      * For polymorphic callsites - setup the Dalvik frame and load Dalvik PC
      * into rPC then jump to dvmJitToInterpNoChain to dispatch the
@@ -1576,9 +1602,16 @@ dvmCompiler_TEMPLATE_INVOKE_METHOD_NO_OPT_PROF:
     ldrb    r8, [rSELF, #offThread_breakFlags] @ r8<- breakFlags
     add     r3, r1, #1  @ Thumb addr is odd
     SAVEAREA_FROM_FP(r1, rFP)           @ r1<- stack save area
-    sub     r1, r1, r7, lsl #2          @ r1<- newFp (old savearea - regsSize)
+// begin WITH_TAINT_TRACKING
+    sub     r1, r1, r7, lsl #3
+    sub     r1, r1, #4                  @ r1<- newFp (old savearea - 2*regsSize - 4)
+// end WITH_TAINT_TRACKING
     SAVEAREA_FROM_FP(r10, r1)           @ r10<- stack save area
-    sub     r10, r10, r2, lsl #2        @ r10<- bottom (newsave - outsSize)
+// begin WITH_TAINT_TRACKING
+    // PJG: typo fixed from 2.3.4
+    sub     r10, r10, r2, lsl #2
+    sub	    r10, r10, #4		@ r10<- bottom (newsave - outsSize - 4)
+// end WITH_TAINT_TRACKING
     cmp     r10, r9                     @ bottom < interpStackEnd?
     bxlo    lr                          @ return to raise stack overflow excep.
     @ r1 = newFP, r0 = methodToCall, r3 = returnCell, rPC = dalvikCallsite
@@ -1631,9 +1664,9 @@ dvmCompiler_TEMPLATE_INVOKE_METHOD_NO_OPT_PROF:
     .balign 4
     .global dvmCompiler_TEMPLATE_INVOKE_METHOD_CHAIN_PROF
 dvmCompiler_TEMPLATE_INVOKE_METHOD_CHAIN_PROF:
-/* File: armv5te/TEMPLATE_INVOKE_METHOD_CHAIN_PROF.S */
+/* File: armv5te_taint/TEMPLATE_INVOKE_METHOD_CHAIN_PROF.S */
 #define TEMPLATE_INLINE_PROFILING
-/* File: armv5te/TEMPLATE_INVOKE_METHOD_CHAIN.S */
+/* File: armv5te_taint/TEMPLATE_INVOKE_METHOD_CHAIN.S */
     /*
      * For monomorphic callsite, setup the Dalvik frame and return to the
      * Thumb code through the link register to transfer control to the callee
@@ -1647,10 +1680,16 @@ dvmCompiler_TEMPLATE_INVOKE_METHOD_CHAIN_PROF:
     ldrb    r8, [rSELF, #offThread_breakFlags]        @ r8<- breakFlags
     add     r3, r1, #1  @ Thumb addr is odd
     SAVEAREA_FROM_FP(r1, rFP)           @ r1<- stack save area
-    sub     r1, r1, r7, lsl #2          @ r1<- newFp (old savearea - regsSize)
+// begin WITH_TAINT_TRACKING
+    sub     r1, r1, r7, lsl #3
+    sub     r1, r1, #4                  @ r1<- newFp (old savearea - 2*regsSize - 4)
+// end WITH_TAINT_TRACKING
     SAVEAREA_FROM_FP(r10, r1)           @ r10<- stack save area
     add     r12, lr, #2                 @ setup the punt-to-interp address
-    sub     r10, r10, r2, lsl #2        @ r10<- bottom (newsave - outsSize)
+// begin WITH_TAINT_TRACKING
+    sub     r10, r10, r2, lsl #2
+    sub	    r10, r10, #4                @ r10<- bottom (newsave - outsSize - 4)
+// end WITH_TAINT_TRACKING
     cmp     r10, r9                     @ bottom < interpStackEnd?
     bxlo    r12                         @ return to raise stack overflow excep.
     @ r1 = newFP, r0 = methodToCall, r3 = returnCell, rPC = dalvikCallsite
@@ -1689,9 +1728,9 @@ dvmCompiler_TEMPLATE_INVOKE_METHOD_CHAIN_PROF:
     .balign 4
     .global dvmCompiler_TEMPLATE_INVOKE_METHOD_PREDICTED_CHAIN_PROF
 dvmCompiler_TEMPLATE_INVOKE_METHOD_PREDICTED_CHAIN_PROF:
-/* File: armv5te/TEMPLATE_INVOKE_METHOD_PREDICTED_CHAIN_PROF.S */
+/* File: armv5te_taint/TEMPLATE_INVOKE_METHOD_PREDICTED_CHAIN_PROF.S */
 #define TEMPLATE_INLINE_PROFILING
-/* File: armv5te/TEMPLATE_INVOKE_METHOD_PREDICTED_CHAIN.S */
+/* File: armv5te_taint/TEMPLATE_INVOKE_METHOD_PREDICTED_CHAIN.S */
     /*
      * For polymorphic callsite, check whether the cached class pointer matches
      * the current one. If so setup the Dalvik frame and return to the
@@ -1758,16 +1797,19 @@ dvmCompiler_TEMPLATE_INVOKE_METHOD_PREDICTED_CHAIN_PROF:
     .balign 4
     .global dvmCompiler_TEMPLATE_INVOKE_METHOD_NATIVE_PROF
 dvmCompiler_TEMPLATE_INVOKE_METHOD_NATIVE_PROF:
-/* File: armv5te/TEMPLATE_INVOKE_METHOD_NATIVE_PROF.S */
+/* File: armv5te_taint/TEMPLATE_INVOKE_METHOD_NATIVE_PROF.S */
 #define TEMPLATE_INLINE_PROFILING
-/* File: armv5te/TEMPLATE_INVOKE_METHOD_NATIVE.S */
+/* File: armv5te_taint/TEMPLATE_INVOKE_METHOD_NATIVE.S */
     @ r0 = methodToCall, r1 = returnCell, rPC = dalvikCallsite
     @ r7 = methodToCall->registersSize
     ldr     r9, [rSELF, #offThread_interpStackEnd]    @ r9<- interpStackEnd
     ldrb    r8, [rSELF, #offThread_breakFlags]        @ r8<- breakFlags
     add     r3, r1, #1  @ Thumb addr is odd
     SAVEAREA_FROM_FP(r1, rFP)           @ r1<- stack save area
-    sub     r1, r1, r7, lsl #2          @ r1<- newFp (old savearea - regsSize)
+// begin WITH_TAINT_TRACKING
+    sub     r1, r1, r7, lsl #3
+    sub	    r1, r1, #4                  @ r1<- newFp (old savearea - 2*regsSize - 4)
+// end WITH_TAINT_TRACKING
     SAVEAREA_FROM_FP(r10, r1)           @ r10<- stack save area
     cmp     r10, r9                     @ bottom < interpStackEnd?
     bxlo    lr                          @ return to raise stack overflow excep.
@@ -1821,6 +1863,16 @@ dvmCompiler_TEMPLATE_INVOKE_METHOD_NATIVE_PROF:
     ldr     pc, .LdvmFastNativeMethodTraceExit
 #endif
     @ native return; r10=newSaveArea
+
+// begin WITH_TAINT_TRACKING
+    // set return taint
+    SAVEAREA_FROM_FP(r0, rFP)                       @ r0<- stack save area
+    ldr     r1, [r0, #offStackSaveArea_argCount]    @ r1<- arg count
+    sub     r0, r0, r1, lsl #2
+    ldr     r2, [r0, #-4]                           @ r2<- return taint
+    str	    r2, [rSELF, #offThread_rtaint]
+// end WITH_TAINT_TRACKING
+
     @ equivalent to dvmPopJniLocals
     ldr     r2, [r10, #offStackSaveArea_returnAddr] @ r2 = chaining cell ret
     ldr     r0, [r10, #offStackSaveArea_localRefCookie] @ r0<- saved->top
@@ -1848,7 +1900,7 @@ dvmCompiler_TEMPLATE_INVOKE_METHOD_NATIVE_PROF:
 #undef TEMPLATE_INLINE_PROFILING
 
     .size   dvmCompilerTemplateStart, .-dvmCompilerTemplateStart
-/* File: armv5te/footer.S */
+/* File: armv5te_taint/footer.S */
 /*
  * ===========================================================================
  *  Common subroutines and data
@@ -1897,6 +1949,16 @@ dvmCompiler_TEMPLATE_INVOKE_METHOD_NATIVE_PROF:
 212:
 
     @ native return; r10=newSaveArea
+
+// begin WITH_TAINT_TRACKING
+    // set return taint
+    SAVEAREA_FROM_FP(r0, rFP)                       @ r0<- stack save area
+    ldr     r1, [r0, #offStackSaveArea_argCount]    @ r1<- arg count
+    sub     r0, r0, r1, lsl #2
+    ldr     r2, [r0, #-4]                           @ r2<- return taint
+    str	    r2, [rSELF, #offThread_rtaint]
+// end WITH_TAINT_TRACKING
+
     @ equivalent to dvmPopJniLocals
     ldr     r2, [r10, #offStackSaveArea_returnAddr] @ r2 = chaining cell ret
     ldr     r0, [r10, #offStackSaveArea_localRefCookie] @ r0<- saved->top
diff --git a/vm/compiler/template_notaint/Makefile-template b/vm/compiler/template_notaint/Makefile-template
new file mode 100644
index 0000000..9203183
--- /dev/null
+++ b/vm/compiler/template_notaint/Makefile-template
@@ -0,0 +1,49 @@
+# Copyright (C) 2008 The Android Open Source Project
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#      http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+#
+# Makefile for the Dalvik modular interpreter.  This is not currently
+# integrated into the build system.
+#
+
+SHELL := /bin/sh
+
+# Build system has TARGET_ARCH=arm, but we need the exact architecture.
+# The base assumption for an ARM platform is ARMv5TE, but we may want to
+# support older ARMv4 devices, or use special features from ARMv6 or VFP.
+# The simulator build is "desktop".
+#
+# To generate sources for all targets:
+# for arch in desktop armv5te; do TARGET_ARCH_EXT=$arch make -f Makefile-mterp; done
+#
+#TARGET_ARCH_EXT := armv5te
+
+OUTPUT_DIR := out
+
+# Accumulate all possible dependencies for the generated files in a very
+# conservative fashion.  If it's not one of the generated files in "out",
+# assume it's a dependency.
+SOURCE_DEPS := \
+	$(shell find . -path ./$(OUTPUT_DIR) -prune -o -type f -print)
+
+# Source files generated by the script.  There's always one C and one
+# assembly file, though in practice one or the other could be empty.
+GEN_SOURCES := \
+	$(OUTPUT_DIR)/CompilerTemplateAsm-$(TARGET_ARCH_EXT).S
+
+target: $(GEN_SOURCES)
+
+$(GEN_SOURCES): $(SOURCE_DEPS)
+	@mkdir -p out
+	./gen-template.py $(TARGET_ARCH_EXT) $(OUTPUT_DIR)
diff --git a/vm/compiler/template_notaint/README.txt b/vm/compiler/template_notaint/README.txt
new file mode 100644
index 0000000..fced412
--- /dev/null
+++ b/vm/compiler/template_notaint/README.txt
@@ -0,0 +1 @@
+See README.txt under dalvik/vm/mterp for details.
diff --git a/vm/compiler/template_notaint/armv5te-vfp/TEMPLATE_ADD_DOUBLE_VFP.S b/vm/compiler/template_notaint/armv5te-vfp/TEMPLATE_ADD_DOUBLE_VFP.S
new file mode 100644
index 0000000..51693fa
--- /dev/null
+++ b/vm/compiler/template_notaint/armv5te-vfp/TEMPLATE_ADD_DOUBLE_VFP.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te-vfp/fbinopWide.S" {"instr":"faddd   d2, d0, d1"}
diff --git a/vm/compiler/template_notaint/armv5te-vfp/TEMPLATE_ADD_FLOAT_VFP.S b/vm/compiler/template_notaint/armv5te-vfp/TEMPLATE_ADD_FLOAT_VFP.S
new file mode 100644
index 0000000..ad1e122
--- /dev/null
+++ b/vm/compiler/template_notaint/armv5te-vfp/TEMPLATE_ADD_FLOAT_VFP.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te-vfp/fbinop.S" {"instr":"fadds   s2, s0, s1"}
diff --git a/vm/compiler/template_notaint/armv5te-vfp/TEMPLATE_CMPG_DOUBLE_VFP.S b/vm/compiler/template_notaint/armv5te-vfp/TEMPLATE_CMPG_DOUBLE_VFP.S
new file mode 100644
index 0000000..992c894
--- /dev/null
+++ b/vm/compiler/template_notaint/armv5te-vfp/TEMPLATE_CMPG_DOUBLE_VFP.S
@@ -0,0 +1,33 @@
+%verify "executed"
+%verify "basic lt, gt, eq */
+%verify "left arg NaN"
+%verify "right arg NaN"
+    /*
+     * Compare two floating-point values.  Puts 0, 1, or -1 into the
+     * destination register based on the results of the comparison.
+     *
+     * int compare(x, y) {
+     *     if (x == y) {
+     *         return 0;
+     *     } else if (x < y) {
+     *         return -1;
+     *     } else if (x > y) {
+     *         return 1;
+     *     } else {
+     *         return 1;
+     *     }
+     * }
+     *
+     * On entry:
+     *    r0 = &op1 [vBB]
+     *    r1 = &op2 [vCC]
+     */
+    /* op vAA, vBB, vCC */
+    fldd    d0, [r0]                    @ d0<- vBB
+    fldd    d1, [r1]                    @ d1<- vCC
+    fcmpd  d0, d1                       @ compare (vBB, vCC)
+    mov     r0, #1                      @ r0<- 1 (default)
+    fmstat                              @ export status flags
+    mvnmi   r0, #0                      @ (less than) r0<- -1
+    moveq   r0, #0                      @ (equal) r0<- 0
+    bx      lr
diff --git a/vm/compiler/template_notaint/armv5te-vfp/TEMPLATE_CMPG_FLOAT_VFP.S b/vm/compiler/template_notaint/armv5te-vfp/TEMPLATE_CMPG_FLOAT_VFP.S
new file mode 100644
index 0000000..0510ef6
--- /dev/null
+++ b/vm/compiler/template_notaint/armv5te-vfp/TEMPLATE_CMPG_FLOAT_VFP.S
@@ -0,0 +1,32 @@
+%verify "executed"
+%verify "basic lt, gt, eq */
+%verify "left arg NaN"
+%verify "right arg NaN"
+    /*
+     * Compare two floating-point values.  Puts 0, 1, or -1 into the
+     * destination register based on the results of the comparison.
+     *
+     * int compare(x, y) {
+     *     if (x == y) {
+     *         return 0;
+     *     } else if (x < y) {
+     *         return -1;
+     *     } else if (x > y) {
+     *         return 1;
+     *     } else {
+     *         return 1;
+     *     }
+     * }
+     * On entry:
+     *    r0 = &op1 [vBB]
+     *    r1 = &op2 [vCC]
+     */
+    /* op vAA, vBB, vCC */
+    flds    s0, [r0]                    @ d0<- vBB
+    flds    s1, [r1]                    @ d1<- vCC
+    fcmps  s0, s1                      @ compare (vBB, vCC)
+    mov     r0, #1                      @ r0<- 1 (default)
+    fmstat                              @ export status flags
+    mvnmi   r0, #0                      @ (less than) r0<- -1
+    moveq   r0, #0                      @ (equal) r0<- 0
+    bx      lr
diff --git a/vm/compiler/template_notaint/armv5te-vfp/TEMPLATE_CMPL_DOUBLE_VFP.S b/vm/compiler/template_notaint/armv5te-vfp/TEMPLATE_CMPL_DOUBLE_VFP.S
new file mode 100644
index 0000000..7241af1
--- /dev/null
+++ b/vm/compiler/template_notaint/armv5te-vfp/TEMPLATE_CMPL_DOUBLE_VFP.S
@@ -0,0 +1,32 @@
+%verify "executed"
+%verify "basic lt, gt, eq */
+%verify "left arg NaN"
+%verify "right arg NaN"
+    /*
+     * Compare two floating-point values.  Puts 0, 1, or -1 into the
+     * destination register based on the results of the comparison.
+     *
+     * int compare(x, y) {
+     *     if (x == y) {
+     *         return 0;
+     *     } else if (x > y) {
+     *         return 1;
+     *     } else if (x < y) {
+     *         return -1;
+     *     } else {
+     *         return -1;
+     *     }
+     * }
+     * On entry:
+     *    r0 = &op1 [vBB]
+     *    r1 = &op2 [vCC]
+     */
+    /* op vAA, vBB, vCC */
+    fldd    d0, [r0]                    @ d0<- vBB
+    fldd    d1, [r1]                    @ d1<- vCC
+    fcmped  d0, d1                      @ compare (vBB, vCC)
+    mvn     r0, #0                      @ r0<- -1 (default)
+    fmstat                              @ export status flags
+    movgt   r0, #1                      @ (greater than) r0<- 1
+    moveq   r0, #0                      @ (equal) r0<- 0
+    bx      lr
diff --git a/vm/compiler/template_notaint/armv5te-vfp/TEMPLATE_CMPL_FLOAT_VFP.S b/vm/compiler/template_notaint/armv5te-vfp/TEMPLATE_CMPL_FLOAT_VFP.S
new file mode 100644
index 0000000..bdb42d6
--- /dev/null
+++ b/vm/compiler/template_notaint/armv5te-vfp/TEMPLATE_CMPL_FLOAT_VFP.S
@@ -0,0 +1,32 @@
+%verify "executed"
+%verify "basic lt, gt, eq */
+%verify "left arg NaN"
+%verify "right arg NaN"
+    /*
+     * Compare two floating-point values.  Puts 0, 1, or -1 into the
+     * destination register based on the results of the comparison.
+     *
+     * int compare(x, y) {
+     *     if (x == y) {
+     *         return 0;
+     *     } else if (x > y) {
+     *         return 1;
+     *     } else if (x < y) {
+     *         return -1;
+     *     } else {
+     *         return -1;
+     *     }
+     * }
+     * On entry:
+     *    r0 = &op1 [vBB]
+     *    r1 = &op2 [vCC]
+     */
+    /* op vAA, vBB, vCC */
+    flds    s0, [r0]                    @ d0<- vBB
+    flds    s1, [r1]                    @ d1<- vCC
+    fcmps  s0, s1                      @ compare (vBB, vCC)
+    mvn     r0, #0                      @ r0<- -1 (default)
+    fmstat                              @ export status flags
+    movgt   r0, #1                      @ (greater than) r0<- 1
+    moveq   r0, #0                      @ (equal) r0<- 0
+    bx      lr
diff --git a/vm/compiler/template_notaint/armv5te-vfp/TEMPLATE_DIV_DOUBLE_VFP.S b/vm/compiler/template_notaint/armv5te-vfp/TEMPLATE_DIV_DOUBLE_VFP.S
new file mode 100644
index 0000000..8fa58b8
--- /dev/null
+++ b/vm/compiler/template_notaint/armv5te-vfp/TEMPLATE_DIV_DOUBLE_VFP.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te-vfp/fbinopWide.S" {"instr":"fdivd   d2, d0, d1"}
diff --git a/vm/compiler/template_notaint/armv5te-vfp/TEMPLATE_DIV_FLOAT_VFP.S b/vm/compiler/template_notaint/armv5te-vfp/TEMPLATE_DIV_FLOAT_VFP.S
new file mode 100644
index 0000000..fc125ce
--- /dev/null
+++ b/vm/compiler/template_notaint/armv5te-vfp/TEMPLATE_DIV_FLOAT_VFP.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te-vfp/fbinop.S" {"instr":"fdivs   s2, s0, s1"}
diff --git a/vm/compiler/template_notaint/armv5te-vfp/TEMPLATE_DOUBLE_TO_FLOAT_VFP.S b/vm/compiler/template_notaint/armv5te-vfp/TEMPLATE_DOUBLE_TO_FLOAT_VFP.S
new file mode 100644
index 0000000..dba3b08
--- /dev/null
+++ b/vm/compiler/template_notaint/armv5te-vfp/TEMPLATE_DOUBLE_TO_FLOAT_VFP.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te-vfp/funopNarrower.S" {"instr":"fcvtsd  s0, d0"}
diff --git a/vm/compiler/template_notaint/armv5te-vfp/TEMPLATE_DOUBLE_TO_INT_VFP.S b/vm/compiler/template_notaint/armv5te-vfp/TEMPLATE_DOUBLE_TO_INT_VFP.S
new file mode 100644
index 0000000..4d910aa
--- /dev/null
+++ b/vm/compiler/template_notaint/armv5te-vfp/TEMPLATE_DOUBLE_TO_INT_VFP.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te-vfp/funopNarrower.S" {"instr":"ftosizd  s0, d0"}
diff --git a/vm/compiler/template_notaint/armv5te-vfp/TEMPLATE_FLOAT_TO_DOUBLE_VFP.S b/vm/compiler/template_notaint/armv5te-vfp/TEMPLATE_FLOAT_TO_DOUBLE_VFP.S
new file mode 100644
index 0000000..a5157dd
--- /dev/null
+++ b/vm/compiler/template_notaint/armv5te-vfp/TEMPLATE_FLOAT_TO_DOUBLE_VFP.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te-vfp/funopWider.S" {"instr":"fcvtds  d0, s0"}
diff --git a/vm/compiler/template_notaint/armv5te-vfp/TEMPLATE_FLOAT_TO_INT_VFP.S b/vm/compiler/template_notaint/armv5te-vfp/TEMPLATE_FLOAT_TO_INT_VFP.S
new file mode 100644
index 0000000..90900aa
--- /dev/null
+++ b/vm/compiler/template_notaint/armv5te-vfp/TEMPLATE_FLOAT_TO_INT_VFP.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te-vfp/funop.S" {"instr":"ftosizs s1, s0"}
diff --git a/vm/compiler/template_notaint/armv5te-vfp/TEMPLATE_INT_TO_DOUBLE_VFP.S b/vm/compiler/template_notaint/armv5te-vfp/TEMPLATE_INT_TO_DOUBLE_VFP.S
new file mode 100644
index 0000000..c9f4fd6
--- /dev/null
+++ b/vm/compiler/template_notaint/armv5te-vfp/TEMPLATE_INT_TO_DOUBLE_VFP.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te-vfp/funopWider.S" {"instr":"fsitod  d0, s0"}
diff --git a/vm/compiler/template_notaint/armv5te-vfp/TEMPLATE_INT_TO_FLOAT_VFP.S b/vm/compiler/template_notaint/armv5te-vfp/TEMPLATE_INT_TO_FLOAT_VFP.S
new file mode 100644
index 0000000..a8f57b5
--- /dev/null
+++ b/vm/compiler/template_notaint/armv5te-vfp/TEMPLATE_INT_TO_FLOAT_VFP.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te-vfp/funop.S" {"instr":"fsitos  s1, s0"}
diff --git a/vm/compiler/template_notaint/armv5te-vfp/TEMPLATE_MEM_OP_DECODE.S b/vm/compiler/template_notaint/armv5te-vfp/TEMPLATE_MEM_OP_DECODE.S
new file mode 100644
index 0000000..8bee853
--- /dev/null
+++ b/vm/compiler/template_notaint/armv5te-vfp/TEMPLATE_MEM_OP_DECODE.S
@@ -0,0 +1,19 @@
+#if defined(WITH_SELF_VERIFICATION)
+    /*
+     * This handler encapsulates heap memory ops for selfVerification mode.
+     *
+     * The call to the handler is inserted prior to a heap memory operation.
+     * This handler then calls a function to decode the memory op, and process
+     * it accordingly. Afterwards, the handler changes the return address to
+     * skip the memory op so it never gets executed.
+     */
+    vpush   {d0-d15}                    @ save out all fp registers
+    push    {r0-r12,lr}                 @ save out all registers
+    ldr     r2, .LdvmSelfVerificationMemOpDecode @ defined in footer.S
+    mov     r0, lr                      @ arg0 <- link register
+    mov     r1, sp                      @ arg1 <- stack pointer
+    blx     r2                          @ decode and handle the mem op
+    pop     {r0-r12,lr}                 @ restore all registers
+    vpop    {d0-d15}                    @ restore all fp registers
+    bx      lr                          @ return to compiled code
+#endif
diff --git a/vm/compiler/template_notaint/armv5te-vfp/TEMPLATE_MUL_DOUBLE_VFP.S b/vm/compiler/template_notaint/armv5te-vfp/TEMPLATE_MUL_DOUBLE_VFP.S
new file mode 100644
index 0000000..459e796
--- /dev/null
+++ b/vm/compiler/template_notaint/armv5te-vfp/TEMPLATE_MUL_DOUBLE_VFP.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te-vfp/fbinopWide.S" {"instr":"fmuld   d2, d0, d1"}
diff --git a/vm/compiler/template_notaint/armv5te-vfp/TEMPLATE_MUL_FLOAT_VFP.S b/vm/compiler/template_notaint/armv5te-vfp/TEMPLATE_MUL_FLOAT_VFP.S
new file mode 100644
index 0000000..301fa84
--- /dev/null
+++ b/vm/compiler/template_notaint/armv5te-vfp/TEMPLATE_MUL_FLOAT_VFP.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te-vfp/fbinop.S" {"instr":"fmuls   s2, s0, s1"}
diff --git a/vm/compiler/template_notaint/armv5te-vfp/TEMPLATE_RESTORE_STATE.S b/vm/compiler/template_notaint/armv5te-vfp/TEMPLATE_RESTORE_STATE.S
new file mode 100644
index 0000000..196d082
--- /dev/null
+++ b/vm/compiler/template_notaint/armv5te-vfp/TEMPLATE_RESTORE_STATE.S
@@ -0,0 +1,11 @@
+    /*
+     * This handler restores state following a selfVerification memory access.
+     * On entry:
+     *    r0 - offset from rSELF to the 1st element of the coreRegs save array.
+     */
+    add     r0, r0, rSELF               @ pointer to heapArgSpace.coreRegs[0]
+    add     r0, #64                     @ pointer to heapArgSpace.fpRegs[0]
+    vldmia  r0, {d0-d15}
+    sub     r0, #64                     @ pointer to heapArgSpace.coreRegs[0]
+    ldmia   r0, {r0-r12}
+    bx      lr
diff --git a/vm/compiler/template_notaint/armv5te-vfp/TEMPLATE_SAVE_STATE.S b/vm/compiler/template_notaint/armv5te-vfp/TEMPLATE_SAVE_STATE.S
new file mode 100644
index 0000000..11f62b7
--- /dev/null
+++ b/vm/compiler/template_notaint/armv5te-vfp/TEMPLATE_SAVE_STATE.S
@@ -0,0 +1,23 @@
+    /*
+     * This handler performs a register save for selfVerification mode.
+     * On entry:
+     *    Top of stack + 4: r7 value to save
+     *    Top of stack + 0: r0 value to save
+     *    r0 - offset from rSELF to the beginning of the heapArgSpace record
+     *    r7 - the value of regMap
+     *
+     * The handler must save regMap, r0-r12 and then return with r0-r12
+     * with their original values (note that this means r0 and r7 must take
+     * the values on the stack - not the ones in those registers on entry.
+     * Finally, the two registers previously pushed must be popped.
+     */
+    add     r0, r0, rSELF               @ pointer to heapArgSpace
+    stmia   r0!, {r7}                   @ save regMap
+    ldr     r7, [r13, #0]               @ recover r0 value
+    stmia   r0!, {r7}                   @ save r0
+    ldr     r7, [r13, #4]               @ recover r7 value
+    stmia   r0!, {r1-r12}
+    add     r0, #12                     @ move to start of FP save regio
+    vstmia  r0, {d0-d15}
+    pop     {r0, r7}                    @ recover r0, r7
+    bx      lr
diff --git a/vm/compiler/template_notaint/armv5te-vfp/TEMPLATE_SQRT_DOUBLE_VFP.S b/vm/compiler/template_notaint/armv5te-vfp/TEMPLATE_SQRT_DOUBLE_VFP.S
new file mode 100644
index 0000000..1c6bb46
--- /dev/null
+++ b/vm/compiler/template_notaint/armv5te-vfp/TEMPLATE_SQRT_DOUBLE_VFP.S
@@ -0,0 +1,23 @@
+%verify "executed"
+    /*
+     * 64-bit floating point vfp sqrt operation.
+     * If the result is a NaN, bail out to library code to do
+     * the right thing.
+     *
+     * On entry:
+     *     r2 src addr of op1
+     * On exit:
+     *     r0,r1 = res
+     */
+    fldd    d0, [r2]
+    fsqrtd  d1, d0
+    fcmpd   d1, d1
+    fmstat
+    fmrrd   r0, r1, d1
+    bxeq    lr   @ Result OK - return
+    ldr     r2, .Lsqrt
+    fmrrd   r0, r1, d0   @ reload orig operand
+    bx      r2   @ tail call to sqrt library routine
+
+.Lsqrt:
+    .word   sqrt
diff --git a/vm/compiler/template_notaint/armv5te-vfp/TEMPLATE_SUB_DOUBLE_VFP.S b/vm/compiler/template_notaint/armv5te-vfp/TEMPLATE_SUB_DOUBLE_VFP.S
new file mode 100644
index 0000000..8fa20a0
--- /dev/null
+++ b/vm/compiler/template_notaint/armv5te-vfp/TEMPLATE_SUB_DOUBLE_VFP.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te-vfp/fbinopWide.S" {"instr":"fsubd   d2, d0, d1"}
diff --git a/vm/compiler/template_notaint/armv5te-vfp/TEMPLATE_SUB_FLOAT_VFP.S b/vm/compiler/template_notaint/armv5te-vfp/TEMPLATE_SUB_FLOAT_VFP.S
new file mode 100644
index 0000000..5e17e51
--- /dev/null
+++ b/vm/compiler/template_notaint/armv5te-vfp/TEMPLATE_SUB_FLOAT_VFP.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te-vfp/fbinop.S" {"instr":"fsubs   s2, s0, s1"}
diff --git a/vm/compiler/template_notaint/armv5te-vfp/TemplateOpList.h b/vm/compiler/template_notaint/armv5te-vfp/TemplateOpList.h
new file mode 100644
index 0000000..0365ba4
--- /dev/null
+++ b/vm/compiler/template_notaint/armv5te-vfp/TemplateOpList.h
@@ -0,0 +1,65 @@
+/*
+ * Copyright (C) 2009 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+/*
+ * Dalvik opcode list that uses additional templates to complete JIT execution.
+ */
+#ifndef JIT_TEMPLATE
+#define JIT_TEMPLATE(X)
+#endif
+
+JIT_TEMPLATE(CMP_LONG)
+JIT_TEMPLATE(RETURN)
+JIT_TEMPLATE(INVOKE_METHOD_NO_OPT)
+JIT_TEMPLATE(INVOKE_METHOD_CHAIN)
+JIT_TEMPLATE(INVOKE_METHOD_PREDICTED_CHAIN)
+JIT_TEMPLATE(INVOKE_METHOD_NATIVE)
+JIT_TEMPLATE(MUL_LONG)
+JIT_TEMPLATE(SHL_LONG)
+JIT_TEMPLATE(SHR_LONG)
+JIT_TEMPLATE(USHR_LONG)
+JIT_TEMPLATE(ADD_FLOAT_VFP)
+JIT_TEMPLATE(SUB_FLOAT_VFP)
+JIT_TEMPLATE(MUL_FLOAT_VFP)
+JIT_TEMPLATE(DIV_FLOAT_VFP)
+JIT_TEMPLATE(ADD_DOUBLE_VFP)
+JIT_TEMPLATE(SUB_DOUBLE_VFP)
+JIT_TEMPLATE(MUL_DOUBLE_VFP)
+JIT_TEMPLATE(DIV_DOUBLE_VFP)
+JIT_TEMPLATE(DOUBLE_TO_FLOAT_VFP)
+JIT_TEMPLATE(DOUBLE_TO_INT_VFP)
+JIT_TEMPLATE(FLOAT_TO_DOUBLE_VFP)
+JIT_TEMPLATE(FLOAT_TO_INT_VFP)
+JIT_TEMPLATE(INT_TO_DOUBLE_VFP)
+JIT_TEMPLATE(INT_TO_FLOAT_VFP)
+JIT_TEMPLATE(CMPG_DOUBLE_VFP)
+JIT_TEMPLATE(CMPL_DOUBLE_VFP)
+JIT_TEMPLATE(CMPG_FLOAT_VFP)
+JIT_TEMPLATE(CMPL_FLOAT_VFP)
+JIT_TEMPLATE(SQRT_DOUBLE_VFP)
+JIT_TEMPLATE(THROW_EXCEPTION_COMMON)
+JIT_TEMPLATE(MEM_OP_DECODE)
+JIT_TEMPLATE(STRING_COMPARETO)
+JIT_TEMPLATE(STRING_INDEXOF)
+JIT_TEMPLATE(INTERPRET)
+JIT_TEMPLATE(MONITOR_ENTER)
+JIT_TEMPLATE(MONITOR_ENTER_DEBUG)
+JIT_TEMPLATE(PERIODIC_PROFILING)
+JIT_TEMPLATE(RETURN_PROF)
+JIT_TEMPLATE(INVOKE_METHOD_NO_OPT_PROF)
+JIT_TEMPLATE(INVOKE_METHOD_CHAIN_PROF)
+JIT_TEMPLATE(INVOKE_METHOD_PREDICTED_CHAIN_PROF)
+JIT_TEMPLATE(INVOKE_METHOD_NATIVE_PROF)
diff --git a/vm/compiler/template_notaint/armv5te-vfp/fbinop.S b/vm/compiler/template_notaint/armv5te-vfp/fbinop.S
new file mode 100644
index 0000000..3bc4b52
--- /dev/null
+++ b/vm/compiler/template_notaint/armv5te-vfp/fbinop.S
@@ -0,0 +1,14 @@
+    /*
+     * Generic 32-bit floating point operation.  Provide an "instr" line that
+     * specifies an instruction that performs s2 = s0 op s1.
+     *
+     * On entry:
+     *     r0 = target dalvik register address
+     *     r1 = op1 address
+     *     r2 = op2 address
+     */
+     flds    s0,[r1]
+     flds    s1,[r2]
+     $instr
+     fsts    s2,[r0]
+     bx      lr
diff --git a/vm/compiler/template_notaint/armv5te-vfp/fbinopWide.S b/vm/compiler/template_notaint/armv5te-vfp/fbinopWide.S
new file mode 100644
index 0000000..3774646
--- /dev/null
+++ b/vm/compiler/template_notaint/armv5te-vfp/fbinopWide.S
@@ -0,0 +1,14 @@
+    /*
+     * Generic 64-bit floating point operation.  Provide an "instr" line that
+     * specifies an instruction that performs s2 = s0 op s1.
+     *
+     * On entry:
+     *     r0 = target dalvik register address
+     *     r1 = op1 address
+     *     r2 = op2 address
+     */
+     fldd    d0,[r1]
+     fldd    d1,[r2]
+     $instr
+     fstd    d2,[r0]
+     bx      lr
diff --git a/vm/compiler/template_notaint/armv5te-vfp/funop.S b/vm/compiler/template_notaint/armv5te-vfp/funop.S
new file mode 100644
index 0000000..8409c28
--- /dev/null
+++ b/vm/compiler/template_notaint/armv5te-vfp/funop.S
@@ -0,0 +1,15 @@
+    /*
+     * Generic 32bit-to-32bit floating point unary operation.  Provide an
+     * "instr" line that specifies an instruction that performs "s1 = op s0".
+     *
+     * For: float-to-int, int-to-float
+     *
+     * On entry:
+     *     r0 = target dalvik register address
+     *     r1 = src dalvik register address
+     */
+    /* unop vA, vB */
+    flds    s0, [r1]                    @ s0<- vB
+    $instr                              @ s1<- op s0
+    fsts    s1, [r0]                    @ vA<- s1
+    bx      lr
diff --git a/vm/compiler/template_notaint/armv5te-vfp/funopNarrower.S b/vm/compiler/template_notaint/armv5te-vfp/funopNarrower.S
new file mode 100644
index 0000000..8566fca
--- /dev/null
+++ b/vm/compiler/template_notaint/armv5te-vfp/funopNarrower.S
@@ -0,0 +1,15 @@
+    /*
+     * Generic 64bit-to-32bit floating point unary operation.  Provide an
+     * "instr" line that specifies an instruction that performs "s0 = op d0".
+     *
+     * For: double-to-int, double-to-float
+     *
+     * On entry:
+     *     r0 = target dalvik register address
+     *     r1 = src dalvik register address
+     */
+    /* unop vA, vB */
+    fldd    d0, [r1]                    @ d0<- vB
+    $instr                              @ s0<- op d0
+    fsts    s0, [r0]                    @ vA<- s0
+    bx      lr
diff --git a/vm/compiler/template_notaint/armv5te-vfp/funopWider.S b/vm/compiler/template_notaint/armv5te-vfp/funopWider.S
new file mode 100644
index 0000000..dbe745c
--- /dev/null
+++ b/vm/compiler/template_notaint/armv5te-vfp/funopWider.S
@@ -0,0 +1,15 @@
+    /*
+     * Generic 32bit-to-64bit floating point unary operation.  Provide an
+     * "instr" line that specifies an instruction that performs "d0 = op s0".
+     *
+     * For: int-to-double, float-to-double
+     *
+     * On entry:
+     *     r0 = target dalvik register address
+     *     r1 = src dalvik register address
+     */
+    /* unop vA, vB */
+    flds    s0, [r1]                    @ s0<- vB
+    $instr                              @ d0<- op s0
+    fstd    d0, [r0]                    @ vA<- d0
+    bx      lr
diff --git a/vm/compiler/template_notaint/armv5te-vfp/platform.S b/vm/compiler/template_notaint/armv5te-vfp/platform.S
new file mode 100644
index 0000000..e0666a5
--- /dev/null
+++ b/vm/compiler/template_notaint/armv5te-vfp/platform.S
@@ -0,0 +1,5 @@
+/*
+ * ===========================================================================
+ *  CPU-version-specific defines and utility
+ * ===========================================================================
+ */
diff --git a/vm/compiler/template_notaint/armv5te/TEMPLATE_CMPG_DOUBLE.S b/vm/compiler/template_notaint/armv5te/TEMPLATE_CMPG_DOUBLE.S
new file mode 100644
index 0000000..f18f6d3
--- /dev/null
+++ b/vm/compiler/template_notaint/armv5te/TEMPLATE_CMPG_DOUBLE.S
@@ -0,0 +1 @@
+%include "armv5te/TEMPLATE_CMPL_DOUBLE.S" { "naninst":"mov     r0, #1" }
diff --git a/vm/compiler/template_notaint/armv5te/TEMPLATE_CMPG_FLOAT.S b/vm/compiler/template_notaint/armv5te/TEMPLATE_CMPG_FLOAT.S
new file mode 100644
index 0000000..02887e5
--- /dev/null
+++ b/vm/compiler/template_notaint/armv5te/TEMPLATE_CMPG_FLOAT.S
@@ -0,0 +1 @@
+%include "armv5te/TEMPLATE_CMPL_FLOAT.S" { "naninst":"mov     r0, #1" }
diff --git a/vm/compiler/template_notaint/armv5te/TEMPLATE_CMPL_DOUBLE.S b/vm/compiler/template_notaint/armv5te/TEMPLATE_CMPL_DOUBLE.S
new file mode 100644
index 0000000..4fd5a71
--- /dev/null
+++ b/vm/compiler/template_notaint/armv5te/TEMPLATE_CMPL_DOUBLE.S
@@ -0,0 +1,38 @@
+%default { "naninst":"mvn     r0, #0" }
+    /*
+     * For the JIT: incoming arguments in r0-r1, r2-r3
+     *              result in r0
+     *
+     * Compare two floating-point values.  Puts 0, 1, or -1 into the
+     * destination register based on the results of the comparison.
+     *
+     * Provide a "naninst" instruction that puts 1 or -1 into r1 depending
+     * on what value we'd like to return when one of the operands is NaN.
+     *
+     * See OP_CMPL_FLOAT for an explanation.
+     *
+     * For: cmpl-double, cmpg-double
+     */
+    /* op vAA, vBB, vCC */
+    push    {r0-r3}                     @ save operands
+    mov     r11, lr                     @ save return address
+    mov     lr, pc
+    ldr     pc, .L__aeabi_cdcmple       @ PIC way of "bl __aeabi_cdcmple"
+    bhi     .L${opcode}_gt_or_nan       @ C set and Z clear, disambiguate
+    mvncc   r0, #0                      @ (less than) r1<- -1
+    moveq   r0, #0                      @ (equal) r1<- 0, trumps less than
+    add     sp, #16                     @ drop unused operands
+    bx      r11
+
+    @ Test for NaN with a second comparison.  EABI forbids testing bit
+    @ patterns, and we can't represent 0x7fc00000 in immediate form, so
+    @ make the library call.
+.L${opcode}_gt_or_nan:
+    pop     {r2-r3}                     @ restore operands in reverse order
+    pop     {r0-r1}                     @ restore operands in reverse order
+    mov     lr, pc
+    ldr     pc, .L__aeabi_cdcmple       @ r0<- Z set if eq, C clear if <
+    movcc   r0, #1                      @ (greater than) r1<- 1
+    bxcc    r11
+    $naninst                            @ r1<- 1 or -1 for NaN
+    bx      r11
diff --git a/vm/compiler/template_notaint/armv5te/TEMPLATE_CMPL_FLOAT.S b/vm/compiler/template_notaint/armv5te/TEMPLATE_CMPL_FLOAT.S
new file mode 100644
index 0000000..d0f2bec
--- /dev/null
+++ b/vm/compiler/template_notaint/armv5te/TEMPLATE_CMPL_FLOAT.S
@@ -0,0 +1,56 @@
+%default { "naninst":"mvn     r0, #0" }
+    /*
+     * For the JIT: incoming arguments in r0-r1, r2-r3
+     *              result in r0
+     *
+     * Compare two floating-point values.  Puts 0, 1, or -1 into the
+     * destination register based on the results of the comparison.
+     *
+     * Provide a "naninst" instruction that puts 1 or -1 into r1 depending
+     * on what value we'd like to return when one of the operands is NaN.
+     *
+     * The operation we're implementing is:
+     *   if (x == y)
+     *     return 0;
+     *   else if (x < y)
+     *     return -1;
+     *   else if (x > y)
+     *     return 1;
+     *   else
+     *     return {-1,1};  // one or both operands was NaN
+     *
+     * The straightforward implementation requires 3 calls to functions
+     * that return a result in r0.  We can do it with two calls if our
+     * EABI library supports __aeabi_cfcmple (only one if we want to check
+     * for NaN directly):
+     *   check x <= y
+     *     if <, return -1
+     *     if ==, return 0
+     *   check y <= x
+     *     if <, return 1
+     *   return {-1,1}
+     *
+     * for: cmpl-float, cmpg-float
+     */
+    /* op vAA, vBB, vCC */
+    mov     r9, r0                      @ Save copies - we may need to redo
+    mov     r10, r1
+    mov     r11, lr                     @ save return address
+    mov     lr, pc
+    ldr     pc, .L__aeabi_cfcmple       @ cmp <=: C clear if <, Z set if eq
+    bhi     .L${opcode}_gt_or_nan       @ C set and Z clear, disambiguate
+    mvncc   r0, #0                      @ (less than) r0<- -1
+    moveq   r0, #0                      @ (equal) r0<- 0, trumps less than
+    bx      r11
+    @ Test for NaN with a second comparison.  EABI forbids testing bit
+    @ patterns, and we can't represent 0x7fc00000 in immediate form, so
+    @ make the library call.
+.L${opcode}_gt_or_nan:
+    mov     r0, r10                     @ restore in reverse order
+    mov     r1, r9
+    mov     lr, pc
+    ldr     pc, .L__aeabi_cfcmple       @ r0<- Z set if eq, C clear if <
+    movcc   r0, #1                      @ (greater than) r1<- 1
+    bxcc    r11
+    $naninst                            @ r1<- 1 or -1 for NaN
+    bx      r11
diff --git a/vm/compiler/template_notaint/armv5te/TEMPLATE_CMP_LONG.S b/vm/compiler/template_notaint/armv5te/TEMPLATE_CMP_LONG.S
new file mode 100644
index 0000000..e5e8196
--- /dev/null
+++ b/vm/compiler/template_notaint/armv5te/TEMPLATE_CMP_LONG.S
@@ -0,0 +1,33 @@
+    /*
+     * Compare two 64-bit values.  Puts 0, 1, or -1 into the destination
+     * register based on the results of the comparison.
+     *
+     * We load the full values with LDM, but in practice many values could
+     * be resolved by only looking at the high word.  This could be made
+     * faster or slower by splitting the LDM into a pair of LDRs.
+     *
+     * If we just wanted to set condition flags, we could do this:
+     *  subs    ip, r0, r2
+     *  sbcs    ip, r1, r3
+     *  subeqs  ip, r0, r2
+     * Leaving { <0, 0, >0 } in ip.  However, we have to set it to a specific
+     * integer value, which we can do with 2 conditional mov/mvn instructions
+     * (set 1, set -1; if they're equal we already have 0 in ip), giving
+     * us a constant 5-cycle path plus a branch at the end to the
+     * instruction epilogue code.  The multi-compare approach below needs
+     * 2 or 3 cycles + branch if the high word doesn't match, 6 + branch
+     * in the worst case (the 64-bit values are equal).
+     */
+    /* cmp-long vAA, vBB, vCC */
+    cmp     r1, r3                      @ compare (vBB+1, vCC+1)
+    blt     .L${opcode}_less            @ signed compare on high part
+    bgt     .L${opcode}_greater
+    subs    r0, r0, r2                  @ r0<- r0 - r2
+    bxeq     lr
+    bhi     .L${opcode}_greater         @ unsigned compare on low part
+.L${opcode}_less:
+    mvn     r0, #0                      @ r0<- -1
+    bx      lr
+.L${opcode}_greater:
+    mov     r0, #1                      @ r0<- 1
+    bx      lr
diff --git a/vm/compiler/template_notaint/armv5te/TEMPLATE_INTERPRET.S b/vm/compiler/template_notaint/armv5te/TEMPLATE_INTERPRET.S
new file mode 100644
index 0000000..9f24887
--- /dev/null
+++ b/vm/compiler/template_notaint/armv5te/TEMPLATE_INTERPRET.S
@@ -0,0 +1,30 @@
+    /*
+     * This handler transfers control to the interpeter without performing
+     * any lookups.  It may be called either as part of a normal chaining
+     * operation, or from the transition code in header.S.  We distinquish
+     * the two cases by looking at the link register.  If called from a
+     * translation chain, it will point to the chaining Dalvik PC -3.
+     * On entry:
+     *    lr - if NULL:
+     *        r1 - the Dalvik PC to begin interpretation.
+     *    else
+     *        [lr, #3] contains Dalvik PC to begin interpretation
+     *    rSELF - pointer to thread
+     *    rFP - Dalvik frame pointer
+     */
+    cmp     lr, #0
+#if defined(WORKAROUND_CORTEX_A9_745320)
+    /* Don't use conditional loads if the HW defect exists */
+    beq     101f
+    ldr     r1,[lr, #3]
+101:
+#else
+    ldrne   r1,[lr, #3]
+#endif
+    ldr     r2, .LinterpPunt
+    mov     r0, r1                       @ set Dalvik PC
+    bx      r2
+    @ doesn't return
+
+.LinterpPunt:
+    .word   dvmJitToInterpPunt
diff --git a/vm/compiler/template_notaint/armv5te/TEMPLATE_INVOKE_METHOD_CHAIN.S b/vm/compiler/template_notaint/armv5te/TEMPLATE_INVOKE_METHOD_CHAIN.S
new file mode 100644
index 0000000..03b97a4
--- /dev/null
+++ b/vm/compiler/template_notaint/armv5te/TEMPLATE_INVOKE_METHOD_CHAIN.S
@@ -0,0 +1,49 @@
+%default { "chaintgt" : ".LinvokeChain" }
+    /*
+     * For monomorphic callsite, setup the Dalvik frame and return to the
+     * Thumb code through the link register to transfer control to the callee
+     * method through a dedicated chaining cell.
+     */
+    @ r0 = methodToCall, r1 = returnCell, r2 = methodToCall->outsSize
+    @ rPC = dalvikCallsite, r7 = methodToCall->registersSize
+    @ methodToCall is guaranteed to be non-native
+$chaintgt:
+    ldr     r9, [rSELF, #offThread_interpStackEnd]    @ r9<- interpStackEnd
+    ldrb    r8, [rSELF, #offThread_breakFlags]        @ r8<- breakFlags
+    add     r3, r1, #1  @ Thumb addr is odd
+    SAVEAREA_FROM_FP(r1, rFP)           @ r1<- stack save area
+    sub     r1, r1, r7, lsl #2          @ r1<- newFp (old savearea - regsSize)
+    SAVEAREA_FROM_FP(r10, r1)           @ r10<- stack save area
+    add     r12, lr, #2                 @ setup the punt-to-interp address
+    sub     r10, r10, r2, lsl #2        @ r10<- bottom (newsave - outsSize)
+    cmp     r10, r9                     @ bottom < interpStackEnd?
+    bxlo    r12                         @ return to raise stack overflow excep.
+    @ r1 = newFP, r0 = methodToCall, r3 = returnCell, rPC = dalvikCallsite
+    ldr     r9, [r0, #offMethod_clazz]      @ r9<- method->clazz
+    str     rPC, [rFP, #(offStackSaveArea_currentPc - sizeofStackSaveArea)]
+    str     rPC, [r1, #(offStackSaveArea_savedPc - sizeofStackSaveArea)]
+
+    @ set up newSaveArea
+    str     rFP, [r1, #(offStackSaveArea_prevFrame - sizeofStackSaveArea)]
+    str     r3, [r1, #(offStackSaveArea_returnAddr - sizeofStackSaveArea)]
+    str     r0, [r1, #(offStackSaveArea_method - sizeofStackSaveArea)]
+    cmp     r8, #0                      @ breakFlags != 0
+    bxne    r12                         @ bail to the interpreter
+
+    ldr     r3, [r9, #offClassObject_pDvmDex] @ r3<- method->clazz->pDvmDex
+
+    @ Update "thread" values for the new method
+    str     r0, [rSELF, #offThread_method]    @ self->method = methodToCall
+    str     r3, [rSELF, #offThread_methodClassDex] @ self->methodClassDex = ...
+    mov     rFP, r1                         @ fp = newFp
+    str     rFP, [rSELF, #offThread_curFrame]  @ curFrame = newFp
+#if defined(TEMPLATE_INLINE_PROFILING)
+    stmfd   sp!, {r0-r2,lr}             @ preserve clobbered live registers
+    mov     r1, r6
+    @ r0=methodToCall, r1=rSELF
+    mov     lr, pc
+    ldr     pc, .LdvmFastMethodTraceEnter
+    ldmfd   sp!, {r0-r2,lr}             @ restore registers
+#endif
+
+    bx      lr                              @ return to the callee-chaining cell
diff --git a/vm/compiler/template_notaint/armv5te/TEMPLATE_INVOKE_METHOD_CHAIN_PROF.S b/vm/compiler/template_notaint/armv5te/TEMPLATE_INVOKE_METHOD_CHAIN_PROF.S
new file mode 100644
index 0000000..d1be4fd
--- /dev/null
+++ b/vm/compiler/template_notaint/armv5te/TEMPLATE_INVOKE_METHOD_CHAIN_PROF.S
@@ -0,0 +1,3 @@
+#define TEMPLATE_INLINE_PROFILING
+%include "armv5te/TEMPLATE_INVOKE_METHOD_CHAIN.S" { "chaintgt" : ".LinvokeChainProf" }
+#undef TEMPLATE_INLINE_PROFILING
diff --git a/vm/compiler/template_notaint/armv5te/TEMPLATE_INVOKE_METHOD_NATIVE.S b/vm/compiler/template_notaint/armv5te/TEMPLATE_INVOKE_METHOD_NATIVE.S
new file mode 100644
index 0000000..2a73c22
--- /dev/null
+++ b/vm/compiler/template_notaint/armv5te/TEMPLATE_INVOKE_METHOD_NATIVE.S
@@ -0,0 +1,83 @@
+    @ r0 = methodToCall, r1 = returnCell, rPC = dalvikCallsite
+    @ r7 = methodToCall->registersSize
+    ldr     r9, [rSELF, #offThread_interpStackEnd]    @ r9<- interpStackEnd
+    ldrb    r8, [rSELF, #offThread_breakFlags]        @ r8<- breakFlags
+    add     r3, r1, #1  @ Thumb addr is odd
+    SAVEAREA_FROM_FP(r1, rFP)           @ r1<- stack save area
+    sub     r1, r1, r7, lsl #2          @ r1<- newFp (old savearea - regsSize)
+    SAVEAREA_FROM_FP(r10, r1)           @ r10<- stack save area
+    cmp     r10, r9                     @ bottom < interpStackEnd?
+    bxlo    lr                          @ return to raise stack overflow excep.
+    @ r1 = newFP, r0 = methodToCall, r3 = returnCell, rPC = dalvikCallsite
+    str     rPC, [rFP, #(offStackSaveArea_currentPc - sizeofStackSaveArea)]
+    str     rPC, [r1, #(offStackSaveArea_savedPc - sizeofStackSaveArea)]
+
+    @ set up newSaveArea
+    str     rFP, [r1, #(offStackSaveArea_prevFrame - sizeofStackSaveArea)]
+    str     r3, [r1, #(offStackSaveArea_returnAddr - sizeofStackSaveArea)]
+    str     r0, [r1, #(offStackSaveArea_method - sizeofStackSaveArea)]
+    cmp     r8, #0                      @ breakFlags != 0
+    ldr     r8, [r0, #offMethod_nativeFunc] @ r8<- method->nativeFunc
+#if !defined(WITH_SELF_VERIFICATION)
+    bxne    lr                          @ bail to the interpreter
+#else
+    bx      lr                          @ bail to interpreter unconditionally
+#endif
+
+    @ go ahead and transfer control to the native code
+    ldr     r9, [rSELF, #offThread_jniLocal_topCookie]@r9<-thread->localRef->...
+    mov     r2, #0
+    str     r1, [rSELF, #offThread_curFrame]   @ curFrame = newFp
+    str     r2, [rSELF, #offThread_inJitCodeCache] @ not in the jit code cache
+    str     r9, [r1, #(offStackSaveArea_localRefCookie - sizeofStackSaveArea)]
+                                        @ newFp->localRefCookie=top
+    SAVEAREA_FROM_FP(r10, r1)           @ r10<- new stack save area
+
+    mov     r2, r0                        @ arg2<- methodToCall
+    mov     r0, r1                        @ arg0<- newFP
+    add     r1, rSELF, #offThread_retval  @ arg1<- &retval
+    mov     r3, rSELF                     @ arg3<- self
+#if defined(TEMPLATE_INLINE_PROFILING)
+    @ r2=methodToCall, r6=rSELF
+    stmfd   sp!, {r2,r6}                @ to be consumed after JNI return
+    stmfd   sp!, {r0-r3}                @ preserve r0-r3
+    mov     r0, r2
+    mov     r1, r6
+    @ r0=JNIMethod, r1=rSELF
+    mov     lr, pc
+    ldr     pc, .LdvmFastMethodTraceEnter
+    ldmfd   sp!, {r0-r3}                @ restore r0-r3
+#endif
+
+    blx     r8                          @ off to the native code
+
+#if defined(TEMPLATE_INLINE_PROFILING)
+    ldmfd   sp!, {r0-r1}                @ restore r2 and r6
+    @ r0=JNIMethod, r1=rSELF
+    mov     lr, pc
+    ldr     pc, .LdvmFastNativeMethodTraceExit
+#endif
+    @ native return; r10=newSaveArea
+    @ equivalent to dvmPopJniLocals
+    ldr     r2, [r10, #offStackSaveArea_returnAddr] @ r2 = chaining cell ret
+    ldr     r0, [r10, #offStackSaveArea_localRefCookie] @ r0<- saved->top
+    ldr     r1, [rSELF, #offThread_exception] @ check for exception
+    str     rFP, [rSELF, #offThread_curFrame]  @ curFrame = fp
+    cmp     r1, #0                      @ null?
+    str     r0, [rSELF, #offThread_jniLocal_topCookie] @ new top <- old top
+    ldr     r0, [rFP, #(offStackSaveArea_currentPc - sizeofStackSaveArea)]
+
+    @ r0 = dalvikCallsitePC
+    bne     .LhandleException           @ no, handle exception
+
+    str     r2, [rSELF, #offThread_inJitCodeCache] @ set the mode properly
+    cmp     r2, #0                      @ return chaining cell still exists?
+    bxne    r2                          @ yes - go ahead
+
+    @ continue executing the next instruction through the interpreter
+    ldr     r1, .LdvmJitToInterpTraceSelectNoChain @ defined in footer.S
+    add     rPC, r0, #6                 @ reconstruct new rPC (advance 6 bytes)
+#if defined(WITH_JIT_TUNING)
+    mov     r0, #kCallsiteInterpreted
+#endif
+    mov     pc, r1
diff --git a/vm/compiler/template_notaint/armv5te/TEMPLATE_INVOKE_METHOD_NATIVE_PROF.S b/vm/compiler/template_notaint/armv5te/TEMPLATE_INVOKE_METHOD_NATIVE_PROF.S
new file mode 100644
index 0000000..816277a
--- /dev/null
+++ b/vm/compiler/template_notaint/armv5te/TEMPLATE_INVOKE_METHOD_NATIVE_PROF.S
@@ -0,0 +1,3 @@
+#define TEMPLATE_INLINE_PROFILING
+%include "armv5te/TEMPLATE_INVOKE_METHOD_NATIVE.S"
+#undef TEMPLATE_INLINE_PROFILING
diff --git a/vm/compiler/template_notaint/armv5te/TEMPLATE_INVOKE_METHOD_NO_OPT.S b/vm/compiler/template_notaint/armv5te/TEMPLATE_INVOKE_METHOD_NO_OPT.S
new file mode 100644
index 0000000..a7a0961
--- /dev/null
+++ b/vm/compiler/template_notaint/armv5te/TEMPLATE_INVOKE_METHOD_NO_OPT.S
@@ -0,0 +1,60 @@
+    /*
+     * For polymorphic callsites - setup the Dalvik frame and load Dalvik PC
+     * into rPC then jump to dvmJitToInterpNoChain to dispatch the
+     * runtime-resolved callee.
+     */
+    @ r0 = methodToCall, r1 = returnCell, rPC = dalvikCallsite
+    ldrh    r7, [r0, #offMethod_registersSize]  @ r7<- methodToCall->regsSize
+    ldrh    r2, [r0, #offMethod_outsSize]  @ r2<- methodToCall->outsSize
+    ldr     r9, [rSELF, #offThread_interpStackEnd]    @ r9<- interpStackEnd
+    ldrb    r8, [rSELF, #offThread_breakFlags] @ r8<- breakFlags
+    add     r3, r1, #1  @ Thumb addr is odd
+    SAVEAREA_FROM_FP(r1, rFP)           @ r1<- stack save area
+    sub     r1, r1, r7, lsl #2          @ r1<- newFp (old savearea - regsSize)
+    SAVEAREA_FROM_FP(r10, r1)           @ r10<- stack save area
+    sub     r10, r10, r2, lsl #2        @ r10<- bottom (newsave - outsSize)
+    cmp     r10, r9                     @ bottom < interpStackEnd?
+    bxlo    lr                          @ return to raise stack overflow excep.
+    @ r1 = newFP, r0 = methodToCall, r3 = returnCell, rPC = dalvikCallsite
+    ldr     r9, [r0, #offMethod_clazz]      @ r9<- method->clazz
+    ldr     r10, [r0, #offMethod_accessFlags] @ r10<- methodToCall->accessFlags
+    str     rPC, [rFP, #(offStackSaveArea_currentPc - sizeofStackSaveArea)]
+    str     rPC, [r1, #(offStackSaveArea_savedPc - sizeofStackSaveArea)]
+    ldr     rPC, [r0, #offMethod_insns]     @ rPC<- methodToCall->insns
+
+
+    @ set up newSaveArea
+    str     rFP, [r1, #(offStackSaveArea_prevFrame - sizeofStackSaveArea)]
+    str     r3, [r1, #(offStackSaveArea_returnAddr - sizeofStackSaveArea)]
+    str     r0, [r1, #(offStackSaveArea_method - sizeofStackSaveArea)]
+    cmp     r8, #0                      @ breakFlags != 0
+    bxne    lr                          @ bail to the interpreter
+    tst     r10, #ACC_NATIVE
+#if !defined(WITH_SELF_VERIFICATION)
+    bne     .LinvokeNative
+#else
+    bxne    lr                          @ bail to the interpreter
+#endif
+
+    ldr     r10, .LdvmJitToInterpTraceSelectNoChain
+    ldr     r3, [r9, #offClassObject_pDvmDex] @ r3<- method->clazz->pDvmDex
+
+    @ Update "thread" values for the new method
+    str     r0, [rSELF, #offThread_method]    @ self->method = methodToCall
+    str     r3, [rSELF, #offThread_methodClassDex] @ self->methodClassDex = ...
+    mov     rFP, r1                         @ fp = newFp
+    str     rFP, [rSELF, #offThread_curFrame]  @ curFrame = newFp
+#if defined(TEMPLATE_INLINE_PROFILING)
+    stmfd   sp!, {r0-r3}                    @ preserve r0-r3
+    mov     r1, r6
+    @ r0=methodToCall, r1=rSELF
+    mov     lr, pc
+    ldr     pc, .LdvmFastMethodTraceEnter
+    ldmfd   sp!, {r0-r3}                    @ restore r0-r3
+#endif
+
+    @ Start executing the callee
+#if defined(WITH_JIT_TUNING)
+    mov     r0, #kInlineCacheMiss
+#endif
+    mov     pc, r10                         @ dvmJitToInterpTraceSelectNoChain
diff --git a/vm/compiler/template_notaint/armv5te/TEMPLATE_INVOKE_METHOD_NO_OPT_PROF.S b/vm/compiler/template_notaint/armv5te/TEMPLATE_INVOKE_METHOD_NO_OPT_PROF.S
new file mode 100644
index 0000000..bfea7d9
--- /dev/null
+++ b/vm/compiler/template_notaint/armv5te/TEMPLATE_INVOKE_METHOD_NO_OPT_PROF.S
@@ -0,0 +1,3 @@
+#define TEMPLATE_INLINE_PROFILING
+%include "armv5te/TEMPLATE_INVOKE_METHOD_NO_OPT.S"
+#undef TEMPLATE_INLINE_PROFILING
diff --git a/vm/compiler/template_notaint/armv5te/TEMPLATE_INVOKE_METHOD_PREDICTED_CHAIN.S b/vm/compiler/template_notaint/armv5te/TEMPLATE_INVOKE_METHOD_PREDICTED_CHAIN.S
new file mode 100644
index 0000000..9dd4ff8
--- /dev/null
+++ b/vm/compiler/template_notaint/armv5te/TEMPLATE_INVOKE_METHOD_PREDICTED_CHAIN.S
@@ -0,0 +1,60 @@
+%default { "chaintgt" : ".LinvokeChain" }
+    /*
+     * For polymorphic callsite, check whether the cached class pointer matches
+     * the current one. If so setup the Dalvik frame and return to the
+     * Thumb code through the link register to transfer control to the callee
+     * method through a dedicated chaining cell.
+     *
+     * The predicted chaining cell is declared in ArmLIR.h with the
+     * following layout:
+     *
+     *  typedef struct PredictedChainingCell {
+     *      u4 branch;
+     *      const ClassObject *clazz;
+     *      const Method *method;
+     *      u4 counter;
+     *  } PredictedChainingCell;
+     *
+     * Upon returning to the callsite:
+     *    - lr  : to branch to the chaining cell
+     *    - lr+2: to punt to the interpreter
+     *    - lr+4: to fully resolve the callee and may rechain.
+     *            r3 <- class
+     *            r9 <- counter
+     */
+    @ r0 = this, r1 = returnCell, r2 = predictedChainCell, rPC = dalvikCallsite
+    ldr     r3, [r0, #offObject_clazz]  @ r3 <- this->class
+    ldr     r8, [r2, #4]    @ r8 <- predictedChainCell->clazz
+    ldr     r0, [r2, #8]    @ r0 <- predictedChainCell->method
+    ldr     r9, [rSELF, #offThread_icRechainCount] @ r1 <- shared rechainCount
+    cmp     r3, r8          @ predicted class == actual class?
+#if defined(WITH_JIT_TUNING)
+    ldr     r7, .LdvmICHitCount
+#if defined(WORKAROUND_CORTEX_A9_745320)
+    /* Don't use conditional loads if the HW defect exists */
+    bne     101f
+    ldr     r10, [r7, #0]
+101:
+#else
+    ldreq   r10, [r7, #0]
+#endif
+    add     r10, r10, #1
+    streq   r10, [r7, #0]
+#endif
+    ldreqh  r7, [r0, #offMethod_registersSize]  @ r7<- methodToCall->regsSize
+    ldreqh  r2, [r0, #offMethod_outsSize]  @ r2<- methodToCall->outsSize
+    beq     $chaintgt   @ predicted chain is valid
+    ldr     r7, [r3, #offClassObject_vtable] @ r7 <- this->class->vtable
+    cmp     r8, #0          @ initialized class or not
+    moveq   r1, #0
+    subne   r1, r9, #1      @ count--
+    strne   r1, [rSELF, #offThread_icRechainCount]  @ write back to thread
+    add     lr, lr, #4      @ return to fully-resolve landing pad
+    /*
+     * r1 <- count
+     * r2 <- &predictedChainCell
+     * r3 <- this->class
+     * r4 <- dPC
+     * r7 <- this->class->vtable
+     */
+    bx      lr
diff --git a/vm/compiler/template_notaint/armv5te/TEMPLATE_INVOKE_METHOD_PREDICTED_CHAIN_PROF.S b/vm/compiler/template_notaint/armv5te/TEMPLATE_INVOKE_METHOD_PREDICTED_CHAIN_PROF.S
new file mode 100644
index 0000000..6ca5bdd
--- /dev/null
+++ b/vm/compiler/template_notaint/armv5te/TEMPLATE_INVOKE_METHOD_PREDICTED_CHAIN_PROF.S
@@ -0,0 +1,3 @@
+#define TEMPLATE_INLINE_PROFILING
+%include "armv5te/TEMPLATE_INVOKE_METHOD_PREDICTED_CHAIN.S" { "chaintgt" : ".LinvokeChainProf" }
+#undef TEMPLATE_INLINE_PROFILING
diff --git a/vm/compiler/template_notaint/armv5te/TEMPLATE_MEM_OP_DECODE.S b/vm/compiler/template_notaint/armv5te/TEMPLATE_MEM_OP_DECODE.S
new file mode 100644
index 0000000..03926b6
--- /dev/null
+++ b/vm/compiler/template_notaint/armv5te/TEMPLATE_MEM_OP_DECODE.S
@@ -0,0 +1,17 @@
+#if defined(WITH_SELF_VERIFICATION)
+    /*
+     * This handler encapsulates heap memory ops for selfVerification mode.
+     *
+     * The call to the handler is inserted prior to a heap memory operation.
+     * This handler then calls a function to decode the memory op, and process
+     * it accordingly. Afterwards, the handler changes the return address to
+     * skip the memory op so it never gets executed.
+     */
+    push    {r0-r12,lr}                 @ save out all registers
+    ldr     r2, .LdvmSelfVerificationMemOpDecode @ defined in footer.S
+    mov     r0, lr                      @ arg0 <- link register
+    mov     r1, sp                      @ arg1 <- stack pointer
+    blx     r2                          @ decode and handle the mem op
+    pop     {r0-r12,lr}                 @ restore all registers
+    bx      lr                          @ return to compiled code
+#endif
diff --git a/vm/compiler/template_notaint/armv5te/TEMPLATE_MONITOR_ENTER.S b/vm/compiler/template_notaint/armv5te/TEMPLATE_MONITOR_ENTER.S
new file mode 100644
index 0000000..1ed3fb1
--- /dev/null
+++ b/vm/compiler/template_notaint/armv5te/TEMPLATE_MONITOR_ENTER.S
@@ -0,0 +1,21 @@
+    /*
+     * Call out to the runtime to lock an object.  Because this thread
+     * may have been suspended in THREAD_MONITOR state and the Jit's
+     * translation cache subsequently cleared, we cannot return directly.
+     * Instead, unconditionally transition to the interpreter to resume.
+     *
+     * On entry:
+     *    r0 - self pointer
+     *    r1 - the object (which has already been null-checked by the caller
+     *    r4 - the Dalvik PC of the following instruction.
+     */
+    ldr     r2, .LdvmLockObject
+    mov     r3, #0                       @ Record that we're not returning
+    str     r3, [r0, #offThread_inJitCodeCache]
+    blx     r2                           @ dvmLockObject(self, obj)
+    ldr     r2, .LdvmJitToInterpNoChain
+    @ Bail to interpreter - no chain [note - r4 still contains rPC]
+#if defined(WITH_JIT_TUNING)
+    mov     r0, #kHeavyweightMonitor
+#endif
+    bx      r2
diff --git a/vm/compiler/template_notaint/armv5te/TEMPLATE_MONITOR_ENTER_DEBUG.S b/vm/compiler/template_notaint/armv5te/TEMPLATE_MONITOR_ENTER_DEBUG.S
new file mode 100644
index 0000000..2695483
--- /dev/null
+++ b/vm/compiler/template_notaint/armv5te/TEMPLATE_MONITOR_ENTER_DEBUG.S
@@ -0,0 +1,28 @@
+    /*
+     * To support deadlock prediction, this version of MONITOR_ENTER
+     * will always call the heavyweight dvmLockObject, check for an
+     * exception and then bail out to the interpreter.
+     *
+     * On entry:
+     *    r0 - self pointer
+     *    r1 - the object (which has already been null-checked by the caller
+     *    r4 - the Dalvik PC of the following instruction.
+     *
+     */
+    ldr     r2, .LdvmLockObject
+    mov     r3, #0                       @ Record that we're not returning
+    str     r3, [r0, #offThread_inJitCodeCache]
+    blx     r2             @ dvmLockObject(self, obj)
+    @ test for exception
+    ldr     r1, [rSELF, #offThread_exception]
+    cmp     r1, #0
+    beq     1f
+    ldr     r2, .LhandleException
+    sub     r0, r4, #2     @ roll dPC back to this monitor instruction
+    bx      r2
+1:
+    @ Bail to interpreter - no chain [note - r4 still contains rPC]
+#if defined(WITH_JIT_TUNING)
+    mov     r0, #kHeavyweightMonitor
+#endif
+    ldr     pc, .LdvmJitToInterpNoChain
diff --git a/vm/compiler/template_notaint/armv5te/TEMPLATE_MUL_LONG.S b/vm/compiler/template_notaint/armv5te/TEMPLATE_MUL_LONG.S
new file mode 100644
index 0000000..8a9b115
--- /dev/null
+++ b/vm/compiler/template_notaint/armv5te/TEMPLATE_MUL_LONG.S
@@ -0,0 +1,28 @@
+    /*
+     * Signed 64-bit integer multiply.
+     *
+     * For JIT: op1 in r0/r1, op2 in r2/r3, return in r0/r1
+     *
+     * Consider WXxYZ (r1r0 x r3r2) with a long multiply:
+     *        WX
+     *      x YZ
+     *  --------
+     *     ZW ZX
+     *  YW YX
+     *
+     * The low word of the result holds ZX, the high word holds
+     * (ZW+YX) + (the high overflow from ZX).  YW doesn't matter because
+     * it doesn't fit in the low 64 bits.
+     *
+     * Unlike most ARM math operations, multiply instructions have
+     * restrictions on using the same register more than once (Rd and Rm
+     * cannot be the same).
+     */
+    /* mul-long vAA, vBB, vCC */
+    mul     ip, r2, r1                  @  ip<- ZxW
+    umull   r9, r10, r2, r0             @  r9/r10 <- ZxX
+    mla     r2, r0, r3, ip              @  r2<- YxX + (ZxW)
+    add     r10, r2, r10                @  r10<- r10 + low(ZxW + (YxX))
+    mov     r0,r9
+    mov     r1,r10
+    bx      lr
diff --git a/vm/compiler/template_notaint/armv5te/TEMPLATE_PERIODIC_PROFILING.S b/vm/compiler/template_notaint/armv5te/TEMPLATE_PERIODIC_PROFILING.S
new file mode 100644
index 0000000..c0f7d6e
--- /dev/null
+++ b/vm/compiler/template_notaint/armv5te/TEMPLATE_PERIODIC_PROFILING.S
@@ -0,0 +1,26 @@
+    /*
+     * Increment profile counter for this trace, and decrement
+     * sample counter.  If sample counter goes below zero, turn
+     * off profiling.
+     *
+     * On entry
+     * (lr-11) is address of pointer to counter.  Note: the counter
+     *    actually exists 10 bytes before the return target, but because
+     *    we are arriving from thumb mode, lr will have its low bit set.
+     */
+     ldr    r0, [lr,#-11]
+     ldr    r1, [rSELF, #offThread_pProfileCountdown]
+     ldr    r2, [r0]                    @ get counter
+     ldr    r3, [r1]                    @ get countdown timer
+     add    r2, #1
+     subs   r2, #1
+     blt    .L${opcode}_disable_profiling
+     str    r2, [r0]
+     str    r3, [r1]
+     bx     lr
+
+.L${opcode}_disable_profiling:
+     mov    r4, lr                     @ preserve lr
+     ldr    r0, .LdvmJitTraceProfilingOff
+     blx    r0
+     bx     r4
diff --git a/vm/compiler/template_notaint/armv5te/TEMPLATE_RESTORE_STATE.S b/vm/compiler/template_notaint/armv5te/TEMPLATE_RESTORE_STATE.S
new file mode 100644
index 0000000..25b4ffa
--- /dev/null
+++ b/vm/compiler/template_notaint/armv5te/TEMPLATE_RESTORE_STATE.S
@@ -0,0 +1,8 @@
+    /*
+     * This handler restores state following a selfVerification memory access.
+     * On entry:
+     *    r0 - offset from rSELF to the 1st element of the coreRegs save array.
+     */
+    add     r0, r0, rSELF               @ pointer to heapArgSpace.coreRegs[0]
+    ldmia   r0, {r0-r12}
+    bx      lr
diff --git a/vm/compiler/template_notaint/armv5te/TEMPLATE_RETURN.S b/vm/compiler/template_notaint/armv5te/TEMPLATE_RETURN.S
new file mode 100644
index 0000000..d074c9e
--- /dev/null
+++ b/vm/compiler/template_notaint/armv5te/TEMPLATE_RETURN.S
@@ -0,0 +1,57 @@
+    /*
+     * Unwind a frame from the Dalvik stack for compiled OP_RETURN_XXX.
+     * If the stored value in returnAddr
+     * is non-zero, the caller is compiled by the JIT thus return to the
+     * address in the code cache following the invoke instruction. Otherwise
+     * return to the special dvmJitToInterpNoChain entry point.
+     */
+#if defined(TEMPLATE_INLINE_PROFILING)
+    stmfd   sp!, {r0-r2,lr}             @ preserve live registers
+    mov     r0, r6
+    @ r0=rSELF
+    mov     lr, pc
+    ldr     pc, .LdvmFastMethodTraceExit
+    ldmfd   sp!, {r0-r2,lr}             @ restore live registers
+#endif
+    SAVEAREA_FROM_FP(r0, rFP)           @ r0<- saveArea (old)
+    ldr     r10, [r0, #offStackSaveArea_prevFrame] @ r10<- saveArea->prevFrame
+    ldrb    r8, [rSELF, #offThread_breakFlags] @ r8<- breakFlags
+    ldr     rPC, [r0, #offStackSaveArea_savedPc] @ rPC<- saveArea->savedPc
+#if !defined(WITH_SELF_VERIFICATION)
+    ldr     r9,  [r0, #offStackSaveArea_returnAddr] @ r9<- chaining cell ret
+#else
+    mov     r9, #0                      @ disable chaining
+#endif
+    ldr     r2, [r10, #(offStackSaveArea_method - sizeofStackSaveArea)]
+                                        @ r2<- method we're returning to
+    cmp     r2, #0                      @ break frame?
+#if !defined(WITH_SELF_VERIFICATION)
+    beq     1f                          @ bail to interpreter
+#else
+    blxeq   lr                          @ punt to interpreter and compare state
+#endif
+    ldr     r1, .LdvmJitToInterpNoChainNoProfile @ defined in footer.S
+    mov     rFP, r10                    @ publish new FP
+    ldr     r10, [r2, #offMethod_clazz] @ r10<- method->clazz
+
+    str     r2, [rSELF, #offThread_method]@ self->method = newSave->method
+    ldr     r0, [r10, #offClassObject_pDvmDex] @ r0<- method->clazz->pDvmDex
+    str     rFP, [rSELF, #offThread_curFrame] @ curFrame = fp
+    add     rPC, rPC, #6                @ publish new rPC (advance 6 bytes)
+    str     r0, [rSELF, #offThread_methodClassDex]
+    cmp     r8, #0                      @ check the break flags
+    movne   r9, #0                      @ clear the chaining cell address
+    str     r9, [rSELF, #offThread_inJitCodeCache] @ in code cache or not
+    cmp     r9, #0                      @ chaining cell exists?
+    blxne   r9                          @ jump to the chaining cell
+#if defined(WITH_JIT_TUNING)
+    mov     r0, #kCallsiteInterpreted
+#endif
+    mov     pc, r1                      @ callsite is interpreted
+1:
+    mov     r0, #0
+    str     r0, [rSELF, #offThread_inJitCodeCache] @ reset inJitCodeCache
+    stmia   rSELF, {rPC, rFP}           @ SAVE_PC_FP_TO_SELF()
+    ldr     r2, .LdvmMterpStdBail       @ defined in footer.S
+    mov     r0, rSELF                   @ Expecting rSELF in r0
+    blx     r2                          @ exit the interpreter
diff --git a/vm/compiler/template_notaint/armv5te/TEMPLATE_RETURN_PROF.S b/vm/compiler/template_notaint/armv5te/TEMPLATE_RETURN_PROF.S
new file mode 100644
index 0000000..d7af0bd
--- /dev/null
+++ b/vm/compiler/template_notaint/armv5te/TEMPLATE_RETURN_PROF.S
@@ -0,0 +1,3 @@
+#define TEMPLATE_INLINE_PROFILING
+%include "armv5te/TEMPLATE_RETURN.S"
+#undef TEMPLATE_INLINE_PROFILING
diff --git a/vm/compiler/template_notaint/armv5te/TEMPLATE_SAVE_STATE.S b/vm/compiler/template_notaint/armv5te/TEMPLATE_SAVE_STATE.S
new file mode 100644
index 0000000..1c3aa4d
--- /dev/null
+++ b/vm/compiler/template_notaint/armv5te/TEMPLATE_SAVE_STATE.S
@@ -0,0 +1,21 @@
+    /*
+     * This handler performs a register save for selfVerification mode.
+     * On entry:
+     *    Top of stack + 4: r7 value to save
+     *    Top of stack + 0: r0 value to save
+     *    r0 - offset from rSELF to the beginning of the heapArgSpace record
+     *    r7 - the value of regMap
+     *
+     * The handler must save regMap, r0-r12 and then return with r0-r12
+     * with their original values (note that this means r0 and r7 must take
+     * the values on the stack - not the ones in those registers on entry.
+     * Finally, the two registers previously pushed must be popped.
+     */
+    add     r0, r0, rSELF               @ pointer to heapArgSpace
+    stmia   r0!, {r7}                   @ save regMap
+    ldr     r7, [r13, #0]               @ recover r0 value
+    stmia   r0!, {r7}                   @ save r0
+    ldr     r7, [r13, #4]               @ recover r7 value
+    stmia   r0!, {r1-r12}
+    pop     {r0, r7}                    @ recover r0, r7
+    bx      lr
diff --git a/vm/compiler/template_notaint/armv5te/TEMPLATE_SHL_LONG.S b/vm/compiler/template_notaint/armv5te/TEMPLATE_SHL_LONG.S
new file mode 100644
index 0000000..532f8a4
--- /dev/null
+++ b/vm/compiler/template_notaint/armv5te/TEMPLATE_SHL_LONG.S
@@ -0,0 +1,15 @@
+    /*
+     * Long integer shift.  This is different from the generic 32/64-bit
+     * binary operations because vAA/vBB are 64-bit but vCC (the shift
+     * distance) is 32-bit.  Also, Dalvik requires us to ignore all but the low
+     * 6 bits.
+     */
+    /* shl-long vAA, vBB, vCC */
+    and     r2, r2, #63                 @ r2<- r2 & 0x3f
+    mov     r1, r1, asl r2              @  r1<- r1 << r2
+    rsb     r3, r2, #32                 @  r3<- 32 - r2
+    orr     r1, r1, r0, lsr r3          @  r1<- r1 | (r0 << (32-r2))
+    subs    ip, r2, #32                 @  ip<- r2 - 32
+    movpl   r1, r0, asl ip              @  if r2 >= 32, r1<- r0 << (r2-32)
+    mov     r0, r0, asl r2              @  r0<- r0 << r2
+    bx      lr
diff --git a/vm/compiler/template_notaint/armv5te/TEMPLATE_SHR_LONG.S b/vm/compiler/template_notaint/armv5te/TEMPLATE_SHR_LONG.S
new file mode 100644
index 0000000..c737840
--- /dev/null
+++ b/vm/compiler/template_notaint/armv5te/TEMPLATE_SHR_LONG.S
@@ -0,0 +1,15 @@
+    /*
+     * Long integer shift.  This is different from the generic 32/64-bit
+     * binary operations because vAA/vBB are 64-bit but vCC (the shift
+     * distance) is 32-bit.  Also, Dalvik requires us to ignore all but the low
+     * 6 bits.
+     */
+    /* shr-long vAA, vBB, vCC */
+    and     r2, r2, #63                 @ r0<- r0 & 0x3f
+    mov     r0, r0, lsr r2              @  r0<- r2 >> r2
+    rsb     r3, r2, #32                 @  r3<- 32 - r2
+    orr     r0, r0, r1, asl r3          @  r0<- r0 | (r1 << (32-r2))
+    subs    ip, r2, #32                 @  ip<- r2 - 32
+    movpl   r0, r1, asr ip              @  if r2 >= 32, r0<-r1 >> (r2-32)
+    mov     r1, r1, asr r2              @  r1<- r1 >> r2
+    bx      lr
diff --git a/vm/compiler/template_notaint/armv5te/TEMPLATE_STRING_COMPARETO.S b/vm/compiler/template_notaint/armv5te/TEMPLATE_STRING_COMPARETO.S
new file mode 100644
index 0000000..54bde47
--- /dev/null
+++ b/vm/compiler/template_notaint/armv5te/TEMPLATE_STRING_COMPARETO.S
@@ -0,0 +1,133 @@
+    /*
+     * String's compareTo.
+     *
+     * Requires r0/r1 to have been previously checked for null.  Will
+     * return negative if this's string is < comp, 0 if they are the
+     * same and positive if >.
+     *
+     * IMPORTANT NOTE:
+     *
+     * This code relies on hard-coded offsets for string objects, and must be
+     * kept in sync with definitions in UtfString.h.  See asm-constants.h
+     *
+     * On entry:
+     *    r0:   this object pointer
+     *    r1:   comp object pointer
+     *
+     */
+
+    mov    r2, r0         @ this to r2, opening up r0 for return value
+    subs   r0, r2, r1     @ Same?
+    bxeq   lr
+
+    ldr    r4, [r2, #STRING_FIELDOFF_OFFSET]
+    ldr    r9, [r1, #STRING_FIELDOFF_OFFSET]
+    ldr    r7, [r2, #STRING_FIELDOFF_COUNT]
+    ldr    r10, [r1, #STRING_FIELDOFF_COUNT]
+    ldr    r2, [r2, #STRING_FIELDOFF_VALUE]
+    ldr    r1, [r1, #STRING_FIELDOFF_VALUE]
+
+    /*
+     * At this point, we have:
+     *    value:  r2/r1
+     *    offset: r4/r9
+     *    count:  r7/r10
+     * We're going to compute
+     *    r11 <- countDiff
+     *    r10 <- minCount
+     */
+     subs  r11, r7, r10
+     movls r10, r7
+
+     /* Now, build pointers to the string data */
+     add   r2, r2, r4, lsl #1
+     add   r1, r1, r9, lsl #1
+     /*
+      * Note: data pointers point to previous element so we can use pre-index
+      * mode with base writeback.
+      */
+     add   r2, #16-2   @ offset to contents[-1]
+     add   r1, #16-2   @ offset to contents[-1]
+
+     /*
+      * At this point we have:
+      *   r2: *this string data
+      *   r1: *comp string data
+      *   r10: iteration count for comparison
+      *   r11: value to return if the first part of the string is equal
+      *   r0: reserved for result
+      *   r3, r4, r7, r8, r9, r12 available for loading string data
+      */
+
+    subs  r10, #2
+    blt   do_remainder2
+
+      /*
+       * Unroll the first two checks so we can quickly catch early mismatch
+       * on long strings (but preserve incoming alignment)
+       */
+
+    ldrh  r3, [r2, #2]!
+    ldrh  r4, [r1, #2]!
+    ldrh  r7, [r2, #2]!
+    ldrh  r8, [r1, #2]!
+    subs  r0, r3, r4
+    subeqs  r0, r7, r8
+    bxne  lr
+    cmp   r10, #28
+    bgt   do_memcmp16
+    subs  r10, #3
+    blt   do_remainder
+
+loopback_triple:
+    ldrh  r3, [r2, #2]!
+    ldrh  r4, [r1, #2]!
+    ldrh  r7, [r2, #2]!
+    ldrh  r8, [r1, #2]!
+    ldrh  r9, [r2, #2]!
+    ldrh  r12,[r1, #2]!
+    subs  r0, r3, r4
+    subeqs  r0, r7, r8
+    subeqs  r0, r9, r12
+    bxne  lr
+    subs  r10, #3
+    bge   loopback_triple
+
+do_remainder:
+    adds  r10, #3
+    beq   returnDiff
+
+loopback_single:
+    ldrh  r3, [r2, #2]!
+    ldrh  r4, [r1, #2]!
+    subs  r0, r3, r4
+    bxne  lr
+    subs  r10, #1
+    bne     loopback_single
+
+returnDiff:
+    mov   r0, r11
+    bx    lr
+
+do_remainder2:
+    adds  r10, #2
+    bne   loopback_single
+    mov   r0, r11
+    bx    lr
+
+    /* Long string case */
+do_memcmp16:
+    mov   r4, lr
+    ldr   lr, .Lmemcmp16
+    mov   r7, r11
+    add   r0, r2, #2
+    add   r1, r1, #2
+    mov   r2, r10
+    blx   lr
+    cmp   r0, #0
+    bxne  r4
+    mov   r0, r7
+    bx    r4
+
+.Lmemcmp16:
+    .word __memcmp16
diff --git a/vm/compiler/template_notaint/armv5te/TEMPLATE_STRING_INDEXOF.S b/vm/compiler/template_notaint/armv5te/TEMPLATE_STRING_INDEXOF.S
new file mode 100644
index 0000000..bdfdf28
--- /dev/null
+++ b/vm/compiler/template_notaint/armv5te/TEMPLATE_STRING_INDEXOF.S
@@ -0,0 +1,112 @@
+    /*
+     * String's indexOf.
+     *
+     * Requires r0 to have been previously checked for null.  Will
+     * return index of match of r1 in r0.
+     *
+     * IMPORTANT NOTE:
+     *
+     * This code relies on hard-coded offsets for string objects, and must be
+     * kept in sync wth definitions in UtfString.h  See asm-constants.h
+     *
+     * On entry:
+     *    r0:   string object pointer
+     *    r1:   char to match
+     *    r2:   Starting offset in string data
+     */
+
+    ldr    r7, [r0, #STRING_FIELDOFF_OFFSET]
+    ldr    r8, [r0, #STRING_FIELDOFF_COUNT]
+    ldr    r0, [r0, #STRING_FIELDOFF_VALUE]
+
+    /*
+     * At this point, we have:
+     *    r0: object pointer
+     *    r1: char to match
+     *    r2: starting offset
+     *    r7: offset
+     *    r8: string length
+     */
+
+     /* Build pointer to start of string data */
+     add   r0, #16
+     add   r0, r0, r7, lsl #1
+
+     /* Save a copy of starting data in r7 */
+     mov   r7, r0
+
+     /* Clamp start to [0..count] */
+     cmp   r2, #0
+     movlt r2, #0
+     cmp   r2, r8
+     movgt r2, r8
+
+     /* Build pointer to start of data to compare and pre-bias */
+     add   r0, r0, r2, lsl #1
+     sub   r0, #2
+
+     /* Compute iteration count */
+     sub   r8, r2
+
+     /*
+      * At this point we have:
+      *   r0: start of data to test
+      *   r1: chat to compare
+      *   r8: iteration count
+      *   r7: original start of string
+      *   r3, r4, r9, r10, r11, r12 available for loading string data
+      */
+
+    subs  r8, #4
+    blt   indexof_remainder
+
+indexof_loop4:
+    ldrh  r3, [r0, #2]!
+    ldrh  r4, [r0, #2]!
+    ldrh  r10, [r0, #2]!
+    ldrh  r11, [r0, #2]!
+    cmp   r3, r1
+    beq   match_0
+    cmp   r4, r1
+    beq   match_1
+    cmp   r10, r1
+    beq   match_2
+    cmp   r11, r1
+    beq   match_3
+    subs  r8, #4
+    bge   indexof_loop4
+
+indexof_remainder:
+    adds    r8, #4
+    beq     indexof_nomatch
+
+indexof_loop1:
+    ldrh  r3, [r0, #2]!
+    cmp   r3, r1
+    beq   match_3
+    subs  r8, #1
+    bne   indexof_loop1
+
+indexof_nomatch:
+    mov   r0, #-1
+    bx    lr
+
+match_0:
+    sub   r0, #6
+    sub   r0, r7
+    asr   r0, r0, #1
+    bx    lr
+match_1:
+    sub   r0, #4
+    sub   r0, r7
+    asr   r0, r0, #1
+    bx    lr
+match_2:
+    sub   r0, #2
+    sub   r0, r7
+    asr   r0, r0, #1
+    bx    lr
+match_3:
+    sub   r0, r7
+    asr   r0, r0, #1
+    bx    lr
diff --git a/vm/compiler/template_notaint/armv5te/TEMPLATE_THROW_EXCEPTION_COMMON.S b/vm/compiler/template_notaint/armv5te/TEMPLATE_THROW_EXCEPTION_COMMON.S
new file mode 100644
index 0000000..b737798
--- /dev/null
+++ b/vm/compiler/template_notaint/armv5te/TEMPLATE_THROW_EXCEPTION_COMMON.S
@@ -0,0 +1,6 @@
+    /*
+     * Throw an exception from JIT'ed code.
+     * On entry:
+     *    r0    Dalvik PC that raises the exception
+     */
+    b       .LhandleException
diff --git a/vm/compiler/template_notaint/armv5te/TEMPLATE_USHR_LONG.S b/vm/compiler/template_notaint/armv5te/TEMPLATE_USHR_LONG.S
new file mode 100644
index 0000000..8a48df2
--- /dev/null
+++ b/vm/compiler/template_notaint/armv5te/TEMPLATE_USHR_LONG.S
@@ -0,0 +1,15 @@
+    /*
+     * Long integer shift.  This is different from the generic 32/64-bit
+     * binary operations because vAA/vBB are 64-bit but vCC (the shift
+     * distance) is 32-bit.  Also, Dalvik requires us to ignore all but the low
+     * 6 bits.
+     */
+    /* ushr-long vAA, vBB, vCC */
+    and     r2, r2, #63                 @ r0<- r0 & 0x3f
+    mov     r0, r0, lsr r2              @  r0<- r2 >> r2
+    rsb     r3, r2, #32                 @  r3<- 32 - r2
+    orr     r0, r0, r1, asl r3          @  r0<- r0 | (r1 << (32-r2))
+    subs    ip, r2, #32                 @  ip<- r2 - 32
+    movpl   r0, r1, lsr ip              @  if r2 >= 32, r0<-r1 >>> (r2-32)
+    mov     r1, r1, lsr r2              @  r1<- r1 >>> r2
+    bx      lr
diff --git a/vm/compiler/template_notaint/armv5te/TemplateOpList.h b/vm/compiler/template_notaint/armv5te/TemplateOpList.h
new file mode 100644
index 0000000..abfec4b
--- /dev/null
+++ b/vm/compiler/template_notaint/armv5te/TemplateOpList.h
@@ -0,0 +1,50 @@
+/*
+ * Copyright (C) 2009 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+/*
+ * Dalvik opcode list that uses additional templates to complete JIT execution.
+ */
+#ifndef JIT_TEMPLATE
+#define JIT_TEMPLATE(X)
+#endif
+
+JIT_TEMPLATE(CMP_LONG)
+JIT_TEMPLATE(RETURN)
+JIT_TEMPLATE(INVOKE_METHOD_NO_OPT)
+JIT_TEMPLATE(INVOKE_METHOD_CHAIN)
+JIT_TEMPLATE(INVOKE_METHOD_PREDICTED_CHAIN)
+JIT_TEMPLATE(INVOKE_METHOD_NATIVE)
+JIT_TEMPLATE(CMPG_DOUBLE)
+JIT_TEMPLATE(CMPL_DOUBLE)
+JIT_TEMPLATE(CMPG_FLOAT)
+JIT_TEMPLATE(CMPL_FLOAT)
+JIT_TEMPLATE(MUL_LONG)
+JIT_TEMPLATE(SHL_LONG)
+JIT_TEMPLATE(SHR_LONG)
+JIT_TEMPLATE(USHR_LONG)
+JIT_TEMPLATE(THROW_EXCEPTION_COMMON)
+JIT_TEMPLATE(MEM_OP_DECODE)
+JIT_TEMPLATE(STRING_COMPARETO)
+JIT_TEMPLATE(STRING_INDEXOF)
+JIT_TEMPLATE(INTERPRET)
+JIT_TEMPLATE(MONITOR_ENTER)
+JIT_TEMPLATE(MONITOR_ENTER_DEBUG)
+JIT_TEMPLATE(PERIODIC_PROFILING)
+JIT_TEMPLATE(RETURN_PROF)
+JIT_TEMPLATE(INVOKE_METHOD_NO_OPT_PROF)
+JIT_TEMPLATE(INVOKE_METHOD_CHAIN_PROF)
+JIT_TEMPLATE(INVOKE_METHOD_PREDICTED_CHAIN_PROF)
+JIT_TEMPLATE(INVOKE_METHOD_NATIVE_PROF)
diff --git a/vm/compiler/template_notaint/armv5te/footer.S b/vm/compiler/template_notaint/armv5te/footer.S
new file mode 100644
index 0000000..16660ae
--- /dev/null
+++ b/vm/compiler/template_notaint/armv5te/footer.S
@@ -0,0 +1,129 @@
+/*
+ * ===========================================================================
+ *  Common subroutines and data
+ * ===========================================================================
+ */
+
+    .text
+    .align  2
+.LinvokeNative:
+    @ Prep for the native call
+    @ r1 = newFP, r0 = methodToCall
+    mov     r2, #0
+    ldr     r9, [rSELF, #offThread_jniLocal_topCookie]@r9<-thread->localRef->...
+    str     r2, [rSELF, #offThread_inJitCodeCache] @ not in jit code cache
+    str     r1, [rSELF, #offThread_curFrame]   @ curFrame = newFp
+    str     r9, [r1, #(offStackSaveArea_localRefCookie - sizeofStackSaveArea)]
+                                        @ newFp->localRefCookie=top
+    ldrh    lr, [rSELF, #offThread_subMode]
+    SAVEAREA_FROM_FP(r10, r1)           @ r10<- new stack save area
+
+    mov     r2, r0                      @ r2<- methodToCall
+    mov     r0, r1                      @ r0<- newFP
+    add     r1, rSELF, #offThread_retval  @ r1<- &retval
+    mov     r3, rSELF                   @ arg3<- self
+    ands    lr, #kSubModeMethodTrace
+    beq     121f                        @ hop if not profiling
+    @ r2: methodToCall, r6: rSELF
+    stmfd   sp!, {r2,r6}
+    stmfd   sp!, {r0-r3}
+    mov     r0, r2
+    mov     r1, r6
+    mov     lr, pc
+    ldr     pc, .LdvmFastMethodTraceEnter
+    ldmfd   sp!, {r0-r3}
+
+    mov     lr, pc
+    ldr     pc, [r2, #offMethod_nativeFunc]
+
+    ldmfd   sp!, {r0-r1}
+    mov     lr, pc
+    ldr     pc, .LdvmFastNativeMethodTraceExit
+    b       212f
+121:
+    mov     lr, pc
+    ldr     pc, [r2, #offMethod_nativeFunc]
+212:
+
+    @ native return; r10=newSaveArea
+    @ equivalent to dvmPopJniLocals
+    ldr     r2, [r10, #offStackSaveArea_returnAddr] @ r2 = chaining cell ret
+    ldr     r0, [r10, #offStackSaveArea_localRefCookie] @ r0<- saved->top
+    ldr     r1, [rSELF, #offThread_exception] @ check for exception
+    str     rFP, [rSELF, #offThread_curFrame]  @ curFrame = fp
+    cmp     r1, #0                      @ null?
+    str     r0, [rSELF, #offThread_jniLocal_topCookie] @ new top <- old top
+    ldr     r0, [r10, #offStackSaveArea_savedPc] @ reload rPC
+
+    @ r0 = dalvikCallsitePC
+    bne     .LhandleException           @ no, handle exception
+
+    str     r2, [rSELF, #offThread_inJitCodeCache] @ set the new mode
+    cmp     r2, #0                      @ return chaining cell still exists?
+    bxne    r2                          @ yes - go ahead
+
+    @ continue executing the next instruction through the interpreter
+    ldr     r1, .LdvmJitToInterpTraceSelectNoChain @ defined in footer.S
+    add     rPC, r0, #6                 @ reconstruct new rPC (advance 6 bytes)
+#if defined(WITH_JIT_TUNING)
+    mov     r0, #kCallsiteInterpreted
+#endif
+    mov     pc, r1
+
+/*
+ * On entry:
+ * r0  Faulting Dalvik PC
+ */
+.LhandleException:
+#if defined(WITH_SELF_VERIFICATION)
+    ldr     pc, .LdeadFood @ should not see this under self-verification mode
+.LdeadFood:
+    .word   0xdeadf00d
+#endif
+    mov     r2, #0
+    str     r2, [rSELF, #offThread_inJitCodeCache] @ in interpreter land
+    ldr     r1, .LdvmMterpCommonExceptionThrown @ PIC way of getting &func
+    ldr     rIBASE, .LdvmAsmInstructionStart    @ same as above
+    mov     rPC, r0                 @ reload the faulting Dalvik address
+    mov     pc, r1                  @ branch to dvmMterpCommonExceptionThrown
+
+    .align  2
+.LdvmAsmInstructionStart:
+    .word   dvmAsmInstructionStart
+.LdvmJitToInterpNoChainNoProfile:
+    .word   dvmJitToInterpNoChainNoProfile
+.LdvmJitToInterpTraceSelectNoChain:
+    .word   dvmJitToInterpTraceSelectNoChain
+.LdvmJitToInterpNoChain:
+    .word   dvmJitToInterpNoChain
+.LdvmMterpStdBail:
+    .word   dvmMterpStdBail
+.LdvmMterpCommonExceptionThrown:
+    .word   dvmMterpCommonExceptionThrown
+.LdvmLockObject:
+    .word   dvmLockObject
+.LdvmJitTraceProfilingOff:
+    .word   dvmJitTraceProfilingOff
+#if defined(WITH_JIT_TUNING)
+.LdvmICHitCount:
+    .word   gDvmICHitCount
+#endif
+#if defined(WITH_SELF_VERIFICATION)
+.LdvmSelfVerificationMemOpDecode:
+    .word   dvmSelfVerificationMemOpDecode
+#endif
+.LdvmFastMethodTraceEnter:
+    .word   dvmFastMethodTraceEnter
+.LdvmFastNativeMethodTraceExit:
+    .word   dvmFastNativeMethodTraceExit
+.LdvmFastMethodTraceExit:
+    .word   dvmFastMethodTraceExit
+.L__aeabi_cdcmple:
+    .word   __aeabi_cdcmple
+.L__aeabi_cfcmple:
+    .word   __aeabi_cfcmple
+
+    .global dmvCompilerTemplateEnd
+dmvCompilerTemplateEnd:
+
+#endif /* WITH_JIT */
diff --git a/vm/compiler/template_notaint/armv5te/header.S b/vm/compiler/template_notaint/armv5te/header.S
new file mode 100644
index 0000000..6dcf5b9
--- /dev/null
+++ b/vm/compiler/template_notaint/armv5te/header.S
@@ -0,0 +1,95 @@
+/*
+ * Copyright (C) 2008 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#if defined(WITH_JIT)
+
+/*
+ * ARMv5 definitions and declarations.
+ */
+
+/*
+ARM EABI general notes:
+
+r0-r3 hold first 4 args to a method; they are not preserved across method calls
+r4-r8 are available for general use
+r9 is given special treatment in some situations, but not for us
+r10 (sl) seems to be generally available
+r11 (fp) is used by gcc (unless -fomit-frame-pointer is set)
+r12 (ip) is scratch -- not preserved across method calls
+r13 (sp) should be managed carefully in case a signal arrives
+r14 (lr) must be preserved
+r15 (pc) can be tinkered with directly
+
+r0 holds returns of <= 4 bytes
+r0-r1 hold returns of 8 bytes, low word in r0
+
+Callee must save/restore r4+ (except r12) if it modifies them.
+
+Stack is "full descending".  Only the arguments that don't fit in the first 4
+registers are placed on the stack.  "sp" points at the first stacked argument
+(i.e. the 5th arg).
+
+VFP: single-precision results in s0, double-precision results in d0.
+
+In the EABI, "sp" must be 64-bit aligned on entry to a function, and any
+64-bit quantities (long long, double) must be 64-bit aligned.
+*/
+
+/*
+JIT and ARM notes:
+
+The following registers have fixed assignments:
+
+  reg nick      purpose
+  r5  rFP       interpreted frame pointer, used for accessing locals and args
+  r6  rSELF     thread pointer
+
+The following registers have fixed assignments in mterp but are scratch
+registers in compiled code
+
+  reg nick      purpose
+  r4  rPC       interpreted program counter, used for fetching instructions
+  r7  rINST     first 16-bit code unit of current instruction
+  r8  rIBASE    interpreted instruction base pointer, used for computed goto
+
+Macros are provided for common operations.  Each macro MUST emit only
+one instruction to make instruction-counting easier.  They MUST NOT alter
+unspecified registers or condition codes.
+*/
+
+/* single-purpose registers, given names for clarity */
+#define rPC     r4
+#define rFP     r5
+#define rSELF   r6
+#define rINST   r7
+#define rIBASE  r8
+
+/*
+ * Given a frame pointer, find the stack save area.
+ *
+ * In C this is "((StackSaveArea*)(_fp) -1)".
+ */
+#define SAVEAREA_FROM_FP(_reg, _fpreg) \
+    sub     _reg, _fpreg, #sizeofStackSaveArea
+
+#define EXPORT_PC() \
+    str     rPC, [rFP, #(-sizeofStackSaveArea + offStackSaveArea_currentPc)]
+
+/*
+ * This is a #include, not a %include, because we want the C pre-processor
+ * to expand the macros into assembler assignment statements.
+ */
+#include "../../../mterp/common/asm-constants.h"
diff --git a/vm/compiler/template_notaint/armv5te/platform.S b/vm/compiler/template_notaint/armv5te/platform.S
new file mode 100644
index 0000000..e0666a5
--- /dev/null
+++ b/vm/compiler/template_notaint/armv5te/platform.S
@@ -0,0 +1,5 @@
+/*
+ * ===========================================================================
+ *  CPU-version-specific defines and utility
+ * ===========================================================================
+ */
diff --git a/vm/compiler/template_notaint/armv7-a-neon/TemplateOpList.h b/vm/compiler/template_notaint/armv7-a-neon/TemplateOpList.h
new file mode 100644
index 0000000..0365ba4
--- /dev/null
+++ b/vm/compiler/template_notaint/armv7-a-neon/TemplateOpList.h
@@ -0,0 +1,65 @@
+/*
+ * Copyright (C) 2009 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+/*
+ * Dalvik opcode list that uses additional templates to complete JIT execution.
+ */
+#ifndef JIT_TEMPLATE
+#define JIT_TEMPLATE(X)
+#endif
+
+JIT_TEMPLATE(CMP_LONG)
+JIT_TEMPLATE(RETURN)
+JIT_TEMPLATE(INVOKE_METHOD_NO_OPT)
+JIT_TEMPLATE(INVOKE_METHOD_CHAIN)
+JIT_TEMPLATE(INVOKE_METHOD_PREDICTED_CHAIN)
+JIT_TEMPLATE(INVOKE_METHOD_NATIVE)
+JIT_TEMPLATE(MUL_LONG)
+JIT_TEMPLATE(SHL_LONG)
+JIT_TEMPLATE(SHR_LONG)
+JIT_TEMPLATE(USHR_LONG)
+JIT_TEMPLATE(ADD_FLOAT_VFP)
+JIT_TEMPLATE(SUB_FLOAT_VFP)
+JIT_TEMPLATE(MUL_FLOAT_VFP)
+JIT_TEMPLATE(DIV_FLOAT_VFP)
+JIT_TEMPLATE(ADD_DOUBLE_VFP)
+JIT_TEMPLATE(SUB_DOUBLE_VFP)
+JIT_TEMPLATE(MUL_DOUBLE_VFP)
+JIT_TEMPLATE(DIV_DOUBLE_VFP)
+JIT_TEMPLATE(DOUBLE_TO_FLOAT_VFP)
+JIT_TEMPLATE(DOUBLE_TO_INT_VFP)
+JIT_TEMPLATE(FLOAT_TO_DOUBLE_VFP)
+JIT_TEMPLATE(FLOAT_TO_INT_VFP)
+JIT_TEMPLATE(INT_TO_DOUBLE_VFP)
+JIT_TEMPLATE(INT_TO_FLOAT_VFP)
+JIT_TEMPLATE(CMPG_DOUBLE_VFP)
+JIT_TEMPLATE(CMPL_DOUBLE_VFP)
+JIT_TEMPLATE(CMPG_FLOAT_VFP)
+JIT_TEMPLATE(CMPL_FLOAT_VFP)
+JIT_TEMPLATE(SQRT_DOUBLE_VFP)
+JIT_TEMPLATE(THROW_EXCEPTION_COMMON)
+JIT_TEMPLATE(MEM_OP_DECODE)
+JIT_TEMPLATE(STRING_COMPARETO)
+JIT_TEMPLATE(STRING_INDEXOF)
+JIT_TEMPLATE(INTERPRET)
+JIT_TEMPLATE(MONITOR_ENTER)
+JIT_TEMPLATE(MONITOR_ENTER_DEBUG)
+JIT_TEMPLATE(PERIODIC_PROFILING)
+JIT_TEMPLATE(RETURN_PROF)
+JIT_TEMPLATE(INVOKE_METHOD_NO_OPT_PROF)
+JIT_TEMPLATE(INVOKE_METHOD_CHAIN_PROF)
+JIT_TEMPLATE(INVOKE_METHOD_PREDICTED_CHAIN_PROF)
+JIT_TEMPLATE(INVOKE_METHOD_NATIVE_PROF)
diff --git a/vm/compiler/template_notaint/armv7-a/TemplateOpList.h b/vm/compiler/template_notaint/armv7-a/TemplateOpList.h
new file mode 100644
index 0000000..0365ba4
--- /dev/null
+++ b/vm/compiler/template_notaint/armv7-a/TemplateOpList.h
@@ -0,0 +1,65 @@
+/*
+ * Copyright (C) 2009 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+/*
+ * Dalvik opcode list that uses additional templates to complete JIT execution.
+ */
+#ifndef JIT_TEMPLATE
+#define JIT_TEMPLATE(X)
+#endif
+
+JIT_TEMPLATE(CMP_LONG)
+JIT_TEMPLATE(RETURN)
+JIT_TEMPLATE(INVOKE_METHOD_NO_OPT)
+JIT_TEMPLATE(INVOKE_METHOD_CHAIN)
+JIT_TEMPLATE(INVOKE_METHOD_PREDICTED_CHAIN)
+JIT_TEMPLATE(INVOKE_METHOD_NATIVE)
+JIT_TEMPLATE(MUL_LONG)
+JIT_TEMPLATE(SHL_LONG)
+JIT_TEMPLATE(SHR_LONG)
+JIT_TEMPLATE(USHR_LONG)
+JIT_TEMPLATE(ADD_FLOAT_VFP)
+JIT_TEMPLATE(SUB_FLOAT_VFP)
+JIT_TEMPLATE(MUL_FLOAT_VFP)
+JIT_TEMPLATE(DIV_FLOAT_VFP)
+JIT_TEMPLATE(ADD_DOUBLE_VFP)
+JIT_TEMPLATE(SUB_DOUBLE_VFP)
+JIT_TEMPLATE(MUL_DOUBLE_VFP)
+JIT_TEMPLATE(DIV_DOUBLE_VFP)
+JIT_TEMPLATE(DOUBLE_TO_FLOAT_VFP)
+JIT_TEMPLATE(DOUBLE_TO_INT_VFP)
+JIT_TEMPLATE(FLOAT_TO_DOUBLE_VFP)
+JIT_TEMPLATE(FLOAT_TO_INT_VFP)
+JIT_TEMPLATE(INT_TO_DOUBLE_VFP)
+JIT_TEMPLATE(INT_TO_FLOAT_VFP)
+JIT_TEMPLATE(CMPG_DOUBLE_VFP)
+JIT_TEMPLATE(CMPL_DOUBLE_VFP)
+JIT_TEMPLATE(CMPG_FLOAT_VFP)
+JIT_TEMPLATE(CMPL_FLOAT_VFP)
+JIT_TEMPLATE(SQRT_DOUBLE_VFP)
+JIT_TEMPLATE(THROW_EXCEPTION_COMMON)
+JIT_TEMPLATE(MEM_OP_DECODE)
+JIT_TEMPLATE(STRING_COMPARETO)
+JIT_TEMPLATE(STRING_INDEXOF)
+JIT_TEMPLATE(INTERPRET)
+JIT_TEMPLATE(MONITOR_ENTER)
+JIT_TEMPLATE(MONITOR_ENTER_DEBUG)
+JIT_TEMPLATE(PERIODIC_PROFILING)
+JIT_TEMPLATE(RETURN_PROF)
+JIT_TEMPLATE(INVOKE_METHOD_NO_OPT_PROF)
+JIT_TEMPLATE(INVOKE_METHOD_CHAIN_PROF)
+JIT_TEMPLATE(INVOKE_METHOD_PREDICTED_CHAIN_PROF)
+JIT_TEMPLATE(INVOKE_METHOD_NATIVE_PROF)
diff --git a/vm/compiler/template_notaint/config-armv5te b/vm/compiler/template_notaint/config-armv5te
new file mode 100644
index 0000000..668df1b
--- /dev/null
+++ b/vm/compiler/template_notaint/config-armv5te
@@ -0,0 +1,45 @@
+# Copyright (C) 2009 The Android Open Source Project
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#      http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+#
+# Configuration for ARMv5TE architecture targets.
+#
+
+# file header and basic definitions
+#import c/header.c
+import armv5te/header.S
+
+# C pre-processor defines for stub C instructions
+#import cstubs/stubdefs.c
+
+# highly-platform-specific defs
+import armv5te/platform.S
+
+# common defs for the C helpers; include this before the instruction handlers
+#import c/opcommon.c
+
+# opcode list; argument to op-start is default directory
+op-start armv5te
+
+op-end
+
+# "helper" code for C; include if you use any of the C stubs (this generates
+# object code, so it's normally excluded)
+##import c/gotoTargets.c
+
+# end of defs; include this when cstubs/stubdefs.c is included
+#import cstubs/enddefs.c
+
+# common subroutines for asm
+import armv5te/footer.S
diff --git a/vm/compiler/template_notaint/config-armv5te-vfp b/vm/compiler/template_notaint/config-armv5te-vfp
new file mode 100644
index 0000000..774bd96
--- /dev/null
+++ b/vm/compiler/template_notaint/config-armv5te-vfp
@@ -0,0 +1,68 @@
+
+# Copyright (C) 2009 The Android Open Source Project
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#      http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+#
+# Configuration for ARMv5TE architecture targets.
+#
+
+# file header and basic definitions
+#import c/header.c
+import armv5te/header.S
+
+# C pre-processor defines for stub C instructions
+#import cstubs/stubdefs.c
+
+# highly-platform-specific defs
+import armv5te-vfp/platform.S
+
+# common defs for the C helpers; include this before the instruction handlers
+#import c/opcommon.c
+
+# opcode list; argument to op-start is default directory
+op-start armv5te-vfp
+    op TEMPLATE_CMP_LONG armv5te
+    op TEMPLATE_INVOKE_METHOD_CHAIN armv5te
+    op TEMPLATE_INVOKE_METHOD_NATIVE armv5te
+    op TEMPLATE_INVOKE_METHOD_NO_OPT armv5te
+    op TEMPLATE_INVOKE_METHOD_PREDICTED_CHAIN armv5te
+    op TEMPLATE_MUL_LONG armv5te
+    op TEMPLATE_RETURN armv5te
+    op TEMPLATE_SHL_LONG armv5te
+    op TEMPLATE_SHR_LONG armv5te
+    op TEMPLATE_USHR_LONG armv5te
+    op TEMPLATE_THROW_EXCEPTION_COMMON armv5te
+    op TEMPLATE_STRING_COMPARETO armv5te
+    op TEMPLATE_STRING_INDEXOF armv5te
+    op TEMPLATE_INTERPRET armv5te
+    op TEMPLATE_MONITOR_ENTER armv5te
+    op TEMPLATE_MONITOR_ENTER_DEBUG armv5te
+    op TEMPLATE_PERIODIC_PROFILING armv5te
+    op TEMPLATE_INVOKE_METHOD_CHAIN_PROF armv5te
+    op TEMPLATE_INVOKE_METHOD_PREDICTED_CHAIN_PROF armv5te
+    op TEMPLATE_INVOKE_METHOD_NATIVE_PROF armv5te
+    op TEMPLATE_INVOKE_METHOD_NO_OPT_PROF armv5te
+    op TEMPLATE_RETURN_PROF armv5te
+
+op-end
+
+# "helper" code for C; include if you use any of the C stubs (this generates
+# object code, so it's normally excluded)
+##import c/gotoTargets.c
+
+# end of defs; include this when cstubs/stubdefs.c is included
+#import cstubs/enddefs.c
+
+# common subroutines for asm
+import armv5te/footer.S
diff --git a/vm/compiler/template_notaint/config-armv7-a b/vm/compiler/template_notaint/config-armv7-a
new file mode 100644
index 0000000..9d66e55
--- /dev/null
+++ b/vm/compiler/template_notaint/config-armv7-a
@@ -0,0 +1,67 @@
+
+# Copyright (C) 2009 The Android Open Source Project
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#      http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+#
+# Configuration for ARMv7-a architecture targets.
+#
+
+# file header and basic definitions
+#import c/header.c
+import armv5te/header.S
+
+# C pre-processor defines for stub C instructions
+#import cstubs/stubdefs.c
+
+# highly-platform-specific defs
+import armv5te-vfp/platform.S
+
+# common defs for the C helpers; include this before the instruction handlers
+#import c/opcommon.c
+
+# opcode list; argument to op-start is default directory
+op-start armv5te-vfp
+    op TEMPLATE_CMP_LONG armv5te
+    op TEMPLATE_INVOKE_METHOD_CHAIN armv5te
+    op TEMPLATE_INVOKE_METHOD_NATIVE armv5te
+    op TEMPLATE_INVOKE_METHOD_NO_OPT armv5te
+    op TEMPLATE_INVOKE_METHOD_PREDICTED_CHAIN armv5te
+    op TEMPLATE_MUL_LONG armv5te
+    op TEMPLATE_RETURN armv5te
+    op TEMPLATE_SHL_LONG armv5te
+    op TEMPLATE_SHR_LONG armv5te
+    op TEMPLATE_USHR_LONG armv5te
+    op TEMPLATE_THROW_EXCEPTION_COMMON armv5te
+    op TEMPLATE_STRING_COMPARETO armv5te
+    op TEMPLATE_STRING_INDEXOF armv5te
+    op TEMPLATE_INTERPRET armv5te
+    op TEMPLATE_MONITOR_ENTER armv5te
+    op TEMPLATE_MONITOR_ENTER_DEBUG armv5te
+    op TEMPLATE_PERIODIC_PROFILING armv5te
+    op TEMPLATE_INVOKE_METHOD_CHAIN_PROF armv5te
+    op TEMPLATE_INVOKE_METHOD_PREDICTED_CHAIN_PROF armv5te
+    op TEMPLATE_INVOKE_METHOD_NATIVE_PROF armv5te
+    op TEMPLATE_INVOKE_METHOD_NO_OPT_PROF armv5te
+    op TEMPLATE_RETURN_PROF armv5te
+op-end
+
+# "helper" code for C; include if you use any of the C stubs (this generates
+# object code, so it's normally excluded)
+##import c/gotoTargets.c
+
+# end of defs; include this when cstubs/stubdefs.c is included
+#import cstubs/enddefs.c
+
+# common subroutines for asm
+import armv5te/footer.S
diff --git a/vm/compiler/template_notaint/config-armv7-a-neon b/vm/compiler/template_notaint/config-armv7-a-neon
new file mode 100644
index 0000000..9d66e55
--- /dev/null
+++ b/vm/compiler/template_notaint/config-armv7-a-neon
@@ -0,0 +1,67 @@
+
+# Copyright (C) 2009 The Android Open Source Project
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#      http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+#
+# Configuration for ARMv7-a architecture targets.
+#
+
+# file header and basic definitions
+#import c/header.c
+import armv5te/header.S
+
+# C pre-processor defines for stub C instructions
+#import cstubs/stubdefs.c
+
+# highly-platform-specific defs
+import armv5te-vfp/platform.S
+
+# common defs for the C helpers; include this before the instruction handlers
+#import c/opcommon.c
+
+# opcode list; argument to op-start is default directory
+op-start armv5te-vfp
+    op TEMPLATE_CMP_LONG armv5te
+    op TEMPLATE_INVOKE_METHOD_CHAIN armv5te
+    op TEMPLATE_INVOKE_METHOD_NATIVE armv5te
+    op TEMPLATE_INVOKE_METHOD_NO_OPT armv5te
+    op TEMPLATE_INVOKE_METHOD_PREDICTED_CHAIN armv5te
+    op TEMPLATE_MUL_LONG armv5te
+    op TEMPLATE_RETURN armv5te
+    op TEMPLATE_SHL_LONG armv5te
+    op TEMPLATE_SHR_LONG armv5te
+    op TEMPLATE_USHR_LONG armv5te
+    op TEMPLATE_THROW_EXCEPTION_COMMON armv5te
+    op TEMPLATE_STRING_COMPARETO armv5te
+    op TEMPLATE_STRING_INDEXOF armv5te
+    op TEMPLATE_INTERPRET armv5te
+    op TEMPLATE_MONITOR_ENTER armv5te
+    op TEMPLATE_MONITOR_ENTER_DEBUG armv5te
+    op TEMPLATE_PERIODIC_PROFILING armv5te
+    op TEMPLATE_INVOKE_METHOD_CHAIN_PROF armv5te
+    op TEMPLATE_INVOKE_METHOD_PREDICTED_CHAIN_PROF armv5te
+    op TEMPLATE_INVOKE_METHOD_NATIVE_PROF armv5te
+    op TEMPLATE_INVOKE_METHOD_NO_OPT_PROF armv5te
+    op TEMPLATE_RETURN_PROF armv5te
+op-end
+
+# "helper" code for C; include if you use any of the C stubs (this generates
+# object code, so it's normally excluded)
+##import c/gotoTargets.c
+
+# end of defs; include this when cstubs/stubdefs.c is included
+#import cstubs/enddefs.c
+
+# common subroutines for asm
+import armv5te/footer.S
diff --git a/vm/compiler/template_notaint/config-ia32 b/vm/compiler/template_notaint/config-ia32
new file mode 100644
index 0000000..5709017
--- /dev/null
+++ b/vm/compiler/template_notaint/config-ia32
@@ -0,0 +1,45 @@
+# Copyright (C) 2010 The Android Open Source Project
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#      http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+#
+# Configuration for ARMv5TE architecture targets.
+#
+
+# file header and basic definitions
+#import c/header.c
+import ia32/header.S
+
+# C pre-processor defines for stub C instructions
+#import cstubs/stubdefs.c
+
+# highly-platform-specific defs
+import ia32/platform.S
+
+# common defs for the C helpers; include this before the instruction handlers
+#import c/opcommon.c
+
+# opcode list; argument to op-start is default directory
+op-start ia32
+
+op-end
+
+# "helper" code for C; include if you use any of the C stubs (this generates
+# object code, so it's normally excluded)
+##import c/gotoTargets.c
+
+# end of defs; include this when cstubs/stubdefs.c is included
+#import cstubs/enddefs.c
+
+# common subroutines for asm
+import ia32/footer.S
diff --git a/vm/compiler/template_notaint/gen-template.py b/vm/compiler/template_notaint/gen-template.py
new file mode 100644
index 0000000..02e9107
--- /dev/null
+++ b/vm/compiler/template_notaint/gen-template.py
@@ -0,0 +1,423 @@
+#!/usr/bin/env python
+#
+# Copyright (C) 2007 The Android Open Source Project
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#      http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+#
+# Using instructions from an architecture-specific config file, generate C
+# and assembly source files for the Dalvik JIT.
+#
+
+import sys, string, re, time
+from string import Template
+
+interp_defs_file = "TemplateOpList.h" # need opcode list
+
+handler_size_bits = -1000
+handler_size_bytes = -1000
+in_op_start = 0             # 0=not started, 1=started, 2=ended
+default_op_dir = None
+opcode_locations = {}
+asm_stub_text = []
+label_prefix = ".L"         # use ".L" to hide labels from gdb
+
+
+# Exception class.
+class DataParseError(SyntaxError):
+    "Failure when parsing data file"
+
+#
+# Set any omnipresent substitution values.
+#
+def getGlobalSubDict():
+    return { "handler_size_bits":handler_size_bits,
+             "handler_size_bytes":handler_size_bytes }
+
+#
+# Parse arch config file --
+# Set handler_size_bytes to the value of tokens[1], and handler_size_bits to
+# log2(handler_size_bytes).  Throws an exception if "bytes" is not a power
+# of two.
+#
+def setHandlerSize(tokens):
+    global handler_size_bits, handler_size_bytes
+    if len(tokens) != 2:
+        raise DataParseError("handler-size requires one argument")
+    if handler_size_bits != -1000:
+        raise DataParseError("handler-size may only be set once")
+
+    # compute log2(n), and make sure n is a power of 2
+    handler_size_bytes = bytes = int(tokens[1])
+    bits = -1
+    while bytes > 0:
+        bytes //= 2     # halve with truncating division
+        bits += 1
+
+    if handler_size_bytes == 0 or handler_size_bytes != (1 << bits):
+        raise DataParseError("handler-size (%d) must be power of 2 and > 0" \
+                % orig_bytes)
+    handler_size_bits = bits
+
+#
+# Parse arch config file --
+# Copy a file in to the C or asm output file.
+#
+def importFile(tokens):
+    if len(tokens) != 2:
+        raise DataParseError("import requires one argument")
+    source = tokens[1]
+    if source.endswith(".S"):
+        appendSourceFile(tokens[1], getGlobalSubDict(), asm_fp, None)
+    else:
+        raise DataParseError("don't know how to import %s (expecting .c/.S)"
+                % source)
+
+#
+# Parse arch config file --
+# Copy a file in to the C or asm output file.
+#
+def setAsmStub(tokens):
+    global asm_stub_text
+    if len(tokens) != 2:
+        raise DataParseError("import requires one argument")
+    try:
+        stub_fp = open(tokens[1])
+        asm_stub_text = stub_fp.readlines()
+    except IOError, err:
+        stub_fp.close()
+        raise DataParseError("unable to load asm-stub: %s" % str(err))
+    stub_fp.close()
+
+#
+# Parse arch config file --
+# Start of opcode list.
+#
+def opStart(tokens):
+    global in_op_start
+    global default_op_dir
+    if len(tokens) != 2:
+        raise DataParseError("opStart takes a directory name argument")
+    if in_op_start != 0:
+        raise DataParseError("opStart can only be specified once")
+    default_op_dir = tokens[1]
+    in_op_start = 1
+
+#
+# Parse arch config file --
+# Set location of a single opcode's source file.
+#
+def opEntry(tokens):
+    #global opcode_locations
+    if len(tokens) != 3:
+        raise DataParseError("op requires exactly two arguments")
+    if in_op_start != 1:
+        raise DataParseError("op statements must be between opStart/opEnd")
+    try:
+        index = opcodes.index(tokens[1])
+    except ValueError:
+        raise DataParseError("unknown opcode %s" % tokens[1])
+    opcode_locations[tokens[1]] = tokens[2]
+
+#
+# Parse arch config file --
+# End of opcode list; emit instruction blocks.
+#
+def opEnd(tokens):
+    global in_op_start
+    if len(tokens) != 1:
+        raise DataParseError("opEnd takes no arguments")
+    if in_op_start != 1:
+        raise DataParseError("opEnd must follow opStart, and only appear once")
+    in_op_start = 2
+
+    loadAndEmitOpcodes()
+
+
+#
+# Extract an ordered list of instructions from the VM sources.  We use the
+# "goto table" definition macro, which has exactly kNumPackedOpcodes
+# entries.
+#
+def getOpcodeList():
+    opcodes = []
+    opcode_fp = open("%s/%s" % (target_arch, interp_defs_file))
+    opcode_re = re.compile(r"^JIT_TEMPLATE\((\w+)\)", re.DOTALL)
+    for line in opcode_fp:
+        match = opcode_re.match(line)
+        if not match:
+            continue
+        opcodes.append("TEMPLATE_" + match.group(1))
+    opcode_fp.close()
+
+    return opcodes
+
+
+#
+# Load and emit opcodes for all kNumPackedOpcodes instructions.
+#
+def loadAndEmitOpcodes():
+    sister_list = []
+
+    # point dvmAsmInstructionStart at the first handler or stub
+    asm_fp.write("\n    .global dvmCompilerTemplateStart\n")
+    asm_fp.write("    .type   dvmCompilerTemplateStart, %function\n")
+    asm_fp.write("    .text\n\n")
+    asm_fp.write("dvmCompilerTemplateStart:\n\n")
+
+    for i in xrange(len(opcodes)):
+        op = opcodes[i]
+
+        if opcode_locations.has_key(op):
+            location = opcode_locations[op]
+        else:
+            location = default_op_dir
+
+        loadAndEmitAsm(location, i, sister_list)
+
+    # Use variable sized handlers now
+    # asm_fp.write("\n    .balign %d\n" % handler_size_bytes)
+    asm_fp.write("    .size   dvmCompilerTemplateStart, .-dvmCompilerTemplateStart\n")
+
+#
+# Load an assembly fragment and emit it.
+#
+def loadAndEmitAsm(location, opindex, sister_list):
+    op = opcodes[opindex]
+    source = "%s/%s.S" % (location, op)
+    dict = getGlobalSubDict()
+    dict.update({ "opcode":op, "opnum":opindex })
+    print " emit %s --> asm" % source
+
+    emitAsmHeader(asm_fp, dict)
+    appendSourceFile(source, dict, asm_fp, sister_list)
+
+#
+# Output the alignment directive and label for an assembly piece.
+#
+def emitAsmHeader(outfp, dict):
+    outfp.write("/* ------------------------------ */\n")
+    # The alignment directive ensures that the handler occupies
+    # at least the correct amount of space.  We don't try to deal
+    # with overflow here.
+    outfp.write("    .balign 4\n")
+    # Emit a label so that gdb will say the right thing.  We prepend an
+    # underscore so the symbol name doesn't clash with the Opcode enum.
+    template_name = "dvmCompiler_%(opcode)s" % dict
+    outfp.write("    .global %s\n" % template_name);
+    outfp.write("%s:\n" % template_name);
+
+#
+# Output a generic instruction stub that updates the "glue" struct and
+# calls the C implementation.
+#
+def emitAsmStub(outfp, dict):
+    emitAsmHeader(outfp, dict)
+    for line in asm_stub_text:
+        templ = Template(line)
+        outfp.write(templ.substitute(dict))
+
+#
+# Append the file specified by "source" to the open "outfp".  Each line will
+# be template-replaced using the substitution dictionary "dict".
+#
+# If the first line of the file starts with "%" it is taken as a directive.
+# A "%include" line contains a filename and, optionally, a Python-style
+# dictionary declaration with substitution strings.  (This is implemented
+# with recursion.)
+#
+# If "sister_list" is provided, and we find a line that contains only "&",
+# all subsequent lines from the file will be appended to sister_list instead
+# of copied to the output.
+#
+# This may modify "dict".
+#
+def appendSourceFile(source, dict, outfp, sister_list):
+    outfp.write("/* File: %s */\n" % source)
+    infp = open(source, "r")
+    in_sister = False
+    for line in infp:
+        if line.startswith("%include"):
+            # Parse the "include" line
+            tokens = line.strip().split(' ', 2)
+            if len(tokens) < 2:
+                raise DataParseError("malformed %%include in %s" % source)
+
+            alt_source = tokens[1].strip("\"")
+            if alt_source == source:
+                raise DataParseError("self-referential %%include in %s"
+                        % source)
+
+            new_dict = dict.copy()
+            if len(tokens) == 3:
+                new_dict.update(eval(tokens[2]))
+            #print " including src=%s dict=%s" % (alt_source, new_dict)
+            appendSourceFile(alt_source, new_dict, outfp, sister_list)
+            continue
+
+        elif line.startswith("%default"):
+            # copy keywords into dictionary
+            tokens = line.strip().split(' ', 1)
+            if len(tokens) < 2:
+                raise DataParseError("malformed %%default in %s" % source)
+            defaultValues = eval(tokens[1])
+            for entry in defaultValues:
+                dict.setdefault(entry, defaultValues[entry])
+            continue
+
+        elif line.startswith("%verify"):
+            # more to come, someday
+            continue
+
+        elif line.startswith("%break") and sister_list != None:
+            # allow more than one %break, ignoring all following the first
+            if not in_sister:
+                in_sister = True
+                sister_list.append("\n/* continuation for %(opcode)s */\n"%dict)
+            continue
+
+        # perform keyword substitution if a dictionary was provided
+        if dict != None:
+            templ = Template(line)
+            try:
+                subline = templ.substitute(dict)
+            except KeyError, err:
+                raise DataParseError("keyword substitution failed in %s: %s"
+                        % (source, str(err)))
+            except:
+                print "ERROR: substitution failed: " + line
+                raise
+        else:
+            subline = line
+
+        # write output to appropriate file
+        if in_sister:
+            sister_list.append(subline)
+        else:
+            outfp.write(subline)
+    outfp.write("\n")
+    infp.close()
+
+#
+# Emit a C-style section header comment.
+#
+def emitSectionComment(str, fp):
+    equals = "========================================" \
+             "==================================="
+
+    fp.write("\n/*\n * %s\n *  %s\n * %s\n */\n" %
+        (equals, str, equals))
+
+
+#
+# ===========================================================================
+# "main" code
+#
+
+#
+# Check args.
+#
+if len(sys.argv) != 3:
+    print "Usage: %s target-arch output-dir" % sys.argv[0]
+    sys.exit(2)
+
+target_arch = sys.argv[1]
+output_dir = sys.argv[2]
+
+#
+# Extract opcode list.
+#
+opcodes = getOpcodeList()
+#for op in opcodes:
+#    print "  %s" % op
+
+#
+# Open config file.
+#
+try:
+    config_fp = open("config-%s" % target_arch)
+except:
+    print "Unable to open config file 'config-%s'" % target_arch
+    sys.exit(1)
+
+#
+# Open and prepare output files.
+#
+try:
+    asm_fp = open("%s/CompilerTemplateAsm-%s.S" % (output_dir, target_arch), "w")
+except:
+    print "Unable to open output files"
+    print "Make sure directory '%s' exists and existing files are writable" \
+            % output_dir
+    # Ideally we'd remove the files to avoid confusing "make", but if they
+    # failed to open we probably won't be able to remove them either.
+    sys.exit(1)
+
+print "Generating %s" % (asm_fp.name)
+
+file_header = """/*
+ * This file was generated automatically by gen-template.py for '%s'.
+ *
+ * --> DO NOT EDIT <--
+ */
+
+""" % (target_arch)
+
+asm_fp.write(file_header)
+
+#
+# Process the config file.
+#
+failed = False
+try:
+    for line in config_fp:
+        line = line.strip()         # remove CRLF, leading spaces
+        tokens = line.split(' ')    # tokenize
+        #print "%d: %s" % (len(tokens), tokens)
+        if len(tokens[0]) == 0:
+            #print "  blank"
+            pass
+        elif tokens[0][0] == '#':
+            #print "  comment"
+            pass
+        else:
+            if tokens[0] == "handler-size":
+                setHandlerSize(tokens)
+            elif tokens[0] == "import":
+                importFile(tokens)
+            elif tokens[0] == "asm-stub":
+                setAsmStub(tokens)
+            elif tokens[0] == "op-start":
+                opStart(tokens)
+            elif tokens[0] == "op-end":
+                opEnd(tokens)
+            elif tokens[0] == "op":
+                opEntry(tokens)
+            else:
+                raise DataParseError, "unrecognized command '%s'" % tokens[0]
+except DataParseError, err:
+    print "Failed: " + str(err)
+    # TODO: remove output files so "make" doesn't get confused
+    failed = True
+    asm_fp.close()
+    c_fp = asm_fp = None
+
+config_fp.close()
+
+#
+# Done!
+#
+if asm_fp:
+    asm_fp.close()
+
+sys.exit(failed)
diff --git a/vm/compiler/template_notaint/ia32/TEMPLATE_INTERPRET.S b/vm/compiler/template_notaint/ia32/TEMPLATE_INTERPRET.S
new file mode 100644
index 0000000..5c7bf7c
--- /dev/null
+++ b/vm/compiler/template_notaint/ia32/TEMPLATE_INTERPRET.S
@@ -0,0 +1,38 @@
+    /*
+     * This handler is a bit odd - it may be called via chaining or
+     * from static code and is expected to cause control to flow
+     * to the interpreter.  The problem is where to find the Dalvik
+     * PC of the next instruction.  When called via chaining, the dPC
+     * will be located at *rp.  When called from static code, rPC is
+     * valid and rp is a real return pointer (that should be ignored).
+     * The Arm target deals with this by using the link register as
+     * a flag.  If it is zero, we know we were called from static code.
+     * If non-zero, it points to the chain cell containing dPC.
+     * For x86, we'll infer the source by looking where rp points.
+     * If it points to anywhere within the code cache, we'll assume
+     * we got here via chaining.  Otherwise, we'll assume rPC is valid.
+     *
+     * On entry:
+     *    (TOS)<- return pointer or pointer to dPC
+     */
+
+/*
+ * FIXME - this won't work as-is.  The cache boundaries are not
+ * set up until later.  Perhaps rething this whole thing.  Do we
+ * really need an interpret teplate?
+ */
+
+
+     movl   rSELF,%ecx
+     movl   $$.LinterpPunt,%edx
+     pop    %eax
+     /*cmpl   %eax,offThread_jitCacheEnd(%ecx)*/
+     ja     1f
+     /*cmpl   %eax,offThread_jitCacheStart(%ecx)*/
+     jb     1f
+     movl   %eax,rPC
+1:
+     jmp    *(%edx)
+
+.LinterpPunt:
+    .long   dvmJitToInterpPunt
diff --git a/vm/compiler/template_notaint/ia32/TemplateOpList.h b/vm/compiler/template_notaint/ia32/TemplateOpList.h
new file mode 100644
index 0000000..a5000da
--- /dev/null
+++ b/vm/compiler/template_notaint/ia32/TemplateOpList.h
@@ -0,0 +1,24 @@
+/*
+ * Copyright (C) 2010 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+/*
+ * Dalvik opcode list that uses additional templates to complete JIT execution.
+ */
+#ifndef JIT_TEMPLATE
+#define JIT_TEMPLATE(X)
+#endif
+
+JIT_TEMPLATE(INTERPRET)
diff --git a/vm/compiler/template_notaint/ia32/footer.S b/vm/compiler/template_notaint/ia32/footer.S
new file mode 100644
index 0000000..d350c77
--- /dev/null
+++ b/vm/compiler/template_notaint/ia32/footer.S
@@ -0,0 +1,13 @@
+/*
+ * ===========================================================================
+ *  Common subroutines and data
+ * ===========================================================================
+ */
+
+    .text
+    .align  4
+
+    .global dmvCompilerTemplateEnd
+dmvCompilerTemplateEnd:
+
+#endif /* WITH_JIT */
diff --git a/vm/compiler/template_notaint/ia32/header.S b/vm/compiler/template_notaint/ia32/header.S
new file mode 100644
index 0000000..ea2cc0f
--- /dev/null
+++ b/vm/compiler/template_notaint/ia32/header.S
@@ -0,0 +1,29 @@
+/*
+ * Copyright (C) 2010 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#if defined(WITH_JIT)
+
+/* Subset of defines from mterp/x86/header.S */
+#define rSELF (%ebp)
+#define rPC   %esi
+#define rFP   %edi
+#define rINST %ebx
+
+/*
+ * This is a #include, not a %include, because we want the C pre-processor
+ * to expand the macros into assembler assignment statements.
+ */
+#include "../../../mterp/common/asm-constants.h"
diff --git a/vm/compiler/template_notaint/ia32/platform.S b/vm/compiler/template_notaint/ia32/platform.S
new file mode 100644
index 0000000..a84e62d
--- /dev/null
+++ b/vm/compiler/template_notaint/ia32/platform.S
@@ -0,0 +1,7 @@
+/*
+ * ===========================================================================
+ *  CPU-version-specific defines and utility
+ * ===========================================================================
+ */
+
+
diff --git a/vm/compiler/template_notaint/out/CompilerTemplateAsm-armv5te-vfp.S b/vm/compiler/template_notaint/out/CompilerTemplateAsm-armv5te-vfp.S
new file mode 100644
index 0000000..331d902
--- /dev/null
+++ b/vm/compiler/template_notaint/out/CompilerTemplateAsm-armv5te-vfp.S
@@ -0,0 +1,1981 @@
+/*
+ * This file was generated automatically by gen-template.py for 'armv5te-vfp'.
+ *
+ * --> DO NOT EDIT <--
+ */
+
+/* File: armv5te/header.S */
+/*
+ * Copyright (C) 2008 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#if defined(WITH_JIT)
+
+/*
+ * ARMv5 definitions and declarations.
+ */
+
+/*
+ARM EABI general notes:
+
+r0-r3 hold first 4 args to a method; they are not preserved across method calls
+r4-r8 are available for general use
+r9 is given special treatment in some situations, but not for us
+r10 (sl) seems to be generally available
+r11 (fp) is used by gcc (unless -fomit-frame-pointer is set)
+r12 (ip) is scratch -- not preserved across method calls
+r13 (sp) should be managed carefully in case a signal arrives
+r14 (lr) must be preserved
+r15 (pc) can be tinkered with directly
+
+r0 holds returns of <= 4 bytes
+r0-r1 hold returns of 8 bytes, low word in r0
+
+Callee must save/restore r4+ (except r12) if it modifies them.
+
+Stack is "full descending".  Only the arguments that don't fit in the first 4
+registers are placed on the stack.  "sp" points at the first stacked argument
+(i.e. the 5th arg).
+
+VFP: single-precision results in s0, double-precision results in d0.
+
+In the EABI, "sp" must be 64-bit aligned on entry to a function, and any
+64-bit quantities (long long, double) must be 64-bit aligned.
+*/
+
+/*
+JIT and ARM notes:
+
+The following registers have fixed assignments:
+
+  reg nick      purpose
+  r5  rFP       interpreted frame pointer, used for accessing locals and args
+  r6  rSELF     thread pointer
+
+The following registers have fixed assignments in mterp but are scratch
+registers in compiled code
+
+  reg nick      purpose
+  r4  rPC       interpreted program counter, used for fetching instructions
+  r7  rINST     first 16-bit code unit of current instruction
+  r8  rIBASE    interpreted instruction base pointer, used for computed goto
+
+Macros are provided for common operations.  Each macro MUST emit only
+one instruction to make instruction-counting easier.  They MUST NOT alter
+unspecified registers or condition codes.
+*/
+
+/* single-purpose registers, given names for clarity */
+#define rPC     r4
+#define rFP     r5
+#define rSELF   r6
+#define rINST   r7
+#define rIBASE  r8
+
+/*
+ * Given a frame pointer, find the stack save area.
+ *
+ * In C this is "((StackSaveArea*)(_fp) -1)".
+ */
+#define SAVEAREA_FROM_FP(_reg, _fpreg) \
+    sub     _reg, _fpreg, #sizeofStackSaveArea
+
+#define EXPORT_PC() \
+    str     rPC, [rFP, #(-sizeofStackSaveArea + offStackSaveArea_currentPc)]
+
+/*
+ * This is a #include, not a %include, because we want the C pre-processor
+ * to expand the macros into assembler assignment statements.
+ */
+#include "../../../mterp/common/asm-constants.h"
+
+/* File: armv5te-vfp/platform.S */
+/*
+ * ===========================================================================
+ *  CPU-version-specific defines and utility
+ * ===========================================================================
+ */
+
+
+    .global dvmCompilerTemplateStart
+    .type   dvmCompilerTemplateStart, %function
+    .text
+
+dvmCompilerTemplateStart:
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_CMP_LONG
+dvmCompiler_TEMPLATE_CMP_LONG:
+/* File: armv5te/TEMPLATE_CMP_LONG.S */
+    /*
+     * Compare two 64-bit values.  Puts 0, 1, or -1 into the destination
+     * register based on the results of the comparison.
+     *
+     * We load the full values with LDM, but in practice many values could
+     * be resolved by only looking at the high word.  This could be made
+     * faster or slower by splitting the LDM into a pair of LDRs.
+     *
+     * If we just wanted to set condition flags, we could do this:
+     *  subs    ip, r0, r2
+     *  sbcs    ip, r1, r3
+     *  subeqs  ip, r0, r2
+     * Leaving { <0, 0, >0 } in ip.  However, we have to set it to a specific
+     * integer value, which we can do with 2 conditional mov/mvn instructions
+     * (set 1, set -1; if they're equal we already have 0 in ip), giving
+     * us a constant 5-cycle path plus a branch at the end to the
+     * instruction epilogue code.  The multi-compare approach below needs
+     * 2 or 3 cycles + branch if the high word doesn't match, 6 + branch
+     * in the worst case (the 64-bit values are equal).
+     */
+    /* cmp-long vAA, vBB, vCC */
+    cmp     r1, r3                      @ compare (vBB+1, vCC+1)
+    blt     .LTEMPLATE_CMP_LONG_less            @ signed compare on high part
+    bgt     .LTEMPLATE_CMP_LONG_greater
+    subs    r0, r0, r2                  @ r0<- r0 - r2
+    bxeq     lr
+    bhi     .LTEMPLATE_CMP_LONG_greater         @ unsigned compare on low part
+.LTEMPLATE_CMP_LONG_less:
+    mvn     r0, #0                      @ r0<- -1
+    bx      lr
+.LTEMPLATE_CMP_LONG_greater:
+    mov     r0, #1                      @ r0<- 1
+    bx      lr
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_RETURN
+dvmCompiler_TEMPLATE_RETURN:
+/* File: armv5te/TEMPLATE_RETURN.S */
+    /*
+     * Unwind a frame from the Dalvik stack for compiled OP_RETURN_XXX.
+     * If the stored value in returnAddr
+     * is non-zero, the caller is compiled by the JIT thus return to the
+     * address in the code cache following the invoke instruction. Otherwise
+     * return to the special dvmJitToInterpNoChain entry point.
+     */
+#if defined(TEMPLATE_INLINE_PROFILING)
+    stmfd   sp!, {r0-r2,lr}             @ preserve live registers
+    mov     r0, r6
+    @ r0=rSELF
+    mov     lr, pc
+    ldr     pc, .LdvmFastMethodTraceExit
+    ldmfd   sp!, {r0-r2,lr}             @ restore live registers
+#endif
+    SAVEAREA_FROM_FP(r0, rFP)           @ r0<- saveArea (old)
+    ldr     r10, [r0, #offStackSaveArea_prevFrame] @ r10<- saveArea->prevFrame
+    ldrb    r8, [rSELF, #offThread_breakFlags] @ r8<- breakFlags
+    ldr     rPC, [r0, #offStackSaveArea_savedPc] @ rPC<- saveArea->savedPc
+#if !defined(WITH_SELF_VERIFICATION)
+    ldr     r9,  [r0, #offStackSaveArea_returnAddr] @ r9<- chaining cell ret
+#else
+    mov     r9, #0                      @ disable chaining
+#endif
+    ldr     r2, [r10, #(offStackSaveArea_method - sizeofStackSaveArea)]
+                                        @ r2<- method we're returning to
+    cmp     r2, #0                      @ break frame?
+#if !defined(WITH_SELF_VERIFICATION)
+    beq     1f                          @ bail to interpreter
+#else
+    blxeq   lr                          @ punt to interpreter and compare state
+#endif
+    ldr     r1, .LdvmJitToInterpNoChainNoProfile @ defined in footer.S
+    mov     rFP, r10                    @ publish new FP
+    ldr     r10, [r2, #offMethod_clazz] @ r10<- method->clazz
+
+    str     r2, [rSELF, #offThread_method]@ self->method = newSave->method
+    ldr     r0, [r10, #offClassObject_pDvmDex] @ r0<- method->clazz->pDvmDex
+    str     rFP, [rSELF, #offThread_curFrame] @ curFrame = fp
+    add     rPC, rPC, #6                @ publish new rPC (advance 6 bytes)
+    str     r0, [rSELF, #offThread_methodClassDex]
+    cmp     r8, #0                      @ check the break flags
+    movne   r9, #0                      @ clear the chaining cell address
+    str     r9, [rSELF, #offThread_inJitCodeCache] @ in code cache or not
+    cmp     r9, #0                      @ chaining cell exists?
+    blxne   r9                          @ jump to the chaining cell
+#if defined(WITH_JIT_TUNING)
+    mov     r0, #kCallsiteInterpreted
+#endif
+    mov     pc, r1                      @ callsite is interpreted
+1:
+    mov     r0, #0
+    str     r0, [rSELF, #offThread_inJitCodeCache] @ reset inJitCodeCache
+    stmia   rSELF, {rPC, rFP}           @ SAVE_PC_FP_TO_SELF()
+    ldr     r2, .LdvmMterpStdBail       @ defined in footer.S
+    mov     r0, rSELF                   @ Expecting rSELF in r0
+    blx     r2                          @ exit the interpreter
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_INVOKE_METHOD_NO_OPT
+dvmCompiler_TEMPLATE_INVOKE_METHOD_NO_OPT:
+/* File: armv5te/TEMPLATE_INVOKE_METHOD_NO_OPT.S */
+    /*
+     * For polymorphic callsites - setup the Dalvik frame and load Dalvik PC
+     * into rPC then jump to dvmJitToInterpNoChain to dispatch the
+     * runtime-resolved callee.
+     */
+    @ r0 = methodToCall, r1 = returnCell, rPC = dalvikCallsite
+    ldrh    r7, [r0, #offMethod_registersSize]  @ r7<- methodToCall->regsSize
+    ldrh    r2, [r0, #offMethod_outsSize]  @ r2<- methodToCall->outsSize
+    ldr     r9, [rSELF, #offThread_interpStackEnd]    @ r9<- interpStackEnd
+    ldrb    r8, [rSELF, #offThread_breakFlags] @ r8<- breakFlags
+    add     r3, r1, #1  @ Thumb addr is odd
+    SAVEAREA_FROM_FP(r1, rFP)           @ r1<- stack save area
+    sub     r1, r1, r7, lsl #2          @ r1<- newFp (old savearea - regsSize)
+    SAVEAREA_FROM_FP(r10, r1)           @ r10<- stack save area
+    sub     r10, r10, r2, lsl #2        @ r10<- bottom (newsave - outsSize)
+    cmp     r10, r9                     @ bottom < interpStackEnd?
+    bxlo    lr                          @ return to raise stack overflow excep.
+    @ r1 = newFP, r0 = methodToCall, r3 = returnCell, rPC = dalvikCallsite
+    ldr     r9, [r0, #offMethod_clazz]      @ r9<- method->clazz
+    ldr     r10, [r0, #offMethod_accessFlags] @ r10<- methodToCall->accessFlags
+    str     rPC, [rFP, #(offStackSaveArea_currentPc - sizeofStackSaveArea)]
+    str     rPC, [r1, #(offStackSaveArea_savedPc - sizeofStackSaveArea)]
+    ldr     rPC, [r0, #offMethod_insns]     @ rPC<- methodToCall->insns
+
+
+    @ set up newSaveArea
+    str     rFP, [r1, #(offStackSaveArea_prevFrame - sizeofStackSaveArea)]
+    str     r3, [r1, #(offStackSaveArea_returnAddr - sizeofStackSaveArea)]
+    str     r0, [r1, #(offStackSaveArea_method - sizeofStackSaveArea)]
+    cmp     r8, #0                      @ breakFlags != 0
+    bxne    lr                          @ bail to the interpreter
+    tst     r10, #ACC_NATIVE
+#if !defined(WITH_SELF_VERIFICATION)
+    bne     .LinvokeNative
+#else
+    bxne    lr                          @ bail to the interpreter
+#endif
+
+    ldr     r10, .LdvmJitToInterpTraceSelectNoChain
+    ldr     r3, [r9, #offClassObject_pDvmDex] @ r3<- method->clazz->pDvmDex
+
+    @ Update "thread" values for the new method
+    str     r0, [rSELF, #offThread_method]    @ self->method = methodToCall
+    str     r3, [rSELF, #offThread_methodClassDex] @ self->methodClassDex = ...
+    mov     rFP, r1                         @ fp = newFp
+    str     rFP, [rSELF, #offThread_curFrame]  @ curFrame = newFp
+#if defined(TEMPLATE_INLINE_PROFILING)
+    stmfd   sp!, {r0-r3}                    @ preserve r0-r3
+    mov     r1, r6
+    @ r0=methodToCall, r1=rSELF
+    mov     lr, pc
+    ldr     pc, .LdvmFastMethodTraceEnter
+    ldmfd   sp!, {r0-r3}                    @ restore r0-r3
+#endif
+
+    @ Start executing the callee
+#if defined(WITH_JIT_TUNING)
+    mov     r0, #kInlineCacheMiss
+#endif
+    mov     pc, r10                         @ dvmJitToInterpTraceSelectNoChain
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_INVOKE_METHOD_CHAIN
+dvmCompiler_TEMPLATE_INVOKE_METHOD_CHAIN:
+/* File: armv5te/TEMPLATE_INVOKE_METHOD_CHAIN.S */
+    /*
+     * For monomorphic callsite, setup the Dalvik frame and return to the
+     * Thumb code through the link register to transfer control to the callee
+     * method through a dedicated chaining cell.
+     */
+    @ r0 = methodToCall, r1 = returnCell, r2 = methodToCall->outsSize
+    @ rPC = dalvikCallsite, r7 = methodToCall->registersSize
+    @ methodToCall is guaranteed to be non-native
+.LinvokeChain:
+    ldr     r9, [rSELF, #offThread_interpStackEnd]    @ r9<- interpStackEnd
+    ldrb    r8, [rSELF, #offThread_breakFlags]        @ r8<- breakFlags
+    add     r3, r1, #1  @ Thumb addr is odd
+    SAVEAREA_FROM_FP(r1, rFP)           @ r1<- stack save area
+    sub     r1, r1, r7, lsl #2          @ r1<- newFp (old savearea - regsSize)
+    SAVEAREA_FROM_FP(r10, r1)           @ r10<- stack save area
+    add     r12, lr, #2                 @ setup the punt-to-interp address
+    sub     r10, r10, r2, lsl #2        @ r10<- bottom (newsave - outsSize)
+    cmp     r10, r9                     @ bottom < interpStackEnd?
+    bxlo    r12                         @ return to raise stack overflow excep.
+    @ r1 = newFP, r0 = methodToCall, r3 = returnCell, rPC = dalvikCallsite
+    ldr     r9, [r0, #offMethod_clazz]      @ r9<- method->clazz
+    str     rPC, [rFP, #(offStackSaveArea_currentPc - sizeofStackSaveArea)]
+    str     rPC, [r1, #(offStackSaveArea_savedPc - sizeofStackSaveArea)]
+
+    @ set up newSaveArea
+    str     rFP, [r1, #(offStackSaveArea_prevFrame - sizeofStackSaveArea)]
+    str     r3, [r1, #(offStackSaveArea_returnAddr - sizeofStackSaveArea)]
+    str     r0, [r1, #(offStackSaveArea_method - sizeofStackSaveArea)]
+    cmp     r8, #0                      @ breakFlags != 0
+    bxne    r12                         @ bail to the interpreter
+
+    ldr     r3, [r9, #offClassObject_pDvmDex] @ r3<- method->clazz->pDvmDex
+
+    @ Update "thread" values for the new method
+    str     r0, [rSELF, #offThread_method]    @ self->method = methodToCall
+    str     r3, [rSELF, #offThread_methodClassDex] @ self->methodClassDex = ...
+    mov     rFP, r1                         @ fp = newFp
+    str     rFP, [rSELF, #offThread_curFrame]  @ curFrame = newFp
+#if defined(TEMPLATE_INLINE_PROFILING)
+    stmfd   sp!, {r0-r2,lr}             @ preserve clobbered live registers
+    mov     r1, r6
+    @ r0=methodToCall, r1=rSELF
+    mov     lr, pc
+    ldr     pc, .LdvmFastMethodTraceEnter
+    ldmfd   sp!, {r0-r2,lr}             @ restore registers
+#endif
+
+    bx      lr                              @ return to the callee-chaining cell
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_INVOKE_METHOD_PREDICTED_CHAIN
+dvmCompiler_TEMPLATE_INVOKE_METHOD_PREDICTED_CHAIN:
+/* File: armv5te/TEMPLATE_INVOKE_METHOD_PREDICTED_CHAIN.S */
+    /*
+     * For polymorphic callsite, check whether the cached class pointer matches
+     * the current one. If so setup the Dalvik frame and return to the
+     * Thumb code through the link register to transfer control to the callee
+     * method through a dedicated chaining cell.
+     *
+     * The predicted chaining cell is declared in ArmLIR.h with the
+     * following layout:
+     *
+     *  typedef struct PredictedChainingCell {
+     *      u4 branch;
+     *      const ClassObject *clazz;
+     *      const Method *method;
+     *      u4 counter;
+     *  } PredictedChainingCell;
+     *
+     * Upon returning to the callsite:
+     *    - lr  : to branch to the chaining cell
+     *    - lr+2: to punt to the interpreter
+     *    - lr+4: to fully resolve the callee and may rechain.
+     *            r3 <- class
+     *            r9 <- counter
+     */
+    @ r0 = this, r1 = returnCell, r2 = predictedChainCell, rPC = dalvikCallsite
+    ldr     r3, [r0, #offObject_clazz]  @ r3 <- this->class
+    ldr     r8, [r2, #4]    @ r8 <- predictedChainCell->clazz
+    ldr     r0, [r2, #8]    @ r0 <- predictedChainCell->method
+    ldr     r9, [rSELF, #offThread_icRechainCount] @ r1 <- shared rechainCount
+    cmp     r3, r8          @ predicted class == actual class?
+#if defined(WITH_JIT_TUNING)
+    ldr     r7, .LdvmICHitCount
+#if defined(WORKAROUND_CORTEX_A9_745320)
+    /* Don't use conditional loads if the HW defect exists */
+    bne     101f
+    ldr     r10, [r7, #0]
+101:
+#else
+    ldreq   r10, [r7, #0]
+#endif
+    add     r10, r10, #1
+    streq   r10, [r7, #0]
+#endif
+    ldreqh  r7, [r0, #offMethod_registersSize]  @ r7<- methodToCall->regsSize
+    ldreqh  r2, [r0, #offMethod_outsSize]  @ r2<- methodToCall->outsSize
+    beq     .LinvokeChain   @ predicted chain is valid
+    ldr     r7, [r3, #offClassObject_vtable] @ r7 <- this->class->vtable
+    cmp     r8, #0          @ initialized class or not
+    moveq   r1, #0
+    subne   r1, r9, #1      @ count--
+    strne   r1, [rSELF, #offThread_icRechainCount]  @ write back to thread
+    add     lr, lr, #4      @ return to fully-resolve landing pad
+    /*
+     * r1 <- count
+     * r2 <- &predictedChainCell
+     * r3 <- this->class
+     * r4 <- dPC
+     * r7 <- this->class->vtable
+     */
+    bx      lr
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_INVOKE_METHOD_NATIVE
+dvmCompiler_TEMPLATE_INVOKE_METHOD_NATIVE:
+/* File: armv5te/TEMPLATE_INVOKE_METHOD_NATIVE.S */
+    @ r0 = methodToCall, r1 = returnCell, rPC = dalvikCallsite
+    @ r7 = methodToCall->registersSize
+    ldr     r9, [rSELF, #offThread_interpStackEnd]    @ r9<- interpStackEnd
+    ldrb    r8, [rSELF, #offThread_breakFlags]        @ r8<- breakFlags
+    add     r3, r1, #1  @ Thumb addr is odd
+    SAVEAREA_FROM_FP(r1, rFP)           @ r1<- stack save area
+    sub     r1, r1, r7, lsl #2          @ r1<- newFp (old savearea - regsSize)
+    SAVEAREA_FROM_FP(r10, r1)           @ r10<- stack save area
+    cmp     r10, r9                     @ bottom < interpStackEnd?
+    bxlo    lr                          @ return to raise stack overflow excep.
+    @ r1 = newFP, r0 = methodToCall, r3 = returnCell, rPC = dalvikCallsite
+    str     rPC, [rFP, #(offStackSaveArea_currentPc - sizeofStackSaveArea)]
+    str     rPC, [r1, #(offStackSaveArea_savedPc - sizeofStackSaveArea)]
+
+    @ set up newSaveArea
+    str     rFP, [r1, #(offStackSaveArea_prevFrame - sizeofStackSaveArea)]
+    str     r3, [r1, #(offStackSaveArea_returnAddr - sizeofStackSaveArea)]
+    str     r0, [r1, #(offStackSaveArea_method - sizeofStackSaveArea)]
+    cmp     r8, #0                      @ breakFlags != 0
+    ldr     r8, [r0, #offMethod_nativeFunc] @ r8<- method->nativeFunc
+#if !defined(WITH_SELF_VERIFICATION)
+    bxne    lr                          @ bail to the interpreter
+#else
+    bx      lr                          @ bail to interpreter unconditionally
+#endif
+
+    @ go ahead and transfer control to the native code
+    ldr     r9, [rSELF, #offThread_jniLocal_topCookie]@r9<-thread->localRef->...
+    mov     r2, #0
+    str     r1, [rSELF, #offThread_curFrame]   @ curFrame = newFp
+    str     r2, [rSELF, #offThread_inJitCodeCache] @ not in the jit code cache
+    str     r9, [r1, #(offStackSaveArea_localRefCookie - sizeofStackSaveArea)]
+                                        @ newFp->localRefCookie=top
+    SAVEAREA_FROM_FP(r10, r1)           @ r10<- new stack save area
+
+    mov     r2, r0                        @ arg2<- methodToCall
+    mov     r0, r1                        @ arg0<- newFP
+    add     r1, rSELF, #offThread_retval  @ arg1<- &retval
+    mov     r3, rSELF                     @ arg3<- self
+#if defined(TEMPLATE_INLINE_PROFILING)
+    @ r2=methodToCall, r6=rSELF
+    stmfd   sp!, {r2,r6}                @ to be consumed after JNI return
+    stmfd   sp!, {r0-r3}                @ preserve r0-r3
+    mov     r0, r2
+    mov     r1, r6
+    @ r0=JNIMethod, r1=rSELF
+    mov     lr, pc
+    ldr     pc, .LdvmFastMethodTraceEnter
+    ldmfd   sp!, {r0-r3}                @ restore r0-r3
+#endif
+
+    blx     r8                          @ off to the native code
+
+#if defined(TEMPLATE_INLINE_PROFILING)
+    ldmfd   sp!, {r0-r1}                @ restore r2 and r6
+    @ r0=JNIMethod, r1=rSELF
+    mov     lr, pc
+    ldr     pc, .LdvmFastNativeMethodTraceExit
+#endif
+    @ native return; r10=newSaveArea
+    @ equivalent to dvmPopJniLocals
+    ldr     r2, [r10, #offStackSaveArea_returnAddr] @ r2 = chaining cell ret
+    ldr     r0, [r10, #offStackSaveArea_localRefCookie] @ r0<- saved->top
+    ldr     r1, [rSELF, #offThread_exception] @ check for exception
+    str     rFP, [rSELF, #offThread_curFrame]  @ curFrame = fp
+    cmp     r1, #0                      @ null?
+    str     r0, [rSELF, #offThread_jniLocal_topCookie] @ new top <- old top
+    ldr     r0, [rFP, #(offStackSaveArea_currentPc - sizeofStackSaveArea)]
+
+    @ r0 = dalvikCallsitePC
+    bne     .LhandleException           @ no, handle exception
+
+    str     r2, [rSELF, #offThread_inJitCodeCache] @ set the mode properly
+    cmp     r2, #0                      @ return chaining cell still exists?
+    bxne    r2                          @ yes - go ahead
+
+    @ continue executing the next instruction through the interpreter
+    ldr     r1, .LdvmJitToInterpTraceSelectNoChain @ defined in footer.S
+    add     rPC, r0, #6                 @ reconstruct new rPC (advance 6 bytes)
+#if defined(WITH_JIT_TUNING)
+    mov     r0, #kCallsiteInterpreted
+#endif
+    mov     pc, r1
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_MUL_LONG
+dvmCompiler_TEMPLATE_MUL_LONG:
+/* File: armv5te/TEMPLATE_MUL_LONG.S */
+    /*
+     * Signed 64-bit integer multiply.
+     *
+     * For JIT: op1 in r0/r1, op2 in r2/r3, return in r0/r1
+     *
+     * Consider WXxYZ (r1r0 x r3r2) with a long multiply:
+     *        WX
+     *      x YZ
+     *  --------
+     *     ZW ZX
+     *  YW YX
+     *
+     * The low word of the result holds ZX, the high word holds
+     * (ZW+YX) + (the high overflow from ZX).  YW doesn't matter because
+     * it doesn't fit in the low 64 bits.
+     *
+     * Unlike most ARM math operations, multiply instructions have
+     * restrictions on using the same register more than once (Rd and Rm
+     * cannot be the same).
+     */
+    /* mul-long vAA, vBB, vCC */
+    mul     ip, r2, r1                  @  ip<- ZxW
+    umull   r9, r10, r2, r0             @  r9/r10 <- ZxX
+    mla     r2, r0, r3, ip              @  r2<- YxX + (ZxW)
+    add     r10, r2, r10                @  r10<- r10 + low(ZxW + (YxX))
+    mov     r0,r9
+    mov     r1,r10
+    bx      lr
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_SHL_LONG
+dvmCompiler_TEMPLATE_SHL_LONG:
+/* File: armv5te/TEMPLATE_SHL_LONG.S */
+    /*
+     * Long integer shift.  This is different from the generic 32/64-bit
+     * binary operations because vAA/vBB are 64-bit but vCC (the shift
+     * distance) is 32-bit.  Also, Dalvik requires us to ignore all but the low
+     * 6 bits.
+     */
+    /* shl-long vAA, vBB, vCC */
+    and     r2, r2, #63                 @ r2<- r2 & 0x3f
+    mov     r1, r1, asl r2              @  r1<- r1 << r2
+    rsb     r3, r2, #32                 @  r3<- 32 - r2
+    orr     r1, r1, r0, lsr r3          @  r1<- r1 | (r0 << (32-r2))
+    subs    ip, r2, #32                 @  ip<- r2 - 32
+    movpl   r1, r0, asl ip              @  if r2 >= 32, r1<- r0 << (r2-32)
+    mov     r0, r0, asl r2              @  r0<- r0 << r2
+    bx      lr
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_SHR_LONG
+dvmCompiler_TEMPLATE_SHR_LONG:
+/* File: armv5te/TEMPLATE_SHR_LONG.S */
+    /*
+     * Long integer shift.  This is different from the generic 32/64-bit
+     * binary operations because vAA/vBB are 64-bit but vCC (the shift
+     * distance) is 32-bit.  Also, Dalvik requires us to ignore all but the low
+     * 6 bits.
+     */
+    /* shr-long vAA, vBB, vCC */
+    and     r2, r2, #63                 @ r0<- r0 & 0x3f
+    mov     r0, r0, lsr r2              @  r0<- r2 >> r2
+    rsb     r3, r2, #32                 @  r3<- 32 - r2
+    orr     r0, r0, r1, asl r3          @  r0<- r0 | (r1 << (32-r2))
+    subs    ip, r2, #32                 @  ip<- r2 - 32
+    movpl   r0, r1, asr ip              @  if r2 >= 32, r0<-r1 >> (r2-32)
+    mov     r1, r1, asr r2              @  r1<- r1 >> r2
+    bx      lr
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_USHR_LONG
+dvmCompiler_TEMPLATE_USHR_LONG:
+/* File: armv5te/TEMPLATE_USHR_LONG.S */
+    /*
+     * Long integer shift.  This is different from the generic 32/64-bit
+     * binary operations because vAA/vBB are 64-bit but vCC (the shift
+     * distance) is 32-bit.  Also, Dalvik requires us to ignore all but the low
+     * 6 bits.
+     */
+    /* ushr-long vAA, vBB, vCC */
+    and     r2, r2, #63                 @ r0<- r0 & 0x3f
+    mov     r0, r0, lsr r2              @  r0<- r2 >> r2
+    rsb     r3, r2, #32                 @  r3<- 32 - r2
+    orr     r0, r0, r1, asl r3          @  r0<- r0 | (r1 << (32-r2))
+    subs    ip, r2, #32                 @  ip<- r2 - 32
+    movpl   r0, r1, lsr ip              @  if r2 >= 32, r0<-r1 >>> (r2-32)
+    mov     r1, r1, lsr r2              @  r1<- r1 >>> r2
+    bx      lr
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_ADD_FLOAT_VFP
+dvmCompiler_TEMPLATE_ADD_FLOAT_VFP:
+/* File: armv5te-vfp/TEMPLATE_ADD_FLOAT_VFP.S */
+/* File: armv5te-vfp/fbinop.S */
+    /*
+     * Generic 32-bit floating point operation.  Provide an "instr" line that
+     * specifies an instruction that performs s2 = s0 op s1.
+     *
+     * On entry:
+     *     r0 = target dalvik register address
+     *     r1 = op1 address
+     *     r2 = op2 address
+     */
+     flds    s0,[r1]
+     flds    s1,[r2]
+     fadds   s2, s0, s1
+     fsts    s2,[r0]
+     bx      lr
+
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_SUB_FLOAT_VFP
+dvmCompiler_TEMPLATE_SUB_FLOAT_VFP:
+/* File: armv5te-vfp/TEMPLATE_SUB_FLOAT_VFP.S */
+/* File: armv5te-vfp/fbinop.S */
+    /*
+     * Generic 32-bit floating point operation.  Provide an "instr" line that
+     * specifies an instruction that performs s2 = s0 op s1.
+     *
+     * On entry:
+     *     r0 = target dalvik register address
+     *     r1 = op1 address
+     *     r2 = op2 address
+     */
+     flds    s0,[r1]
+     flds    s1,[r2]
+     fsubs   s2, s0, s1
+     fsts    s2,[r0]
+     bx      lr
+
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_MUL_FLOAT_VFP
+dvmCompiler_TEMPLATE_MUL_FLOAT_VFP:
+/* File: armv5te-vfp/TEMPLATE_MUL_FLOAT_VFP.S */
+/* File: armv5te-vfp/fbinop.S */
+    /*
+     * Generic 32-bit floating point operation.  Provide an "instr" line that
+     * specifies an instruction that performs s2 = s0 op s1.
+     *
+     * On entry:
+     *     r0 = target dalvik register address
+     *     r1 = op1 address
+     *     r2 = op2 address
+     */
+     flds    s0,[r1]
+     flds    s1,[r2]
+     fmuls   s2, s0, s1
+     fsts    s2,[r0]
+     bx      lr
+
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_DIV_FLOAT_VFP
+dvmCompiler_TEMPLATE_DIV_FLOAT_VFP:
+/* File: armv5te-vfp/TEMPLATE_DIV_FLOAT_VFP.S */
+/* File: armv5te-vfp/fbinop.S */
+    /*
+     * Generic 32-bit floating point operation.  Provide an "instr" line that
+     * specifies an instruction that performs s2 = s0 op s1.
+     *
+     * On entry:
+     *     r0 = target dalvik register address
+     *     r1 = op1 address
+     *     r2 = op2 address
+     */
+     flds    s0,[r1]
+     flds    s1,[r2]
+     fdivs   s2, s0, s1
+     fsts    s2,[r0]
+     bx      lr
+
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_ADD_DOUBLE_VFP
+dvmCompiler_TEMPLATE_ADD_DOUBLE_VFP:
+/* File: armv5te-vfp/TEMPLATE_ADD_DOUBLE_VFP.S */
+/* File: armv5te-vfp/fbinopWide.S */
+    /*
+     * Generic 64-bit floating point operation.  Provide an "instr" line that
+     * specifies an instruction that performs s2 = s0 op s1.
+     *
+     * On entry:
+     *     r0 = target dalvik register address
+     *     r1 = op1 address
+     *     r2 = op2 address
+     */
+     fldd    d0,[r1]
+     fldd    d1,[r2]
+     faddd   d2, d0, d1
+     fstd    d2,[r0]
+     bx      lr
+
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_SUB_DOUBLE_VFP
+dvmCompiler_TEMPLATE_SUB_DOUBLE_VFP:
+/* File: armv5te-vfp/TEMPLATE_SUB_DOUBLE_VFP.S */
+/* File: armv5te-vfp/fbinopWide.S */
+    /*
+     * Generic 64-bit floating point operation.  Provide an "instr" line that
+     * specifies an instruction that performs s2 = s0 op s1.
+     *
+     * On entry:
+     *     r0 = target dalvik register address
+     *     r1 = op1 address
+     *     r2 = op2 address
+     */
+     fldd    d0,[r1]
+     fldd    d1,[r2]
+     fsubd   d2, d0, d1
+     fstd    d2,[r0]
+     bx      lr
+
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_MUL_DOUBLE_VFP
+dvmCompiler_TEMPLATE_MUL_DOUBLE_VFP:
+/* File: armv5te-vfp/TEMPLATE_MUL_DOUBLE_VFP.S */
+/* File: armv5te-vfp/fbinopWide.S */
+    /*
+     * Generic 64-bit floating point operation.  Provide an "instr" line that
+     * specifies an instruction that performs s2 = s0 op s1.
+     *
+     * On entry:
+     *     r0 = target dalvik register address
+     *     r1 = op1 address
+     *     r2 = op2 address
+     */
+     fldd    d0,[r1]
+     fldd    d1,[r2]
+     fmuld   d2, d0, d1
+     fstd    d2,[r0]
+     bx      lr
+
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_DIV_DOUBLE_VFP
+dvmCompiler_TEMPLATE_DIV_DOUBLE_VFP:
+/* File: armv5te-vfp/TEMPLATE_DIV_DOUBLE_VFP.S */
+/* File: armv5te-vfp/fbinopWide.S */
+    /*
+     * Generic 64-bit floating point operation.  Provide an "instr" line that
+     * specifies an instruction that performs s2 = s0 op s1.
+     *
+     * On entry:
+     *     r0 = target dalvik register address
+     *     r1 = op1 address
+     *     r2 = op2 address
+     */
+     fldd    d0,[r1]
+     fldd    d1,[r2]
+     fdivd   d2, d0, d1
+     fstd    d2,[r0]
+     bx      lr
+
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_DOUBLE_TO_FLOAT_VFP
+dvmCompiler_TEMPLATE_DOUBLE_TO_FLOAT_VFP:
+/* File: armv5te-vfp/TEMPLATE_DOUBLE_TO_FLOAT_VFP.S */
+/* File: armv5te-vfp/funopNarrower.S */
+    /*
+     * Generic 64bit-to-32bit floating point unary operation.  Provide an
+     * "instr" line that specifies an instruction that performs "s0 = op d0".
+     *
+     * For: double-to-int, double-to-float
+     *
+     * On entry:
+     *     r0 = target dalvik register address
+     *     r1 = src dalvik register address
+     */
+    /* unop vA, vB */
+    fldd    d0, [r1]                    @ d0<- vB
+    fcvtsd  s0, d0                              @ s0<- op d0
+    fsts    s0, [r0]                    @ vA<- s0
+    bx      lr
+
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_DOUBLE_TO_INT_VFP
+dvmCompiler_TEMPLATE_DOUBLE_TO_INT_VFP:
+/* File: armv5te-vfp/TEMPLATE_DOUBLE_TO_INT_VFP.S */
+/* File: armv5te-vfp/funopNarrower.S */
+    /*
+     * Generic 64bit-to-32bit floating point unary operation.  Provide an
+     * "instr" line that specifies an instruction that performs "s0 = op d0".
+     *
+     * For: double-to-int, double-to-float
+     *
+     * On entry:
+     *     r0 = target dalvik register address
+     *     r1 = src dalvik register address
+     */
+    /* unop vA, vB */
+    fldd    d0, [r1]                    @ d0<- vB
+    ftosizd  s0, d0                              @ s0<- op d0
+    fsts    s0, [r0]                    @ vA<- s0
+    bx      lr
+
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_FLOAT_TO_DOUBLE_VFP
+dvmCompiler_TEMPLATE_FLOAT_TO_DOUBLE_VFP:
+/* File: armv5te-vfp/TEMPLATE_FLOAT_TO_DOUBLE_VFP.S */
+/* File: armv5te-vfp/funopWider.S */
+    /*
+     * Generic 32bit-to-64bit floating point unary operation.  Provide an
+     * "instr" line that specifies an instruction that performs "d0 = op s0".
+     *
+     * For: int-to-double, float-to-double
+     *
+     * On entry:
+     *     r0 = target dalvik register address
+     *     r1 = src dalvik register address
+     */
+    /* unop vA, vB */
+    flds    s0, [r1]                    @ s0<- vB
+    fcvtds  d0, s0                              @ d0<- op s0
+    fstd    d0, [r0]                    @ vA<- d0
+    bx      lr
+
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_FLOAT_TO_INT_VFP
+dvmCompiler_TEMPLATE_FLOAT_TO_INT_VFP:
+/* File: armv5te-vfp/TEMPLATE_FLOAT_TO_INT_VFP.S */
+/* File: armv5te-vfp/funop.S */
+    /*
+     * Generic 32bit-to-32bit floating point unary operation.  Provide an
+     * "instr" line that specifies an instruction that performs "s1 = op s0".
+     *
+     * For: float-to-int, int-to-float
+     *
+     * On entry:
+     *     r0 = target dalvik register address
+     *     r1 = src dalvik register address
+     */
+    /* unop vA, vB */
+    flds    s0, [r1]                    @ s0<- vB
+    ftosizs s1, s0                              @ s1<- op s0
+    fsts    s1, [r0]                    @ vA<- s1
+    bx      lr
+
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_INT_TO_DOUBLE_VFP
+dvmCompiler_TEMPLATE_INT_TO_DOUBLE_VFP:
+/* File: armv5te-vfp/TEMPLATE_INT_TO_DOUBLE_VFP.S */
+/* File: armv5te-vfp/funopWider.S */
+    /*
+     * Generic 32bit-to-64bit floating point unary operation.  Provide an
+     * "instr" line that specifies an instruction that performs "d0 = op s0".
+     *
+     * For: int-to-double, float-to-double
+     *
+     * On entry:
+     *     r0 = target dalvik register address
+     *     r1 = src dalvik register address
+     */
+    /* unop vA, vB */
+    flds    s0, [r1]                    @ s0<- vB
+    fsitod  d0, s0                              @ d0<- op s0
+    fstd    d0, [r0]                    @ vA<- d0
+    bx      lr
+
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_INT_TO_FLOAT_VFP
+dvmCompiler_TEMPLATE_INT_TO_FLOAT_VFP:
+/* File: armv5te-vfp/TEMPLATE_INT_TO_FLOAT_VFP.S */
+/* File: armv5te-vfp/funop.S */
+    /*
+     * Generic 32bit-to-32bit floating point unary operation.  Provide an
+     * "instr" line that specifies an instruction that performs "s1 = op s0".
+     *
+     * For: float-to-int, int-to-float
+     *
+     * On entry:
+     *     r0 = target dalvik register address
+     *     r1 = src dalvik register address
+     */
+    /* unop vA, vB */
+    flds    s0, [r1]                    @ s0<- vB
+    fsitos  s1, s0                              @ s1<- op s0
+    fsts    s1, [r0]                    @ vA<- s1
+    bx      lr
+
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_CMPG_DOUBLE_VFP
+dvmCompiler_TEMPLATE_CMPG_DOUBLE_VFP:
+/* File: armv5te-vfp/TEMPLATE_CMPG_DOUBLE_VFP.S */
+    /*
+     * Compare two floating-point values.  Puts 0, 1, or -1 into the
+     * destination register based on the results of the comparison.
+     *
+     * int compare(x, y) {
+     *     if (x == y) {
+     *         return 0;
+     *     } else if (x < y) {
+     *         return -1;
+     *     } else if (x > y) {
+     *         return 1;
+     *     } else {
+     *         return 1;
+     *     }
+     * }
+     *
+     * On entry:
+     *    r0 = &op1 [vBB]
+     *    r1 = &op2 [vCC]
+     */
+    /* op vAA, vBB, vCC */
+    fldd    d0, [r0]                    @ d0<- vBB
+    fldd    d1, [r1]                    @ d1<- vCC
+    fcmpd  d0, d1                       @ compare (vBB, vCC)
+    mov     r0, #1                      @ r0<- 1 (default)
+    fmstat                              @ export status flags
+    mvnmi   r0, #0                      @ (less than) r0<- -1
+    moveq   r0, #0                      @ (equal) r0<- 0
+    bx      lr
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_CMPL_DOUBLE_VFP
+dvmCompiler_TEMPLATE_CMPL_DOUBLE_VFP:
+/* File: armv5te-vfp/TEMPLATE_CMPL_DOUBLE_VFP.S */
+    /*
+     * Compare two floating-point values.  Puts 0, 1, or -1 into the
+     * destination register based on the results of the comparison.
+     *
+     * int compare(x, y) {
+     *     if (x == y) {
+     *         return 0;
+     *     } else if (x > y) {
+     *         return 1;
+     *     } else if (x < y) {
+     *         return -1;
+     *     } else {
+     *         return -1;
+     *     }
+     * }
+     * On entry:
+     *    r0 = &op1 [vBB]
+     *    r1 = &op2 [vCC]
+     */
+    /* op vAA, vBB, vCC */
+    fldd    d0, [r0]                    @ d0<- vBB
+    fldd    d1, [r1]                    @ d1<- vCC
+    fcmped  d0, d1                      @ compare (vBB, vCC)
+    mvn     r0, #0                      @ r0<- -1 (default)
+    fmstat                              @ export status flags
+    movgt   r0, #1                      @ (greater than) r0<- 1
+    moveq   r0, #0                      @ (equal) r0<- 0
+    bx      lr
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_CMPG_FLOAT_VFP
+dvmCompiler_TEMPLATE_CMPG_FLOAT_VFP:
+/* File: armv5te-vfp/TEMPLATE_CMPG_FLOAT_VFP.S */
+    /*
+     * Compare two floating-point values.  Puts 0, 1, or -1 into the
+     * destination register based on the results of the comparison.
+     *
+     * int compare(x, y) {
+     *     if (x == y) {
+     *         return 0;
+     *     } else if (x < y) {
+     *         return -1;
+     *     } else if (x > y) {
+     *         return 1;
+     *     } else {
+     *         return 1;
+     *     }
+     * }
+     * On entry:
+     *    r0 = &op1 [vBB]
+     *    r1 = &op2 [vCC]
+     */
+    /* op vAA, vBB, vCC */
+    flds    s0, [r0]                    @ d0<- vBB
+    flds    s1, [r1]                    @ d1<- vCC
+    fcmps  s0, s1                      @ compare (vBB, vCC)
+    mov     r0, #1                      @ r0<- 1 (default)
+    fmstat                              @ export status flags
+    mvnmi   r0, #0                      @ (less than) r0<- -1
+    moveq   r0, #0                      @ (equal) r0<- 0
+    bx      lr
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_CMPL_FLOAT_VFP
+dvmCompiler_TEMPLATE_CMPL_FLOAT_VFP:
+/* File: armv5te-vfp/TEMPLATE_CMPL_FLOAT_VFP.S */
+    /*
+     * Compare two floating-point values.  Puts 0, 1, or -1 into the
+     * destination register based on the results of the comparison.
+     *
+     * int compare(x, y) {
+     *     if (x == y) {
+     *         return 0;
+     *     } else if (x > y) {
+     *         return 1;
+     *     } else if (x < y) {
+     *         return -1;
+     *     } else {
+     *         return -1;
+     *     }
+     * }
+     * On entry:
+     *    r0 = &op1 [vBB]
+     *    r1 = &op2 [vCC]
+     */
+    /* op vAA, vBB, vCC */
+    flds    s0, [r0]                    @ d0<- vBB
+    flds    s1, [r1]                    @ d1<- vCC
+    fcmps  s0, s1                      @ compare (vBB, vCC)
+    mvn     r0, #0                      @ r0<- -1 (default)
+    fmstat                              @ export status flags
+    movgt   r0, #1                      @ (greater than) r0<- 1
+    moveq   r0, #0                      @ (equal) r0<- 0
+    bx      lr
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_SQRT_DOUBLE_VFP
+dvmCompiler_TEMPLATE_SQRT_DOUBLE_VFP:
+/* File: armv5te-vfp/TEMPLATE_SQRT_DOUBLE_VFP.S */
+    /*
+     * 64-bit floating point vfp sqrt operation.
+     * If the result is a NaN, bail out to library code to do
+     * the right thing.
+     *
+     * On entry:
+     *     r2 src addr of op1
+     * On exit:
+     *     r0,r1 = res
+     */
+    fldd    d0, [r2]
+    fsqrtd  d1, d0
+    fcmpd   d1, d1
+    fmstat
+    fmrrd   r0, r1, d1
+    bxeq    lr   @ Result OK - return
+    ldr     r2, .Lsqrt
+    fmrrd   r0, r1, d0   @ reload orig operand
+    bx      r2   @ tail call to sqrt library routine
+
+.Lsqrt:
+    .word   sqrt
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_THROW_EXCEPTION_COMMON
+dvmCompiler_TEMPLATE_THROW_EXCEPTION_COMMON:
+/* File: armv5te/TEMPLATE_THROW_EXCEPTION_COMMON.S */
+    /*
+     * Throw an exception from JIT'ed code.
+     * On entry:
+     *    r0    Dalvik PC that raises the exception
+     */
+    b       .LhandleException
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_MEM_OP_DECODE
+dvmCompiler_TEMPLATE_MEM_OP_DECODE:
+/* File: armv5te-vfp/TEMPLATE_MEM_OP_DECODE.S */
+#if defined(WITH_SELF_VERIFICATION)
+    /*
+     * This handler encapsulates heap memory ops for selfVerification mode.
+     *
+     * The call to the handler is inserted prior to a heap memory operation.
+     * This handler then calls a function to decode the memory op, and process
+     * it accordingly. Afterwards, the handler changes the return address to
+     * skip the memory op so it never gets executed.
+     */
+    vpush   {d0-d15}                    @ save out all fp registers
+    push    {r0-r12,lr}                 @ save out all registers
+    ldr     r2, .LdvmSelfVerificationMemOpDecode @ defined in footer.S
+    mov     r0, lr                      @ arg0 <- link register
+    mov     r1, sp                      @ arg1 <- stack pointer
+    blx     r2                          @ decode and handle the mem op
+    pop     {r0-r12,lr}                 @ restore all registers
+    vpop    {d0-d15}                    @ restore all fp registers
+    bx      lr                          @ return to compiled code
+#endif
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_STRING_COMPARETO
+dvmCompiler_TEMPLATE_STRING_COMPARETO:
+/* File: armv5te/TEMPLATE_STRING_COMPARETO.S */
+    /*
+     * String's compareTo.
+     *
+     * Requires r0/r1 to have been previously checked for null.  Will
+     * return negative if this's string is < comp, 0 if they are the
+     * same and positive if >.
+     *
+     * IMPORTANT NOTE:
+     *
+     * This code relies on hard-coded offsets for string objects, and must be
+     * kept in sync with definitions in UtfString.h.  See asm-constants.h
+     *
+     * On entry:
+     *    r0:   this object pointer
+     *    r1:   comp object pointer
+     *
+     */
+
+    mov    r2, r0         @ this to r2, opening up r0 for return value
+    subs   r0, r2, r1     @ Same?
+    bxeq   lr
+
+    ldr    r4, [r2, #STRING_FIELDOFF_OFFSET]
+    ldr    r9, [r1, #STRING_FIELDOFF_OFFSET]
+    ldr    r7, [r2, #STRING_FIELDOFF_COUNT]
+    ldr    r10, [r1, #STRING_FIELDOFF_COUNT]
+    ldr    r2, [r2, #STRING_FIELDOFF_VALUE]
+    ldr    r1, [r1, #STRING_FIELDOFF_VALUE]
+
+    /*
+     * At this point, we have:
+     *    value:  r2/r1
+     *    offset: r4/r9
+     *    count:  r7/r10
+     * We're going to compute
+     *    r11 <- countDiff
+     *    r10 <- minCount
+     */
+     subs  r11, r7, r10
+     movls r10, r7
+
+     /* Now, build pointers to the string data */
+     add   r2, r2, r4, lsl #1
+     add   r1, r1, r9, lsl #1
+     /*
+      * Note: data pointers point to previous element so we can use pre-index
+      * mode with base writeback.
+      */
+     add   r2, #16-2   @ offset to contents[-1]
+     add   r1, #16-2   @ offset to contents[-1]
+
+     /*
+      * At this point we have:
+      *   r2: *this string data
+      *   r1: *comp string data
+      *   r10: iteration count for comparison
+      *   r11: value to return if the first part of the string is equal
+      *   r0: reserved for result
+      *   r3, r4, r7, r8, r9, r12 available for loading string data
+      */
+
+    subs  r10, #2
+    blt   do_remainder2
+
+      /*
+       * Unroll the first two checks so we can quickly catch early mismatch
+       * on long strings (but preserve incoming alignment)
+       */
+
+    ldrh  r3, [r2, #2]!
+    ldrh  r4, [r1, #2]!
+    ldrh  r7, [r2, #2]!
+    ldrh  r8, [r1, #2]!
+    subs  r0, r3, r4
+    subeqs  r0, r7, r8
+    bxne  lr
+    cmp   r10, #28
+    bgt   do_memcmp16
+    subs  r10, #3
+    blt   do_remainder
+
+loopback_triple:
+    ldrh  r3, [r2, #2]!
+    ldrh  r4, [r1, #2]!
+    ldrh  r7, [r2, #2]!
+    ldrh  r8, [r1, #2]!
+    ldrh  r9, [r2, #2]!
+    ldrh  r12,[r1, #2]!
+    subs  r0, r3, r4
+    subeqs  r0, r7, r8
+    subeqs  r0, r9, r12
+    bxne  lr
+    subs  r10, #3
+    bge   loopback_triple
+
+do_remainder:
+    adds  r10, #3
+    beq   returnDiff
+
+loopback_single:
+    ldrh  r3, [r2, #2]!
+    ldrh  r4, [r1, #2]!
+    subs  r0, r3, r4
+    bxne  lr
+    subs  r10, #1
+    bne     loopback_single
+
+returnDiff:
+    mov   r0, r11
+    bx    lr
+
+do_remainder2:
+    adds  r10, #2
+    bne   loopback_single
+    mov   r0, r11
+    bx    lr
+
+    /* Long string case */
+do_memcmp16:
+    mov   r4, lr
+    ldr   lr, .Lmemcmp16
+    mov   r7, r11
+    add   r0, r2, #2
+    add   r1, r1, #2
+    mov   r2, r10
+    blx   lr
+    cmp   r0, #0
+    bxne  r4
+    mov   r0, r7
+    bx    r4
+
+.Lmemcmp16:
+    .word __memcmp16
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_STRING_INDEXOF
+dvmCompiler_TEMPLATE_STRING_INDEXOF:
+/* File: armv5te/TEMPLATE_STRING_INDEXOF.S */
+    /*
+     * String's indexOf.
+     *
+     * Requires r0 to have been previously checked for null.  Will
+     * return index of match of r1 in r0.
+     *
+     * IMPORTANT NOTE:
+     *
+     * This code relies on hard-coded offsets for string objects, and must be
+     * kept in sync wth definitions in UtfString.h  See asm-constants.h
+     *
+     * On entry:
+     *    r0:   string object pointer
+     *    r1:   char to match
+     *    r2:   Starting offset in string data
+     */
+
+    ldr    r7, [r0, #STRING_FIELDOFF_OFFSET]
+    ldr    r8, [r0, #STRING_FIELDOFF_COUNT]
+    ldr    r0, [r0, #STRING_FIELDOFF_VALUE]
+
+    /*
+     * At this point, we have:
+     *    r0: object pointer
+     *    r1: char to match
+     *    r2: starting offset
+     *    r7: offset
+     *    r8: string length
+     */
+
+     /* Build pointer to start of string data */
+     add   r0, #16
+     add   r0, r0, r7, lsl #1
+
+     /* Save a copy of starting data in r7 */
+     mov   r7, r0
+
+     /* Clamp start to [0..count] */
+     cmp   r2, #0
+     movlt r2, #0
+     cmp   r2, r8
+     movgt r2, r8
+
+     /* Build pointer to start of data to compare and pre-bias */
+     add   r0, r0, r2, lsl #1
+     sub   r0, #2
+
+     /* Compute iteration count */
+     sub   r8, r2
+
+     /*
+      * At this point we have:
+      *   r0: start of data to test
+      *   r1: chat to compare
+      *   r8: iteration count
+      *   r7: original start of string
+      *   r3, r4, r9, r10, r11, r12 available for loading string data
+      */
+
+    subs  r8, #4
+    blt   indexof_remainder
+
+indexof_loop4:
+    ldrh  r3, [r0, #2]!
+    ldrh  r4, [r0, #2]!
+    ldrh  r10, [r0, #2]!
+    ldrh  r11, [r0, #2]!
+    cmp   r3, r1
+    beq   match_0
+    cmp   r4, r1
+    beq   match_1
+    cmp   r10, r1
+    beq   match_2
+    cmp   r11, r1
+    beq   match_3
+    subs  r8, #4
+    bge   indexof_loop4
+
+indexof_remainder:
+    adds    r8, #4
+    beq     indexof_nomatch
+
+indexof_loop1:
+    ldrh  r3, [r0, #2]!
+    cmp   r3, r1
+    beq   match_3
+    subs  r8, #1
+    bne   indexof_loop1
+
+indexof_nomatch:
+    mov   r0, #-1
+    bx    lr
+
+match_0:
+    sub   r0, #6
+    sub   r0, r7
+    asr   r0, r0, #1
+    bx    lr
+match_1:
+    sub   r0, #4
+    sub   r0, r7
+    asr   r0, r0, #1
+    bx    lr
+match_2:
+    sub   r0, #2
+    sub   r0, r7
+    asr   r0, r0, #1
+    bx    lr
+match_3:
+    sub   r0, r7
+    asr   r0, r0, #1
+    bx    lr
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_INTERPRET
+dvmCompiler_TEMPLATE_INTERPRET:
+/* File: armv5te/TEMPLATE_INTERPRET.S */
+    /*
+     * This handler transfers control to the interpeter without performing
+     * any lookups.  It may be called either as part of a normal chaining
+     * operation, or from the transition code in header.S.  We distinquish
+     * the two cases by looking at the link register.  If called from a
+     * translation chain, it will point to the chaining Dalvik PC -3.
+     * On entry:
+     *    lr - if NULL:
+     *        r1 - the Dalvik PC to begin interpretation.
+     *    else
+     *        [lr, #3] contains Dalvik PC to begin interpretation
+     *    rSELF - pointer to thread
+     *    rFP - Dalvik frame pointer
+     */
+    cmp     lr, #0
+#if defined(WORKAROUND_CORTEX_A9_745320)
+    /* Don't use conditional loads if the HW defect exists */
+    beq     101f
+    ldr     r1,[lr, #3]
+101:
+#else
+    ldrne   r1,[lr, #3]
+#endif
+    ldr     r2, .LinterpPunt
+    mov     r0, r1                       @ set Dalvik PC
+    bx      r2
+    @ doesn't return
+
+.LinterpPunt:
+    .word   dvmJitToInterpPunt
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_MONITOR_ENTER
+dvmCompiler_TEMPLATE_MONITOR_ENTER:
+/* File: armv5te/TEMPLATE_MONITOR_ENTER.S */
+    /*
+     * Call out to the runtime to lock an object.  Because this thread
+     * may have been suspended in THREAD_MONITOR state and the Jit's
+     * translation cache subsequently cleared, we cannot return directly.
+     * Instead, unconditionally transition to the interpreter to resume.
+     *
+     * On entry:
+     *    r0 - self pointer
+     *    r1 - the object (which has already been null-checked by the caller
+     *    r4 - the Dalvik PC of the following instruction.
+     */
+    ldr     r2, .LdvmLockObject
+    mov     r3, #0                       @ Record that we're not returning
+    str     r3, [r0, #offThread_inJitCodeCache]
+    blx     r2                           @ dvmLockObject(self, obj)
+    ldr     r2, .LdvmJitToInterpNoChain
+    @ Bail to interpreter - no chain [note - r4 still contains rPC]
+#if defined(WITH_JIT_TUNING)
+    mov     r0, #kHeavyweightMonitor
+#endif
+    bx      r2
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_MONITOR_ENTER_DEBUG
+dvmCompiler_TEMPLATE_MONITOR_ENTER_DEBUG:
+/* File: armv5te/TEMPLATE_MONITOR_ENTER_DEBUG.S */
+    /*
+     * To support deadlock prediction, this version of MONITOR_ENTER
+     * will always call the heavyweight dvmLockObject, check for an
+     * exception and then bail out to the interpreter.
+     *
+     * On entry:
+     *    r0 - self pointer
+     *    r1 - the object (which has already been null-checked by the caller
+     *    r4 - the Dalvik PC of the following instruction.
+     *
+     */
+    ldr     r2, .LdvmLockObject
+    mov     r3, #0                       @ Record that we're not returning
+    str     r3, [r0, #offThread_inJitCodeCache]
+    blx     r2             @ dvmLockObject(self, obj)
+    @ test for exception
+    ldr     r1, [rSELF, #offThread_exception]
+    cmp     r1, #0
+    beq     1f
+    ldr     r2, .LhandleException
+    sub     r0, r4, #2     @ roll dPC back to this monitor instruction
+    bx      r2
+1:
+    @ Bail to interpreter - no chain [note - r4 still contains rPC]
+#if defined(WITH_JIT_TUNING)
+    mov     r0, #kHeavyweightMonitor
+#endif
+    ldr     pc, .LdvmJitToInterpNoChain
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_PERIODIC_PROFILING
+dvmCompiler_TEMPLATE_PERIODIC_PROFILING:
+/* File: armv5te/TEMPLATE_PERIODIC_PROFILING.S */
+    /*
+     * Increment profile counter for this trace, and decrement
+     * sample counter.  If sample counter goes below zero, turn
+     * off profiling.
+     *
+     * On entry
+     * (lr-11) is address of pointer to counter.  Note: the counter
+     *    actually exists 10 bytes before the return target, but because
+     *    we are arriving from thumb mode, lr will have its low bit set.
+     */
+     ldr    r0, [lr,#-11]
+     ldr    r1, [rSELF, #offThread_pProfileCountdown]
+     ldr    r2, [r0]                    @ get counter
+     ldr    r3, [r1]                    @ get countdown timer
+     add    r2, #1
+     subs   r2, #1
+     blt    .LTEMPLATE_PERIODIC_PROFILING_disable_profiling
+     str    r2, [r0]
+     str    r3, [r1]
+     bx     lr
+
+.LTEMPLATE_PERIODIC_PROFILING_disable_profiling:
+     mov    r4, lr                     @ preserve lr
+     ldr    r0, .LdvmJitTraceProfilingOff
+     blx    r0
+     bx     r4
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_RETURN_PROF
+dvmCompiler_TEMPLATE_RETURN_PROF:
+/* File: armv5te/TEMPLATE_RETURN_PROF.S */
+#define TEMPLATE_INLINE_PROFILING
+/* File: armv5te/TEMPLATE_RETURN.S */
+    /*
+     * Unwind a frame from the Dalvik stack for compiled OP_RETURN_XXX.
+     * If the stored value in returnAddr
+     * is non-zero, the caller is compiled by the JIT thus return to the
+     * address in the code cache following the invoke instruction. Otherwise
+     * return to the special dvmJitToInterpNoChain entry point.
+     */
+#if defined(TEMPLATE_INLINE_PROFILING)
+    stmfd   sp!, {r0-r2,lr}             @ preserve live registers
+    mov     r0, r6
+    @ r0=rSELF
+    mov     lr, pc
+    ldr     pc, .LdvmFastMethodTraceExit
+    ldmfd   sp!, {r0-r2,lr}             @ restore live registers
+#endif
+    SAVEAREA_FROM_FP(r0, rFP)           @ r0<- saveArea (old)
+    ldr     r10, [r0, #offStackSaveArea_prevFrame] @ r10<- saveArea->prevFrame
+    ldrb    r8, [rSELF, #offThread_breakFlags] @ r8<- breakFlags
+    ldr     rPC, [r0, #offStackSaveArea_savedPc] @ rPC<- saveArea->savedPc
+#if !defined(WITH_SELF_VERIFICATION)
+    ldr     r9,  [r0, #offStackSaveArea_returnAddr] @ r9<- chaining cell ret
+#else
+    mov     r9, #0                      @ disable chaining
+#endif
+    ldr     r2, [r10, #(offStackSaveArea_method - sizeofStackSaveArea)]
+                                        @ r2<- method we're returning to
+    cmp     r2, #0                      @ break frame?
+#if !defined(WITH_SELF_VERIFICATION)
+    beq     1f                          @ bail to interpreter
+#else
+    blxeq   lr                          @ punt to interpreter and compare state
+#endif
+    ldr     r1, .LdvmJitToInterpNoChainNoProfile @ defined in footer.S
+    mov     rFP, r10                    @ publish new FP
+    ldr     r10, [r2, #offMethod_clazz] @ r10<- method->clazz
+
+    str     r2, [rSELF, #offThread_method]@ self->method = newSave->method
+    ldr     r0, [r10, #offClassObject_pDvmDex] @ r0<- method->clazz->pDvmDex
+    str     rFP, [rSELF, #offThread_curFrame] @ curFrame = fp
+    add     rPC, rPC, #6                @ publish new rPC (advance 6 bytes)
+    str     r0, [rSELF, #offThread_methodClassDex]
+    cmp     r8, #0                      @ check the break flags
+    movne   r9, #0                      @ clear the chaining cell address
+    str     r9, [rSELF, #offThread_inJitCodeCache] @ in code cache or not
+    cmp     r9, #0                      @ chaining cell exists?
+    blxne   r9                          @ jump to the chaining cell
+#if defined(WITH_JIT_TUNING)
+    mov     r0, #kCallsiteInterpreted
+#endif
+    mov     pc, r1                      @ callsite is interpreted
+1:
+    mov     r0, #0
+    str     r0, [rSELF, #offThread_inJitCodeCache] @ reset inJitCodeCache
+    stmia   rSELF, {rPC, rFP}           @ SAVE_PC_FP_TO_SELF()
+    ldr     r2, .LdvmMterpStdBail       @ defined in footer.S
+    mov     r0, rSELF                   @ Expecting rSELF in r0
+    blx     r2                          @ exit the interpreter
+
+#undef TEMPLATE_INLINE_PROFILING
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_INVOKE_METHOD_NO_OPT_PROF
+dvmCompiler_TEMPLATE_INVOKE_METHOD_NO_OPT_PROF:
+/* File: armv5te/TEMPLATE_INVOKE_METHOD_NO_OPT_PROF.S */
+#define TEMPLATE_INLINE_PROFILING
+/* File: armv5te/TEMPLATE_INVOKE_METHOD_NO_OPT.S */
+    /*
+     * For polymorphic callsites - setup the Dalvik frame and load Dalvik PC
+     * into rPC then jump to dvmJitToInterpNoChain to dispatch the
+     * runtime-resolved callee.
+     */
+    @ r0 = methodToCall, r1 = returnCell, rPC = dalvikCallsite
+    ldrh    r7, [r0, #offMethod_registersSize]  @ r7<- methodToCall->regsSize
+    ldrh    r2, [r0, #offMethod_outsSize]  @ r2<- methodToCall->outsSize
+    ldr     r9, [rSELF, #offThread_interpStackEnd]    @ r9<- interpStackEnd
+    ldrb    r8, [rSELF, #offThread_breakFlags] @ r8<- breakFlags
+    add     r3, r1, #1  @ Thumb addr is odd
+    SAVEAREA_FROM_FP(r1, rFP)           @ r1<- stack save area
+    sub     r1, r1, r7, lsl #2          @ r1<- newFp (old savearea - regsSize)
+    SAVEAREA_FROM_FP(r10, r1)           @ r10<- stack save area
+    sub     r10, r10, r2, lsl #2        @ r10<- bottom (newsave - outsSize)
+    cmp     r10, r9                     @ bottom < interpStackEnd?
+    bxlo    lr                          @ return to raise stack overflow excep.
+    @ r1 = newFP, r0 = methodToCall, r3 = returnCell, rPC = dalvikCallsite
+    ldr     r9, [r0, #offMethod_clazz]      @ r9<- method->clazz
+    ldr     r10, [r0, #offMethod_accessFlags] @ r10<- methodToCall->accessFlags
+    str     rPC, [rFP, #(offStackSaveArea_currentPc - sizeofStackSaveArea)]
+    str     rPC, [r1, #(offStackSaveArea_savedPc - sizeofStackSaveArea)]
+    ldr     rPC, [r0, #offMethod_insns]     @ rPC<- methodToCall->insns
+
+
+    @ set up newSaveArea
+    str     rFP, [r1, #(offStackSaveArea_prevFrame - sizeofStackSaveArea)]
+    str     r3, [r1, #(offStackSaveArea_returnAddr - sizeofStackSaveArea)]
+    str     r0, [r1, #(offStackSaveArea_method - sizeofStackSaveArea)]
+    cmp     r8, #0                      @ breakFlags != 0
+    bxne    lr                          @ bail to the interpreter
+    tst     r10, #ACC_NATIVE
+#if !defined(WITH_SELF_VERIFICATION)
+    bne     .LinvokeNative
+#else
+    bxne    lr                          @ bail to the interpreter
+#endif
+
+    ldr     r10, .LdvmJitToInterpTraceSelectNoChain
+    ldr     r3, [r9, #offClassObject_pDvmDex] @ r3<- method->clazz->pDvmDex
+
+    @ Update "thread" values for the new method
+    str     r0, [rSELF, #offThread_method]    @ self->method = methodToCall
+    str     r3, [rSELF, #offThread_methodClassDex] @ self->methodClassDex = ...
+    mov     rFP, r1                         @ fp = newFp
+    str     rFP, [rSELF, #offThread_curFrame]  @ curFrame = newFp
+#if defined(TEMPLATE_INLINE_PROFILING)
+    stmfd   sp!, {r0-r3}                    @ preserve r0-r3
+    mov     r1, r6
+    @ r0=methodToCall, r1=rSELF
+    mov     lr, pc
+    ldr     pc, .LdvmFastMethodTraceEnter
+    ldmfd   sp!, {r0-r3}                    @ restore r0-r3
+#endif
+
+    @ Start executing the callee
+#if defined(WITH_JIT_TUNING)
+    mov     r0, #kInlineCacheMiss
+#endif
+    mov     pc, r10                         @ dvmJitToInterpTraceSelectNoChain
+
+#undef TEMPLATE_INLINE_PROFILING
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_INVOKE_METHOD_CHAIN_PROF
+dvmCompiler_TEMPLATE_INVOKE_METHOD_CHAIN_PROF:
+/* File: armv5te/TEMPLATE_INVOKE_METHOD_CHAIN_PROF.S */
+#define TEMPLATE_INLINE_PROFILING
+/* File: armv5te/TEMPLATE_INVOKE_METHOD_CHAIN.S */
+    /*
+     * For monomorphic callsite, setup the Dalvik frame and return to the
+     * Thumb code through the link register to transfer control to the callee
+     * method through a dedicated chaining cell.
+     */
+    @ r0 = methodToCall, r1 = returnCell, r2 = methodToCall->outsSize
+    @ rPC = dalvikCallsite, r7 = methodToCall->registersSize
+    @ methodToCall is guaranteed to be non-native
+.LinvokeChainProf:
+    ldr     r9, [rSELF, #offThread_interpStackEnd]    @ r9<- interpStackEnd
+    ldrb    r8, [rSELF, #offThread_breakFlags]        @ r8<- breakFlags
+    add     r3, r1, #1  @ Thumb addr is odd
+    SAVEAREA_FROM_FP(r1, rFP)           @ r1<- stack save area
+    sub     r1, r1, r7, lsl #2          @ r1<- newFp (old savearea - regsSize)
+    SAVEAREA_FROM_FP(r10, r1)           @ r10<- stack save area
+    add     r12, lr, #2                 @ setup the punt-to-interp address
+    sub     r10, r10, r2, lsl #2        @ r10<- bottom (newsave - outsSize)
+    cmp     r10, r9                     @ bottom < interpStackEnd?
+    bxlo    r12                         @ return to raise stack overflow excep.
+    @ r1 = newFP, r0 = methodToCall, r3 = returnCell, rPC = dalvikCallsite
+    ldr     r9, [r0, #offMethod_clazz]      @ r9<- method->clazz
+    str     rPC, [rFP, #(offStackSaveArea_currentPc - sizeofStackSaveArea)]
+    str     rPC, [r1, #(offStackSaveArea_savedPc - sizeofStackSaveArea)]
+
+    @ set up newSaveArea
+    str     rFP, [r1, #(offStackSaveArea_prevFrame - sizeofStackSaveArea)]
+    str     r3, [r1, #(offStackSaveArea_returnAddr - sizeofStackSaveArea)]
+    str     r0, [r1, #(offStackSaveArea_method - sizeofStackSaveArea)]
+    cmp     r8, #0                      @ breakFlags != 0
+    bxne    r12                         @ bail to the interpreter
+
+    ldr     r3, [r9, #offClassObject_pDvmDex] @ r3<- method->clazz->pDvmDex
+
+    @ Update "thread" values for the new method
+    str     r0, [rSELF, #offThread_method]    @ self->method = methodToCall
+    str     r3, [rSELF, #offThread_methodClassDex] @ self->methodClassDex = ...
+    mov     rFP, r1                         @ fp = newFp
+    str     rFP, [rSELF, #offThread_curFrame]  @ curFrame = newFp
+#if defined(TEMPLATE_INLINE_PROFILING)
+    stmfd   sp!, {r0-r2,lr}             @ preserve clobbered live registers
+    mov     r1, r6
+    @ r0=methodToCall, r1=rSELF
+    mov     lr, pc
+    ldr     pc, .LdvmFastMethodTraceEnter
+    ldmfd   sp!, {r0-r2,lr}             @ restore registers
+#endif
+
+    bx      lr                              @ return to the callee-chaining cell
+
+#undef TEMPLATE_INLINE_PROFILING
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_INVOKE_METHOD_PREDICTED_CHAIN_PROF
+dvmCompiler_TEMPLATE_INVOKE_METHOD_PREDICTED_CHAIN_PROF:
+/* File: armv5te/TEMPLATE_INVOKE_METHOD_PREDICTED_CHAIN_PROF.S */
+#define TEMPLATE_INLINE_PROFILING
+/* File: armv5te/TEMPLATE_INVOKE_METHOD_PREDICTED_CHAIN.S */
+    /*
+     * For polymorphic callsite, check whether the cached class pointer matches
+     * the current one. If so setup the Dalvik frame and return to the
+     * Thumb code through the link register to transfer control to the callee
+     * method through a dedicated chaining cell.
+     *
+     * The predicted chaining cell is declared in ArmLIR.h with the
+     * following layout:
+     *
+     *  typedef struct PredictedChainingCell {
+     *      u4 branch;
+     *      const ClassObject *clazz;
+     *      const Method *method;
+     *      u4 counter;
+     *  } PredictedChainingCell;
+     *
+     * Upon returning to the callsite:
+     *    - lr  : to branch to the chaining cell
+     *    - lr+2: to punt to the interpreter
+     *    - lr+4: to fully resolve the callee and may rechain.
+     *            r3 <- class
+     *            r9 <- counter
+     */
+    @ r0 = this, r1 = returnCell, r2 = predictedChainCell, rPC = dalvikCallsite
+    ldr     r3, [r0, #offObject_clazz]  @ r3 <- this->class
+    ldr     r8, [r2, #4]    @ r8 <- predictedChainCell->clazz
+    ldr     r0, [r2, #8]    @ r0 <- predictedChainCell->method
+    ldr     r9, [rSELF, #offThread_icRechainCount] @ r1 <- shared rechainCount
+    cmp     r3, r8          @ predicted class == actual class?
+#if defined(WITH_JIT_TUNING)
+    ldr     r7, .LdvmICHitCount
+#if defined(WORKAROUND_CORTEX_A9_745320)
+    /* Don't use conditional loads if the HW defect exists */
+    bne     101f
+    ldr     r10, [r7, #0]
+101:
+#else
+    ldreq   r10, [r7, #0]
+#endif
+    add     r10, r10, #1
+    streq   r10, [r7, #0]
+#endif
+    ldreqh  r7, [r0, #offMethod_registersSize]  @ r7<- methodToCall->regsSize
+    ldreqh  r2, [r0, #offMethod_outsSize]  @ r2<- methodToCall->outsSize
+    beq     .LinvokeChainProf   @ predicted chain is valid
+    ldr     r7, [r3, #offClassObject_vtable] @ r7 <- this->class->vtable
+    cmp     r8, #0          @ initialized class or not
+    moveq   r1, #0
+    subne   r1, r9, #1      @ count--
+    strne   r1, [rSELF, #offThread_icRechainCount]  @ write back to thread
+    add     lr, lr, #4      @ return to fully-resolve landing pad
+    /*
+     * r1 <- count
+     * r2 <- &predictedChainCell
+     * r3 <- this->class
+     * r4 <- dPC
+     * r7 <- this->class->vtable
+     */
+    bx      lr
+
+#undef TEMPLATE_INLINE_PROFILING
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_INVOKE_METHOD_NATIVE_PROF
+dvmCompiler_TEMPLATE_INVOKE_METHOD_NATIVE_PROF:
+/* File: armv5te/TEMPLATE_INVOKE_METHOD_NATIVE_PROF.S */
+#define TEMPLATE_INLINE_PROFILING
+/* File: armv5te/TEMPLATE_INVOKE_METHOD_NATIVE.S */
+    @ r0 = methodToCall, r1 = returnCell, rPC = dalvikCallsite
+    @ r7 = methodToCall->registersSize
+    ldr     r9, [rSELF, #offThread_interpStackEnd]    @ r9<- interpStackEnd
+    ldrb    r8, [rSELF, #offThread_breakFlags]        @ r8<- breakFlags
+    add     r3, r1, #1  @ Thumb addr is odd
+    SAVEAREA_FROM_FP(r1, rFP)           @ r1<- stack save area
+    sub     r1, r1, r7, lsl #2          @ r1<- newFp (old savearea - regsSize)
+    SAVEAREA_FROM_FP(r10, r1)           @ r10<- stack save area
+    cmp     r10, r9                     @ bottom < interpStackEnd?
+    bxlo    lr                          @ return to raise stack overflow excep.
+    @ r1 = newFP, r0 = methodToCall, r3 = returnCell, rPC = dalvikCallsite
+    str     rPC, [rFP, #(offStackSaveArea_currentPc - sizeofStackSaveArea)]
+    str     rPC, [r1, #(offStackSaveArea_savedPc - sizeofStackSaveArea)]
+
+    @ set up newSaveArea
+    str     rFP, [r1, #(offStackSaveArea_prevFrame - sizeofStackSaveArea)]
+    str     r3, [r1, #(offStackSaveArea_returnAddr - sizeofStackSaveArea)]
+    str     r0, [r1, #(offStackSaveArea_method - sizeofStackSaveArea)]
+    cmp     r8, #0                      @ breakFlags != 0
+    ldr     r8, [r0, #offMethod_nativeFunc] @ r8<- method->nativeFunc
+#if !defined(WITH_SELF_VERIFICATION)
+    bxne    lr                          @ bail to the interpreter
+#else
+    bx      lr                          @ bail to interpreter unconditionally
+#endif
+
+    @ go ahead and transfer control to the native code
+    ldr     r9, [rSELF, #offThread_jniLocal_topCookie]@r9<-thread->localRef->...
+    mov     r2, #0
+    str     r1, [rSELF, #offThread_curFrame]   @ curFrame = newFp
+    str     r2, [rSELF, #offThread_inJitCodeCache] @ not in the jit code cache
+    str     r9, [r1, #(offStackSaveArea_localRefCookie - sizeofStackSaveArea)]
+                                        @ newFp->localRefCookie=top
+    SAVEAREA_FROM_FP(r10, r1)           @ r10<- new stack save area
+
+    mov     r2, r0                        @ arg2<- methodToCall
+    mov     r0, r1                        @ arg0<- newFP
+    add     r1, rSELF, #offThread_retval  @ arg1<- &retval
+    mov     r3, rSELF                     @ arg3<- self
+#if defined(TEMPLATE_INLINE_PROFILING)
+    @ r2=methodToCall, r6=rSELF
+    stmfd   sp!, {r2,r6}                @ to be consumed after JNI return
+    stmfd   sp!, {r0-r3}                @ preserve r0-r3
+    mov     r0, r2
+    mov     r1, r6
+    @ r0=JNIMethod, r1=rSELF
+    mov     lr, pc
+    ldr     pc, .LdvmFastMethodTraceEnter
+    ldmfd   sp!, {r0-r3}                @ restore r0-r3
+#endif
+
+    blx     r8                          @ off to the native code
+
+#if defined(TEMPLATE_INLINE_PROFILING)
+    ldmfd   sp!, {r0-r1}                @ restore r2 and r6
+    @ r0=JNIMethod, r1=rSELF
+    mov     lr, pc
+    ldr     pc, .LdvmFastNativeMethodTraceExit
+#endif
+    @ native return; r10=newSaveArea
+    @ equivalent to dvmPopJniLocals
+    ldr     r2, [r10, #offStackSaveArea_returnAddr] @ r2 = chaining cell ret
+    ldr     r0, [r10, #offStackSaveArea_localRefCookie] @ r0<- saved->top
+    ldr     r1, [rSELF, #offThread_exception] @ check for exception
+    str     rFP, [rSELF, #offThread_curFrame]  @ curFrame = fp
+    cmp     r1, #0                      @ null?
+    str     r0, [rSELF, #offThread_jniLocal_topCookie] @ new top <- old top
+    ldr     r0, [rFP, #(offStackSaveArea_currentPc - sizeofStackSaveArea)]
+
+    @ r0 = dalvikCallsitePC
+    bne     .LhandleException           @ no, handle exception
+
+    str     r2, [rSELF, #offThread_inJitCodeCache] @ set the mode properly
+    cmp     r2, #0                      @ return chaining cell still exists?
+    bxne    r2                          @ yes - go ahead
+
+    @ continue executing the next instruction through the interpreter
+    ldr     r1, .LdvmJitToInterpTraceSelectNoChain @ defined in footer.S
+    add     rPC, r0, #6                 @ reconstruct new rPC (advance 6 bytes)
+#if defined(WITH_JIT_TUNING)
+    mov     r0, #kCallsiteInterpreted
+#endif
+    mov     pc, r1
+
+#undef TEMPLATE_INLINE_PROFILING
+
+    .size   dvmCompilerTemplateStart, .-dvmCompilerTemplateStart
+/* File: armv5te/footer.S */
+/*
+ * ===========================================================================
+ *  Common subroutines and data
+ * ===========================================================================
+ */
+
+    .text
+    .align  2
+.LinvokeNative:
+    @ Prep for the native call
+    @ r1 = newFP, r0 = methodToCall
+    mov     r2, #0
+    ldr     r9, [rSELF, #offThread_jniLocal_topCookie]@r9<-thread->localRef->...
+    str     r2, [rSELF, #offThread_inJitCodeCache] @ not in jit code cache
+    str     r1, [rSELF, #offThread_curFrame]   @ curFrame = newFp
+    str     r9, [r1, #(offStackSaveArea_localRefCookie - sizeofStackSaveArea)]
+                                        @ newFp->localRefCookie=top
+    ldrh    lr, [rSELF, #offThread_subMode]
+    SAVEAREA_FROM_FP(r10, r1)           @ r10<- new stack save area
+
+    mov     r2, r0                      @ r2<- methodToCall
+    mov     r0, r1                      @ r0<- newFP
+    add     r1, rSELF, #offThread_retval  @ r1<- &retval
+    mov     r3, rSELF                   @ arg3<- self
+    ands    lr, #kSubModeMethodTrace
+    beq     121f                        @ hop if not profiling
+    @ r2: methodToCall, r6: rSELF
+    stmfd   sp!, {r2,r6}
+    stmfd   sp!, {r0-r3}
+    mov     r0, r2
+    mov     r1, r6
+    mov     lr, pc
+    ldr     pc, .LdvmFastMethodTraceEnter
+    ldmfd   sp!, {r0-r3}
+
+    mov     lr, pc
+    ldr     pc, [r2, #offMethod_nativeFunc]
+
+    ldmfd   sp!, {r0-r1}
+    mov     lr, pc
+    ldr     pc, .LdvmFastNativeMethodTraceExit
+    b       212f
+121:
+    mov     lr, pc
+    ldr     pc, [r2, #offMethod_nativeFunc]
+212:
+
+    @ native return; r10=newSaveArea
+    @ equivalent to dvmPopJniLocals
+    ldr     r2, [r10, #offStackSaveArea_returnAddr] @ r2 = chaining cell ret
+    ldr     r0, [r10, #offStackSaveArea_localRefCookie] @ r0<- saved->top
+    ldr     r1, [rSELF, #offThread_exception] @ check for exception
+    str     rFP, [rSELF, #offThread_curFrame]  @ curFrame = fp
+    cmp     r1, #0                      @ null?
+    str     r0, [rSELF, #offThread_jniLocal_topCookie] @ new top <- old top
+    ldr     r0, [r10, #offStackSaveArea_savedPc] @ reload rPC
+
+    @ r0 = dalvikCallsitePC
+    bne     .LhandleException           @ no, handle exception
+
+    str     r2, [rSELF, #offThread_inJitCodeCache] @ set the new mode
+    cmp     r2, #0                      @ return chaining cell still exists?
+    bxne    r2                          @ yes - go ahead
+
+    @ continue executing the next instruction through the interpreter
+    ldr     r1, .LdvmJitToInterpTraceSelectNoChain @ defined in footer.S
+    add     rPC, r0, #6                 @ reconstruct new rPC (advance 6 bytes)
+#if defined(WITH_JIT_TUNING)
+    mov     r0, #kCallsiteInterpreted
+#endif
+    mov     pc, r1
+
+/*
+ * On entry:
+ * r0  Faulting Dalvik PC
+ */
+.LhandleException:
+#if defined(WITH_SELF_VERIFICATION)
+    ldr     pc, .LdeadFood @ should not see this under self-verification mode
+.LdeadFood:
+    .word   0xdeadf00d
+#endif
+    mov     r2, #0
+    str     r2, [rSELF, #offThread_inJitCodeCache] @ in interpreter land
+    ldr     r1, .LdvmMterpCommonExceptionThrown @ PIC way of getting &func
+    ldr     rIBASE, .LdvmAsmInstructionStart    @ same as above
+    mov     rPC, r0                 @ reload the faulting Dalvik address
+    mov     pc, r1                  @ branch to dvmMterpCommonExceptionThrown
+
+    .align  2
+.LdvmAsmInstructionStart:
+    .word   dvmAsmInstructionStart
+.LdvmJitToInterpNoChainNoProfile:
+    .word   dvmJitToInterpNoChainNoProfile
+.LdvmJitToInterpTraceSelectNoChain:
+    .word   dvmJitToInterpTraceSelectNoChain
+.LdvmJitToInterpNoChain:
+    .word   dvmJitToInterpNoChain
+.LdvmMterpStdBail:
+    .word   dvmMterpStdBail
+.LdvmMterpCommonExceptionThrown:
+    .word   dvmMterpCommonExceptionThrown
+.LdvmLockObject:
+    .word   dvmLockObject
+.LdvmJitTraceProfilingOff:
+    .word   dvmJitTraceProfilingOff
+#if defined(WITH_JIT_TUNING)
+.LdvmICHitCount:
+    .word   gDvmICHitCount
+#endif
+#if defined(WITH_SELF_VERIFICATION)
+.LdvmSelfVerificationMemOpDecode:
+    .word   dvmSelfVerificationMemOpDecode
+#endif
+.LdvmFastMethodTraceEnter:
+    .word   dvmFastMethodTraceEnter
+.LdvmFastNativeMethodTraceExit:
+    .word   dvmFastNativeMethodTraceExit
+.LdvmFastMethodTraceExit:
+    .word   dvmFastMethodTraceExit
+.L__aeabi_cdcmple:
+    .word   __aeabi_cdcmple
+.L__aeabi_cfcmple:
+    .word   __aeabi_cfcmple
+
+    .global dmvCompilerTemplateEnd
+dmvCompilerTemplateEnd:
+
+#endif /* WITH_JIT */
+
diff --git a/vm/compiler/template_notaint/out/CompilerTemplateAsm-armv5te.S b/vm/compiler/template_notaint/out/CompilerTemplateAsm-armv5te.S
new file mode 100644
index 0000000..044843e
--- /dev/null
+++ b/vm/compiler/template_notaint/out/CompilerTemplateAsm-armv5te.S
@@ -0,0 +1,1712 @@
+/*
+ * This file was generated automatically by gen-template.py for 'armv5te'.
+ *
+ * --> DO NOT EDIT <--
+ */
+
+/* File: armv5te/header.S */
+/*
+ * Copyright (C) 2008 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#if defined(WITH_JIT)
+
+/*
+ * ARMv5 definitions and declarations.
+ */
+
+/*
+ARM EABI general notes:
+
+r0-r3 hold first 4 args to a method; they are not preserved across method calls
+r4-r8 are available for general use
+r9 is given special treatment in some situations, but not for us
+r10 (sl) seems to be generally available
+r11 (fp) is used by gcc (unless -fomit-frame-pointer is set)
+r12 (ip) is scratch -- not preserved across method calls
+r13 (sp) should be managed carefully in case a signal arrives
+r14 (lr) must be preserved
+r15 (pc) can be tinkered with directly
+
+r0 holds returns of <= 4 bytes
+r0-r1 hold returns of 8 bytes, low word in r0
+
+Callee must save/restore r4+ (except r12) if it modifies them.
+
+Stack is "full descending".  Only the arguments that don't fit in the first 4
+registers are placed on the stack.  "sp" points at the first stacked argument
+(i.e. the 5th arg).
+
+VFP: single-precision results in s0, double-precision results in d0.
+
+In the EABI, "sp" must be 64-bit aligned on entry to a function, and any
+64-bit quantities (long long, double) must be 64-bit aligned.
+*/
+
+/*
+JIT and ARM notes:
+
+The following registers have fixed assignments:
+
+  reg nick      purpose
+  r5  rFP       interpreted frame pointer, used for accessing locals and args
+  r6  rSELF     thread pointer
+
+The following registers have fixed assignments in mterp but are scratch
+registers in compiled code
+
+  reg nick      purpose
+  r4  rPC       interpreted program counter, used for fetching instructions
+  r7  rINST     first 16-bit code unit of current instruction
+  r8  rIBASE    interpreted instruction base pointer, used for computed goto
+
+Macros are provided for common operations.  Each macro MUST emit only
+one instruction to make instruction-counting easier.  They MUST NOT alter
+unspecified registers or condition codes.
+*/
+
+/* single-purpose registers, given names for clarity */
+#define rPC     r4
+#define rFP     r5
+#define rSELF   r6
+#define rINST   r7
+#define rIBASE  r8
+
+/*
+ * Given a frame pointer, find the stack save area.
+ *
+ * In C this is "((StackSaveArea*)(_fp) -1)".
+ */
+#define SAVEAREA_FROM_FP(_reg, _fpreg) \
+    sub     _reg, _fpreg, #sizeofStackSaveArea
+
+#define EXPORT_PC() \
+    str     rPC, [rFP, #(-sizeofStackSaveArea + offStackSaveArea_currentPc)]
+
+/*
+ * This is a #include, not a %include, because we want the C pre-processor
+ * to expand the macros into assembler assignment statements.
+ */
+#include "../../../mterp/common/asm-constants.h"
+
+/* File: armv5te/platform.S */
+/*
+ * ===========================================================================
+ *  CPU-version-specific defines and utility
+ * ===========================================================================
+ */
+
+
+    .global dvmCompilerTemplateStart
+    .type   dvmCompilerTemplateStart, %function
+    .text
+
+dvmCompilerTemplateStart:
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_CMP_LONG
+dvmCompiler_TEMPLATE_CMP_LONG:
+/* File: armv5te/TEMPLATE_CMP_LONG.S */
+    /*
+     * Compare two 64-bit values.  Puts 0, 1, or -1 into the destination
+     * register based on the results of the comparison.
+     *
+     * We load the full values with LDM, but in practice many values could
+     * be resolved by only looking at the high word.  This could be made
+     * faster or slower by splitting the LDM into a pair of LDRs.
+     *
+     * If we just wanted to set condition flags, we could do this:
+     *  subs    ip, r0, r2
+     *  sbcs    ip, r1, r3
+     *  subeqs  ip, r0, r2
+     * Leaving { <0, 0, >0 } in ip.  However, we have to set it to a specific
+     * integer value, which we can do with 2 conditional mov/mvn instructions
+     * (set 1, set -1; if they're equal we already have 0 in ip), giving
+     * us a constant 5-cycle path plus a branch at the end to the
+     * instruction epilogue code.  The multi-compare approach below needs
+     * 2 or 3 cycles + branch if the high word doesn't match, 6 + branch
+     * in the worst case (the 64-bit values are equal).
+     */
+    /* cmp-long vAA, vBB, vCC */
+    cmp     r1, r3                      @ compare (vBB+1, vCC+1)
+    blt     .LTEMPLATE_CMP_LONG_less            @ signed compare on high part
+    bgt     .LTEMPLATE_CMP_LONG_greater
+    subs    r0, r0, r2                  @ r0<- r0 - r2
+    bxeq     lr
+    bhi     .LTEMPLATE_CMP_LONG_greater         @ unsigned compare on low part
+.LTEMPLATE_CMP_LONG_less:
+    mvn     r0, #0                      @ r0<- -1
+    bx      lr
+.LTEMPLATE_CMP_LONG_greater:
+    mov     r0, #1                      @ r0<- 1
+    bx      lr
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_RETURN
+dvmCompiler_TEMPLATE_RETURN:
+/* File: armv5te/TEMPLATE_RETURN.S */
+    /*
+     * Unwind a frame from the Dalvik stack for compiled OP_RETURN_XXX.
+     * If the stored value in returnAddr
+     * is non-zero, the caller is compiled by the JIT thus return to the
+     * address in the code cache following the invoke instruction. Otherwise
+     * return to the special dvmJitToInterpNoChain entry point.
+     */
+#if defined(TEMPLATE_INLINE_PROFILING)
+    stmfd   sp!, {r0-r2,lr}             @ preserve live registers
+    mov     r0, r6
+    @ r0=rSELF
+    mov     lr, pc
+    ldr     pc, .LdvmFastMethodTraceExit
+    ldmfd   sp!, {r0-r2,lr}             @ restore live registers
+#endif
+    SAVEAREA_FROM_FP(r0, rFP)           @ r0<- saveArea (old)
+    ldr     r10, [r0, #offStackSaveArea_prevFrame] @ r10<- saveArea->prevFrame
+    ldrb    r8, [rSELF, #offThread_breakFlags] @ r8<- breakFlags
+    ldr     rPC, [r0, #offStackSaveArea_savedPc] @ rPC<- saveArea->savedPc
+#if !defined(WITH_SELF_VERIFICATION)
+    ldr     r9,  [r0, #offStackSaveArea_returnAddr] @ r9<- chaining cell ret
+#else
+    mov     r9, #0                      @ disable chaining
+#endif
+    ldr     r2, [r10, #(offStackSaveArea_method - sizeofStackSaveArea)]
+                                        @ r2<- method we're returning to
+    cmp     r2, #0                      @ break frame?
+#if !defined(WITH_SELF_VERIFICATION)
+    beq     1f                          @ bail to interpreter
+#else
+    blxeq   lr                          @ punt to interpreter and compare state
+#endif
+    ldr     r1, .LdvmJitToInterpNoChainNoProfile @ defined in footer.S
+    mov     rFP, r10                    @ publish new FP
+    ldr     r10, [r2, #offMethod_clazz] @ r10<- method->clazz
+
+    str     r2, [rSELF, #offThread_method]@ self->method = newSave->method
+    ldr     r0, [r10, #offClassObject_pDvmDex] @ r0<- method->clazz->pDvmDex
+    str     rFP, [rSELF, #offThread_curFrame] @ curFrame = fp
+    add     rPC, rPC, #6                @ publish new rPC (advance 6 bytes)
+    str     r0, [rSELF, #offThread_methodClassDex]
+    cmp     r8, #0                      @ check the break flags
+    movne   r9, #0                      @ clear the chaining cell address
+    str     r9, [rSELF, #offThread_inJitCodeCache] @ in code cache or not
+    cmp     r9, #0                      @ chaining cell exists?
+    blxne   r9                          @ jump to the chaining cell
+#if defined(WITH_JIT_TUNING)
+    mov     r0, #kCallsiteInterpreted
+#endif
+    mov     pc, r1                      @ callsite is interpreted
+1:
+    mov     r0, #0
+    str     r0, [rSELF, #offThread_inJitCodeCache] @ reset inJitCodeCache
+    stmia   rSELF, {rPC, rFP}           @ SAVE_PC_FP_TO_SELF()
+    ldr     r2, .LdvmMterpStdBail       @ defined in footer.S
+    mov     r0, rSELF                   @ Expecting rSELF in r0
+    blx     r2                          @ exit the interpreter
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_INVOKE_METHOD_NO_OPT
+dvmCompiler_TEMPLATE_INVOKE_METHOD_NO_OPT:
+/* File: armv5te/TEMPLATE_INVOKE_METHOD_NO_OPT.S */
+    /*
+     * For polymorphic callsites - setup the Dalvik frame and load Dalvik PC
+     * into rPC then jump to dvmJitToInterpNoChain to dispatch the
+     * runtime-resolved callee.
+     */
+    @ r0 = methodToCall, r1 = returnCell, rPC = dalvikCallsite
+    ldrh    r7, [r0, #offMethod_registersSize]  @ r7<- methodToCall->regsSize
+    ldrh    r2, [r0, #offMethod_outsSize]  @ r2<- methodToCall->outsSize
+    ldr     r9, [rSELF, #offThread_interpStackEnd]    @ r9<- interpStackEnd
+    ldrb    r8, [rSELF, #offThread_breakFlags] @ r8<- breakFlags
+    add     r3, r1, #1  @ Thumb addr is odd
+    SAVEAREA_FROM_FP(r1, rFP)           @ r1<- stack save area
+    sub     r1, r1, r7, lsl #2          @ r1<- newFp (old savearea - regsSize)
+    SAVEAREA_FROM_FP(r10, r1)           @ r10<- stack save area
+    sub     r10, r10, r2, lsl #2        @ r10<- bottom (newsave - outsSize)
+    cmp     r10, r9                     @ bottom < interpStackEnd?
+    bxlo    lr                          @ return to raise stack overflow excep.
+    @ r1 = newFP, r0 = methodToCall, r3 = returnCell, rPC = dalvikCallsite
+    ldr     r9, [r0, #offMethod_clazz]      @ r9<- method->clazz
+    ldr     r10, [r0, #offMethod_accessFlags] @ r10<- methodToCall->accessFlags
+    str     rPC, [rFP, #(offStackSaveArea_currentPc - sizeofStackSaveArea)]
+    str     rPC, [r1, #(offStackSaveArea_savedPc - sizeofStackSaveArea)]
+    ldr     rPC, [r0, #offMethod_insns]     @ rPC<- methodToCall->insns
+
+
+    @ set up newSaveArea
+    str     rFP, [r1, #(offStackSaveArea_prevFrame - sizeofStackSaveArea)]
+    str     r3, [r1, #(offStackSaveArea_returnAddr - sizeofStackSaveArea)]
+    str     r0, [r1, #(offStackSaveArea_method - sizeofStackSaveArea)]
+    cmp     r8, #0                      @ breakFlags != 0
+    bxne    lr                          @ bail to the interpreter
+    tst     r10, #ACC_NATIVE
+#if !defined(WITH_SELF_VERIFICATION)
+    bne     .LinvokeNative
+#else
+    bxne    lr                          @ bail to the interpreter
+#endif
+
+    ldr     r10, .LdvmJitToInterpTraceSelectNoChain
+    ldr     r3, [r9, #offClassObject_pDvmDex] @ r3<- method->clazz->pDvmDex
+
+    @ Update "thread" values for the new method
+    str     r0, [rSELF, #offThread_method]    @ self->method = methodToCall
+    str     r3, [rSELF, #offThread_methodClassDex] @ self->methodClassDex = ...
+    mov     rFP, r1                         @ fp = newFp
+    str     rFP, [rSELF, #offThread_curFrame]  @ curFrame = newFp
+#if defined(TEMPLATE_INLINE_PROFILING)
+    stmfd   sp!, {r0-r3}                    @ preserve r0-r3
+    mov     r1, r6
+    @ r0=methodToCall, r1=rSELF
+    mov     lr, pc
+    ldr     pc, .LdvmFastMethodTraceEnter
+    ldmfd   sp!, {r0-r3}                    @ restore r0-r3
+#endif
+
+    @ Start executing the callee
+#if defined(WITH_JIT_TUNING)
+    mov     r0, #kInlineCacheMiss
+#endif
+    mov     pc, r10                         @ dvmJitToInterpTraceSelectNoChain
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_INVOKE_METHOD_CHAIN
+dvmCompiler_TEMPLATE_INVOKE_METHOD_CHAIN:
+/* File: armv5te/TEMPLATE_INVOKE_METHOD_CHAIN.S */
+    /*
+     * For monomorphic callsite, setup the Dalvik frame and return to the
+     * Thumb code through the link register to transfer control to the callee
+     * method through a dedicated chaining cell.
+     */
+    @ r0 = methodToCall, r1 = returnCell, r2 = methodToCall->outsSize
+    @ rPC = dalvikCallsite, r7 = methodToCall->registersSize
+    @ methodToCall is guaranteed to be non-native
+.LinvokeChain:
+    ldr     r9, [rSELF, #offThread_interpStackEnd]    @ r9<- interpStackEnd
+    ldrb    r8, [rSELF, #offThread_breakFlags]        @ r8<- breakFlags
+    add     r3, r1, #1  @ Thumb addr is odd
+    SAVEAREA_FROM_FP(r1, rFP)           @ r1<- stack save area
+    sub     r1, r1, r7, lsl #2          @ r1<- newFp (old savearea - regsSize)
+    SAVEAREA_FROM_FP(r10, r1)           @ r10<- stack save area
+    add     r12, lr, #2                 @ setup the punt-to-interp address
+    sub     r10, r10, r2, lsl #2        @ r10<- bottom (newsave - outsSize)
+    cmp     r10, r9                     @ bottom < interpStackEnd?
+    bxlo    r12                         @ return to raise stack overflow excep.
+    @ r1 = newFP, r0 = methodToCall, r3 = returnCell, rPC = dalvikCallsite
+    ldr     r9, [r0, #offMethod_clazz]      @ r9<- method->clazz
+    str     rPC, [rFP, #(offStackSaveArea_currentPc - sizeofStackSaveArea)]
+    str     rPC, [r1, #(offStackSaveArea_savedPc - sizeofStackSaveArea)]
+
+    @ set up newSaveArea
+    str     rFP, [r1, #(offStackSaveArea_prevFrame - sizeofStackSaveArea)]
+    str     r3, [r1, #(offStackSaveArea_returnAddr - sizeofStackSaveArea)]
+    str     r0, [r1, #(offStackSaveArea_method - sizeofStackSaveArea)]
+    cmp     r8, #0                      @ breakFlags != 0
+    bxne    r12                         @ bail to the interpreter
+
+    ldr     r3, [r9, #offClassObject_pDvmDex] @ r3<- method->clazz->pDvmDex
+
+    @ Update "thread" values for the new method
+    str     r0, [rSELF, #offThread_method]    @ self->method = methodToCall
+    str     r3, [rSELF, #offThread_methodClassDex] @ self->methodClassDex = ...
+    mov     rFP, r1                         @ fp = newFp
+    str     rFP, [rSELF, #offThread_curFrame]  @ curFrame = newFp
+#if defined(TEMPLATE_INLINE_PROFILING)
+    stmfd   sp!, {r0-r2,lr}             @ preserve clobbered live registers
+    mov     r1, r6
+    @ r0=methodToCall, r1=rSELF
+    mov     lr, pc
+    ldr     pc, .LdvmFastMethodTraceEnter
+    ldmfd   sp!, {r0-r2,lr}             @ restore registers
+#endif
+
+    bx      lr                              @ return to the callee-chaining cell
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_INVOKE_METHOD_PREDICTED_CHAIN
+dvmCompiler_TEMPLATE_INVOKE_METHOD_PREDICTED_CHAIN:
+/* File: armv5te/TEMPLATE_INVOKE_METHOD_PREDICTED_CHAIN.S */
+    /*
+     * For polymorphic callsite, check whether the cached class pointer matches
+     * the current one. If so setup the Dalvik frame and return to the
+     * Thumb code through the link register to transfer control to the callee
+     * method through a dedicated chaining cell.
+     *
+     * The predicted chaining cell is declared in ArmLIR.h with the
+     * following layout:
+     *
+     *  typedef struct PredictedChainingCell {
+     *      u4 branch;
+     *      const ClassObject *clazz;
+     *      const Method *method;
+     *      u4 counter;
+     *  } PredictedChainingCell;
+     *
+     * Upon returning to the callsite:
+     *    - lr  : to branch to the chaining cell
+     *    - lr+2: to punt to the interpreter
+     *    - lr+4: to fully resolve the callee and may rechain.
+     *            r3 <- class
+     *            r9 <- counter
+     */
+    @ r0 = this, r1 = returnCell, r2 = predictedChainCell, rPC = dalvikCallsite
+    ldr     r3, [r0, #offObject_clazz]  @ r3 <- this->class
+    ldr     r8, [r2, #4]    @ r8 <- predictedChainCell->clazz
+    ldr     r0, [r2, #8]    @ r0 <- predictedChainCell->method
+    ldr     r9, [rSELF, #offThread_icRechainCount] @ r1 <- shared rechainCount
+    cmp     r3, r8          @ predicted class == actual class?
+#if defined(WITH_JIT_TUNING)
+    ldr     r7, .LdvmICHitCount
+#if defined(WORKAROUND_CORTEX_A9_745320)
+    /* Don't use conditional loads if the HW defect exists */
+    bne     101f
+    ldr     r10, [r7, #0]
+101:
+#else
+    ldreq   r10, [r7, #0]
+#endif
+    add     r10, r10, #1
+    streq   r10, [r7, #0]
+#endif
+    ldreqh  r7, [r0, #offMethod_registersSize]  @ r7<- methodToCall->regsSize
+    ldreqh  r2, [r0, #offMethod_outsSize]  @ r2<- methodToCall->outsSize
+    beq     .LinvokeChain   @ predicted chain is valid
+    ldr     r7, [r3, #offClassObject_vtable] @ r7 <- this->class->vtable
+    cmp     r8, #0          @ initialized class or not
+    moveq   r1, #0
+    subne   r1, r9, #1      @ count--
+    strne   r1, [rSELF, #offThread_icRechainCount]  @ write back to thread
+    add     lr, lr, #4      @ return to fully-resolve landing pad
+    /*
+     * r1 <- count
+     * r2 <- &predictedChainCell
+     * r3 <- this->class
+     * r4 <- dPC
+     * r7 <- this->class->vtable
+     */
+    bx      lr
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_INVOKE_METHOD_NATIVE
+dvmCompiler_TEMPLATE_INVOKE_METHOD_NATIVE:
+/* File: armv5te/TEMPLATE_INVOKE_METHOD_NATIVE.S */
+    @ r0 = methodToCall, r1 = returnCell, rPC = dalvikCallsite
+    @ r7 = methodToCall->registersSize
+    ldr     r9, [rSELF, #offThread_interpStackEnd]    @ r9<- interpStackEnd
+    ldrb    r8, [rSELF, #offThread_breakFlags]        @ r8<- breakFlags
+    add     r3, r1, #1  @ Thumb addr is odd
+    SAVEAREA_FROM_FP(r1, rFP)           @ r1<- stack save area
+    sub     r1, r1, r7, lsl #2          @ r1<- newFp (old savearea - regsSize)
+    SAVEAREA_FROM_FP(r10, r1)           @ r10<- stack save area
+    cmp     r10, r9                     @ bottom < interpStackEnd?
+    bxlo    lr                          @ return to raise stack overflow excep.
+    @ r1 = newFP, r0 = methodToCall, r3 = returnCell, rPC = dalvikCallsite
+    str     rPC, [rFP, #(offStackSaveArea_currentPc - sizeofStackSaveArea)]
+    str     rPC, [r1, #(offStackSaveArea_savedPc - sizeofStackSaveArea)]
+
+    @ set up newSaveArea
+    str     rFP, [r1, #(offStackSaveArea_prevFrame - sizeofStackSaveArea)]
+    str     r3, [r1, #(offStackSaveArea_returnAddr - sizeofStackSaveArea)]
+    str     r0, [r1, #(offStackSaveArea_method - sizeofStackSaveArea)]
+    cmp     r8, #0                      @ breakFlags != 0
+    ldr     r8, [r0, #offMethod_nativeFunc] @ r8<- method->nativeFunc
+#if !defined(WITH_SELF_VERIFICATION)
+    bxne    lr                          @ bail to the interpreter
+#else
+    bx      lr                          @ bail to interpreter unconditionally
+#endif
+
+    @ go ahead and transfer control to the native code
+    ldr     r9, [rSELF, #offThread_jniLocal_topCookie]@r9<-thread->localRef->...
+    mov     r2, #0
+    str     r1, [rSELF, #offThread_curFrame]   @ curFrame = newFp
+    str     r2, [rSELF, #offThread_inJitCodeCache] @ not in the jit code cache
+    str     r9, [r1, #(offStackSaveArea_localRefCookie - sizeofStackSaveArea)]
+                                        @ newFp->localRefCookie=top
+    SAVEAREA_FROM_FP(r10, r1)           @ r10<- new stack save area
+
+    mov     r2, r0                        @ arg2<- methodToCall
+    mov     r0, r1                        @ arg0<- newFP
+    add     r1, rSELF, #offThread_retval  @ arg1<- &retval
+    mov     r3, rSELF                     @ arg3<- self
+#if defined(TEMPLATE_INLINE_PROFILING)
+    @ r2=methodToCall, r6=rSELF
+    stmfd   sp!, {r2,r6}                @ to be consumed after JNI return
+    stmfd   sp!, {r0-r3}                @ preserve r0-r3
+    mov     r0, r2
+    mov     r1, r6
+    @ r0=JNIMethod, r1=rSELF
+    mov     lr, pc
+    ldr     pc, .LdvmFastMethodTraceEnter
+    ldmfd   sp!, {r0-r3}                @ restore r0-r3
+#endif
+
+    blx     r8                          @ off to the native code
+
+#if defined(TEMPLATE_INLINE_PROFILING)
+    ldmfd   sp!, {r0-r1}                @ restore r2 and r6
+    @ r0=JNIMethod, r1=rSELF
+    mov     lr, pc
+    ldr     pc, .LdvmFastNativeMethodTraceExit
+#endif
+    @ native return; r10=newSaveArea
+    @ equivalent to dvmPopJniLocals
+    ldr     r2, [r10, #offStackSaveArea_returnAddr] @ r2 = chaining cell ret
+    ldr     r0, [r10, #offStackSaveArea_localRefCookie] @ r0<- saved->top
+    ldr     r1, [rSELF, #offThread_exception] @ check for exception
+    str     rFP, [rSELF, #offThread_curFrame]  @ curFrame = fp
+    cmp     r1, #0                      @ null?
+    str     r0, [rSELF, #offThread_jniLocal_topCookie] @ new top <- old top
+    ldr     r0, [rFP, #(offStackSaveArea_currentPc - sizeofStackSaveArea)]
+
+    @ r0 = dalvikCallsitePC
+    bne     .LhandleException           @ no, handle exception
+
+    str     r2, [rSELF, #offThread_inJitCodeCache] @ set the mode properly
+    cmp     r2, #0                      @ return chaining cell still exists?
+    bxne    r2                          @ yes - go ahead
+
+    @ continue executing the next instruction through the interpreter
+    ldr     r1, .LdvmJitToInterpTraceSelectNoChain @ defined in footer.S
+    add     rPC, r0, #6                 @ reconstruct new rPC (advance 6 bytes)
+#if defined(WITH_JIT_TUNING)
+    mov     r0, #kCallsiteInterpreted
+#endif
+    mov     pc, r1
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_CMPG_DOUBLE
+dvmCompiler_TEMPLATE_CMPG_DOUBLE:
+/* File: armv5te/TEMPLATE_CMPG_DOUBLE.S */
+/* File: armv5te/TEMPLATE_CMPL_DOUBLE.S */
+    /*
+     * For the JIT: incoming arguments in r0-r1, r2-r3
+     *              result in r0
+     *
+     * Compare two floating-point values.  Puts 0, 1, or -1 into the
+     * destination register based on the results of the comparison.
+     *
+     * Provide a "naninst" instruction that puts 1 or -1 into r1 depending
+     * on what value we'd like to return when one of the operands is NaN.
+     *
+     * See OP_CMPL_FLOAT for an explanation.
+     *
+     * For: cmpl-double, cmpg-double
+     */
+    /* op vAA, vBB, vCC */
+    push    {r0-r3}                     @ save operands
+    mov     r11, lr                     @ save return address
+    mov     lr, pc
+    ldr     pc, .L__aeabi_cdcmple       @ PIC way of "bl __aeabi_cdcmple"
+    bhi     .LTEMPLATE_CMPG_DOUBLE_gt_or_nan       @ C set and Z clear, disambiguate
+    mvncc   r0, #0                      @ (less than) r1<- -1
+    moveq   r0, #0                      @ (equal) r1<- 0, trumps less than
+    add     sp, #16                     @ drop unused operands
+    bx      r11
+
+    @ Test for NaN with a second comparison.  EABI forbids testing bit
+    @ patterns, and we can't represent 0x7fc00000 in immediate form, so
+    @ make the library call.
+.LTEMPLATE_CMPG_DOUBLE_gt_or_nan:
+    pop     {r2-r3}                     @ restore operands in reverse order
+    pop     {r0-r1}                     @ restore operands in reverse order
+    mov     lr, pc
+    ldr     pc, .L__aeabi_cdcmple       @ r0<- Z set if eq, C clear if <
+    movcc   r0, #1                      @ (greater than) r1<- 1
+    bxcc    r11
+    mov     r0, #1                            @ r1<- 1 or -1 for NaN
+    bx      r11
+
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_CMPL_DOUBLE
+dvmCompiler_TEMPLATE_CMPL_DOUBLE:
+/* File: armv5te/TEMPLATE_CMPL_DOUBLE.S */
+    /*
+     * For the JIT: incoming arguments in r0-r1, r2-r3
+     *              result in r0
+     *
+     * Compare two floating-point values.  Puts 0, 1, or -1 into the
+     * destination register based on the results of the comparison.
+     *
+     * Provide a "naninst" instruction that puts 1 or -1 into r1 depending
+     * on what value we'd like to return when one of the operands is NaN.
+     *
+     * See OP_CMPL_FLOAT for an explanation.
+     *
+     * For: cmpl-double, cmpg-double
+     */
+    /* op vAA, vBB, vCC */
+    push    {r0-r3}                     @ save operands
+    mov     r11, lr                     @ save return address
+    mov     lr, pc
+    ldr     pc, .L__aeabi_cdcmple       @ PIC way of "bl __aeabi_cdcmple"
+    bhi     .LTEMPLATE_CMPL_DOUBLE_gt_or_nan       @ C set and Z clear, disambiguate
+    mvncc   r0, #0                      @ (less than) r1<- -1
+    moveq   r0, #0                      @ (equal) r1<- 0, trumps less than
+    add     sp, #16                     @ drop unused operands
+    bx      r11
+
+    @ Test for NaN with a second comparison.  EABI forbids testing bit
+    @ patterns, and we can't represent 0x7fc00000 in immediate form, so
+    @ make the library call.
+.LTEMPLATE_CMPL_DOUBLE_gt_or_nan:
+    pop     {r2-r3}                     @ restore operands in reverse order
+    pop     {r0-r1}                     @ restore operands in reverse order
+    mov     lr, pc
+    ldr     pc, .L__aeabi_cdcmple       @ r0<- Z set if eq, C clear if <
+    movcc   r0, #1                      @ (greater than) r1<- 1
+    bxcc    r11
+    mvn     r0, #0                            @ r1<- 1 or -1 for NaN
+    bx      r11
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_CMPG_FLOAT
+dvmCompiler_TEMPLATE_CMPG_FLOAT:
+/* File: armv5te/TEMPLATE_CMPG_FLOAT.S */
+/* File: armv5te/TEMPLATE_CMPL_FLOAT.S */
+    /*
+     * For the JIT: incoming arguments in r0-r1, r2-r3
+     *              result in r0
+     *
+     * Compare two floating-point values.  Puts 0, 1, or -1 into the
+     * destination register based on the results of the comparison.
+     *
+     * Provide a "naninst" instruction that puts 1 or -1 into r1 depending
+     * on what value we'd like to return when one of the operands is NaN.
+     *
+     * The operation we're implementing is:
+     *   if (x == y)
+     *     return 0;
+     *   else if (x < y)
+     *     return -1;
+     *   else if (x > y)
+     *     return 1;
+     *   else
+     *     return {-1,1};  // one or both operands was NaN
+     *
+     * The straightforward implementation requires 3 calls to functions
+     * that return a result in r0.  We can do it with two calls if our
+     * EABI library supports __aeabi_cfcmple (only one if we want to check
+     * for NaN directly):
+     *   check x <= y
+     *     if <, return -1
+     *     if ==, return 0
+     *   check y <= x
+     *     if <, return 1
+     *   return {-1,1}
+     *
+     * for: cmpl-float, cmpg-float
+     */
+    /* op vAA, vBB, vCC */
+    mov     r9, r0                      @ Save copies - we may need to redo
+    mov     r10, r1
+    mov     r11, lr                     @ save return address
+    mov     lr, pc
+    ldr     pc, .L__aeabi_cfcmple       @ cmp <=: C clear if <, Z set if eq
+    bhi     .LTEMPLATE_CMPG_FLOAT_gt_or_nan       @ C set and Z clear, disambiguate
+    mvncc   r0, #0                      @ (less than) r0<- -1
+    moveq   r0, #0                      @ (equal) r0<- 0, trumps less than
+    bx      r11
+    @ Test for NaN with a second comparison.  EABI forbids testing bit
+    @ patterns, and we can't represent 0x7fc00000 in immediate form, so
+    @ make the library call.
+.LTEMPLATE_CMPG_FLOAT_gt_or_nan:
+    mov     r0, r10                     @ restore in reverse order
+    mov     r1, r9
+    mov     lr, pc
+    ldr     pc, .L__aeabi_cfcmple       @ r0<- Z set if eq, C clear if <
+    movcc   r0, #1                      @ (greater than) r1<- 1
+    bxcc    r11
+    mov     r0, #1                            @ r1<- 1 or -1 for NaN
+    bx      r11
+
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_CMPL_FLOAT
+dvmCompiler_TEMPLATE_CMPL_FLOAT:
+/* File: armv5te/TEMPLATE_CMPL_FLOAT.S */
+    /*
+     * For the JIT: incoming arguments in r0-r1, r2-r3
+     *              result in r0
+     *
+     * Compare two floating-point values.  Puts 0, 1, or -1 into the
+     * destination register based on the results of the comparison.
+     *
+     * Provide a "naninst" instruction that puts 1 or -1 into r1 depending
+     * on what value we'd like to return when one of the operands is NaN.
+     *
+     * The operation we're implementing is:
+     *   if (x == y)
+     *     return 0;
+     *   else if (x < y)
+     *     return -1;
+     *   else if (x > y)
+     *     return 1;
+     *   else
+     *     return {-1,1};  // one or both operands was NaN
+     *
+     * The straightforward implementation requires 3 calls to functions
+     * that return a result in r0.  We can do it with two calls if our
+     * EABI library supports __aeabi_cfcmple (only one if we want to check
+     * for NaN directly):
+     *   check x <= y
+     *     if <, return -1
+     *     if ==, return 0
+     *   check y <= x
+     *     if <, return 1
+     *   return {-1,1}
+     *
+     * for: cmpl-float, cmpg-float
+     */
+    /* op vAA, vBB, vCC */
+    mov     r9, r0                      @ Save copies - we may need to redo
+    mov     r10, r1
+    mov     r11, lr                     @ save return address
+    mov     lr, pc
+    ldr     pc, .L__aeabi_cfcmple       @ cmp <=: C clear if <, Z set if eq
+    bhi     .LTEMPLATE_CMPL_FLOAT_gt_or_nan       @ C set and Z clear, disambiguate
+    mvncc   r0, #0                      @ (less than) r0<- -1
+    moveq   r0, #0                      @ (equal) r0<- 0, trumps less than
+    bx      r11
+    @ Test for NaN with a second comparison.  EABI forbids testing bit
+    @ patterns, and we can't represent 0x7fc00000 in immediate form, so
+    @ make the library call.
+.LTEMPLATE_CMPL_FLOAT_gt_or_nan:
+    mov     r0, r10                     @ restore in reverse order
+    mov     r1, r9
+    mov     lr, pc
+    ldr     pc, .L__aeabi_cfcmple       @ r0<- Z set if eq, C clear if <
+    movcc   r0, #1                      @ (greater than) r1<- 1
+    bxcc    r11
+    mvn     r0, #0                            @ r1<- 1 or -1 for NaN
+    bx      r11
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_MUL_LONG
+dvmCompiler_TEMPLATE_MUL_LONG:
+/* File: armv5te/TEMPLATE_MUL_LONG.S */
+    /*
+     * Signed 64-bit integer multiply.
+     *
+     * For JIT: op1 in r0/r1, op2 in r2/r3, return in r0/r1
+     *
+     * Consider WXxYZ (r1r0 x r3r2) with a long multiply:
+     *        WX
+     *      x YZ
+     *  --------
+     *     ZW ZX
+     *  YW YX
+     *
+     * The low word of the result holds ZX, the high word holds
+     * (ZW+YX) + (the high overflow from ZX).  YW doesn't matter because
+     * it doesn't fit in the low 64 bits.
+     *
+     * Unlike most ARM math operations, multiply instructions have
+     * restrictions on using the same register more than once (Rd and Rm
+     * cannot be the same).
+     */
+    /* mul-long vAA, vBB, vCC */
+    mul     ip, r2, r1                  @  ip<- ZxW
+    umull   r9, r10, r2, r0             @  r9/r10 <- ZxX
+    mla     r2, r0, r3, ip              @  r2<- YxX + (ZxW)
+    add     r10, r2, r10                @  r10<- r10 + low(ZxW + (YxX))
+    mov     r0,r9
+    mov     r1,r10
+    bx      lr
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_SHL_LONG
+dvmCompiler_TEMPLATE_SHL_LONG:
+/* File: armv5te/TEMPLATE_SHL_LONG.S */
+    /*
+     * Long integer shift.  This is different from the generic 32/64-bit
+     * binary operations because vAA/vBB are 64-bit but vCC (the shift
+     * distance) is 32-bit.  Also, Dalvik requires us to ignore all but the low
+     * 6 bits.
+     */
+    /* shl-long vAA, vBB, vCC */
+    and     r2, r2, #63                 @ r2<- r2 & 0x3f
+    mov     r1, r1, asl r2              @  r1<- r1 << r2
+    rsb     r3, r2, #32                 @  r3<- 32 - r2
+    orr     r1, r1, r0, lsr r3          @  r1<- r1 | (r0 << (32-r2))
+    subs    ip, r2, #32                 @  ip<- r2 - 32
+    movpl   r1, r0, asl ip              @  if r2 >= 32, r1<- r0 << (r2-32)
+    mov     r0, r0, asl r2              @  r0<- r0 << r2
+    bx      lr
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_SHR_LONG
+dvmCompiler_TEMPLATE_SHR_LONG:
+/* File: armv5te/TEMPLATE_SHR_LONG.S */
+    /*
+     * Long integer shift.  This is different from the generic 32/64-bit
+     * binary operations because vAA/vBB are 64-bit but vCC (the shift
+     * distance) is 32-bit.  Also, Dalvik requires us to ignore all but the low
+     * 6 bits.
+     */
+    /* shr-long vAA, vBB, vCC */
+    and     r2, r2, #63                 @ r0<- r0 & 0x3f
+    mov     r0, r0, lsr r2              @  r0<- r2 >> r2
+    rsb     r3, r2, #32                 @  r3<- 32 - r2
+    orr     r0, r0, r1, asl r3          @  r0<- r0 | (r1 << (32-r2))
+    subs    ip, r2, #32                 @  ip<- r2 - 32
+    movpl   r0, r1, asr ip              @  if r2 >= 32, r0<-r1 >> (r2-32)
+    mov     r1, r1, asr r2              @  r1<- r1 >> r2
+    bx      lr
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_USHR_LONG
+dvmCompiler_TEMPLATE_USHR_LONG:
+/* File: armv5te/TEMPLATE_USHR_LONG.S */
+    /*
+     * Long integer shift.  This is different from the generic 32/64-bit
+     * binary operations because vAA/vBB are 64-bit but vCC (the shift
+     * distance) is 32-bit.  Also, Dalvik requires us to ignore all but the low
+     * 6 bits.
+     */
+    /* ushr-long vAA, vBB, vCC */
+    and     r2, r2, #63                 @ r0<- r0 & 0x3f
+    mov     r0, r0, lsr r2              @  r0<- r2 >> r2
+    rsb     r3, r2, #32                 @  r3<- 32 - r2
+    orr     r0, r0, r1, asl r3          @  r0<- r0 | (r1 << (32-r2))
+    subs    ip, r2, #32                 @  ip<- r2 - 32
+    movpl   r0, r1, lsr ip              @  if r2 >= 32, r0<-r1 >>> (r2-32)
+    mov     r1, r1, lsr r2              @  r1<- r1 >>> r2
+    bx      lr
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_THROW_EXCEPTION_COMMON
+dvmCompiler_TEMPLATE_THROW_EXCEPTION_COMMON:
+/* File: armv5te/TEMPLATE_THROW_EXCEPTION_COMMON.S */
+    /*
+     * Throw an exception from JIT'ed code.
+     * On entry:
+     *    r0    Dalvik PC that raises the exception
+     */
+    b       .LhandleException
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_MEM_OP_DECODE
+dvmCompiler_TEMPLATE_MEM_OP_DECODE:
+/* File: armv5te/TEMPLATE_MEM_OP_DECODE.S */
+#if defined(WITH_SELF_VERIFICATION)
+    /*
+     * This handler encapsulates heap memory ops for selfVerification mode.
+     *
+     * The call to the handler is inserted prior to a heap memory operation.
+     * This handler then calls a function to decode the memory op, and process
+     * it accordingly. Afterwards, the handler changes the return address to
+     * skip the memory op so it never gets executed.
+     */
+    push    {r0-r12,lr}                 @ save out all registers
+    ldr     r2, .LdvmSelfVerificationMemOpDecode @ defined in footer.S
+    mov     r0, lr                      @ arg0 <- link register
+    mov     r1, sp                      @ arg1 <- stack pointer
+    blx     r2                          @ decode and handle the mem op
+    pop     {r0-r12,lr}                 @ restore all registers
+    bx      lr                          @ return to compiled code
+#endif
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_STRING_COMPARETO
+dvmCompiler_TEMPLATE_STRING_COMPARETO:
+/* File: armv5te/TEMPLATE_STRING_COMPARETO.S */
+    /*
+     * String's compareTo.
+     *
+     * Requires r0/r1 to have been previously checked for null.  Will
+     * return negative if this's string is < comp, 0 if they are the
+     * same and positive if >.
+     *
+     * IMPORTANT NOTE:
+     *
+     * This code relies on hard-coded offsets for string objects, and must be
+     * kept in sync with definitions in UtfString.h.  See asm-constants.h
+     *
+     * On entry:
+     *    r0:   this object pointer
+     *    r1:   comp object pointer
+     *
+     */
+
+    mov    r2, r0         @ this to r2, opening up r0 for return value
+    subs   r0, r2, r1     @ Same?
+    bxeq   lr
+
+    ldr    r4, [r2, #STRING_FIELDOFF_OFFSET]
+    ldr    r9, [r1, #STRING_FIELDOFF_OFFSET]
+    ldr    r7, [r2, #STRING_FIELDOFF_COUNT]
+    ldr    r10, [r1, #STRING_FIELDOFF_COUNT]
+    ldr    r2, [r2, #STRING_FIELDOFF_VALUE]
+    ldr    r1, [r1, #STRING_FIELDOFF_VALUE]
+
+    /*
+     * At this point, we have:
+     *    value:  r2/r1
+     *    offset: r4/r9
+     *    count:  r7/r10
+     * We're going to compute
+     *    r11 <- countDiff
+     *    r10 <- minCount
+     */
+     subs  r11, r7, r10
+     movls r10, r7
+
+     /* Now, build pointers to the string data */
+     add   r2, r2, r4, lsl #1
+     add   r1, r1, r9, lsl #1
+     /*
+      * Note: data pointers point to previous element so we can use pre-index
+      * mode with base writeback.
+      */
+     add   r2, #16-2   @ offset to contents[-1]
+     add   r1, #16-2   @ offset to contents[-1]
+
+     /*
+      * At this point we have:
+      *   r2: *this string data
+      *   r1: *comp string data
+      *   r10: iteration count for comparison
+      *   r11: value to return if the first part of the string is equal
+      *   r0: reserved for result
+      *   r3, r4, r7, r8, r9, r12 available for loading string data
+      */
+
+    subs  r10, #2
+    blt   do_remainder2
+
+      /*
+       * Unroll the first two checks so we can quickly catch early mismatch
+       * on long strings (but preserve incoming alignment)
+       */
+
+    ldrh  r3, [r2, #2]!
+    ldrh  r4, [r1, #2]!
+    ldrh  r7, [r2, #2]!
+    ldrh  r8, [r1, #2]!
+    subs  r0, r3, r4
+    subeqs  r0, r7, r8
+    bxne  lr
+    cmp   r10, #28
+    bgt   do_memcmp16
+    subs  r10, #3
+    blt   do_remainder
+
+loopback_triple:
+    ldrh  r3, [r2, #2]!
+    ldrh  r4, [r1, #2]!
+    ldrh  r7, [r2, #2]!
+    ldrh  r8, [r1, #2]!
+    ldrh  r9, [r2, #2]!
+    ldrh  r12,[r1, #2]!
+    subs  r0, r3, r4
+    subeqs  r0, r7, r8
+    subeqs  r0, r9, r12
+    bxne  lr
+    subs  r10, #3
+    bge   loopback_triple
+
+do_remainder:
+    adds  r10, #3
+    beq   returnDiff
+
+loopback_single:
+    ldrh  r3, [r2, #2]!
+    ldrh  r4, [r1, #2]!
+    subs  r0, r3, r4
+    bxne  lr
+    subs  r10, #1
+    bne     loopback_single
+
+returnDiff:
+    mov   r0, r11
+    bx    lr
+
+do_remainder2:
+    adds  r10, #2
+    bne   loopback_single
+    mov   r0, r11
+    bx    lr
+
+    /* Long string case */
+do_memcmp16:
+    mov   r4, lr
+    ldr   lr, .Lmemcmp16
+    mov   r7, r11
+    add   r0, r2, #2
+    add   r1, r1, #2
+    mov   r2, r10
+    blx   lr
+    cmp   r0, #0
+    bxne  r4
+    mov   r0, r7
+    bx    r4
+
+.Lmemcmp16:
+    .word __memcmp16
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_STRING_INDEXOF
+dvmCompiler_TEMPLATE_STRING_INDEXOF:
+/* File: armv5te/TEMPLATE_STRING_INDEXOF.S */
+    /*
+     * String's indexOf.
+     *
+     * Requires r0 to have been previously checked for null.  Will
+     * return index of match of r1 in r0.
+     *
+     * IMPORTANT NOTE:
+     *
+     * This code relies on hard-coded offsets for string objects, and must be
+     * kept in sync wth definitions in UtfString.h  See asm-constants.h
+     *
+     * On entry:
+     *    r0:   string object pointer
+     *    r1:   char to match
+     *    r2:   Starting offset in string data
+     */
+
+    ldr    r7, [r0, #STRING_FIELDOFF_OFFSET]
+    ldr    r8, [r0, #STRING_FIELDOFF_COUNT]
+    ldr    r0, [r0, #STRING_FIELDOFF_VALUE]
+
+    /*
+     * At this point, we have:
+     *    r0: object pointer
+     *    r1: char to match
+     *    r2: starting offset
+     *    r7: offset
+     *    r8: string length
+     */
+
+     /* Build pointer to start of string data */
+     add   r0, #16
+     add   r0, r0, r7, lsl #1
+
+     /* Save a copy of starting data in r7 */
+     mov   r7, r0
+
+     /* Clamp start to [0..count] */
+     cmp   r2, #0
+     movlt r2, #0
+     cmp   r2, r8
+     movgt r2, r8
+
+     /* Build pointer to start of data to compare and pre-bias */
+     add   r0, r0, r2, lsl #1
+     sub   r0, #2
+
+     /* Compute iteration count */
+     sub   r8, r2
+
+     /*
+      * At this point we have:
+      *   r0: start of data to test
+      *   r1: chat to compare
+      *   r8: iteration count
+      *   r7: original start of string
+      *   r3, r4, r9, r10, r11, r12 available for loading string data
+      */
+
+    subs  r8, #4
+    blt   indexof_remainder
+
+indexof_loop4:
+    ldrh  r3, [r0, #2]!
+    ldrh  r4, [r0, #2]!
+    ldrh  r10, [r0, #2]!
+    ldrh  r11, [r0, #2]!
+    cmp   r3, r1
+    beq   match_0
+    cmp   r4, r1
+    beq   match_1
+    cmp   r10, r1
+    beq   match_2
+    cmp   r11, r1
+    beq   match_3
+    subs  r8, #4
+    bge   indexof_loop4
+
+indexof_remainder:
+    adds    r8, #4
+    beq     indexof_nomatch
+
+indexof_loop1:
+    ldrh  r3, [r0, #2]!
+    cmp   r3, r1
+    beq   match_3
+    subs  r8, #1
+    bne   indexof_loop1
+
+indexof_nomatch:
+    mov   r0, #-1
+    bx    lr
+
+match_0:
+    sub   r0, #6
+    sub   r0, r7
+    asr   r0, r0, #1
+    bx    lr
+match_1:
+    sub   r0, #4
+    sub   r0, r7
+    asr   r0, r0, #1
+    bx    lr
+match_2:
+    sub   r0, #2
+    sub   r0, r7
+    asr   r0, r0, #1
+    bx    lr
+match_3:
+    sub   r0, r7
+    asr   r0, r0, #1
+    bx    lr
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_INTERPRET
+dvmCompiler_TEMPLATE_INTERPRET:
+/* File: armv5te/TEMPLATE_INTERPRET.S */
+    /*
+     * This handler transfers control to the interpeter without performing
+     * any lookups.  It may be called either as part of a normal chaining
+     * operation, or from the transition code in header.S.  We distinquish
+     * the two cases by looking at the link register.  If called from a
+     * translation chain, it will point to the chaining Dalvik PC -3.
+     * On entry:
+     *    lr - if NULL:
+     *        r1 - the Dalvik PC to begin interpretation.
+     *    else
+     *        [lr, #3] contains Dalvik PC to begin interpretation
+     *    rSELF - pointer to thread
+     *    rFP - Dalvik frame pointer
+     */
+    cmp     lr, #0
+#if defined(WORKAROUND_CORTEX_A9_745320)
+    /* Don't use conditional loads if the HW defect exists */
+    beq     101f
+    ldr     r1,[lr, #3]
+101:
+#else
+    ldrne   r1,[lr, #3]
+#endif
+    ldr     r2, .LinterpPunt
+    mov     r0, r1                       @ set Dalvik PC
+    bx      r2
+    @ doesn't return
+
+.LinterpPunt:
+    .word   dvmJitToInterpPunt
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_MONITOR_ENTER
+dvmCompiler_TEMPLATE_MONITOR_ENTER:
+/* File: armv5te/TEMPLATE_MONITOR_ENTER.S */
+    /*
+     * Call out to the runtime to lock an object.  Because this thread
+     * may have been suspended in THREAD_MONITOR state and the Jit's
+     * translation cache subsequently cleared, we cannot return directly.
+     * Instead, unconditionally transition to the interpreter to resume.
+     *
+     * On entry:
+     *    r0 - self pointer
+     *    r1 - the object (which has already been null-checked by the caller
+     *    r4 - the Dalvik PC of the following instruction.
+     */
+    ldr     r2, .LdvmLockObject
+    mov     r3, #0                       @ Record that we're not returning
+    str     r3, [r0, #offThread_inJitCodeCache]
+    blx     r2                           @ dvmLockObject(self, obj)
+    ldr     r2, .LdvmJitToInterpNoChain
+    @ Bail to interpreter - no chain [note - r4 still contains rPC]
+#if defined(WITH_JIT_TUNING)
+    mov     r0, #kHeavyweightMonitor
+#endif
+    bx      r2
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_MONITOR_ENTER_DEBUG
+dvmCompiler_TEMPLATE_MONITOR_ENTER_DEBUG:
+/* File: armv5te/TEMPLATE_MONITOR_ENTER_DEBUG.S */
+    /*
+     * To support deadlock prediction, this version of MONITOR_ENTER
+     * will always call the heavyweight dvmLockObject, check for an
+     * exception and then bail out to the interpreter.
+     *
+     * On entry:
+     *    r0 - self pointer
+     *    r1 - the object (which has already been null-checked by the caller
+     *    r4 - the Dalvik PC of the following instruction.
+     *
+     */
+    ldr     r2, .LdvmLockObject
+    mov     r3, #0                       @ Record that we're not returning
+    str     r3, [r0, #offThread_inJitCodeCache]
+    blx     r2             @ dvmLockObject(self, obj)
+    @ test for exception
+    ldr     r1, [rSELF, #offThread_exception]
+    cmp     r1, #0
+    beq     1f
+    ldr     r2, .LhandleException
+    sub     r0, r4, #2     @ roll dPC back to this monitor instruction
+    bx      r2
+1:
+    @ Bail to interpreter - no chain [note - r4 still contains rPC]
+#if defined(WITH_JIT_TUNING)
+    mov     r0, #kHeavyweightMonitor
+#endif
+    ldr     pc, .LdvmJitToInterpNoChain
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_PERIODIC_PROFILING
+dvmCompiler_TEMPLATE_PERIODIC_PROFILING:
+/* File: armv5te/TEMPLATE_PERIODIC_PROFILING.S */
+    /*
+     * Increment profile counter for this trace, and decrement
+     * sample counter.  If sample counter goes below zero, turn
+     * off profiling.
+     *
+     * On entry
+     * (lr-11) is address of pointer to counter.  Note: the counter
+     *    actually exists 10 bytes before the return target, but because
+     *    we are arriving from thumb mode, lr will have its low bit set.
+     */
+     ldr    r0, [lr,#-11]
+     ldr    r1, [rSELF, #offThread_pProfileCountdown]
+     ldr    r2, [r0]                    @ get counter
+     ldr    r3, [r1]                    @ get countdown timer
+     add    r2, #1
+     subs   r2, #1
+     blt    .LTEMPLATE_PERIODIC_PROFILING_disable_profiling
+     str    r2, [r0]
+     str    r3, [r1]
+     bx     lr
+
+.LTEMPLATE_PERIODIC_PROFILING_disable_profiling:
+     mov    r4, lr                     @ preserve lr
+     ldr    r0, .LdvmJitTraceProfilingOff
+     blx    r0
+     bx     r4
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_RETURN_PROF
+dvmCompiler_TEMPLATE_RETURN_PROF:
+/* File: armv5te/TEMPLATE_RETURN_PROF.S */
+#define TEMPLATE_INLINE_PROFILING
+/* File: armv5te/TEMPLATE_RETURN.S */
+    /*
+     * Unwind a frame from the Dalvik stack for compiled OP_RETURN_XXX.
+     * If the stored value in returnAddr
+     * is non-zero, the caller is compiled by the JIT thus return to the
+     * address in the code cache following the invoke instruction. Otherwise
+     * return to the special dvmJitToInterpNoChain entry point.
+     */
+#if defined(TEMPLATE_INLINE_PROFILING)
+    stmfd   sp!, {r0-r2,lr}             @ preserve live registers
+    mov     r0, r6
+    @ r0=rSELF
+    mov     lr, pc
+    ldr     pc, .LdvmFastMethodTraceExit
+    ldmfd   sp!, {r0-r2,lr}             @ restore live registers
+#endif
+    SAVEAREA_FROM_FP(r0, rFP)           @ r0<- saveArea (old)
+    ldr     r10, [r0, #offStackSaveArea_prevFrame] @ r10<- saveArea->prevFrame
+    ldrb    r8, [rSELF, #offThread_breakFlags] @ r8<- breakFlags
+    ldr     rPC, [r0, #offStackSaveArea_savedPc] @ rPC<- saveArea->savedPc
+#if !defined(WITH_SELF_VERIFICATION)
+    ldr     r9,  [r0, #offStackSaveArea_returnAddr] @ r9<- chaining cell ret
+#else
+    mov     r9, #0                      @ disable chaining
+#endif
+    ldr     r2, [r10, #(offStackSaveArea_method - sizeofStackSaveArea)]
+                                        @ r2<- method we're returning to
+    cmp     r2, #0                      @ break frame?
+#if !defined(WITH_SELF_VERIFICATION)
+    beq     1f                          @ bail to interpreter
+#else
+    blxeq   lr                          @ punt to interpreter and compare state
+#endif
+    ldr     r1, .LdvmJitToInterpNoChainNoProfile @ defined in footer.S
+    mov     rFP, r10                    @ publish new FP
+    ldr     r10, [r2, #offMethod_clazz] @ r10<- method->clazz
+
+    str     r2, [rSELF, #offThread_method]@ self->method = newSave->method
+    ldr     r0, [r10, #offClassObject_pDvmDex] @ r0<- method->clazz->pDvmDex
+    str     rFP, [rSELF, #offThread_curFrame] @ curFrame = fp
+    add     rPC, rPC, #6                @ publish new rPC (advance 6 bytes)
+    str     r0, [rSELF, #offThread_methodClassDex]
+    cmp     r8, #0                      @ check the break flags
+    movne   r9, #0                      @ clear the chaining cell address
+    str     r9, [rSELF, #offThread_inJitCodeCache] @ in code cache or not
+    cmp     r9, #0                      @ chaining cell exists?
+    blxne   r9                          @ jump to the chaining cell
+#if defined(WITH_JIT_TUNING)
+    mov     r0, #kCallsiteInterpreted
+#endif
+    mov     pc, r1                      @ callsite is interpreted
+1:
+    mov     r0, #0
+    str     r0, [rSELF, #offThread_inJitCodeCache] @ reset inJitCodeCache
+    stmia   rSELF, {rPC, rFP}           @ SAVE_PC_FP_TO_SELF()
+    ldr     r2, .LdvmMterpStdBail       @ defined in footer.S
+    mov     r0, rSELF                   @ Expecting rSELF in r0
+    blx     r2                          @ exit the interpreter
+
+#undef TEMPLATE_INLINE_PROFILING
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_INVOKE_METHOD_NO_OPT_PROF
+dvmCompiler_TEMPLATE_INVOKE_METHOD_NO_OPT_PROF:
+/* File: armv5te/TEMPLATE_INVOKE_METHOD_NO_OPT_PROF.S */
+#define TEMPLATE_INLINE_PROFILING
+/* File: armv5te/TEMPLATE_INVOKE_METHOD_NO_OPT.S */
+    /*
+     * For polymorphic callsites - setup the Dalvik frame and load Dalvik PC
+     * into rPC then jump to dvmJitToInterpNoChain to dispatch the
+     * runtime-resolved callee.
+     */
+    @ r0 = methodToCall, r1 = returnCell, rPC = dalvikCallsite
+    ldrh    r7, [r0, #offMethod_registersSize]  @ r7<- methodToCall->regsSize
+    ldrh    r2, [r0, #offMethod_outsSize]  @ r2<- methodToCall->outsSize
+    ldr     r9, [rSELF, #offThread_interpStackEnd]    @ r9<- interpStackEnd
+    ldrb    r8, [rSELF, #offThread_breakFlags] @ r8<- breakFlags
+    add     r3, r1, #1  @ Thumb addr is odd
+    SAVEAREA_FROM_FP(r1, rFP)           @ r1<- stack save area
+    sub     r1, r1, r7, lsl #2          @ r1<- newFp (old savearea - regsSize)
+    SAVEAREA_FROM_FP(r10, r1)           @ r10<- stack save area
+    sub     r10, r10, r2, lsl #2        @ r10<- bottom (newsave - outsSize)
+    cmp     r10, r9                     @ bottom < interpStackEnd?
+    bxlo    lr                          @ return to raise stack overflow excep.
+    @ r1 = newFP, r0 = methodToCall, r3 = returnCell, rPC = dalvikCallsite
+    ldr     r9, [r0, #offMethod_clazz]      @ r9<- method->clazz
+    ldr     r10, [r0, #offMethod_accessFlags] @ r10<- methodToCall->accessFlags
+    str     rPC, [rFP, #(offStackSaveArea_currentPc - sizeofStackSaveArea)]
+    str     rPC, [r1, #(offStackSaveArea_savedPc - sizeofStackSaveArea)]
+    ldr     rPC, [r0, #offMethod_insns]     @ rPC<- methodToCall->insns
+
+
+    @ set up newSaveArea
+    str     rFP, [r1, #(offStackSaveArea_prevFrame - sizeofStackSaveArea)]
+    str     r3, [r1, #(offStackSaveArea_returnAddr - sizeofStackSaveArea)]
+    str     r0, [r1, #(offStackSaveArea_method - sizeofStackSaveArea)]
+    cmp     r8, #0                      @ breakFlags != 0
+    bxne    lr                          @ bail to the interpreter
+    tst     r10, #ACC_NATIVE
+#if !defined(WITH_SELF_VERIFICATION)
+    bne     .LinvokeNative
+#else
+    bxne    lr                          @ bail to the interpreter
+#endif
+
+    ldr     r10, .LdvmJitToInterpTraceSelectNoChain
+    ldr     r3, [r9, #offClassObject_pDvmDex] @ r3<- method->clazz->pDvmDex
+
+    @ Update "thread" values for the new method
+    str     r0, [rSELF, #offThread_method]    @ self->method = methodToCall
+    str     r3, [rSELF, #offThread_methodClassDex] @ self->methodClassDex = ...
+    mov     rFP, r1                         @ fp = newFp
+    str     rFP, [rSELF, #offThread_curFrame]  @ curFrame = newFp
+#if defined(TEMPLATE_INLINE_PROFILING)
+    stmfd   sp!, {r0-r3}                    @ preserve r0-r3
+    mov     r1, r6
+    @ r0=methodToCall, r1=rSELF
+    mov     lr, pc
+    ldr     pc, .LdvmFastMethodTraceEnter
+    ldmfd   sp!, {r0-r3}                    @ restore r0-r3
+#endif
+
+    @ Start executing the callee
+#if defined(WITH_JIT_TUNING)
+    mov     r0, #kInlineCacheMiss
+#endif
+    mov     pc, r10                         @ dvmJitToInterpTraceSelectNoChain
+
+#undef TEMPLATE_INLINE_PROFILING
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_INVOKE_METHOD_CHAIN_PROF
+dvmCompiler_TEMPLATE_INVOKE_METHOD_CHAIN_PROF:
+/* File: armv5te/TEMPLATE_INVOKE_METHOD_CHAIN_PROF.S */
+#define TEMPLATE_INLINE_PROFILING
+/* File: armv5te/TEMPLATE_INVOKE_METHOD_CHAIN.S */
+    /*
+     * For monomorphic callsite, setup the Dalvik frame and return to the
+     * Thumb code through the link register to transfer control to the callee
+     * method through a dedicated chaining cell.
+     */
+    @ r0 = methodToCall, r1 = returnCell, r2 = methodToCall->outsSize
+    @ rPC = dalvikCallsite, r7 = methodToCall->registersSize
+    @ methodToCall is guaranteed to be non-native
+.LinvokeChainProf:
+    ldr     r9, [rSELF, #offThread_interpStackEnd]    @ r9<- interpStackEnd
+    ldrb    r8, [rSELF, #offThread_breakFlags]        @ r8<- breakFlags
+    add     r3, r1, #1  @ Thumb addr is odd
+    SAVEAREA_FROM_FP(r1, rFP)           @ r1<- stack save area
+    sub     r1, r1, r7, lsl #2          @ r1<- newFp (old savearea - regsSize)
+    SAVEAREA_FROM_FP(r10, r1)           @ r10<- stack save area
+    add     r12, lr, #2                 @ setup the punt-to-interp address
+    sub     r10, r10, r2, lsl #2        @ r10<- bottom (newsave - outsSize)
+    cmp     r10, r9                     @ bottom < interpStackEnd?
+    bxlo    r12                         @ return to raise stack overflow excep.
+    @ r1 = newFP, r0 = methodToCall, r3 = returnCell, rPC = dalvikCallsite
+    ldr     r9, [r0, #offMethod_clazz]      @ r9<- method->clazz
+    str     rPC, [rFP, #(offStackSaveArea_currentPc - sizeofStackSaveArea)]
+    str     rPC, [r1, #(offStackSaveArea_savedPc - sizeofStackSaveArea)]
+
+    @ set up newSaveArea
+    str     rFP, [r1, #(offStackSaveArea_prevFrame - sizeofStackSaveArea)]
+    str     r3, [r1, #(offStackSaveArea_returnAddr - sizeofStackSaveArea)]
+    str     r0, [r1, #(offStackSaveArea_method - sizeofStackSaveArea)]
+    cmp     r8, #0                      @ breakFlags != 0
+    bxne    r12                         @ bail to the interpreter
+
+    ldr     r3, [r9, #offClassObject_pDvmDex] @ r3<- method->clazz->pDvmDex
+
+    @ Update "thread" values for the new method
+    str     r0, [rSELF, #offThread_method]    @ self->method = methodToCall
+    str     r3, [rSELF, #offThread_methodClassDex] @ self->methodClassDex = ...
+    mov     rFP, r1                         @ fp = newFp
+    str     rFP, [rSELF, #offThread_curFrame]  @ curFrame = newFp
+#if defined(TEMPLATE_INLINE_PROFILING)
+    stmfd   sp!, {r0-r2,lr}             @ preserve clobbered live registers
+    mov     r1, r6
+    @ r0=methodToCall, r1=rSELF
+    mov     lr, pc
+    ldr     pc, .LdvmFastMethodTraceEnter
+    ldmfd   sp!, {r0-r2,lr}             @ restore registers
+#endif
+
+    bx      lr                              @ return to the callee-chaining cell
+
+#undef TEMPLATE_INLINE_PROFILING
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_INVOKE_METHOD_PREDICTED_CHAIN_PROF
+dvmCompiler_TEMPLATE_INVOKE_METHOD_PREDICTED_CHAIN_PROF:
+/* File: armv5te/TEMPLATE_INVOKE_METHOD_PREDICTED_CHAIN_PROF.S */
+#define TEMPLATE_INLINE_PROFILING
+/* File: armv5te/TEMPLATE_INVOKE_METHOD_PREDICTED_CHAIN.S */
+    /*
+     * For polymorphic callsite, check whether the cached class pointer matches
+     * the current one. If so setup the Dalvik frame and return to the
+     * Thumb code through the link register to transfer control to the callee
+     * method through a dedicated chaining cell.
+     *
+     * The predicted chaining cell is declared in ArmLIR.h with the
+     * following layout:
+     *
+     *  typedef struct PredictedChainingCell {
+     *      u4 branch;
+     *      const ClassObject *clazz;
+     *      const Method *method;
+     *      u4 counter;
+     *  } PredictedChainingCell;
+     *
+     * Upon returning to the callsite:
+     *    - lr  : to branch to the chaining cell
+     *    - lr+2: to punt to the interpreter
+     *    - lr+4: to fully resolve the callee and may rechain.
+     *            r3 <- class
+     *            r9 <- counter
+     */
+    @ r0 = this, r1 = returnCell, r2 = predictedChainCell, rPC = dalvikCallsite
+    ldr     r3, [r0, #offObject_clazz]  @ r3 <- this->class
+    ldr     r8, [r2, #4]    @ r8 <- predictedChainCell->clazz
+    ldr     r0, [r2, #8]    @ r0 <- predictedChainCell->method
+    ldr     r9, [rSELF, #offThread_icRechainCount] @ r1 <- shared rechainCount
+    cmp     r3, r8          @ predicted class == actual class?
+#if defined(WITH_JIT_TUNING)
+    ldr     r7, .LdvmICHitCount
+#if defined(WORKAROUND_CORTEX_A9_745320)
+    /* Don't use conditional loads if the HW defect exists */
+    bne     101f
+    ldr     r10, [r7, #0]
+101:
+#else
+    ldreq   r10, [r7, #0]
+#endif
+    add     r10, r10, #1
+    streq   r10, [r7, #0]
+#endif
+    ldreqh  r7, [r0, #offMethod_registersSize]  @ r7<- methodToCall->regsSize
+    ldreqh  r2, [r0, #offMethod_outsSize]  @ r2<- methodToCall->outsSize
+    beq     .LinvokeChainProf   @ predicted chain is valid
+    ldr     r7, [r3, #offClassObject_vtable] @ r7 <- this->class->vtable
+    cmp     r8, #0          @ initialized class or not
+    moveq   r1, #0
+    subne   r1, r9, #1      @ count--
+    strne   r1, [rSELF, #offThread_icRechainCount]  @ write back to thread
+    add     lr, lr, #4      @ return to fully-resolve landing pad
+    /*
+     * r1 <- count
+     * r2 <- &predictedChainCell
+     * r3 <- this->class
+     * r4 <- dPC
+     * r7 <- this->class->vtable
+     */
+    bx      lr
+
+#undef TEMPLATE_INLINE_PROFILING
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_INVOKE_METHOD_NATIVE_PROF
+dvmCompiler_TEMPLATE_INVOKE_METHOD_NATIVE_PROF:
+/* File: armv5te/TEMPLATE_INVOKE_METHOD_NATIVE_PROF.S */
+#define TEMPLATE_INLINE_PROFILING
+/* File: armv5te/TEMPLATE_INVOKE_METHOD_NATIVE.S */
+    @ r0 = methodToCall, r1 = returnCell, rPC = dalvikCallsite
+    @ r7 = methodToCall->registersSize
+    ldr     r9, [rSELF, #offThread_interpStackEnd]    @ r9<- interpStackEnd
+    ldrb    r8, [rSELF, #offThread_breakFlags]        @ r8<- breakFlags
+    add     r3, r1, #1  @ Thumb addr is odd
+    SAVEAREA_FROM_FP(r1, rFP)           @ r1<- stack save area
+    sub     r1, r1, r7, lsl #2          @ r1<- newFp (old savearea - regsSize)
+    SAVEAREA_FROM_FP(r10, r1)           @ r10<- stack save area
+    cmp     r10, r9                     @ bottom < interpStackEnd?
+    bxlo    lr                          @ return to raise stack overflow excep.
+    @ r1 = newFP, r0 = methodToCall, r3 = returnCell, rPC = dalvikCallsite
+    str     rPC, [rFP, #(offStackSaveArea_currentPc - sizeofStackSaveArea)]
+    str     rPC, [r1, #(offStackSaveArea_savedPc - sizeofStackSaveArea)]
+
+    @ set up newSaveArea
+    str     rFP, [r1, #(offStackSaveArea_prevFrame - sizeofStackSaveArea)]
+    str     r3, [r1, #(offStackSaveArea_returnAddr - sizeofStackSaveArea)]
+    str     r0, [r1, #(offStackSaveArea_method - sizeofStackSaveArea)]
+    cmp     r8, #0                      @ breakFlags != 0
+    ldr     r8, [r0, #offMethod_nativeFunc] @ r8<- method->nativeFunc
+#if !defined(WITH_SELF_VERIFICATION)
+    bxne    lr                          @ bail to the interpreter
+#else
+    bx      lr                          @ bail to interpreter unconditionally
+#endif
+
+    @ go ahead and transfer control to the native code
+    ldr     r9, [rSELF, #offThread_jniLocal_topCookie]@r9<-thread->localRef->...
+    mov     r2, #0
+    str     r1, [rSELF, #offThread_curFrame]   @ curFrame = newFp
+    str     r2, [rSELF, #offThread_inJitCodeCache] @ not in the jit code cache
+    str     r9, [r1, #(offStackSaveArea_localRefCookie - sizeofStackSaveArea)]
+                                        @ newFp->localRefCookie=top
+    SAVEAREA_FROM_FP(r10, r1)           @ r10<- new stack save area
+
+    mov     r2, r0                        @ arg2<- methodToCall
+    mov     r0, r1                        @ arg0<- newFP
+    add     r1, rSELF, #offThread_retval  @ arg1<- &retval
+    mov     r3, rSELF                     @ arg3<- self
+#if defined(TEMPLATE_INLINE_PROFILING)
+    @ r2=methodToCall, r6=rSELF
+    stmfd   sp!, {r2,r6}                @ to be consumed after JNI return
+    stmfd   sp!, {r0-r3}                @ preserve r0-r3
+    mov     r0, r2
+    mov     r1, r6
+    @ r0=JNIMethod, r1=rSELF
+    mov     lr, pc
+    ldr     pc, .LdvmFastMethodTraceEnter
+    ldmfd   sp!, {r0-r3}                @ restore r0-r3
+#endif
+
+    blx     r8                          @ off to the native code
+
+#if defined(TEMPLATE_INLINE_PROFILING)
+    ldmfd   sp!, {r0-r1}                @ restore r2 and r6
+    @ r0=JNIMethod, r1=rSELF
+    mov     lr, pc
+    ldr     pc, .LdvmFastNativeMethodTraceExit
+#endif
+    @ native return; r10=newSaveArea
+    @ equivalent to dvmPopJniLocals
+    ldr     r2, [r10, #offStackSaveArea_returnAddr] @ r2 = chaining cell ret
+    ldr     r0, [r10, #offStackSaveArea_localRefCookie] @ r0<- saved->top
+    ldr     r1, [rSELF, #offThread_exception] @ check for exception
+    str     rFP, [rSELF, #offThread_curFrame]  @ curFrame = fp
+    cmp     r1, #0                      @ null?
+    str     r0, [rSELF, #offThread_jniLocal_topCookie] @ new top <- old top
+    ldr     r0, [rFP, #(offStackSaveArea_currentPc - sizeofStackSaveArea)]
+
+    @ r0 = dalvikCallsitePC
+    bne     .LhandleException           @ no, handle exception
+
+    str     r2, [rSELF, #offThread_inJitCodeCache] @ set the mode properly
+    cmp     r2, #0                      @ return chaining cell still exists?
+    bxne    r2                          @ yes - go ahead
+
+    @ continue executing the next instruction through the interpreter
+    ldr     r1, .LdvmJitToInterpTraceSelectNoChain @ defined in footer.S
+    add     rPC, r0, #6                 @ reconstruct new rPC (advance 6 bytes)
+#if defined(WITH_JIT_TUNING)
+    mov     r0, #kCallsiteInterpreted
+#endif
+    mov     pc, r1
+
+#undef TEMPLATE_INLINE_PROFILING
+
+    .size   dvmCompilerTemplateStart, .-dvmCompilerTemplateStart
+/* File: armv5te/footer.S */
+/*
+ * ===========================================================================
+ *  Common subroutines and data
+ * ===========================================================================
+ */
+
+    .text
+    .align  2
+.LinvokeNative:
+    @ Prep for the native call
+    @ r1 = newFP, r0 = methodToCall
+    mov     r2, #0
+    ldr     r9, [rSELF, #offThread_jniLocal_topCookie]@r9<-thread->localRef->...
+    str     r2, [rSELF, #offThread_inJitCodeCache] @ not in jit code cache
+    str     r1, [rSELF, #offThread_curFrame]   @ curFrame = newFp
+    str     r9, [r1, #(offStackSaveArea_localRefCookie - sizeofStackSaveArea)]
+                                        @ newFp->localRefCookie=top
+    ldrh    lr, [rSELF, #offThread_subMode]
+    SAVEAREA_FROM_FP(r10, r1)           @ r10<- new stack save area
+
+    mov     r2, r0                      @ r2<- methodToCall
+    mov     r0, r1                      @ r0<- newFP
+    add     r1, rSELF, #offThread_retval  @ r1<- &retval
+    mov     r3, rSELF                   @ arg3<- self
+    ands    lr, #kSubModeMethodTrace
+    beq     121f                        @ hop if not profiling
+    @ r2: methodToCall, r6: rSELF
+    stmfd   sp!, {r2,r6}
+    stmfd   sp!, {r0-r3}
+    mov     r0, r2
+    mov     r1, r6
+    mov     lr, pc
+    ldr     pc, .LdvmFastMethodTraceEnter
+    ldmfd   sp!, {r0-r3}
+
+    mov     lr, pc
+    ldr     pc, [r2, #offMethod_nativeFunc]
+
+    ldmfd   sp!, {r0-r1}
+    mov     lr, pc
+    ldr     pc, .LdvmFastNativeMethodTraceExit
+    b       212f
+121:
+    mov     lr, pc
+    ldr     pc, [r2, #offMethod_nativeFunc]
+212:
+
+    @ native return; r10=newSaveArea
+    @ equivalent to dvmPopJniLocals
+    ldr     r2, [r10, #offStackSaveArea_returnAddr] @ r2 = chaining cell ret
+    ldr     r0, [r10, #offStackSaveArea_localRefCookie] @ r0<- saved->top
+    ldr     r1, [rSELF, #offThread_exception] @ check for exception
+    str     rFP, [rSELF, #offThread_curFrame]  @ curFrame = fp
+    cmp     r1, #0                      @ null?
+    str     r0, [rSELF, #offThread_jniLocal_topCookie] @ new top <- old top
+    ldr     r0, [r10, #offStackSaveArea_savedPc] @ reload rPC
+
+    @ r0 = dalvikCallsitePC
+    bne     .LhandleException           @ no, handle exception
+
+    str     r2, [rSELF, #offThread_inJitCodeCache] @ set the new mode
+    cmp     r2, #0                      @ return chaining cell still exists?
+    bxne    r2                          @ yes - go ahead
+
+    @ continue executing the next instruction through the interpreter
+    ldr     r1, .LdvmJitToInterpTraceSelectNoChain @ defined in footer.S
+    add     rPC, r0, #6                 @ reconstruct new rPC (advance 6 bytes)
+#if defined(WITH_JIT_TUNING)
+    mov     r0, #kCallsiteInterpreted
+#endif
+    mov     pc, r1
+
+/*
+ * On entry:
+ * r0  Faulting Dalvik PC
+ */
+.LhandleException:
+#if defined(WITH_SELF_VERIFICATION)
+    ldr     pc, .LdeadFood @ should not see this under self-verification mode
+.LdeadFood:
+    .word   0xdeadf00d
+#endif
+    mov     r2, #0
+    str     r2, [rSELF, #offThread_inJitCodeCache] @ in interpreter land
+    ldr     r1, .LdvmMterpCommonExceptionThrown @ PIC way of getting &func
+    ldr     rIBASE, .LdvmAsmInstructionStart    @ same as above
+    mov     rPC, r0                 @ reload the faulting Dalvik address
+    mov     pc, r1                  @ branch to dvmMterpCommonExceptionThrown
+
+    .align  2
+.LdvmAsmInstructionStart:
+    .word   dvmAsmInstructionStart
+.LdvmJitToInterpNoChainNoProfile:
+    .word   dvmJitToInterpNoChainNoProfile
+.LdvmJitToInterpTraceSelectNoChain:
+    .word   dvmJitToInterpTraceSelectNoChain
+.LdvmJitToInterpNoChain:
+    .word   dvmJitToInterpNoChain
+.LdvmMterpStdBail:
+    .word   dvmMterpStdBail
+.LdvmMterpCommonExceptionThrown:
+    .word   dvmMterpCommonExceptionThrown
+.LdvmLockObject:
+    .word   dvmLockObject
+.LdvmJitTraceProfilingOff:
+    .word   dvmJitTraceProfilingOff
+#if defined(WITH_JIT_TUNING)
+.LdvmICHitCount:
+    .word   gDvmICHitCount
+#endif
+#if defined(WITH_SELF_VERIFICATION)
+.LdvmSelfVerificationMemOpDecode:
+    .word   dvmSelfVerificationMemOpDecode
+#endif
+.LdvmFastMethodTraceEnter:
+    .word   dvmFastMethodTraceEnter
+.LdvmFastNativeMethodTraceExit:
+    .word   dvmFastNativeMethodTraceExit
+.LdvmFastMethodTraceExit:
+    .word   dvmFastMethodTraceExit
+.L__aeabi_cdcmple:
+    .word   __aeabi_cdcmple
+.L__aeabi_cfcmple:
+    .word   __aeabi_cfcmple
+
+    .global dmvCompilerTemplateEnd
+dmvCompilerTemplateEnd:
+
+#endif /* WITH_JIT */
+
diff --git a/vm/compiler/template_notaint/out/CompilerTemplateAsm-armv7-a-neon.S b/vm/compiler/template_notaint/out/CompilerTemplateAsm-armv7-a-neon.S
new file mode 100644
index 0000000..ba798e0
--- /dev/null
+++ b/vm/compiler/template_notaint/out/CompilerTemplateAsm-armv7-a-neon.S
@@ -0,0 +1,1981 @@
+/*
+ * This file was generated automatically by gen-template.py for 'armv7-a-neon'.
+ *
+ * --> DO NOT EDIT <--
+ */
+
+/* File: armv5te/header.S */
+/*
+ * Copyright (C) 2008 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#if defined(WITH_JIT)
+
+/*
+ * ARMv5 definitions and declarations.
+ */
+
+/*
+ARM EABI general notes:
+
+r0-r3 hold first 4 args to a method; they are not preserved across method calls
+r4-r8 are available for general use
+r9 is given special treatment in some situations, but not for us
+r10 (sl) seems to be generally available
+r11 (fp) is used by gcc (unless -fomit-frame-pointer is set)
+r12 (ip) is scratch -- not preserved across method calls
+r13 (sp) should be managed carefully in case a signal arrives
+r14 (lr) must be preserved
+r15 (pc) can be tinkered with directly
+
+r0 holds returns of <= 4 bytes
+r0-r1 hold returns of 8 bytes, low word in r0
+
+Callee must save/restore r4+ (except r12) if it modifies them.
+
+Stack is "full descending".  Only the arguments that don't fit in the first 4
+registers are placed on the stack.  "sp" points at the first stacked argument
+(i.e. the 5th arg).
+
+VFP: single-precision results in s0, double-precision results in d0.
+
+In the EABI, "sp" must be 64-bit aligned on entry to a function, and any
+64-bit quantities (long long, double) must be 64-bit aligned.
+*/
+
+/*
+JIT and ARM notes:
+
+The following registers have fixed assignments:
+
+  reg nick      purpose
+  r5  rFP       interpreted frame pointer, used for accessing locals and args
+  r6  rSELF     thread pointer
+
+The following registers have fixed assignments in mterp but are scratch
+registers in compiled code
+
+  reg nick      purpose
+  r4  rPC       interpreted program counter, used for fetching instructions
+  r7  rINST     first 16-bit code unit of current instruction
+  r8  rIBASE    interpreted instruction base pointer, used for computed goto
+
+Macros are provided for common operations.  Each macro MUST emit only
+one instruction to make instruction-counting easier.  They MUST NOT alter
+unspecified registers or condition codes.
+*/
+
+/* single-purpose registers, given names for clarity */
+#define rPC     r4
+#define rFP     r5
+#define rSELF   r6
+#define rINST   r7
+#define rIBASE  r8
+
+/*
+ * Given a frame pointer, find the stack save area.
+ *
+ * In C this is "((StackSaveArea*)(_fp) -1)".
+ */
+#define SAVEAREA_FROM_FP(_reg, _fpreg) \
+    sub     _reg, _fpreg, #sizeofStackSaveArea
+
+#define EXPORT_PC() \
+    str     rPC, [rFP, #(-sizeofStackSaveArea + offStackSaveArea_currentPc)]
+
+/*
+ * This is a #include, not a %include, because we want the C pre-processor
+ * to expand the macros into assembler assignment statements.
+ */
+#include "../../../mterp/common/asm-constants.h"
+
+/* File: armv5te-vfp/platform.S */
+/*
+ * ===========================================================================
+ *  CPU-version-specific defines and utility
+ * ===========================================================================
+ */
+
+
+    .global dvmCompilerTemplateStart
+    .type   dvmCompilerTemplateStart, %function
+    .text
+
+dvmCompilerTemplateStart:
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_CMP_LONG
+dvmCompiler_TEMPLATE_CMP_LONG:
+/* File: armv5te/TEMPLATE_CMP_LONG.S */
+    /*
+     * Compare two 64-bit values.  Puts 0, 1, or -1 into the destination
+     * register based on the results of the comparison.
+     *
+     * We load the full values with LDM, but in practice many values could
+     * be resolved by only looking at the high word.  This could be made
+     * faster or slower by splitting the LDM into a pair of LDRs.
+     *
+     * If we just wanted to set condition flags, we could do this:
+     *  subs    ip, r0, r2
+     *  sbcs    ip, r1, r3
+     *  subeqs  ip, r0, r2
+     * Leaving { <0, 0, >0 } in ip.  However, we have to set it to a specific
+     * integer value, which we can do with 2 conditional mov/mvn instructions
+     * (set 1, set -1; if they're equal we already have 0 in ip), giving
+     * us a constant 5-cycle path plus a branch at the end to the
+     * instruction epilogue code.  The multi-compare approach below needs
+     * 2 or 3 cycles + branch if the high word doesn't match, 6 + branch
+     * in the worst case (the 64-bit values are equal).
+     */
+    /* cmp-long vAA, vBB, vCC */
+    cmp     r1, r3                      @ compare (vBB+1, vCC+1)
+    blt     .LTEMPLATE_CMP_LONG_less            @ signed compare on high part
+    bgt     .LTEMPLATE_CMP_LONG_greater
+    subs    r0, r0, r2                  @ r0<- r0 - r2
+    bxeq     lr
+    bhi     .LTEMPLATE_CMP_LONG_greater         @ unsigned compare on low part
+.LTEMPLATE_CMP_LONG_less:
+    mvn     r0, #0                      @ r0<- -1
+    bx      lr
+.LTEMPLATE_CMP_LONG_greater:
+    mov     r0, #1                      @ r0<- 1
+    bx      lr
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_RETURN
+dvmCompiler_TEMPLATE_RETURN:
+/* File: armv5te/TEMPLATE_RETURN.S */
+    /*
+     * Unwind a frame from the Dalvik stack for compiled OP_RETURN_XXX.
+     * If the stored value in returnAddr
+     * is non-zero, the caller is compiled by the JIT thus return to the
+     * address in the code cache following the invoke instruction. Otherwise
+     * return to the special dvmJitToInterpNoChain entry point.
+     */
+#if defined(TEMPLATE_INLINE_PROFILING)
+    stmfd   sp!, {r0-r2,lr}             @ preserve live registers
+    mov     r0, r6
+    @ r0=rSELF
+    mov     lr, pc
+    ldr     pc, .LdvmFastMethodTraceExit
+    ldmfd   sp!, {r0-r2,lr}             @ restore live registers
+#endif
+    SAVEAREA_FROM_FP(r0, rFP)           @ r0<- saveArea (old)
+    ldr     r10, [r0, #offStackSaveArea_prevFrame] @ r10<- saveArea->prevFrame
+    ldrb    r8, [rSELF, #offThread_breakFlags] @ r8<- breakFlags
+    ldr     rPC, [r0, #offStackSaveArea_savedPc] @ rPC<- saveArea->savedPc
+#if !defined(WITH_SELF_VERIFICATION)
+    ldr     r9,  [r0, #offStackSaveArea_returnAddr] @ r9<- chaining cell ret
+#else
+    mov     r9, #0                      @ disable chaining
+#endif
+    ldr     r2, [r10, #(offStackSaveArea_method - sizeofStackSaveArea)]
+                                        @ r2<- method we're returning to
+    cmp     r2, #0                      @ break frame?
+#if !defined(WITH_SELF_VERIFICATION)
+    beq     1f                          @ bail to interpreter
+#else
+    blxeq   lr                          @ punt to interpreter and compare state
+#endif
+    ldr     r1, .LdvmJitToInterpNoChainNoProfile @ defined in footer.S
+    mov     rFP, r10                    @ publish new FP
+    ldr     r10, [r2, #offMethod_clazz] @ r10<- method->clazz
+
+    str     r2, [rSELF, #offThread_method]@ self->method = newSave->method
+    ldr     r0, [r10, #offClassObject_pDvmDex] @ r0<- method->clazz->pDvmDex
+    str     rFP, [rSELF, #offThread_curFrame] @ curFrame = fp
+    add     rPC, rPC, #6                @ publish new rPC (advance 6 bytes)
+    str     r0, [rSELF, #offThread_methodClassDex]
+    cmp     r8, #0                      @ check the break flags
+    movne   r9, #0                      @ clear the chaining cell address
+    str     r9, [rSELF, #offThread_inJitCodeCache] @ in code cache or not
+    cmp     r9, #0                      @ chaining cell exists?
+    blxne   r9                          @ jump to the chaining cell
+#if defined(WITH_JIT_TUNING)
+    mov     r0, #kCallsiteInterpreted
+#endif
+    mov     pc, r1                      @ callsite is interpreted
+1:
+    mov     r0, #0
+    str     r0, [rSELF, #offThread_inJitCodeCache] @ reset inJitCodeCache
+    stmia   rSELF, {rPC, rFP}           @ SAVE_PC_FP_TO_SELF()
+    ldr     r2, .LdvmMterpStdBail       @ defined in footer.S
+    mov     r0, rSELF                   @ Expecting rSELF in r0
+    blx     r2                          @ exit the interpreter
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_INVOKE_METHOD_NO_OPT
+dvmCompiler_TEMPLATE_INVOKE_METHOD_NO_OPT:
+/* File: armv5te/TEMPLATE_INVOKE_METHOD_NO_OPT.S */
+    /*
+     * For polymorphic callsites - setup the Dalvik frame and load Dalvik PC
+     * into rPC then jump to dvmJitToInterpNoChain to dispatch the
+     * runtime-resolved callee.
+     */
+    @ r0 = methodToCall, r1 = returnCell, rPC = dalvikCallsite
+    ldrh    r7, [r0, #offMethod_registersSize]  @ r7<- methodToCall->regsSize
+    ldrh    r2, [r0, #offMethod_outsSize]  @ r2<- methodToCall->outsSize
+    ldr     r9, [rSELF, #offThread_interpStackEnd]    @ r9<- interpStackEnd
+    ldrb    r8, [rSELF, #offThread_breakFlags] @ r8<- breakFlags
+    add     r3, r1, #1  @ Thumb addr is odd
+    SAVEAREA_FROM_FP(r1, rFP)           @ r1<- stack save area
+    sub     r1, r1, r7, lsl #2          @ r1<- newFp (old savearea - regsSize)
+    SAVEAREA_FROM_FP(r10, r1)           @ r10<- stack save area
+    sub     r10, r10, r2, lsl #2        @ r10<- bottom (newsave - outsSize)
+    cmp     r10, r9                     @ bottom < interpStackEnd?
+    bxlo    lr                          @ return to raise stack overflow excep.
+    @ r1 = newFP, r0 = methodToCall, r3 = returnCell, rPC = dalvikCallsite
+    ldr     r9, [r0, #offMethod_clazz]      @ r9<- method->clazz
+    ldr     r10, [r0, #offMethod_accessFlags] @ r10<- methodToCall->accessFlags
+    str     rPC, [rFP, #(offStackSaveArea_currentPc - sizeofStackSaveArea)]
+    str     rPC, [r1, #(offStackSaveArea_savedPc - sizeofStackSaveArea)]
+    ldr     rPC, [r0, #offMethod_insns]     @ rPC<- methodToCall->insns
+
+
+    @ set up newSaveArea
+    str     rFP, [r1, #(offStackSaveArea_prevFrame - sizeofStackSaveArea)]
+    str     r3, [r1, #(offStackSaveArea_returnAddr - sizeofStackSaveArea)]
+    str     r0, [r1, #(offStackSaveArea_method - sizeofStackSaveArea)]
+    cmp     r8, #0                      @ breakFlags != 0
+    bxne    lr                          @ bail to the interpreter
+    tst     r10, #ACC_NATIVE
+#if !defined(WITH_SELF_VERIFICATION)
+    bne     .LinvokeNative
+#else
+    bxne    lr                          @ bail to the interpreter
+#endif
+
+    ldr     r10, .LdvmJitToInterpTraceSelectNoChain
+    ldr     r3, [r9, #offClassObject_pDvmDex] @ r3<- method->clazz->pDvmDex
+
+    @ Update "thread" values for the new method
+    str     r0, [rSELF, #offThread_method]    @ self->method = methodToCall
+    str     r3, [rSELF, #offThread_methodClassDex] @ self->methodClassDex = ...
+    mov     rFP, r1                         @ fp = newFp
+    str     rFP, [rSELF, #offThread_curFrame]  @ curFrame = newFp
+#if defined(TEMPLATE_INLINE_PROFILING)
+    stmfd   sp!, {r0-r3}                    @ preserve r0-r3
+    mov     r1, r6
+    @ r0=methodToCall, r1=rSELF
+    mov     lr, pc
+    ldr     pc, .LdvmFastMethodTraceEnter
+    ldmfd   sp!, {r0-r3}                    @ restore r0-r3
+#endif
+
+    @ Start executing the callee
+#if defined(WITH_JIT_TUNING)
+    mov     r0, #kInlineCacheMiss
+#endif
+    mov     pc, r10                         @ dvmJitToInterpTraceSelectNoChain
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_INVOKE_METHOD_CHAIN
+dvmCompiler_TEMPLATE_INVOKE_METHOD_CHAIN:
+/* File: armv5te/TEMPLATE_INVOKE_METHOD_CHAIN.S */
+    /*
+     * For monomorphic callsite, setup the Dalvik frame and return to the
+     * Thumb code through the link register to transfer control to the callee
+     * method through a dedicated chaining cell.
+     */
+    @ r0 = methodToCall, r1 = returnCell, r2 = methodToCall->outsSize
+    @ rPC = dalvikCallsite, r7 = methodToCall->registersSize
+    @ methodToCall is guaranteed to be non-native
+.LinvokeChain:
+    ldr     r9, [rSELF, #offThread_interpStackEnd]    @ r9<- interpStackEnd
+    ldrb    r8, [rSELF, #offThread_breakFlags]        @ r8<- breakFlags
+    add     r3, r1, #1  @ Thumb addr is odd
+    SAVEAREA_FROM_FP(r1, rFP)           @ r1<- stack save area
+    sub     r1, r1, r7, lsl #2          @ r1<- newFp (old savearea - regsSize)
+    SAVEAREA_FROM_FP(r10, r1)           @ r10<- stack save area
+    add     r12, lr, #2                 @ setup the punt-to-interp address
+    sub     r10, r10, r2, lsl #2        @ r10<- bottom (newsave - outsSize)
+    cmp     r10, r9                     @ bottom < interpStackEnd?
+    bxlo    r12                         @ return to raise stack overflow excep.
+    @ r1 = newFP, r0 = methodToCall, r3 = returnCell, rPC = dalvikCallsite
+    ldr     r9, [r0, #offMethod_clazz]      @ r9<- method->clazz
+    str     rPC, [rFP, #(offStackSaveArea_currentPc - sizeofStackSaveArea)]
+    str     rPC, [r1, #(offStackSaveArea_savedPc - sizeofStackSaveArea)]
+
+    @ set up newSaveArea
+    str     rFP, [r1, #(offStackSaveArea_prevFrame - sizeofStackSaveArea)]
+    str     r3, [r1, #(offStackSaveArea_returnAddr - sizeofStackSaveArea)]
+    str     r0, [r1, #(offStackSaveArea_method - sizeofStackSaveArea)]
+    cmp     r8, #0                      @ breakFlags != 0
+    bxne    r12                         @ bail to the interpreter
+
+    ldr     r3, [r9, #offClassObject_pDvmDex] @ r3<- method->clazz->pDvmDex
+
+    @ Update "thread" values for the new method
+    str     r0, [rSELF, #offThread_method]    @ self->method = methodToCall
+    str     r3, [rSELF, #offThread_methodClassDex] @ self->methodClassDex = ...
+    mov     rFP, r1                         @ fp = newFp
+    str     rFP, [rSELF, #offThread_curFrame]  @ curFrame = newFp
+#if defined(TEMPLATE_INLINE_PROFILING)
+    stmfd   sp!, {r0-r2,lr}             @ preserve clobbered live registers
+    mov     r1, r6
+    @ r0=methodToCall, r1=rSELF
+    mov     lr, pc
+    ldr     pc, .LdvmFastMethodTraceEnter
+    ldmfd   sp!, {r0-r2,lr}             @ restore registers
+#endif
+
+    bx      lr                              @ return to the callee-chaining cell
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_INVOKE_METHOD_PREDICTED_CHAIN
+dvmCompiler_TEMPLATE_INVOKE_METHOD_PREDICTED_CHAIN:
+/* File: armv5te/TEMPLATE_INVOKE_METHOD_PREDICTED_CHAIN.S */
+    /*
+     * For polymorphic callsite, check whether the cached class pointer matches
+     * the current one. If so setup the Dalvik frame and return to the
+     * Thumb code through the link register to transfer control to the callee
+     * method through a dedicated chaining cell.
+     *
+     * The predicted chaining cell is declared in ArmLIR.h with the
+     * following layout:
+     *
+     *  typedef struct PredictedChainingCell {
+     *      u4 branch;
+     *      const ClassObject *clazz;
+     *      const Method *method;
+     *      u4 counter;
+     *  } PredictedChainingCell;
+     *
+     * Upon returning to the callsite:
+     *    - lr  : to branch to the chaining cell
+     *    - lr+2: to punt to the interpreter
+     *    - lr+4: to fully resolve the callee and may rechain.
+     *            r3 <- class
+     *            r9 <- counter
+     */
+    @ r0 = this, r1 = returnCell, r2 = predictedChainCell, rPC = dalvikCallsite
+    ldr     r3, [r0, #offObject_clazz]  @ r3 <- this->class
+    ldr     r8, [r2, #4]    @ r8 <- predictedChainCell->clazz
+    ldr     r0, [r2, #8]    @ r0 <- predictedChainCell->method
+    ldr     r9, [rSELF, #offThread_icRechainCount] @ r1 <- shared rechainCount
+    cmp     r3, r8          @ predicted class == actual class?
+#if defined(WITH_JIT_TUNING)
+    ldr     r7, .LdvmICHitCount
+#if defined(WORKAROUND_CORTEX_A9_745320)
+    /* Don't use conditional loads if the HW defect exists */
+    bne     101f
+    ldr     r10, [r7, #0]
+101:
+#else
+    ldreq   r10, [r7, #0]
+#endif
+    add     r10, r10, #1
+    streq   r10, [r7, #0]
+#endif
+    ldreqh  r7, [r0, #offMethod_registersSize]  @ r7<- methodToCall->regsSize
+    ldreqh  r2, [r0, #offMethod_outsSize]  @ r2<- methodToCall->outsSize
+    beq     .LinvokeChain   @ predicted chain is valid
+    ldr     r7, [r3, #offClassObject_vtable] @ r7 <- this->class->vtable
+    cmp     r8, #0          @ initialized class or not
+    moveq   r1, #0
+    subne   r1, r9, #1      @ count--
+    strne   r1, [rSELF, #offThread_icRechainCount]  @ write back to thread
+    add     lr, lr, #4      @ return to fully-resolve landing pad
+    /*
+     * r1 <- count
+     * r2 <- &predictedChainCell
+     * r3 <- this->class
+     * r4 <- dPC
+     * r7 <- this->class->vtable
+     */
+    bx      lr
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_INVOKE_METHOD_NATIVE
+dvmCompiler_TEMPLATE_INVOKE_METHOD_NATIVE:
+/* File: armv5te/TEMPLATE_INVOKE_METHOD_NATIVE.S */
+    @ r0 = methodToCall, r1 = returnCell, rPC = dalvikCallsite
+    @ r7 = methodToCall->registersSize
+    ldr     r9, [rSELF, #offThread_interpStackEnd]    @ r9<- interpStackEnd
+    ldrb    r8, [rSELF, #offThread_breakFlags]        @ r8<- breakFlags
+    add     r3, r1, #1  @ Thumb addr is odd
+    SAVEAREA_FROM_FP(r1, rFP)           @ r1<- stack save area
+    sub     r1, r1, r7, lsl #2          @ r1<- newFp (old savearea - regsSize)
+    SAVEAREA_FROM_FP(r10, r1)           @ r10<- stack save area
+    cmp     r10, r9                     @ bottom < interpStackEnd?
+    bxlo    lr                          @ return to raise stack overflow excep.
+    @ r1 = newFP, r0 = methodToCall, r3 = returnCell, rPC = dalvikCallsite
+    str     rPC, [rFP, #(offStackSaveArea_currentPc - sizeofStackSaveArea)]
+    str     rPC, [r1, #(offStackSaveArea_savedPc - sizeofStackSaveArea)]
+
+    @ set up newSaveArea
+    str     rFP, [r1, #(offStackSaveArea_prevFrame - sizeofStackSaveArea)]
+    str     r3, [r1, #(offStackSaveArea_returnAddr - sizeofStackSaveArea)]
+    str     r0, [r1, #(offStackSaveArea_method - sizeofStackSaveArea)]
+    cmp     r8, #0                      @ breakFlags != 0
+    ldr     r8, [r0, #offMethod_nativeFunc] @ r8<- method->nativeFunc
+#if !defined(WITH_SELF_VERIFICATION)
+    bxne    lr                          @ bail to the interpreter
+#else
+    bx      lr                          @ bail to interpreter unconditionally
+#endif
+
+    @ go ahead and transfer control to the native code
+    ldr     r9, [rSELF, #offThread_jniLocal_topCookie]@r9<-thread->localRef->...
+    mov     r2, #0
+    str     r1, [rSELF, #offThread_curFrame]   @ curFrame = newFp
+    str     r2, [rSELF, #offThread_inJitCodeCache] @ not in the jit code cache
+    str     r9, [r1, #(offStackSaveArea_localRefCookie - sizeofStackSaveArea)]
+                                        @ newFp->localRefCookie=top
+    SAVEAREA_FROM_FP(r10, r1)           @ r10<- new stack save area
+
+    mov     r2, r0                        @ arg2<- methodToCall
+    mov     r0, r1                        @ arg0<- newFP
+    add     r1, rSELF, #offThread_retval  @ arg1<- &retval
+    mov     r3, rSELF                     @ arg3<- self
+#if defined(TEMPLATE_INLINE_PROFILING)
+    @ r2=methodToCall, r6=rSELF
+    stmfd   sp!, {r2,r6}                @ to be consumed after JNI return
+    stmfd   sp!, {r0-r3}                @ preserve r0-r3
+    mov     r0, r2
+    mov     r1, r6
+    @ r0=JNIMethod, r1=rSELF
+    mov     lr, pc
+    ldr     pc, .LdvmFastMethodTraceEnter
+    ldmfd   sp!, {r0-r3}                @ restore r0-r3
+#endif
+
+    blx     r8                          @ off to the native code
+
+#if defined(TEMPLATE_INLINE_PROFILING)
+    ldmfd   sp!, {r0-r1}                @ restore r2 and r6
+    @ r0=JNIMethod, r1=rSELF
+    mov     lr, pc
+    ldr     pc, .LdvmFastNativeMethodTraceExit
+#endif
+    @ native return; r10=newSaveArea
+    @ equivalent to dvmPopJniLocals
+    ldr     r2, [r10, #offStackSaveArea_returnAddr] @ r2 = chaining cell ret
+    ldr     r0, [r10, #offStackSaveArea_localRefCookie] @ r0<- saved->top
+    ldr     r1, [rSELF, #offThread_exception] @ check for exception
+    str     rFP, [rSELF, #offThread_curFrame]  @ curFrame = fp
+    cmp     r1, #0                      @ null?
+    str     r0, [rSELF, #offThread_jniLocal_topCookie] @ new top <- old top
+    ldr     r0, [rFP, #(offStackSaveArea_currentPc - sizeofStackSaveArea)]
+
+    @ r0 = dalvikCallsitePC
+    bne     .LhandleException           @ no, handle exception
+
+    str     r2, [rSELF, #offThread_inJitCodeCache] @ set the mode properly
+    cmp     r2, #0                      @ return chaining cell still exists?
+    bxne    r2                          @ yes - go ahead
+
+    @ continue executing the next instruction through the interpreter
+    ldr     r1, .LdvmJitToInterpTraceSelectNoChain @ defined in footer.S
+    add     rPC, r0, #6                 @ reconstruct new rPC (advance 6 bytes)
+#if defined(WITH_JIT_TUNING)
+    mov     r0, #kCallsiteInterpreted
+#endif
+    mov     pc, r1
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_MUL_LONG
+dvmCompiler_TEMPLATE_MUL_LONG:
+/* File: armv5te/TEMPLATE_MUL_LONG.S */
+    /*
+     * Signed 64-bit integer multiply.
+     *
+     * For JIT: op1 in r0/r1, op2 in r2/r3, return in r0/r1
+     *
+     * Consider WXxYZ (r1r0 x r3r2) with a long multiply:
+     *        WX
+     *      x YZ
+     *  --------
+     *     ZW ZX
+     *  YW YX
+     *
+     * The low word of the result holds ZX, the high word holds
+     * (ZW+YX) + (the high overflow from ZX).  YW doesn't matter because
+     * it doesn't fit in the low 64 bits.
+     *
+     * Unlike most ARM math operations, multiply instructions have
+     * restrictions on using the same register more than once (Rd and Rm
+     * cannot be the same).
+     */
+    /* mul-long vAA, vBB, vCC */
+    mul     ip, r2, r1                  @  ip<- ZxW
+    umull   r9, r10, r2, r0             @  r9/r10 <- ZxX
+    mla     r2, r0, r3, ip              @  r2<- YxX + (ZxW)
+    add     r10, r2, r10                @  r10<- r10 + low(ZxW + (YxX))
+    mov     r0,r9
+    mov     r1,r10
+    bx      lr
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_SHL_LONG
+dvmCompiler_TEMPLATE_SHL_LONG:
+/* File: armv5te/TEMPLATE_SHL_LONG.S */
+    /*
+     * Long integer shift.  This is different from the generic 32/64-bit
+     * binary operations because vAA/vBB are 64-bit but vCC (the shift
+     * distance) is 32-bit.  Also, Dalvik requires us to ignore all but the low
+     * 6 bits.
+     */
+    /* shl-long vAA, vBB, vCC */
+    and     r2, r2, #63                 @ r2<- r2 & 0x3f
+    mov     r1, r1, asl r2              @  r1<- r1 << r2
+    rsb     r3, r2, #32                 @  r3<- 32 - r2
+    orr     r1, r1, r0, lsr r3          @  r1<- r1 | (r0 << (32-r2))
+    subs    ip, r2, #32                 @  ip<- r2 - 32
+    movpl   r1, r0, asl ip              @  if r2 >= 32, r1<- r0 << (r2-32)
+    mov     r0, r0, asl r2              @  r0<- r0 << r2
+    bx      lr
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_SHR_LONG
+dvmCompiler_TEMPLATE_SHR_LONG:
+/* File: armv5te/TEMPLATE_SHR_LONG.S */
+    /*
+     * Long integer shift.  This is different from the generic 32/64-bit
+     * binary operations because vAA/vBB are 64-bit but vCC (the shift
+     * distance) is 32-bit.  Also, Dalvik requires us to ignore all but the low
+     * 6 bits.
+     */
+    /* shr-long vAA, vBB, vCC */
+    and     r2, r2, #63                 @ r0<- r0 & 0x3f
+    mov     r0, r0, lsr r2              @  r0<- r2 >> r2
+    rsb     r3, r2, #32                 @  r3<- 32 - r2
+    orr     r0, r0, r1, asl r3          @  r0<- r0 | (r1 << (32-r2))
+    subs    ip, r2, #32                 @  ip<- r2 - 32
+    movpl   r0, r1, asr ip              @  if r2 >= 32, r0<-r1 >> (r2-32)
+    mov     r1, r1, asr r2              @  r1<- r1 >> r2
+    bx      lr
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_USHR_LONG
+dvmCompiler_TEMPLATE_USHR_LONG:
+/* File: armv5te/TEMPLATE_USHR_LONG.S */
+    /*
+     * Long integer shift.  This is different from the generic 32/64-bit
+     * binary operations because vAA/vBB are 64-bit but vCC (the shift
+     * distance) is 32-bit.  Also, Dalvik requires us to ignore all but the low
+     * 6 bits.
+     */
+    /* ushr-long vAA, vBB, vCC */
+    and     r2, r2, #63                 @ r0<- r0 & 0x3f
+    mov     r0, r0, lsr r2              @  r0<- r2 >> r2
+    rsb     r3, r2, #32                 @  r3<- 32 - r2
+    orr     r0, r0, r1, asl r3          @  r0<- r0 | (r1 << (32-r2))
+    subs    ip, r2, #32                 @  ip<- r2 - 32
+    movpl   r0, r1, lsr ip              @  if r2 >= 32, r0<-r1 >>> (r2-32)
+    mov     r1, r1, lsr r2              @  r1<- r1 >>> r2
+    bx      lr
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_ADD_FLOAT_VFP
+dvmCompiler_TEMPLATE_ADD_FLOAT_VFP:
+/* File: armv5te-vfp/TEMPLATE_ADD_FLOAT_VFP.S */
+/* File: armv5te-vfp/fbinop.S */
+    /*
+     * Generic 32-bit floating point operation.  Provide an "instr" line that
+     * specifies an instruction that performs s2 = s0 op s1.
+     *
+     * On entry:
+     *     r0 = target dalvik register address
+     *     r1 = op1 address
+     *     r2 = op2 address
+     */
+     flds    s0,[r1]
+     flds    s1,[r2]
+     fadds   s2, s0, s1
+     fsts    s2,[r0]
+     bx      lr
+
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_SUB_FLOAT_VFP
+dvmCompiler_TEMPLATE_SUB_FLOAT_VFP:
+/* File: armv5te-vfp/TEMPLATE_SUB_FLOAT_VFP.S */
+/* File: armv5te-vfp/fbinop.S */
+    /*
+     * Generic 32-bit floating point operation.  Provide an "instr" line that
+     * specifies an instruction that performs s2 = s0 op s1.
+     *
+     * On entry:
+     *     r0 = target dalvik register address
+     *     r1 = op1 address
+     *     r2 = op2 address
+     */
+     flds    s0,[r1]
+     flds    s1,[r2]
+     fsubs   s2, s0, s1
+     fsts    s2,[r0]
+     bx      lr
+
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_MUL_FLOAT_VFP
+dvmCompiler_TEMPLATE_MUL_FLOAT_VFP:
+/* File: armv5te-vfp/TEMPLATE_MUL_FLOAT_VFP.S */
+/* File: armv5te-vfp/fbinop.S */
+    /*
+     * Generic 32-bit floating point operation.  Provide an "instr" line that
+     * specifies an instruction that performs s2 = s0 op s1.
+     *
+     * On entry:
+     *     r0 = target dalvik register address
+     *     r1 = op1 address
+     *     r2 = op2 address
+     */
+     flds    s0,[r1]
+     flds    s1,[r2]
+     fmuls   s2, s0, s1
+     fsts    s2,[r0]
+     bx      lr
+
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_DIV_FLOAT_VFP
+dvmCompiler_TEMPLATE_DIV_FLOAT_VFP:
+/* File: armv5te-vfp/TEMPLATE_DIV_FLOAT_VFP.S */
+/* File: armv5te-vfp/fbinop.S */
+    /*
+     * Generic 32-bit floating point operation.  Provide an "instr" line that
+     * specifies an instruction that performs s2 = s0 op s1.
+     *
+     * On entry:
+     *     r0 = target dalvik register address
+     *     r1 = op1 address
+     *     r2 = op2 address
+     */
+     flds    s0,[r1]
+     flds    s1,[r2]
+     fdivs   s2, s0, s1
+     fsts    s2,[r0]
+     bx      lr
+
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_ADD_DOUBLE_VFP
+dvmCompiler_TEMPLATE_ADD_DOUBLE_VFP:
+/* File: armv5te-vfp/TEMPLATE_ADD_DOUBLE_VFP.S */
+/* File: armv5te-vfp/fbinopWide.S */
+    /*
+     * Generic 64-bit floating point operation.  Provide an "instr" line that
+     * specifies an instruction that performs s2 = s0 op s1.
+     *
+     * On entry:
+     *     r0 = target dalvik register address
+     *     r1 = op1 address
+     *     r2 = op2 address
+     */
+     fldd    d0,[r1]
+     fldd    d1,[r2]
+     faddd   d2, d0, d1
+     fstd    d2,[r0]
+     bx      lr
+
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_SUB_DOUBLE_VFP
+dvmCompiler_TEMPLATE_SUB_DOUBLE_VFP:
+/* File: armv5te-vfp/TEMPLATE_SUB_DOUBLE_VFP.S */
+/* File: armv5te-vfp/fbinopWide.S */
+    /*
+     * Generic 64-bit floating point operation.  Provide an "instr" line that
+     * specifies an instruction that performs s2 = s0 op s1.
+     *
+     * On entry:
+     *     r0 = target dalvik register address
+     *     r1 = op1 address
+     *     r2 = op2 address
+     */
+     fldd    d0,[r1]
+     fldd    d1,[r2]
+     fsubd   d2, d0, d1
+     fstd    d2,[r0]
+     bx      lr
+
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_MUL_DOUBLE_VFP
+dvmCompiler_TEMPLATE_MUL_DOUBLE_VFP:
+/* File: armv5te-vfp/TEMPLATE_MUL_DOUBLE_VFP.S */
+/* File: armv5te-vfp/fbinopWide.S */
+    /*
+     * Generic 64-bit floating point operation.  Provide an "instr" line that
+     * specifies an instruction that performs s2 = s0 op s1.
+     *
+     * On entry:
+     *     r0 = target dalvik register address
+     *     r1 = op1 address
+     *     r2 = op2 address
+     */
+     fldd    d0,[r1]
+     fldd    d1,[r2]
+     fmuld   d2, d0, d1
+     fstd    d2,[r0]
+     bx      lr
+
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_DIV_DOUBLE_VFP
+dvmCompiler_TEMPLATE_DIV_DOUBLE_VFP:
+/* File: armv5te-vfp/TEMPLATE_DIV_DOUBLE_VFP.S */
+/* File: armv5te-vfp/fbinopWide.S */
+    /*
+     * Generic 64-bit floating point operation.  Provide an "instr" line that
+     * specifies an instruction that performs s2 = s0 op s1.
+     *
+     * On entry:
+     *     r0 = target dalvik register address
+     *     r1 = op1 address
+     *     r2 = op2 address
+     */
+     fldd    d0,[r1]
+     fldd    d1,[r2]
+     fdivd   d2, d0, d1
+     fstd    d2,[r0]
+     bx      lr
+
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_DOUBLE_TO_FLOAT_VFP
+dvmCompiler_TEMPLATE_DOUBLE_TO_FLOAT_VFP:
+/* File: armv5te-vfp/TEMPLATE_DOUBLE_TO_FLOAT_VFP.S */
+/* File: armv5te-vfp/funopNarrower.S */
+    /*
+     * Generic 64bit-to-32bit floating point unary operation.  Provide an
+     * "instr" line that specifies an instruction that performs "s0 = op d0".
+     *
+     * For: double-to-int, double-to-float
+     *
+     * On entry:
+     *     r0 = target dalvik register address
+     *     r1 = src dalvik register address
+     */
+    /* unop vA, vB */
+    fldd    d0, [r1]                    @ d0<- vB
+    fcvtsd  s0, d0                              @ s0<- op d0
+    fsts    s0, [r0]                    @ vA<- s0
+    bx      lr
+
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_DOUBLE_TO_INT_VFP
+dvmCompiler_TEMPLATE_DOUBLE_TO_INT_VFP:
+/* File: armv5te-vfp/TEMPLATE_DOUBLE_TO_INT_VFP.S */
+/* File: armv5te-vfp/funopNarrower.S */
+    /*
+     * Generic 64bit-to-32bit floating point unary operation.  Provide an
+     * "instr" line that specifies an instruction that performs "s0 = op d0".
+     *
+     * For: double-to-int, double-to-float
+     *
+     * On entry:
+     *     r0 = target dalvik register address
+     *     r1 = src dalvik register address
+     */
+    /* unop vA, vB */
+    fldd    d0, [r1]                    @ d0<- vB
+    ftosizd  s0, d0                              @ s0<- op d0
+    fsts    s0, [r0]                    @ vA<- s0
+    bx      lr
+
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_FLOAT_TO_DOUBLE_VFP
+dvmCompiler_TEMPLATE_FLOAT_TO_DOUBLE_VFP:
+/* File: armv5te-vfp/TEMPLATE_FLOAT_TO_DOUBLE_VFP.S */
+/* File: armv5te-vfp/funopWider.S */
+    /*
+     * Generic 32bit-to-64bit floating point unary operation.  Provide an
+     * "instr" line that specifies an instruction that performs "d0 = op s0".
+     *
+     * For: int-to-double, float-to-double
+     *
+     * On entry:
+     *     r0 = target dalvik register address
+     *     r1 = src dalvik register address
+     */
+    /* unop vA, vB */
+    flds    s0, [r1]                    @ s0<- vB
+    fcvtds  d0, s0                              @ d0<- op s0
+    fstd    d0, [r0]                    @ vA<- d0
+    bx      lr
+
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_FLOAT_TO_INT_VFP
+dvmCompiler_TEMPLATE_FLOAT_TO_INT_VFP:
+/* File: armv5te-vfp/TEMPLATE_FLOAT_TO_INT_VFP.S */
+/* File: armv5te-vfp/funop.S */
+    /*
+     * Generic 32bit-to-32bit floating point unary operation.  Provide an
+     * "instr" line that specifies an instruction that performs "s1 = op s0".
+     *
+     * For: float-to-int, int-to-float
+     *
+     * On entry:
+     *     r0 = target dalvik register address
+     *     r1 = src dalvik register address
+     */
+    /* unop vA, vB */
+    flds    s0, [r1]                    @ s0<- vB
+    ftosizs s1, s0                              @ s1<- op s0
+    fsts    s1, [r0]                    @ vA<- s1
+    bx      lr
+
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_INT_TO_DOUBLE_VFP
+dvmCompiler_TEMPLATE_INT_TO_DOUBLE_VFP:
+/* File: armv5te-vfp/TEMPLATE_INT_TO_DOUBLE_VFP.S */
+/* File: armv5te-vfp/funopWider.S */
+    /*
+     * Generic 32bit-to-64bit floating point unary operation.  Provide an
+     * "instr" line that specifies an instruction that performs "d0 = op s0".
+     *
+     * For: int-to-double, float-to-double
+     *
+     * On entry:
+     *     r0 = target dalvik register address
+     *     r1 = src dalvik register address
+     */
+    /* unop vA, vB */
+    flds    s0, [r1]                    @ s0<- vB
+    fsitod  d0, s0                              @ d0<- op s0
+    fstd    d0, [r0]                    @ vA<- d0
+    bx      lr
+
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_INT_TO_FLOAT_VFP
+dvmCompiler_TEMPLATE_INT_TO_FLOAT_VFP:
+/* File: armv5te-vfp/TEMPLATE_INT_TO_FLOAT_VFP.S */
+/* File: armv5te-vfp/funop.S */
+    /*
+     * Generic 32bit-to-32bit floating point unary operation.  Provide an
+     * "instr" line that specifies an instruction that performs "s1 = op s0".
+     *
+     * For: float-to-int, int-to-float
+     *
+     * On entry:
+     *     r0 = target dalvik register address
+     *     r1 = src dalvik register address
+     */
+    /* unop vA, vB */
+    flds    s0, [r1]                    @ s0<- vB
+    fsitos  s1, s0                              @ s1<- op s0
+    fsts    s1, [r0]                    @ vA<- s1
+    bx      lr
+
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_CMPG_DOUBLE_VFP
+dvmCompiler_TEMPLATE_CMPG_DOUBLE_VFP:
+/* File: armv5te-vfp/TEMPLATE_CMPG_DOUBLE_VFP.S */
+    /*
+     * Compare two floating-point values.  Puts 0, 1, or -1 into the
+     * destination register based on the results of the comparison.
+     *
+     * int compare(x, y) {
+     *     if (x == y) {
+     *         return 0;
+     *     } else if (x < y) {
+     *         return -1;
+     *     } else if (x > y) {
+     *         return 1;
+     *     } else {
+     *         return 1;
+     *     }
+     * }
+     *
+     * On entry:
+     *    r0 = &op1 [vBB]
+     *    r1 = &op2 [vCC]
+     */
+    /* op vAA, vBB, vCC */
+    fldd    d0, [r0]                    @ d0<- vBB
+    fldd    d1, [r1]                    @ d1<- vCC
+    fcmpd  d0, d1                       @ compare (vBB, vCC)
+    mov     r0, #1                      @ r0<- 1 (default)
+    fmstat                              @ export status flags
+    mvnmi   r0, #0                      @ (less than) r0<- -1
+    moveq   r0, #0                      @ (equal) r0<- 0
+    bx      lr
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_CMPL_DOUBLE_VFP
+dvmCompiler_TEMPLATE_CMPL_DOUBLE_VFP:
+/* File: armv5te-vfp/TEMPLATE_CMPL_DOUBLE_VFP.S */
+    /*
+     * Compare two floating-point values.  Puts 0, 1, or -1 into the
+     * destination register based on the results of the comparison.
+     *
+     * int compare(x, y) {
+     *     if (x == y) {
+     *         return 0;
+     *     } else if (x > y) {
+     *         return 1;
+     *     } else if (x < y) {
+     *         return -1;
+     *     } else {
+     *         return -1;
+     *     }
+     * }
+     * On entry:
+     *    r0 = &op1 [vBB]
+     *    r1 = &op2 [vCC]
+     */
+    /* op vAA, vBB, vCC */
+    fldd    d0, [r0]                    @ d0<- vBB
+    fldd    d1, [r1]                    @ d1<- vCC
+    fcmped  d0, d1                      @ compare (vBB, vCC)
+    mvn     r0, #0                      @ r0<- -1 (default)
+    fmstat                              @ export status flags
+    movgt   r0, #1                      @ (greater than) r0<- 1
+    moveq   r0, #0                      @ (equal) r0<- 0
+    bx      lr
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_CMPG_FLOAT_VFP
+dvmCompiler_TEMPLATE_CMPG_FLOAT_VFP:
+/* File: armv5te-vfp/TEMPLATE_CMPG_FLOAT_VFP.S */
+    /*
+     * Compare two floating-point values.  Puts 0, 1, or -1 into the
+     * destination register based on the results of the comparison.
+     *
+     * int compare(x, y) {
+     *     if (x == y) {
+     *         return 0;
+     *     } else if (x < y) {
+     *         return -1;
+     *     } else if (x > y) {
+     *         return 1;
+     *     } else {
+     *         return 1;
+     *     }
+     * }
+     * On entry:
+     *    r0 = &op1 [vBB]
+     *    r1 = &op2 [vCC]
+     */
+    /* op vAA, vBB, vCC */
+    flds    s0, [r0]                    @ d0<- vBB
+    flds    s1, [r1]                    @ d1<- vCC
+    fcmps  s0, s1                      @ compare (vBB, vCC)
+    mov     r0, #1                      @ r0<- 1 (default)
+    fmstat                              @ export status flags
+    mvnmi   r0, #0                      @ (less than) r0<- -1
+    moveq   r0, #0                      @ (equal) r0<- 0
+    bx      lr
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_CMPL_FLOAT_VFP
+dvmCompiler_TEMPLATE_CMPL_FLOAT_VFP:
+/* File: armv5te-vfp/TEMPLATE_CMPL_FLOAT_VFP.S */
+    /*
+     * Compare two floating-point values.  Puts 0, 1, or -1 into the
+     * destination register based on the results of the comparison.
+     *
+     * int compare(x, y) {
+     *     if (x == y) {
+     *         return 0;
+     *     } else if (x > y) {
+     *         return 1;
+     *     } else if (x < y) {
+     *         return -1;
+     *     } else {
+     *         return -1;
+     *     }
+     * }
+     * On entry:
+     *    r0 = &op1 [vBB]
+     *    r1 = &op2 [vCC]
+     */
+    /* op vAA, vBB, vCC */
+    flds    s0, [r0]                    @ d0<- vBB
+    flds    s1, [r1]                    @ d1<- vCC
+    fcmps  s0, s1                      @ compare (vBB, vCC)
+    mvn     r0, #0                      @ r0<- -1 (default)
+    fmstat                              @ export status flags
+    movgt   r0, #1                      @ (greater than) r0<- 1
+    moveq   r0, #0                      @ (equal) r0<- 0
+    bx      lr
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_SQRT_DOUBLE_VFP
+dvmCompiler_TEMPLATE_SQRT_DOUBLE_VFP:
+/* File: armv5te-vfp/TEMPLATE_SQRT_DOUBLE_VFP.S */
+    /*
+     * 64-bit floating point vfp sqrt operation.
+     * If the result is a NaN, bail out to library code to do
+     * the right thing.
+     *
+     * On entry:
+     *     r2 src addr of op1
+     * On exit:
+     *     r0,r1 = res
+     */
+    fldd    d0, [r2]
+    fsqrtd  d1, d0
+    fcmpd   d1, d1
+    fmstat
+    fmrrd   r0, r1, d1
+    bxeq    lr   @ Result OK - return
+    ldr     r2, .Lsqrt
+    fmrrd   r0, r1, d0   @ reload orig operand
+    bx      r2   @ tail call to sqrt library routine
+
+.Lsqrt:
+    .word   sqrt
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_THROW_EXCEPTION_COMMON
+dvmCompiler_TEMPLATE_THROW_EXCEPTION_COMMON:
+/* File: armv5te/TEMPLATE_THROW_EXCEPTION_COMMON.S */
+    /*
+     * Throw an exception from JIT'ed code.
+     * On entry:
+     *    r0    Dalvik PC that raises the exception
+     */
+    b       .LhandleException
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_MEM_OP_DECODE
+dvmCompiler_TEMPLATE_MEM_OP_DECODE:
+/* File: armv5te-vfp/TEMPLATE_MEM_OP_DECODE.S */
+#if defined(WITH_SELF_VERIFICATION)
+    /*
+     * This handler encapsulates heap memory ops for selfVerification mode.
+     *
+     * The call to the handler is inserted prior to a heap memory operation.
+     * This handler then calls a function to decode the memory op, and process
+     * it accordingly. Afterwards, the handler changes the return address to
+     * skip the memory op so it never gets executed.
+     */
+    vpush   {d0-d15}                    @ save out all fp registers
+    push    {r0-r12,lr}                 @ save out all registers
+    ldr     r2, .LdvmSelfVerificationMemOpDecode @ defined in footer.S
+    mov     r0, lr                      @ arg0 <- link register
+    mov     r1, sp                      @ arg1 <- stack pointer
+    blx     r2                          @ decode and handle the mem op
+    pop     {r0-r12,lr}                 @ restore all registers
+    vpop    {d0-d15}                    @ restore all fp registers
+    bx      lr                          @ return to compiled code
+#endif
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_STRING_COMPARETO
+dvmCompiler_TEMPLATE_STRING_COMPARETO:
+/* File: armv5te/TEMPLATE_STRING_COMPARETO.S */
+    /*
+     * String's compareTo.
+     *
+     * Requires r0/r1 to have been previously checked for null.  Will
+     * return negative if this's string is < comp, 0 if they are the
+     * same and positive if >.
+     *
+     * IMPORTANT NOTE:
+     *
+     * This code relies on hard-coded offsets for string objects, and must be
+     * kept in sync with definitions in UtfString.h.  See asm-constants.h
+     *
+     * On entry:
+     *    r0:   this object pointer
+     *    r1:   comp object pointer
+     *
+     */
+
+    mov    r2, r0         @ this to r2, opening up r0 for return value
+    subs   r0, r2, r1     @ Same?
+    bxeq   lr
+
+    ldr    r4, [r2, #STRING_FIELDOFF_OFFSET]
+    ldr    r9, [r1, #STRING_FIELDOFF_OFFSET]
+    ldr    r7, [r2, #STRING_FIELDOFF_COUNT]
+    ldr    r10, [r1, #STRING_FIELDOFF_COUNT]
+    ldr    r2, [r2, #STRING_FIELDOFF_VALUE]
+    ldr    r1, [r1, #STRING_FIELDOFF_VALUE]
+
+    /*
+     * At this point, we have:
+     *    value:  r2/r1
+     *    offset: r4/r9
+     *    count:  r7/r10
+     * We're going to compute
+     *    r11 <- countDiff
+     *    r10 <- minCount
+     */
+     subs  r11, r7, r10
+     movls r10, r7
+
+     /* Now, build pointers to the string data */
+     add   r2, r2, r4, lsl #1
+     add   r1, r1, r9, lsl #1
+     /*
+      * Note: data pointers point to previous element so we can use pre-index
+      * mode with base writeback.
+      */
+     add   r2, #16-2   @ offset to contents[-1]
+     add   r1, #16-2   @ offset to contents[-1]
+
+     /*
+      * At this point we have:
+      *   r2: *this string data
+      *   r1: *comp string data
+      *   r10: iteration count for comparison
+      *   r11: value to return if the first part of the string is equal
+      *   r0: reserved for result
+      *   r3, r4, r7, r8, r9, r12 available for loading string data
+      */
+
+    subs  r10, #2
+    blt   do_remainder2
+
+      /*
+       * Unroll the first two checks so we can quickly catch early mismatch
+       * on long strings (but preserve incoming alignment)
+       */
+
+    ldrh  r3, [r2, #2]!
+    ldrh  r4, [r1, #2]!
+    ldrh  r7, [r2, #2]!
+    ldrh  r8, [r1, #2]!
+    subs  r0, r3, r4
+    subeqs  r0, r7, r8
+    bxne  lr
+    cmp   r10, #28
+    bgt   do_memcmp16
+    subs  r10, #3
+    blt   do_remainder
+
+loopback_triple:
+    ldrh  r3, [r2, #2]!
+    ldrh  r4, [r1, #2]!
+    ldrh  r7, [r2, #2]!
+    ldrh  r8, [r1, #2]!
+    ldrh  r9, [r2, #2]!
+    ldrh  r12,[r1, #2]!
+    subs  r0, r3, r4
+    subeqs  r0, r7, r8
+    subeqs  r0, r9, r12
+    bxne  lr
+    subs  r10, #3
+    bge   loopback_triple
+
+do_remainder:
+    adds  r10, #3
+    beq   returnDiff
+
+loopback_single:
+    ldrh  r3, [r2, #2]!
+    ldrh  r4, [r1, #2]!
+    subs  r0, r3, r4
+    bxne  lr
+    subs  r10, #1
+    bne     loopback_single
+
+returnDiff:
+    mov   r0, r11
+    bx    lr
+
+do_remainder2:
+    adds  r10, #2
+    bne   loopback_single
+    mov   r0, r11
+    bx    lr
+
+    /* Long string case */
+do_memcmp16:
+    mov   r4, lr
+    ldr   lr, .Lmemcmp16
+    mov   r7, r11
+    add   r0, r2, #2
+    add   r1, r1, #2
+    mov   r2, r10
+    blx   lr
+    cmp   r0, #0
+    bxne  r4
+    mov   r0, r7
+    bx    r4
+
+.Lmemcmp16:
+    .word __memcmp16
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_STRING_INDEXOF
+dvmCompiler_TEMPLATE_STRING_INDEXOF:
+/* File: armv5te/TEMPLATE_STRING_INDEXOF.S */
+    /*
+     * String's indexOf.
+     *
+     * Requires r0 to have been previously checked for null.  Will
+     * return index of match of r1 in r0.
+     *
+     * IMPORTANT NOTE:
+     *
+     * This code relies on hard-coded offsets for string objects, and must be
+     * kept in sync wth definitions in UtfString.h  See asm-constants.h
+     *
+     * On entry:
+     *    r0:   string object pointer
+     *    r1:   char to match
+     *    r2:   Starting offset in string data
+     */
+
+    ldr    r7, [r0, #STRING_FIELDOFF_OFFSET]
+    ldr    r8, [r0, #STRING_FIELDOFF_COUNT]
+    ldr    r0, [r0, #STRING_FIELDOFF_VALUE]
+
+    /*
+     * At this point, we have:
+     *    r0: object pointer
+     *    r1: char to match
+     *    r2: starting offset
+     *    r7: offset
+     *    r8: string length
+     */
+
+     /* Build pointer to start of string data */
+     add   r0, #16
+     add   r0, r0, r7, lsl #1
+
+     /* Save a copy of starting data in r7 */
+     mov   r7, r0
+
+     /* Clamp start to [0..count] */
+     cmp   r2, #0
+     movlt r2, #0
+     cmp   r2, r8
+     movgt r2, r8
+
+     /* Build pointer to start of data to compare and pre-bias */
+     add   r0, r0, r2, lsl #1
+     sub   r0, #2
+
+     /* Compute iteration count */
+     sub   r8, r2
+
+     /*
+      * At this point we have:
+      *   r0: start of data to test
+      *   r1: chat to compare
+      *   r8: iteration count
+      *   r7: original start of string
+      *   r3, r4, r9, r10, r11, r12 available for loading string data
+      */
+
+    subs  r8, #4
+    blt   indexof_remainder
+
+indexof_loop4:
+    ldrh  r3, [r0, #2]!
+    ldrh  r4, [r0, #2]!
+    ldrh  r10, [r0, #2]!
+    ldrh  r11, [r0, #2]!
+    cmp   r3, r1
+    beq   match_0
+    cmp   r4, r1
+    beq   match_1
+    cmp   r10, r1
+    beq   match_2
+    cmp   r11, r1
+    beq   match_3
+    subs  r8, #4
+    bge   indexof_loop4
+
+indexof_remainder:
+    adds    r8, #4
+    beq     indexof_nomatch
+
+indexof_loop1:
+    ldrh  r3, [r0, #2]!
+    cmp   r3, r1
+    beq   match_3
+    subs  r8, #1
+    bne   indexof_loop1
+
+indexof_nomatch:
+    mov   r0, #-1
+    bx    lr
+
+match_0:
+    sub   r0, #6
+    sub   r0, r7
+    asr   r0, r0, #1
+    bx    lr
+match_1:
+    sub   r0, #4
+    sub   r0, r7
+    asr   r0, r0, #1
+    bx    lr
+match_2:
+    sub   r0, #2
+    sub   r0, r7
+    asr   r0, r0, #1
+    bx    lr
+match_3:
+    sub   r0, r7
+    asr   r0, r0, #1
+    bx    lr
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_INTERPRET
+dvmCompiler_TEMPLATE_INTERPRET:
+/* File: armv5te/TEMPLATE_INTERPRET.S */
+    /*
+     * This handler transfers control to the interpeter without performing
+     * any lookups.  It may be called either as part of a normal chaining
+     * operation, or from the transition code in header.S.  We distinquish
+     * the two cases by looking at the link register.  If called from a
+     * translation chain, it will point to the chaining Dalvik PC -3.
+     * On entry:
+     *    lr - if NULL:
+     *        r1 - the Dalvik PC to begin interpretation.
+     *    else
+     *        [lr, #3] contains Dalvik PC to begin interpretation
+     *    rSELF - pointer to thread
+     *    rFP - Dalvik frame pointer
+     */
+    cmp     lr, #0
+#if defined(WORKAROUND_CORTEX_A9_745320)
+    /* Don't use conditional loads if the HW defect exists */
+    beq     101f
+    ldr     r1,[lr, #3]
+101:
+#else
+    ldrne   r1,[lr, #3]
+#endif
+    ldr     r2, .LinterpPunt
+    mov     r0, r1                       @ set Dalvik PC
+    bx      r2
+    @ doesn't return
+
+.LinterpPunt:
+    .word   dvmJitToInterpPunt
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_MONITOR_ENTER
+dvmCompiler_TEMPLATE_MONITOR_ENTER:
+/* File: armv5te/TEMPLATE_MONITOR_ENTER.S */
+    /*
+     * Call out to the runtime to lock an object.  Because this thread
+     * may have been suspended in THREAD_MONITOR state and the Jit's
+     * translation cache subsequently cleared, we cannot return directly.
+     * Instead, unconditionally transition to the interpreter to resume.
+     *
+     * On entry:
+     *    r0 - self pointer
+     *    r1 - the object (which has already been null-checked by the caller
+     *    r4 - the Dalvik PC of the following instruction.
+     */
+    ldr     r2, .LdvmLockObject
+    mov     r3, #0                       @ Record that we're not returning
+    str     r3, [r0, #offThread_inJitCodeCache]
+    blx     r2                           @ dvmLockObject(self, obj)
+    ldr     r2, .LdvmJitToInterpNoChain
+    @ Bail to interpreter - no chain [note - r4 still contains rPC]
+#if defined(WITH_JIT_TUNING)
+    mov     r0, #kHeavyweightMonitor
+#endif
+    bx      r2
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_MONITOR_ENTER_DEBUG
+dvmCompiler_TEMPLATE_MONITOR_ENTER_DEBUG:
+/* File: armv5te/TEMPLATE_MONITOR_ENTER_DEBUG.S */
+    /*
+     * To support deadlock prediction, this version of MONITOR_ENTER
+     * will always call the heavyweight dvmLockObject, check for an
+     * exception and then bail out to the interpreter.
+     *
+     * On entry:
+     *    r0 - self pointer
+     *    r1 - the object (which has already been null-checked by the caller
+     *    r4 - the Dalvik PC of the following instruction.
+     *
+     */
+    ldr     r2, .LdvmLockObject
+    mov     r3, #0                       @ Record that we're not returning
+    str     r3, [r0, #offThread_inJitCodeCache]
+    blx     r2             @ dvmLockObject(self, obj)
+    @ test for exception
+    ldr     r1, [rSELF, #offThread_exception]
+    cmp     r1, #0
+    beq     1f
+    ldr     r2, .LhandleException
+    sub     r0, r4, #2     @ roll dPC back to this monitor instruction
+    bx      r2
+1:
+    @ Bail to interpreter - no chain [note - r4 still contains rPC]
+#if defined(WITH_JIT_TUNING)
+    mov     r0, #kHeavyweightMonitor
+#endif
+    ldr     pc, .LdvmJitToInterpNoChain
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_PERIODIC_PROFILING
+dvmCompiler_TEMPLATE_PERIODIC_PROFILING:
+/* File: armv5te/TEMPLATE_PERIODIC_PROFILING.S */
+    /*
+     * Increment profile counter for this trace, and decrement
+     * sample counter.  If sample counter goes below zero, turn
+     * off profiling.
+     *
+     * On entry
+     * (lr-11) is address of pointer to counter.  Note: the counter
+     *    actually exists 10 bytes before the return target, but because
+     *    we are arriving from thumb mode, lr will have its low bit set.
+     */
+     ldr    r0, [lr,#-11]
+     ldr    r1, [rSELF, #offThread_pProfileCountdown]
+     ldr    r2, [r0]                    @ get counter
+     ldr    r3, [r1]                    @ get countdown timer
+     add    r2, #1
+     subs   r2, #1
+     blt    .LTEMPLATE_PERIODIC_PROFILING_disable_profiling
+     str    r2, [r0]
+     str    r3, [r1]
+     bx     lr
+
+.LTEMPLATE_PERIODIC_PROFILING_disable_profiling:
+     mov    r4, lr                     @ preserve lr
+     ldr    r0, .LdvmJitTraceProfilingOff
+     blx    r0
+     bx     r4
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_RETURN_PROF
+dvmCompiler_TEMPLATE_RETURN_PROF:
+/* File: armv5te/TEMPLATE_RETURN_PROF.S */
+#define TEMPLATE_INLINE_PROFILING
+/* File: armv5te/TEMPLATE_RETURN.S */
+    /*
+     * Unwind a frame from the Dalvik stack for compiled OP_RETURN_XXX.
+     * If the stored value in returnAddr
+     * is non-zero, the caller is compiled by the JIT thus return to the
+     * address in the code cache following the invoke instruction. Otherwise
+     * return to the special dvmJitToInterpNoChain entry point.
+     */
+#if defined(TEMPLATE_INLINE_PROFILING)
+    stmfd   sp!, {r0-r2,lr}             @ preserve live registers
+    mov     r0, r6
+    @ r0=rSELF
+    mov     lr, pc
+    ldr     pc, .LdvmFastMethodTraceExit
+    ldmfd   sp!, {r0-r2,lr}             @ restore live registers
+#endif
+    SAVEAREA_FROM_FP(r0, rFP)           @ r0<- saveArea (old)
+    ldr     r10, [r0, #offStackSaveArea_prevFrame] @ r10<- saveArea->prevFrame
+    ldrb    r8, [rSELF, #offThread_breakFlags] @ r8<- breakFlags
+    ldr     rPC, [r0, #offStackSaveArea_savedPc] @ rPC<- saveArea->savedPc
+#if !defined(WITH_SELF_VERIFICATION)
+    ldr     r9,  [r0, #offStackSaveArea_returnAddr] @ r9<- chaining cell ret
+#else
+    mov     r9, #0                      @ disable chaining
+#endif
+    ldr     r2, [r10, #(offStackSaveArea_method - sizeofStackSaveArea)]
+                                        @ r2<- method we're returning to
+    cmp     r2, #0                      @ break frame?
+#if !defined(WITH_SELF_VERIFICATION)
+    beq     1f                          @ bail to interpreter
+#else
+    blxeq   lr                          @ punt to interpreter and compare state
+#endif
+    ldr     r1, .LdvmJitToInterpNoChainNoProfile @ defined in footer.S
+    mov     rFP, r10                    @ publish new FP
+    ldr     r10, [r2, #offMethod_clazz] @ r10<- method->clazz
+
+    str     r2, [rSELF, #offThread_method]@ self->method = newSave->method
+    ldr     r0, [r10, #offClassObject_pDvmDex] @ r0<- method->clazz->pDvmDex
+    str     rFP, [rSELF, #offThread_curFrame] @ curFrame = fp
+    add     rPC, rPC, #6                @ publish new rPC (advance 6 bytes)
+    str     r0, [rSELF, #offThread_methodClassDex]
+    cmp     r8, #0                      @ check the break flags
+    movne   r9, #0                      @ clear the chaining cell address
+    str     r9, [rSELF, #offThread_inJitCodeCache] @ in code cache or not
+    cmp     r9, #0                      @ chaining cell exists?
+    blxne   r9                          @ jump to the chaining cell
+#if defined(WITH_JIT_TUNING)
+    mov     r0, #kCallsiteInterpreted
+#endif
+    mov     pc, r1                      @ callsite is interpreted
+1:
+    mov     r0, #0
+    str     r0, [rSELF, #offThread_inJitCodeCache] @ reset inJitCodeCache
+    stmia   rSELF, {rPC, rFP}           @ SAVE_PC_FP_TO_SELF()
+    ldr     r2, .LdvmMterpStdBail       @ defined in footer.S
+    mov     r0, rSELF                   @ Expecting rSELF in r0
+    blx     r2                          @ exit the interpreter
+
+#undef TEMPLATE_INLINE_PROFILING
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_INVOKE_METHOD_NO_OPT_PROF
+dvmCompiler_TEMPLATE_INVOKE_METHOD_NO_OPT_PROF:
+/* File: armv5te/TEMPLATE_INVOKE_METHOD_NO_OPT_PROF.S */
+#define TEMPLATE_INLINE_PROFILING
+/* File: armv5te/TEMPLATE_INVOKE_METHOD_NO_OPT.S */
+    /*
+     * For polymorphic callsites - setup the Dalvik frame and load Dalvik PC
+     * into rPC then jump to dvmJitToInterpNoChain to dispatch the
+     * runtime-resolved callee.
+     */
+    @ r0 = methodToCall, r1 = returnCell, rPC = dalvikCallsite
+    ldrh    r7, [r0, #offMethod_registersSize]  @ r7<- methodToCall->regsSize
+    ldrh    r2, [r0, #offMethod_outsSize]  @ r2<- methodToCall->outsSize
+    ldr     r9, [rSELF, #offThread_interpStackEnd]    @ r9<- interpStackEnd
+    ldrb    r8, [rSELF, #offThread_breakFlags] @ r8<- breakFlags
+    add     r3, r1, #1  @ Thumb addr is odd
+    SAVEAREA_FROM_FP(r1, rFP)           @ r1<- stack save area
+    sub     r1, r1, r7, lsl #2          @ r1<- newFp (old savearea - regsSize)
+    SAVEAREA_FROM_FP(r10, r1)           @ r10<- stack save area
+    sub     r10, r10, r2, lsl #2        @ r10<- bottom (newsave - outsSize)
+    cmp     r10, r9                     @ bottom < interpStackEnd?
+    bxlo    lr                          @ return to raise stack overflow excep.
+    @ r1 = newFP, r0 = methodToCall, r3 = returnCell, rPC = dalvikCallsite
+    ldr     r9, [r0, #offMethod_clazz]      @ r9<- method->clazz
+    ldr     r10, [r0, #offMethod_accessFlags] @ r10<- methodToCall->accessFlags
+    str     rPC, [rFP, #(offStackSaveArea_currentPc - sizeofStackSaveArea)]
+    str     rPC, [r1, #(offStackSaveArea_savedPc - sizeofStackSaveArea)]
+    ldr     rPC, [r0, #offMethod_insns]     @ rPC<- methodToCall->insns
+
+
+    @ set up newSaveArea
+    str     rFP, [r1, #(offStackSaveArea_prevFrame - sizeofStackSaveArea)]
+    str     r3, [r1, #(offStackSaveArea_returnAddr - sizeofStackSaveArea)]
+    str     r0, [r1, #(offStackSaveArea_method - sizeofStackSaveArea)]
+    cmp     r8, #0                      @ breakFlags != 0
+    bxne    lr                          @ bail to the interpreter
+    tst     r10, #ACC_NATIVE
+#if !defined(WITH_SELF_VERIFICATION)
+    bne     .LinvokeNative
+#else
+    bxne    lr                          @ bail to the interpreter
+#endif
+
+    ldr     r10, .LdvmJitToInterpTraceSelectNoChain
+    ldr     r3, [r9, #offClassObject_pDvmDex] @ r3<- method->clazz->pDvmDex
+
+    @ Update "thread" values for the new method
+    str     r0, [rSELF, #offThread_method]    @ self->method = methodToCall
+    str     r3, [rSELF, #offThread_methodClassDex] @ self->methodClassDex = ...
+    mov     rFP, r1                         @ fp = newFp
+    str     rFP, [rSELF, #offThread_curFrame]  @ curFrame = newFp
+#if defined(TEMPLATE_INLINE_PROFILING)
+    stmfd   sp!, {r0-r3}                    @ preserve r0-r3
+    mov     r1, r6
+    @ r0=methodToCall, r1=rSELF
+    mov     lr, pc
+    ldr     pc, .LdvmFastMethodTraceEnter
+    ldmfd   sp!, {r0-r3}                    @ restore r0-r3
+#endif
+
+    @ Start executing the callee
+#if defined(WITH_JIT_TUNING)
+    mov     r0, #kInlineCacheMiss
+#endif
+    mov     pc, r10                         @ dvmJitToInterpTraceSelectNoChain
+
+#undef TEMPLATE_INLINE_PROFILING
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_INVOKE_METHOD_CHAIN_PROF
+dvmCompiler_TEMPLATE_INVOKE_METHOD_CHAIN_PROF:
+/* File: armv5te/TEMPLATE_INVOKE_METHOD_CHAIN_PROF.S */
+#define TEMPLATE_INLINE_PROFILING
+/* File: armv5te/TEMPLATE_INVOKE_METHOD_CHAIN.S */
+    /*
+     * For monomorphic callsite, setup the Dalvik frame and return to the
+     * Thumb code through the link register to transfer control to the callee
+     * method through a dedicated chaining cell.
+     */
+    @ r0 = methodToCall, r1 = returnCell, r2 = methodToCall->outsSize
+    @ rPC = dalvikCallsite, r7 = methodToCall->registersSize
+    @ methodToCall is guaranteed to be non-native
+.LinvokeChainProf:
+    ldr     r9, [rSELF, #offThread_interpStackEnd]    @ r9<- interpStackEnd
+    ldrb    r8, [rSELF, #offThread_breakFlags]        @ r8<- breakFlags
+    add     r3, r1, #1  @ Thumb addr is odd
+    SAVEAREA_FROM_FP(r1, rFP)           @ r1<- stack save area
+    sub     r1, r1, r7, lsl #2          @ r1<- newFp (old savearea - regsSize)
+    SAVEAREA_FROM_FP(r10, r1)           @ r10<- stack save area
+    add     r12, lr, #2                 @ setup the punt-to-interp address
+    sub     r10, r10, r2, lsl #2        @ r10<- bottom (newsave - outsSize)
+    cmp     r10, r9                     @ bottom < interpStackEnd?
+    bxlo    r12                         @ return to raise stack overflow excep.
+    @ r1 = newFP, r0 = methodToCall, r3 = returnCell, rPC = dalvikCallsite
+    ldr     r9, [r0, #offMethod_clazz]      @ r9<- method->clazz
+    str     rPC, [rFP, #(offStackSaveArea_currentPc - sizeofStackSaveArea)]
+    str     rPC, [r1, #(offStackSaveArea_savedPc - sizeofStackSaveArea)]
+
+    @ set up newSaveArea
+    str     rFP, [r1, #(offStackSaveArea_prevFrame - sizeofStackSaveArea)]
+    str     r3, [r1, #(offStackSaveArea_returnAddr - sizeofStackSaveArea)]
+    str     r0, [r1, #(offStackSaveArea_method - sizeofStackSaveArea)]
+    cmp     r8, #0                      @ breakFlags != 0
+    bxne    r12                         @ bail to the interpreter
+
+    ldr     r3, [r9, #offClassObject_pDvmDex] @ r3<- method->clazz->pDvmDex
+
+    @ Update "thread" values for the new method
+    str     r0, [rSELF, #offThread_method]    @ self->method = methodToCall
+    str     r3, [rSELF, #offThread_methodClassDex] @ self->methodClassDex = ...
+    mov     rFP, r1                         @ fp = newFp
+    str     rFP, [rSELF, #offThread_curFrame]  @ curFrame = newFp
+#if defined(TEMPLATE_INLINE_PROFILING)
+    stmfd   sp!, {r0-r2,lr}             @ preserve clobbered live registers
+    mov     r1, r6
+    @ r0=methodToCall, r1=rSELF
+    mov     lr, pc
+    ldr     pc, .LdvmFastMethodTraceEnter
+    ldmfd   sp!, {r0-r2,lr}             @ restore registers
+#endif
+
+    bx      lr                              @ return to the callee-chaining cell
+
+#undef TEMPLATE_INLINE_PROFILING
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_INVOKE_METHOD_PREDICTED_CHAIN_PROF
+dvmCompiler_TEMPLATE_INVOKE_METHOD_PREDICTED_CHAIN_PROF:
+/* File: armv5te/TEMPLATE_INVOKE_METHOD_PREDICTED_CHAIN_PROF.S */
+#define TEMPLATE_INLINE_PROFILING
+/* File: armv5te/TEMPLATE_INVOKE_METHOD_PREDICTED_CHAIN.S */
+    /*
+     * For polymorphic callsite, check whether the cached class pointer matches
+     * the current one. If so setup the Dalvik frame and return to the
+     * Thumb code through the link register to transfer control to the callee
+     * method through a dedicated chaining cell.
+     *
+     * The predicted chaining cell is declared in ArmLIR.h with the
+     * following layout:
+     *
+     *  typedef struct PredictedChainingCell {
+     *      u4 branch;
+     *      const ClassObject *clazz;
+     *      const Method *method;
+     *      u4 counter;
+     *  } PredictedChainingCell;
+     *
+     * Upon returning to the callsite:
+     *    - lr  : to branch to the chaining cell
+     *    - lr+2: to punt to the interpreter
+     *    - lr+4: to fully resolve the callee and may rechain.
+     *            r3 <- class
+     *            r9 <- counter
+     */
+    @ r0 = this, r1 = returnCell, r2 = predictedChainCell, rPC = dalvikCallsite
+    ldr     r3, [r0, #offObject_clazz]  @ r3 <- this->class
+    ldr     r8, [r2, #4]    @ r8 <- predictedChainCell->clazz
+    ldr     r0, [r2, #8]    @ r0 <- predictedChainCell->method
+    ldr     r9, [rSELF, #offThread_icRechainCount] @ r1 <- shared rechainCount
+    cmp     r3, r8          @ predicted class == actual class?
+#if defined(WITH_JIT_TUNING)
+    ldr     r7, .LdvmICHitCount
+#if defined(WORKAROUND_CORTEX_A9_745320)
+    /* Don't use conditional loads if the HW defect exists */
+    bne     101f
+    ldr     r10, [r7, #0]
+101:
+#else
+    ldreq   r10, [r7, #0]
+#endif
+    add     r10, r10, #1
+    streq   r10, [r7, #0]
+#endif
+    ldreqh  r7, [r0, #offMethod_registersSize]  @ r7<- methodToCall->regsSize
+    ldreqh  r2, [r0, #offMethod_outsSize]  @ r2<- methodToCall->outsSize
+    beq     .LinvokeChainProf   @ predicted chain is valid
+    ldr     r7, [r3, #offClassObject_vtable] @ r7 <- this->class->vtable
+    cmp     r8, #0          @ initialized class or not
+    moveq   r1, #0
+    subne   r1, r9, #1      @ count--
+    strne   r1, [rSELF, #offThread_icRechainCount]  @ write back to thread
+    add     lr, lr, #4      @ return to fully-resolve landing pad
+    /*
+     * r1 <- count
+     * r2 <- &predictedChainCell
+     * r3 <- this->class
+     * r4 <- dPC
+     * r7 <- this->class->vtable
+     */
+    bx      lr
+
+#undef TEMPLATE_INLINE_PROFILING
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_INVOKE_METHOD_NATIVE_PROF
+dvmCompiler_TEMPLATE_INVOKE_METHOD_NATIVE_PROF:
+/* File: armv5te/TEMPLATE_INVOKE_METHOD_NATIVE_PROF.S */
+#define TEMPLATE_INLINE_PROFILING
+/* File: armv5te/TEMPLATE_INVOKE_METHOD_NATIVE.S */
+    @ r0 = methodToCall, r1 = returnCell, rPC = dalvikCallsite
+    @ r7 = methodToCall->registersSize
+    ldr     r9, [rSELF, #offThread_interpStackEnd]    @ r9<- interpStackEnd
+    ldrb    r8, [rSELF, #offThread_breakFlags]        @ r8<- breakFlags
+    add     r3, r1, #1  @ Thumb addr is odd
+    SAVEAREA_FROM_FP(r1, rFP)           @ r1<- stack save area
+    sub     r1, r1, r7, lsl #2          @ r1<- newFp (old savearea - regsSize)
+    SAVEAREA_FROM_FP(r10, r1)           @ r10<- stack save area
+    cmp     r10, r9                     @ bottom < interpStackEnd?
+    bxlo    lr                          @ return to raise stack overflow excep.
+    @ r1 = newFP, r0 = methodToCall, r3 = returnCell, rPC = dalvikCallsite
+    str     rPC, [rFP, #(offStackSaveArea_currentPc - sizeofStackSaveArea)]
+    str     rPC, [r1, #(offStackSaveArea_savedPc - sizeofStackSaveArea)]
+
+    @ set up newSaveArea
+    str     rFP, [r1, #(offStackSaveArea_prevFrame - sizeofStackSaveArea)]
+    str     r3, [r1, #(offStackSaveArea_returnAddr - sizeofStackSaveArea)]
+    str     r0, [r1, #(offStackSaveArea_method - sizeofStackSaveArea)]
+    cmp     r8, #0                      @ breakFlags != 0
+    ldr     r8, [r0, #offMethod_nativeFunc] @ r8<- method->nativeFunc
+#if !defined(WITH_SELF_VERIFICATION)
+    bxne    lr                          @ bail to the interpreter
+#else
+    bx      lr                          @ bail to interpreter unconditionally
+#endif
+
+    @ go ahead and transfer control to the native code
+    ldr     r9, [rSELF, #offThread_jniLocal_topCookie]@r9<-thread->localRef->...
+    mov     r2, #0
+    str     r1, [rSELF, #offThread_curFrame]   @ curFrame = newFp
+    str     r2, [rSELF, #offThread_inJitCodeCache] @ not in the jit code cache
+    str     r9, [r1, #(offStackSaveArea_localRefCookie - sizeofStackSaveArea)]
+                                        @ newFp->localRefCookie=top
+    SAVEAREA_FROM_FP(r10, r1)           @ r10<- new stack save area
+
+    mov     r2, r0                        @ arg2<- methodToCall
+    mov     r0, r1                        @ arg0<- newFP
+    add     r1, rSELF, #offThread_retval  @ arg1<- &retval
+    mov     r3, rSELF                     @ arg3<- self
+#if defined(TEMPLATE_INLINE_PROFILING)
+    @ r2=methodToCall, r6=rSELF
+    stmfd   sp!, {r2,r6}                @ to be consumed after JNI return
+    stmfd   sp!, {r0-r3}                @ preserve r0-r3
+    mov     r0, r2
+    mov     r1, r6
+    @ r0=JNIMethod, r1=rSELF
+    mov     lr, pc
+    ldr     pc, .LdvmFastMethodTraceEnter
+    ldmfd   sp!, {r0-r3}                @ restore r0-r3
+#endif
+
+    blx     r8                          @ off to the native code
+
+#if defined(TEMPLATE_INLINE_PROFILING)
+    ldmfd   sp!, {r0-r1}                @ restore r2 and r6
+    @ r0=JNIMethod, r1=rSELF
+    mov     lr, pc
+    ldr     pc, .LdvmFastNativeMethodTraceExit
+#endif
+    @ native return; r10=newSaveArea
+    @ equivalent to dvmPopJniLocals
+    ldr     r2, [r10, #offStackSaveArea_returnAddr] @ r2 = chaining cell ret
+    ldr     r0, [r10, #offStackSaveArea_localRefCookie] @ r0<- saved->top
+    ldr     r1, [rSELF, #offThread_exception] @ check for exception
+    str     rFP, [rSELF, #offThread_curFrame]  @ curFrame = fp
+    cmp     r1, #0                      @ null?
+    str     r0, [rSELF, #offThread_jniLocal_topCookie] @ new top <- old top
+    ldr     r0, [rFP, #(offStackSaveArea_currentPc - sizeofStackSaveArea)]
+
+    @ r0 = dalvikCallsitePC
+    bne     .LhandleException           @ no, handle exception
+
+    str     r2, [rSELF, #offThread_inJitCodeCache] @ set the mode properly
+    cmp     r2, #0                      @ return chaining cell still exists?
+    bxne    r2                          @ yes - go ahead
+
+    @ continue executing the next instruction through the interpreter
+    ldr     r1, .LdvmJitToInterpTraceSelectNoChain @ defined in footer.S
+    add     rPC, r0, #6                 @ reconstruct new rPC (advance 6 bytes)
+#if defined(WITH_JIT_TUNING)
+    mov     r0, #kCallsiteInterpreted
+#endif
+    mov     pc, r1
+
+#undef TEMPLATE_INLINE_PROFILING
+
+    .size   dvmCompilerTemplateStart, .-dvmCompilerTemplateStart
+/* File: armv5te/footer.S */
+/*
+ * ===========================================================================
+ *  Common subroutines and data
+ * ===========================================================================
+ */
+
+    .text
+    .align  2
+.LinvokeNative:
+    @ Prep for the native call
+    @ r1 = newFP, r0 = methodToCall
+    mov     r2, #0
+    ldr     r9, [rSELF, #offThread_jniLocal_topCookie]@r9<-thread->localRef->...
+    str     r2, [rSELF, #offThread_inJitCodeCache] @ not in jit code cache
+    str     r1, [rSELF, #offThread_curFrame]   @ curFrame = newFp
+    str     r9, [r1, #(offStackSaveArea_localRefCookie - sizeofStackSaveArea)]
+                                        @ newFp->localRefCookie=top
+    ldrh    lr, [rSELF, #offThread_subMode]
+    SAVEAREA_FROM_FP(r10, r1)           @ r10<- new stack save area
+
+    mov     r2, r0                      @ r2<- methodToCall
+    mov     r0, r1                      @ r0<- newFP
+    add     r1, rSELF, #offThread_retval  @ r1<- &retval
+    mov     r3, rSELF                   @ arg3<- self
+    ands    lr, #kSubModeMethodTrace
+    beq     121f                        @ hop if not profiling
+    @ r2: methodToCall, r6: rSELF
+    stmfd   sp!, {r2,r6}
+    stmfd   sp!, {r0-r3}
+    mov     r0, r2
+    mov     r1, r6
+    mov     lr, pc
+    ldr     pc, .LdvmFastMethodTraceEnter
+    ldmfd   sp!, {r0-r3}
+
+    mov     lr, pc
+    ldr     pc, [r2, #offMethod_nativeFunc]
+
+    ldmfd   sp!, {r0-r1}
+    mov     lr, pc
+    ldr     pc, .LdvmFastNativeMethodTraceExit
+    b       212f
+121:
+    mov     lr, pc
+    ldr     pc, [r2, #offMethod_nativeFunc]
+212:
+
+    @ native return; r10=newSaveArea
+    @ equivalent to dvmPopJniLocals
+    ldr     r2, [r10, #offStackSaveArea_returnAddr] @ r2 = chaining cell ret
+    ldr     r0, [r10, #offStackSaveArea_localRefCookie] @ r0<- saved->top
+    ldr     r1, [rSELF, #offThread_exception] @ check for exception
+    str     rFP, [rSELF, #offThread_curFrame]  @ curFrame = fp
+    cmp     r1, #0                      @ null?
+    str     r0, [rSELF, #offThread_jniLocal_topCookie] @ new top <- old top
+    ldr     r0, [r10, #offStackSaveArea_savedPc] @ reload rPC
+
+    @ r0 = dalvikCallsitePC
+    bne     .LhandleException           @ no, handle exception
+
+    str     r2, [rSELF, #offThread_inJitCodeCache] @ set the new mode
+    cmp     r2, #0                      @ return chaining cell still exists?
+    bxne    r2                          @ yes - go ahead
+
+    @ continue executing the next instruction through the interpreter
+    ldr     r1, .LdvmJitToInterpTraceSelectNoChain @ defined in footer.S
+    add     rPC, r0, #6                 @ reconstruct new rPC (advance 6 bytes)
+#if defined(WITH_JIT_TUNING)
+    mov     r0, #kCallsiteInterpreted
+#endif
+    mov     pc, r1
+
+/*
+ * On entry:
+ * r0  Faulting Dalvik PC
+ */
+.LhandleException:
+#if defined(WITH_SELF_VERIFICATION)
+    ldr     pc, .LdeadFood @ should not see this under self-verification mode
+.LdeadFood:
+    .word   0xdeadf00d
+#endif
+    mov     r2, #0
+    str     r2, [rSELF, #offThread_inJitCodeCache] @ in interpreter land
+    ldr     r1, .LdvmMterpCommonExceptionThrown @ PIC way of getting &func
+    ldr     rIBASE, .LdvmAsmInstructionStart    @ same as above
+    mov     rPC, r0                 @ reload the faulting Dalvik address
+    mov     pc, r1                  @ branch to dvmMterpCommonExceptionThrown
+
+    .align  2
+.LdvmAsmInstructionStart:
+    .word   dvmAsmInstructionStart
+.LdvmJitToInterpNoChainNoProfile:
+    .word   dvmJitToInterpNoChainNoProfile
+.LdvmJitToInterpTraceSelectNoChain:
+    .word   dvmJitToInterpTraceSelectNoChain
+.LdvmJitToInterpNoChain:
+    .word   dvmJitToInterpNoChain
+.LdvmMterpStdBail:
+    .word   dvmMterpStdBail
+.LdvmMterpCommonExceptionThrown:
+    .word   dvmMterpCommonExceptionThrown
+.LdvmLockObject:
+    .word   dvmLockObject
+.LdvmJitTraceProfilingOff:
+    .word   dvmJitTraceProfilingOff
+#if defined(WITH_JIT_TUNING)
+.LdvmICHitCount:
+    .word   gDvmICHitCount
+#endif
+#if defined(WITH_SELF_VERIFICATION)
+.LdvmSelfVerificationMemOpDecode:
+    .word   dvmSelfVerificationMemOpDecode
+#endif
+.LdvmFastMethodTraceEnter:
+    .word   dvmFastMethodTraceEnter
+.LdvmFastNativeMethodTraceExit:
+    .word   dvmFastNativeMethodTraceExit
+.LdvmFastMethodTraceExit:
+    .word   dvmFastMethodTraceExit
+.L__aeabi_cdcmple:
+    .word   __aeabi_cdcmple
+.L__aeabi_cfcmple:
+    .word   __aeabi_cfcmple
+
+    .global dmvCompilerTemplateEnd
+dmvCompilerTemplateEnd:
+
+#endif /* WITH_JIT */
+
diff --git a/vm/compiler/template_notaint/out/CompilerTemplateAsm-armv7-a.S b/vm/compiler/template_notaint/out/CompilerTemplateAsm-armv7-a.S
new file mode 100644
index 0000000..825ac40
--- /dev/null
+++ b/vm/compiler/template_notaint/out/CompilerTemplateAsm-armv7-a.S
@@ -0,0 +1,1981 @@
+/*
+ * This file was generated automatically by gen-template.py for 'armv7-a'.
+ *
+ * --> DO NOT EDIT <--
+ */
+
+/* File: armv5te/header.S */
+/*
+ * Copyright (C) 2008 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#if defined(WITH_JIT)
+
+/*
+ * ARMv5 definitions and declarations.
+ */
+
+/*
+ARM EABI general notes:
+
+r0-r3 hold first 4 args to a method; they are not preserved across method calls
+r4-r8 are available for general use
+r9 is given special treatment in some situations, but not for us
+r10 (sl) seems to be generally available
+r11 (fp) is used by gcc (unless -fomit-frame-pointer is set)
+r12 (ip) is scratch -- not preserved across method calls
+r13 (sp) should be managed carefully in case a signal arrives
+r14 (lr) must be preserved
+r15 (pc) can be tinkered with directly
+
+r0 holds returns of <= 4 bytes
+r0-r1 hold returns of 8 bytes, low word in r0
+
+Callee must save/restore r4+ (except r12) if it modifies them.
+
+Stack is "full descending".  Only the arguments that don't fit in the first 4
+registers are placed on the stack.  "sp" points at the first stacked argument
+(i.e. the 5th arg).
+
+VFP: single-precision results in s0, double-precision results in d0.
+
+In the EABI, "sp" must be 64-bit aligned on entry to a function, and any
+64-bit quantities (long long, double) must be 64-bit aligned.
+*/
+
+/*
+JIT and ARM notes:
+
+The following registers have fixed assignments:
+
+  reg nick      purpose
+  r5  rFP       interpreted frame pointer, used for accessing locals and args
+  r6  rSELF     thread pointer
+
+The following registers have fixed assignments in mterp but are scratch
+registers in compiled code
+
+  reg nick      purpose
+  r4  rPC       interpreted program counter, used for fetching instructions
+  r7  rINST     first 16-bit code unit of current instruction
+  r8  rIBASE    interpreted instruction base pointer, used for computed goto
+
+Macros are provided for common operations.  Each macro MUST emit only
+one instruction to make instruction-counting easier.  They MUST NOT alter
+unspecified registers or condition codes.
+*/
+
+/* single-purpose registers, given names for clarity */
+#define rPC     r4
+#define rFP     r5
+#define rSELF   r6
+#define rINST   r7
+#define rIBASE  r8
+
+/*
+ * Given a frame pointer, find the stack save area.
+ *
+ * In C this is "((StackSaveArea*)(_fp) -1)".
+ */
+#define SAVEAREA_FROM_FP(_reg, _fpreg) \
+    sub     _reg, _fpreg, #sizeofStackSaveArea
+
+#define EXPORT_PC() \
+    str     rPC, [rFP, #(-sizeofStackSaveArea + offStackSaveArea_currentPc)]
+
+/*
+ * This is a #include, not a %include, because we want the C pre-processor
+ * to expand the macros into assembler assignment statements.
+ */
+#include "../../../mterp/common/asm-constants.h"
+
+/* File: armv5te-vfp/platform.S */
+/*
+ * ===========================================================================
+ *  CPU-version-specific defines and utility
+ * ===========================================================================
+ */
+
+
+    .global dvmCompilerTemplateStart
+    .type   dvmCompilerTemplateStart, %function
+    .text
+
+dvmCompilerTemplateStart:
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_CMP_LONG
+dvmCompiler_TEMPLATE_CMP_LONG:
+/* File: armv5te/TEMPLATE_CMP_LONG.S */
+    /*
+     * Compare two 64-bit values.  Puts 0, 1, or -1 into the destination
+     * register based on the results of the comparison.
+     *
+     * We load the full values with LDM, but in practice many values could
+     * be resolved by only looking at the high word.  This could be made
+     * faster or slower by splitting the LDM into a pair of LDRs.
+     *
+     * If we just wanted to set condition flags, we could do this:
+     *  subs    ip, r0, r2
+     *  sbcs    ip, r1, r3
+     *  subeqs  ip, r0, r2
+     * Leaving { <0, 0, >0 } in ip.  However, we have to set it to a specific
+     * integer value, which we can do with 2 conditional mov/mvn instructions
+     * (set 1, set -1; if they're equal we already have 0 in ip), giving
+     * us a constant 5-cycle path plus a branch at the end to the
+     * instruction epilogue code.  The multi-compare approach below needs
+     * 2 or 3 cycles + branch if the high word doesn't match, 6 + branch
+     * in the worst case (the 64-bit values are equal).
+     */
+    /* cmp-long vAA, vBB, vCC */
+    cmp     r1, r3                      @ compare (vBB+1, vCC+1)
+    blt     .LTEMPLATE_CMP_LONG_less            @ signed compare on high part
+    bgt     .LTEMPLATE_CMP_LONG_greater
+    subs    r0, r0, r2                  @ r0<- r0 - r2
+    bxeq     lr
+    bhi     .LTEMPLATE_CMP_LONG_greater         @ unsigned compare on low part
+.LTEMPLATE_CMP_LONG_less:
+    mvn     r0, #0                      @ r0<- -1
+    bx      lr
+.LTEMPLATE_CMP_LONG_greater:
+    mov     r0, #1                      @ r0<- 1
+    bx      lr
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_RETURN
+dvmCompiler_TEMPLATE_RETURN:
+/* File: armv5te/TEMPLATE_RETURN.S */
+    /*
+     * Unwind a frame from the Dalvik stack for compiled OP_RETURN_XXX.
+     * If the stored value in returnAddr
+     * is non-zero, the caller is compiled by the JIT thus return to the
+     * address in the code cache following the invoke instruction. Otherwise
+     * return to the special dvmJitToInterpNoChain entry point.
+     */
+#if defined(TEMPLATE_INLINE_PROFILING)
+    stmfd   sp!, {r0-r2,lr}             @ preserve live registers
+    mov     r0, r6
+    @ r0=rSELF
+    mov     lr, pc
+    ldr     pc, .LdvmFastMethodTraceExit
+    ldmfd   sp!, {r0-r2,lr}             @ restore live registers
+#endif
+    SAVEAREA_FROM_FP(r0, rFP)           @ r0<- saveArea (old)
+    ldr     r10, [r0, #offStackSaveArea_prevFrame] @ r10<- saveArea->prevFrame
+    ldrb    r8, [rSELF, #offThread_breakFlags] @ r8<- breakFlags
+    ldr     rPC, [r0, #offStackSaveArea_savedPc] @ rPC<- saveArea->savedPc
+#if !defined(WITH_SELF_VERIFICATION)
+    ldr     r9,  [r0, #offStackSaveArea_returnAddr] @ r9<- chaining cell ret
+#else
+    mov     r9, #0                      @ disable chaining
+#endif
+    ldr     r2, [r10, #(offStackSaveArea_method - sizeofStackSaveArea)]
+                                        @ r2<- method we're returning to
+    cmp     r2, #0                      @ break frame?
+#if !defined(WITH_SELF_VERIFICATION)
+    beq     1f                          @ bail to interpreter
+#else
+    blxeq   lr                          @ punt to interpreter and compare state
+#endif
+    ldr     r1, .LdvmJitToInterpNoChainNoProfile @ defined in footer.S
+    mov     rFP, r10                    @ publish new FP
+    ldr     r10, [r2, #offMethod_clazz] @ r10<- method->clazz
+
+    str     r2, [rSELF, #offThread_method]@ self->method = newSave->method
+    ldr     r0, [r10, #offClassObject_pDvmDex] @ r0<- method->clazz->pDvmDex
+    str     rFP, [rSELF, #offThread_curFrame] @ curFrame = fp
+    add     rPC, rPC, #6                @ publish new rPC (advance 6 bytes)
+    str     r0, [rSELF, #offThread_methodClassDex]
+    cmp     r8, #0                      @ check the break flags
+    movne   r9, #0                      @ clear the chaining cell address
+    str     r9, [rSELF, #offThread_inJitCodeCache] @ in code cache or not
+    cmp     r9, #0                      @ chaining cell exists?
+    blxne   r9                          @ jump to the chaining cell
+#if defined(WITH_JIT_TUNING)
+    mov     r0, #kCallsiteInterpreted
+#endif
+    mov     pc, r1                      @ callsite is interpreted
+1:
+    mov     r0, #0
+    str     r0, [rSELF, #offThread_inJitCodeCache] @ reset inJitCodeCache
+    stmia   rSELF, {rPC, rFP}           @ SAVE_PC_FP_TO_SELF()
+    ldr     r2, .LdvmMterpStdBail       @ defined in footer.S
+    mov     r0, rSELF                   @ Expecting rSELF in r0
+    blx     r2                          @ exit the interpreter
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_INVOKE_METHOD_NO_OPT
+dvmCompiler_TEMPLATE_INVOKE_METHOD_NO_OPT:
+/* File: armv5te/TEMPLATE_INVOKE_METHOD_NO_OPT.S */
+    /*
+     * For polymorphic callsites - setup the Dalvik frame and load Dalvik PC
+     * into rPC then jump to dvmJitToInterpNoChain to dispatch the
+     * runtime-resolved callee.
+     */
+    @ r0 = methodToCall, r1 = returnCell, rPC = dalvikCallsite
+    ldrh    r7, [r0, #offMethod_registersSize]  @ r7<- methodToCall->regsSize
+    ldrh    r2, [r0, #offMethod_outsSize]  @ r2<- methodToCall->outsSize
+    ldr     r9, [rSELF, #offThread_interpStackEnd]    @ r9<- interpStackEnd
+    ldrb    r8, [rSELF, #offThread_breakFlags] @ r8<- breakFlags
+    add     r3, r1, #1  @ Thumb addr is odd
+    SAVEAREA_FROM_FP(r1, rFP)           @ r1<- stack save area
+    sub     r1, r1, r7, lsl #2          @ r1<- newFp (old savearea - regsSize)
+    SAVEAREA_FROM_FP(r10, r1)           @ r10<- stack save area
+    sub     r10, r10, r2, lsl #2        @ r10<- bottom (newsave - outsSize)
+    cmp     r10, r9                     @ bottom < interpStackEnd?
+    bxlo    lr                          @ return to raise stack overflow excep.
+    @ r1 = newFP, r0 = methodToCall, r3 = returnCell, rPC = dalvikCallsite
+    ldr     r9, [r0, #offMethod_clazz]      @ r9<- method->clazz
+    ldr     r10, [r0, #offMethod_accessFlags] @ r10<- methodToCall->accessFlags
+    str     rPC, [rFP, #(offStackSaveArea_currentPc - sizeofStackSaveArea)]
+    str     rPC, [r1, #(offStackSaveArea_savedPc - sizeofStackSaveArea)]
+    ldr     rPC, [r0, #offMethod_insns]     @ rPC<- methodToCall->insns
+
+
+    @ set up newSaveArea
+    str     rFP, [r1, #(offStackSaveArea_prevFrame - sizeofStackSaveArea)]
+    str     r3, [r1, #(offStackSaveArea_returnAddr - sizeofStackSaveArea)]
+    str     r0, [r1, #(offStackSaveArea_method - sizeofStackSaveArea)]
+    cmp     r8, #0                      @ breakFlags != 0
+    bxne    lr                          @ bail to the interpreter
+    tst     r10, #ACC_NATIVE
+#if !defined(WITH_SELF_VERIFICATION)
+    bne     .LinvokeNative
+#else
+    bxne    lr                          @ bail to the interpreter
+#endif
+
+    ldr     r10, .LdvmJitToInterpTraceSelectNoChain
+    ldr     r3, [r9, #offClassObject_pDvmDex] @ r3<- method->clazz->pDvmDex
+
+    @ Update "thread" values for the new method
+    str     r0, [rSELF, #offThread_method]    @ self->method = methodToCall
+    str     r3, [rSELF, #offThread_methodClassDex] @ self->methodClassDex = ...
+    mov     rFP, r1                         @ fp = newFp
+    str     rFP, [rSELF, #offThread_curFrame]  @ curFrame = newFp
+#if defined(TEMPLATE_INLINE_PROFILING)
+    stmfd   sp!, {r0-r3}                    @ preserve r0-r3
+    mov     r1, r6
+    @ r0=methodToCall, r1=rSELF
+    mov     lr, pc
+    ldr     pc, .LdvmFastMethodTraceEnter
+    ldmfd   sp!, {r0-r3}                    @ restore r0-r3
+#endif
+
+    @ Start executing the callee
+#if defined(WITH_JIT_TUNING)
+    mov     r0, #kInlineCacheMiss
+#endif
+    mov     pc, r10                         @ dvmJitToInterpTraceSelectNoChain
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_INVOKE_METHOD_CHAIN
+dvmCompiler_TEMPLATE_INVOKE_METHOD_CHAIN:
+/* File: armv5te/TEMPLATE_INVOKE_METHOD_CHAIN.S */
+    /*
+     * For monomorphic callsite, setup the Dalvik frame and return to the
+     * Thumb code through the link register to transfer control to the callee
+     * method through a dedicated chaining cell.
+     */
+    @ r0 = methodToCall, r1 = returnCell, r2 = methodToCall->outsSize
+    @ rPC = dalvikCallsite, r7 = methodToCall->registersSize
+    @ methodToCall is guaranteed to be non-native
+.LinvokeChain:
+    ldr     r9, [rSELF, #offThread_interpStackEnd]    @ r9<- interpStackEnd
+    ldrb    r8, [rSELF, #offThread_breakFlags]        @ r8<- breakFlags
+    add     r3, r1, #1  @ Thumb addr is odd
+    SAVEAREA_FROM_FP(r1, rFP)           @ r1<- stack save area
+    sub     r1, r1, r7, lsl #2          @ r1<- newFp (old savearea - regsSize)
+    SAVEAREA_FROM_FP(r10, r1)           @ r10<- stack save area
+    add     r12, lr, #2                 @ setup the punt-to-interp address
+    sub     r10, r10, r2, lsl #2        @ r10<- bottom (newsave - outsSize)
+    cmp     r10, r9                     @ bottom < interpStackEnd?
+    bxlo    r12                         @ return to raise stack overflow excep.
+    @ r1 = newFP, r0 = methodToCall, r3 = returnCell, rPC = dalvikCallsite
+    ldr     r9, [r0, #offMethod_clazz]      @ r9<- method->clazz
+    str     rPC, [rFP, #(offStackSaveArea_currentPc - sizeofStackSaveArea)]
+    str     rPC, [r1, #(offStackSaveArea_savedPc - sizeofStackSaveArea)]
+
+    @ set up newSaveArea
+    str     rFP, [r1, #(offStackSaveArea_prevFrame - sizeofStackSaveArea)]
+    str     r3, [r1, #(offStackSaveArea_returnAddr - sizeofStackSaveArea)]
+    str     r0, [r1, #(offStackSaveArea_method - sizeofStackSaveArea)]
+    cmp     r8, #0                      @ breakFlags != 0
+    bxne    r12                         @ bail to the interpreter
+
+    ldr     r3, [r9, #offClassObject_pDvmDex] @ r3<- method->clazz->pDvmDex
+
+    @ Update "thread" values for the new method
+    str     r0, [rSELF, #offThread_method]    @ self->method = methodToCall
+    str     r3, [rSELF, #offThread_methodClassDex] @ self->methodClassDex = ...
+    mov     rFP, r1                         @ fp = newFp
+    str     rFP, [rSELF, #offThread_curFrame]  @ curFrame = newFp
+#if defined(TEMPLATE_INLINE_PROFILING)
+    stmfd   sp!, {r0-r2,lr}             @ preserve clobbered live registers
+    mov     r1, r6
+    @ r0=methodToCall, r1=rSELF
+    mov     lr, pc
+    ldr     pc, .LdvmFastMethodTraceEnter
+    ldmfd   sp!, {r0-r2,lr}             @ restore registers
+#endif
+
+    bx      lr                              @ return to the callee-chaining cell
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_INVOKE_METHOD_PREDICTED_CHAIN
+dvmCompiler_TEMPLATE_INVOKE_METHOD_PREDICTED_CHAIN:
+/* File: armv5te/TEMPLATE_INVOKE_METHOD_PREDICTED_CHAIN.S */
+    /*
+     * For polymorphic callsite, check whether the cached class pointer matches
+     * the current one. If so setup the Dalvik frame and return to the
+     * Thumb code through the link register to transfer control to the callee
+     * method through a dedicated chaining cell.
+     *
+     * The predicted chaining cell is declared in ArmLIR.h with the
+     * following layout:
+     *
+     *  typedef struct PredictedChainingCell {
+     *      u4 branch;
+     *      const ClassObject *clazz;
+     *      const Method *method;
+     *      u4 counter;
+     *  } PredictedChainingCell;
+     *
+     * Upon returning to the callsite:
+     *    - lr  : to branch to the chaining cell
+     *    - lr+2: to punt to the interpreter
+     *    - lr+4: to fully resolve the callee and may rechain.
+     *            r3 <- class
+     *            r9 <- counter
+     */
+    @ r0 = this, r1 = returnCell, r2 = predictedChainCell, rPC = dalvikCallsite
+    ldr     r3, [r0, #offObject_clazz]  @ r3 <- this->class
+    ldr     r8, [r2, #4]    @ r8 <- predictedChainCell->clazz
+    ldr     r0, [r2, #8]    @ r0 <- predictedChainCell->method
+    ldr     r9, [rSELF, #offThread_icRechainCount] @ r1 <- shared rechainCount
+    cmp     r3, r8          @ predicted class == actual class?
+#if defined(WITH_JIT_TUNING)
+    ldr     r7, .LdvmICHitCount
+#if defined(WORKAROUND_CORTEX_A9_745320)
+    /* Don't use conditional loads if the HW defect exists */
+    bne     101f
+    ldr     r10, [r7, #0]
+101:
+#else
+    ldreq   r10, [r7, #0]
+#endif
+    add     r10, r10, #1
+    streq   r10, [r7, #0]
+#endif
+    ldreqh  r7, [r0, #offMethod_registersSize]  @ r7<- methodToCall->regsSize
+    ldreqh  r2, [r0, #offMethod_outsSize]  @ r2<- methodToCall->outsSize
+    beq     .LinvokeChain   @ predicted chain is valid
+    ldr     r7, [r3, #offClassObject_vtable] @ r7 <- this->class->vtable
+    cmp     r8, #0          @ initialized class or not
+    moveq   r1, #0
+    subne   r1, r9, #1      @ count--
+    strne   r1, [rSELF, #offThread_icRechainCount]  @ write back to thread
+    add     lr, lr, #4      @ return to fully-resolve landing pad
+    /*
+     * r1 <- count
+     * r2 <- &predictedChainCell
+     * r3 <- this->class
+     * r4 <- dPC
+     * r7 <- this->class->vtable
+     */
+    bx      lr
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_INVOKE_METHOD_NATIVE
+dvmCompiler_TEMPLATE_INVOKE_METHOD_NATIVE:
+/* File: armv5te/TEMPLATE_INVOKE_METHOD_NATIVE.S */
+    @ r0 = methodToCall, r1 = returnCell, rPC = dalvikCallsite
+    @ r7 = methodToCall->registersSize
+    ldr     r9, [rSELF, #offThread_interpStackEnd]    @ r9<- interpStackEnd
+    ldrb    r8, [rSELF, #offThread_breakFlags]        @ r8<- breakFlags
+    add     r3, r1, #1  @ Thumb addr is odd
+    SAVEAREA_FROM_FP(r1, rFP)           @ r1<- stack save area
+    sub     r1, r1, r7, lsl #2          @ r1<- newFp (old savearea - regsSize)
+    SAVEAREA_FROM_FP(r10, r1)           @ r10<- stack save area
+    cmp     r10, r9                     @ bottom < interpStackEnd?
+    bxlo    lr                          @ return to raise stack overflow excep.
+    @ r1 = newFP, r0 = methodToCall, r3 = returnCell, rPC = dalvikCallsite
+    str     rPC, [rFP, #(offStackSaveArea_currentPc - sizeofStackSaveArea)]
+    str     rPC, [r1, #(offStackSaveArea_savedPc - sizeofStackSaveArea)]
+
+    @ set up newSaveArea
+    str     rFP, [r1, #(offStackSaveArea_prevFrame - sizeofStackSaveArea)]
+    str     r3, [r1, #(offStackSaveArea_returnAddr - sizeofStackSaveArea)]
+    str     r0, [r1, #(offStackSaveArea_method - sizeofStackSaveArea)]
+    cmp     r8, #0                      @ breakFlags != 0
+    ldr     r8, [r0, #offMethod_nativeFunc] @ r8<- method->nativeFunc
+#if !defined(WITH_SELF_VERIFICATION)
+    bxne    lr                          @ bail to the interpreter
+#else
+    bx      lr                          @ bail to interpreter unconditionally
+#endif
+
+    @ go ahead and transfer control to the native code
+    ldr     r9, [rSELF, #offThread_jniLocal_topCookie]@r9<-thread->localRef->...
+    mov     r2, #0
+    str     r1, [rSELF, #offThread_curFrame]   @ curFrame = newFp
+    str     r2, [rSELF, #offThread_inJitCodeCache] @ not in the jit code cache
+    str     r9, [r1, #(offStackSaveArea_localRefCookie - sizeofStackSaveArea)]
+                                        @ newFp->localRefCookie=top
+    SAVEAREA_FROM_FP(r10, r1)           @ r10<- new stack save area
+
+    mov     r2, r0                        @ arg2<- methodToCall
+    mov     r0, r1                        @ arg0<- newFP
+    add     r1, rSELF, #offThread_retval  @ arg1<- &retval
+    mov     r3, rSELF                     @ arg3<- self
+#if defined(TEMPLATE_INLINE_PROFILING)
+    @ r2=methodToCall, r6=rSELF
+    stmfd   sp!, {r2,r6}                @ to be consumed after JNI return
+    stmfd   sp!, {r0-r3}                @ preserve r0-r3
+    mov     r0, r2
+    mov     r1, r6
+    @ r0=JNIMethod, r1=rSELF
+    mov     lr, pc
+    ldr     pc, .LdvmFastMethodTraceEnter
+    ldmfd   sp!, {r0-r3}                @ restore r0-r3
+#endif
+
+    blx     r8                          @ off to the native code
+
+#if defined(TEMPLATE_INLINE_PROFILING)
+    ldmfd   sp!, {r0-r1}                @ restore r2 and r6
+    @ r0=JNIMethod, r1=rSELF
+    mov     lr, pc
+    ldr     pc, .LdvmFastNativeMethodTraceExit
+#endif
+    @ native return; r10=newSaveArea
+    @ equivalent to dvmPopJniLocals
+    ldr     r2, [r10, #offStackSaveArea_returnAddr] @ r2 = chaining cell ret
+    ldr     r0, [r10, #offStackSaveArea_localRefCookie] @ r0<- saved->top
+    ldr     r1, [rSELF, #offThread_exception] @ check for exception
+    str     rFP, [rSELF, #offThread_curFrame]  @ curFrame = fp
+    cmp     r1, #0                      @ null?
+    str     r0, [rSELF, #offThread_jniLocal_topCookie] @ new top <- old top
+    ldr     r0, [rFP, #(offStackSaveArea_currentPc - sizeofStackSaveArea)]
+
+    @ r0 = dalvikCallsitePC
+    bne     .LhandleException           @ no, handle exception
+
+    str     r2, [rSELF, #offThread_inJitCodeCache] @ set the mode properly
+    cmp     r2, #0                      @ return chaining cell still exists?
+    bxne    r2                          @ yes - go ahead
+
+    @ continue executing the next instruction through the interpreter
+    ldr     r1, .LdvmJitToInterpTraceSelectNoChain @ defined in footer.S
+    add     rPC, r0, #6                 @ reconstruct new rPC (advance 6 bytes)
+#if defined(WITH_JIT_TUNING)
+    mov     r0, #kCallsiteInterpreted
+#endif
+    mov     pc, r1
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_MUL_LONG
+dvmCompiler_TEMPLATE_MUL_LONG:
+/* File: armv5te/TEMPLATE_MUL_LONG.S */
+    /*
+     * Signed 64-bit integer multiply.
+     *
+     * For JIT: op1 in r0/r1, op2 in r2/r3, return in r0/r1
+     *
+     * Consider WXxYZ (r1r0 x r3r2) with a long multiply:
+     *        WX
+     *      x YZ
+     *  --------
+     *     ZW ZX
+     *  YW YX
+     *
+     * The low word of the result holds ZX, the high word holds
+     * (ZW+YX) + (the high overflow from ZX).  YW doesn't matter because
+     * it doesn't fit in the low 64 bits.
+     *
+     * Unlike most ARM math operations, multiply instructions have
+     * restrictions on using the same register more than once (Rd and Rm
+     * cannot be the same).
+     */
+    /* mul-long vAA, vBB, vCC */
+    mul     ip, r2, r1                  @  ip<- ZxW
+    umull   r9, r10, r2, r0             @  r9/r10 <- ZxX
+    mla     r2, r0, r3, ip              @  r2<- YxX + (ZxW)
+    add     r10, r2, r10                @  r10<- r10 + low(ZxW + (YxX))
+    mov     r0,r9
+    mov     r1,r10
+    bx      lr
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_SHL_LONG
+dvmCompiler_TEMPLATE_SHL_LONG:
+/* File: armv5te/TEMPLATE_SHL_LONG.S */
+    /*
+     * Long integer shift.  This is different from the generic 32/64-bit
+     * binary operations because vAA/vBB are 64-bit but vCC (the shift
+     * distance) is 32-bit.  Also, Dalvik requires us to ignore all but the low
+     * 6 bits.
+     */
+    /* shl-long vAA, vBB, vCC */
+    and     r2, r2, #63                 @ r2<- r2 & 0x3f
+    mov     r1, r1, asl r2              @  r1<- r1 << r2
+    rsb     r3, r2, #32                 @  r3<- 32 - r2
+    orr     r1, r1, r0, lsr r3          @  r1<- r1 | (r0 << (32-r2))
+    subs    ip, r2, #32                 @  ip<- r2 - 32
+    movpl   r1, r0, asl ip              @  if r2 >= 32, r1<- r0 << (r2-32)
+    mov     r0, r0, asl r2              @  r0<- r0 << r2
+    bx      lr
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_SHR_LONG
+dvmCompiler_TEMPLATE_SHR_LONG:
+/* File: armv5te/TEMPLATE_SHR_LONG.S */
+    /*
+     * Long integer shift.  This is different from the generic 32/64-bit
+     * binary operations because vAA/vBB are 64-bit but vCC (the shift
+     * distance) is 32-bit.  Also, Dalvik requires us to ignore all but the low
+     * 6 bits.
+     */
+    /* shr-long vAA, vBB, vCC */
+    and     r2, r2, #63                 @ r0<- r0 & 0x3f
+    mov     r0, r0, lsr r2              @  r0<- r2 >> r2
+    rsb     r3, r2, #32                 @  r3<- 32 - r2
+    orr     r0, r0, r1, asl r3          @  r0<- r0 | (r1 << (32-r2))
+    subs    ip, r2, #32                 @  ip<- r2 - 32
+    movpl   r0, r1, asr ip              @  if r2 >= 32, r0<-r1 >> (r2-32)
+    mov     r1, r1, asr r2              @  r1<- r1 >> r2
+    bx      lr
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_USHR_LONG
+dvmCompiler_TEMPLATE_USHR_LONG:
+/* File: armv5te/TEMPLATE_USHR_LONG.S */
+    /*
+     * Long integer shift.  This is different from the generic 32/64-bit
+     * binary operations because vAA/vBB are 64-bit but vCC (the shift
+     * distance) is 32-bit.  Also, Dalvik requires us to ignore all but the low
+     * 6 bits.
+     */
+    /* ushr-long vAA, vBB, vCC */
+    and     r2, r2, #63                 @ r0<- r0 & 0x3f
+    mov     r0, r0, lsr r2              @  r0<- r2 >> r2
+    rsb     r3, r2, #32                 @  r3<- 32 - r2
+    orr     r0, r0, r1, asl r3          @  r0<- r0 | (r1 << (32-r2))
+    subs    ip, r2, #32                 @  ip<- r2 - 32
+    movpl   r0, r1, lsr ip              @  if r2 >= 32, r0<-r1 >>> (r2-32)
+    mov     r1, r1, lsr r2              @  r1<- r1 >>> r2
+    bx      lr
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_ADD_FLOAT_VFP
+dvmCompiler_TEMPLATE_ADD_FLOAT_VFP:
+/* File: armv5te-vfp/TEMPLATE_ADD_FLOAT_VFP.S */
+/* File: armv5te-vfp/fbinop.S */
+    /*
+     * Generic 32-bit floating point operation.  Provide an "instr" line that
+     * specifies an instruction that performs s2 = s0 op s1.
+     *
+     * On entry:
+     *     r0 = target dalvik register address
+     *     r1 = op1 address
+     *     r2 = op2 address
+     */
+     flds    s0,[r1]
+     flds    s1,[r2]
+     fadds   s2, s0, s1
+     fsts    s2,[r0]
+     bx      lr
+
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_SUB_FLOAT_VFP
+dvmCompiler_TEMPLATE_SUB_FLOAT_VFP:
+/* File: armv5te-vfp/TEMPLATE_SUB_FLOAT_VFP.S */
+/* File: armv5te-vfp/fbinop.S */
+    /*
+     * Generic 32-bit floating point operation.  Provide an "instr" line that
+     * specifies an instruction that performs s2 = s0 op s1.
+     *
+     * On entry:
+     *     r0 = target dalvik register address
+     *     r1 = op1 address
+     *     r2 = op2 address
+     */
+     flds    s0,[r1]
+     flds    s1,[r2]
+     fsubs   s2, s0, s1
+     fsts    s2,[r0]
+     bx      lr
+
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_MUL_FLOAT_VFP
+dvmCompiler_TEMPLATE_MUL_FLOAT_VFP:
+/* File: armv5te-vfp/TEMPLATE_MUL_FLOAT_VFP.S */
+/* File: armv5te-vfp/fbinop.S */
+    /*
+     * Generic 32-bit floating point operation.  Provide an "instr" line that
+     * specifies an instruction that performs s2 = s0 op s1.
+     *
+     * On entry:
+     *     r0 = target dalvik register address
+     *     r1 = op1 address
+     *     r2 = op2 address
+     */
+     flds    s0,[r1]
+     flds    s1,[r2]
+     fmuls   s2, s0, s1
+     fsts    s2,[r0]
+     bx      lr
+
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_DIV_FLOAT_VFP
+dvmCompiler_TEMPLATE_DIV_FLOAT_VFP:
+/* File: armv5te-vfp/TEMPLATE_DIV_FLOAT_VFP.S */
+/* File: armv5te-vfp/fbinop.S */
+    /*
+     * Generic 32-bit floating point operation.  Provide an "instr" line that
+     * specifies an instruction that performs s2 = s0 op s1.
+     *
+     * On entry:
+     *     r0 = target dalvik register address
+     *     r1 = op1 address
+     *     r2 = op2 address
+     */
+     flds    s0,[r1]
+     flds    s1,[r2]
+     fdivs   s2, s0, s1
+     fsts    s2,[r0]
+     bx      lr
+
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_ADD_DOUBLE_VFP
+dvmCompiler_TEMPLATE_ADD_DOUBLE_VFP:
+/* File: armv5te-vfp/TEMPLATE_ADD_DOUBLE_VFP.S */
+/* File: armv5te-vfp/fbinopWide.S */
+    /*
+     * Generic 64-bit floating point operation.  Provide an "instr" line that
+     * specifies an instruction that performs s2 = s0 op s1.
+     *
+     * On entry:
+     *     r0 = target dalvik register address
+     *     r1 = op1 address
+     *     r2 = op2 address
+     */
+     fldd    d0,[r1]
+     fldd    d1,[r2]
+     faddd   d2, d0, d1
+     fstd    d2,[r0]
+     bx      lr
+
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_SUB_DOUBLE_VFP
+dvmCompiler_TEMPLATE_SUB_DOUBLE_VFP:
+/* File: armv5te-vfp/TEMPLATE_SUB_DOUBLE_VFP.S */
+/* File: armv5te-vfp/fbinopWide.S */
+    /*
+     * Generic 64-bit floating point operation.  Provide an "instr" line that
+     * specifies an instruction that performs s2 = s0 op s1.
+     *
+     * On entry:
+     *     r0 = target dalvik register address
+     *     r1 = op1 address
+     *     r2 = op2 address
+     */
+     fldd    d0,[r1]
+     fldd    d1,[r2]
+     fsubd   d2, d0, d1
+     fstd    d2,[r0]
+     bx      lr
+
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_MUL_DOUBLE_VFP
+dvmCompiler_TEMPLATE_MUL_DOUBLE_VFP:
+/* File: armv5te-vfp/TEMPLATE_MUL_DOUBLE_VFP.S */
+/* File: armv5te-vfp/fbinopWide.S */
+    /*
+     * Generic 64-bit floating point operation.  Provide an "instr" line that
+     * specifies an instruction that performs s2 = s0 op s1.
+     *
+     * On entry:
+     *     r0 = target dalvik register address
+     *     r1 = op1 address
+     *     r2 = op2 address
+     */
+     fldd    d0,[r1]
+     fldd    d1,[r2]
+     fmuld   d2, d0, d1
+     fstd    d2,[r0]
+     bx      lr
+
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_DIV_DOUBLE_VFP
+dvmCompiler_TEMPLATE_DIV_DOUBLE_VFP:
+/* File: armv5te-vfp/TEMPLATE_DIV_DOUBLE_VFP.S */
+/* File: armv5te-vfp/fbinopWide.S */
+    /*
+     * Generic 64-bit floating point operation.  Provide an "instr" line that
+     * specifies an instruction that performs s2 = s0 op s1.
+     *
+     * On entry:
+     *     r0 = target dalvik register address
+     *     r1 = op1 address
+     *     r2 = op2 address
+     */
+     fldd    d0,[r1]
+     fldd    d1,[r2]
+     fdivd   d2, d0, d1
+     fstd    d2,[r0]
+     bx      lr
+
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_DOUBLE_TO_FLOAT_VFP
+dvmCompiler_TEMPLATE_DOUBLE_TO_FLOAT_VFP:
+/* File: armv5te-vfp/TEMPLATE_DOUBLE_TO_FLOAT_VFP.S */
+/* File: armv5te-vfp/funopNarrower.S */
+    /*
+     * Generic 64bit-to-32bit floating point unary operation.  Provide an
+     * "instr" line that specifies an instruction that performs "s0 = op d0".
+     *
+     * For: double-to-int, double-to-float
+     *
+     * On entry:
+     *     r0 = target dalvik register address
+     *     r1 = src dalvik register address
+     */
+    /* unop vA, vB */
+    fldd    d0, [r1]                    @ d0<- vB
+    fcvtsd  s0, d0                              @ s0<- op d0
+    fsts    s0, [r0]                    @ vA<- s0
+    bx      lr
+
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_DOUBLE_TO_INT_VFP
+dvmCompiler_TEMPLATE_DOUBLE_TO_INT_VFP:
+/* File: armv5te-vfp/TEMPLATE_DOUBLE_TO_INT_VFP.S */
+/* File: armv5te-vfp/funopNarrower.S */
+    /*
+     * Generic 64bit-to-32bit floating point unary operation.  Provide an
+     * "instr" line that specifies an instruction that performs "s0 = op d0".
+     *
+     * For: double-to-int, double-to-float
+     *
+     * On entry:
+     *     r0 = target dalvik register address
+     *     r1 = src dalvik register address
+     */
+    /* unop vA, vB */
+    fldd    d0, [r1]                    @ d0<- vB
+    ftosizd  s0, d0                              @ s0<- op d0
+    fsts    s0, [r0]                    @ vA<- s0
+    bx      lr
+
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_FLOAT_TO_DOUBLE_VFP
+dvmCompiler_TEMPLATE_FLOAT_TO_DOUBLE_VFP:
+/* File: armv5te-vfp/TEMPLATE_FLOAT_TO_DOUBLE_VFP.S */
+/* File: armv5te-vfp/funopWider.S */
+    /*
+     * Generic 32bit-to-64bit floating point unary operation.  Provide an
+     * "instr" line that specifies an instruction that performs "d0 = op s0".
+     *
+     * For: int-to-double, float-to-double
+     *
+     * On entry:
+     *     r0 = target dalvik register address
+     *     r1 = src dalvik register address
+     */
+    /* unop vA, vB */
+    flds    s0, [r1]                    @ s0<- vB
+    fcvtds  d0, s0                              @ d0<- op s0
+    fstd    d0, [r0]                    @ vA<- d0
+    bx      lr
+
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_FLOAT_TO_INT_VFP
+dvmCompiler_TEMPLATE_FLOAT_TO_INT_VFP:
+/* File: armv5te-vfp/TEMPLATE_FLOAT_TO_INT_VFP.S */
+/* File: armv5te-vfp/funop.S */
+    /*
+     * Generic 32bit-to-32bit floating point unary operation.  Provide an
+     * "instr" line that specifies an instruction that performs "s1 = op s0".
+     *
+     * For: float-to-int, int-to-float
+     *
+     * On entry:
+     *     r0 = target dalvik register address
+     *     r1 = src dalvik register address
+     */
+    /* unop vA, vB */
+    flds    s0, [r1]                    @ s0<- vB
+    ftosizs s1, s0                              @ s1<- op s0
+    fsts    s1, [r0]                    @ vA<- s1
+    bx      lr
+
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_INT_TO_DOUBLE_VFP
+dvmCompiler_TEMPLATE_INT_TO_DOUBLE_VFP:
+/* File: armv5te-vfp/TEMPLATE_INT_TO_DOUBLE_VFP.S */
+/* File: armv5te-vfp/funopWider.S */
+    /*
+     * Generic 32bit-to-64bit floating point unary operation.  Provide an
+     * "instr" line that specifies an instruction that performs "d0 = op s0".
+     *
+     * For: int-to-double, float-to-double
+     *
+     * On entry:
+     *     r0 = target dalvik register address
+     *     r1 = src dalvik register address
+     */
+    /* unop vA, vB */
+    flds    s0, [r1]                    @ s0<- vB
+    fsitod  d0, s0                              @ d0<- op s0
+    fstd    d0, [r0]                    @ vA<- d0
+    bx      lr
+
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_INT_TO_FLOAT_VFP
+dvmCompiler_TEMPLATE_INT_TO_FLOAT_VFP:
+/* File: armv5te-vfp/TEMPLATE_INT_TO_FLOAT_VFP.S */
+/* File: armv5te-vfp/funop.S */
+    /*
+     * Generic 32bit-to-32bit floating point unary operation.  Provide an
+     * "instr" line that specifies an instruction that performs "s1 = op s0".
+     *
+     * For: float-to-int, int-to-float
+     *
+     * On entry:
+     *     r0 = target dalvik register address
+     *     r1 = src dalvik register address
+     */
+    /* unop vA, vB */
+    flds    s0, [r1]                    @ s0<- vB
+    fsitos  s1, s0                              @ s1<- op s0
+    fsts    s1, [r0]                    @ vA<- s1
+    bx      lr
+
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_CMPG_DOUBLE_VFP
+dvmCompiler_TEMPLATE_CMPG_DOUBLE_VFP:
+/* File: armv5te-vfp/TEMPLATE_CMPG_DOUBLE_VFP.S */
+    /*
+     * Compare two floating-point values.  Puts 0, 1, or -1 into the
+     * destination register based on the results of the comparison.
+     *
+     * int compare(x, y) {
+     *     if (x == y) {
+     *         return 0;
+     *     } else if (x < y) {
+     *         return -1;
+     *     } else if (x > y) {
+     *         return 1;
+     *     } else {
+     *         return 1;
+     *     }
+     * }
+     *
+     * On entry:
+     *    r0 = &op1 [vBB]
+     *    r1 = &op2 [vCC]
+     */
+    /* op vAA, vBB, vCC */
+    fldd    d0, [r0]                    @ d0<- vBB
+    fldd    d1, [r1]                    @ d1<- vCC
+    fcmpd  d0, d1                       @ compare (vBB, vCC)
+    mov     r0, #1                      @ r0<- 1 (default)
+    fmstat                              @ export status flags
+    mvnmi   r0, #0                      @ (less than) r0<- -1
+    moveq   r0, #0                      @ (equal) r0<- 0
+    bx      lr
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_CMPL_DOUBLE_VFP
+dvmCompiler_TEMPLATE_CMPL_DOUBLE_VFP:
+/* File: armv5te-vfp/TEMPLATE_CMPL_DOUBLE_VFP.S */
+    /*
+     * Compare two floating-point values.  Puts 0, 1, or -1 into the
+     * destination register based on the results of the comparison.
+     *
+     * int compare(x, y) {
+     *     if (x == y) {
+     *         return 0;
+     *     } else if (x > y) {
+     *         return 1;
+     *     } else if (x < y) {
+     *         return -1;
+     *     } else {
+     *         return -1;
+     *     }
+     * }
+     * On entry:
+     *    r0 = &op1 [vBB]
+     *    r1 = &op2 [vCC]
+     */
+    /* op vAA, vBB, vCC */
+    fldd    d0, [r0]                    @ d0<- vBB
+    fldd    d1, [r1]                    @ d1<- vCC
+    fcmped  d0, d1                      @ compare (vBB, vCC)
+    mvn     r0, #0                      @ r0<- -1 (default)
+    fmstat                              @ export status flags
+    movgt   r0, #1                      @ (greater than) r0<- 1
+    moveq   r0, #0                      @ (equal) r0<- 0
+    bx      lr
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_CMPG_FLOAT_VFP
+dvmCompiler_TEMPLATE_CMPG_FLOAT_VFP:
+/* File: armv5te-vfp/TEMPLATE_CMPG_FLOAT_VFP.S */
+    /*
+     * Compare two floating-point values.  Puts 0, 1, or -1 into the
+     * destination register based on the results of the comparison.
+     *
+     * int compare(x, y) {
+     *     if (x == y) {
+     *         return 0;
+     *     } else if (x < y) {
+     *         return -1;
+     *     } else if (x > y) {
+     *         return 1;
+     *     } else {
+     *         return 1;
+     *     }
+     * }
+     * On entry:
+     *    r0 = &op1 [vBB]
+     *    r1 = &op2 [vCC]
+     */
+    /* op vAA, vBB, vCC */
+    flds    s0, [r0]                    @ d0<- vBB
+    flds    s1, [r1]                    @ d1<- vCC
+    fcmps  s0, s1                      @ compare (vBB, vCC)
+    mov     r0, #1                      @ r0<- 1 (default)
+    fmstat                              @ export status flags
+    mvnmi   r0, #0                      @ (less than) r0<- -1
+    moveq   r0, #0                      @ (equal) r0<- 0
+    bx      lr
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_CMPL_FLOAT_VFP
+dvmCompiler_TEMPLATE_CMPL_FLOAT_VFP:
+/* File: armv5te-vfp/TEMPLATE_CMPL_FLOAT_VFP.S */
+    /*
+     * Compare two floating-point values.  Puts 0, 1, or -1 into the
+     * destination register based on the results of the comparison.
+     *
+     * int compare(x, y) {
+     *     if (x == y) {
+     *         return 0;
+     *     } else if (x > y) {
+     *         return 1;
+     *     } else if (x < y) {
+     *         return -1;
+     *     } else {
+     *         return -1;
+     *     }
+     * }
+     * On entry:
+     *    r0 = &op1 [vBB]
+     *    r1 = &op2 [vCC]
+     */
+    /* op vAA, vBB, vCC */
+    flds    s0, [r0]                    @ d0<- vBB
+    flds    s1, [r1]                    @ d1<- vCC
+    fcmps  s0, s1                      @ compare (vBB, vCC)
+    mvn     r0, #0                      @ r0<- -1 (default)
+    fmstat                              @ export status flags
+    movgt   r0, #1                      @ (greater than) r0<- 1
+    moveq   r0, #0                      @ (equal) r0<- 0
+    bx      lr
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_SQRT_DOUBLE_VFP
+dvmCompiler_TEMPLATE_SQRT_DOUBLE_VFP:
+/* File: armv5te-vfp/TEMPLATE_SQRT_DOUBLE_VFP.S */
+    /*
+     * 64-bit floating point vfp sqrt operation.
+     * If the result is a NaN, bail out to library code to do
+     * the right thing.
+     *
+     * On entry:
+     *     r2 src addr of op1
+     * On exit:
+     *     r0,r1 = res
+     */
+    fldd    d0, [r2]
+    fsqrtd  d1, d0
+    fcmpd   d1, d1
+    fmstat
+    fmrrd   r0, r1, d1
+    bxeq    lr   @ Result OK - return
+    ldr     r2, .Lsqrt
+    fmrrd   r0, r1, d0   @ reload orig operand
+    bx      r2   @ tail call to sqrt library routine
+
+.Lsqrt:
+    .word   sqrt
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_THROW_EXCEPTION_COMMON
+dvmCompiler_TEMPLATE_THROW_EXCEPTION_COMMON:
+/* File: armv5te/TEMPLATE_THROW_EXCEPTION_COMMON.S */
+    /*
+     * Throw an exception from JIT'ed code.
+     * On entry:
+     *    r0    Dalvik PC that raises the exception
+     */
+    b       .LhandleException
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_MEM_OP_DECODE
+dvmCompiler_TEMPLATE_MEM_OP_DECODE:
+/* File: armv5te-vfp/TEMPLATE_MEM_OP_DECODE.S */
+#if defined(WITH_SELF_VERIFICATION)
+    /*
+     * This handler encapsulates heap memory ops for selfVerification mode.
+     *
+     * The call to the handler is inserted prior to a heap memory operation.
+     * This handler then calls a function to decode the memory op, and process
+     * it accordingly. Afterwards, the handler changes the return address to
+     * skip the memory op so it never gets executed.
+     */
+    vpush   {d0-d15}                    @ save out all fp registers
+    push    {r0-r12,lr}                 @ save out all registers
+    ldr     r2, .LdvmSelfVerificationMemOpDecode @ defined in footer.S
+    mov     r0, lr                      @ arg0 <- link register
+    mov     r1, sp                      @ arg1 <- stack pointer
+    blx     r2                          @ decode and handle the mem op
+    pop     {r0-r12,lr}                 @ restore all registers
+    vpop    {d0-d15}                    @ restore all fp registers
+    bx      lr                          @ return to compiled code
+#endif
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_STRING_COMPARETO
+dvmCompiler_TEMPLATE_STRING_COMPARETO:
+/* File: armv5te/TEMPLATE_STRING_COMPARETO.S */
+    /*
+     * String's compareTo.
+     *
+     * Requires r0/r1 to have been previously checked for null.  Will
+     * return negative if this's string is < comp, 0 if they are the
+     * same and positive if >.
+     *
+     * IMPORTANT NOTE:
+     *
+     * This code relies on hard-coded offsets for string objects, and must be
+     * kept in sync with definitions in UtfString.h.  See asm-constants.h
+     *
+     * On entry:
+     *    r0:   this object pointer
+     *    r1:   comp object pointer
+     *
+     */
+
+    mov    r2, r0         @ this to r2, opening up r0 for return value
+    subs   r0, r2, r1     @ Same?
+    bxeq   lr
+
+    ldr    r4, [r2, #STRING_FIELDOFF_OFFSET]
+    ldr    r9, [r1, #STRING_FIELDOFF_OFFSET]
+    ldr    r7, [r2, #STRING_FIELDOFF_COUNT]
+    ldr    r10, [r1, #STRING_FIELDOFF_COUNT]
+    ldr    r2, [r2, #STRING_FIELDOFF_VALUE]
+    ldr    r1, [r1, #STRING_FIELDOFF_VALUE]
+
+    /*
+     * At this point, we have:
+     *    value:  r2/r1
+     *    offset: r4/r9
+     *    count:  r7/r10
+     * We're going to compute
+     *    r11 <- countDiff
+     *    r10 <- minCount
+     */
+     subs  r11, r7, r10
+     movls r10, r7
+
+     /* Now, build pointers to the string data */
+     add   r2, r2, r4, lsl #1
+     add   r1, r1, r9, lsl #1
+     /*
+      * Note: data pointers point to previous element so we can use pre-index
+      * mode with base writeback.
+      */
+     add   r2, #16-2   @ offset to contents[-1]
+     add   r1, #16-2   @ offset to contents[-1]
+
+     /*
+      * At this point we have:
+      *   r2: *this string data
+      *   r1: *comp string data
+      *   r10: iteration count for comparison
+      *   r11: value to return if the first part of the string is equal
+      *   r0: reserved for result
+      *   r3, r4, r7, r8, r9, r12 available for loading string data
+      */
+
+    subs  r10, #2
+    blt   do_remainder2
+
+      /*
+       * Unroll the first two checks so we can quickly catch early mismatch
+       * on long strings (but preserve incoming alignment)
+       */
+
+    ldrh  r3, [r2, #2]!
+    ldrh  r4, [r1, #2]!
+    ldrh  r7, [r2, #2]!
+    ldrh  r8, [r1, #2]!
+    subs  r0, r3, r4
+    subeqs  r0, r7, r8
+    bxne  lr
+    cmp   r10, #28
+    bgt   do_memcmp16
+    subs  r10, #3
+    blt   do_remainder
+
+loopback_triple:
+    ldrh  r3, [r2, #2]!
+    ldrh  r4, [r1, #2]!
+    ldrh  r7, [r2, #2]!
+    ldrh  r8, [r1, #2]!
+    ldrh  r9, [r2, #2]!
+    ldrh  r12,[r1, #2]!
+    subs  r0, r3, r4
+    subeqs  r0, r7, r8
+    subeqs  r0, r9, r12
+    bxne  lr
+    subs  r10, #3
+    bge   loopback_triple
+
+do_remainder:
+    adds  r10, #3
+    beq   returnDiff
+
+loopback_single:
+    ldrh  r3, [r2, #2]!
+    ldrh  r4, [r1, #2]!
+    subs  r0, r3, r4
+    bxne  lr
+    subs  r10, #1
+    bne     loopback_single
+
+returnDiff:
+    mov   r0, r11
+    bx    lr
+
+do_remainder2:
+    adds  r10, #2
+    bne   loopback_single
+    mov   r0, r11
+    bx    lr
+
+    /* Long string case */
+do_memcmp16:
+    mov   r4, lr
+    ldr   lr, .Lmemcmp16
+    mov   r7, r11
+    add   r0, r2, #2
+    add   r1, r1, #2
+    mov   r2, r10
+    blx   lr
+    cmp   r0, #0
+    bxne  r4
+    mov   r0, r7
+    bx    r4
+
+.Lmemcmp16:
+    .word __memcmp16
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_STRING_INDEXOF
+dvmCompiler_TEMPLATE_STRING_INDEXOF:
+/* File: armv5te/TEMPLATE_STRING_INDEXOF.S */
+    /*
+     * String's indexOf.
+     *
+     * Requires r0 to have been previously checked for null.  Will
+     * return index of match of r1 in r0.
+     *
+     * IMPORTANT NOTE:
+     *
+     * This code relies on hard-coded offsets for string objects, and must be
+     * kept in sync wth definitions in UtfString.h  See asm-constants.h
+     *
+     * On entry:
+     *    r0:   string object pointer
+     *    r1:   char to match
+     *    r2:   Starting offset in string data
+     */
+
+    ldr    r7, [r0, #STRING_FIELDOFF_OFFSET]
+    ldr    r8, [r0, #STRING_FIELDOFF_COUNT]
+    ldr    r0, [r0, #STRING_FIELDOFF_VALUE]
+
+    /*
+     * At this point, we have:
+     *    r0: object pointer
+     *    r1: char to match
+     *    r2: starting offset
+     *    r7: offset
+     *    r8: string length
+     */
+
+     /* Build pointer to start of string data */
+     add   r0, #16
+     add   r0, r0, r7, lsl #1
+
+     /* Save a copy of starting data in r7 */
+     mov   r7, r0
+
+     /* Clamp start to [0..count] */
+     cmp   r2, #0
+     movlt r2, #0
+     cmp   r2, r8
+     movgt r2, r8
+
+     /* Build pointer to start of data to compare and pre-bias */
+     add   r0, r0, r2, lsl #1
+     sub   r0, #2
+
+     /* Compute iteration count */
+     sub   r8, r2
+
+     /*
+      * At this point we have:
+      *   r0: start of data to test
+      *   r1: chat to compare
+      *   r8: iteration count
+      *   r7: original start of string
+      *   r3, r4, r9, r10, r11, r12 available for loading string data
+      */
+
+    subs  r8, #4
+    blt   indexof_remainder
+
+indexof_loop4:
+    ldrh  r3, [r0, #2]!
+    ldrh  r4, [r0, #2]!
+    ldrh  r10, [r0, #2]!
+    ldrh  r11, [r0, #2]!
+    cmp   r3, r1
+    beq   match_0
+    cmp   r4, r1
+    beq   match_1
+    cmp   r10, r1
+    beq   match_2
+    cmp   r11, r1
+    beq   match_3
+    subs  r8, #4
+    bge   indexof_loop4
+
+indexof_remainder:
+    adds    r8, #4
+    beq     indexof_nomatch
+
+indexof_loop1:
+    ldrh  r3, [r0, #2]!
+    cmp   r3, r1
+    beq   match_3
+    subs  r8, #1
+    bne   indexof_loop1
+
+indexof_nomatch:
+    mov   r0, #-1
+    bx    lr
+
+match_0:
+    sub   r0, #6
+    sub   r0, r7
+    asr   r0, r0, #1
+    bx    lr
+match_1:
+    sub   r0, #4
+    sub   r0, r7
+    asr   r0, r0, #1
+    bx    lr
+match_2:
+    sub   r0, #2
+    sub   r0, r7
+    asr   r0, r0, #1
+    bx    lr
+match_3:
+    sub   r0, r7
+    asr   r0, r0, #1
+    bx    lr
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_INTERPRET
+dvmCompiler_TEMPLATE_INTERPRET:
+/* File: armv5te/TEMPLATE_INTERPRET.S */
+    /*
+     * This handler transfers control to the interpeter without performing
+     * any lookups.  It may be called either as part of a normal chaining
+     * operation, or from the transition code in header.S.  We distinquish
+     * the two cases by looking at the link register.  If called from a
+     * translation chain, it will point to the chaining Dalvik PC -3.
+     * On entry:
+     *    lr - if NULL:
+     *        r1 - the Dalvik PC to begin interpretation.
+     *    else
+     *        [lr, #3] contains Dalvik PC to begin interpretation
+     *    rSELF - pointer to thread
+     *    rFP - Dalvik frame pointer
+     */
+    cmp     lr, #0
+#if defined(WORKAROUND_CORTEX_A9_745320)
+    /* Don't use conditional loads if the HW defect exists */
+    beq     101f
+    ldr     r1,[lr, #3]
+101:
+#else
+    ldrne   r1,[lr, #3]
+#endif
+    ldr     r2, .LinterpPunt
+    mov     r0, r1                       @ set Dalvik PC
+    bx      r2
+    @ doesn't return
+
+.LinterpPunt:
+    .word   dvmJitToInterpPunt
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_MONITOR_ENTER
+dvmCompiler_TEMPLATE_MONITOR_ENTER:
+/* File: armv5te/TEMPLATE_MONITOR_ENTER.S */
+    /*
+     * Call out to the runtime to lock an object.  Because this thread
+     * may have been suspended in THREAD_MONITOR state and the Jit's
+     * translation cache subsequently cleared, we cannot return directly.
+     * Instead, unconditionally transition to the interpreter to resume.
+     *
+     * On entry:
+     *    r0 - self pointer
+     *    r1 - the object (which has already been null-checked by the caller
+     *    r4 - the Dalvik PC of the following instruction.
+     */
+    ldr     r2, .LdvmLockObject
+    mov     r3, #0                       @ Record that we're not returning
+    str     r3, [r0, #offThread_inJitCodeCache]
+    blx     r2                           @ dvmLockObject(self, obj)
+    ldr     r2, .LdvmJitToInterpNoChain
+    @ Bail to interpreter - no chain [note - r4 still contains rPC]
+#if defined(WITH_JIT_TUNING)
+    mov     r0, #kHeavyweightMonitor
+#endif
+    bx      r2
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_MONITOR_ENTER_DEBUG
+dvmCompiler_TEMPLATE_MONITOR_ENTER_DEBUG:
+/* File: armv5te/TEMPLATE_MONITOR_ENTER_DEBUG.S */
+    /*
+     * To support deadlock prediction, this version of MONITOR_ENTER
+     * will always call the heavyweight dvmLockObject, check for an
+     * exception and then bail out to the interpreter.
+     *
+     * On entry:
+     *    r0 - self pointer
+     *    r1 - the object (which has already been null-checked by the caller
+     *    r4 - the Dalvik PC of the following instruction.
+     *
+     */
+    ldr     r2, .LdvmLockObject
+    mov     r3, #0                       @ Record that we're not returning
+    str     r3, [r0, #offThread_inJitCodeCache]
+    blx     r2             @ dvmLockObject(self, obj)
+    @ test for exception
+    ldr     r1, [rSELF, #offThread_exception]
+    cmp     r1, #0
+    beq     1f
+    ldr     r2, .LhandleException
+    sub     r0, r4, #2     @ roll dPC back to this monitor instruction
+    bx      r2
+1:
+    @ Bail to interpreter - no chain [note - r4 still contains rPC]
+#if defined(WITH_JIT_TUNING)
+    mov     r0, #kHeavyweightMonitor
+#endif
+    ldr     pc, .LdvmJitToInterpNoChain
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_PERIODIC_PROFILING
+dvmCompiler_TEMPLATE_PERIODIC_PROFILING:
+/* File: armv5te/TEMPLATE_PERIODIC_PROFILING.S */
+    /*
+     * Increment profile counter for this trace, and decrement
+     * sample counter.  If sample counter goes below zero, turn
+     * off profiling.
+     *
+     * On entry
+     * (lr-11) is address of pointer to counter.  Note: the counter
+     *    actually exists 10 bytes before the return target, but because
+     *    we are arriving from thumb mode, lr will have its low bit set.
+     */
+     ldr    r0, [lr,#-11]
+     ldr    r1, [rSELF, #offThread_pProfileCountdown]
+     ldr    r2, [r0]                    @ get counter
+     ldr    r3, [r1]                    @ get countdown timer
+     add    r2, #1
+     subs   r2, #1
+     blt    .LTEMPLATE_PERIODIC_PROFILING_disable_profiling
+     str    r2, [r0]
+     str    r3, [r1]
+     bx     lr
+
+.LTEMPLATE_PERIODIC_PROFILING_disable_profiling:
+     mov    r4, lr                     @ preserve lr
+     ldr    r0, .LdvmJitTraceProfilingOff
+     blx    r0
+     bx     r4
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_RETURN_PROF
+dvmCompiler_TEMPLATE_RETURN_PROF:
+/* File: armv5te/TEMPLATE_RETURN_PROF.S */
+#define TEMPLATE_INLINE_PROFILING
+/* File: armv5te/TEMPLATE_RETURN.S */
+    /*
+     * Unwind a frame from the Dalvik stack for compiled OP_RETURN_XXX.
+     * If the stored value in returnAddr
+     * is non-zero, the caller is compiled by the JIT thus return to the
+     * address in the code cache following the invoke instruction. Otherwise
+     * return to the special dvmJitToInterpNoChain entry point.
+     */
+#if defined(TEMPLATE_INLINE_PROFILING)
+    stmfd   sp!, {r0-r2,lr}             @ preserve live registers
+    mov     r0, r6
+    @ r0=rSELF
+    mov     lr, pc
+    ldr     pc, .LdvmFastMethodTraceExit
+    ldmfd   sp!, {r0-r2,lr}             @ restore live registers
+#endif
+    SAVEAREA_FROM_FP(r0, rFP)           @ r0<- saveArea (old)
+    ldr     r10, [r0, #offStackSaveArea_prevFrame] @ r10<- saveArea->prevFrame
+    ldrb    r8, [rSELF, #offThread_breakFlags] @ r8<- breakFlags
+    ldr     rPC, [r0, #offStackSaveArea_savedPc] @ rPC<- saveArea->savedPc
+#if !defined(WITH_SELF_VERIFICATION)
+    ldr     r9,  [r0, #offStackSaveArea_returnAddr] @ r9<- chaining cell ret
+#else
+    mov     r9, #0                      @ disable chaining
+#endif
+    ldr     r2, [r10, #(offStackSaveArea_method - sizeofStackSaveArea)]
+                                        @ r2<- method we're returning to
+    cmp     r2, #0                      @ break frame?
+#if !defined(WITH_SELF_VERIFICATION)
+    beq     1f                          @ bail to interpreter
+#else
+    blxeq   lr                          @ punt to interpreter and compare state
+#endif
+    ldr     r1, .LdvmJitToInterpNoChainNoProfile @ defined in footer.S
+    mov     rFP, r10                    @ publish new FP
+    ldr     r10, [r2, #offMethod_clazz] @ r10<- method->clazz
+
+    str     r2, [rSELF, #offThread_method]@ self->method = newSave->method
+    ldr     r0, [r10, #offClassObject_pDvmDex] @ r0<- method->clazz->pDvmDex
+    str     rFP, [rSELF, #offThread_curFrame] @ curFrame = fp
+    add     rPC, rPC, #6                @ publish new rPC (advance 6 bytes)
+    str     r0, [rSELF, #offThread_methodClassDex]
+    cmp     r8, #0                      @ check the break flags
+    movne   r9, #0                      @ clear the chaining cell address
+    str     r9, [rSELF, #offThread_inJitCodeCache] @ in code cache or not
+    cmp     r9, #0                      @ chaining cell exists?
+    blxne   r9                          @ jump to the chaining cell
+#if defined(WITH_JIT_TUNING)
+    mov     r0, #kCallsiteInterpreted
+#endif
+    mov     pc, r1                      @ callsite is interpreted
+1:
+    mov     r0, #0
+    str     r0, [rSELF, #offThread_inJitCodeCache] @ reset inJitCodeCache
+    stmia   rSELF, {rPC, rFP}           @ SAVE_PC_FP_TO_SELF()
+    ldr     r2, .LdvmMterpStdBail       @ defined in footer.S
+    mov     r0, rSELF                   @ Expecting rSELF in r0
+    blx     r2                          @ exit the interpreter
+
+#undef TEMPLATE_INLINE_PROFILING
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_INVOKE_METHOD_NO_OPT_PROF
+dvmCompiler_TEMPLATE_INVOKE_METHOD_NO_OPT_PROF:
+/* File: armv5te/TEMPLATE_INVOKE_METHOD_NO_OPT_PROF.S */
+#define TEMPLATE_INLINE_PROFILING
+/* File: armv5te/TEMPLATE_INVOKE_METHOD_NO_OPT.S */
+    /*
+     * For polymorphic callsites - setup the Dalvik frame and load Dalvik PC
+     * into rPC then jump to dvmJitToInterpNoChain to dispatch the
+     * runtime-resolved callee.
+     */
+    @ r0 = methodToCall, r1 = returnCell, rPC = dalvikCallsite
+    ldrh    r7, [r0, #offMethod_registersSize]  @ r7<- methodToCall->regsSize
+    ldrh    r2, [r0, #offMethod_outsSize]  @ r2<- methodToCall->outsSize
+    ldr     r9, [rSELF, #offThread_interpStackEnd]    @ r9<- interpStackEnd
+    ldrb    r8, [rSELF, #offThread_breakFlags] @ r8<- breakFlags
+    add     r3, r1, #1  @ Thumb addr is odd
+    SAVEAREA_FROM_FP(r1, rFP)           @ r1<- stack save area
+    sub     r1, r1, r7, lsl #2          @ r1<- newFp (old savearea - regsSize)
+    SAVEAREA_FROM_FP(r10, r1)           @ r10<- stack save area
+    sub     r10, r10, r2, lsl #2        @ r10<- bottom (newsave - outsSize)
+    cmp     r10, r9                     @ bottom < interpStackEnd?
+    bxlo    lr                          @ return to raise stack overflow excep.
+    @ r1 = newFP, r0 = methodToCall, r3 = returnCell, rPC = dalvikCallsite
+    ldr     r9, [r0, #offMethod_clazz]      @ r9<- method->clazz
+    ldr     r10, [r0, #offMethod_accessFlags] @ r10<- methodToCall->accessFlags
+    str     rPC, [rFP, #(offStackSaveArea_currentPc - sizeofStackSaveArea)]
+    str     rPC, [r1, #(offStackSaveArea_savedPc - sizeofStackSaveArea)]
+    ldr     rPC, [r0, #offMethod_insns]     @ rPC<- methodToCall->insns
+
+
+    @ set up newSaveArea
+    str     rFP, [r1, #(offStackSaveArea_prevFrame - sizeofStackSaveArea)]
+    str     r3, [r1, #(offStackSaveArea_returnAddr - sizeofStackSaveArea)]
+    str     r0, [r1, #(offStackSaveArea_method - sizeofStackSaveArea)]
+    cmp     r8, #0                      @ breakFlags != 0
+    bxne    lr                          @ bail to the interpreter
+    tst     r10, #ACC_NATIVE
+#if !defined(WITH_SELF_VERIFICATION)
+    bne     .LinvokeNative
+#else
+    bxne    lr                          @ bail to the interpreter
+#endif
+
+    ldr     r10, .LdvmJitToInterpTraceSelectNoChain
+    ldr     r3, [r9, #offClassObject_pDvmDex] @ r3<- method->clazz->pDvmDex
+
+    @ Update "thread" values for the new method
+    str     r0, [rSELF, #offThread_method]    @ self->method = methodToCall
+    str     r3, [rSELF, #offThread_methodClassDex] @ self->methodClassDex = ...
+    mov     rFP, r1                         @ fp = newFp
+    str     rFP, [rSELF, #offThread_curFrame]  @ curFrame = newFp
+#if defined(TEMPLATE_INLINE_PROFILING)
+    stmfd   sp!, {r0-r3}                    @ preserve r0-r3
+    mov     r1, r6
+    @ r0=methodToCall, r1=rSELF
+    mov     lr, pc
+    ldr     pc, .LdvmFastMethodTraceEnter
+    ldmfd   sp!, {r0-r3}                    @ restore r0-r3
+#endif
+
+    @ Start executing the callee
+#if defined(WITH_JIT_TUNING)
+    mov     r0, #kInlineCacheMiss
+#endif
+    mov     pc, r10                         @ dvmJitToInterpTraceSelectNoChain
+
+#undef TEMPLATE_INLINE_PROFILING
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_INVOKE_METHOD_CHAIN_PROF
+dvmCompiler_TEMPLATE_INVOKE_METHOD_CHAIN_PROF:
+/* File: armv5te/TEMPLATE_INVOKE_METHOD_CHAIN_PROF.S */
+#define TEMPLATE_INLINE_PROFILING
+/* File: armv5te/TEMPLATE_INVOKE_METHOD_CHAIN.S */
+    /*
+     * For monomorphic callsite, setup the Dalvik frame and return to the
+     * Thumb code through the link register to transfer control to the callee
+     * method through a dedicated chaining cell.
+     */
+    @ r0 = methodToCall, r1 = returnCell, r2 = methodToCall->outsSize
+    @ rPC = dalvikCallsite, r7 = methodToCall->registersSize
+    @ methodToCall is guaranteed to be non-native
+.LinvokeChainProf:
+    ldr     r9, [rSELF, #offThread_interpStackEnd]    @ r9<- interpStackEnd
+    ldrb    r8, [rSELF, #offThread_breakFlags]        @ r8<- breakFlags
+    add     r3, r1, #1  @ Thumb addr is odd
+    SAVEAREA_FROM_FP(r1, rFP)           @ r1<- stack save area
+    sub     r1, r1, r7, lsl #2          @ r1<- newFp (old savearea - regsSize)
+    SAVEAREA_FROM_FP(r10, r1)           @ r10<- stack save area
+    add     r12, lr, #2                 @ setup the punt-to-interp address
+    sub     r10, r10, r2, lsl #2        @ r10<- bottom (newsave - outsSize)
+    cmp     r10, r9                     @ bottom < interpStackEnd?
+    bxlo    r12                         @ return to raise stack overflow excep.
+    @ r1 = newFP, r0 = methodToCall, r3 = returnCell, rPC = dalvikCallsite
+    ldr     r9, [r0, #offMethod_clazz]      @ r9<- method->clazz
+    str     rPC, [rFP, #(offStackSaveArea_currentPc - sizeofStackSaveArea)]
+    str     rPC, [r1, #(offStackSaveArea_savedPc - sizeofStackSaveArea)]
+
+    @ set up newSaveArea
+    str     rFP, [r1, #(offStackSaveArea_prevFrame - sizeofStackSaveArea)]
+    str     r3, [r1, #(offStackSaveArea_returnAddr - sizeofStackSaveArea)]
+    str     r0, [r1, #(offStackSaveArea_method - sizeofStackSaveArea)]
+    cmp     r8, #0                      @ breakFlags != 0
+    bxne    r12                         @ bail to the interpreter
+
+    ldr     r3, [r9, #offClassObject_pDvmDex] @ r3<- method->clazz->pDvmDex
+
+    @ Update "thread" values for the new method
+    str     r0, [rSELF, #offThread_method]    @ self->method = methodToCall
+    str     r3, [rSELF, #offThread_methodClassDex] @ self->methodClassDex = ...
+    mov     rFP, r1                         @ fp = newFp
+    str     rFP, [rSELF, #offThread_curFrame]  @ curFrame = newFp
+#if defined(TEMPLATE_INLINE_PROFILING)
+    stmfd   sp!, {r0-r2,lr}             @ preserve clobbered live registers
+    mov     r1, r6
+    @ r0=methodToCall, r1=rSELF
+    mov     lr, pc
+    ldr     pc, .LdvmFastMethodTraceEnter
+    ldmfd   sp!, {r0-r2,lr}             @ restore registers
+#endif
+
+    bx      lr                              @ return to the callee-chaining cell
+
+#undef TEMPLATE_INLINE_PROFILING
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_INVOKE_METHOD_PREDICTED_CHAIN_PROF
+dvmCompiler_TEMPLATE_INVOKE_METHOD_PREDICTED_CHAIN_PROF:
+/* File: armv5te/TEMPLATE_INVOKE_METHOD_PREDICTED_CHAIN_PROF.S */
+#define TEMPLATE_INLINE_PROFILING
+/* File: armv5te/TEMPLATE_INVOKE_METHOD_PREDICTED_CHAIN.S */
+    /*
+     * For polymorphic callsite, check whether the cached class pointer matches
+     * the current one. If so setup the Dalvik frame and return to the
+     * Thumb code through the link register to transfer control to the callee
+     * method through a dedicated chaining cell.
+     *
+     * The predicted chaining cell is declared in ArmLIR.h with the
+     * following layout:
+     *
+     *  typedef struct PredictedChainingCell {
+     *      u4 branch;
+     *      const ClassObject *clazz;
+     *      const Method *method;
+     *      u4 counter;
+     *  } PredictedChainingCell;
+     *
+     * Upon returning to the callsite:
+     *    - lr  : to branch to the chaining cell
+     *    - lr+2: to punt to the interpreter
+     *    - lr+4: to fully resolve the callee and may rechain.
+     *            r3 <- class
+     *            r9 <- counter
+     */
+    @ r0 = this, r1 = returnCell, r2 = predictedChainCell, rPC = dalvikCallsite
+    ldr     r3, [r0, #offObject_clazz]  @ r3 <- this->class
+    ldr     r8, [r2, #4]    @ r8 <- predictedChainCell->clazz
+    ldr     r0, [r2, #8]    @ r0 <- predictedChainCell->method
+    ldr     r9, [rSELF, #offThread_icRechainCount] @ r1 <- shared rechainCount
+    cmp     r3, r8          @ predicted class == actual class?
+#if defined(WITH_JIT_TUNING)
+    ldr     r7, .LdvmICHitCount
+#if defined(WORKAROUND_CORTEX_A9_745320)
+    /* Don't use conditional loads if the HW defect exists */
+    bne     101f
+    ldr     r10, [r7, #0]
+101:
+#else
+    ldreq   r10, [r7, #0]
+#endif
+    add     r10, r10, #1
+    streq   r10, [r7, #0]
+#endif
+    ldreqh  r7, [r0, #offMethod_registersSize]  @ r7<- methodToCall->regsSize
+    ldreqh  r2, [r0, #offMethod_outsSize]  @ r2<- methodToCall->outsSize
+    beq     .LinvokeChainProf   @ predicted chain is valid
+    ldr     r7, [r3, #offClassObject_vtable] @ r7 <- this->class->vtable
+    cmp     r8, #0          @ initialized class or not
+    moveq   r1, #0
+    subne   r1, r9, #1      @ count--
+    strne   r1, [rSELF, #offThread_icRechainCount]  @ write back to thread
+    add     lr, lr, #4      @ return to fully-resolve landing pad
+    /*
+     * r1 <- count
+     * r2 <- &predictedChainCell
+     * r3 <- this->class
+     * r4 <- dPC
+     * r7 <- this->class->vtable
+     */
+    bx      lr
+
+#undef TEMPLATE_INLINE_PROFILING
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_INVOKE_METHOD_NATIVE_PROF
+dvmCompiler_TEMPLATE_INVOKE_METHOD_NATIVE_PROF:
+/* File: armv5te/TEMPLATE_INVOKE_METHOD_NATIVE_PROF.S */
+#define TEMPLATE_INLINE_PROFILING
+/* File: armv5te/TEMPLATE_INVOKE_METHOD_NATIVE.S */
+    @ r0 = methodToCall, r1 = returnCell, rPC = dalvikCallsite
+    @ r7 = methodToCall->registersSize
+    ldr     r9, [rSELF, #offThread_interpStackEnd]    @ r9<- interpStackEnd
+    ldrb    r8, [rSELF, #offThread_breakFlags]        @ r8<- breakFlags
+    add     r3, r1, #1  @ Thumb addr is odd
+    SAVEAREA_FROM_FP(r1, rFP)           @ r1<- stack save area
+    sub     r1, r1, r7, lsl #2          @ r1<- newFp (old savearea - regsSize)
+    SAVEAREA_FROM_FP(r10, r1)           @ r10<- stack save area
+    cmp     r10, r9                     @ bottom < interpStackEnd?
+    bxlo    lr                          @ return to raise stack overflow excep.
+    @ r1 = newFP, r0 = methodToCall, r3 = returnCell, rPC = dalvikCallsite
+    str     rPC, [rFP, #(offStackSaveArea_currentPc - sizeofStackSaveArea)]
+    str     rPC, [r1, #(offStackSaveArea_savedPc - sizeofStackSaveArea)]
+
+    @ set up newSaveArea
+    str     rFP, [r1, #(offStackSaveArea_prevFrame - sizeofStackSaveArea)]
+    str     r3, [r1, #(offStackSaveArea_returnAddr - sizeofStackSaveArea)]
+    str     r0, [r1, #(offStackSaveArea_method - sizeofStackSaveArea)]
+    cmp     r8, #0                      @ breakFlags != 0
+    ldr     r8, [r0, #offMethod_nativeFunc] @ r8<- method->nativeFunc
+#if !defined(WITH_SELF_VERIFICATION)
+    bxne    lr                          @ bail to the interpreter
+#else
+    bx      lr                          @ bail to interpreter unconditionally
+#endif
+
+    @ go ahead and transfer control to the native code
+    ldr     r9, [rSELF, #offThread_jniLocal_topCookie]@r9<-thread->localRef->...
+    mov     r2, #0
+    str     r1, [rSELF, #offThread_curFrame]   @ curFrame = newFp
+    str     r2, [rSELF, #offThread_inJitCodeCache] @ not in the jit code cache
+    str     r9, [r1, #(offStackSaveArea_localRefCookie - sizeofStackSaveArea)]
+                                        @ newFp->localRefCookie=top
+    SAVEAREA_FROM_FP(r10, r1)           @ r10<- new stack save area
+
+    mov     r2, r0                        @ arg2<- methodToCall
+    mov     r0, r1                        @ arg0<- newFP
+    add     r1, rSELF, #offThread_retval  @ arg1<- &retval
+    mov     r3, rSELF                     @ arg3<- self
+#if defined(TEMPLATE_INLINE_PROFILING)
+    @ r2=methodToCall, r6=rSELF
+    stmfd   sp!, {r2,r6}                @ to be consumed after JNI return
+    stmfd   sp!, {r0-r3}                @ preserve r0-r3
+    mov     r0, r2
+    mov     r1, r6
+    @ r0=JNIMethod, r1=rSELF
+    mov     lr, pc
+    ldr     pc, .LdvmFastMethodTraceEnter
+    ldmfd   sp!, {r0-r3}                @ restore r0-r3
+#endif
+
+    blx     r8                          @ off to the native code
+
+#if defined(TEMPLATE_INLINE_PROFILING)
+    ldmfd   sp!, {r0-r1}                @ restore r2 and r6
+    @ r0=JNIMethod, r1=rSELF
+    mov     lr, pc
+    ldr     pc, .LdvmFastNativeMethodTraceExit
+#endif
+    @ native return; r10=newSaveArea
+    @ equivalent to dvmPopJniLocals
+    ldr     r2, [r10, #offStackSaveArea_returnAddr] @ r2 = chaining cell ret
+    ldr     r0, [r10, #offStackSaveArea_localRefCookie] @ r0<- saved->top
+    ldr     r1, [rSELF, #offThread_exception] @ check for exception
+    str     rFP, [rSELF, #offThread_curFrame]  @ curFrame = fp
+    cmp     r1, #0                      @ null?
+    str     r0, [rSELF, #offThread_jniLocal_topCookie] @ new top <- old top
+    ldr     r0, [rFP, #(offStackSaveArea_currentPc - sizeofStackSaveArea)]
+
+    @ r0 = dalvikCallsitePC
+    bne     .LhandleException           @ no, handle exception
+
+    str     r2, [rSELF, #offThread_inJitCodeCache] @ set the mode properly
+    cmp     r2, #0                      @ return chaining cell still exists?
+    bxne    r2                          @ yes - go ahead
+
+    @ continue executing the next instruction through the interpreter
+    ldr     r1, .LdvmJitToInterpTraceSelectNoChain @ defined in footer.S
+    add     rPC, r0, #6                 @ reconstruct new rPC (advance 6 bytes)
+#if defined(WITH_JIT_TUNING)
+    mov     r0, #kCallsiteInterpreted
+#endif
+    mov     pc, r1
+
+#undef TEMPLATE_INLINE_PROFILING
+
+    .size   dvmCompilerTemplateStart, .-dvmCompilerTemplateStart
+/* File: armv5te/footer.S */
+/*
+ * ===========================================================================
+ *  Common subroutines and data
+ * ===========================================================================
+ */
+
+    .text
+    .align  2
+.LinvokeNative:
+    @ Prep for the native call
+    @ r1 = newFP, r0 = methodToCall
+    mov     r2, #0
+    ldr     r9, [rSELF, #offThread_jniLocal_topCookie]@r9<-thread->localRef->...
+    str     r2, [rSELF, #offThread_inJitCodeCache] @ not in jit code cache
+    str     r1, [rSELF, #offThread_curFrame]   @ curFrame = newFp
+    str     r9, [r1, #(offStackSaveArea_localRefCookie - sizeofStackSaveArea)]
+                                        @ newFp->localRefCookie=top
+    ldrh    lr, [rSELF, #offThread_subMode]
+    SAVEAREA_FROM_FP(r10, r1)           @ r10<- new stack save area
+
+    mov     r2, r0                      @ r2<- methodToCall
+    mov     r0, r1                      @ r0<- newFP
+    add     r1, rSELF, #offThread_retval  @ r1<- &retval
+    mov     r3, rSELF                   @ arg3<- self
+    ands    lr, #kSubModeMethodTrace
+    beq     121f                        @ hop if not profiling
+    @ r2: methodToCall, r6: rSELF
+    stmfd   sp!, {r2,r6}
+    stmfd   sp!, {r0-r3}
+    mov     r0, r2
+    mov     r1, r6
+    mov     lr, pc
+    ldr     pc, .LdvmFastMethodTraceEnter
+    ldmfd   sp!, {r0-r3}
+
+    mov     lr, pc
+    ldr     pc, [r2, #offMethod_nativeFunc]
+
+    ldmfd   sp!, {r0-r1}
+    mov     lr, pc
+    ldr     pc, .LdvmFastNativeMethodTraceExit
+    b       212f
+121:
+    mov     lr, pc
+    ldr     pc, [r2, #offMethod_nativeFunc]
+212:
+
+    @ native return; r10=newSaveArea
+    @ equivalent to dvmPopJniLocals
+    ldr     r2, [r10, #offStackSaveArea_returnAddr] @ r2 = chaining cell ret
+    ldr     r0, [r10, #offStackSaveArea_localRefCookie] @ r0<- saved->top
+    ldr     r1, [rSELF, #offThread_exception] @ check for exception
+    str     rFP, [rSELF, #offThread_curFrame]  @ curFrame = fp
+    cmp     r1, #0                      @ null?
+    str     r0, [rSELF, #offThread_jniLocal_topCookie] @ new top <- old top
+    ldr     r0, [r10, #offStackSaveArea_savedPc] @ reload rPC
+
+    @ r0 = dalvikCallsitePC
+    bne     .LhandleException           @ no, handle exception
+
+    str     r2, [rSELF, #offThread_inJitCodeCache] @ set the new mode
+    cmp     r2, #0                      @ return chaining cell still exists?
+    bxne    r2                          @ yes - go ahead
+
+    @ continue executing the next instruction through the interpreter
+    ldr     r1, .LdvmJitToInterpTraceSelectNoChain @ defined in footer.S
+    add     rPC, r0, #6                 @ reconstruct new rPC (advance 6 bytes)
+#if defined(WITH_JIT_TUNING)
+    mov     r0, #kCallsiteInterpreted
+#endif
+    mov     pc, r1
+
+/*
+ * On entry:
+ * r0  Faulting Dalvik PC
+ */
+.LhandleException:
+#if defined(WITH_SELF_VERIFICATION)
+    ldr     pc, .LdeadFood @ should not see this under self-verification mode
+.LdeadFood:
+    .word   0xdeadf00d
+#endif
+    mov     r2, #0
+    str     r2, [rSELF, #offThread_inJitCodeCache] @ in interpreter land
+    ldr     r1, .LdvmMterpCommonExceptionThrown @ PIC way of getting &func
+    ldr     rIBASE, .LdvmAsmInstructionStart    @ same as above
+    mov     rPC, r0                 @ reload the faulting Dalvik address
+    mov     pc, r1                  @ branch to dvmMterpCommonExceptionThrown
+
+    .align  2
+.LdvmAsmInstructionStart:
+    .word   dvmAsmInstructionStart
+.LdvmJitToInterpNoChainNoProfile:
+    .word   dvmJitToInterpNoChainNoProfile
+.LdvmJitToInterpTraceSelectNoChain:
+    .word   dvmJitToInterpTraceSelectNoChain
+.LdvmJitToInterpNoChain:
+    .word   dvmJitToInterpNoChain
+.LdvmMterpStdBail:
+    .word   dvmMterpStdBail
+.LdvmMterpCommonExceptionThrown:
+    .word   dvmMterpCommonExceptionThrown
+.LdvmLockObject:
+    .word   dvmLockObject
+.LdvmJitTraceProfilingOff:
+    .word   dvmJitTraceProfilingOff
+#if defined(WITH_JIT_TUNING)
+.LdvmICHitCount:
+    .word   gDvmICHitCount
+#endif
+#if defined(WITH_SELF_VERIFICATION)
+.LdvmSelfVerificationMemOpDecode:
+    .word   dvmSelfVerificationMemOpDecode
+#endif
+.LdvmFastMethodTraceEnter:
+    .word   dvmFastMethodTraceEnter
+.LdvmFastNativeMethodTraceExit:
+    .word   dvmFastNativeMethodTraceExit
+.LdvmFastMethodTraceExit:
+    .word   dvmFastMethodTraceExit
+.L__aeabi_cdcmple:
+    .word   __aeabi_cdcmple
+.L__aeabi_cfcmple:
+    .word   __aeabi_cfcmple
+
+    .global dmvCompilerTemplateEnd
+dmvCompilerTemplateEnd:
+
+#endif /* WITH_JIT */
+
diff --git a/vm/compiler/template_notaint/out/CompilerTemplateAsm-ia32.S b/vm/compiler/template_notaint/out/CompilerTemplateAsm-ia32.S
new file mode 100644
index 0000000..4e86d09
--- /dev/null
+++ b/vm/compiler/template_notaint/out/CompilerTemplateAsm-ia32.S
@@ -0,0 +1,113 @@
+/*
+ * This file was generated automatically by gen-template.py for 'ia32'.
+ *
+ * --> DO NOT EDIT <--
+ */
+
+/* File: ia32/header.S */
+/*
+ * Copyright (C) 2010 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#if defined(WITH_JIT)
+
+/* Subset of defines from mterp/x86/header.S */
+#define rSELF (%ebp)
+#define rPC   %esi
+#define rFP   %edi
+#define rINST %ebx
+
+/*
+ * This is a #include, not a %include, because we want the C pre-processor
+ * to expand the macros into assembler assignment statements.
+ */
+#include "../../../mterp/common/asm-constants.h"
+
+/* File: ia32/platform.S */
+/*
+ * ===========================================================================
+ *  CPU-version-specific defines and utility
+ * ===========================================================================
+ */
+
+
+
+
+    .global dvmCompilerTemplateStart
+    .type   dvmCompilerTemplateStart, %function
+    .text
+
+dvmCompilerTemplateStart:
+
+/* ------------------------------ */
+    .balign 4
+    .global dvmCompiler_TEMPLATE_INTERPRET
+dvmCompiler_TEMPLATE_INTERPRET:
+/* File: ia32/TEMPLATE_INTERPRET.S */
+    /*
+     * This handler is a bit odd - it may be called via chaining or
+     * from static code and is expected to cause control to flow
+     * to the interpreter.  The problem is where to find the Dalvik
+     * PC of the next instruction.  When called via chaining, the dPC
+     * will be located at *rp.  When called from static code, rPC is
+     * valid and rp is a real return pointer (that should be ignored).
+     * The Arm target deals with this by using the link register as
+     * a flag.  If it is zero, we know we were called from static code.
+     * If non-zero, it points to the chain cell containing dPC.
+     * For x86, we'll infer the source by looking where rp points.
+     * If it points to anywhere within the code cache, we'll assume
+     * we got here via chaining.  Otherwise, we'll assume rPC is valid.
+     *
+     * On entry:
+     *    (TOS)<- return pointer or pointer to dPC
+     */
+
+/*
+ * FIXME - this won't work as-is.  The cache boundaries are not
+ * set up until later.  Perhaps rething this whole thing.  Do we
+ * really need an interpret teplate?
+ */
+
+
+     movl   rSELF,%ecx
+     movl   $.LinterpPunt,%edx
+     pop    %eax
+     /*cmpl   %eax,offThread_jitCacheEnd(%ecx)*/
+     ja     1f
+     /*cmpl   %eax,offThread_jitCacheStart(%ecx)*/
+     jb     1f
+     movl   %eax,rPC
+1:
+     jmp    *(%edx)
+
+.LinterpPunt:
+    .long   dvmJitToInterpPunt
+
+    .size   dvmCompilerTemplateStart, .-dvmCompilerTemplateStart
+/* File: ia32/footer.S */
+/*
+ * ===========================================================================
+ *  Common subroutines and data
+ * ===========================================================================
+ */
+
+    .text
+    .align  4
+
+    .global dmvCompilerTemplateEnd
+dmvCompilerTemplateEnd:
+
+#endif /* WITH_JIT */
+
diff --git a/vm/compiler/template_notaint/rebuild.sh b/vm/compiler/template_notaint/rebuild.sh
new file mode 100644
index 0000000..f04d097
--- /dev/null
+++ b/vm/compiler/template_notaint/rebuild.sh
@@ -0,0 +1,22 @@
+#!/bin/sh
+#
+# Copyright (C) 2008 The Android Open Source Project
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#      http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+#
+# Rebuild for all known targets.  Necessary until the stuff in "out" gets
+# generated as part of the build.
+#
+set -e
+for arch in ia32 armv5te armv5te-vfp armv7-a armv7-a-neon; do TARGET_ARCH_EXT=$arch make -f Makefile-template; done
diff --git a/vm/interp/Interp.cpp b/vm/interp/Interp.cpp
index 4109764..2727550 100644
--- a/vm/interp/Interp.cpp
+++ b/vm/interp/Interp.cpp
@@ -896,7 +896,11 @@ Object* dvmGetThisPtr(const Method* method, const u4* fp)
 {
     if (dvmIsStaticMethod(method))
         return NULL;
+#ifdef WITH_TAINT_TRACKING
+    return (Object*)fp[(method->registersSize - method->insSize)<<1];
+#else
     return (Object*)fp[method->registersSize - method->insSize];
+#endif
 }
 
 
@@ -956,7 +960,11 @@ void dvmDumpRegs(const Method* method, const u4* framePtr, bool inOnly)
     for (i = method->registersSize-1; i >= 0; i--) {
         if (i >= localCount) {
             ALOG(LOG_VERBOSE, LOG_TAG"i", "  v%-2d in%-2d : 0x%08x",
+#ifdef WITH_TAINT_TRACKING
+                i, i-localCount, framePtr[i<<1]);
+#else
                 i, i-localCount, framePtr[i]);
+#endif
         } else {
             if (inOnly) {
                 ALOG(LOG_VERBOSE, LOG_TAG"i", "  [...]");
@@ -977,7 +985,11 @@ void dvmDumpRegs(const Method* method, const u4* framePtr, bool inOnly)
             }
 #endif
             ALOG(LOG_VERBOSE, LOG_TAG"i", "  v%-2d      : 0x%08x %s",
+#ifdef WITH_TAINT_TRACKING
+                i, framePtr[i<<1], name);
+#else
                 i, framePtr[i], name);
+#endif
         }
     }
 }
@@ -1227,6 +1239,11 @@ bool dvmInterpHandleFillArrayData(ArrayObject* arrayObj, const u2* arrayData)
         return false;
     }
     copySwappedArrayData(arrayObj->contents, &arrayData[4], size, width);
+#ifdef WITH_TAINT_TRACKING
+    if (arrayObj->length == size) {
+    	arrayObj->taint.tag = TAINT_CLEAR;
+    }
+#endif
     return true;
 }
 
@@ -1877,7 +1894,11 @@ void dvmCheckBefore(const u2 *pc, u4 *fp, Thread* self)
  * The interpreted stack frame, which holds the method arguments, has
  * already been set up.
  */
+#ifdef WITH_TAINT_TRACKING
+void dvmInterpret(Thread* self, const Method* method, JValue* pResult, u4* rtaint)
+#else
 void dvmInterpret(Thread* self, const Method* method, JValue* pResult)
+#endif
 {
     InterpSaveState interpSaveState;
     ExecutionSubModes savedSubModes;
@@ -1930,6 +1951,9 @@ void dvmInterpret(Thread* self, const Method* method, JValue* pResult)
      *
      * No need to initialize "retval".
      */
+#ifdef WITH_TAINT_TRACKING
+    self->interpSave.rtaint.tag = TAINT_CLEAR;
+#endif
     self->interpSave.method = method;
     self->interpSave.curFrame = (u4*) self->interpSave.curFrame;
     self->interpSave.pc = method->insns;
@@ -1964,6 +1988,9 @@ void dvmInterpret(Thread* self, const Method* method, JValue* pResult)
     (*stdInterp)(self);
 
     *pResult = self->interpSave.retval;
+#ifdef WITH_TAINT_TRACKING
+    *rtaint = self->interpSave.rtaint.tag;
+#endif
 
     /* Restore interpreter state from previous activation */
     self->interpSave = interpSaveState;
diff --git a/vm/interp/Interp.h b/vm/interp/Interp.h
index e54ec61..a2f0094 100644
--- a/vm/interp/Interp.h
+++ b/vm/interp/Interp.h
@@ -37,7 +37,11 @@ INLINE void dvmExportPC(const u2* pc, const u4* fp)
  * Interpreter entry point.  Call here after setting up the interpreted
  * stack (most code will want to get here via dvmCallMethod().)
  */
+#ifdef WITH_TAINT_TRACKING
+void dvmInterpret(Thread* thread, const Method* method, JValue* pResult, u4* rtaint);
+#else
 void dvmInterpret(Thread* thread, const Method* method, JValue* pResult);
+#endif
 
 /*
  * Throw an exception for a problem detected by the verifier.
diff --git a/vm/interp/InterpDefs.h b/vm/interp/InterpDefs.h
index acec648..9bd477b 100644
--- a/vm/interp/InterpDefs.h
+++ b/vm/interp/InterpDefs.h
@@ -24,6 +24,10 @@
 #ifndef DALVIK_INTERP_DEFS_H_
 #define DALVIK_INTERP_DEFS_H_
 
+#ifdef WITH_TAINT_TRACKING
+#include "interp/Taint.h"
+#endif
+
 #if defined(WITH_JIT)
 /*
  * Size of save area for callee-save FP regs, which are not automatically
diff --git a/vm/interp/InterpState.h b/vm/interp/InterpState.h
index 37b7fdd..9b4fea5 100644
--- a/vm/interp/InterpState.h
+++ b/vm/interp/InterpState.h
@@ -24,6 +24,10 @@
 #ifndef DALVIK_INTERP_STATE_H_
 #define DALVIK_INTERP_STATE_H_
 
+#ifdef WITH_TAINT_TRACKING
+#include "interp/Taint.h"
+#endif
+
 /*
  * Execution mode, e.g. interpreter vs. JIT.
  */
@@ -100,6 +104,9 @@ struct InterpSaveState {
     const Method    *method;    // Method being executed
     DvmDex*         methodClassDex;
     JValue          retval;
+#ifdef WITH_TAINT_TRACKING
+    Taint       rtaint;			// return taint value
+#endif /* WITH_TAINT_TRACKING */
     void*           bailPtr;
 #if defined(WITH_TRACKREF_CHECKS)
     int             debugTrackedRefStart;
diff --git a/vm/interp/Jit.cpp b/vm/interp/Jit.cpp
index 9f87705..a6147ca 100644
--- a/vm/interp/Jit.cpp
+++ b/vm/interp/Jit.cpp
@@ -62,6 +62,9 @@ void dvmSelfVerificationShadowSpaceFree(Thread* self)
  *     pc  (Dalvik PC)
  *     fp  (Dalvik FP)
  *     retval
+ *     // begin WITH_TAINT_TRACKING
+ *     rtaint
+ *     // end WITH_TAINT_tRACKING
  *     method
  *     methodClassDex
  *     interpStackEnd
@@ -70,12 +73,17 @@ void* dvmSelfVerificationSaveState(const u2* pc, u4* fp,
                                    Thread* self, int targetTrace)
 {
     ShadowSpace *shadowSpace = self->shadowSpace;
+#ifdef WITH_TAINT_TRACKING
+    unsigned preBytes = self->interpSave.method->outsSize*4*2 + sizeof(StackSaveArea) + 4;
+    unsigned postBytes = self->interpSave.method->registersSize*4*2;
+#else
     unsigned preBytes = self->interpSave.method->outsSize*4 +
         sizeof(StackSaveArea);
     unsigned postBytes = self->interpSave.method->registersSize*4;
+#endif /*WITH_TAINT_TRACKING*/
 
-    //ALOGD("### selfVerificationSaveState(%d) pc: %#x fp: %#x",
-    //    self->threadId, (int)pc, (int)fp);
+    ALOGD("### selfVerificationSaveState(%d) pc: %#x fp: %#x",
+        self->threadId, (int)pc, (int)fp);
 
     if (shadowSpace->selfVerificationState != kSVSIdle) {
         ALOGD("~~~ Save: INCORRECT PREVIOUS STATE(%d): %d",
@@ -97,6 +105,9 @@ void* dvmSelfVerificationSaveState(const u2* pc, u4* fp,
     shadowSpace->startPC = pc;
     shadowSpace->fp = fp;
     shadowSpace->retval = self->interpSave.retval;
+#ifdef WITH_TAINT_TRACKING
+    shadowSpace->rtaint = self->interpSave.rtaint;
+#endif /*WITH_TAINT_TRACKING*/
     shadowSpace->interpStackEnd = self->interpStackEnd;
 
     /*
@@ -138,9 +149,9 @@ void* dvmSelfVerificationRestoreState(const u2* pc, u4* fp,
     shadowSpace->endShadowFP = fp;
     shadowSpace->jitExitState = exitState;
 
-    //ALOGD("### selfVerificationRestoreState(%d) pc: %#x fp: %#x endPC: %#x",
-    //    self->threadId, (int)shadowSpace->startPC, (int)shadowSpace->fp,
-    //    (int)pc);
+    ALOGD("### selfVerificationRestoreState(%d) pc: %#x fp: %#x endPC: %#x",
+        self->threadId, (int)shadowSpace->startPC, (int)shadowSpace->fp,
+        (int)pc);
 
     if (shadowSpace->selfVerificationState != kSVSStart) {
         ALOGD("~~~ Restore: INCORRECT PREVIOUS STATE(%d): %d",
@@ -166,6 +177,9 @@ void* dvmSelfVerificationRestoreState(const u2* pc, u4* fp,
     self->interpSave.method = shadowSpace->method;
     self->interpSave.methodClassDex = shadowSpace->methodClassDex;
     self->interpSave.retval = shadowSpace->retval;
+#ifdef WITH_TAINT_TRACKING
+    self->interpSave.rtaint = shadowSpace->rtaint;
+#endif /*WITH_TAINT_TRACKING*/
     self->interpStackEnd = shadowSpace->interpStackEnd;
 
     return shadowSpace;
@@ -175,10 +189,19 @@ void* dvmSelfVerificationRestoreState(const u2* pc, u4* fp,
 static void selfVerificationPrintRegisters(int* addr, int* addrRef,
                                            int numWords)
 {
+#ifdef WITH_TAINT_TRACKING
+    int i = 0;
+    while(i<numWords) {
+        ALOGD("(v%d) 0x%8x%s", i/2, addr[i], addr[i] != addrRef[i] ? " X" : "");
+        ALOGD("(t%d) 0x%8x (taint tag)%s", i/2, addr[i+1], addr[i+1] != addrRef[i+1] ? " X" : "");
+        i+=2;
+    }
+#else
     int i;
     for (i = 0; i < numWords; i++) {
         ALOGD("(v%d) 0x%8x%s", i, addr[i], addr[i] != addrRef[i] ? " X" : "");
     }
+#endif /*WITH_TAINT_TRACKING*/
 }
 
 /* Print values maintained in shadowSpace */
@@ -192,8 +215,13 @@ static void selfVerificationDumpState(const u2* pc, Thread* self)
     int localRegs = 0;
     int frameBytes2 = 0;
     if ((uintptr_t)self->interpSave.curFrame < (uintptr_t)shadowSpace->fp) {
+#ifdef WITH_TAINT_TRACKING
+        localRegs = (stackSave->method->registersSize -
+                     stackSave->method->insSize)*4*2;
+#else
         localRegs = (stackSave->method->registersSize -
                      stackSave->method->insSize)*4;
+#endif /*WITH_TAINT_TRACKING*/
         frameBytes2 = (int) shadowSpace->fp -
                       (int)self->interpSave.curFrame - localRegs;
     }
@@ -269,9 +297,9 @@ void dvmCheckSelfVerification(const u2* pc, Thread* self)
     DecodedInstruction decInsn;
     dexDecodeInstruction(pc, &decInsn);
 
-    //ALOGD("### DbgIntp(%d): PC: %#x endPC: %#x state: %d len: %d %s",
-    //    self->threadId, (int)pc, (int)shadowSpace->endPC, state,
-    //    shadowSpace->traceLength, dexGetOpcodeName(decInsn.opcode));
+    ALOGD("### DbgIntp(%d): PC: %#x endPC: %#x state: %d len: %d %s",
+        self->threadId, (int)pc, (int)shadowSpace->endPC, state,
+        shadowSpace->traceLength, dexGetOpcodeName(decInsn.opcode));
 
     if (state == kSVSIdle || state == kSVSStart) {
         ALOGD("~~~ DbgIntrp: INCORRECT PREVIOUS STATE(%d): %d",
@@ -323,12 +351,19 @@ void dvmCheckSelfVerification(const u2* pc, Thread* self)
                                            frameBytes/4);
             selfVerificationSpinLoop(shadowSpace);
         }
+#ifndef WITH_TAINT_TRACKING
+        // PJG: incorrect for our stack config
         /* Check new frame if it exists (invokes only) */
         if ((uintptr_t)self->interpSave.curFrame < (uintptr_t)shadowSpace->fp) {
             StackSaveArea* stackSave =
                 SAVEAREA_FROM_FP(self->interpSave.curFrame);
+#ifdef WITH_TAINT_TRACKING
+            int localRegs = (stackSave->method->registersSize -
+                             stackSave->method->insSize)*4*2;
+#else
             int localRegs = (stackSave->method->registersSize -
                              stackSave->method->insSize)*4;
+#endif /*WITH_TAINT_TRACKING*/
             int frameBytes2 = (int) shadowSpace->fp -
                               (int) self->interpSave.curFrame - localRegs;
             if (memcmp(((char*)self->interpSave.curFrame)+localRegs,
@@ -358,6 +393,7 @@ void dvmCheckSelfVerification(const u2* pc, Thread* self)
                 selfVerificationSpinLoop(shadowSpace);
             }
         }
+#endif /*WITH_TAINT_TRACKING*/
 
         /* Check memory space */
         bool memDiff = false;
@@ -384,7 +420,6 @@ void dvmCheckSelfVerification(const u2* pc, Thread* self)
         }
         if (memDiff) selfVerificationSpinLoop(shadowSpace);
 
-
         /*
          * Success.  If this shadowed trace included a single-stepped
          * instruction, we need to stay in the interpreter for one
diff --git a/vm/interp/Jit.h b/vm/interp/Jit.h
index 962040b..4bd7d91 100644
--- a/vm/interp/Jit.h
+++ b/vm/interp/Jit.h
@@ -26,7 +26,12 @@
 
 #if defined (WITH_SELF_VERIFICATION)
 
+#ifdef WITH_TAINT_TRACKING
+// 2x storage for registers
+#define REG_SPACE 512                /* default size of shadow space */
+#else
 #define REG_SPACE 256                /* default size of shadow space */
+#endif /*WITH_TAINT_TRACKING*/
 #define HEAP_SPACE JIT_MAX_TRACE_LEN /* default size of heap space */
 
 struct ShadowHeap {
@@ -45,6 +50,9 @@ struct ShadowSpace {
     const Method *method;
     DvmDex* methodClassDex;
     JValue retval;
+#ifdef WITH_TAINT_TRACKING
+    Taint       rtaint;			// return taint value
+#endif /* WITH_TAINT_TRACKING */
     const u1* interpStackEnd;
     SelfVerificationState jitExitState;  /* exit point for JIT'ed code */
     SelfVerificationState selfVerificationState;  /* current SV running state */
diff --git a/vm/interp/Stack.cpp b/vm/interp/Stack.cpp
index a1f8d71..ee9c5d7 100644
--- a/vm/interp/Stack.cpp
+++ b/vm/interp/Stack.cpp
@@ -70,9 +70,16 @@ static bool dvmPushInterpFrame(Thread* self, const Method* method)
     assert(!dvmIsNativeMethod(method));
     assert(!dvmIsAbstractMethod(method));
 
+#ifdef WITH_TAINT_TRACKING
+    /* taint tags are interleaved, plus "native hack" spacer for args */
+    stackReq = method->registersSize * 8 + 4       // params + locals
+                + sizeof(StackSaveArea) * 2     // break frame + regular frame
+                + method->outsSize * 8 + 4;         // args to other methods
+# else
     stackReq = method->registersSize * 4        // params + locals
                 + sizeof(StackSaveArea) * 2     // break frame + regular frame
                 + method->outsSize * 4;         // args to other methods
+#endif
 
     if (self->interpSave.curFrame != NULL)
         stackPtr = (u1*) SAVEAREA_FROM_FP(self->interpSave.curFrame);
@@ -96,13 +103,22 @@ static bool dvmPushInterpFrame(Thread* self, const Method* method)
      */
     stackPtr -= sizeof(StackSaveArea);
     breakSaveBlock = (StackSaveArea*)stackPtr;
+#ifdef WITH_TAINT_TRACKING
+    /* interleaved taint tracking plus "native hack" spacer for args */
+    stackPtr -= method->registersSize * 8 + 4 + sizeof(StackSaveArea);
+#else
     stackPtr -= method->registersSize * 4 + sizeof(StackSaveArea);
+#endif
     saveBlock = (StackSaveArea*) stackPtr;
 
 #if !defined(NDEBUG) && !defined(PAD_SAVE_AREA)
     /* debug -- memset the new stack, unless we want valgrind's help */
+#ifdef WITH_TAINT_TRACKING
+    memset(stackPtr - (method->outsSize*8+4), 0xaf, stackReq);
+#else
     memset(stackPtr - (method->outsSize*4), 0xaf, stackReq);
 #endif
+#endif
 #ifdef EASY_GDB
     breakSaveBlock->prevSave =
        (StackSaveArea*)FP_FROM_SAVEAREA(self->interpSave.curFrame);
@@ -145,8 +161,14 @@ bool dvmPushJNIFrame(Thread* self, const Method* method)
 
     assert(dvmIsNativeMethod(method));
 
+#ifdef WITH_TAINT_TRACKING
+    /* Interleaved taint tags plus "native hack" spacer */
+    stackReq = method->registersSize * 8 + 4    // params only
+                + sizeof(StackSaveArea) * 2;    // break frame + regular frame
+#else
     stackReq = method->registersSize * 4        // params only
                 + sizeof(StackSaveArea) * 2;    // break frame + regular frame
+#endif
 
     if (self->interpSave.curFrame != NULL)
         stackPtr = (u1*) SAVEAREA_FROM_FP(self->interpSave.curFrame);
@@ -171,7 +193,12 @@ bool dvmPushJNIFrame(Thread* self, const Method* method)
      */
     stackPtr -= sizeof(StackSaveArea);
     breakSaveBlock = (StackSaveArea*)stackPtr;
+#ifdef WITH_TAINT_TRACKING
+    /* interleaved taint tags plus "native hack" spacer */
+    stackPtr -= method->registersSize * 8 + 4 + sizeof(StackSaveArea);
+#else
     stackPtr -= method->registersSize * 4 + sizeof(StackSaveArea);
+#endif
     saveBlock = (StackSaveArea*) stackPtr;
 
 #if !defined(NDEBUG) && !defined(PAD_SAVE_AREA)
@@ -447,31 +474,63 @@ void dvmCallMethodV(Thread* self, const Method* method, Object* obj,
     ClassObject* clazz;
     u4* ins;
 
+#ifdef WITH_TAINT_TRACKING
+    int slot_cnt = 0;
+    bool nativeTarget = dvmIsNativeMethod(method);
+#endif
+
     clazz = callPrep(self, method, obj, false);
     if (clazz == NULL)
         return;
 
     /* "ins" for new frame start at frame pointer plus locals */
+#ifdef WITH_TAINT_TRACKING
+    if (nativeTarget) {
+    	/* native target, no taint tag interleaving */
+    	ins = ((u4*)self->interpSave.curFrame) + (method->registersSize - method->insSize);
+    } else {
+    	/* interpreted target, taint tags are interleaved */
+    	ins = ((u4*)self->interpSave.curFrame) +
+    			((method->registersSize - method->insSize) << 1);
+    }
+#else
     ins = ((u4*)self->interpSave.curFrame) +
            (method->registersSize - method->insSize);
+#endif
 
     //ALOGD("  FP is %p, INs live at >= %p", self->interpSave.curFrame, ins);
-
     /* put "this" pointer into in0 if appropriate */
     if (!dvmIsStaticMethod(method)) {
 #ifdef WITH_EXTRA_OBJECT_VALIDATION
         assert(obj != NULL && dvmIsHeapAddress(obj));
 #endif
         *ins++ = (u4) obj;
+#ifdef WITH_TAINT_TRACKING
+        if (!nativeTarget) {
+        	*ins++ = TAINT_CLEAR;
+        }
+        slot_cnt++;
+#endif
         verifyCount++;
     }
-
     while (*desc != '\0') {
         switch (*(desc++)) {
             case 'D': case 'J': {
                 u8 val = va_arg(args, u8);
                 memcpy(ins, &val, 8);       // EABI prevents direct store
-                ins += 2;
+#ifdef WITH_TAINT_TRACKING
+                if (nativeTarget) {
+                	ins += 2;
+                } else { /* adjust for taint tag interleaving */
+                	ins[2] = ins[1];
+                	ins[1] = TAINT_CLEAR;
+                	ins[3] = TAINT_CLEAR;
+                	ins += 4;
+                }
+                slot_cnt += 2;
+#else                
+		ins += 2;
+#endif
                 verifyCount += 2;
                 break;
             }
@@ -479,6 +538,13 @@ void dvmCallMethodV(Thread* self, const Method* method, Object* obj,
                 /* floats were normalized to doubles; convert back */
                 float f = (float) va_arg(args, double);
                 *ins++ = dvmFloatToU4(f);
+#ifdef WITH_TAINT_TRACKING
+                if (!nativeTarget) {
+                	*ins++ = TAINT_CLEAR;
+                }
+                slot_cnt++;
+#endif
+
                 verifyCount++;
                 break;
             }
@@ -490,17 +556,42 @@ void dvmCallMethodV(Thread* self, const Method* method, Object* obj,
                     *ins++ = (u4) dvmDecodeIndirectRef(self, argObj);
                 else
                     *ins++ = (u4) argObj;
+#ifdef WITH_TAINT_TRACKING
+                if (!nativeTarget) {
+                	*ins++ = TAINT_CLEAR;
+                }
+                slot_cnt++;
+#endif
+
                 verifyCount++;
                 break;
             }
             default: {
                 /* Z B C S I -- all passed as 32-bit integers */
                 *ins++ = va_arg(args, u4);
+#ifdef WITH_TAINT_TRACKING
+                if (!nativeTarget) {
+                	*ins++ = TAINT_CLEAR;
+                }
+                slot_cnt++;
+#endif
                 verifyCount++;
                 break;
             }
         }
     }
+#ifdef WITH_TAINT_TRACKING
+    /* native hack spacer */
+    *ins++ = TAINT_CLEAR; /* if nativeTarget, this is return taint */
+    {
+    	int i;
+    	if (nativeTarget) {
+    		for (i = 0; i < slot_cnt; i++) {
+    			*ins++ = TAINT_CLEAR;
+    		}
+    	}
+    }
+#endif
 
 #ifndef NDEBUG
     if (verifyCount != method->insSize) {
@@ -510,7 +601,6 @@ void dvmCallMethodV(Thread* self, const Method* method, Object* obj,
         goto bail;
     }
 #endif
-
     //dvmDumpThreadStack(dvmThreadSelf());
 
     if (dvmIsNativeMethod(method)) {
@@ -523,9 +613,16 @@ void dvmCallMethodV(Thread* self, const Method* method, Object* obj,
                               method, self);
         TRACE_METHOD_EXIT(self, method);
     } else {
+#ifdef WITH_TAINT_TRACKING
+    	u4 rtaint; /* not used */
+    	dvmInterpret(self, method, pResult, &rtaint);
+//		if (dvmCheckException(self)) {
+//        ALOGE("exception of self in dvmCallMethodV 5");
+//		}
+#else
         dvmInterpret(self, method, pResult);
+#endif
     }
-
 #ifndef NDEBUG
 bail:
 #endif
@@ -553,18 +650,40 @@ void dvmCallMethodA(Thread* self, const Method* method, Object* obj,
     ClassObject* clazz;
     u4* ins;
 
+#ifdef WITH_TAINT_TRACKING
+    int slot_cnt = 0;
+    bool nativeTarget = dvmIsNativeMethod(method);
+#endif
+
     clazz = callPrep(self, method, obj, false);
     if (clazz == NULL)
         return;
 
     /* "ins" for new frame start at frame pointer plus locals */
+#ifdef WITH_TAINT_TRACKING
+    if (nativeTarget) {
+    	/* native target, no taint tag interleaving */
+    	ins = ((u4*)self->interpSave.curFrame) + (method->registersSize - method->insSize);
+    } else {
+    	/* interpreted target, taint tags are interleaved */
+    	ins = ((u4*)self->interpSave.curFrame) +
+    			((method->registersSize - method->insSize) << 1);
+    }
+#else
     ins = ((u4*)self->interpSave.curFrame) +
         (method->registersSize - method->insSize);
+#endif
 
     /* put "this" pointer into in0 if appropriate */
     if (!dvmIsStaticMethod(method)) {
         assert(obj != NULL);
         *ins++ = (u4) obj;              /* obj is a "real" ref */
+#ifdef WITH_TAINT_TRACKING
+        if (!nativeTarget) {
+        	*ins++ = TAINT_CLEAR;
+        }
+        slot_cnt++;
+#endif
         verifyCount++;
     }
 
@@ -573,7 +692,19 @@ void dvmCallMethodA(Thread* self, const Method* method, Object* obj,
         case 'D':                       /* 64-bit quantity; have to use */
         case 'J':                       /*  memcpy() in case of mis-alignment */
             memcpy(ins, &args->j, 8);
+#ifdef WITH_TAINT_TRACKING
+            if (nativeTarget) {
+            	ins += 2;
+            } else { /* adjust for taint tag interleaving */
+            	ins[2] = ins[1];
+            	ins[1] = TAINT_CLEAR;
+            	ins[3] = TAINT_CLEAR;
+            	ins += 4;
+            }
+            slot_cnt += 2;
+#else
             ins += 2;
+#endif
             verifyCount++;              /* this needs an extra push */
             break;
         case 'L':                       /* includes array refs */
@@ -581,22 +712,58 @@ void dvmCallMethodA(Thread* self, const Method* method, Object* obj,
                 *ins++ = (u4) dvmDecodeIndirectRef(self, args->l);
             else
                 *ins++ = (u4) args->l;
+#ifdef WITH_TAINT_TRACKING
+            if (!nativeTarget) {
+            	*ins++ = TAINT_CLEAR;
+            }
+            slot_cnt++;
+#endif
             break;
         case 'F':
         case 'I':
             *ins++ = args->i;           /* full 32 bits */
+#ifdef WITH_TAINT_TRACKING
+            if (!nativeTarget) {
+            	*ins++ = TAINT_CLEAR;
+            }
+            slot_cnt++;
+#endif
             break;
         case 'S':
             *ins++ = args->s;           /* 16 bits, sign-extended */
+#ifdef WITH_TAINT_TRACKING
+            if (!nativeTarget) {
+            	*ins++ = TAINT_CLEAR;
+            }
+            slot_cnt++;
+#endif            
             break;
         case 'C':
             *ins++ = args->c;           /* 16 bits, unsigned */
+#ifdef WITH_TAINT_TRACKING
+            if (!nativeTarget) {
+            	*ins++ = TAINT_CLEAR;
+            }
+            slot_cnt++;
+#endif
             break;
         case 'B':
             *ins++ = args->b;           /* 8 bits, sign-extended */
+#ifdef WITH_TAINT_TRACKING
+            if (!nativeTarget) {
+            	*ins++ = TAINT_CLEAR;
+            }
+            slot_cnt++;
+#endif
             break;
         case 'Z':
             *ins++ = args->z;           /* 8 bits, zero or non-zero */
+#ifdef WITH_TAINT_TRACKING
+            if (!nativeTarget) {
+            	*ins++ = TAINT_CLEAR;
+            }
+            slot_cnt++;
+#endif
             break;
         default:
             ALOGE("Invalid char %c in short signature of %s.%s",
@@ -609,6 +776,19 @@ void dvmCallMethodA(Thread* self, const Method* method, Object* obj,
         args++;
     }
 
+#ifdef WITH_TAINT_TRACKING
+    /* native hack spacer */
+    *ins++ = TAINT_CLEAR; /* if nativeTarget, this is return taint */
+    {
+    	int i;
+    	if (nativeTarget) {
+    		for (i = 0; i < slot_cnt; i++) {
+    			*ins++ = TAINT_CLEAR;
+    		}
+    	}
+    }
+#endif
+
 #ifndef NDEBUG
     if (verifyCount != method->insSize) {
         ALOGE("Got vfycount=%d insSize=%d for %s.%s", verifyCount,
@@ -628,7 +808,12 @@ void dvmCallMethodA(Thread* self, const Method* method, Object* obj,
                               method, self);
         TRACE_METHOD_EXIT(self, method);
     } else {
+#ifdef WITH_TAINT_TRACKING
+    	u4 rtaint; /* not used */
+    	dvmInterpret(self, method, pResult, &rtaint);
+#else
         dvmInterpret(self, method, pResult);
+#endif
     }
 
 bail:
@@ -665,6 +850,17 @@ Object* dvmInvokeMethod(Object* obj, const Method* method,
     JValue retval;
     bool needPop = false;
 
+#ifdef WITH_TAINT_TRACKING
+    u4 rtaint = TAINT_CLEAR;
+    int slot_cnt = 0;
+    bool nativeTarget = dvmIsNativeMethod(method);
+    /* For simplicity, argument tags for native targets
+     * are unioned. This may cause false positives, but
+     * it is the easiest way to handle this for now.
+     */
+    u4 nativeTag = TAINT_CLEAR;
+#endif
+
     /* verify arg count */
     if (argList != NULL)
         argListLength = argList->length;
@@ -683,8 +879,19 @@ Object* dvmInvokeMethod(Object* obj, const Method* method,
     needPop = true;
 
     /* "ins" for new frame start at frame pointer plus locals */
+#ifdef WITH_TAINT_TRACKING
+    if (nativeTarget) {
+    	/* native target, no taint tag interleaving */
+    	ins = ((s4*)self->interpSave.curFrame) + (method->registersSize - method->insSize);
+    } else {
+    	/* interpreted target, taint tags are interleaved */
+    	ins = ((s4*)self->interpSave.curFrame) +
+    			((method->registersSize - method->insSize) << 1);
+    }
+#else
     ins = ((s4*)self->interpSave.curFrame) +
         (method->registersSize - method->insSize);
+#endif
     verifyCount = 0;
 
     //ALOGD("  FP is %p, INs live at >= %p", self->interpSave.curFrame, ins);
@@ -693,6 +900,12 @@ Object* dvmInvokeMethod(Object* obj, const Method* method,
     if (!dvmIsStaticMethod(method)) {
         assert(obj != NULL);
         *ins++ = (s4) obj;
+#ifdef WITH_TAINT_TRACKING
+        if (!nativeTarget) {
+        	*ins++ = TAINT_CLEAR;
+        }
+        slot_cnt++;
+#endif
         verifyCount++;
     }
 
@@ -703,6 +916,9 @@ Object* dvmInvokeMethod(Object* obj, const Method* method,
     DataObject** args = (DataObject**)(void*)argList->contents;
     ClassObject** types = (ClassObject**)(void*)params->contents;
     for (int i = 0; i < argListLength; i++) {
+#ifdef WITH_TAINT_TRACKING
+        int tag = dvmGetPrimitiveTaint(*args, *types);
+#endif
         int width = dvmConvertArgument(*args++, *types++, ins);
         if (width < 0) {
             dvmPopFrame(self);      // throw wants to pull PC out of stack
@@ -710,11 +926,47 @@ Object* dvmInvokeMethod(Object* obj, const Method* method,
             throwArgumentTypeMismatch(i, *(types-1), *(args-1));
             goto bail;
         }
-
+#ifdef WITH_TAINT_TRACKING
+        /* dvmConvertArgument() returns -1, 1, or 2 */
+        if (nativeTarget) {
+        	nativeTag |= tag; /* TODO: is there a better way to do this?*/
+        	ins += width;
+        } else {
+        	if (width == 2) {
+        		ins[2] = ins[1];
+        		ins[1] = tag;
+        		ins[3] = tag;
+        		ins += 4;
+        	} else if (width == 1) {
+        		ins[1] = tag;
+        		ins += 2;
+        	} else { /* error condition duplicated from above */
+        		dvmPopFrame(self);
+        		needPop = false;
+			dvmThrowExceptionFmt(gDvm.exIllegalArgumentException, "argument type mismatch");
+        		goto bail;
+        	}
+        }
+        slot_cnt += width;
+#else
         ins += width;
+#endif
         verifyCount += width;
     }
 
+#ifdef WITH_TAINT_TRACKING
+    /* native hack spacer */
+    *ins++ = TAINT_CLEAR; /* if nativeTarget, this is return taint */
+    {
+    	int i;
+    	if (nativeTarget) {
+    		for (i = 0; i < slot_cnt; i++) {
+    			*ins++ = nativeTag; /* TODO: better way? */
+    		}
+    	}
+    }
+#endif
+
 #ifndef NDEBUG
     if (verifyCount != method->insSize) {
         ALOGE("Got vfycount=%d insSize=%d for %s.%s", verifyCount,
@@ -733,8 +985,15 @@ Object* dvmInvokeMethod(Object* obj, const Method* method,
         (*method->nativeFunc)((u4*)self->interpSave.curFrame, &retval,
                               method, self);
         TRACE_METHOD_EXIT(self, method);
+#ifdef WITH_TAINT_TRACKING
+        rtaint = ((u4*)self->interpSave.curFrame)[slot_cnt];
+#endif
     } else {
+#ifdef WITH_TAINT_TRACKING
+        dvmInterpret(self, method, &retval, &rtaint);
+#else
         dvmInterpret(self, method, &retval);
+#endif
     }
 
     /*
@@ -764,6 +1023,9 @@ Object* dvmInvokeMethod(Object* obj, const Method* method,
          */
         if (returnType != NULL) {
             retObj = (Object*)dvmBoxPrimitive(retval, returnType);
+#ifdef WITH_TAINT_TRACKING
+            dvmSetPrimitiveTaint((DataObject*)retObj, returnType, rtaint);
+#endif
             dvmReleaseTrackedAlloc(retObj, NULL);
         }
     }
diff --git a/vm/interp/Stack.h b/vm/interp/Stack.h
index 06e7ec5..e42ee29 100644
--- a/vm/interp/Stack.h
+++ b/vm/interp/Stack.h
@@ -136,6 +136,11 @@ struct StackSaveArea {
     /* pointer to method we're *currently* executing; handy for exceptions */
     const Method* method;
 
+#ifdef WITH_TAINT_TRACKING
+    // we need this to get return taint from native targets
+    u4			argCount;
+#endif /*WITH_TAINT_TRACKING*/
+
     union {
         /* for JNI native methods: bottom of local reference segment */
         u4          localRefCookie;
@@ -157,12 +162,21 @@ struct StackSaveArea {
 #define FP_FROM_SAVEAREA(_save) ((u4*) ((StackSaveArea*)(_save) +1))
 
 /* when calling a function, get a pointer to outs[0] */
+#ifdef WITH_TAINT_TRACKING
+#define OUTS_FROM_FP(_fp, _argCount) \
+    ((u4*) ((u1*)SAVEAREA_FROM_FP(_fp) - \
+	( ((sizeof(u4) * (_argCount))<<1) +4) ))
+#else /* ndef WITH_TAINT_TRACKING */
 #define OUTS_FROM_FP(_fp, _argCount) \
     ((u4*) ((u1*)SAVEAREA_FROM_FP(_fp) - sizeof(u4) * (_argCount)))
+#endif /* WITH_TAINT_TRACKING */
 
 /* reserve this many bytes for handling StackOverflowError */
+#ifdef WITH_TAINT_TRACKING
+#define STACK_OVERFLOW_RESERVE  1024
+#else
 #define STACK_OVERFLOW_RESERVE  768
-
+#endif
 /*
  * Determine if the frame pointer points to a "break frame".
  */
diff --git a/vm/interp/Taint.h b/vm/interp/Taint.h
new file mode 100644
index 0000000..7621c63
--- /dev/null
+++ b/vm/interp/Taint.h
@@ -0,0 +1,50 @@
+/*
+ * Copyright (c) 2010 The Pennsylvania State University
+ * Systems and Internet Infrastructure Security Laboratory
+ *
+ * Authors: William Enck <enck@cse.psu.edu>
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+/*
+ * Dalvik interpreter public definitions.
+ */
+#ifndef _DALVIK_INTERP_TAINT
+#define _DALVIK_INTERP_TAINT
+
+/* The Taint structure */
+typedef struct Taint {
+    u4 tag;
+} Taint;
+
+/* The Taint markings */
+
+#define TAINT_CLEAR         ((u4)0x00000000) /* No taint */
+#define TAINT_LOCATION      ((u4)0x00000001) /* Location */
+#define TAINT_CONTACTS      ((u4)0x00000002) /* Address Book (ContactsProvider) */
+#define TAINT_MIC           ((u4)0x00000004) /* Microphone Input */
+#define TAINT_PHONE_NUMBER  ((u4)0x00000008) /* Phone Number */
+#define TAINT_LOCATION_GPS  ((u4)0x00000010) /* GPS Location */
+#define TAINT_LOCATION_NET  ((u4)0x00000020) /* NET-based Location */
+#define TAINT_LOCATION_LAST ((u4)0x00000040) /* Last known Location */
+#define TAINT_CAMERA        ((u4)0x00000080) /* camera */
+#define TAINT_ACCELEROMETER ((u4)0x00000100) /* accelerometer */
+#define TAINT_SMS           ((u4)0x00000200) /* SMS */
+#define TAINT_IMEI          ((u4)0x00000400) /* IMEI */
+#define TAINT_IMSI          ((u4)0x00000800) /* IMSI */
+#define TAINT_ICCID         ((u4)0x00001000) /* ICCID (SIM card identifier) */
+#define TAINT_DEVICE_SN     ((u4)0x00002000) /* Device serial number */
+#define TAINT_ACCOUNT       ((u4)0x00004000) /* User account information */
+#define TAINT_HISTORY       ((u4)0x00008000) /* browser history */
+
+#endif /*_DALVIK_INTERP_TAINT*/
diff --git a/vm/mterp/arm-vfp_taint/OP_ADD_DOUBLE.S b/vm/mterp/arm-vfp_taint/OP_ADD_DOUBLE.S
new file mode 100644
index 0000000..792f933
--- /dev/null
+++ b/vm/mterp/arm-vfp_taint/OP_ADD_DOUBLE.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "arm-vfp_taint/fbinopWide.S" {"instr":"faddd   d2, d0, d1"}
diff --git a/vm/mterp/arm-vfp_taint/OP_ADD_DOUBLE_2ADDR.S b/vm/mterp/arm-vfp_taint/OP_ADD_DOUBLE_2ADDR.S
new file mode 100644
index 0000000..0d9d762
--- /dev/null
+++ b/vm/mterp/arm-vfp_taint/OP_ADD_DOUBLE_2ADDR.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "arm-vfp_taint/fbinopWide2addr.S" {"instr":"faddd   d2, d0, d1"}
diff --git a/vm/mterp/arm-vfp_taint/OP_ADD_FLOAT.S b/vm/mterp/arm-vfp_taint/OP_ADD_FLOAT.S
new file mode 100644
index 0000000..b682616
--- /dev/null
+++ b/vm/mterp/arm-vfp_taint/OP_ADD_FLOAT.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "arm-vfp_taint/fbinop.S" {"instr":"fadds   s2, s0, s1"}
diff --git a/vm/mterp/arm-vfp_taint/OP_ADD_FLOAT_2ADDR.S b/vm/mterp/arm-vfp_taint/OP_ADD_FLOAT_2ADDR.S
new file mode 100644
index 0000000..7c440b6
--- /dev/null
+++ b/vm/mterp/arm-vfp_taint/OP_ADD_FLOAT_2ADDR.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "arm-vfp_taint/fbinop2addr.S" {"instr":"fadds   s2, s0, s1"}
diff --git a/vm/mterp/arm-vfp_taint/OP_CMPG_DOUBLE.S b/vm/mterp/arm-vfp_taint/OP_CMPG_DOUBLE.S
new file mode 100644
index 0000000..3d66a4b
--- /dev/null
+++ b/vm/mterp/arm-vfp_taint/OP_CMPG_DOUBLE.S
@@ -0,0 +1,54 @@
+%verify "executed"
+%verify "basic lt, gt, eq */
+%verify "left arg NaN"
+%verify "right arg NaN"
+    /*
+     * Compare two floating-point values.  Puts 0, 1, or -1 into the
+     * destination register based on the results of the comparison.
+     *
+     * int compare(x, y) {
+     *     if (x == y) {
+     *         return 0;
+     *     } else if (x < y) {
+     *         return -1;
+     *     } else if (x > y) {
+     *         return 1;
+     *     } else {
+     *         return 1;
+     *     }
+     * }
+     */
+    /* op vAA, vBB, vCC */
+    FETCH(r0, 1)                        @ r0<- CCBB
+    mov     r9, rINST, lsr #8           @ r9<- AA
+    and     r2, r0, #255                @ r2<- BB
+    mov     r3, r0, lsr #8              @ r3<- CC
+    VREG_INDEX_TO_ADDR(r2, r2)          @ r2<- &vBB
+    VREG_INDEX_TO_ADDR(r3, r3)          @ r3<- &vCC
+// begin WITH_TAINT_TRACKING
+//    fldd    d0, [r2]                    @ d0<- vBB
+    flds    s0, [r2]
+    flds    s1, [r2, #8]
+//    fldd    d1, [r3]                    @ d1<- vCC
+    flds    s2, [r3]
+    flds    s3, [r3, #8]
+// end WITH_TAINT_TRACKING
+    fcmped  d0, d1                      @ compare (vBB, vCC)
+    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
+    mov     r0, #1                      @ r0<- 1 (default)
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+    b       .L${opcode}_finish          @ argh
+
+%break
+.L${opcode}_finish:
+    fmstat                              @ export status flags
+    mvnmi   r0, #0                      @ (less than) r1<- -1
+    moveq   r0, #0                      @ (equal) r1<- 0
+    SET_VREG(r0, r9)                    @ vAA<- r0
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r1)
+    SET_TAINT_CLEAR(r0)
+    SET_VREG_TAINT(r0, r9, r1)
+// end WITH_TAINT_TRACKING
+    GOTO_OPCODE(ip)                     @ jump to next instruction
+
diff --git a/vm/mterp/arm-vfp_taint/OP_CMPG_FLOAT.S b/vm/mterp/arm-vfp_taint/OP_CMPG_FLOAT.S
new file mode 100644
index 0000000..08d7458
--- /dev/null
+++ b/vm/mterp/arm-vfp_taint/OP_CMPG_FLOAT.S
@@ -0,0 +1,48 @@
+%verify "executed"
+%verify "basic lt, gt, eq */
+%verify "left arg NaN"
+%verify "right arg NaN"
+    /*
+     * Compare two floating-point values.  Puts 0, 1, or -1 into the
+     * destination register based on the results of the comparison.
+     *
+     * int compare(x, y) {
+     *     if (x == y) {
+     *         return 0;
+     *     } else if (x < y) {
+     *         return -1;
+     *     } else if (x > y) {
+     *         return 1;
+     *     } else {
+     *         return 1;
+     *     }
+     * }
+     */
+    /* op vAA, vBB, vCC */
+    FETCH(r0, 1)                        @ r0<- CCBB
+    mov     r9, rINST, lsr #8           @ r9<- AA
+    and     r2, r0, #255                @ r2<- BB
+    mov     r3, r0, lsr #8              @ r3<- CC
+    VREG_INDEX_TO_ADDR(r2, r2)          @ r2<- &vBB
+    VREG_INDEX_TO_ADDR(r3, r3)          @ r3<- &vCC
+    flds    s0, [r2]                    @ s0<- vBB
+    flds    s1, [r3]                    @ s1<- vCC
+    fcmpes  s0, s1                      @ compare (vBB, vCC)
+    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
+    mov     r0, #1                      @ r0<- 1 (default)
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+    fmstat                              @ export status flags
+    mvnmi   r0, #0                      @ (less than) r1<- -1
+    moveq   r0, #0                      @ (equal) r1<- 0
+    b       .L${opcode}_finish          @ argh
+
+%break
+.L${opcode}_finish:
+    SET_VREG(r0, r9)                    @ vAA<- r0
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r1)
+    SET_TAINT_CLEAR(r0)
+    SET_VREG_TAINT(r0, r9, r1)
+// end WITH_TAINT_TRACKING
+    GOTO_OPCODE(ip)                     @ jump to next instruction
+
diff --git a/vm/mterp/arm-vfp_taint/OP_CMPL_DOUBLE.S b/vm/mterp/arm-vfp_taint/OP_CMPL_DOUBLE.S
new file mode 100644
index 0000000..0d211b0
--- /dev/null
+++ b/vm/mterp/arm-vfp_taint/OP_CMPL_DOUBLE.S
@@ -0,0 +1,54 @@
+%verify "executed"
+%verify "basic lt, gt, eq */
+%verify "left arg NaN"
+%verify "right arg NaN"
+    /*
+     * Compare two floating-point values.  Puts 0, 1, or -1 into the
+     * destination register based on the results of the comparison.
+     *
+     * int compare(x, y) {
+     *     if (x == y) {
+     *         return 0;
+     *     } else if (x > y) {
+     *         return 1;
+     *     } else if (x < y) {
+     *         return -1;
+     *     } else {
+     *         return -1;
+     *     }
+     * }
+     */
+    /* op vAA, vBB, vCC */
+    FETCH(r0, 1)                        @ r0<- CCBB
+    mov     r9, rINST, lsr #8           @ r9<- AA
+    and     r2, r0, #255                @ r2<- BB
+    mov     r3, r0, lsr #8              @ r3<- CC
+    VREG_INDEX_TO_ADDR(r2, r2)          @ r2<- &vBB
+    VREG_INDEX_TO_ADDR(r3, r3)          @ r3<- &vCC
+// begin WITH_TAINT_TRACKING
+//    fldd    d0, [r2]                    @ d0<- vBB
+    flds    s0, [r2]
+    flds    s1, [r2, #8]
+//    fldd    d1, [r3]                    @ d1<- vCC
+    flds    s2, [r3]
+    flds    s3, [r3, #8]
+// end WITH_TAINT_TRACKING
+    fcmped  d0, d1                      @ compare (vBB, vCC)
+    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
+    mvn     r0, #0                      @ r0<- -1 (default)
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+    b       .L${opcode}_finish          @ argh
+
+%break
+.L${opcode}_finish:
+    fmstat                              @ export status flags
+    movgt   r0, #1                      @ (greater than) r1<- 1
+    moveq   r0, #0                      @ (equal) r1<- 0
+    SET_VREG(r0, r9)                    @ vAA<- r0
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r1)
+    SET_TAINT_CLEAR(r0)
+    SET_VREG_TAINT(r0, r9, r1)
+// end WITH_TAINT_TRACKING
+    GOTO_OPCODE(ip)                     @ jump to next instruction
+
diff --git a/vm/mterp/arm-vfp_taint/OP_CMPL_FLOAT.S b/vm/mterp/arm-vfp_taint/OP_CMPL_FLOAT.S
new file mode 100644
index 0000000..e3aa61b
--- /dev/null
+++ b/vm/mterp/arm-vfp_taint/OP_CMPL_FLOAT.S
@@ -0,0 +1,48 @@
+%verify "executed"
+%verify "basic lt, gt, eq */
+%verify "left arg NaN"
+%verify "right arg NaN"
+    /*
+     * Compare two floating-point values.  Puts 0, 1, or -1 into the
+     * destination register based on the results of the comparison.
+     *
+     * int compare(x, y) {
+     *     if (x == y) {
+     *         return 0;
+     *     } else if (x > y) {
+     *         return 1;
+     *     } else if (x < y) {
+     *         return -1;
+     *     } else {
+     *         return -1;
+     *     }
+     * }
+     */
+    /* op vAA, vBB, vCC */
+    FETCH(r0, 1)                        @ r0<- CCBB
+    mov     r9, rINST, lsr #8           @ r9<- AA
+    and     r2, r0, #255                @ r2<- BB
+    mov     r3, r0, lsr #8              @ r3<- CC
+    VREG_INDEX_TO_ADDR(r2, r2)          @ r2<- &vBB
+    VREG_INDEX_TO_ADDR(r3, r3)          @ r3<- &vCC
+    flds    s0, [r2]                    @ s0<- vBB
+    flds    s1, [r3]                    @ s1<- vCC
+    fcmpes  s0, s1                      @ compare (vBB, vCC)
+    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
+    mvn     r0, #0                      @ r0<- -1 (default)
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+    fmstat                              @ export status flags
+    movgt   r0, #1                      @ (greater than) r1<- 1
+    moveq   r0, #0                      @ (equal) r1<- 0
+    b       .L${opcode}_finish          @ argh
+
+%break
+.L${opcode}_finish:
+    SET_VREG(r0, r9)                    @ vAA<- r0
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r1)
+    SET_TAINT_CLEAR(r0)
+    SET_VREG_TAINT(r0, r9, r1)
+// end WITH_TAINT_TRACKING
+    GOTO_OPCODE(ip)                     @ jump to next instruction
+
diff --git a/vm/mterp/arm-vfp_taint/OP_DIV_DOUBLE.S b/vm/mterp/arm-vfp_taint/OP_DIV_DOUBLE.S
new file mode 100644
index 0000000..e0090dd
--- /dev/null
+++ b/vm/mterp/arm-vfp_taint/OP_DIV_DOUBLE.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "arm-vfp_taint/fbinopWide.S" {"instr":"fdivd   d2, d0, d1"}
diff --git a/vm/mterp/arm-vfp_taint/OP_DIV_DOUBLE_2ADDR.S b/vm/mterp/arm-vfp_taint/OP_DIV_DOUBLE_2ADDR.S
new file mode 100644
index 0000000..508bfa1
--- /dev/null
+++ b/vm/mterp/arm-vfp_taint/OP_DIV_DOUBLE_2ADDR.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "arm-vfp_taint/fbinopWide2addr.S" {"instr":"fdivd   d2, d0, d1"}
diff --git a/vm/mterp/arm-vfp_taint/OP_DIV_FLOAT.S b/vm/mterp/arm-vfp_taint/OP_DIV_FLOAT.S
new file mode 100644
index 0000000..3a89320
--- /dev/null
+++ b/vm/mterp/arm-vfp_taint/OP_DIV_FLOAT.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "arm-vfp_taint/fbinop.S" {"instr":"fdivs   s2, s0, s1"}
diff --git a/vm/mterp/arm-vfp_taint/OP_DIV_FLOAT_2ADDR.S b/vm/mterp/arm-vfp_taint/OP_DIV_FLOAT_2ADDR.S
new file mode 100644
index 0000000..d2b6a1b
--- /dev/null
+++ b/vm/mterp/arm-vfp_taint/OP_DIV_FLOAT_2ADDR.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "arm-vfp_taint/fbinop2addr.S" {"instr":"fdivs   s2, s0, s1"}
diff --git a/vm/mterp/arm-vfp_taint/OP_DOUBLE_TO_FLOAT.S b/vm/mterp/arm-vfp_taint/OP_DOUBLE_TO_FLOAT.S
new file mode 100644
index 0000000..818fa1d
--- /dev/null
+++ b/vm/mterp/arm-vfp_taint/OP_DOUBLE_TO_FLOAT.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "arm-vfp_taint/funopNarrower.S" {"instr":"fcvtsd  s0, d0"}
diff --git a/vm/mterp/arm-vfp_taint/OP_DOUBLE_TO_INT.S b/vm/mterp/arm-vfp_taint/OP_DOUBLE_TO_INT.S
new file mode 100644
index 0000000..2051f4c
--- /dev/null
+++ b/vm/mterp/arm-vfp_taint/OP_DOUBLE_TO_INT.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "arm-vfp_taint/funopNarrower.S" {"instr":"ftosizd  s0, d0"}
diff --git a/vm/mterp/arm-vfp_taint/OP_FLOAT_TO_DOUBLE.S b/vm/mterp/arm-vfp_taint/OP_FLOAT_TO_DOUBLE.S
new file mode 100644
index 0000000..517fd38
--- /dev/null
+++ b/vm/mterp/arm-vfp_taint/OP_FLOAT_TO_DOUBLE.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "arm-vfp_taint/funopWider.S" {"instr":"fcvtds  d0, s0"}
diff --git a/vm/mterp/arm-vfp_taint/OP_FLOAT_TO_INT.S b/vm/mterp/arm-vfp_taint/OP_FLOAT_TO_INT.S
new file mode 100644
index 0000000..bbe2962
--- /dev/null
+++ b/vm/mterp/arm-vfp_taint/OP_FLOAT_TO_INT.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "arm-vfp_taint/funop.S" {"instr":"ftosizs s1, s0"}
diff --git a/vm/mterp/arm-vfp_taint/OP_INT_TO_DOUBLE.S b/vm/mterp/arm-vfp_taint/OP_INT_TO_DOUBLE.S
new file mode 100644
index 0000000..5c73b4b
--- /dev/null
+++ b/vm/mterp/arm-vfp_taint/OP_INT_TO_DOUBLE.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "arm-vfp_taint/funopWider.S" {"instr":"fsitod  d0, s0"}
diff --git a/vm/mterp/arm-vfp_taint/OP_INT_TO_FLOAT.S b/vm/mterp/arm-vfp_taint/OP_INT_TO_FLOAT.S
new file mode 100644
index 0000000..875ffda
--- /dev/null
+++ b/vm/mterp/arm-vfp_taint/OP_INT_TO_FLOAT.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "arm-vfp_taint/funop.S" {"instr":"fsitos  s1, s0"}
diff --git a/vm/mterp/arm-vfp_taint/OP_MUL_DOUBLE.S b/vm/mterp/arm-vfp_taint/OP_MUL_DOUBLE.S
new file mode 100644
index 0000000..091e651
--- /dev/null
+++ b/vm/mterp/arm-vfp_taint/OP_MUL_DOUBLE.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "arm-vfp_taint/fbinopWide.S" {"instr":"fmuld   d2, d0, d1"}
diff --git a/vm/mterp/arm-vfp_taint/OP_MUL_DOUBLE_2ADDR.S b/vm/mterp/arm-vfp_taint/OP_MUL_DOUBLE_2ADDR.S
new file mode 100644
index 0000000..2434392
--- /dev/null
+++ b/vm/mterp/arm-vfp_taint/OP_MUL_DOUBLE_2ADDR.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "arm-vfp_taint/fbinopWide2addr.S" {"instr":"fmuld   d2, d0, d1"}
diff --git a/vm/mterp/arm-vfp_taint/OP_MUL_FLOAT.S b/vm/mterp/arm-vfp_taint/OP_MUL_FLOAT.S
new file mode 100644
index 0000000..1d1b183
--- /dev/null
+++ b/vm/mterp/arm-vfp_taint/OP_MUL_FLOAT.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "arm-vfp_taint/fbinop.S" {"instr":"fmuls   s2, s0, s1"}
diff --git a/vm/mterp/arm-vfp_taint/OP_MUL_FLOAT_2ADDR.S b/vm/mterp/arm-vfp_taint/OP_MUL_FLOAT_2ADDR.S
new file mode 100644
index 0000000..54fe3d3
--- /dev/null
+++ b/vm/mterp/arm-vfp_taint/OP_MUL_FLOAT_2ADDR.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "arm-vfp_taint/fbinop2addr.S" {"instr":"fmuls   s2, s0, s1"}
diff --git a/vm/mterp/arm-vfp_taint/OP_SUB_DOUBLE.S b/vm/mterp/arm-vfp_taint/OP_SUB_DOUBLE.S
new file mode 100644
index 0000000..0d07ce7
--- /dev/null
+++ b/vm/mterp/arm-vfp_taint/OP_SUB_DOUBLE.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "arm-vfp_taint/fbinopWide.S" {"instr":"fsubd   d2, d0, d1"}
diff --git a/vm/mterp/arm-vfp_taint/OP_SUB_DOUBLE_2ADDR.S b/vm/mterp/arm-vfp_taint/OP_SUB_DOUBLE_2ADDR.S
new file mode 100644
index 0000000..e520f3e
--- /dev/null
+++ b/vm/mterp/arm-vfp_taint/OP_SUB_DOUBLE_2ADDR.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "arm-vfp_taint/fbinopWide2addr.S" {"instr":"fsubd   d2, d0, d1"}
diff --git a/vm/mterp/arm-vfp_taint/OP_SUB_FLOAT.S b/vm/mterp/arm-vfp_taint/OP_SUB_FLOAT.S
new file mode 100644
index 0000000..527eee1
--- /dev/null
+++ b/vm/mterp/arm-vfp_taint/OP_SUB_FLOAT.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "arm-vfp_taint/fbinop.S" {"instr":"fsubs   s2, s0, s1"}
diff --git a/vm/mterp/arm-vfp_taint/OP_SUB_FLOAT_2ADDR.S b/vm/mterp/arm-vfp_taint/OP_SUB_FLOAT_2ADDR.S
new file mode 100644
index 0000000..7cc350b
--- /dev/null
+++ b/vm/mterp/arm-vfp_taint/OP_SUB_FLOAT_2ADDR.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "arm-vfp_taint/fbinop2addr.S" {"instr":"fsubs   s2, s0, s1"}
diff --git a/vm/mterp/arm-vfp_taint/fbinop.S b/vm/mterp/arm-vfp_taint/fbinop.S
new file mode 100644
index 0000000..3c33a94
--- /dev/null
+++ b/vm/mterp/arm-vfp_taint/fbinop.S
@@ -0,0 +1,35 @@
+    /*
+     * Generic 32-bit floating-point operation.  Provide an "instr" line that
+     * specifies an instruction that performs "s2 = s0 op s1".  Because we
+     * use the "softfp" ABI, this must be an instruction, not a function call.
+     *
+     * For: add-float, sub-float, mul-float, div-float
+     */
+    /* floatop vAA, vBB, vCC */
+    FETCH(r0, 1)                        @ r0<- CCBB
+    mov     r9, rINST, lsr #8           @ r9<- AA
+    mov     r3, r0, lsr #8              @ r3<- CC
+    and     r2, r0, #255                @ r2<- BB
+    VREG_INDEX_TO_ADDR(r3, r3)          @ r3<- &vCC
+    VREG_INDEX_TO_ADDR(r2, r2)          @ r2<- &vBB
+    flds    s1, [r3]                    @ s1<- vCC
+    flds    s0, [r2]                    @ s0<- vBB
+// begin WITH_TAINT_TRACKING
+    ldr     r0, [r3, #4]
+    ldr     r1, [r2, #4]
+    orr     r0, r0, r1
+// end WITH_TAINT_TRACKING
+    b     .L${opcode}_finish
+%break
+
+.L${opcode}_finish:
+    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
+    $instr                              @ s2<- op
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+    VREG_INDEX_TO_ADDR(r9, r9)          @ r9<- &vAA
+    fsts    s2, [r9]                    @ vAA<- s2
+// begin WITH_TAINT_TRACKING
+    str     r0, [r9, #4]
+// end WITH_TAINT_TRACKING
+    GOTO_OPCODE(ip)                     @ jump to next instruction
+
diff --git a/vm/mterp/arm-vfp_taint/fbinop2addr.S b/vm/mterp/arm-vfp_taint/fbinop2addr.S
new file mode 100644
index 0000000..f8da5c9
--- /dev/null
+++ b/vm/mterp/arm-vfp_taint/fbinop2addr.S
@@ -0,0 +1,34 @@
+    /*
+     * Generic 32-bit floating point "/2addr" binary operation.  Provide
+     * an "instr" line that specifies an instruction that performs
+     * "s2 = s0 op s1".
+     *
+     * For: add-float/2addr, sub-float/2addr, mul-float/2addr, div-float/2addr
+     */
+    /* binop/2addr vA, vB */
+    mov     r3, rINST, lsr #12          @ r3<- B
+    mov     r9, rINST, lsr #8           @ r9<- A+
+    VREG_INDEX_TO_ADDR(r3, r3)          @ r3<- &vB
+    and     r9, r9, #15                 @ r9<- A
+    flds    s1, [r3]                    @ s1<- vB
+// begin WITH_TAINT_TRACKING
+    ldr     r0, [r3, #4]
+// end WITH_TAINT_TRACKING
+    VREG_INDEX_TO_ADDR(r9, r9)          @ r9<- &vA
+    FETCH_ADVANCE_INST(1)               @ advance rPC, load rINST
+    flds    s0, [r9]                    @ s0<- vA
+// begin WITH_TAINT_TRACKING
+    ldr     r1, [r9, #4]
+    orr     r0, r0, r1
+// end WITH_TAINT_TRACKING
+    b       .L${opcode}_finish
+%break
+
+.L${opcode}_finish:
+    $instr                              @ s2<- op
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+    fsts    s2, [r9]                    @ vAA<- s2
+// begin WITH_TAINT_TRACKING
+    str     r0, [r9, #4]
+// end WITH_TAINT_TRACKING
+    GOTO_OPCODE(ip)                     @ jump to next instruction
diff --git a/vm/mterp/arm-vfp_taint/fbinopWide.S b/vm/mterp/arm-vfp_taint/fbinopWide.S
new file mode 100644
index 0000000..beb9877
--- /dev/null
+++ b/vm/mterp/arm-vfp_taint/fbinopWide.S
@@ -0,0 +1,41 @@
+    /*
+     * Generic 64-bit double-precision floating point binary operation.
+     * Provide an "instr" line that specifies an instruction that performs
+     * "d2 = d0 op d1".
+     *
+     * for: add-double, sub-double, mul-double, div-double
+     */
+    /* doubleop vAA, vBB, vCC */
+    FETCH(r0, 1)                        @ r0<- CCBB
+    mov     r9, rINST, lsr #8           @ r9<- AA
+    mov     r3, r0, lsr #8              @ r3<- CC
+    and     r2, r0, #255                @ r2<- BB
+    VREG_INDEX_TO_ADDR(r3, r3)          @ r3<- &vCC
+    VREG_INDEX_TO_ADDR(r2, r2)          @ r2<- &vBB
+// begin WITH_TAINT_TRACKING
+//    fldd    d1, [r3]                    @ d1<- vCC
+//    fldd    d0, [r2]                    @ d0<- vBB
+    flds    s2, [r3]
+    flds    s3, [r3, #8]
+    flds    s0, [r2]
+    flds    s1, [r2, #8]
+    ldr     r0, [r3, #4]
+    ldr     r1, [r2, #4]
+    orr     r0, r0, r1
+// end WITH_TAINT_TRACKING
+    b     .L${opcode}_finish
+%break
+
+.L${opcode}_finish:
+    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
+    $instr                              @ s2<- op
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+    VREG_INDEX_TO_ADDR(r9, r9)          @ r9<- &vAA
+// begin WITH_TAINT_TRACKING
+//    fstd    d2, [r9]                    @ vAA<- d2
+    fsts    s4, [r9]
+    fsts    s5, [r9, #8]
+    str     r0, [r9, #4]
+    str     r0, [r9, #12]
+// end WITH_TAINT_TRACKING
+    GOTO_OPCODE(ip)                     @ jump to next instruction
diff --git a/vm/mterp/arm-vfp_taint/fbinopWide2addr.S b/vm/mterp/arm-vfp_taint/fbinopWide2addr.S
new file mode 100644
index 0000000..1f93f55
--- /dev/null
+++ b/vm/mterp/arm-vfp_taint/fbinopWide2addr.S
@@ -0,0 +1,42 @@
+    /*
+     * Generic 64-bit floating point "/2addr" binary operation.  Provide
+     * an "instr" line that specifies an instruction that performs
+     * "d2 = d0 op d1".
+     *
+     * For: add-double/2addr, sub-double/2addr, mul-double/2addr,
+     *      div-double/2addr
+     */
+    /* binop/2addr vA, vB */
+    mov     r3, rINST, lsr #12          @ r3<- B
+    mov     r9, rINST, lsr #8           @ r9<- A+
+    VREG_INDEX_TO_ADDR(r3, r3)          @ r3<- &vB
+    and     r9, r9, #15                 @ r9<- A
+// begin WITH_TAINT_TRACKING
+//    fldd    d1, [r3]                    @ d1<- vB
+    flds    s2, [r3]
+    flds    s3, [r3, #8]
+    ldr     r0, [r3, #4]
+// end WITH_TAINT_TRACKING
+    VREG_INDEX_TO_ADDR(r9, r9)          @ r9<- &vA
+    FETCH_ADVANCE_INST(1)               @ advance rPC, load rINST
+// begin WITH_TAINT_TRACKING
+//    fldd    d0, [r9]                    @ d0<- vA
+    flds    s0, [r9]
+    flds    s1, [r9, #8]
+    ldr     r1, [r9, #4]
+// end WITH_TAINT_TRACKING
+    b     .L${opcode}_finish
+%break
+
+.L${opcode}_finish:
+    $instr                              @ d2<- op
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+// begin WITH_TAINT_TRACKING
+    orr    r0, r0, r1
+//    fstd    d2, [r9]                    @ vAA<- d2
+    fsts    s4, [r9]
+    fsts    s5, [r9, #8]
+    str     r0, [r9, #4]
+    str     r0, [r9, #12]
+// end WITH_TAINT_TRACKING
+    GOTO_OPCODE(ip)                     @ jump to next instruction
diff --git a/vm/mterp/arm-vfp_taint/funop.S b/vm/mterp/arm-vfp_taint/funop.S
new file mode 100644
index 0000000..2b9bee5
--- /dev/null
+++ b/vm/mterp/arm-vfp_taint/funop.S
@@ -0,0 +1,24 @@
+    /*
+     * Generic 32-bit unary floating-point operation.  Provide an "instr"
+     * line that specifies an instruction that performs "s1 = op s0".
+     *
+     * for: int-to-float, float-to-int
+     */
+    /* unop vA, vB */
+    mov     r3, rINST, lsr #12          @ r3<- B
+    mov     r9, rINST, lsr #8           @ r9<- A+
+    VREG_INDEX_TO_ADDR(r3, r3)          @ r3<- &vB
+    flds    s0, [r3]                    @ s0<- vB
+// begin WITH_TAINT_TRACKING
+    ldr     r0, [r3, #4]
+// end WITH_TAINT_TRACKING
+    FETCH_ADVANCE_INST(1)               @ advance rPC, load rINST
+    and     r9, r9, #15                 @ r9<- A
+    $instr                              @ s1<- op
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+    VREG_INDEX_TO_ADDR(r9, r9)          @ r9<- &vA
+    fsts    s1, [r9]                    @ vA<- s1
+// begin WITH_TAINT_TRACKING
+    str     r0, [r9, #4]
+// end WITH_TAINT_TRACKING
+    GOTO_OPCODE(ip)                     @ jump to next instruction
diff --git a/vm/mterp/arm-vfp_taint/funopNarrower.S b/vm/mterp/arm-vfp_taint/funopNarrower.S
new file mode 100644
index 0000000..07a43ca
--- /dev/null
+++ b/vm/mterp/arm-vfp_taint/funopNarrower.S
@@ -0,0 +1,26 @@
+    /*
+     * Generic 64bit-to-32bit unary floating point operation.  Provide an
+     * "instr" line that specifies an instruction that performs "s0 = op d0".
+     *
+     * For: double-to-int, double-to-float
+     */
+    /* unop vA, vB */
+    mov     r3, rINST, lsr #12          @ r3<- B
+    mov     r9, rINST, lsr #8           @ r9<- A+
+    VREG_INDEX_TO_ADDR(r3, r3)          @ r3<- &vB
+// begin WITH_TAINT_TRACKING
+//    fldd    d0, [r3]                    @ d0<- vB
+    flds    s0, [r3]
+    flds    s1, [r3, #8]
+    ldr     r0, [r3, #4]
+// end WITH_TAINT_TRACKING
+    FETCH_ADVANCE_INST(1)               @ advance rPC, load rINST
+    and     r9, r9, #15                 @ r9<- A
+    $instr                              @ s0<- op
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+    VREG_INDEX_TO_ADDR(r9, r9)          @ r9<- &vA
+    fsts    s0, [r9]                    @ vA<- s0
+// begin WITH_TAINT_TRACKING
+    str     r0, [r9, #4]
+// end WITH_TAINT_TRACKING
+    GOTO_OPCODE(ip)                     @ jump to next instruction
diff --git a/vm/mterp/arm-vfp_taint/funopWider.S b/vm/mterp/arm-vfp_taint/funopWider.S
new file mode 100644
index 0000000..8e9bd5b
--- /dev/null
+++ b/vm/mterp/arm-vfp_taint/funopWider.S
@@ -0,0 +1,27 @@
+    /*
+     * Generic 32bit-to-64bit floating point unary operation.  Provide an
+     * "instr" line that specifies an instruction that performs "d0 = op s0".
+     *
+     * For: int-to-double, float-to-double
+     */
+    /* unop vA, vB */
+    mov     r3, rINST, lsr #12          @ r3<- B
+    mov     r9, rINST, lsr #8           @ r9<- A+
+    VREG_INDEX_TO_ADDR(r3, r3)          @ r3<- &vB
+    flds    s0, [r3]                    @ s0<- vB
+// begin WITH_TAINT_TRACKING
+    ldr     r0, [r3, #4]
+// end WITH_TAINT_TRACKING
+    FETCH_ADVANCE_INST(1)               @ advance rPC, load rINST
+    and     r9, r9, #15                 @ r9<- A
+    $instr                              @ d0<- op
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+    VREG_INDEX_TO_ADDR(r9, r9)          @ r9<- &vA
+// begin WITH_TAINT_TRACKING
+//    fstd    d0, [r9]                    @ vA<- d0
+    fsts    s0, [r9]
+    fsts    s1, [r9, #8]
+    str     r0, [r9, #4]
+    str     r0, [r9, #12]
+// end WITH_TAINT_TRACKING
+    GOTO_OPCODE(ip)                     @ jump to next instruction
diff --git a/vm/mterp/armv5te_taint/OP_ADD_DOUBLE.S b/vm/mterp/armv5te_taint/OP_ADD_DOUBLE.S
new file mode 100644
index 0000000..12ada2e
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_ADD_DOUBLE.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te_taint/binopWide.S" {"instr":"bl      __aeabi_dadd"}
diff --git a/vm/mterp/armv5te_taint/OP_ADD_DOUBLE_2ADDR.S b/vm/mterp/armv5te_taint/OP_ADD_DOUBLE_2ADDR.S
new file mode 100644
index 0000000..da778b5
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_ADD_DOUBLE_2ADDR.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te_taint/binopWide2addr.S" {"instr":"bl      __aeabi_dadd"}
diff --git a/vm/mterp/armv5te_taint/OP_ADD_FLOAT.S b/vm/mterp/armv5te_taint/OP_ADD_FLOAT.S
new file mode 100644
index 0000000..36b2f72
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_ADD_FLOAT.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te_taint/binop.S" {"instr":"bl      __aeabi_fadd"}
diff --git a/vm/mterp/armv5te_taint/OP_ADD_FLOAT_2ADDR.S b/vm/mterp/armv5te_taint/OP_ADD_FLOAT_2ADDR.S
new file mode 100644
index 0000000..de888fd
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_ADD_FLOAT_2ADDR.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te_taint/binop2addr.S" {"instr":"bl      __aeabi_fadd"}
diff --git a/vm/mterp/armv5te_taint/OP_ADD_INT.S b/vm/mterp/armv5te_taint/OP_ADD_INT.S
new file mode 100644
index 0000000..511e28a
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_ADD_INT.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te_taint/binop.S" {"instr":"add     r0, r0, r1"}
diff --git a/vm/mterp/armv5te_taint/OP_ADD_INT_2ADDR.S b/vm/mterp/armv5te_taint/OP_ADD_INT_2ADDR.S
new file mode 100644
index 0000000..7acc7cd
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_ADD_INT_2ADDR.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te_taint/binop2addr.S" {"instr":"add     r0, r0, r1"}
diff --git a/vm/mterp/armv5te_taint/OP_ADD_INT_LIT16.S b/vm/mterp/armv5te_taint/OP_ADD_INT_LIT16.S
new file mode 100644
index 0000000..c34fa47
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_ADD_INT_LIT16.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te_taint/binopLit16.S" {"instr":"add     r0, r0, r1"}
diff --git a/vm/mterp/armv5te_taint/OP_ADD_INT_LIT8.S b/vm/mterp/armv5te_taint/OP_ADD_INT_LIT8.S
new file mode 100644
index 0000000..9548c6d
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_ADD_INT_LIT8.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te_taint/binopLit8.S" {"instr":"add     r0, r0, r1"}
diff --git a/vm/mterp/armv5te_taint/OP_ADD_LONG.S b/vm/mterp/armv5te_taint/OP_ADD_LONG.S
new file mode 100644
index 0000000..84a63d1
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_ADD_LONG.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te_taint/binopWide.S" {"preinstr":"adds    r0, r0, r2", "instr":"adc     r1, r1, r3"}
diff --git a/vm/mterp/armv5te_taint/OP_ADD_LONG_2ADDR.S b/vm/mterp/armv5te_taint/OP_ADD_LONG_2ADDR.S
new file mode 100644
index 0000000..4aed731
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_ADD_LONG_2ADDR.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te_taint/binopWide2addr.S" {"preinstr":"adds    r0, r0, r2", "instr":"adc     r1, r1, r3"}
diff --git a/vm/mterp/armv5te_taint/OP_AGET.S b/vm/mterp/armv5te_taint/OP_AGET.S
new file mode 100644
index 0000000..cc62f74
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_AGET.S
@@ -0,0 +1,49 @@
+%default { "load":"ldr", "shift":"2" }
+%verify "executed"
+    /*
+     * Array get, 32 bits or less.  vAA <- vBB[vCC].
+     *
+     * Note: using the usual FETCH/and/shift stuff, this fits in exactly 17
+     * instructions.  We use a pair of FETCH_Bs instead.
+     *
+     * for: aget, aget-object, aget-boolean, aget-byte, aget-char, aget-short
+     */
+    /* op vAA, vBB, vCC */
+    FETCH_B(r2, 1, 0)                   @ r2<- BB
+    mov     r9, rINST, lsr #8           @ r9<- AA
+    FETCH_B(r3, 1, 1)                   @ r3<- CC
+    GET_VREG(r0, r2)                    @ r0<- vBB (array object)
+    GET_VREG(r1, r3)                    @ r1<- vCC (requested index)
+    cmp     r0, #0                      @ null array object?
+    beq     common_errNullObject        @ yes, bail
+// begin WITH_TAINT_TRACKING
+    bl		.L${opcode}_taint_prop_1
+// end WITH_TAINT_TRACKING
+    ldr     r3, [r0, #offArrayObject_length]    @ r3<- arrayObj->length
+    add     r0, r0, r1, lsl #$shift     @ r0<- arrayObj + index*width
+    cmp     r1, r3                      @ compare unsigned index, length
+// begin WITH_TAINT_TRACKING
+//    bcs     common_errArrayIndex        @ index >= length, bail	// in subroutine
+//    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST // in subroutine
+    bl		.L${opcode}_taint_prop_2
+// end WITH_TAINT_TRACKING
+    $load   r2, [r0, #offArrayObject_contents]  @ r2<- vBB[vCC]
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+    SET_VREG(r2, r9)                    @ vAA<- r2
+    GOTO_OPCODE(ip)                     @ jump to next instruction
+
+%break
+
+.L${opcode}_taint_prop_1:
+    ldr	    r2, [r0, #offArrayObject_taint]
+    SET_TAINT_FP(r10)
+    GET_VREG_TAINT(r3, r3, r10)
+    orr	    r2, r3, r2                  @ r2<- r2 | r1
+    bx	    lr
+
+.L${opcode}_taint_prop_2:
+    bcs     common_errArrayIndex        @ index >= length, bail
+    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
+    SET_TAINT_FP(r3)
+    SET_VREG_TAINT(r2, r9, r3)
+    bx      lr
diff --git a/vm/mterp/armv5te_taint/OP_AGET_BOOLEAN.S b/vm/mterp/armv5te_taint/OP_AGET_BOOLEAN.S
new file mode 100644
index 0000000..a66a3e0
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_AGET_BOOLEAN.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te_taint/OP_AGET.S" { "load":"ldrb", "shift":"0" }
diff --git a/vm/mterp/armv5te_taint/OP_AGET_BYTE.S b/vm/mterp/armv5te_taint/OP_AGET_BYTE.S
new file mode 100644
index 0000000..bd84869
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_AGET_BYTE.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te_taint/OP_AGET.S" { "load":"ldrsb", "shift":"0" }
diff --git a/vm/mterp/armv5te_taint/OP_AGET_CHAR.S b/vm/mterp/armv5te_taint/OP_AGET_CHAR.S
new file mode 100644
index 0000000..6a7ee2a
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_AGET_CHAR.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te_taint/OP_AGET.S" { "load":"ldrh", "shift":"1" }
diff --git a/vm/mterp/armv5te_taint/OP_AGET_OBJECT.S b/vm/mterp/armv5te_taint/OP_AGET_OBJECT.S
new file mode 100644
index 0000000..42e9bdf
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_AGET_OBJECT.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te_taint/OP_AGET.S"
diff --git a/vm/mterp/armv5te_taint/OP_AGET_SHORT.S b/vm/mterp/armv5te_taint/OP_AGET_SHORT.S
new file mode 100644
index 0000000..1f49674
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_AGET_SHORT.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te_taint/OP_AGET.S" { "load":"ldrsh", "shift":"1" }
diff --git a/vm/mterp/armv5te_taint/OP_AGET_WIDE.S b/vm/mterp/armv5te_taint/OP_AGET_WIDE.S
new file mode 100644
index 0000000..daf8e29
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_AGET_WIDE.S
@@ -0,0 +1,49 @@
+%verify "executed"
+    /*
+     * Array get, 64 bits.  vAA <- vBB[vCC].
+     *
+     * Arrays of long/double are 64-bit aligned, so it's okay to use LDRD.
+     */
+    /* aget-wide vAA, vBB, vCC */
+    FETCH(r0, 1)                        @ r0<- CCBB
+    mov     r9, rINST, lsr #8           @ r9<- AA
+    and     r2, r0, #255                @ r2<- BB
+    mov     r3, r0, lsr #8              @ r3<- CC
+    GET_VREG(r0, r2)                    @ r0<- vBB (array object)
+    GET_VREG(r1, r3)                    @ r1<- vCC (requested index)
+    cmp     r0, #0                      @ null array object?
+    beq     common_errNullObject        @ yes, bail
+// begin WITH_TAINT_TRACKING
+    bl      .L${opcode}_taint_prop      @ r10<- taint
+// end WITH_TAINT_TRACKING
+    ldr     r3, [r0, #offArrayObject_length]    @ r3<- arrayObj->length
+    add     r0, r0, r1, lsl #3          @ r0<- arrayObj + index*width
+    cmp     r1, r3                      @ compare unsigned index, length
+    bcc     .L${opcode}_finish          @ okay, continue below
+    b       common_errArrayIndex        @ index >= length, bail
+    @ May want to swap the order of these two branches depending on how the
+    @ branch prediction (if any) handles conditional forward branches vs.
+    @ unconditional forward branches.
+%break
+
+.L${opcode}_finish:
+    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
+// begin WITH_TAINT_TRACKING
+    ldrd    r0, [r0, #offArrayObject_contents]  @ r0/r1<- vBB[vCC]
+    mov     r2, r1
+    mov     r1, r10
+    mov     r3, r10
+    add     r9, rFP, r9, lsl #3         @ r9<- &fp[AA]
+// end WITH_TAINT_TRACKING
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+// begin WITH_TAINT_TRACKING
+    stmia   r9, {r0-r3}                 @ vAA/vAA+1<- r2/r3
+// begin WITH_TAINT_TRACKING
+    GOTO_OPCODE(ip)                     @ jump to next instruction
+
+.L${opcode}_taint_prop:
+    ldr     r2, [r0, #offArrayObject_taint]
+    SET_TAINT_FP(r10)
+    GET_VREG_TAINT(r10, r3, r10)
+    orr     r10, r10, r2                @ r10<- r10 | r1
+    bx      lr
diff --git a/vm/mterp/armv5te_taint/OP_AND_INT.S b/vm/mterp/armv5te_taint/OP_AND_INT.S
new file mode 100644
index 0000000..43f5f30
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_AND_INT.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te_taint/binop.S" {"instr":"and     r0, r0, r1"}
diff --git a/vm/mterp/armv5te_taint/OP_AND_INT_2ADDR.S b/vm/mterp/armv5te_taint/OP_AND_INT_2ADDR.S
new file mode 100644
index 0000000..0d0f752
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_AND_INT_2ADDR.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te_taint/binop2addr.S" {"instr":"and     r0, r0, r1"}
diff --git a/vm/mterp/armv5te_taint/OP_AND_INT_LIT16.S b/vm/mterp/armv5te_taint/OP_AND_INT_LIT16.S
new file mode 100644
index 0000000..4b7095d
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_AND_INT_LIT16.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te_taint/binopLit16.S" {"instr":"and     r0, r0, r1"}
diff --git a/vm/mterp/armv5te_taint/OP_AND_INT_LIT8.S b/vm/mterp/armv5te_taint/OP_AND_INT_LIT8.S
new file mode 100644
index 0000000..623b451
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_AND_INT_LIT8.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te_taint/binopLit8.S" {"instr":"and     r0, r0, r1"}
diff --git a/vm/mterp/armv5te_taint/OP_AND_LONG.S b/vm/mterp/armv5te_taint/OP_AND_LONG.S
new file mode 100644
index 0000000..5405aec
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_AND_LONG.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te_taint/binopWide.S" {"preinstr":"and     r0, r0, r2", "instr":"and     r1, r1, r3"}
diff --git a/vm/mterp/armv5te_taint/OP_AND_LONG_2ADDR.S b/vm/mterp/armv5te_taint/OP_AND_LONG_2ADDR.S
new file mode 100644
index 0000000..b82f491
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_AND_LONG_2ADDR.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te_taint/binopWide2addr.S" {"preinstr":"and     r0, r0, r2", "instr":"and     r1, r1, r3"}
diff --git a/vm/mterp/armv5te_taint/OP_APUT.S b/vm/mterp/armv5te_taint/OP_APUT.S
new file mode 100644
index 0000000..2b9ed36
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_APUT.S
@@ -0,0 +1,41 @@
+%default { "store":"str", "shift":"2" }
+%verify "executed"
+    /*
+     * Array put, 32 bits or less.  vBB[vCC] <- vAA.
+     *
+     * Note: using the usual FETCH/and/shift stuff, this fits in exactly 17
+     * instructions.  We use a pair of FETCH_Bs instead.
+     *
+     * for: aput, aput-boolean, aput-byte, aput-char, aput-short
+     */
+    /* op vAA, vBB, vCC */
+    FETCH_B(r2, 1, 0)                   @ r2<- BB
+    mov     r9, rINST, lsr #8           @ r9<- AA
+    FETCH_B(r3, 1, 1)                   @ r3<- CC
+    GET_VREG(r0, r2)                    @ r0<- vBB (array object)
+    GET_VREG(r1, r3)                    @ r1<- vCC (requested index)
+    cmp     r0, #0                      @ null array object?
+    beq     common_errNullObject        @ yes, bail
+    ldr     r3, [r0, #offArrayObject_length]    @ r3<- arrayObj->length
+    add     r0, r0, r1, lsl #$shift     @ r0<- arrayObj + index*width
+    cmp     r1, r3                      @ compare unsigned index, length
+    bcs     common_errArrayIndex        @ index >= length, bail
+// begin WITH_TAINT_TRACKING
+    bl	.L${opcode}_taint_prop
+// end WITH_TAINT_TRACKING
+    GET_VREG(r2, r9)                    @ r2<- vAA
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+    $store  r2, [r0, #offArrayObject_contents]  @ vBB[vCC]<- r2
+    GOTO_OPCODE(ip)                     @ jump to next instruction
+
+%break
+
+.L${opcode}_taint_prop:
+    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
+    GET_VREG(r1, r2)                    @ r1<- vBB (array object)
+    ldr     r2, [r1, #offArrayObject_taint]
+    SET_TAINT_FP(r3)
+    GET_VREG_TAINT(r3, r9, r3)
+    orr     r2, r2, r3                  @ r2<- r2 | r3
+    str     r2, [r1, #offArrayObject_taint]
+    bx      lr
diff --git a/vm/mterp/armv5te_taint/OP_APUT_BOOLEAN.S b/vm/mterp/armv5te_taint/OP_APUT_BOOLEAN.S
new file mode 100644
index 0000000..214709f
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_APUT_BOOLEAN.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te_taint/OP_APUT.S" { "store":"strb", "shift":"0" }
diff --git a/vm/mterp/armv5te_taint/OP_APUT_BYTE.S b/vm/mterp/armv5te_taint/OP_APUT_BYTE.S
new file mode 100644
index 0000000..214709f
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_APUT_BYTE.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te_taint/OP_APUT.S" { "store":"strb", "shift":"0" }
diff --git a/vm/mterp/armv5te_taint/OP_APUT_CHAR.S b/vm/mterp/armv5te_taint/OP_APUT_CHAR.S
new file mode 100644
index 0000000..256251a
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_APUT_CHAR.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te_taint/OP_APUT.S" { "store":"strh", "shift":"1" }
diff --git a/vm/mterp/armv5te_taint/OP_APUT_OBJECT.S b/vm/mterp/armv5te_taint/OP_APUT_OBJECT.S
new file mode 100644
index 0000000..daf8173
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_APUT_OBJECT.S
@@ -0,0 +1,75 @@
+%verify "executed"
+    /*
+     * Store an object into an array.  vBB[vCC] <- vAA.
+     */
+    /* op vAA, vBB, vCC */
+    FETCH(r0, 1)                        @ r0<- CCBB
+    mov     r9, rINST, lsr #8           @ r9<- AA
+    and     r2, r0, #255                @ r2<- BB
+    mov     r3, r0, lsr #8              @ r3<- CC
+    GET_VREG(rINST, r2)                 @ rINST<- vBB (array object)
+    GET_VREG(r1, r3)                    @ r1<- vCC (requested index)
+// begin WITH_TAINT_TRACKING
+    bl      .L${opcode}_taint_prop_1
+// end WITH_TAINT_TRACKING
+    cmp     rINST, #0                   @ null array object?
+    GET_VREG(r9, r9)                    @ r9<- vAA
+    beq     common_errNullObject        @ yes, bail
+// begin WITH_TAINT_TRACKING
+    bl      .L${opcode}_taint_prop_2
+// end WITH_TAINT_TRACKING
+    ldr     r3, [rINST, #offArrayObject_length]   @ r3<- arrayObj->length
+    add     r10, rINST, r1, lsl #2      @ r10<- arrayObj + index*width
+    cmp     r1, r3                      @ compare unsigned index, length
+    bcc     .L${opcode}_finish          @ we're okay, continue on
+    b       common_errArrayIndex        @ index >= length, bail
+
+%break
+    /*
+     * On entry:
+     *  rINST = vBB (arrayObj)
+     *  r9 = vAA (obj)
+     *  r10 = offset into array (vBB + vCC * width)
+     */
+.L${opcode}_finish:
+// begin WITH_TAINT_TRACKING
+    str     r2, [rINST, #offArrayObject_taint]
+// end WITH_TAINT_TRACKING
+    cmp     r9, #0                      @ storing null reference?
+    beq     .L${opcode}_skip_check      @ yes, skip type checks
+    ldr     r0, [r9, #offObject_clazz]  @ r0<- obj->clazz
+    ldr     r1, [rINST, #offObject_clazz]  @ r1<- arrayObj->clazz
+    bl      dvmCanPutArrayElement       @ test object type vs. array type
+    cmp     r0, #0                      @ okay?
+    beq     .L${opcode}_throw           @ no
+    mov     r1, rINST                   @ r1<- arrayObj
+    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
+    ldr     r2, [rSELF, #offThread_cardTable]     @ get biased CT base
+    add     r10, #offArrayObject_contents   @ r0<- pointer to slot
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+    str     r9, [r10]                   @ vBB[vCC]<- vAA
+    strb    r2, [r2, r1, lsr #GC_CARD_SHIFT] @ mark card using object head
+    GOTO_OPCODE(ip)                     @ jump to next instruction
+.L${opcode}_skip_check:
+    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+    str     r9, [r10, #offArrayObject_contents] @ vBB[vCC]<- vAA
+    GOTO_OPCODE(ip)                     @ jump to next instruction
+.L${opcode}_throw:
+    @ The types don't match.  We need to throw an ArrayStoreException.
+    ldr     r0, [r9, #offObject_clazz]
+    ldr     r1, [rINST, #offObject_clazz]
+    EXPORT_PC()
+    bl      dvmThrowArrayStoreExceptionIncompatibleElement
+    b       common_exceptionThrown
+
+.L${opcode}_taint_prop_1:
+    SET_TAINT_FP(r3)
+    GET_VREG_TAINT(r2, r9, r3)
+    bx      lr
+
+.L${opcode}_taint_prop_2:
+    ldr     r3, [rINST, #offArrayObject_taint]
+    orr     r2, r2, r3                  @ r2<- r2 | r3
+    bx      lr
+
diff --git a/vm/mterp/armv5te_taint/OP_APUT_SHORT.S b/vm/mterp/armv5te_taint/OP_APUT_SHORT.S
new file mode 100644
index 0000000..256251a
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_APUT_SHORT.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te_taint/OP_APUT.S" { "store":"strh", "shift":"1" }
diff --git a/vm/mterp/armv5te_taint/OP_APUT_WIDE.S b/vm/mterp/armv5te_taint/OP_APUT_WIDE.S
new file mode 100644
index 0000000..533a8b9
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_APUT_WIDE.S
@@ -0,0 +1,48 @@
+%verify "executed"
+    /*
+     * Array put, 64 bits.  vBB[vCC] <- vAA.
+     *
+     * Arrays of long/double are 64-bit aligned, so it's okay to use STRD.
+     */
+    /* aput-wide vAA, vBB, vCC */
+    FETCH(r0, 1)                        @ r0<- CCBB
+    mov     r9, rINST, lsr #8           @ r9<- AA
+    and     r2, r0, #255                @ r2<- BB
+    mov     r3, r0, lsr #8              @ r3<- CC
+    GET_VREG(r0, r2)                    @ r0<- vBB (array object)
+    GET_VREG(r1, r3)                    @ r1<- vCC (requested index)
+    cmp     r0, #0                      @ null array object?
+    beq     common_errNullObject        @ yes, bail
+    ldr     r3, [r0, #offArrayObject_length]    @ r3<- arrayObj->length
+// begin WITH_TAINT_TRACKING
+    mov     r10, r0
+// end WITH_TAINT_TRACKING
+    add     r0, r0, r1, lsl #3          @ r0<- arrayObj + index*width
+    cmp     r1, r3                      @ compare unsigned index, length
+// begin WITH_TAINT_TRACKING
+    add     r9, rFP, r9, lsl #3         @ r9<- &fp[AA]
+// end WITH_TAINT_TRACKING
+    bcc     .L${opcode}_finish          @ okay, continue below
+    b       common_errArrayIndex        @ index >= length, bail
+    @ May want to swap the order of these two branches depending on how the
+    @ branch prediction (if any) handles conditional forward branches vs.
+    @ unconditional forward branches.
+%break
+
+.L${opcode}_finish:
+    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
+// begin WITH_TAINT_TRACKING
+//    ldmia   r9, {r2-r3}                 @ r2/r3<- vAA/vAA+1
+    ldr     r2, [r9, #0]
+    ldr     r3, [r9, #8]
+    ldr     r1, [r9, #4]                      @ r1<- array taint
+    ldr     r9, [r10, #offArrayObject_taint]
+    orr     r1, r1, r9                        @ r1<- r1 | r9
+    str     r1, [r10, #offArrayObject_taint]
+// end WITH_TAINT_TRACKING
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+// begin WITH_TAINT_TRACKING
+    strd    r2, [r0, #offArrayObject_contents]  @ r2/r3<- vBB[vCC]
+// end WITH_TAINT_TRACKING
+    GOTO_OPCODE(ip)                     @ jump to next instruction
+
diff --git a/vm/mterp/armv5te_taint/OP_ARRAY_LENGTH.S b/vm/mterp/armv5te_taint/OP_ARRAY_LENGTH.S
new file mode 100644
index 0000000..3257945
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_ARRAY_LENGTH.S
@@ -0,0 +1,21 @@
+%verify "executed"
+    /*
+     * Return the length of an array.
+     */
+    mov     r1, rINST, lsr #12          @ r1<- B
+    mov     r2, rINST, lsr #8           @ r2<- A+
+    GET_VREG(r0, r1)                    @ r0<- vB (object ref)
+    and     r2, r2, #15                 @ r2<- A
+    cmp     r0, #0                      @ is object null?
+    beq     common_errNullObject        @ yup, fail
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r1)
+    SET_TAINT_CLEAR(r3)
+    SET_VREG_TAINT(r3, r2, r1)
+// end WITH_TAINT_TRACKING
+    FETCH_ADVANCE_INST(1)               @ advance rPC, load rINST
+    ldr     r3, [r0, #offArrayObject_length]    @ r3<- array length
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+    SET_VREG(r3, r2)                    @ vB<- length
+    GOTO_OPCODE(ip)                     @ jump to next instruction
+
diff --git a/vm/mterp/armv5te_taint/OP_BREAKPOINT.S b/vm/mterp/armv5te_taint/OP_BREAKPOINT.S
new file mode 100644
index 0000000..b4ea333
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_BREAKPOINT.S
@@ -0,0 +1,15 @@
+%verify "executed"
+    /*
+     * Breakpoint handler.
+     *
+     * Restart this instruction with the original opcode.  By
+     * the time we get here, the breakpoint will have already been
+     * handled.
+     */
+    mov     r0, rPC
+    bl      dvmGetOriginalOpcode        @ (rPC)
+    FETCH(rINST, 0)                     @ reload OP_BREAKPOINT + rest of inst
+    ldr     r1, [rSELF, #offThread_mainHandlerTable]
+    and     rINST, #0xff00
+    orr     rINST, rINST, r0
+    GOTO_OPCODE_BASE(r1, r0)
diff --git a/vm/mterp/armv5te_taint/OP_CHECK_CAST.S b/vm/mterp/armv5te_taint/OP_CHECK_CAST.S
new file mode 100644
index 0000000..57df60e
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_CHECK_CAST.S
@@ -0,0 +1,68 @@
+%verify "executed"
+%verify "null object"
+%verify "class cast exception thrown, with correct class name"
+%verify "class cast exception not thrown on same class"
+%verify "class cast exception not thrown on subclass"
+%verify "class not resolved"
+%verify "class already resolved"
+    /*
+     * Check to see if a cast from one class to another is allowed.
+     */
+    /* check-cast vAA, class@BBBB */
+    mov     r3, rINST, lsr #8           @ r3<- AA
+    FETCH(r2, 1)                        @ r2<- BBBB
+    GET_VREG(r9, r3)                    @ r9<- object
+    ldr     r0, [rSELF, #offThread_methodClassDex]    @ r0<- pDvmDex
+    cmp     r9, #0                      @ is object null?
+    ldr     r0, [r0, #offDvmDex_pResClasses]    @ r0<- pDvmDex->pResClasses
+    beq     .L${opcode}_okay            @ null obj, cast always succeeds
+    ldr     r1, [r0, r2, lsl #2]        @ r1<- resolved class
+    ldr     r0, [r9, #offObject_clazz]  @ r0<- obj->clazz
+    cmp     r1, #0                      @ have we resolved this before?
+    beq     .L${opcode}_resolve         @ not resolved, do it now
+.L${opcode}_resolved:
+    cmp     r0, r1                      @ same class (trivial success)?
+    bne     .L${opcode}_fullcheck       @ no, do full check
+.L${opcode}_okay:
+    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+    GOTO_OPCODE(ip)                     @ jump to next instruction
+%break
+
+    /*
+     * Trivial test failed, need to perform full check.  This is common.
+     *  r0 holds obj->clazz
+     *  r1 holds desired class resolved from BBBB
+     *  r9 holds object
+     */
+.L${opcode}_fullcheck:
+    mov     r10, r1                     @ avoid ClassObject getting clobbered
+    bl      dvmInstanceofNonTrivial     @ r0<- boolean result
+    cmp     r0, #0                      @ failed?
+    bne     .L${opcode}_okay            @ no, success
+
+    @ A cast has failed.  We need to throw a ClassCastException.
+    EXPORT_PC()                         @ about to throw
+    ldr     r0, [r9, #offObject_clazz]  @ r0<- obj->clazz (actual class)
+    mov     r1, r10                     @ r1<- desired class
+    bl      dvmThrowClassCastException
+    b       common_exceptionThrown
+
+    /*
+     * Resolution required.  This is the least-likely path.
+     *
+     *  r2 holds BBBB
+     *  r9 holds object
+     */
+.L${opcode}_resolve:
+    EXPORT_PC()                         @ resolve() could throw
+    ldr     r3, [rSELF, #offThread_method] @ r3<- self->method
+    mov     r1, r2                      @ r1<- BBBB
+    mov     r2, #0                      @ r2<- false
+    ldr     r0, [r3, #offMethod_clazz]  @ r0<- method->clazz
+    bl      dvmResolveClass             @ r0<- resolved ClassObject ptr
+    cmp     r0, #0                      @ got null?
+    beq     common_exceptionThrown      @ yes, handle exception
+    mov     r1, r0                      @ r1<- class resolved from BBB
+    ldr     r0, [r9, #offObject_clazz]  @ r0<- obj->clazz
+    b       .L${opcode}_resolved        @ pick up where we left off
diff --git a/vm/mterp/armv5te_taint/OP_CMPG_DOUBLE.S b/vm/mterp/armv5te_taint/OP_CMPG_DOUBLE.S
new file mode 100644
index 0000000..e338f66
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_CMPG_DOUBLE.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te_taint/OP_CMPL_DOUBLE.S" { "naninst":"mov     r1, #1" }
diff --git a/vm/mterp/armv5te_taint/OP_CMPG_FLOAT.S b/vm/mterp/armv5te_taint/OP_CMPG_FLOAT.S
new file mode 100644
index 0000000..fd1ab1c
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_CMPG_FLOAT.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te_taint/OP_CMPL_FLOAT.S" { "naninst":"mov     r1, #1" }
diff --git a/vm/mterp/armv5te_taint/OP_CMP_LONG.S b/vm/mterp/armv5te_taint/OP_CMP_LONG.S
new file mode 100644
index 0000000..4e0216d
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_CMP_LONG.S
@@ -0,0 +1,80 @@
+%verify "executed"
+%verify "basic lt, gt, eq"
+%verify "hi equal, lo <=>"
+%verify "lo equal, hi <=>"
+    /*
+     * Compare two 64-bit values.  Puts 0, 1, or -1 into the destination
+     * register based on the results of the comparison.
+     *
+     * We load the full values with LDM, but in practice many values could
+     * be resolved by only looking at the high word.  This could be made
+     * faster or slower by splitting the LDM into a pair of LDRs.
+     *
+     * If we just wanted to set condition flags, we could do this:
+     *  subs    ip, r0, r2
+     *  sbcs    ip, r1, r3
+     *  subeqs  ip, r0, r2
+     * Leaving { <0, 0, >0 } in ip.  However, we have to set it to a specific
+     * integer value, which we can do with 2 conditional mov/mvn instructions
+     * (set 1, set -1; if they're equal we already have 0 in ip), giving
+     * us a constant 5-cycle path plus a branch at the end to the
+     * instruction epilogue code.  The multi-compare approach below needs
+     * 2 or 3 cycles + branch if the high word doesn't match, 6 + branch
+     * in the worst case (the 64-bit values are equal).
+     */
+    /* cmp-long vAA, vBB, vCC */
+    FETCH(r0, 1)                        @ r0<- CCBB
+    mov     r9, rINST, lsr #8           @ r9<- AA
+    and     r2, r0, #255                @ r2<- BB
+    mov     r3, r0, lsr #8              @ r3<- CC
+// begin WITH_TAINT_TRACKING
+    bl      cmp_long_taint_prop
+// end WITH_TAINT_TRACKING
+    cmp     r1, r3                      @ compare (vBB+1, vCC+1)
+    blt     .L${opcode}_less            @ signed compare on high part
+    bgt     .L${opcode}_greater
+    subs    r1, r0, r2                  @ r1<- r0 - r2
+    bhi     .L${opcode}_greater         @ unsigned compare on low part
+    bne     .L${opcode}_less
+    b       .L${opcode}_finish          @ equal; r1 already holds 0
+%break
+
+.L${opcode}_less:
+    mvn     r1, #0                      @ r1<- -1
+    @ Want to cond code the next mov so we can avoid branch, but don't see it;
+    @ instead, we just replicate the tail end.
+    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
+    SET_VREG(r1, r9)                    @ vAA<- r1
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r0)
+    SET_TAINT_CLEAR(r1)
+    SET_VREG_TAINT(r1, r9, r0)
+// end WITH_TAINT_TRACKING
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+    GOTO_OPCODE(ip)                     @ jump to next instruction
+
+.L${opcode}_greater:
+    mov     r1, #1                      @ r1<- 1
+    @ fall through to _finish
+
+.L${opcode}_finish:
+    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
+    SET_VREG(r1, r9)                    @ vAA<- r1
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r0)
+    SET_TAINT_CLEAR(r1)
+    SET_VREG_TAINT(r1, r9, r0)
+// end WITH_TAINT_TRACKING
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+    GOTO_OPCODE(ip)                     @ jump to next instruction
+
+cmp_long_taint_prop:
+    add     r2, rFP, r2, lsl #3         @ r2<- &fp[BB]
+    add     r3, rFP, r3, lsl #3         @ r3<- &fp[CC]
+//    ldmia   r2, {r0-r1}                 @ r0/r1<- vBB/vBB+1
+    ldr     r0, [r2, #0]
+    ldr     r1, [r2, #8]
+//    ldmia   r3, {r2-r3}                 @ r2/r3<- vCC/vCC+1
+    ldr     r2, [r3, #0]
+    ldr     r3, [r3, #8]
+    bx      lr
diff --git a/vm/mterp/armv5te_taint/OP_CONST.S b/vm/mterp/armv5te_taint/OP_CONST.S
new file mode 100644
index 0000000..a184461
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_CONST.S
@@ -0,0 +1,16 @@
+%verify "executed"
+    /* const vAA, #+BBBBbbbb */
+    mov     r3, rINST, lsr #8           @ r3<- AA
+    FETCH(r0, 1)                        @ r0<- bbbb (low)
+    FETCH(r1, 2)                        @ r1<- BBBB (high)
+    FETCH_ADVANCE_INST(3)               @ advance rPC, load rINST
+    orr     r0, r0, r1, lsl #16         @ r0<- BBBBbbbb
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r2)
+    SET_TAINT_CLEAR(r1)
+    SET_VREG_TAINT(r1, r3, r2)
+// end WITH_TAINT_TRACKING
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+    SET_VREG(r0, r3)                    @ vAA<- r0
+    GOTO_OPCODE(ip)                     @ jump to next instruction
+
diff --git a/vm/mterp/armv5te_taint/OP_CONST_16.S b/vm/mterp/armv5te_taint/OP_CONST_16.S
new file mode 100644
index 0000000..614d602
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_CONST_16.S
@@ -0,0 +1,14 @@
+%verify "executed"
+    /* const/16 vAA, #+BBBB */
+    FETCH_S(r0, 1)                      @ r0<- ssssBBBB (sign-extended)
+    mov     r3, rINST, lsr #8           @ r3<- AA
+// BEGIN WITH_TAINT_TRACKING
+	SET_TAINT_FP(r1)
+	SET_TAINT_CLEAR(r2)
+    SET_VREG_TAINT(r2, r3, r1)
+// END WITH_TAINT_TRACKING
+    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
+    SET_VREG(r0, r3)                    @ vAA<- r0
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+    GOTO_OPCODE(ip)                     @ jump to next instruction
+
diff --git a/vm/mterp/armv5te_taint/OP_CONST_4.S b/vm/mterp/armv5te_taint/OP_CONST_4.S
new file mode 100644
index 0000000..cde885c
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_CONST_4.S
@@ -0,0 +1,16 @@
+%verify "executed"
+    /* const/4 vA, #+B */
+    mov     r1, rINST, lsl #16          @ r1<- Bxxx0000
+    mov     r0, rINST, lsr #8           @ r0<- A+
+    FETCH_ADVANCE_INST(1)               @ advance rPC, load rINST
+    mov     r1, r1, asr #28             @ r1<- sssssssB (sign-extended)
+    and     r0, r0, #15
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r2)
+    SET_TAINT_CLEAR(r3)
+    SET_VREG_TAINT(r3, r0, r2)
+// end WITH_TAINT_TRACKING
+    GET_INST_OPCODE(ip)                 @ ip<- opcode from rINST
+    SET_VREG(r1, r0)                    @ fp[A]<- r1
+    GOTO_OPCODE(ip)                     @ execute next instruction
+
diff --git a/vm/mterp/armv5te_taint/OP_CONST_CLASS.S b/vm/mterp/armv5te_taint/OP_CONST_CLASS.S
new file mode 100644
index 0000000..c404831
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_CONST_CLASS.S
@@ -0,0 +1,45 @@
+%verify "executed"
+%verify "Class already resolved"
+%verify "Class not yet resolved"
+%verify "Class cannot be resolved"
+    /* const/class vAA, Class@BBBB */
+    FETCH(r1, 1)                        @ r1<- BBBB
+    ldr     r2, [rSELF, #offThread_methodClassDex]  @ r2<- self->methodClassDex
+    mov     r9, rINST, lsr #8           @ r9<- AA
+    ldr     r2, [r2, #offDvmDex_pResClasses]   @ r2<- dvmDex->pResClasses
+    ldr     r0, [r2, r1, lsl #2]        @ r0<- pResClasses[BBBB]
+    cmp     r0, #0                      @ not yet resolved?
+    beq     .L${opcode}_resolve
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r2)
+    SET_TAINT_CLEAR(r3)
+    SET_VREG_TAINT(r3, r9, r2)
+// end WITH_TAINT_TRACKING
+    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+    SET_VREG(r0, r9)                    @ vAA<- r0
+    GOTO_OPCODE(ip)                     @ jump to next instruction
+%break
+
+    /*
+     * Continuation if the Class has not yet been resolved.
+     *  r1: BBBB (Class ref)
+     *  r9: target register
+     */
+.L${opcode}_resolve:
+    EXPORT_PC()
+    ldr     r0, [rSELF, #offThread_method] @ r0<- self->method
+    mov     r2, #1                      @ r2<- true
+    ldr     r0, [r0, #offMethod_clazz]  @ r0<- method->clazz
+    bl      dvmResolveClass             @ r0<- Class reference
+    cmp     r0, #0                      @ failed?
+    beq     common_exceptionThrown      @ yup, handle the exception
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r2)
+    SET_TAINT_CLEAR(r3)
+    SET_VREG_TAINT(r3, r9, r2)
+// end WITH_TAINT_TRACKING
+    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+    SET_VREG(r0, r9)                    @ vAA<- r0
+    GOTO_OPCODE(ip)                     @ jump to next instruction
diff --git a/vm/mterp/armv5te_taint/OP_CONST_HIGH16.S b/vm/mterp/armv5te_taint/OP_CONST_HIGH16.S
new file mode 100644
index 0000000..3c291ec
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_CONST_HIGH16.S
@@ -0,0 +1,15 @@
+%verify "executed"
+    /* const/high16 vAA, #+BBBB0000 */
+    FETCH(r0, 1)                        @ r0<- 0000BBBB (zero-extended)
+    mov     r3, rINST, lsr #8           @ r3<- AA
+    mov     r0, r0, lsl #16             @ r0<- BBBB0000
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r2)
+    SET_TAINT_CLEAR(r1)
+    SET_VREG_TAINT(r1, r3, r2)
+// end WITH_TAINT_TRACKING
+    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
+    SET_VREG(r0, r3)                    @ vAA<- r0
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+    GOTO_OPCODE(ip)                     @ jump to next instruction
+
diff --git a/vm/mterp/armv5te_taint/OP_CONST_STRING.S b/vm/mterp/armv5te_taint/OP_CONST_STRING.S
new file mode 100644
index 0000000..2d3a42e
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_CONST_STRING.S
@@ -0,0 +1,44 @@
+%verify "executed"
+%verify "String already resolved"
+%verify "String not yet resolved"
+%verify "String cannot be resolved"
+    /* const/string vAA, String@BBBB */
+    FETCH(r1, 1)                        @ r1<- BBBB
+    ldr     r2, [rSELF, #offThread_methodClassDex]  @ r2<- self->methodClassDex
+    mov     r9, rINST, lsr #8           @ r9<- AA
+    ldr     r2, [r2, #offDvmDex_pResStrings]   @ r2<- dvmDex->pResStrings
+    ldr     r0, [r2, r1, lsl #2]        @ r0<- pResStrings[BBBB]
+    cmp     r0, #0                      @ not yet resolved?
+    beq     .L${opcode}_resolve
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r2)
+    SET_TAINT_CLEAR(r3)
+    SET_VREG_TAINT(r3, r9, r2)
+// end WITH_TAINT_TRACKING
+    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+    SET_VREG(r0, r9)                    @ vAA<- r0
+    GOTO_OPCODE(ip)                     @ jump to next instruction
+%break
+
+    /*
+     * Continuation if the String has not yet been resolved.
+     *  r1: BBBB (String ref)
+     *  r9: target register
+     */
+.L${opcode}_resolve:
+    EXPORT_PC()
+    ldr     r0, [rSELF, #offThread_method] @ r0<- self->method
+    ldr     r0, [r0, #offMethod_clazz]  @ r0<- method->clazz
+    bl      dvmResolveString            @ r0<- String reference
+    cmp     r0, #0                      @ failed?
+    beq     common_exceptionThrown      @ yup, handle the exception
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r2)
+    SET_TAINT_CLEAR(r3)
+    SET_VREG_TAINT(r3, r9, r2)
+// end WITH_TAINT_TRACKING
+    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+    SET_VREG(r0, r9)                    @ vAA<- r0
+    GOTO_OPCODE(ip)                     @ jump to next instruction
diff --git a/vm/mterp/armv5te_taint/OP_CONST_STRING_JUMBO.S b/vm/mterp/armv5te_taint/OP_CONST_STRING_JUMBO.S
new file mode 100644
index 0000000..70f9bb2
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_CONST_STRING_JUMBO.S
@@ -0,0 +1,46 @@
+%verify "executed"
+%verify "String already resolved"
+%verify "String not yet resolved"
+%verify "String cannot be resolved"
+    /* const/string vAA, String@BBBBBBBB */
+    FETCH(r0, 1)                        @ r0<- bbbb (low)
+    FETCH(r1, 2)                        @ r1<- BBBB (high)
+    ldr     r2, [rSELF, #offThread_methodClassDex]  @ r2<- self->methodClassDex
+    mov     r9, rINST, lsr #8           @ r9<- AA
+    ldr     r2, [r2, #offDvmDex_pResStrings]   @ r2<- dvmDex->pResStrings
+    orr     r1, r0, r1, lsl #16         @ r1<- BBBBbbbb
+    ldr     r0, [r2, r1, lsl #2]        @ r0<- pResStrings[BBBB]
+    cmp     r0, #0
+    beq     .L${opcode}_resolve
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r2)
+    SET_TAINT_CLEAR(r3)
+    SET_VREG_TAINT(r3, r9, r2)
+// end WITH_TAINT_TRACKING
+    FETCH_ADVANCE_INST(3)               @ advance rPC, load rINST
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+    SET_VREG(r0, r9)                    @ vAA<- r0
+    GOTO_OPCODE(ip)                     @ jump to next instruction
+%break
+
+    /*
+     * Continuation if the String has not yet been resolved.
+     *  r1: BBBBBBBB (String ref)
+     *  r9: target register
+     */
+.L${opcode}_resolve:
+    EXPORT_PC()
+    ldr     r0, [rSELF, #offThread_method] @ r0<- self->method
+    ldr     r0, [r0, #offMethod_clazz]  @ r0<- method->clazz
+    bl      dvmResolveString            @ r0<- String reference
+    cmp     r0, #0                      @ failed?
+    beq     common_exceptionThrown      @ yup, handle the exception
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r2)
+    SET_TAINT_CLEAR(r3)
+    SET_VREG_TAINT(r3, r9, r2)
+// end WITH_TAINT_TRACKING
+    FETCH_ADVANCE_INST(3)               @ advance rPC, load rINST
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+    SET_VREG(r0, r9)                    @ vAA<- r0
+    GOTO_OPCODE(ip)                     @ jump to next instruction
diff --git a/vm/mterp/armv5te_taint/OP_CONST_WIDE.S b/vm/mterp/armv5te_taint/OP_CONST_WIDE.S
new file mode 100644
index 0000000..0789bef
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_CONST_WIDE.S
@@ -0,0 +1,23 @@
+%verify "executed"
+    /* const-wide vAA, #+HHHHhhhhBBBBbbbb */
+    FETCH(r0, 1)                        @ r0<- bbbb (low)
+    FETCH(r1, 2)                        @ r1<- BBBB (low middle)
+    FETCH(r2, 3)                        @ r2<- hhhh (high middle)
+    orr     r0, r0, r1, lsl #16         @ r0<- BBBBbbbb (low word)
+    FETCH(r3, 4)                        @ r3<- HHHH (high)
+    mov     r9, rINST, lsr #8           @ r9<- AA
+// begin WITH_TAINT_TRACKING
+    orr     r2, r2, r3, lsl #16         @ r2<- HHHHhhhh (high word)
+// end WITH_TAINT_TRACKING
+    FETCH_ADVANCE_INST(5)               @ advance rPC, load rINST
+// begin WITH_TAINT_TRACKING
+    add     r9, rFP, r9, lsl #3         @ r9<- &fp[AA]
+// end WITH_TAINT_TRACKING
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_CLEAR(r1)
+    SET_TAINT_CLEAR(r3)
+    stmia   r9, {r0-r3}                 @ vAA<- r0/r1
+// end WITH_TAINT_TRACKING
+    GOTO_OPCODE(ip)                     @ jump to next instruction
+
diff --git a/vm/mterp/armv5te_taint/OP_CONST_WIDE_16.S b/vm/mterp/armv5te_taint/OP_CONST_WIDE_16.S
new file mode 100644
index 0000000..b3654b0
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_CONST_WIDE_16.S
@@ -0,0 +1,19 @@
+%verify "executed"
+    /* const-wide/16 vAA, #+BBBB */
+    FETCH_S(r0, 1)                      @ r0<- ssssBBBB (sign-extended)
+    mov     r3, rINST, lsr #8           @ r3<- AA
+// begin WITH_TAINT_TRACKING
+    mov     r2, r0, asr #31             @ r1<- ssssssss
+// end WITH_TAINT_TRACKING
+    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
+// begin WITH_TAINT_TRACKING
+    add     r9, rFP, r3, lsl #3         @ r3<- &fp[AA]
+// end WITH_TAINT_TRACKING
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_CLEAR(r1)
+    SET_TAINT_CLEAR(r3)
+    stmia   r9, {r0-r3}                 @ vAA<- r0/r1
+// end WITH_TAINT_TRACKING
+    GOTO_OPCODE(ip)                     @ jump to next instruction
+
diff --git a/vm/mterp/armv5te_taint/OP_CONST_WIDE_32.S b/vm/mterp/armv5te_taint/OP_CONST_WIDE_32.S
new file mode 100644
index 0000000..31c9d35
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_CONST_WIDE_32.S
@@ -0,0 +1,19 @@
+%verify "executed"
+    /* const-wide/32 vAA, #+BBBBbbbb */
+    FETCH(r0, 1)                        @ r0<- 0000bbbb (low)
+    mov     r3, rINST, lsr #8           @ r3<- AA
+    FETCH_S(r2, 2)                      @ r2<- ssssBBBB (high)
+    FETCH_ADVANCE_INST(3)               @ advance rPC, load rINST
+    orr     r0, r0, r2, lsl #16         @ r0<- BBBBbbbb
+// begin WITH_TAINT_TRACKING
+    add     r9, rFP, r3, lsl #3         @ r9<- &fp[AA]
+    mov     r2, r0, asr #31             @ r2<- ssssssss
+// end WITH_TAINT_TRACKING
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_CLEAR(r1)
+    SET_TAINT_CLEAR(r3)
+    stmia   r9, {r0-r3}                 @ vAA<- r0/r1
+// end WITH_TAINT_TRACKING
+    GOTO_OPCODE(ip)                     @ jump to next instruction
+
diff --git a/vm/mterp/armv5te_taint/OP_CONST_WIDE_HIGH16.S b/vm/mterp/armv5te_taint/OP_CONST_WIDE_HIGH16.S
new file mode 100644
index 0000000..b6050c3
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_CONST_WIDE_HIGH16.S
@@ -0,0 +1,20 @@
+%verify "executed"
+    /* const-wide/high16 vAA, #+BBBB000000000000 */
+    FETCH(r1, 1)                        @ r1<- 0000BBBB (zero-extended)
+    mov     r3, rINST, lsr #8           @ r3<- AA
+    mov     r0, #0                      @ r0<- 00000000
+// begin WITH_TAINT_TRACKING
+    mov     r2, r1, lsl #16             @ r1<- BBBB0000
+// end WITH_TAINT_TRACKING
+    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
+// begin WITH_TAINT_TRACKING
+    add     r9, rFP, r3, lsl #3         @ r3<- &fp[AA]
+// end WITH_TAINT_TRACKING
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_CLEAR(r1)
+    SET_TAINT_CLEAR(r3)
+    stmia   r9, {r0-r3}                 @ vAA<- r0/r1
+// end WITH_TAINT_TRACKING
+    GOTO_OPCODE(ip)                     @ jump to next instruction
+
diff --git a/vm/mterp/armv5te_taint/OP_DIV_DOUBLE.S b/vm/mterp/armv5te_taint/OP_DIV_DOUBLE.S
new file mode 100644
index 0000000..6b73f1d
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_DIV_DOUBLE.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te_taint/binopWide.S" {"instr":"bl      __aeabi_ddiv"}
diff --git a/vm/mterp/armv5te_taint/OP_DIV_DOUBLE_2ADDR.S b/vm/mterp/armv5te_taint/OP_DIV_DOUBLE_2ADDR.S
new file mode 100644
index 0000000..f96da56
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_DIV_DOUBLE_2ADDR.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te_taint/binopWide2addr.S" {"instr":"bl      __aeabi_ddiv"}
diff --git a/vm/mterp/armv5te_taint/OP_DIV_FLOAT.S b/vm/mterp/armv5te_taint/OP_DIV_FLOAT.S
new file mode 100644
index 0000000..f660396
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_DIV_FLOAT.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te_taint/binop.S" {"instr":"bl      __aeabi_fdiv"}
diff --git a/vm/mterp/armv5te_taint/OP_DIV_FLOAT_2ADDR.S b/vm/mterp/armv5te_taint/OP_DIV_FLOAT_2ADDR.S
new file mode 100644
index 0000000..c4df66d
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_DIV_FLOAT_2ADDR.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te_taint/binop2addr.S" {"instr":"bl      __aeabi_fdiv"}
diff --git a/vm/mterp/armv5te_taint/OP_DIV_INT.S b/vm/mterp/armv5te_taint/OP_DIV_INT.S
new file mode 100644
index 0000000..41b6da8
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_DIV_INT.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te_taint/binop.S" {"instr":"bl     __aeabi_idiv","chkzero":"1"}
diff --git a/vm/mterp/armv5te_taint/OP_DIV_INT_2ADDR.S b/vm/mterp/armv5te_taint/OP_DIV_INT_2ADDR.S
new file mode 100644
index 0000000..af93c07
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_DIV_INT_2ADDR.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te_taint/binop2addr.S" {"instr":"bl     __aeabi_idiv","chkzero":"1"}
diff --git a/vm/mterp/armv5te_taint/OP_DIV_INT_LIT16.S b/vm/mterp/armv5te_taint/OP_DIV_INT_LIT16.S
new file mode 100644
index 0000000..25b893a
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_DIV_INT_LIT16.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te_taint/binopLit16.S" {"instr":"bl     __aeabi_idiv","chkzero":"1"}
diff --git a/vm/mterp/armv5te_taint/OP_DIV_INT_LIT8.S b/vm/mterp/armv5te_taint/OP_DIV_INT_LIT8.S
new file mode 100644
index 0000000..ebe283c
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_DIV_INT_LIT8.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te_taint/binopLit8.S" {"instr":"bl     __aeabi_idiv","chkzero":"1"}
diff --git a/vm/mterp/armv5te_taint/OP_DIV_LONG.S b/vm/mterp/armv5te_taint/OP_DIV_LONG.S
new file mode 100644
index 0000000..73f4ee8
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_DIV_LONG.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te_taint/binopWide.S" {"instr":"bl      __aeabi_ldivmod", "chkzero":"1"}
diff --git a/vm/mterp/armv5te_taint/OP_DIV_LONG_2ADDR.S b/vm/mterp/armv5te_taint/OP_DIV_LONG_2ADDR.S
new file mode 100644
index 0000000..76b22bc
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_DIV_LONG_2ADDR.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te_taint/binopWide2addr.S" {"instr":"bl      __aeabi_ldivmod", "chkzero":"1"}
diff --git a/vm/mterp/armv5te_taint/OP_DOUBLE_TO_FLOAT.S b/vm/mterp/armv5te_taint/OP_DOUBLE_TO_FLOAT.S
new file mode 100644
index 0000000..d121244
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_DOUBLE_TO_FLOAT.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te_taint/unopNarrower.S" {"instr":"bl      __aeabi_d2f"}
diff --git a/vm/mterp/armv5te_taint/OP_DOUBLE_TO_INT.S b/vm/mterp/armv5te_taint/OP_DOUBLE_TO_INT.S
new file mode 100644
index 0000000..2b7d3a7
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_DOUBLE_TO_INT.S
@@ -0,0 +1,55 @@
+%verify "executed"
+/* EABI appears to have Java-style conversions of +inf/-inf/NaN */
+%include "armv5te_taint/unopNarrower.S" {"instr":"bl      __aeabi_d2iz"}
+
+#if 0
+@include "armv5te_taint/unopNarrower.S" {"instr":"bl      d2i_doconv"}
+@break
+/*
+ * Convert the double in r0/r1 to an int in r0.
+ *
+ * We have to clip values to int min/max per the specification.  The
+ * expected common case is a "reasonable" value that converts directly
+ * to modest integer.  The EABI convert function isn't doing this for us.
+ */
+d2i_doconv:
+    stmfd   sp!, {r4, r5, lr}           @ save regs
+    mov     r2, #0x80000000             @ maxint, as a double (low word)
+    mov     r2, r2, asr #9              @  0xffc00000
+    sub     sp, sp, #4                  @ align for EABI
+    mvn     r3, #0xbe000000             @ maxint, as a double (high word)
+    sub     r3, r3, #0x00200000         @  0x41dfffff
+    mov     r4, r0                      @ save a copy of r0
+    mov     r5, r1                      @  and r1
+    bl      __aeabi_dcmpge              @ is arg >= maxint?
+    cmp     r0, #0                      @ nonzero == yes
+    mvnne   r0, #0x80000000             @ return maxint (0x7fffffff)
+    bne     1f
+
+    mov     r0, r4                      @ recover arg
+    mov     r1, r5
+    mov     r3, #0xc1000000             @ minint, as a double (high word)
+    add     r3, r3, #0x00e00000         @  0xc1e00000
+    mov     r2, #0                      @ minint, as a double (low word)
+    bl      __aeabi_dcmple              @ is arg <= minint?
+    cmp     r0, #0                      @ nonzero == yes
+    movne   r0, #0x80000000             @ return minint (80000000)
+    bne     1f
+
+    mov     r0, r4                      @ recover arg
+    mov     r1, r5
+    mov     r2, r4                      @ compare against self
+    mov     r3, r5
+    bl      __aeabi_dcmpeq              @ is arg == self?
+    cmp     r0, #0                      @ zero == no
+    beq     1f                          @ return zero for NaN
+
+    mov     r0, r4                      @ recover arg
+    mov     r1, r5
+    bl      __aeabi_d2iz                @ convert double to int
+
+1:
+    add     sp, sp, #4
+    ldmfd   sp!, {r4, r5, pc}
+#endif
+
diff --git a/vm/mterp/armv5te_taint/OP_DOUBLE_TO_LONG.S b/vm/mterp/armv5te_taint/OP_DOUBLE_TO_LONG.S
new file mode 100644
index 0000000..1ed11ee
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_DOUBLE_TO_LONG.S
@@ -0,0 +1,54 @@
+%verify "executed"
+@include "armv5te_taint/unopWide.S" {"instr":"bl      __aeabi_d2lz"}
+%include "armv5te_taint/unopWide.S" {"instr":"bl      d2l_doconv"}
+
+%break
+/*
+ * Convert the double in r0/r1 to a long in r0/r1.
+ *
+ * We have to clip values to long min/max per the specification.  The
+ * expected common case is a "reasonable" value that converts directly
+ * to modest integer.  The EABI convert function isn't doing this for us.
+ */
+d2l_doconv:
+    stmfd   sp!, {r4, r5, lr}           @ save regs
+    mov     r3, #0x43000000             @ maxlong, as a double (high word)
+    add     r3, #0x00e00000             @  0x43e00000
+    mov     r2, #0                      @ maxlong, as a double (low word)
+    sub     sp, sp, #4                  @ align for EABI
+    mov     r4, r0                      @ save a copy of r0
+    mov     r5, r1                      @  and r1
+    bl      __aeabi_dcmpge              @ is arg >= maxlong?
+    cmp     r0, #0                      @ nonzero == yes
+    mvnne   r0, #0                      @ return maxlong (7fffffffffffffff)
+    mvnne   r1, #0x80000000
+    bne     1f
+
+    mov     r0, r4                      @ recover arg
+    mov     r1, r5
+    mov     r3, #0xc3000000             @ minlong, as a double (high word)
+    add     r3, #0x00e00000             @  0xc3e00000
+    mov     r2, #0                      @ minlong, as a double (low word)
+    bl      __aeabi_dcmple              @ is arg <= minlong?
+    cmp     r0, #0                      @ nonzero == yes
+    movne   r0, #0                      @ return minlong (8000000000000000)
+    movne   r1, #0x80000000
+    bne     1f
+
+    mov     r0, r4                      @ recover arg
+    mov     r1, r5
+    mov     r2, r4                      @ compare against self
+    mov     r3, r5
+    bl      __aeabi_dcmpeq              @ is arg == self?
+    cmp     r0, #0                      @ zero == no
+    moveq   r1, #0                      @ return zero for NaN
+    beq     1f
+
+    mov     r0, r4                      @ recover arg
+    mov     r1, r5
+    bl      __aeabi_d2lz                @ convert double to long
+
+1:
+    add     sp, sp, #4
+    ldmfd   sp!, {r4, r5, pc}
+
diff --git a/vm/mterp/armv5te_taint/OP_EXECUTE_INLINE.S b/vm/mterp/armv5te_taint/OP_EXECUTE_INLINE.S
new file mode 100644
index 0000000..20b20f8
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_EXECUTE_INLINE.S
@@ -0,0 +1,131 @@
+%verify "executed"
+%verify "exception handled"
+    /*
+     * Execute a "native inline" instruction.
+     *
+     * We need to call an InlineOp4Func:
+     *  bool (func)(u4 arg0, u4 arg1, u4 arg2, u4 arg3, JValue* pResult)
+     *
+     * The first four args are in r0-r3, pointer to return value storage
+     * is on the stack.  The function's return value is a flag that tells
+     * us if an exception was thrown.
+     *
+     * TUNING: could maintain two tables, pointer in Thread and
+     * swap if profiler/debuggger active.
+     */
+    /* [opt] execute-inline vAA, {vC, vD, vE, vF}, inline@BBBB */
+    ldrh    r2, [rSELF, #offThread_subMode]
+    FETCH(r10, 1)                       @ r10<- BBBB
+    EXPORT_PC()                         @ can throw
+    ands    r2, #kSubModeDebugProfile   @ Any going on?
+    bne     .L${opcode}_debugmode       @ yes - take slow path
+// begin WITH_TAINT_TRACKING
+    b       .L${opcode}_resume
+%break
+// end WITH_TAINT_TRACKING
+
+.L${opcode}_resume:
+    add     r1, rSELF, #offThread_retval  @ r1<- &self->retval
+// begin WITH_TAINT_TRACKING
+//    sub     sp, sp, #8                  @ make room for arg, +64 bit align
+    sub     sp, sp, #4                  @ make room for arg, +64 bit align
+    mov     r0, rINST, lsr #12          @ r0<- B
+    str     r1, [sp]                    @ push &self->retval
+    add     r1, rSELF, #offThread_rtaint  @ r1< &self->rtaint
+    sub     sp, sp, #4			@ make room for arg,
+    str     r1, [sp]                    @ push &self->rtaint
+    bl      .L${opcode}_continue        @ make call; will return after
+    add     sp, sp, #16                 @ pop stack 4x
+// end WITH_TAINT_TRACKING
+    cmp     r0, #0                      @ test boolean result of inline
+    beq     common_exceptionThrown      @ returned false, handle exception
+    FETCH_ADVANCE_INST(3)               @ advance rPC, load rINST
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+    GOTO_OPCODE(ip)                     @ jump to next instruction
+%break
+
+    /*
+     * Extract args, call function.
+     *  r0 = #of args (0-4)
+     *  r10 = call index
+     *  lr = return addr, above  [DO NOT bl out of here w/o preserving LR]
+     *
+     * Other ideas:
+     * - Use a jump table from the main piece to jump directly into the
+     *   AND/LDR pairs.  Costs a data load, saves a branch.
+     * - Have five separate pieces that do the loading, so we can work the
+     *   interleave a little better.  Increases code size.
+     */
+.L${opcode}_continue:
+    rsb     r0, r0, #4                  @ r0<- 4-r0
+    FETCH(rINST, 2)                     @ rINST<- FEDC
+    add     pc, pc, r0, lsl #3          @ computed goto, 2 instrs each
+    bl      common_abort                @ (skipped due to ARM prefetch)
+// begin WITH_TAINT_TRACKING
+4:  and     ip, rINST, #0xf000          @ isolate F
+    ldr     r3, [rFP, ip, lsr #9]       @ r3<- vF (shift right 12, left 2)
+3:  and     ip, rINST, #0x0f00          @ isolate E
+    ldr     r2, [rFP, ip, lsr #5]       @ r2<- vE
+2:  and     ip, rINST, #0x00f0          @ isolate D
+    ldr     r1, [rFP, ip, lsr #1]       @ r1<- vD
+1:  and     ip, rINST, #0x000f          @ isolate C
+    ldr     r0, [rFP, ip, lsl #3]       @ r0<- vC
+0:
+// push arg0_taint and arg1_taint
+    SET_TAINT_FP(r11)
+    and     ip, rINST, #0x00f0          @ isolate D
+    ldr     ip, [r11, ip, lsr #1]       @ ip<-arg1_taint
+    sub     sp, sp, #4			@ make room for arg
+    str     ip, [sp]                    @ push arg1_taint
+    and     ip, rINST, #0x000f          @ isolate C
+    ldr     ip, [r11, ip, lsl #3]       @ ip<-arg0_taint
+    sub     sp, sp, #4			@ make room for arg
+    str     ip, [sp]                    @ push arg0_taint
+// end WITH_TAINT_TRACKING
+    ldr     rINST, .L${opcode}_table    @ table of InlineOperation
+    ldr     pc, [rINST, r10, lsl #4]    @ sizeof=16, "func" is first entry
+    @ (not reached)
+
+
+    /*
+     * We're debugging or profiling.
+     * r10: opIndex
+     */
+.L${opcode}_debugmode:
+    mov     r0, r10
+    bl      dvmResolveInlineNative
+    cmp     r0, #0                      @ did it resolve?
+    beq     .L${opcode}_resume          @ no, just move on
+    mov     r9, r0                      @ remember method
+    mov     r1, rSELF
+    bl      dvmFastMethodTraceEnter     @ (method, self)
+    add     r1, rSELF, #offThread_retval@ r1<- &self->retval
+// begin WITH_TAINT_TRACKING
+//    sub     sp, sp, #8                  @ make room for arg, +64 bit align
+    sub     sp, sp, #4                  @ make room for arg, +64 bit align
+    mov     r0, rINST, lsr #12          @ r0<- B
+    str     r1, [sp]                    @ push &self->retval
+    add     r1, rSELF, #offThread_rtaint  @ r1< &self->rtaint
+    sub     sp, sp, #4			@ make room for arg,
+    str     r1, [sp]                    @ push &self->rtaint
+// end WITH_TAINT_TRACKING
+    bl      .L${opcode}_continue        @ make call; will return after
+    mov     rINST, r0                   @ save result of inline
+// begin WITH_TAINT_TRACKING
+//    add     sp, sp, #8                  @ pop stack
+    add     sp, sp, #16                 @ pop stack 4x
+// end WITH_TAINT_TRACKING
+    mov     r0, r9                      @ r0<- method
+    mov     r1, rSELF
+    bl      dvmFastNativeMethodTraceExit @ (method, self)
+    cmp     rINST, #0                   @ test boolean result of inline
+    beq     common_exceptionThrown      @ returned false, handle exception
+    FETCH_ADVANCE_INST(3)               @ advance rPC, load rINST
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+    GOTO_OPCODE(ip)                     @ jump to next instruction
+
+
+
+
+.L${opcode}_table:
+    .word   gDvmInlineOpsTable
diff --git a/vm/mterp/armv5te_taint/OP_EXECUTE_INLINE_RANGE.S b/vm/mterp/armv5te_taint/OP_EXECUTE_INLINE_RANGE.S
new file mode 100644
index 0000000..03c3416
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_EXECUTE_INLINE_RANGE.S
@@ -0,0 +1,123 @@
+%verify "executed"
+%verify "exception handled"
+    /*
+     * Execute a "native inline" instruction, using "/range" semantics.
+     * Same idea as execute-inline, but we get the args differently.
+     *
+     * We need to call an InlineOp4Func:
+     *  bool (func)(u4 arg0, u4 arg1, u4 arg2, u4 arg3, JValue* pResult)
+     *
+     * The first four args are in r0-r3, pointer to return value storage
+     * is on the stack.  The function's return value is a flag that tells
+     * us if an exception was thrown.
+     */
+    /* [opt] execute-inline/range {vCCCC..v(CCCC+AA-1)}, inline@BBBB */
+    ldrh    r2, [rSELF, #offThread_subMode]
+    FETCH(r10, 1)                       @ r10<- BBBB
+    EXPORT_PC()                         @ can throw
+    ands    r2, #kSubModeDebugProfile   @ Any going on?
+    bne     .L${opcode}_debugmode       @ yes - take slow path
+// begin WITH_TAINT_TRACKING
+    b       .L${opcode}_resume
+%break
+// end WITH_TAINT_TRACKING
+
+.L${opcode}_resume:
+    add     r1, rSELF, #offThread_retval  @ r1<- &self->retval
+// begin WITH_TAINT_TRACKING
+//    sub     sp, sp, #8                  @ make room for arg, +64 bit align
+    sub     sp, sp, #4                  @ make room for arg, +64 bit align
+    mov     r0, rINST, lsr #8           @ r0<- AA
+    str     r1, [sp]                    @ push &self->retval
+    add     r1, rSELF, #offThread_rtaint  @ r1< &self->rtaint
+    sub     sp, sp, #4			@ make room for arg
+    str     r1, [sp]                    @ push &self->rtaint
+    bl      .L${opcode}_continue        @ make call; will return after
+    add     sp, sp, #16                 @ pop stack 4x
+// end WITH_TAINT_TRACKING
+    cmp     r0, #0                      @ test boolean result of inline
+    beq     common_exceptionThrown      @ returned false, handle exception
+    FETCH_ADVANCE_INST(3)               @ advance rPC, load rINST
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+    GOTO_OPCODE(ip)                     @ jump to next instruction
+%break
+
+    /*
+     * Extract args, call function.
+     *  r0 = #of args (0-4)
+     *  r10 = call index
+     *  lr = return addr, above  [DO NOT bl out of here w/o preserving LR]
+     */
+.L${opcode}_continue:
+    rsb     r0, r0, #4                  @ r0<- 4-r0
+    FETCH(r9, 2)                        @ r9<- CCCC
+    add     pc, pc, r0, lsl #3          @ computed goto, 2 instrs each
+    bl      common_abort                @ (skipped due to ARM prefetch)
+4:  add     ip, r9, #3                  @ base+3
+    GET_VREG(r3, ip)                    @ r3<- vBase[3]
+3:  add     ip, r9, #2                  @ base+2
+    GET_VREG(r2, ip)                    @ r2<- vBase[2]
+2:  add     ip, r9, #1                  @ base+1
+    GET_VREG(r1, ip)                    @ r1<- vBase[1]
+1:  add     ip, r9, #0                  @ (nop)
+    GET_VREG(r0, ip)                    @ r0<- vBase[0]
+0:
+// begin WITH_TAINT_TRACKING
+// push arg0_taint and arg1_taint
+    SET_TAINT_FP(r11)
+    add     ip, r9, #1                  
+    GET_VREG_TAINT(ip, ip, r11)
+    sub     sp, sp, #4			@ make room for arg
+    str     ip, [sp]                    @ push arg1_taint
+    GET_VREG_TAINT(ip, r9, r11)
+    sub     sp, sp, #4			@ make room for arg
+    str     ip, [sp]                    @ push arg0_taint
+// end WITH_TAINT_TRACKING
+    ldr     r9, .L${opcode}_table       @ table of InlineOperation
+    ldr     pc, [r9, r10, lsl #4]       @ sizeof=16, "func" is first entry
+    @ (not reached)
+
+
+    /*
+     * We're debugging or profiling.
+     * r10: opIndex
+     */
+.L${opcode}_debugmode:
+    mov     r0, r10
+    bl      dvmResolveInlineNative
+    cmp     r0, #0                      @ did it resolve?
+    beq     .L${opcode}_resume          @ no, just move on
+    mov     r9, r0                      @ remember method
+    mov     r1, rSELF
+    bl      dvmFastMethodTraceEnter     @ (method, self)
+    add     r1, rSELF, #offThread_retval@ r1<- &self->retval
+// begin WITH_TAINT_TRACKING
+//    sub     sp, sp, #8                  @ make room for arg, +64 bit align
+    sub     sp, sp, #4                  @ make room for arg, +64 bit align
+    mov     r0, rINST, lsr #8           @ r0<- AA
+    str     r1, [sp]                    @ push &self->retval
+    add     r1, rSELF, #offThread_rtaint  @ r1< &self->rtaint
+    sub     sp, sp, #4			@ make room for arg
+    str     r1, [sp]                    @ push &self->rtaint
+// end WITH_TAINT_TRACKING
+    bl      .L${opcode}_continue        @ make call; will return after
+    mov     r9, r0                      @ save result of inline
+// begin WITH_TAINT_TRACKING
+//    add     sp, sp, #8                  @ pop stack
+    add     sp, sp, #16                 @ pop stack 4x
+// end WITH_TAINT_TRACKING
+    mov     r0, rINST                   @ r0<- method
+    mov     r1, rSELF
+    bl      dvmFastNativeMethodTraceExit  @ (method, self)
+    cmp     r9, #0                      @ test boolean result of inline
+    beq     common_exceptionThrown      @ returned false, handle exception
+    FETCH_ADVANCE_INST(3)               @ advance rPC, load rINST
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+    GOTO_OPCODE(ip)                     @ jump to next instruction
+
+
+
+
+.L${opcode}_table:
+    .word   gDvmInlineOpsTable
+
diff --git a/vm/mterp/armv5te_taint/OP_FILLED_NEW_ARRAY.S b/vm/mterp/armv5te_taint/OP_FILLED_NEW_ARRAY.S
new file mode 100644
index 0000000..bfce01a
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_FILLED_NEW_ARRAY.S
@@ -0,0 +1,116 @@
+%default { "isrange":"0" }
+%verify "executed"
+%verify "unimplemented array type"
+    /*
+     * Create a new array with elements filled from registers.
+     *
+     * for: filled-new-array, filled-new-array/range
+     */
+    /* op vB, {vD, vE, vF, vG, vA}, class@CCCC */
+    /* op {vCCCC..v(CCCC+AA-1)}, type@BBBB */
+    ldr     r3, [rSELF, #offThread_methodClassDex]    @ r3<- pDvmDex
+    FETCH(r1, 1)                        @ r1<- BBBB
+    ldr     r3, [r3, #offDvmDex_pResClasses]    @ r3<- pDvmDex->pResClasses
+    EXPORT_PC()                         @ need for resolve and alloc
+    ldr     r0, [r3, r1, lsl #2]        @ r0<- resolved class
+    mov     r10, rINST, lsr #8          @ r10<- AA or BA
+    cmp     r0, #0                      @ already resolved?
+    bne     .L${opcode}_continue        @ yes, continue on
+8:  ldr     r3, [rSELF, #offThread_method] @ r3<- self->method
+    mov     r2, #0                      @ r2<- false
+    ldr     r0, [r3, #offMethod_clazz]  @ r0<- method->clazz
+    bl      dvmResolveClass             @ r0<- call(clazz, ref)
+    cmp     r0, #0                      @ got null?
+    beq     common_exceptionThrown      @ yes, handle exception
+    b       .L${opcode}_continue
+%break
+
+    /*
+     * On entry:
+     *  r0 holds array class
+     *  r10 holds AA or BA
+     */
+.L${opcode}_continue:
+    ldr     r3, [r0, #offClassObject_descriptor] @ r3<- arrayClass->descriptor
+    mov     r2, #ALLOC_DONT_TRACK       @ r2<- alloc flags
+    ldrb    rINST, [r3, #1]             @ rINST<- descriptor[1]
+    .if     $isrange
+    mov     r1, r10                     @ r1<- AA (length)
+    .else
+    mov     r1, r10, lsr #4             @ r1<- B (length)
+    .endif
+    cmp     rINST, #'I'                 @ array of ints?
+    cmpne   rINST, #'L'                 @ array of objects?
+    cmpne   rINST, #'['                 @ array of arrays?
+    mov     r9, r1                      @ save length in r9
+    bne     .L${opcode}_notimpl         @ no, not handled yet
+    bl      dvmAllocArrayByClass        @ r0<- call(arClass, length, flags)
+    cmp     r0, #0                      @ null return?
+    beq     common_exceptionThrown      @ alloc failed, handle exception
+
+    FETCH(r1, 2)                        @ r1<- FEDC or CCCC
+    str     r0, [rSELF, #offThread_retval]      @ retval.l <- new array
+    str     rINST, [rSELF, #offThread_retval+4] @ retval.h <- type
+// begin WITH_TAINT_TRACKING
+    add     r2, r0, #offArrayObject_taint
+// end WITH_TAINT_TRACKING
+    add     r0, r0, #offArrayObject_contents @ r0<- newArray->contents
+    subs    r9, r9, #1                  @ length--, check for neg
+    FETCH_ADVANCE_INST(3)               @ advance to next instr, load rINST
+    bmi     2f                          @ was zero, bail
+
+    @ copy values from registers into the array
+    @ r0=array, r1=CCCC/FEDC, r9=length (from AA or B), r10=AA/BA
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_CLEAR(r3)
+    str     r3, [rSELF, #offThread_rtaint]    @ rtaint <- clear
+    str     r3, [r2]
+// end WITH_TAINT_TRACKING
+    .if     $isrange
+    add     r2, rFP, r1, lsl #2         @ r2<- &fp[CCCC]
+1:  ldr     r3, [r2], #4                @ r3<- *r2++
+    subs    r9, r9, #1                  @ count--
+    str     r3, [r0], #4                @ *contents++ = vX
+    bpl     1b
+    @ continue at 2
+    .else
+    cmp     r9, #4                      @ length was initially 5?
+    and     r2, r10, #15                @ r2<- A
+    bne     1f                          @ <= 4 args, branch
+    GET_VREG(r3, r2)                    @ r3<- vA
+    sub     r9, r9, #1                  @ count--
+    str     r3, [r0, #16]               @ contents[4] = vA
+1:  and     r2, r1, #15                 @ r2<- F/E/D/C
+    GET_VREG(r3, r2)                    @ r3<- vF/vE/vD/vC
+    mov     r1, r1, lsr #4              @ r1<- next reg in low 4
+    subs    r9, r9, #1                  @ count--
+    str     r3, [r0], #4                @ *contents++ = vX
+    bpl     1b
+    @ continue at 2
+    .endif
+
+2:
+    ldr     r0, [rSELF, #offThread_retval]     @ r0<- object
+    ldr     r1, [rSELF, #offThread_retval+4]   @ r1<- type
+    ldr     r2, [rSELF, #offThread_cardTable]  @ r2<- card table base
+    GET_INST_OPCODE(ip)                      @ ip<- opcode from rINST
+    cmp     r1, #'I'                         @ Is int array?
+    strneb  r2, [r2, r0, lsr #GC_CARD_SHIFT] @ Mark card based on object head
+    GOTO_OPCODE(ip)                          @ execute it
+
+    /*
+     * Throw an exception indicating that we have not implemented this
+     * mode of filled-new-array.
+     */
+.L${opcode}_notimpl:
+    ldr     r0, .L_strFilledNewArrayNotImpl_${opcode}
+    bl      dvmThrowInternalError
+    b       common_exceptionThrown
+
+    /*
+     * Ideally we'd only define this once, but depending on layout we can
+     * exceed the range of the load above.
+     */
+
+.L_strFilledNewArrayNotImpl_${opcode}:
+    .word   .LstrFilledNewArrayNotImpl
diff --git a/vm/mterp/armv5te_taint/OP_FILLED_NEW_ARRAY_RANGE.S b/vm/mterp/armv5te_taint/OP_FILLED_NEW_ARRAY_RANGE.S
new file mode 100644
index 0000000..2196f61
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_FILLED_NEW_ARRAY_RANGE.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te_taint/OP_FILLED_NEW_ARRAY.S" { "isrange":"1" }
diff --git a/vm/mterp/armv5te_taint/OP_FILL_ARRAY_DATA.S b/vm/mterp/armv5te_taint/OP_FILL_ARRAY_DATA.S
new file mode 100644
index 0000000..a0d8399
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_FILL_ARRAY_DATA.S
@@ -0,0 +1,15 @@
+%verify "executed"
+    /* fill-array-data vAA, +BBBBBBBB */
+    FETCH(r0, 1)                        @ r0<- bbbb (lo)
+    FETCH(r1, 2)                        @ r1<- BBBB (hi)
+    mov     r3, rINST, lsr #8           @ r3<- AA
+    orr     r1, r0, r1, lsl #16         @ r1<- BBBBbbbb
+    GET_VREG(r0, r3)                    @ r0<- vAA (array object)
+    add     r1, rPC, r1, lsl #1         @ r1<- PC + BBBBbbbb*2 (array data off.)
+    EXPORT_PC();
+    bl      dvmInterpHandleFillArrayData@ fill the array with predefined data
+    cmp     r0, #0                      @ 0 means an exception is thrown
+    beq     common_exceptionThrown      @ has exception
+    FETCH_ADVANCE_INST(3)               @ advance rPC, load rINST
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+    GOTO_OPCODE(ip)                     @ jump to next instruction
diff --git a/vm/mterp/armv5te_taint/OP_FLOAT_TO_DOUBLE.S b/vm/mterp/armv5te_taint/OP_FLOAT_TO_DOUBLE.S
new file mode 100644
index 0000000..870be3e
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_FLOAT_TO_DOUBLE.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te_taint/unopWider.S" {"instr":"bl      __aeabi_f2d"}
diff --git a/vm/mterp/armv5te_taint/OP_FLOAT_TO_INT.S b/vm/mterp/armv5te_taint/OP_FLOAT_TO_INT.S
new file mode 100644
index 0000000..5ab3db2
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_FLOAT_TO_INT.S
@@ -0,0 +1,41 @@
+%verify "executed"
+/* EABI appears to have Java-style conversions of +inf/-inf/NaN */
+%include "armv5te_taint/unop.S" {"instr":"bl      __aeabi_f2iz"}
+
+#if 0
+@include "armv5te_taint/unop.S" {"instr":"bl      f2i_doconv"}
+@break
+/*
+ * Convert the float in r0 to an int in r0.
+ *
+ * We have to clip values to int min/max per the specification.  The
+ * expected common case is a "reasonable" value that converts directly
+ * to modest integer.  The EABI convert function isn't doing this for us.
+ */
+f2i_doconv:
+    stmfd   sp!, {r4, lr}
+    mov     r1, #0x4f000000             @ (float)maxint
+    mov     r4, r0
+    bl      __aeabi_fcmpge              @ is arg >= maxint?
+    cmp     r0, #0                      @ nonzero == yes
+    mvnne   r0, #0x80000000             @ return maxint (7fffffff)
+    ldmnefd sp!, {r4, pc}
+
+    mov     r0, r4                      @ recover arg
+    mov     r1, #0xcf000000             @ (float)minint
+    bl      __aeabi_fcmple              @ is arg <= minint?
+    cmp     r0, #0                      @ nonzero == yes
+    movne   r0, #0x80000000             @ return minint (80000000)
+    ldmnefd sp!, {r4, pc}
+
+    mov     r0, r4                      @ recover arg
+    mov     r1, r4
+    bl      __aeabi_fcmpeq              @ is arg == self?
+    cmp     r0, #0                      @ zero == no
+    ldmeqfd sp!, {r4, pc}               @ return zero for NaN
+
+    mov     r0, r4                      @ recover arg
+    bl      __aeabi_f2iz                @ convert float to int
+    ldmfd   sp!, {r4, pc}
+#endif
+
diff --git a/vm/mterp/armv5te_taint/OP_FLOAT_TO_LONG.S b/vm/mterp/armv5te_taint/OP_FLOAT_TO_LONG.S
new file mode 100644
index 0000000..7ca0417
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_FLOAT_TO_LONG.S
@@ -0,0 +1,41 @@
+%verify "executed"
+@include "armv5te_taint/unopWider.S" {"instr":"bl      __aeabi_f2lz"}
+%include "armv5te_taint/unopWider.S" {"instr":"bl      f2l_doconv"}
+
+%break
+/*
+ * Convert the float in r0 to a long in r0/r1.
+ *
+ * We have to clip values to long min/max per the specification.  The
+ * expected common case is a "reasonable" value that converts directly
+ * to modest integer.  The EABI convert function isn't doing this for us.
+ */
+f2l_doconv:
+    stmfd   sp!, {r4, lr}
+    mov     r1, #0x5f000000             @ (float)maxlong
+    mov     r4, r0
+    bl      __aeabi_fcmpge              @ is arg >= maxlong?
+    cmp     r0, #0                      @ nonzero == yes
+    mvnne   r0, #0                      @ return maxlong (7fffffff)
+    mvnne   r1, #0x80000000
+    ldmnefd sp!, {r4, pc}
+
+    mov     r0, r4                      @ recover arg
+    mov     r1, #0xdf000000             @ (float)minlong
+    bl      __aeabi_fcmple              @ is arg <= minlong?
+    cmp     r0, #0                      @ nonzero == yes
+    movne   r0, #0                      @ return minlong (80000000)
+    movne   r1, #0x80000000
+    ldmnefd sp!, {r4, pc}
+
+    mov     r0, r4                      @ recover arg
+    mov     r1, r4
+    bl      __aeabi_fcmpeq              @ is arg == self?
+    cmp     r0, #0                      @ zero == no
+    moveq   r1, #0                      @ return zero for NaN
+    ldmeqfd sp!, {r4, pc}
+
+    mov     r0, r4                      @ recover arg
+    bl      __aeabi_f2lz                @ convert float to long
+    ldmfd   sp!, {r4, pc}
+
diff --git a/vm/mterp/armv5te_taint/OP_GOTO.S b/vm/mterp/armv5te_taint/OP_GOTO.S
new file mode 100644
index 0000000..7feca7b
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_GOTO.S
@@ -0,0 +1,22 @@
+%verify "executed"
+%verify "forward and backward"
+    /*
+     * Unconditional branch, 8-bit offset.
+     *
+     * The branch distance is a signed code-unit offset, which we need to
+     * double to get a byte offset.
+     */
+    /* goto +AA */
+    /* tuning: use sbfx for 6t2+ targets */
+    mov     r0, rINST, lsl #16          @ r0<- AAxx0000
+    movs    r1, r0, asr #24             @ r1<- ssssssAA (sign-extended)
+    add     r2, r1, r1                  @ r2<- byte offset, set flags
+       @ If backwards branch refresh rIBASE
+    ldrmi   rIBASE, [rSELF, #offThread_curHandlerTable] @ refresh handler base
+    FETCH_ADVANCE_INST_RB(r2)           @ update rPC, load rINST
+#if defined(WITH_JIT)
+    ldr     r0, [rSELF, #offThread_pJitProfTable]
+    bmi     common_testUpdateProfile    @ (r0) check for trace hotness
+#endif
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+    GOTO_OPCODE(ip)                     @ jump to next instruction
diff --git a/vm/mterp/armv5te_taint/OP_GOTO_16.S b/vm/mterp/armv5te_taint/OP_GOTO_16.S
new file mode 100644
index 0000000..8b1f1bd
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_GOTO_16.S
@@ -0,0 +1,19 @@
+%verify "executed"
+%verify "forward and backward"
+    /*
+     * Unconditional branch, 16-bit offset.
+     *
+     * The branch distance is a signed code-unit offset, which we need to
+     * double to get a byte offset.
+     */
+    /* goto/16 +AAAA */
+    FETCH_S(r0, 1)                      @ r0<- ssssAAAA (sign-extended)
+    adds    r1, r0, r0                  @ r1<- byte offset, flags set
+    FETCH_ADVANCE_INST_RB(r1)           @ update rPC, load rINST
+    ldrmi   rIBASE, [rSELF, #offThread_curHandlerTable] @ refresh handler base
+#if defined(WITH_JIT)
+    ldr     r0, [rSELF, #offThread_pJitProfTable]
+    bmi     common_testUpdateProfile    @ (r0) hot trace head?
+#endif
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+    GOTO_OPCODE(ip)                     @ jump to next instruction
diff --git a/vm/mterp/armv5te_taint/OP_GOTO_32.S b/vm/mterp/armv5te_taint/OP_GOTO_32.S
new file mode 100644
index 0000000..6202d7e
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_GOTO_32.S
@@ -0,0 +1,29 @@
+%verify "executed"
+%verify "forward, backward, self"
+    /*
+     * Unconditional branch, 32-bit offset.
+     *
+     * The branch distance is a signed code-unit offset, which we need to
+     * double to get a byte offset.
+     *
+     * Unlike most opcodes, this one is allowed to branch to itself, so
+     * our "backward branch" test must be "<=0" instead of "<0".  Because
+     * we need the V bit set, we'll use an adds to convert from Dalvik
+     * offset to byte offset.
+     */
+    /* goto/32 +AAAAAAAA */
+    FETCH(r0, 1)                        @ r0<- aaaa (lo)
+    FETCH(r1, 2)                        @ r1<- AAAA (hi)
+    orr     r0, r0, r1, lsl #16         @ r0<- AAAAaaaa
+    adds    r1, r0, r0                  @ r1<- byte offset
+#if defined(WITH_JIT)
+    ldr     r0, [rSELF, #offThread_pJitProfTable]
+    ldrle   rIBASE, [rSELF, #offThread_curHandlerTable] @ refresh handler base
+    FETCH_ADVANCE_INST_RB(r1)           @ update rPC, load rINST
+    ble     common_testUpdateProfile    @ (r0) hot trace head?
+#else
+    FETCH_ADVANCE_INST_RB(r1)           @ update rPC, load rINST
+    ldrle   rIBASE, [rSELF, #offThread_curHandlerTable] @ refresh handler base
+#endif
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+    GOTO_OPCODE(ip)                     @ jump to next instruction
diff --git a/vm/mterp/armv5te_taint/OP_IF_EQ.S b/vm/mterp/armv5te_taint/OP_IF_EQ.S
new file mode 100644
index 0000000..2ba7d90
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_IF_EQ.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te_taint/bincmp.S" { "revcmp":"ne" }
diff --git a/vm/mterp/armv5te_taint/OP_IF_EQZ.S b/vm/mterp/armv5te_taint/OP_IF_EQZ.S
new file mode 100644
index 0000000..345ac4f
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_IF_EQZ.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te_taint/zcmp.S" { "revcmp":"ne" }
diff --git a/vm/mterp/armv5te_taint/OP_IF_GE.S b/vm/mterp/armv5te_taint/OP_IF_GE.S
new file mode 100644
index 0000000..25f6035
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_IF_GE.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te_taint/bincmp.S" { "revcmp":"lt" }
diff --git a/vm/mterp/armv5te_taint/OP_IF_GEZ.S b/vm/mterp/armv5te_taint/OP_IF_GEZ.S
new file mode 100644
index 0000000..de0a5d7
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_IF_GEZ.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te_taint/zcmp.S" { "revcmp":"lt" }
diff --git a/vm/mterp/armv5te_taint/OP_IF_GT.S b/vm/mterp/armv5te_taint/OP_IF_GT.S
new file mode 100644
index 0000000..b534ee7
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_IF_GT.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te_taint/bincmp.S" { "revcmp":"le" }
diff --git a/vm/mterp/armv5te_taint/OP_IF_GTZ.S b/vm/mterp/armv5te_taint/OP_IF_GTZ.S
new file mode 100644
index 0000000..3456f00
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_IF_GTZ.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te_taint/zcmp.S" { "revcmp":"le" }
diff --git a/vm/mterp/armv5te_taint/OP_IF_LE.S b/vm/mterp/armv5te_taint/OP_IF_LE.S
new file mode 100644
index 0000000..58f3621
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_IF_LE.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te_taint/bincmp.S" { "revcmp":"gt" }
diff --git a/vm/mterp/armv5te_taint/OP_IF_LEZ.S b/vm/mterp/armv5te_taint/OP_IF_LEZ.S
new file mode 100644
index 0000000..a98e446
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_IF_LEZ.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te_taint/zcmp.S" { "revcmp":"gt" }
diff --git a/vm/mterp/armv5te_taint/OP_IF_LT.S b/vm/mterp/armv5te_taint/OP_IF_LT.S
new file mode 100644
index 0000000..0bfbac3
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_IF_LT.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te_taint/bincmp.S" { "revcmp":"ge" }
diff --git a/vm/mterp/armv5te_taint/OP_IF_LTZ.S b/vm/mterp/armv5te_taint/OP_IF_LTZ.S
new file mode 100644
index 0000000..48f4231
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_IF_LTZ.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te_taint/zcmp.S" { "revcmp":"ge" }
diff --git a/vm/mterp/armv5te_taint/OP_IF_NE.S b/vm/mterp/armv5te_taint/OP_IF_NE.S
new file mode 100644
index 0000000..e924486
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_IF_NE.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te_taint/bincmp.S" { "revcmp":"eq" }
diff --git a/vm/mterp/armv5te_taint/OP_IF_NEZ.S b/vm/mterp/armv5te_taint/OP_IF_NEZ.S
new file mode 100644
index 0000000..41afc94
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_IF_NEZ.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te_taint/zcmp.S" { "revcmp":"eq" }
diff --git a/vm/mterp/armv5te_taint/OP_IGET.S b/vm/mterp/armv5te_taint/OP_IGET.S
new file mode 100644
index 0000000..5851d40
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_IGET.S
@@ -0,0 +1,72 @@
+// begin WITH_TAINT_TRACKING
+%default { "load":"ldr", "barrier":"@ no-op ", "sqnum":"0", "volatile":"0"}
+// end WITH_TAINT_TRACKING
+%verify "executed"
+%verify "null object"
+%verify "field already resolved"
+%verify "field not yet resolved"
+%verify "field cannot be resolved"
+    /*
+     * General 32-bit instance field get.
+     *
+     * for: iget, iget-object, iget-boolean, iget-byte, iget-char, iget-short
+     */
+    /* op vA, vB, field@CCCC */
+    mov     r0, rINST, lsr #12          @ r0<- B
+    ldr     r3, [rSELF, #offThread_methodClassDex]    @ r3<- DvmDex
+    FETCH(r1, 1)                        @ r1<- field ref CCCC
+    ldr     r2, [r3, #offDvmDex_pResFields] @ r2<- pDvmDex->pResFields
+// begin WITH_TAINT_TRACKING
+    bl      .L${opcode}_taint_prop
+// end WITH_TAINT_TRACKING
+    cmp     r0, #0                      @ is resolved entry null?
+    bne     .L${opcode}_finish          @ no, already resolved
+8:  ldr     r2, [rSELF, #offThread_method]    @ r2<- current method
+    EXPORT_PC()                         @ resolve() could throw
+    ldr     r0, [r2, #offMethod_clazz]  @ r0<- method->clazz
+    bl      dvmResolveInstField         @ r0<- resolved InstField ptr
+    cmp     r0, #0
+    bne     .L${opcode}_finish
+    b       common_exceptionThrown
+%break
+
+    /*
+     * Currently:
+     *  r0 holds resolved field
+     *  r9 holds object
+     */
+.L${opcode}_finish:
+    @bl      common_squeak${sqnum}
+    cmp     r9, #0                      @ check object for null
+    ldr     r3, [r0, #offInstField_byteOffset]  @ r3<- byte offset of field
+    beq     common_errNullObject        @ object was null
+// begin WITH_TAINT_TRACKING
+//    .if     $volatile
+//    add     r0, r9, r3                  @ r0<- address of field
+//    bl      dvmQuasiAtomicRead64        @ r0/r1<- value/taint
+//    orr	    r3, r1, r10
+//    .else
+    $load   r0, [r9, r3]                @ r0<- obj.field (8/16/32 bits)
+    $barrier                            @ acquiring load
+    add     r3, r3, #4
+    ldr	    r3, [r9, r3]
+    orr     r3, r3, r10
+//    .endif
+// end WITH_TAINT_TRACKING
+    mov     r2, rINST, lsr #8           @ r2<- A+
+    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
+    and     r2, r2, #15                 @ r2<- A
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+    SET_VREG(r0, r2)                    @ fp[A]<- r0
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r1)
+    SET_VREG_TAINT(r3, r2, r1)
+// end WITH_TAINT_TRACKING
+    GOTO_OPCODE(ip)                     @ jump to next instruction
+
+.L${opcode}_taint_prop:
+    GET_VREG(r9, r0)                    @ r9<- fp[B], the object pointer
+    SET_TAINT_FP(r3)
+    GET_VREG_TAINT(r10, r0, r3)
+    ldr     r0, [r2, r1, lsl #2]        @ r0<- resolved InstField ptr
+    bx      lr
diff --git a/vm/mterp/armv5te_taint/OP_IGET_BOOLEAN.S b/vm/mterp/armv5te_taint/OP_IGET_BOOLEAN.S
new file mode 100644
index 0000000..4321296
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_IGET_BOOLEAN.S
@@ -0,0 +1,3 @@
+%verify "executed"
+@include "armv5te_taint/OP_IGET.S" { "load":"ldrb", "sqnum":"1" }
+%include "armv5te_taint/OP_IGET.S" { "load":"ldr", "sqnum":"1" }
diff --git a/vm/mterp/armv5te_taint/OP_IGET_BYTE.S b/vm/mterp/armv5te_taint/OP_IGET_BYTE.S
new file mode 100644
index 0000000..9b5eb75
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_IGET_BYTE.S
@@ -0,0 +1,4 @@
+%verify "executed"
+%verify "negative value is sign-extended"
+@include "armv5te_taint/OP_IGET.S" { "load":"ldrsb", "sqnum":"2" }
+%include "armv5te_taint/OP_IGET.S" { "load":"ldr", "sqnum":"2" }
diff --git a/vm/mterp/armv5te_taint/OP_IGET_CHAR.S b/vm/mterp/armv5te_taint/OP_IGET_CHAR.S
new file mode 100644
index 0000000..7f51ec9
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_IGET_CHAR.S
@@ -0,0 +1,5 @@
+%verify "executed"
+%verify "large values are not sign-extended"
+@include "armv5te_taint/OP_IGET.S" { "load":"ldrh", "sqnum":"3" }
+%include "armv5te_taint/OP_IGET.S" { "load":"ldr", "sqnum":"3" }
+
diff --git a/vm/mterp/armv5te_taint/OP_IGET_OBJECT.S b/vm/mterp/armv5te_taint/OP_IGET_OBJECT.S
new file mode 100644
index 0000000..72a589d
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_IGET_OBJECT.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te_taint/OP_IGET.S"
diff --git a/vm/mterp/armv5te_taint/OP_IGET_OBJECT_QUICK.S b/vm/mterp/armv5te_taint/OP_IGET_OBJECT_QUICK.S
new file mode 100644
index 0000000..64b6847
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_IGET_OBJECT_QUICK.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te_taint/OP_IGET_QUICK.S"
diff --git a/vm/mterp/armv5te_taint/OP_IGET_OBJECT_VOLATILE.S b/vm/mterp/armv5te_taint/OP_IGET_OBJECT_VOLATILE.S
new file mode 100644
index 0000000..f1014c8
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_IGET_OBJECT_VOLATILE.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te_taint/OP_IGET.S" {"volatile":"1"}
diff --git a/vm/mterp/armv5te_taint/OP_IGET_QUICK.S b/vm/mterp/armv5te_taint/OP_IGET_QUICK.S
new file mode 100644
index 0000000..a9f6dc9
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_IGET_QUICK.S
@@ -0,0 +1,36 @@
+%verify "executed"
+%verify "null object"
+    /* For: iget-quick, iget-object-quick */
+    /* op vA, vB, offset@CCCC */
+    mov     r2, rINST, lsr #12          @ r2<- B
+    GET_VREG(r3, r2)                    @ r3<- object we're operating on
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r0)
+    GET_VREG_TAINT(r9, r2, r0)
+// end WITH_TAINT_TRACKING
+    FETCH(r1, 1)                        @ r1<- field byte offset
+    cmp     r3, #0                      @ check object for null
+    mov     r2, rINST, lsr #8           @ r2<- A(+)
+    beq     common_errNullObject        @ object was null
+    ldr     r0, [r3, r1]                @ r0<- obj.field (always 32 bits)
+// begin WITH_TAINT_TRACKING
+	bl		.L${opcode}_taint_prop
+//    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST // in subroutine
+// end WITH_TAINT_TRACKING
+    and     r2, r2, #15
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+    SET_VREG(r0, r2)                    @ fp[A]<- r0
+// begin WITH_TAINT_TRACKING
+	SET_TAINT_FP(r0)
+	SET_VREG_TAINT(r10, r2, r0)
+// end WITH_TAINT_TRACKING
+    GOTO_OPCODE(ip)                     @ jump to next instruction
+
+%break
+
+.L${opcode}_taint_prop:
+	add		r1, r1, #4
+	ldr		r10, [r3, r1]
+	orr		r10, r9, r10
+	FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
+	bx		lr
diff --git a/vm/mterp/armv5te_taint/OP_IGET_SHORT.S b/vm/mterp/armv5te_taint/OP_IGET_SHORT.S
new file mode 100644
index 0000000..7479bb7
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_IGET_SHORT.S
@@ -0,0 +1,4 @@
+%verify "executed"
+%verify "negative value is sign-extended"
+@include "armv5te_taint/OP_IGET.S" { "load":"ldrsh", "sqnum":"4" }
+%include "armv5te_taint/OP_IGET.S" { "load":"ldr", "sqnum":"4" }
diff --git a/vm/mterp/armv5te_taint/OP_IGET_VOLATILE.S b/vm/mterp/armv5te_taint/OP_IGET_VOLATILE.S
new file mode 100644
index 0000000..f1014c8
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_IGET_VOLATILE.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te_taint/OP_IGET.S" {"volatile":"1"}
diff --git a/vm/mterp/armv5te_taint/OP_IGET_WIDE.S b/vm/mterp/armv5te_taint/OP_IGET_WIDE.S
new file mode 100644
index 0000000..e208355
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_IGET_WIDE.S
@@ -0,0 +1,70 @@
+%default {"volatile":"0"}
+%verify "executed"
+%verify "null object"
+%verify "field already resolved"
+%verify "field not yet resolved"
+%verify "field cannot be resolved"
+    /*
+     * Wide 32-bit instance field get.
+     */
+    /* iget-wide vA, vB, field@CCCC */
+    mov     r0, rINST, lsr #12          @ r0<- B
+    ldr     r3, [rSELF, #offThread_methodClassDex]    @ r3<- DvmDex
+    FETCH(r1, 1)                        @ r1<- field ref CCCC
+    ldr     r2, [r3, #offDvmDex_pResFields] @ r2<- pResFields
+// begin WITH_TAINT_TRACKING
+    bl      .L${opcode}_taint_prop
+// end WITH_TAINT_TRACKING
+    cmp     r0, #0                      @ is resolved entry null?
+    bne     .L${opcode}_finish          @ no, already resolved
+8:  ldr     r2, [rSELF, #offThread_method] @ r2<- current method
+    EXPORT_PC()                         @ resolve() could throw
+    ldr     r0, [r2, #offMethod_clazz]  @ r0<- method->clazz
+    bl      dvmResolveInstField         @ r0<- resolved InstField ptr
+    cmp     r0, #0
+    bne     .L${opcode}_finish
+    b       common_exceptionThrown
+%break
+
+    /*
+     * Currently:
+     *  r0 holds resolved field
+     *  r9 holds object
+     */
+.L${opcode}_finish:
+    cmp     r9, #0                      @ check object for null
+    ldr     r3, [r0, #offInstField_byteOffset]  @ r3<- byte offset of field
+    beq     common_errNullObject        @ object was null
+    .if     $volatile
+// begin WITH_TAINT_TRACKING
+    stmfd   sp!, {r3}
+    add     r0, r9, r3                  		@ r0<- address of field
+    bl      dvmQuasiAtomicRead64        @ r0/r1<- contents of field
+    ldmfd   sp!, {r3}
+    .else
+    ldrd    r0, [r9, r3]                @ r0/r1<- obj.field (64-bit align ok)
+    .endif
+    add     r3, r3, #8
+    ldr     r3, [r9, r3]
+    orr	    r10, r3, r10
+    mov     r2, rINST, lsr #8           @ r2<- A+
+    and     r2, r2, #15                 @ r2<- A
+    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
+    add     r3, rFP, r2, lsl #3         @ r3<- &fp[A]
+// end WITH_TAINT_TRACKING
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+// begin WITH_TAINT_TRACKING
+//    stmia   r3, {r0-r1}                 @ fp[A]<- r0/r1
+    str    r0, [r3, #0]
+    str    r10, [r3, #4]
+    str    r1, [r3, #8]
+    str    r10, [r3, #12]
+// end WITH_TAINT_TRACKING
+    GOTO_OPCODE(ip)                     @ jump to next instruction
+
+.L${opcode}_taint_prop:
+    GET_VREG(r9, r0)                    @ r9<- fp[B], the object pointer
+    SET_TAINT_FP(r3)
+    GET_VREG_TAINT(r10, r0, r3)
+    ldr     r0, [r2, r1, lsl #2]        @ r0<- resolved InstField ptr
+    bx      lr
diff --git a/vm/mterp/armv5te_taint/OP_IGET_WIDE_QUICK.S b/vm/mterp/armv5te_taint/OP_IGET_WIDE_QUICK.S
new file mode 100644
index 0000000..73157e0
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_IGET_WIDE_QUICK.S
@@ -0,0 +1,37 @@
+%verify "executed"
+%verify "null object"
+    /* iget-wide-quick vA, vB, offset@CCCC */
+    mov     r2, rINST, lsr #12          @ r2<- B
+    GET_VREG(r3, r2)                    @ r3<- object we're operating on
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r0)
+    GET_VREG_TAINT(r9, r2, r0)
+// end WITH_TAINT_TRACKING
+    FETCH(ip, 1)                        @ ip<- field byte offset
+    cmp     r3, #0                      @ check object for null
+    mov     r2, rINST, lsr #8           @ r2<- A(+)
+    beq     common_errNullObject        @ object was null
+// begin WITH_TAINT_TRACKING
+    add     r10, ip, #8
+    ldrd    r0, [r3, ip]                @ r0<- obj.field (64 bits, aligned)
+    ldr     r10, [r3, r10]
+    orr     r10, r9, r10
+// end WITH_TAINT_TRACKING
+    and     r2, r2, #15
+    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
+// begin WITH_TAINT_TRACKING
+    bl      iget_wide_quick_taint_prop
+// end WITH_TAINT_TRACKING
+    GOTO_OPCODE(ip)                     @ jump to next instruction
+
+%break
+
+iget_wide_quick_taint_prop:
+    add     r3, rFP, r2, lsl #3         @ r3<- &fp[A]
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+//    stmia   r3, {r0-r1}                 @ fp[A]<- r0/r1
+    str     r0, [r3, #0]
+    str     r10, [r3, #4]
+    str     r1, [r3, #8]
+    str     r10, [r3, #12]
+    bx      lr
diff --git a/vm/mterp/armv5te_taint/OP_IGET_WIDE_VOLATILE.S b/vm/mterp/armv5te_taint/OP_IGET_WIDE_VOLATILE.S
new file mode 100644
index 0000000..42d677e
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_IGET_WIDE_VOLATILE.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te_taint/OP_IGET_WIDE.S" {"volatile":"1"}
diff --git a/vm/mterp/armv5te_taint/OP_INSTANCE_OF.S b/vm/mterp/armv5te_taint/OP_INSTANCE_OF.S
new file mode 100644
index 0000000..d03a02c
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_INSTANCE_OF.S
@@ -0,0 +1,95 @@
+%verify "executed"
+%verify "null object"
+%verify "class cast exception thrown, with correct class name"
+%verify "class cast exception not thrown on same class"
+%verify "class cast exception not thrown on subclass"
+%verify "class not resolved"
+%verify "class already resolved"
+    /*
+     * Check to see if an object reference is an instance of a class.
+     *
+     * Most common situation is a non-null object, being compared against
+     * an already-resolved class.
+     */
+    /* instance-of vA, vB, class@CCCC */
+    mov     r3, rINST, lsr #12          @ r3<- B
+    mov     r9, rINST, lsr #8           @ r9<- A+
+    GET_VREG(r0, r3)                    @ r0<- vB (object)
+    and     r9, r9, #15                 @ r9<- A
+    cmp     r0, #0                      @ is object null?
+    ldr     r2, [rSELF, #offThread_methodClassDex]    @ r2<- pDvmDex
+    beq     .L${opcode}_store           @ null obj, not an instance, store r0
+    FETCH(r3, 1)                        @ r3<- CCCC
+    ldr     r2, [r2, #offDvmDex_pResClasses]    @ r2<- pDvmDex->pResClasses
+    ldr     r1, [r2, r3, lsl #2]        @ r1<- resolved class
+    ldr     r0, [r0, #offObject_clazz]  @ r0<- obj->clazz
+    cmp     r1, #0                      @ have we resolved this before?
+    beq     .L${opcode}_resolve         @ not resolved, do it now
+.L${opcode}_resolved: @ r0=obj->clazz, r1=resolved class
+    cmp     r0, r1                      @ same class (trivial success)?
+    beq     .L${opcode}_trivial         @ yes, trivial finish
+    b       .L${opcode}_fullcheck       @ no, do full check
+%break
+
+    /*
+     * Trivial test failed, need to perform full check.  This is common.
+     *  r0 holds obj->clazz
+     *  r1 holds class resolved from BBBB
+     *  r9 holds A
+     */
+.L${opcode}_fullcheck:
+    bl      dvmInstanceofNonTrivial     @ r0<- boolean result
+    @ fall through to ${opcode}_store
+
+    /*
+     * r0 holds boolean result
+     * r9 holds A
+     */
+.L${opcode}_store:
+    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r2)
+    SET_TAINT_CLEAR(r3)
+    SET_VREG_TAINT(r3, r9, r2)
+// end WITH_TAINT_TRACKING
+    SET_VREG(r0, r9)                    @ vA<- r0
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+    GOTO_OPCODE(ip)                     @ jump to next instruction
+
+    /*
+     * Trivial test succeeded, save and bail.
+     *  r9 holds A
+     */
+.L${opcode}_trivial:
+    mov     r0, #1                      @ indicate success
+    @ could b ${opcode}_store, but copying is faster and cheaper
+    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r2)
+    SET_TAINT_CLEAR(r3)
+    SET_VREG_TAINT(r3, r9, r2)
+// end WITH_TAINT_TRACKING
+    SET_VREG(r0, r9)                    @ vA<- r0
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+    GOTO_OPCODE(ip)                     @ jump to next instruction
+
+    /*
+     * Resolution required.  This is the least-likely path.
+     *
+     *  r3 holds BBBB
+     *  r9 holds A
+     */
+.L${opcode}_resolve:
+    EXPORT_PC()                         @ resolve() could throw
+    ldr     r0, [rSELF, #offThread_method]    @ r0<- self->method
+    mov     r1, r3                      @ r1<- BBBB
+    mov     r2, #1                      @ r2<- true
+    ldr     r0, [r0, #offMethod_clazz]  @ r0<- method->clazz
+    bl      dvmResolveClass             @ r0<- resolved ClassObject ptr
+    cmp     r0, #0                      @ got null?
+    beq     common_exceptionThrown      @ yes, handle exception
+    mov     r1, r0                      @ r1<- class resolved from BBB
+    mov     r3, rINST, lsr #12          @ r3<- B
+    GET_VREG(r0, r3)                    @ r0<- vB (object)
+    ldr     r0, [r0, #offObject_clazz]  @ r0<- obj->clazz
+    b       .L${opcode}_resolved        @ pick up where we left off
diff --git a/vm/mterp/armv5te_taint/OP_INT_TO_BYTE.S b/vm/mterp/armv5te_taint/OP_INT_TO_BYTE.S
new file mode 100644
index 0000000..b3fb9ae
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_INT_TO_BYTE.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te_taint/unop.S" {"preinstr":"mov     r0, r0, asl #24", "instr":"mov     r0, r0, asr #24"}
diff --git a/vm/mterp/armv5te_taint/OP_INT_TO_CHAR.S b/vm/mterp/armv5te_taint/OP_INT_TO_CHAR.S
new file mode 100644
index 0000000..003f8f9
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_INT_TO_CHAR.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te_taint/unop.S" {"preinstr":"mov     r0, r0, asl #16", "instr":"mov     r0, r0, lsr #16"}
diff --git a/vm/mterp/armv5te_taint/OP_INT_TO_DOUBLE.S b/vm/mterp/armv5te_taint/OP_INT_TO_DOUBLE.S
new file mode 100644
index 0000000..934130d
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_INT_TO_DOUBLE.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te_taint/unopWider.S" {"instr":"bl      __aeabi_i2d"}
diff --git a/vm/mterp/armv5te_taint/OP_INT_TO_FLOAT.S b/vm/mterp/armv5te_taint/OP_INT_TO_FLOAT.S
new file mode 100644
index 0000000..e67e344
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_INT_TO_FLOAT.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te_taint/unop.S" {"instr":"bl      __aeabi_i2f"}
diff --git a/vm/mterp/armv5te_taint/OP_INT_TO_LONG.S b/vm/mterp/armv5te_taint/OP_INT_TO_LONG.S
new file mode 100644
index 0000000..4021482
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_INT_TO_LONG.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te_taint/unopWider.S" {"instr":"mov     r1, r0, asr #31"}
diff --git a/vm/mterp/armv5te_taint/OP_INT_TO_SHORT.S b/vm/mterp/armv5te_taint/OP_INT_TO_SHORT.S
new file mode 100644
index 0000000..05c7940
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_INT_TO_SHORT.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te_taint/unop.S" {"preinstr":"mov     r0, r0, asl #16", "instr":"mov     r0, r0, asr #16"}
diff --git a/vm/mterp/armv5te_taint/OP_INVOKE_DIRECT.S b/vm/mterp/armv5te_taint/OP_INVOKE_DIRECT.S
new file mode 100644
index 0000000..7167a2b
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_INVOKE_DIRECT.S
@@ -0,0 +1,46 @@
+%default { "isrange":"0", "routine":"NoRange" }
+%verify "executed"
+%verify "unknown method"
+    /*
+     * Handle a direct method call.
+     *
+     * (We could defer the "is 'this' pointer null" test to the common
+     * method invocation code, and use a flag to indicate that static
+     * calls don't count.  If we do this as part of copying the arguments
+     * out we could avoiding loading the first arg twice.)
+     *
+     * for: invoke-direct, invoke-direct/range
+     */
+    /* op vB, {vD, vE, vF, vG, vA}, class@CCCC */
+    /* op {vCCCC..v(CCCC+AA-1)}, meth@BBBB */
+    ldr     r3, [rSELF, #offThread_methodClassDex]    @ r3<- pDvmDex
+    FETCH(r1, 1)                        @ r1<- BBBB
+    ldr     r3, [r3, #offDvmDex_pResMethods]    @ r3<- pDvmDex->pResMethods
+    FETCH(r10, 2)                       @ r10<- GFED or CCCC
+    ldr     r0, [r3, r1, lsl #2]        @ r0<- resolved methodToCall
+    .if     (!$isrange)
+    and     r10, r10, #15               @ r10<- D (or stays CCCC)
+    .endif
+    cmp     r0, #0                      @ already resolved?
+    EXPORT_PC()                         @ must export for invoke
+    GET_VREG(r9, r10)                   @ r9<- "this" ptr
+    beq     .L${opcode}_resolve         @ not resolved, do it now
+.L${opcode}_finish:
+    cmp     r9, #0                      @ null "this" ref?
+    bne     common_invokeMethod${routine}   @ r0=method, r9="this"
+    b       common_errNullObject        @ yes, throw exception
+%break
+
+    /*
+     * On entry:
+     *  r1 = reference (BBBB or CCCC)
+     *  r10 = "this" register
+     */
+.L${opcode}_resolve:
+    ldr     r3, [rSELF, #offThread_method] @ r3<- self->method
+    ldr     r0, [r3, #offMethod_clazz]  @ r0<- method->clazz
+    mov     r2, #METHOD_DIRECT          @ resolver method type
+    bl      dvmResolveMethod            @ r0<- call(clazz, ref, flags)
+    cmp     r0, #0                      @ got null?
+    bne     .L${opcode}_finish          @ no, continue
+    b       common_exceptionThrown      @ yes, handle exception
diff --git a/vm/mterp/armv5te_taint/OP_INVOKE_DIRECT_RANGE.S b/vm/mterp/armv5te_taint/OP_INVOKE_DIRECT_RANGE.S
new file mode 100644
index 0000000..a1b41c6
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_INVOKE_DIRECT_RANGE.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te_taint/OP_INVOKE_DIRECT.S" { "isrange":"1", "routine":"Range" }
diff --git a/vm/mterp/armv5te_taint/OP_INVOKE_INTERFACE.S b/vm/mterp/armv5te_taint/OP_INVOKE_INTERFACE.S
new file mode 100644
index 0000000..5ed35a8
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_INVOKE_INTERFACE.S
@@ -0,0 +1,27 @@
+%default { "isrange":"0", "routine":"NoRange" }
+%verify "executed"
+%verify "unknown method"
+%verify "null object"
+    /*
+     * Handle an interface method call.
+     *
+     * for: invoke-interface, invoke-interface/range
+     */
+    /* op vB, {vD, vE, vF, vG, vA}, class@CCCC */
+    /* op {vCCCC..v(CCCC+AA-1)}, meth@BBBB */
+    FETCH(r2, 2)                        @ r2<- FEDC or CCCC
+    FETCH(r1, 1)                        @ r1<- BBBB
+    .if     (!$isrange)
+    and     r2, r2, #15                 @ r2<- C (or stays CCCC)
+    .endif
+    EXPORT_PC()                         @ must export for invoke
+    GET_VREG(r9, r2)                    @ r9<- first arg ("this")
+    ldr     r3, [rSELF, #offThread_methodClassDex]    @ r3<- methodClassDex
+    cmp     r9, #0                      @ null obj?
+    ldr     r2, [rSELF, #offThread_method]  @ r2<- method
+    beq     common_errNullObject        @ yes, fail
+    ldr     r0, [r9, #offObject_clazz]  @ r0<- thisPtr->clazz
+    bl      dvmFindInterfaceMethodInCache @ r0<- call(class, ref, method, dex)
+    cmp     r0, #0                      @ failed?
+    beq     common_exceptionThrown      @ yes, handle exception
+    b       common_invokeMethod${routine} @ (r0=method, r9="this")
diff --git a/vm/mterp/armv5te_taint/OP_INVOKE_INTERFACE_RANGE.S b/vm/mterp/armv5te_taint/OP_INVOKE_INTERFACE_RANGE.S
new file mode 100644
index 0000000..12b8390
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_INVOKE_INTERFACE_RANGE.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te_taint/OP_INVOKE_INTERFACE.S" { "isrange":"1", "routine":"Range" }
diff --git a/vm/mterp/armv5te_taint/OP_INVOKE_OBJECT_INIT_RANGE.S b/vm/mterp/armv5te_taint/OP_INVOKE_OBJECT_INIT_RANGE.S
new file mode 100644
index 0000000..ab89189
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_INVOKE_OBJECT_INIT_RANGE.S
@@ -0,0 +1,44 @@
+%default { "jumbo":"0", "cccc":"2" }
+%verify "executed"
+%verify "finalizable class"
+    /*
+     * Invoke Object.<init> on an object.  In practice we know that
+     * Object's nullary constructor doesn't do anything, so we just
+     * skip it unless a debugger is active.
+     */
+    FETCH(r1, ${cccc})                  @ r1<- CCCC
+    GET_VREG(r0, r1)                    @ r0<- "this" ptr
+    cmp     r0, #0                      @ check for NULL
+    beq     common_errNullObject        @ export PC and throw NPE
+    ldr     r1, [r0, #offObject_clazz]  @ r1<- obj->clazz
+    ldr     r2, [r1, #offClassObject_accessFlags] @ r2<- clazz->accessFlags
+    tst     r2, #CLASS_ISFINALIZABLE    @ is this class finalizable?
+    bne     .L${opcode}_setFinal        @ yes, go
+.L${opcode}_finish:
+    ldrh    r1, [rSELF, #offThread_subMode]
+    ands    r1, #kSubModeDebuggerActive @ debugger active?
+    bne     .L${opcode}_debugger        @ Yes - skip optimization
+    FETCH_ADVANCE_INST(${cccc}+1)       @ advance to next instr, load rINST
+    GET_INST_OPCODE(ip)                 @ ip<- opcode from rINST
+    GOTO_OPCODE(ip)                     @ execute it
+%break
+
+.L${opcode}_setFinal:
+    EXPORT_PC()                         @ can throw
+    bl      dvmSetFinalizable           @ call dvmSetFinalizable(obj)
+    ldr     r0, [rSELF, #offThread_exception] @ r0<- self->exception
+    cmp     r0, #0                      @ exception pending?
+    bne     common_exceptionThrown      @ yes, handle it
+    b       .L${opcode}_finish
+
+    /*
+     * A debugger is attached, so we need to go ahead and do
+     * this.  For simplicity, we'll just jump directly to the
+     * corresponding handler.  Note that we can't use
+     * rIBASE here because it may be in single-step mode.
+     * Load the primary table base directly.
+     */
+.L${opcode}_debugger:
+    ldr     r1, [rSELF, #offThread_mainHandlerTable]
+    mov     ip, #OP_INVOKE_DIRECT_RANGE
+    GOTO_OPCODE_BASE(r1,ip)             @ execute it
diff --git a/vm/mterp/armv5te_taint/OP_INVOKE_STATIC.S b/vm/mterp/armv5te_taint/OP_INVOKE_STATIC.S
new file mode 100644
index 0000000..a89db03
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_INVOKE_STATIC.S
@@ -0,0 +1,54 @@
+%default { "routine":"NoRange" }
+%verify "executed"
+%verify "unknown method"
+    /*
+     * Handle a static method call.
+     *
+     * for: invoke-static, invoke-static/range
+     */
+    /* op vB, {vD, vE, vF, vG, vA}, class@CCCC */
+    /* op {vCCCC..v(CCCC+AA-1)}, meth@BBBB */
+    ldr     r3, [rSELF, #offThread_methodClassDex]    @ r3<- pDvmDex
+    FETCH(r1, 1)                        @ r1<- BBBB
+    ldr     r3, [r3, #offDvmDex_pResMethods]    @ r3<- pDvmDex->pResMethods
+    mov     r9, #0                      @ null "this" in delay slot
+    ldr     r0, [r3, r1, lsl #2]        @ r0<- resolved methodToCall
+#if defined(WITH_JIT)
+    add     r10, r3, r1, lsl #2         @ r10<- &resolved_methodToCall
+#endif
+    cmp     r0, #0                      @ already resolved?
+    EXPORT_PC()                         @ must export for invoke
+    bne     common_invokeMethod${routine} @ yes, continue on
+    b       .L${opcode}_resolve
+%break
+
+
+.L${opcode}_resolve:
+    ldr     r3, [rSELF, #offThread_method] @ r3<- self->method
+    ldr     r0, [r3, #offMethod_clazz]  @ r0<- method->clazz
+    mov     r2, #METHOD_STATIC          @ resolver method type
+    bl      dvmResolveMethod            @ r0<- call(clazz, ref, flags)
+    cmp     r0, #0                      @ got null?
+#if defined(WITH_JIT)
+    /*
+     * Check to see if we're actively building a trace.  If so,
+     * we need to keep this instruction out of it.
+     * r10: &resolved_methodToCall
+     */
+    ldrh    r2, [rSELF, #offThread_subMode]
+    beq     common_exceptionThrown            @ null, handle exception
+    ands    r2, #kSubModeJitTraceBuild        @ trace under construction?
+    beq     common_invokeMethod${routine}     @ no (r0=method, r9="this")
+    ldr     r1, [r10]                         @ reload resolved method
+    cmp     r1, #0                            @ finished resolving?
+    bne     common_invokeMethod${routine}     @ yes (r0=method, r9="this")
+    mov     r10, r0                           @ preserve method
+    mov     r0, rSELF
+    mov     r1, rPC
+    bl      dvmJitEndTraceSelect              @ (self, pc)
+    mov     r0, r10
+    b       common_invokeMethod${routine}     @ whew, finally!
+#else
+    bne     common_invokeMethod${routine}     @ (r0=method, r9="this")
+    b       common_exceptionThrown            @ yes, handle exception
+#endif
diff --git a/vm/mterp/armv5te_taint/OP_INVOKE_STATIC_RANGE.S b/vm/mterp/armv5te_taint/OP_INVOKE_STATIC_RANGE.S
new file mode 100644
index 0000000..e78f3ee
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_INVOKE_STATIC_RANGE.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te_taint/OP_INVOKE_STATIC.S" { "routine":"Range" }
diff --git a/vm/mterp/armv5te_taint/OP_INVOKE_SUPER.S b/vm/mterp/armv5te_taint/OP_INVOKE_SUPER.S
new file mode 100644
index 0000000..b1d1411
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_INVOKE_SUPER.S
@@ -0,0 +1,60 @@
+%default { "isrange":"0", "routine":"NoRange" }
+%verify "executed"
+%verify "unknown method"
+    /*
+     * Handle a "super" method call.
+     *
+     * for: invoke-super, invoke-super/range
+     */
+    /* op vB, {vD, vE, vF, vG, vA}, class@CCCC */
+    /* op vAA, {vCCCC..v(CCCC+AA-1)}, meth@BBBB */
+    FETCH(r10, 2)                       @ r10<- GFED or CCCC
+    ldr     r3, [rSELF, #offThread_methodClassDex]    @ r3<- pDvmDex
+    .if     (!$isrange)
+    and     r10, r10, #15               @ r10<- D (or stays CCCC)
+    .endif
+    FETCH(r1, 1)                        @ r1<- BBBB
+    ldr     r3, [r3, #offDvmDex_pResMethods]    @ r3<- pDvmDex->pResMethods
+    GET_VREG(r9, r10)                   @ r9<- "this" ptr
+    ldr     r0, [r3, r1, lsl #2]        @ r0<- resolved baseMethod
+    cmp     r9, #0                      @ null "this"?
+    ldr     r10, [rSELF, #offThread_method] @ r10<- current method
+    beq     common_errNullObject        @ null "this", throw exception
+    cmp     r0, #0                      @ already resolved?
+    ldr     r10, [r10, #offMethod_clazz]  @ r10<- method->clazz
+    EXPORT_PC()                         @ must export for invoke
+    bne     .L${opcode}_continue        @ resolved, continue on
+    b       .L${opcode}_resolve         @ do resolve now
+%break
+
+    /*
+     * At this point:
+     *  r0 = resolved base method
+     *  r10 = method->clazz
+     */
+.L${opcode}_continue:
+    ldr     r1, [r10, #offClassObject_super]    @ r1<- method->clazz->super
+    ldrh    r2, [r0, #offMethod_methodIndex]    @ r2<- baseMethod->methodIndex
+    ldr     r3, [r1, #offClassObject_vtableCount]   @ r3<- super->vtableCount
+    EXPORT_PC()                         @ must export for invoke
+    cmp     r2, r3                      @ compare (methodIndex, vtableCount)
+    bcs     .L${opcode}_nsm             @ method not present in superclass
+    ldr     r1, [r1, #offClassObject_vtable]    @ r1<- ...clazz->super->vtable
+    ldr     r0, [r1, r2, lsl #2]        @ r3<- vtable[methodIndex]
+    bl      common_invokeMethod${routine} @ continue on
+
+.L${opcode}_resolve:
+    mov     r0, r10                     @ r0<- method->clazz
+    mov     r2, #METHOD_VIRTUAL         @ resolver method type
+    bl      dvmResolveMethod            @ r0<- call(clazz, ref, flags)
+    cmp     r0, #0                      @ got null?
+    bne     .L${opcode}_continue        @ no, continue
+    b       common_exceptionThrown      @ yes, handle exception
+
+    /*
+     * Throw a NoSuchMethodError with the method name as the message.
+     *  r0 = resolved base method
+     */
+.L${opcode}_nsm:
+    ldr     r1, [r0, #offMethod_name]   @ r1<- method name
+    b       common_errNoSuchMethod
diff --git a/vm/mterp/armv5te_taint/OP_INVOKE_SUPER_QUICK.S b/vm/mterp/armv5te_taint/OP_INVOKE_SUPER_QUICK.S
new file mode 100644
index 0000000..4848b7e
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_INVOKE_SUPER_QUICK.S
@@ -0,0 +1,25 @@
+%default { "isrange":"0", "routine":"NoRange" }
+%verify "executed"
+%verify "unknown method"
+    /*
+     * Handle an optimized "super" method call.
+     *
+     * for: [opt] invoke-super-quick, invoke-super-quick/range
+     */
+    /* op vB, {vD, vE, vF, vG, vA}, class@CCCC */
+    /* op vAA, {vCCCC..v(CCCC+AA-1)}, meth@BBBB */
+    FETCH(r10, 2)                       @ r10<- GFED or CCCC
+    ldr     r2, [rSELF, #offThread_method]    @ r2<- current method
+    .if     (!$isrange)
+    and     r10, r10, #15               @ r10<- D (or stays CCCC)
+    .endif
+    FETCH(r1, 1)                        @ r1<- BBBB
+    ldr     r2, [r2, #offMethod_clazz]  @ r2<- method->clazz
+    EXPORT_PC()                         @ must export for invoke
+    ldr     r2, [r2, #offClassObject_super]     @ r2<- method->clazz->super
+    GET_VREG(r9, r10)                   @ r9<- "this"
+    ldr     r2, [r2, #offClassObject_vtable]    @ r2<- ...clazz->super->vtable
+    cmp     r9, #0                      @ null "this" ref?
+    ldr     r0, [r2, r1, lsl #2]        @ r0<- super->vtable[BBBB]
+    beq     common_errNullObject        @ "this" is null, throw exception
+    bl      common_invokeMethod${routine} @ (r0=method, r9="this")
diff --git a/vm/mterp/armv5te_taint/OP_INVOKE_SUPER_QUICK_RANGE.S b/vm/mterp/armv5te_taint/OP_INVOKE_SUPER_QUICK_RANGE.S
new file mode 100644
index 0000000..82c3d39
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_INVOKE_SUPER_QUICK_RANGE.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te_taint/OP_INVOKE_SUPER_QUICK.S" { "isrange":"1", "routine":"Range" }
diff --git a/vm/mterp/armv5te_taint/OP_INVOKE_SUPER_RANGE.S b/vm/mterp/armv5te_taint/OP_INVOKE_SUPER_RANGE.S
new file mode 100644
index 0000000..7228e15
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_INVOKE_SUPER_RANGE.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te_taint/OP_INVOKE_SUPER.S" { "isrange":"1", "routine":"Range" }
diff --git a/vm/mterp/armv5te_taint/OP_INVOKE_VIRTUAL.S b/vm/mterp/armv5te_taint/OP_INVOKE_VIRTUAL.S
new file mode 100644
index 0000000..58b0a42
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_INVOKE_VIRTUAL.S
@@ -0,0 +1,45 @@
+%default { "isrange":"0", "routine":"NoRange" }
+%verify "executed"
+%verify "unknown method"
+%verify "null object"
+    /*
+     * Handle a virtual method call.
+     *
+     * for: invoke-virtual, invoke-virtual/range
+     */
+    /* op vB, {vD, vE, vF, vG, vA}, class@CCCC */
+    /* op vAA, {vCCCC..v(CCCC+AA-1)}, meth@BBBB */
+    ldr     r3, [rSELF, #offThread_methodClassDex]    @ r3<- pDvmDex
+    FETCH(r1, 1)                        @ r1<- BBBB
+    ldr     r3, [r3, #offDvmDex_pResMethods]    @ r3<- pDvmDex->pResMethods
+    FETCH(r10, 2)                       @ r10<- GFED or CCCC
+    ldr     r0, [r3, r1, lsl #2]        @ r0<- resolved baseMethod
+    .if     (!$isrange)
+    and     r10, r10, #15               @ r10<- D (or stays CCCC)
+    .endif
+    cmp     r0, #0                      @ already resolved?
+    EXPORT_PC()                         @ must export for invoke
+    bne     .L${opcode}_continue        @ yes, continue on
+    ldr     r3, [rSELF, #offThread_method] @ r3<- self->method
+    ldr     r0, [r3, #offMethod_clazz]  @ r0<- method->clazz
+    mov     r2, #METHOD_VIRTUAL         @ resolver method type
+    bl      dvmResolveMethod            @ r0<- call(clazz, ref, flags)
+    cmp     r0, #0                      @ got null?
+    bne     .L${opcode}_continue        @ no, continue
+    b       common_exceptionThrown      @ yes, handle exception
+%break
+
+    /*
+     * At this point:
+     *  r0 = resolved base method
+     *  r10 = C or CCCC (index of first arg, which is the "this" ptr)
+     */
+.L${opcode}_continue:
+    GET_VREG(r9, r10)                   @ r9<- "this" ptr
+    ldrh    r2, [r0, #offMethod_methodIndex]    @ r2<- baseMethod->methodIndex
+    cmp     r9, #0                      @ is "this" null?
+    beq     common_errNullObject        @ null "this", throw exception
+    ldr     r3, [r9, #offObject_clazz]  @ r3<- thisPtr->clazz
+    ldr     r3, [r3, #offClassObject_vtable]    @ r3<- thisPtr->clazz->vtable
+    ldr     r0, [r3, r2, lsl #2]        @ r3<- vtable[methodIndex]
+    bl      common_invokeMethod${routine} @ (r0=method, r9="this")
diff --git a/vm/mterp/armv5te_taint/OP_INVOKE_VIRTUAL_QUICK.S b/vm/mterp/armv5te_taint/OP_INVOKE_VIRTUAL_QUICK.S
new file mode 100644
index 0000000..4b425da
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_INVOKE_VIRTUAL_QUICK.S
@@ -0,0 +1,23 @@
+%default { "isrange":"0", "routine":"NoRange" }
+%verify "executed"
+%verify "null object"
+    /*
+     * Handle an optimized virtual method call.
+     *
+     * for: [opt] invoke-virtual-quick, invoke-virtual-quick/range
+     */
+    /* op vB, {vD, vE, vF, vG, vA}, class@CCCC */
+    /* op vAA, {vCCCC..v(CCCC+AA-1)}, meth@BBBB */
+    FETCH(r3, 2)                        @ r3<- FEDC or CCCC
+    FETCH(r1, 1)                        @ r1<- BBBB
+    .if     (!$isrange)
+    and     r3, r3, #15                 @ r3<- C (or stays CCCC)
+    .endif
+    GET_VREG(r9, r3)                    @ r9<- vC ("this" ptr)
+    cmp     r9, #0                      @ is "this" null?
+    beq     common_errNullObject        @ null "this", throw exception
+    ldr     r2, [r9, #offObject_clazz]  @ r2<- thisPtr->clazz
+    ldr     r2, [r2, #offClassObject_vtable]    @ r2<- thisPtr->clazz->vtable
+    EXPORT_PC()                         @ invoke must export
+    ldr     r0, [r2, r1, lsl #2]        @ r3<- vtable[BBBB]
+    bl      common_invokeMethod${routine} @ (r0=method, r9="this")
diff --git a/vm/mterp/armv5te_taint/OP_INVOKE_VIRTUAL_QUICK_RANGE.S b/vm/mterp/armv5te_taint/OP_INVOKE_VIRTUAL_QUICK_RANGE.S
new file mode 100644
index 0000000..f52c7b8
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_INVOKE_VIRTUAL_QUICK_RANGE.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te_taint/OP_INVOKE_VIRTUAL_QUICK.S" { "isrange":"1", "routine":"Range" }
diff --git a/vm/mterp/armv5te_taint/OP_INVOKE_VIRTUAL_RANGE.S b/vm/mterp/armv5te_taint/OP_INVOKE_VIRTUAL_RANGE.S
new file mode 100644
index 0000000..4371740
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_INVOKE_VIRTUAL_RANGE.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te_taint/OP_INVOKE_VIRTUAL.S" { "isrange":"1", "routine":"Range" }
diff --git a/vm/mterp/armv5te_taint/OP_IPUT.S b/vm/mterp/armv5te_taint/OP_IPUT.S
new file mode 100644
index 0000000..8bb01e7
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_IPUT.S
@@ -0,0 +1,65 @@
+// begin WITH_TAINT_TRACKING
+%default { "store":"str", "postbarrier":"@ no-op ", "prebarrier":"@ no-op ", "sqnum":"0", "volatile":"0" }
+// end WITH_TAINT_TRACKING
+%verify "executed"
+%verify "null object"
+%verify "field already resolved"
+%verify "field not yet resolved"
+%verify "field cannot be resolved"
+    /*
+     * General 32-bit instance field put.
+     *
+     * for: iput, iput-boolean, iput-byte, iput-char, iput-short
+     */
+    /* op vA, vB, field@CCCC */
+    mov     r0, rINST, lsr #12          @ r0<- B
+    ldr     r3, [rSELF, #offThread_methodClassDex]    @ r3<- DvmDex
+    FETCH(r1, 1)                        @ r1<- field ref CCCC
+    ldr     r2, [r3, #offDvmDex_pResFields] @ r2<- pDvmDex->pResFields
+    GET_VREG(r9, r0)                    @ r9<- fp[B], the object pointer
+    ldr     r0, [r2, r1, lsl #2]        @ r0<- resolved InstField ptr
+    cmp     r0, #0                      @ is resolved entry null?
+    bne     .L${opcode}_finish          @ no, already resolved
+8:  ldr     r2, [rSELF, #offThread_method]    @ r2<- current method
+    EXPORT_PC()                         @ resolve() could throw
+    ldr     r0, [r2, #offMethod_clazz]  @ r0<- method->clazz
+    bl      dvmResolveInstField         @ r0<- resolved InstField ptr
+    cmp     r0, #0                      @ success?
+    bne     .L${opcode}_finish          @ yes, finish up
+    b       common_exceptionThrown
+%break
+
+    /*
+     * Currently:
+     *  r0 holds resolved field
+     *  r9 holds object
+     */
+.L${opcode}_finish:
+    @bl      common_squeak${sqnum}
+    mov     r1, rINST, lsr #8           @ r1<- A+
+    ldr     r3, [r0, #offInstField_byteOffset]  @ r3<- byte offset of field
+    and     r1, r1, #15                 @ r1<- A
+    cmp     r9, #0                      @ check object for null
+    GET_VREG(r0, r1)                    @ r0<- fp[A]
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r2)
+    GET_VREG_TAINT(r10, r1, r2)
+// end WITH_TAINT_TRACKING
+    beq     common_errNullObject        @ object was null
+    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+    $prebarrier                         @ releasing store
+// begin WITH_TAINT_TRACKING
+//    .if     $volatile
+//    add     r2, r9, r3                  @ r2<- target address
+//    mov	    r1, r10                     @ r1<-taint
+//    bl      dvmQuasiAtomicSwap64        @ stores r0/r1 into addr r2
+//    .else
+    $store  r0, [r9, r3]                @ obj.field (8/16/32 bits)<- r0
+    add	    r3, r3, #4
+    str	    r10, [r9, r3]
+//    .endif
+// end WITH_TAINT_TRACKING
+    $postbarrier
+    GOTO_OPCODE(ip)                     @ jump to next instruction
+
diff --git a/vm/mterp/armv5te_taint/OP_IPUT_BOOLEAN.S b/vm/mterp/armv5te_taint/OP_IPUT_BOOLEAN.S
new file mode 100644
index 0000000..e2b748e
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_IPUT_BOOLEAN.S
@@ -0,0 +1,3 @@
+%verify "executed"
+@include "armv5te_taint/OP_IPUT.S" { "store":"strb", "sqnum":"1" }
+%include "armv5te_taint/OP_IPUT.S" { "store":"str", "sqnum":"1" }
diff --git a/vm/mterp/armv5te_taint/OP_IPUT_BYTE.S b/vm/mterp/armv5te_taint/OP_IPUT_BYTE.S
new file mode 100644
index 0000000..68c0cc1
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_IPUT_BYTE.S
@@ -0,0 +1,3 @@
+%verify "executed"
+@include "armv5te_taint/OP_IPUT.S" { "store":"strb", "sqnum":"2" }
+%include "armv5te_taint/OP_IPUT.S" { "store":"str", "sqnum":"2" }
diff --git a/vm/mterp/armv5te_taint/OP_IPUT_CHAR.S b/vm/mterp/armv5te_taint/OP_IPUT_CHAR.S
new file mode 100644
index 0000000..2316d9d
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_IPUT_CHAR.S
@@ -0,0 +1,3 @@
+%verify "executed"
+@include "armv5te_taint/OP_IPUT.S" { "store":"strh", "sqnum":"3" }
+%include "armv5te_taint/OP_IPUT.S" { "store":"str", "sqnum":"3" }
diff --git a/vm/mterp/armv5te_taint/OP_IPUT_OBJECT.S b/vm/mterp/armv5te_taint/OP_IPUT_OBJECT.S
new file mode 100644
index 0000000..0fba7d6
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_IPUT_OBJECT.S
@@ -0,0 +1,67 @@
+// begin WITH_TAINT_TRACKING
+%default { "postbarrier":"@ no-op ", "prebarrier":"@ no-op ", "sqnum":"0", "volatile":"0" }
+// end WITH_TAINT_TRACKING
+%verify "executed"
+%verify "null object"
+%verify "field already resolved"
+%verify "field not yet resolved"
+%verify "field cannot be resolved"
+    /*
+     * 32-bit instance field put.
+     *
+     * for: iput-object, iput-object-volatile
+     */
+    /* op vA, vB, field@CCCC */
+    mov     r0, rINST, lsr #12          @ r0<- B
+    ldr     r3, [rSELF, #offThread_methodClassDex]    @ r3<- DvmDex
+    FETCH(r1, 1)                        @ r1<- field ref CCCC
+    ldr     r2, [r3, #offDvmDex_pResFields] @ r2<- pDvmDex->pResFields
+    GET_VREG(r9, r0)                    @ r9<- fp[B], the object pointer
+    ldr     r0, [r2, r1, lsl #2]        @ r0<- resolved InstField ptr
+    cmp     r0, #0                      @ is resolved entry null?
+    bne     .L${opcode}_finish          @ no, already resolved
+8:  ldr     r2, [rSELF, #offThread_method]    @ r2<- current method
+    EXPORT_PC()                         @ resolve() could throw
+    ldr     r0, [r2, #offMethod_clazz]  @ r0<- method->clazz
+    bl      dvmResolveInstField         @ r0<- resolved InstField ptr
+    cmp     r0, #0                      @ success?
+    bne     .L${opcode}_finish          @ yes, finish up
+    b       common_exceptionThrown
+%break
+
+    /*
+     * Currently:
+     *  r0 holds resolved field
+     *  r9 holds object
+     */
+.L${opcode}_finish:
+    @bl      common_squeak${sqnum}
+    mov     r1, rINST, lsr #8           @ r1<- A+
+    ldr     r3, [r0, #offInstField_byteOffset]  @ r3<- byte offset of field
+    and     r1, r1, #15                 @ r1<- A
+    cmp     r9, #0                      @ check object for null
+    GET_VREG(r0, r1)                    @ r0<- fp[A]
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r2)
+    GET_VREG_TAINT(r10, r1, r2)
+    ldr     r11, [rSELF, #offThread_cardTable]  @ r11<- card table base
+// end WITH_TAINT_TRACKING
+    beq     common_errNullObject        @ object was null
+    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+    $prebarrier                        @ releasing store
+// begin WITH_TAINT_TRACKING
+//    .if     $volatile
+//    add     r2, r9, r3                  @ r2<- target address
+//    mov     r1, r10                     @ r1<-taint
+//    bl      dvmQuasiAtomicSwap64        @ stores r0/r1 into addr r2
+//    .else
+    str     r0, [r9, r3]                @ obj.field (32 bits)<- r0
+    add     r3, r3, #4
+    str     r10, [r9, r3]
+//    .endif
+    $postbarrier
+    cmp     r0, #0                      @ stored a null reference?
+    strneb  r11, [r11, r9, lsr #GC_CARD_SHIFT]  @ mark card if not
+// end WITH_TAINT_TRACKING
+    GOTO_OPCODE(ip)                     @ jump to next instruction
diff --git a/vm/mterp/armv5te_taint/OP_IPUT_OBJECT_QUICK.S b/vm/mterp/armv5te_taint/OP_IPUT_OBJECT_QUICK.S
new file mode 100644
index 0000000..1ee004e
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_IPUT_OBJECT_QUICK.S
@@ -0,0 +1,33 @@
+%verify "executed"
+%verify "null object"
+    /* For: iput-object-quick */
+    /* op vA, vB, offset@CCCC */
+    mov     r2, rINST, lsr #12          @ r2<- B
+    GET_VREG(r3, r2)                    @ r3<- fp[B], the object pointer
+    FETCH(r1, 1)                        @ r1<- field byte offset
+    cmp     r3, #0                      @ check object for null
+    mov     r2, rINST, lsr #8           @ r2<- A(+)
+    beq     common_errNullObject        @ object was null
+    and     r2, r2, #15
+    GET_VREG(r0, r2)                    @ r0<- fp[A]
+// begin WITH_TAINT_TRACKING
+    bl    .L${opcode}_taint_prop
+// end WITH_TAINT_TRACKING
+    cmp     r0, #0
+    strneb  r2, [r2, r3, lsr #GC_CARD_SHIFT] @ mark card based on obj head
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+    GOTO_OPCODE(ip)                     @ jump to next instruction
+%break
+
+.L${opcode}_taint_prop:
+    SET_TAINT_FP(r9)
+    GET_VREG_TAINT(r10, r2, r9)
+    ldr     r2, [rSELF, #offThread_cardTable]  @ r2<- card table base
+    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
+    str     r0, [r3, r1]                @ obj.field (always 32 bits)<- r0
+    add	    r1, r1, #4
+    str	    r10, [r3, r1]
+    bx	    lr
+
+
+
diff --git a/vm/mterp/armv5te_taint/OP_IPUT_OBJECT_VOLATILE.S b/vm/mterp/armv5te_taint/OP_IPUT_OBJECT_VOLATILE.S
new file mode 100644
index 0000000..8fc2f2b
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_IPUT_OBJECT_VOLATILE.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te_taint/OP_IPUT_OBJECT.S" {"volatile":"1"}
diff --git a/vm/mterp/armv5te_taint/OP_IPUT_QUICK.S b/vm/mterp/armv5te_taint/OP_IPUT_QUICK.S
new file mode 100644
index 0000000..65f0996
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_IPUT_QUICK.S
@@ -0,0 +1,25 @@
+%verify "executed"
+%verify "null object"
+    /* For: iput-quick */
+    /* op vA, vB, offset@CCCC */
+    mov     r2, rINST, lsr #12          @ r2<- B
+    GET_VREG(r3, r2)                    @ r3<- fp[B], the object pointer
+    FETCH(r1, 1)                        @ r1<- field byte offset
+    cmp     r3, #0                      @ check object for null
+    mov     r2, rINST, lsr #8           @ r2<- A(+)
+    beq     common_errNullObject        @ object was null
+    and     r2, r2, #15
+    GET_VREG(r0, r2)                    @ r0<- fp[A]
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r9)
+    GET_VREG_TAINT(r10, r2, r9)
+// end WITH_TAINT_TRACKING
+    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
+    str     r0, [r3, r1]                @ obj.field (always 32 bits)<- r0
+// begin WITH_TAINT_TRACKING
+    add	    r1, r1, #4
+    str     r10, [r3, r1]
+// end WITH_TAINT_TRACKING
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+    GOTO_OPCODE(ip)                     @ jump to next instruction
+
diff --git a/vm/mterp/armv5te_taint/OP_IPUT_SHORT.S b/vm/mterp/armv5te_taint/OP_IPUT_SHORT.S
new file mode 100644
index 0000000..a2ed6fd
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_IPUT_SHORT.S
@@ -0,0 +1,3 @@
+%verify "executed"
+@include "armv5te_taint/OP_IPUT.S" { "store":"strh", "sqnum":"4" }
+%include "armv5te_taint/OP_IPUT.S" { "store":"str", "sqnum":"4" }
diff --git a/vm/mterp/armv5te_taint/OP_IPUT_VOLATILE.S b/vm/mterp/armv5te_taint/OP_IPUT_VOLATILE.S
new file mode 100644
index 0000000..3d4d714
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_IPUT_VOLATILE.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te_taint/OP_IPUT.S" {"volatile":"1"}
diff --git a/vm/mterp/armv5te_taint/OP_IPUT_WIDE.S b/vm/mterp/armv5te_taint/OP_IPUT_WIDE.S
new file mode 100644
index 0000000..14382e2
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_IPUT_WIDE.S
@@ -0,0 +1,60 @@
+%default {"volatile":"0"}
+%verify "executed"
+%verify "null object"
+%verify "field already resolved"
+%verify "field not yet resolved"
+%verify "field cannot be resolved"
+    /* iput-wide vA, vB, field@CCCC */
+    mov     r0, rINST, lsr #12          @ r0<- B
+    ldr     r3, [rSELF, #offThread_methodClassDex]    @ r3<- DvmDex
+    FETCH(r1, 1)                        @ r1<- field ref CCCC
+    ldr     r2, [r3, #offDvmDex_pResFields] @ r2<- pResFields
+    GET_VREG(r9, r0)                    @ r9<- fp[B], the object pointer
+    ldr     r0, [r2, r1, lsl #2]        @ r0<- resolved InstField ptr
+    cmp     r0, #0                      @ is resolved entry null?
+    bne     .L${opcode}_finish          @ no, already resolved
+8:  ldr     r2, [rSELF, #offThread_method] @ r2<- current method
+    EXPORT_PC()                         @ resolve() could throw
+    ldr     r0, [r2, #offMethod_clazz]  @ r0<- method->clazz
+    bl      dvmResolveInstField         @ r0<- resolved InstField ptr
+    cmp     r0, #0                      @ success?
+    bne     .L${opcode}_finish          @ yes, finish up
+    b       common_exceptionThrown
+%break
+
+    /*
+     * Currently:
+     *  r0 holds resolved field
+     *  r9 holds object
+     */
+.L${opcode}_finish:
+    mov     r2, rINST, lsr #8           @ r2<- A+
+    cmp     r9, #0                      @ check object for null
+    and     r2, r2, #15                 @ r2<- A
+    ldr     r3, [r0, #offInstField_byteOffset]  @ r3<- byte offset of field
+// begin WITH_TAINT_TRACKING
+    add     r2, rFP, r2, lsl #3         @ r3<- &fp[A]
+// end WITH_TAINT_TRACKING
+    beq     common_errNullObject        @ object was null
+    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
+// begin WITH_TAINT_TRACKING
+//    ldmia   r2, {r0-r1}                 @ r0/r1<- fp[A]
+    ldr	    r0, [r2, #0]
+    ldr     r1, [r2, #8]
+    ldr	    r10, [r2, #4]
+// end WITH_TAINT_TRACKING
+    .if     $volatile
+    stmfd   sp!, {r3}
+    add     r2, r9, r3                  @ r2<- target address
+    bl      dvmQuasiAtomicSwap64Sync    @ stores r0/r1 into addr r2
+    ldmfd   sp!, {r3}
+    .else
+    strd    r0, [r9, r3]                  @ obj.field (64 bits, aligned)<- r0/r1
+    .endif
+// begin WITH_TAINT_TRACKING
+    add	    r3, r3, #8
+    str	    r10, [r9, r3]
+// end WITH_TAINT_TRACKING
+    GET_INST_OPCODE(r10)                 @ extract opcode from rINST
+    GOTO_OPCODE(r10)                     @ jump to next instruction
+
diff --git a/vm/mterp/armv5te_taint/OP_IPUT_WIDE_QUICK.S b/vm/mterp/armv5te_taint/OP_IPUT_WIDE_QUICK.S
new file mode 100644
index 0000000..682fd75
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_IPUT_WIDE_QUICK.S
@@ -0,0 +1,31 @@
+%verify "executed"
+%verify "null object"
+    /* iput-wide-quick vA, vB, offset@CCCC */
+    mov     r0, rINST, lsr #8           @ r0<- A(+)
+    mov     r1, rINST, lsr #12          @ r1<- B
+    and     r0, r0, #15
+    GET_VREG(r2, r1)                    @ r2<- fp[B], the object pointer
+// begin WITH_TAINT_TRACKING
+    bl iput_wide_quick_taint_prop
+// end WITH_TAINT_TRACKING
+    beq     common_errNullObject        @ object was null
+    FETCH(r3, 1)                        @ r3<- field byte offset
+    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
+    strd    r0, [r2, r3]                @ obj.field (64 bits, aligned)<- r0/r1
+// begin WITH_TAINT_TRACKING
+    add     r3, r3, #8
+    str     r9, [r2, r3]
+// end WITH_TAINT_TRACKING
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+    GOTO_OPCODE(ip)                     @ jump to next instruction
+
+%break
+
+iput_wide_quick_taint_prop:
+    add     r3, rFP, r0, lsl #3         @ r3<- &fp[A]
+    cmp     r2, #0                      @ check object for null
+//    ldmia   r3, {r0-r1}                 @ r0/r1<- fp[A]
+    ldr     r0, [r3, #0]
+    ldr     r1, [r3, #8]
+    ldr     r9, [r3, #4]
+    bx      lr
diff --git a/vm/mterp/armv5te_taint/OP_IPUT_WIDE_VOLATILE.S b/vm/mterp/armv5te_taint/OP_IPUT_WIDE_VOLATILE.S
new file mode 100644
index 0000000..e653d6b
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_IPUT_WIDE_VOLATILE.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te_taint/OP_IPUT_WIDE.S" {"volatile":"1"}
diff --git a/vm/mterp/armv5te_taint/OP_LONG_TO_DOUBLE.S b/vm/mterp/armv5te_taint/OP_LONG_TO_DOUBLE.S
new file mode 100644
index 0000000..da6fc00
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_LONG_TO_DOUBLE.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te_taint/unopWide.S" {"instr":"bl      __aeabi_l2d"}
diff --git a/vm/mterp/armv5te_taint/OP_LONG_TO_FLOAT.S b/vm/mterp/armv5te_taint/OP_LONG_TO_FLOAT.S
new file mode 100644
index 0000000..4a70215
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_LONG_TO_FLOAT.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te_taint/unopNarrower.S" {"instr":"bl      __aeabi_l2f"}
diff --git a/vm/mterp/armv5te_taint/OP_LONG_TO_INT.S b/vm/mterp/armv5te_taint/OP_LONG_TO_INT.S
new file mode 100644
index 0000000..9ae56fb
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_LONG_TO_INT.S
@@ -0,0 +1,3 @@
+%verify "executed"
+/* we ignore the high word, making this equivalent to a 32-bit reg move */
+%include "armv5te_taint/OP_MOVE.S"
diff --git a/vm/mterp/armv5te_taint/OP_MONITOR_ENTER.S b/vm/mterp/armv5te_taint/OP_MONITOR_ENTER.S
new file mode 100644
index 0000000..ba5a144
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_MONITOR_ENTER.S
@@ -0,0 +1,16 @@
+%verify "executed"
+%verify "exception for null object"
+    /*
+     * Synchronize on an object.
+     */
+    /* monitor-enter vAA */
+    mov     r2, rINST, lsr #8           @ r2<- AA
+    GET_VREG(r1, r2)                    @ r1<- vAA (object)
+    mov     r0, rSELF                   @ r0<- self
+    cmp     r1, #0                      @ null object?
+    EXPORT_PC()                         @ need for precise GC
+    beq     common_errNullObject        @ null object, throw an exception
+    FETCH_ADVANCE_INST(1)               @ advance rPC, load rINST
+    bl      dvmLockObject               @ call(self, obj)
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+    GOTO_OPCODE(ip)                     @ jump to next instruction
diff --git a/vm/mterp/armv5te_taint/OP_MONITOR_EXIT.S b/vm/mterp/armv5te_taint/OP_MONITOR_EXIT.S
new file mode 100644
index 0000000..9f36f0e
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_MONITOR_EXIT.S
@@ -0,0 +1,26 @@
+%verify "executed"
+%verify "exception for null object (impossible in javac)"
+%verify "dvmUnlockObject fails"
+    /*
+     * Unlock an object.
+     *
+     * Exceptions that occur when unlocking a monitor need to appear as
+     * if they happened at the following instruction.  See the Dalvik
+     * instruction spec.
+     */
+    /* monitor-exit vAA */
+    mov     r2, rINST, lsr #8           @ r2<- AA
+    EXPORT_PC()                         @ before fetch: export the PC
+    GET_VREG(r1, r2)                    @ r1<- vAA (object)
+    cmp     r1, #0                      @ null object?
+    beq     1f                          @ yes
+    mov     r0, rSELF                   @ r0<- self
+    bl      dvmUnlockObject             @ r0<- success for unlock(self, obj)
+    cmp     r0, #0                      @ failed?
+    FETCH_ADVANCE_INST(1)               @ before throw: advance rPC, load rINST
+    beq     common_exceptionThrown      @ yes, exception is pending
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+    GOTO_OPCODE(ip)                     @ jump to next instruction
+1:
+    FETCH_ADVANCE_INST(1)               @ advance before throw
+    b      common_errNullObject
diff --git a/vm/mterp/armv5te_taint/OP_MOVE.S b/vm/mterp/armv5te_taint/OP_MOVE.S
new file mode 100644
index 0000000..42fdcb4
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_MOVE.S
@@ -0,0 +1,17 @@
+%verify "executed"
+    /* for move, move-object, long-to-int */
+    /* op vA, vB */
+    mov     r1, rINST, lsr #12          @ r1<- B from 15:12
+    mov     r0, rINST, lsr #8           @ r0<- A from 11:8
+    FETCH_ADVANCE_INST(1)               @ advance rPC, load rINST
+    GET_VREG(r2, r1)                    @ r2<- fp[B]
+    and     r0, r0, #15
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r3)
+    GET_VREG_TAINT(r1, r1, r3)
+    SET_VREG_TAINT(r1, r0, r3)
+// end WITH_TAINT_TRACKING
+    GET_INST_OPCODE(ip)                 @ ip<- opcode from rINST
+    SET_VREG(r2, r0)                    @ fp[A]<- r2
+    GOTO_OPCODE(ip)                     @ execute next instruction
+
diff --git a/vm/mterp/armv5te_taint/OP_MOVE_16.S b/vm/mterp/armv5te_taint/OP_MOVE_16.S
new file mode 100644
index 0000000..872e091
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_MOVE_16.S
@@ -0,0 +1,16 @@
+%verify "executed"
+    /* for: move/16, move-object/16 */
+    /* op vAAAA, vBBBB */
+    FETCH(r1, 2)                        @ r1<- BBBB
+    FETCH(r0, 1)                        @ r0<- AAAA
+    FETCH_ADVANCE_INST(3)               @ advance rPC, load rINST
+    GET_VREG(r2, r1)                    @ r2<- fp[BBBB]
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r3)
+    GET_VREG_TAINT(r1, r1, r3)
+    SET_VREG_TAINT(r1, r0, r3)
+// end WITH_TAINT_TRACKING
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+    SET_VREG(r2, r0)                    @ fp[AAAA]<- r2
+    GOTO_OPCODE(ip)                     @ jump to next instruction
+
diff --git a/vm/mterp/armv5te_taint/OP_MOVE_EXCEPTION.S b/vm/mterp/armv5te_taint/OP_MOVE_EXCEPTION.S
new file mode 100644
index 0000000..a7a85f3
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_MOVE_EXCEPTION.S
@@ -0,0 +1,15 @@
+%verify "executed"
+    /* move-exception vAA */
+    mov     r2, rINST, lsr #8           @ r2<- AA
+    ldr     r3, [rSELF, #offThread_exception]  @ r3<- dvmGetException bypass
+    mov     r1, #0                      @ r1<- 0
+    FETCH_ADVANCE_INST(1)               @ advance rPC, load rINST
+    SET_VREG(r3, r2)                    @ fp[AA]<- exception obj
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r3)
+    SET_TAINT_CLEAR(r9)
+    SET_VREG_TAINT(r9, r2, r3)
+// end WITH_TAINT_TRACKING
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+    str     r1, [rSELF, #offThread_exception]  @ dvmClearException bypass
+    GOTO_OPCODE(ip)                     @ jump to next instruction
diff --git a/vm/mterp/armv5te_taint/OP_MOVE_FROM16.S b/vm/mterp/armv5te_taint/OP_MOVE_FROM16.S
new file mode 100644
index 0000000..bf57f1a
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_MOVE_FROM16.S
@@ -0,0 +1,16 @@
+%verify "executed"
+    /* for: move/from16, move-object/from16 */
+    /* op vAA, vBBBB */
+    FETCH(r1, 1)                        @ r1<- BBBB
+    mov     r0, rINST, lsr #8           @ r0<- AA
+    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
+    GET_VREG(r2, r1)                    @ r2<- fp[BBBB]
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r3)
+    GET_VREG_TAINT(r1, r1, r3)
+    SET_VREG_TAINT(r1, r0, r3)
+// end WITH_TAINT_TRACKING
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+    SET_VREG(r2, r0)                    @ fp[AA]<- r2
+    GOTO_OPCODE(ip)                     @ jump to next instruction
+
diff --git a/vm/mterp/armv5te_taint/OP_MOVE_OBJECT.S b/vm/mterp/armv5te_taint/OP_MOVE_OBJECT.S
new file mode 100644
index 0000000..0c2f8fa
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_MOVE_OBJECT.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te_taint/OP_MOVE.S"
diff --git a/vm/mterp/armv5te_taint/OP_MOVE_OBJECT_16.S b/vm/mterp/armv5te_taint/OP_MOVE_OBJECT_16.S
new file mode 100644
index 0000000..6acec7d
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_MOVE_OBJECT_16.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te_taint/OP_MOVE_16.S"
diff --git a/vm/mterp/armv5te_taint/OP_MOVE_OBJECT_FROM16.S b/vm/mterp/armv5te_taint/OP_MOVE_OBJECT_FROM16.S
new file mode 100644
index 0000000..1df9a41
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_MOVE_OBJECT_FROM16.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te_taint/OP_MOVE_FROM16.S"
diff --git a/vm/mterp/armv5te_taint/OP_MOVE_RESULT.S b/vm/mterp/armv5te_taint/OP_MOVE_RESULT.S
new file mode 100644
index 0000000..b3bf728
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_MOVE_RESULT.S
@@ -0,0 +1,14 @@
+%verify "executed"
+    /* for: move-result, move-result-object */
+    /* op vAA */
+    mov     r2, rINST, lsr #8           @ r2<- AA
+    FETCH_ADVANCE_INST(1)               @ advance rPC, load rINST
+    ldr     r0, [rSELF, #offThread_retval]    @ r0<- self->retval.i
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+    SET_VREG(r0, r2)                    @ fp[AA]<- r0
+// begin WITH_TAINT_TRACKING
+    ldr     r0, [rSELF, #offThread_rtaint]
+    SET_TAINT_FP(r1)
+    SET_VREG_TAINT(r0, r2, r1)
+// end WITH_TAINT_TRACKING
+    GOTO_OPCODE(ip)                     @ jump to next instruction
diff --git a/vm/mterp/armv5te_taint/OP_MOVE_RESULT_OBJECT.S b/vm/mterp/armv5te_taint/OP_MOVE_RESULT_OBJECT.S
new file mode 100644
index 0000000..3d3620a
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_MOVE_RESULT_OBJECT.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te_taint/OP_MOVE_RESULT.S"
diff --git a/vm/mterp/armv5te_taint/OP_MOVE_RESULT_WIDE.S b/vm/mterp/armv5te_taint/OP_MOVE_RESULT_WIDE.S
new file mode 100644
index 0000000..09c7cf6
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_MOVE_RESULT_WIDE.S
@@ -0,0 +1,20 @@
+%verify "executed"
+    /* move-result-wide vAA */
+    mov     r2, rINST, lsr #8           @ r2<- AA
+    add     r3, rSELF, #offThread_retval  @ r3<- &self->retval
+// begin WITH_TAINT_TRACKING
+    add     r2, rFP, r2, lsl #3         @ r2<- &fp[AA]
+// end WITH_TAINT_TRACKING
+    ldmia   r3, {r0-r1}                 @ r0/r1<- retval.j
+    FETCH_ADVANCE_INST(1)               @ advance rPC, load rINST
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+// begin WITH_TAINT_TRACKING
+//    stmia   r2, {r0-r1}                 @ fp[AA]<- r0/r1
+    ldr r3, [rSELF, #offThread_rtaint]
+    str r0, [r2, #0]
+    str r3, [r2, #4]
+    str r1, [r2, #8]
+    str r3, [r2, #12]
+// end WITH_TAINT_TRACKING
+    GOTO_OPCODE(ip)                     @ jump to next instruction
+
diff --git a/vm/mterp/armv5te_taint/OP_MOVE_WIDE.S b/vm/mterp/armv5te_taint/OP_MOVE_WIDE.S
new file mode 100644
index 0000000..9240f0d
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_MOVE_WIDE.S
@@ -0,0 +1,18 @@
+%verify "executed"
+    /* move-wide vA, vB */
+    /* NOTE: regs can overlap, e.g. "move v6,v7" or "move v7,v6" */
+    mov     r2, rINST, lsr #8           @ r2<- A(+)
+    mov     r3, rINST, lsr #12          @ r3<- B
+    and     r2, r2, #15
+// begin WITH_TAINT_TRACKING
+    add     r3, rFP, r3, lsl #3         @ r3<- &fp[B]
+    add     r9, rFP, r2, lsl #3         @ r9<- &fp[A]
+    ldmia   r3, {r0-r3}                 @ r0/r1<- fp[B]
+// end WITH_TAINT_TRACKING
+    FETCH_ADVANCE_INST(1)               @ advance rPC, load rINST
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+// begin WITH_TAINT_TRACKING
+    stmia   r9, {r0-r3}                 @ fp[A]<- r0/r1
+// end WITH_TAINT_TRACKING
+    GOTO_OPCODE(ip)                     @ jump to next instruction
+
diff --git a/vm/mterp/armv5te_taint/OP_MOVE_WIDE_16.S b/vm/mterp/armv5te_taint/OP_MOVE_WIDE_16.S
new file mode 100644
index 0000000..40d448d
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_MOVE_WIDE_16.S
@@ -0,0 +1,17 @@
+%verify "executed"
+    /* move-wide/16 vAAAA, vBBBB */
+    /* NOTE: regs can overlap, e.g. "move v6,v7" or "move v7,v6" */
+    FETCH(r3, 2)                        @ r3<- BBBB
+    FETCH(r2, 1)                        @ r2<- AAAA
+// begin WITH_TAINT_TRACKING
+    add     r3, rFP, r3, lsl #3         @ r3<- &fp[BBBB]
+    add     r9, rFP, r2, lsl #3         @ r9<- &fp[AAAA]
+    ldmia   r3, {r0-r3}                 @ r0/r1<- fp[BBBB]
+// end WITH_TAINT_TRACKING
+    FETCH_ADVANCE_INST(3)               @ advance rPC, load rINST
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+// begin WITH_TAINT_TRACKING
+    stmia   r9, {r0-r3}                 @ fp[AAAA]<- r0/r1
+// end WITH_TAINT_TRACKING
+    GOTO_OPCODE(ip)                     @ jump to next instruction
+
diff --git a/vm/mterp/armv5te_taint/OP_MOVE_WIDE_FROM16.S b/vm/mterp/armv5te_taint/OP_MOVE_WIDE_FROM16.S
new file mode 100644
index 0000000..8e17891
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_MOVE_WIDE_FROM16.S
@@ -0,0 +1,17 @@
+%verify "executed"
+    /* move-wide/from16 vAA, vBBBB */
+    /* NOTE: regs can overlap, e.g. "move v6,v7" or "move v7,v6" */
+    FETCH(r3, 1)                        @ r3<- BBBB
+    mov     r2, rINST, lsr #8           @ r2<- AA
+// begin WITH_TAINT_TRACKING
+    add     r3, rFP, r3, lsl #3         @ r3<- &fp[BBBB]
+    add     r9, rFP, r2, lsl #3         @ r9<- &fp[AA]
+    ldmia   r3, {r0-r3}                 @ r0/r1<- fp[BBBB]
+// end WITH_TAINT_TRACKING
+    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+// begin WITH_TAINT_TRACKING
+    stmia   r9, {r0-r3}                 @ fp[AA]<- r0/r1
+// end WITH_TAINT_TRACKING
+    GOTO_OPCODE(ip)                     @ jump to next instruction
+
diff --git a/vm/mterp/armv5te_taint/OP_MUL_DOUBLE.S b/vm/mterp/armv5te_taint/OP_MUL_DOUBLE.S
new file mode 100644
index 0000000..348f7cf
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_MUL_DOUBLE.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te_taint/binopWide.S" {"instr":"bl      __aeabi_dmul"}
diff --git a/vm/mterp/armv5te_taint/OP_MUL_DOUBLE_2ADDR.S b/vm/mterp/armv5te_taint/OP_MUL_DOUBLE_2ADDR.S
new file mode 100644
index 0000000..3a77339
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_MUL_DOUBLE_2ADDR.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te_taint/binopWide2addr.S" {"instr":"bl      __aeabi_dmul"}
diff --git a/vm/mterp/armv5te_taint/OP_MUL_FLOAT.S b/vm/mterp/armv5te_taint/OP_MUL_FLOAT.S
new file mode 100644
index 0000000..788d975
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_MUL_FLOAT.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te_taint/binop.S" {"instr":"bl      __aeabi_fmul"}
diff --git a/vm/mterp/armv5te_taint/OP_MUL_FLOAT_2ADDR.S b/vm/mterp/armv5te_taint/OP_MUL_FLOAT_2ADDR.S
new file mode 100644
index 0000000..7eb5364
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_MUL_FLOAT_2ADDR.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te_taint/binop2addr.S" {"instr":"bl      __aeabi_fmul"}
diff --git a/vm/mterp/armv5te_taint/OP_MUL_INT.S b/vm/mterp/armv5te_taint/OP_MUL_INT.S
new file mode 100644
index 0000000..08ac7d1
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_MUL_INT.S
@@ -0,0 +1,3 @@
+%verify "executed"
+/* must be "mul r0, r1, r0" -- "r0, r0, r1" is illegal */
+%include "armv5te_taint/binop.S" {"instr":"mul     r0, r1, r0"}
diff --git a/vm/mterp/armv5te_taint/OP_MUL_INT_2ADDR.S b/vm/mterp/armv5te_taint/OP_MUL_INT_2ADDR.S
new file mode 100644
index 0000000..544b1d6
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_MUL_INT_2ADDR.S
@@ -0,0 +1,3 @@
+%verify "executed"
+/* must be "mul r0, r1, r0" -- "r0, r0, r1" is illegal */
+%include "armv5te_taint/binop2addr.S" {"instr":"mul     r0, r1, r0"}
diff --git a/vm/mterp/armv5te_taint/OP_MUL_INT_LIT16.S b/vm/mterp/armv5te_taint/OP_MUL_INT_LIT16.S
new file mode 100644
index 0000000..1ca060a
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_MUL_INT_LIT16.S
@@ -0,0 +1,3 @@
+%verify "executed"
+/* must be "mul r0, r1, r0" -- "r0, r0, r1" is illegal */
+%include "armv5te_taint/binopLit16.S" {"instr":"mul     r0, r1, r0"}
diff --git a/vm/mterp/armv5te_taint/OP_MUL_INT_LIT8.S b/vm/mterp/armv5te_taint/OP_MUL_INT_LIT8.S
new file mode 100644
index 0000000..c97f476
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_MUL_INT_LIT8.S
@@ -0,0 +1,3 @@
+%verify "executed"
+/* must be "mul r0, r1, r0" -- "r0, r0, r1" is illegal */
+%include "armv5te_taint/binopLit8.S" {"instr":"mul     r0, r1, r0"}
diff --git a/vm/mterp/armv5te_taint/OP_MUL_LONG.S b/vm/mterp/armv5te_taint/OP_MUL_LONG.S
new file mode 100644
index 0000000..c1a09ec
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_MUL_LONG.S
@@ -0,0 +1,64 @@
+%verify "executed"
+    /*
+     * Signed 64-bit integer multiply.
+     *
+     * Consider WXxYZ (r1r0 x r3r2) with a long multiply:
+     *        WX
+     *      x YZ
+     *  --------
+     *     ZW ZX
+     *  YW YX
+     *
+     * The low word of the result holds ZX, the high word holds
+     * (ZW+YX) + (the high overflow from ZX).  YW doesn't matter because
+     * it doesn't fit in the low 64 bits.
+     *
+     * Unlike most ARM math operations, multiply instructions have
+     * restrictions on using the same register more than once (Rd and Rm
+     * cannot be the same).
+     */
+    /* mul-long vAA, vBB, vCC */
+    FETCH(r0, 1)                        @ r0<- CCBB
+    and     r2, r0, #255                @ r2<- BB
+    mov     r3, r0, lsr #8              @ r3<- CC
+// begin WITH_TAINT_TRACKING
+    bl		mul_long_taint_prop
+// end WITH_TAINT_TRACKING
+    mul     ip, r2, r1                  @  ip<- ZxW
+    umull   r9, r10, r2, r0             @  r9/r10 <- ZxX
+    mla     r2, r0, r3, ip              @  r2<- YxX + (ZxW)
+    mov     r0, rINST, lsr #8           @ r0<- AA
+    add     r10, r2, r10                @  r10<- r10 + low(ZxW + (YxX))
+// begin WITH_TAINT_TRACKING
+    add     r0, rFP, r0, lsl #3         @ r0<- &fp[AA]
+// end WITH_TAINT_TRACKING
+    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
+    b       .L${opcode}_finish
+%break
+
+.L${opcode}_finish:
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+// begin WITH_TAINT_TRACKING
+//    stmia   r0, {r9-r10}                @ vAA/vAA+1<- r9/r10
+    str     r9, [r0, #0]
+    str     r10, [r0, #8]
+    str     r10, [r0, #12]
+    ldmfd   sp!, {r10}
+    str     r10, [r0, #4]
+// end WITH_TAINT_TRACKING
+    GOTO_OPCODE(ip)                     @ jump to next instruction
+
+mul_long_taint_prop:
+    add     r2, rFP, r2, lsl #3         @ r2<- &fp[BB]
+    add     r3, rFP, r3, lsl #3         @ r3<- &fp[CC]
+//    ldmia   r2, {r0-r1}                 @ r0/r1<- vBB/vBB+1
+    ldr     r0, [r2, #0]
+    ldr     r9, [r2, #4]
+    ldr     r1, [r2, #8]
+//    ldmia   r3, {r2-r3}                 @ r2/r3<- vCC/vCC+1
+    ldr     r2, [r3, #0]
+    ldr     r10, [r3, #4]
+    ldr     r3, [r3, #8]
+    orr     r10, r9, r10
+    stmfd   sp!, {r10}
+    bx      lr
diff --git a/vm/mterp/armv5te_taint/OP_MUL_LONG_2ADDR.S b/vm/mterp/armv5te_taint/OP_MUL_LONG_2ADDR.S
new file mode 100644
index 0000000..43a4a57
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_MUL_LONG_2ADDR.S
@@ -0,0 +1,49 @@
+%verify "executed"
+    /*
+     * Signed 64-bit integer multiply, "/2addr" version.
+     *
+     * See OP_MUL_LONG for an explanation.
+     *
+     * We get a little tight on registers, so to avoid looking up &fp[A]
+     * again we stuff it into rINST.
+     */
+    /* mul-long/2addr vA, vB */
+    mov     r9, rINST, lsr #8           @ r9<- A+
+    mov     r1, rINST, lsr #12          @ r1<- B
+// begin WITH_TAINT_TRACKING
+    bl      mul_long_2addr_taint_prop
+// end WITH_TAINT_TRACKING
+    umull   r9, r10, r2, r0             @  r9/r10 <- ZxX
+    mla     r2, r0, r3, ip              @  r2<- YxX + (ZxW)
+    mov     r0, rINST                   @ r0<- &fp[A] (free up rINST)
+    FETCH_ADVANCE_INST(1)               @ advance rPC, load rINST
+    add     r10, r2, r10                @  r10<- r10 + low(ZxW + (YxX))
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+// begin WITH_TAINT_TRACKING
+//    stmia   r0, {r9-r10}                @ vAA/vAA+1<- r9/r10
+    str     r9, [r0, #0]
+    str     r10, [r0, #8]
+    str     r10, [r0, #12]
+    ldmfd   sp!, {r10}
+    str     r10, [r0, #4]
+// end WITH_TAINT_TRACKING
+    GOTO_OPCODE(ip)                     @ jump to next instruction
+
+%break
+
+mul_long_2addr_taint_prop:
+    and     r9, r9, #15
+    add     r1, rFP, r1, lsl #3         @ r1<- &fp[B]
+    add     rINST, rFP, r9, lsl #3      @ rINST<- &fp[A]
+//    ldmia   r1, {r2-r3}                 @ r2/r3<- vBB/vBB+1
+    ldr     r2, [r1, #0]
+    ldr     r9, [r1, #4]
+    ldr     r3, [r1, #8]
+//    ldmia   rINST, {r0-r1}              @ r0/r1<- vAA/vAA+1
+    ldr     r0, [rINST, #0]
+    ldr     r10, [rINST, #4]
+    ldr     r1, [rINST, #8]
+    orr     r10, r9, r10
+    stmfd   sp!, {r10}
+    mul     ip, r2, r1                  @  ip<- ZxW
+    bx      lr
diff --git a/vm/mterp/armv5te_taint/OP_NEG_DOUBLE.S b/vm/mterp/armv5te_taint/OP_NEG_DOUBLE.S
new file mode 100644
index 0000000..08533d2
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_NEG_DOUBLE.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te_taint/unopWide.S" {"instr":"add     r1, r1, #0x80000000"}
diff --git a/vm/mterp/armv5te_taint/OP_NEG_FLOAT.S b/vm/mterp/armv5te_taint/OP_NEG_FLOAT.S
new file mode 100644
index 0000000..3e58179
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_NEG_FLOAT.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te_taint/unop.S" {"instr":"add     r0, r0, #0x80000000"}
diff --git a/vm/mterp/armv5te_taint/OP_NEG_INT.S b/vm/mterp/armv5te_taint/OP_NEG_INT.S
new file mode 100644
index 0000000..39ae8a3
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_NEG_INT.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te_taint/unop.S" {"instr":"rsb     r0, r0, #0"}
diff --git a/vm/mterp/armv5te_taint/OP_NEG_LONG.S b/vm/mterp/armv5te_taint/OP_NEG_LONG.S
new file mode 100644
index 0000000..a3aeade
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_NEG_LONG.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te_taint/unopWide.S" {"preinstr":"rsbs    r0, r0, #0", "instr":"rsc     r1, r1, #0"}
diff --git a/vm/mterp/armv5te_taint/OP_NEW_ARRAY.S b/vm/mterp/armv5te_taint/OP_NEW_ARRAY.S
new file mode 100644
index 0000000..a4075db
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_NEW_ARRAY.S
@@ -0,0 +1,66 @@
+%verify "executed"
+%verify "negative array length"
+%verify "allocation fails"
+    /*
+     * Allocate an array of objects, specified with the array class
+     * and a count.
+     *
+     * The verifier guarantees that this is an array class, so we don't
+     * check for it here.
+     */
+    /* new-array vA, vB, class@CCCC */
+    mov     r0, rINST, lsr #12          @ r0<- B
+    FETCH(r2, 1)                        @ r2<- CCCC
+    ldr     r3, [rSELF, #offThread_methodClassDex]    @ r3<- pDvmDex
+    GET_VREG(r1, r0)                    @ r1<- vB (array length)
+    ldr     r3, [r3, #offDvmDex_pResClasses]    @ r3<- pDvmDex->pResClasses
+    cmp     r1, #0                      @ check length
+    ldr     r0, [r3, r2, lsl #2]        @ r0<- resolved class
+    bmi     common_errNegativeArraySize @ negative length, bail - len in r1
+    cmp     r0, #0                      @ already resolved?
+    EXPORT_PC()                         @ req'd for resolve, alloc
+    bne     .L${opcode}_finish          @ resolved, continue
+    b       .L${opcode}_resolve         @ do resolve now
+%break
+
+
+    /*
+     * Resolve class.  (This is an uncommon case.)
+     *
+     *  r1 holds array length
+     *  r2 holds class ref CCCC
+     */
+.L${opcode}_resolve:
+    ldr     r3, [rSELF, #offThread_method] @ r3<- self->method
+    mov     r9, r1                      @ r9<- length (save)
+    mov     r1, r2                      @ r1<- CCCC
+    mov     r2, #0                      @ r2<- false
+    ldr     r0, [r3, #offMethod_clazz]  @ r0<- method->clazz
+    bl      dvmResolveClass             @ r0<- call(clazz, ref)
+    cmp     r0, #0                      @ got null?
+    mov     r1, r9                      @ r1<- length (restore)
+    beq     common_exceptionThrown      @ yes, handle exception
+    @ fall through to ${opcode}_finish
+
+    /*
+     * Finish allocation.
+     *
+     *  r0 holds class
+     *  r1 holds array length
+     */
+.L${opcode}_finish:
+    mov     r2, #ALLOC_DONT_TRACK       @ don't track in local refs table
+    bl      dvmAllocArrayByClass        @ r0<- call(clazz, length, flags)
+    cmp     r0, #0                      @ failed?
+    mov     r2, rINST, lsr #8           @ r2<- A+
+    beq     common_exceptionThrown      @ yes, handle the exception
+    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
+    and     r2, r2, #15                 @ r2<- A
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r1)
+    SET_TAINT_CLEAR(r3)
+    SET_VREG_TAINT(r3, r2, r1)
+// end WITH_TAINT_TRACKING
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+    SET_VREG(r0, r2)                    @ vA<- r0
+    GOTO_OPCODE(ip)                     @ jump to next instruction
diff --git a/vm/mterp/armv5te_taint/OP_NEW_INSTANCE.S b/vm/mterp/armv5te_taint/OP_NEW_INSTANCE.S
new file mode 100644
index 0000000..037b313
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_NEW_INSTANCE.S
@@ -0,0 +1,111 @@
+%verify "executed"
+%verify "class not resolved"
+%verify "class cannot be resolved"
+%verify "class not initialized"
+%verify "class fails to initialize"
+%verify "class already resolved/initialized"
+%verify "class is abstract or interface"
+%verify "allocation fails"
+    /*
+     * Create a new instance of a class.
+     */
+    /* new-instance vAA, class@BBBB */
+    ldr     r3, [rSELF, #offThread_methodClassDex]    @ r3<- pDvmDex
+    FETCH(r1, 1)                        @ r1<- BBBB
+    ldr     r3, [r3, #offDvmDex_pResClasses]    @ r3<- pDvmDex->pResClasses
+    ldr     r0, [r3, r1, lsl #2]        @ r0<- resolved class
+#if defined(WITH_JIT)
+    add     r10, r3, r1, lsl #2         @ r10<- &resolved_class
+#endif
+    EXPORT_PC()                         @ req'd for init, resolve, alloc
+    cmp     r0, #0                      @ already resolved?
+    beq     .L${opcode}_resolve         @ no, resolve it now
+.L${opcode}_resolved:   @ r0=class
+    ldrb    r1, [r0, #offClassObject_status]    @ r1<- ClassStatus enum
+    cmp     r1, #CLASS_INITIALIZED      @ has class been initialized?
+    bne     .L${opcode}_needinit        @ no, init class now
+.L${opcode}_initialized: @ r0=class
+    mov     r1, #ALLOC_DONT_TRACK       @ flags for alloc call
+    bl      dvmAllocObject              @ r0<- new object
+    b       .L${opcode}_finish          @ continue
+%break
+
+    .balign 32                          @ minimize cache lines
+.L${opcode}_finish: @ r0=new object
+    mov     r3, rINST, lsr #8           @ r3<- AA
+    cmp     r0, #0                      @ failed?
+#if defined(WITH_JIT)
+    /*
+     * The JIT needs the class to be fully resolved before it can
+     * include this instruction in a trace.
+     */
+    ldrh    r1, [rSELF, #offThread_subMode]
+    beq     common_exceptionThrown      @ yes, handle the exception
+    ands    r1, #kSubModeJitTraceBuild  @ under construction?
+    bne     .L${opcode}_jitCheck
+#else
+    beq     common_exceptionThrown      @ yes, handle the exception
+#endif
+.L${opcode}_end:
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r2)
+    SET_TAINT_CLEAR(r1)
+    SET_VREG_TAINT(r1, r3, r2)
+// end WITH_TAINT_TRACKING
+    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+    SET_VREG(r0, r3)                    @ vAA<- r0
+    GOTO_OPCODE(ip)                     @ jump to next instruction
+
+#if defined(WITH_JIT)
+    /*
+     * Check to see if we need to stop the trace building early.
+     * r0: new object
+     * r3: vAA
+     */
+.L${opcode}_jitCheck:
+    ldr     r1, [r10]                   @ reload resolved class
+    cmp     r1, #0                      @ okay?
+    bne     .L${opcode}_end             @ yes, finish
+    mov     r9, r0                      @ preserve new object
+    mov     r10, r3                     @ preserve vAA
+    mov     r0, rSELF
+    mov     r1, rPC
+    bl      dvmJitEndTraceSelect        @ (self, pc)
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r2)
+    SET_TAINT_CLEAR(r1)
+    SET_VREG_TAINT(r1, r10, r2)
+// end WITH_TAINT_TRACKING
+    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+    SET_VREG(r9, r10)                   @ vAA<- new object
+    GOTO_OPCODE(ip)                     @ jump to next instruction
+#endif
+
+    /*
+     * Class initialization required.
+     *
+     *  r0 holds class object
+     */
+.L${opcode}_needinit:
+    mov     r9, r0                      @ save r0
+    bl      dvmInitClass                @ initialize class
+    cmp     r0, #0                      @ check boolean result
+    mov     r0, r9                      @ restore r0
+    bne     .L${opcode}_initialized     @ success, continue
+    b       common_exceptionThrown      @ failed, deal with init exception
+
+    /*
+     * Resolution required.  This is the least-likely path.
+     *
+     *  r1 holds BBBB
+     */
+.L${opcode}_resolve:
+    ldr     r3, [rSELF, #offThread_method] @ r3<- self->method
+    mov     r2, #0                      @ r2<- false
+    ldr     r0, [r3, #offMethod_clazz]  @ r0<- method->clazz
+    bl      dvmResolveClass             @ r0<- resolved ClassObject ptr
+    cmp     r0, #0                      @ got null?
+    bne     .L${opcode}_resolved        @ no, continue
+    b       common_exceptionThrown      @ yes, handle exception
diff --git a/vm/mterp/armv5te_taint/OP_NOP.S b/vm/mterp/armv5te_taint/OP_NOP.S
new file mode 100644
index 0000000..1b72d3c
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_NOP.S
@@ -0,0 +1,15 @@
+%verify "executed"
+    FETCH_ADVANCE_INST(1)               @ advance to next instr, load rINST
+    GET_INST_OPCODE(ip)                 @ ip<- opcode from rINST
+    GOTO_OPCODE(ip)                     @ execute it
+
+#ifdef ASSIST_DEBUGGER
+    /* insert fake function header to help gdb find the stack frame */
+    .type   dalvik_inst, %function
+dalvik_inst:
+    .fnstart
+    MTERP_ENTRY1
+    MTERP_ENTRY2
+    .fnend
+#endif
+
diff --git a/vm/mterp/armv5te_taint/OP_NOT_INT.S b/vm/mterp/armv5te_taint/OP_NOT_INT.S
new file mode 100644
index 0000000..604828f
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_NOT_INT.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te_taint/unop.S" {"instr":"mvn     r0, r0"}
diff --git a/vm/mterp/armv5te_taint/OP_NOT_LONG.S b/vm/mterp/armv5te_taint/OP_NOT_LONG.S
new file mode 100644
index 0000000..ecf4d6c
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_NOT_LONG.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te_taint/unopWide.S" {"preinstr":"mvn     r0, r0", "instr":"mvn     r1, r1"}
diff --git a/vm/mterp/armv5te_taint/OP_OR_INT.S b/vm/mterp/armv5te_taint/OP_OR_INT.S
new file mode 100644
index 0000000..687447a
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_OR_INT.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te_taint/binop.S" {"instr":"orr     r0, r0, r1"}
diff --git a/vm/mterp/armv5te_taint/OP_OR_INT_2ADDR.S b/vm/mterp/armv5te_taint/OP_OR_INT_2ADDR.S
new file mode 100644
index 0000000..f1c23a0
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_OR_INT_2ADDR.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te_taint/binop2addr.S" {"instr":"orr     r0, r0, r1"}
diff --git a/vm/mterp/armv5te_taint/OP_OR_INT_LIT16.S b/vm/mterp/armv5te_taint/OP_OR_INT_LIT16.S
new file mode 100644
index 0000000..17d35ea
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_OR_INT_LIT16.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te_taint/binopLit16.S" {"instr":"orr     r0, r0, r1"}
diff --git a/vm/mterp/armv5te_taint/OP_OR_INT_LIT8.S b/vm/mterp/armv5te_taint/OP_OR_INT_LIT8.S
new file mode 100644
index 0000000..0d61dd9
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_OR_INT_LIT8.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te_taint/binopLit8.S" {"instr":"orr     r0, r0, r1"}
diff --git a/vm/mterp/armv5te_taint/OP_OR_LONG.S b/vm/mterp/armv5te_taint/OP_OR_LONG.S
new file mode 100644
index 0000000..6699ea4
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_OR_LONG.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te_taint/binopWide.S" {"preinstr":"orr     r0, r0, r2", "instr":"orr     r1, r1, r3"}
diff --git a/vm/mterp/armv5te_taint/OP_OR_LONG_2ADDR.S b/vm/mterp/armv5te_taint/OP_OR_LONG_2ADDR.S
new file mode 100644
index 0000000..f9f4fba
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_OR_LONG_2ADDR.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te_taint/binopWide2addr.S" {"preinstr":"orr     r0, r0, r2", "instr":"orr     r1, r1, r3"}
diff --git a/vm/mterp/armv5te_taint/OP_PACKED_SWITCH.S b/vm/mterp/armv5te_taint/OP_PACKED_SWITCH.S
new file mode 100644
index 0000000..6fa03c1
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_PACKED_SWITCH.S
@@ -0,0 +1,35 @@
+%default { "func":"dvmInterpHandlePackedSwitch" }
+%verify executed
+    /*
+     * Handle a packed-switch or sparse-switch instruction.  In both cases
+     * we decode it and hand it off to a helper function.
+     *
+     * We don't really expect backward branches in a switch statement, but
+     * they're perfectly legal, so we check for them here.
+     *
+     * When the JIT is present, all targets are considered treated as
+     * a potential trace heads regardless of branch direction.
+     *
+     * for: packed-switch, sparse-switch
+     */
+    /* op vAA, +BBBB */
+    FETCH(r0, 1)                        @ r0<- bbbb (lo)
+    FETCH(r1, 2)                        @ r1<- BBBB (hi)
+    mov     r3, rINST, lsr #8           @ r3<- AA
+    orr     r0, r0, r1, lsl #16         @ r0<- BBBBbbbb
+    GET_VREG(r1, r3)                    @ r1<- vAA
+    add     r0, rPC, r0, lsl #1         @ r0<- PC + BBBBbbbb*2
+    bl      $func                       @ r0<- code-unit branch offset
+    adds    r1, r0, r0                  @ r1<- byte offset; clear V
+#if defined(WITH_JIT)
+    ldr     r0, [rSELF, #offThread_pJitProfTable]
+    ldrle   rIBASE, [rSELF, #offThread_curHandlerTable] @ refresh handler base
+    FETCH_ADVANCE_INST_RB(r1)           @ update rPC, load rINST
+    cmp     r0, #0
+    bne     common_updateProfile
+#else
+    ldrle   rIBASE, [rSELF, #offThread_curHandlerTable] @ refresh handler base
+    FETCH_ADVANCE_INST_RB(r1)           @ update rPC, load rINST
+#endif
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+    GOTO_OPCODE(ip)                     @ jump to next instruction
diff --git a/vm/mterp/armv5te_taint/OP_REM_DOUBLE.S b/vm/mterp/armv5te_taint/OP_REM_DOUBLE.S
new file mode 100644
index 0000000..315a453
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_REM_DOUBLE.S
@@ -0,0 +1,3 @@
+%verify "executed"
+/* EABI doesn't define a double remainder function, but libm does */
+%include "armv5te_taint/binopWide.S" {"instr":"bl      fmod"}
diff --git a/vm/mterp/armv5te_taint/OP_REM_DOUBLE_2ADDR.S b/vm/mterp/armv5te_taint/OP_REM_DOUBLE_2ADDR.S
new file mode 100644
index 0000000..037f7b2
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_REM_DOUBLE_2ADDR.S
@@ -0,0 +1,3 @@
+%verify "executed"
+/* EABI doesn't define a double remainder function, but libm does */
+%include "armv5te_taint/binopWide2addr.S" {"instr":"bl      fmod"}
diff --git a/vm/mterp/armv5te_taint/OP_REM_FLOAT.S b/vm/mterp/armv5te_taint/OP_REM_FLOAT.S
new file mode 100644
index 0000000..8dda456
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_REM_FLOAT.S
@@ -0,0 +1,3 @@
+%verify "executed"
+/* EABI doesn't define a float remainder function, but libm does */
+%include "armv5te_taint/binop.S" {"instr":"bl      fmodf"}
diff --git a/vm/mterp/armv5te_taint/OP_REM_FLOAT_2ADDR.S b/vm/mterp/armv5te_taint/OP_REM_FLOAT_2ADDR.S
new file mode 100644
index 0000000..70eaa30
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_REM_FLOAT_2ADDR.S
@@ -0,0 +1,3 @@
+%verify "executed"
+/* EABI doesn't define a float remainder function, but libm does */
+%include "armv5te_taint/binop2addr.S" {"instr":"bl      fmodf"}
diff --git a/vm/mterp/armv5te_taint/OP_REM_INT.S b/vm/mterp/armv5te_taint/OP_REM_INT.S
new file mode 100644
index 0000000..02bf805
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_REM_INT.S
@@ -0,0 +1,3 @@
+%verify "executed"
+/* idivmod returns quotient in r0 and remainder in r1 */
+%include "armv5te_taint/binop.S" {"instr":"bl      __aeabi_idivmod", "result":"r1", "chkzero":"1"}
diff --git a/vm/mterp/armv5te_taint/OP_REM_INT_2ADDR.S b/vm/mterp/armv5te_taint/OP_REM_INT_2ADDR.S
new file mode 100644
index 0000000..bd3484f
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_REM_INT_2ADDR.S
@@ -0,0 +1,3 @@
+%verify "executed"
+/* idivmod returns quotient in r0 and remainder in r1 */
+%include "armv5te_taint/binop2addr.S" {"instr":"bl      __aeabi_idivmod", "result":"r1", "chkzero":"1"}
diff --git a/vm/mterp/armv5te_taint/OP_REM_INT_LIT16.S b/vm/mterp/armv5te_taint/OP_REM_INT_LIT16.S
new file mode 100644
index 0000000..f0c417d
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_REM_INT_LIT16.S
@@ -0,0 +1,3 @@
+%verify "executed"
+/* idivmod returns quotient in r0 and remainder in r1 */
+%include "armv5te_taint/binopLit16.S" {"instr":"bl      __aeabi_idivmod", "result":"r1", "chkzero":"1"}
diff --git a/vm/mterp/armv5te_taint/OP_REM_INT_LIT8.S b/vm/mterp/armv5te_taint/OP_REM_INT_LIT8.S
new file mode 100644
index 0000000..4b4041f
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_REM_INT_LIT8.S
@@ -0,0 +1,3 @@
+%verify "executed"
+/* idivmod returns quotient in r0 and remainder in r1 */
+%include "armv5te_taint/binopLit8.S" {"instr":"bl      __aeabi_idivmod", "result":"r1", "chkzero":"1"}
diff --git a/vm/mterp/armv5te_taint/OP_REM_LONG.S b/vm/mterp/armv5te_taint/OP_REM_LONG.S
new file mode 100644
index 0000000..dddcde3
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_REM_LONG.S
@@ -0,0 +1,3 @@
+%verify "executed"
+/* ldivmod returns quotient in r0/r1 and remainder in r2/r3 */
+%include "armv5te_taint/binopWide.S" {"instr":"bl      __aeabi_ldivmod", "result0":"r2", "result1":"r3", "chkzero":"1"}
diff --git a/vm/mterp/armv5te_taint/OP_REM_LONG_2ADDR.S b/vm/mterp/armv5te_taint/OP_REM_LONG_2ADDR.S
new file mode 100644
index 0000000..631e6ea
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_REM_LONG_2ADDR.S
@@ -0,0 +1,3 @@
+%verify "executed"
+/* ldivmod returns quotient in r0/r1 and remainder in r2/r3 */
+%include "armv5te_taint/binopWide2addr.S" {"instr":"bl      __aeabi_ldivmod", "result0":"r2", "result1":"r3", "chkzero":"1"}
diff --git a/vm/mterp/armv5te_taint/OP_RETURN.S b/vm/mterp/armv5te_taint/OP_RETURN.S
new file mode 100644
index 0000000..2110043
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_RETURN.S
@@ -0,0 +1,17 @@
+%verify "executed"
+    /*
+     * Return a 32-bit value.  Copies the return value into the "thread"
+     * structure, then jumps to the return handler.
+     *
+     * for: return, return-object
+     */
+    /* op vAA */
+    mov     r2, rINST, lsr #8           @ r2<- AA
+    GET_VREG(r0, r2)                    @ r0<- vAA
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r1)
+    GET_VREG_TAINT(r3, r2, r1)
+    str     r3, [rSELF, #offThread_rtaint]
+// end WITH_TAINT_TRACKING
+    str     r0, [rSELF, #offThread_retval] @ retval.i <- vAA
+    b       common_returnFromMethod
diff --git a/vm/mterp/armv5te_taint/OP_RETURN_OBJECT.S b/vm/mterp/armv5te_taint/OP_RETURN_OBJECT.S
new file mode 100644
index 0000000..2febd99
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_RETURN_OBJECT.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te_taint/OP_RETURN.S"
diff --git a/vm/mterp/armv5te_taint/OP_RETURN_VOID.S b/vm/mterp/armv5te_taint/OP_RETURN_VOID.S
new file mode 100644
index 0000000..6458b25
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_RETURN_VOID.S
@@ -0,0 +1,5 @@
+%verify "executed"
+    SET_TAINT_CLEAR(r1)
+    str     r1, [rSELF, #offThread_rtaint]
+    b       common_returnFromMethod
+
diff --git a/vm/mterp/armv5te_taint/OP_RETURN_VOID_BARRIER.S b/vm/mterp/armv5te_taint/OP_RETURN_VOID_BARRIER.S
new file mode 100644
index 0000000..c70aff9
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_RETURN_VOID_BARRIER.S
@@ -0,0 +1,5 @@
+%verify "executed"
+    SMP_DMB_ST
+    SET_TAINT_CLEAR(r1)
+    str     r1, [rSELF, #offThread_rtaint]
+    b       common_returnFromMethod
diff --git a/vm/mterp/armv5te_taint/OP_RETURN_WIDE.S b/vm/mterp/armv5te_taint/OP_RETURN_WIDE.S
new file mode 100644
index 0000000..572b396
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_RETURN_WIDE.S
@@ -0,0 +1,20 @@
+%verify "executed"
+    /*
+     * Return a 64-bit value.  Copies the return value into the "thread"
+     * structure, then jumps to the return handler.
+     */
+    /* return-wide vAA */
+    mov     r2, rINST, lsr #8           @ r2<- AA
+// begin WITH_TAINT_TRACKING
+    add     r2, rFP, r2, lsl #3         @ r2<- &fp[AA]
+// end WITH_TAINT_TRACKING
+    add     r3, rSELF, #offThread_retval  @ r3<- &self->retval
+// begin WITH_TAINT_TRACKING
+//    ldmia   r2, {r0-r1}                 @ r0/r1 <- vAA/vAA+1
+    ldr     r0, [r2, #0]
+    ldr     r1, [r2, #8]
+    ldr     r9, [r2, #4]
+    str     r9, [rSELF, #offThread_rtaint]
+// end WITH_TAINT_TRACKING
+    stmia   r3, {r0-r1}                 @ retval<- r0/r1
+    b       common_returnFromMethod
diff --git a/vm/mterp/armv5te_taint/OP_RSUB_INT.S b/vm/mterp/armv5te_taint/OP_RSUB_INT.S
new file mode 100644
index 0000000..92d25a6
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_RSUB_INT.S
@@ -0,0 +1,3 @@
+%verify "executed"
+/* this op is "rsub-int", but can be thought of as "rsub-int/lit16" */
+%include "armv5te_taint/binopLit16.S" {"instr":"rsb     r0, r0, r1"}
diff --git a/vm/mterp/armv5te_taint/OP_RSUB_INT_LIT8.S b/vm/mterp/armv5te_taint/OP_RSUB_INT_LIT8.S
new file mode 100644
index 0000000..2118a4f
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_RSUB_INT_LIT8.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te_taint/binopLit8.S" {"instr":"rsb     r0, r0, r1"}
diff --git a/vm/mterp/armv5te_taint/OP_SGET.S b/vm/mterp/armv5te_taint/OP_SGET.S
new file mode 100644
index 0000000..d2f6153
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_SGET.S
@@ -0,0 +1,67 @@
+// begin WITH_TAINT_TRACKING
+%default { "barrier":"@ no-op ", "volatile":"0"}
+// end WITH_TAINT_TRACKING
+%verify "executed"
+%verify "field already resolved"
+%verify "field not yet resolved"
+%verify "field cannot be resolved"
+    /*
+     * General 32-bit SGET handler.
+     *
+     * for: sget, sget-object, sget-boolean, sget-byte, sget-char, sget-short
+     */
+    /* op vAA, field@BBBB */
+    ldr     r2, [rSELF, #offThread_methodClassDex]    @ r2<- DvmDex
+    FETCH(r1, 1)                        @ r1<- field ref BBBB
+    ldr     r10, [r2, #offDvmDex_pResFields] @ r10<- dvmDex->pResFields
+    ldr     r0, [r10, r1, lsl #2]       @ r0<- resolved StaticField ptr
+    cmp     r0, #0                      @ is resolved entry null?
+    beq     .L${opcode}_resolve         @ yes, do resolve
+.L${opcode}_finish: @ field ptr in r0
+// begin WITH_TAINT_TRACKING
+    bl		.L${opcode}_taint_prop
+    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
+    SET_VREG(r0, r2)                    @ fp[AA]<- r0
+// end WITH_TAINT_TRACKING
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+    GOTO_OPCODE(ip)                     @ jump to next instruction
+%break
+
+    /*
+     * Continuation if the field has not yet been resolved.
+     *  r1:  BBBB field ref
+     *  r10: dvmDex->pResFields
+     */
+.L${opcode}_resolve:
+    ldr     r2, [rSELF, #offThread_method]    @ r2<- current method
+#if defined(WITH_JIT)
+    add     r10, r10, r1, lsl #2        @ r10<- &dvmDex->pResFields[field]
+#endif
+    EXPORT_PC()                         @ resolve() could throw, so export now
+    ldr     r0, [r2, #offMethod_clazz]  @ r0<- method->clazz
+    bl      dvmResolveStaticField       @ r0<- resolved StaticField ptr
+    cmp     r0, #0                      @ success?
+    beq     common_exceptionThrown      @ no, handle exception
+#if defined(WITH_JIT)
+    /*
+     * If the JIT is actively building a trace we need to make sure
+     * that the field is fully resolved before including this instruction.
+     */
+    bl      common_verifyField
+#endif
+    b       .L${opcode}_finish
+
+.L${opcode}_taint_prop:
+//    .if     $volatile
+//    add     r0, r0, #offStaticField_value		@ r0<- address of field
+//    bl      dvmQuasiAtomicRead32SfieldTaint		@ r0/r1<- value/taint
+//    .else
+    ldr	    r1, [r0, #offStaticField_taint] @ r1<- taint value
+    ldr     r0, [r0, #offStaticField_value] @ r0<- field value
+    $barrier                            @ acquiring load
+//    .endif
+    mov     r2, rINST, lsr #8           @ r2<- AA
+    SET_TAINT_FP(r3)
+    SET_VREG_TAINT(r1, r2, r3)
+    bx      lr
+
diff --git a/vm/mterp/armv5te_taint/OP_SGET_BOOLEAN.S b/vm/mterp/armv5te_taint/OP_SGET_BOOLEAN.S
new file mode 100644
index 0000000..4bcac59
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_SGET_BOOLEAN.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te_taint/OP_SGET.S"
diff --git a/vm/mterp/armv5te_taint/OP_SGET_BYTE.S b/vm/mterp/armv5te_taint/OP_SGET_BYTE.S
new file mode 100644
index 0000000..4bcac59
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_SGET_BYTE.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te_taint/OP_SGET.S"
diff --git a/vm/mterp/armv5te_taint/OP_SGET_CHAR.S b/vm/mterp/armv5te_taint/OP_SGET_CHAR.S
new file mode 100644
index 0000000..4bcac59
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_SGET_CHAR.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te_taint/OP_SGET.S"
diff --git a/vm/mterp/armv5te_taint/OP_SGET_OBJECT.S b/vm/mterp/armv5te_taint/OP_SGET_OBJECT.S
new file mode 100644
index 0000000..4bcac59
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_SGET_OBJECT.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te_taint/OP_SGET.S"
diff --git a/vm/mterp/armv5te_taint/OP_SGET_OBJECT_VOLATILE.S b/vm/mterp/armv5te_taint/OP_SGET_OBJECT_VOLATILE.S
new file mode 100644
index 0000000..afae457
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_SGET_OBJECT_VOLATILE.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te_taint/OP_SGET.S" {"volatile":"1"}
diff --git a/vm/mterp/armv5te_taint/OP_SGET_SHORT.S b/vm/mterp/armv5te_taint/OP_SGET_SHORT.S
new file mode 100644
index 0000000..4bcac59
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_SGET_SHORT.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te_taint/OP_SGET.S"
diff --git a/vm/mterp/armv5te_taint/OP_SGET_VOLATILE.S b/vm/mterp/armv5te_taint/OP_SGET_VOLATILE.S
new file mode 100644
index 0000000..afae457
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_SGET_VOLATILE.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te_taint/OP_SGET.S" {"volatile":"1"}
diff --git a/vm/mterp/armv5te_taint/OP_SGET_WIDE.S b/vm/mterp/armv5te_taint/OP_SGET_WIDE.S
new file mode 100644
index 0000000..13f774d
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_SGET_WIDE.S
@@ -0,0 +1,68 @@
+%default {"volatile":"0"}
+%verify "executed"
+%verify "field already resolved"
+%verify "field not yet resolved"
+%verify "field cannot be resolved"
+    /*
+     * 64-bit SGET handler.
+     */
+    /* sget-wide vAA, field@BBBB */
+    ldr     r2, [rSELF, #offThread_methodClassDex]    @ r2<- DvmDex
+    FETCH(r1, 1)                        @ r1<- field ref BBBB
+    ldr     r10, [r2, #offDvmDex_pResFields] @ r10<- dvmDex->pResFields
+    ldr     r0, [r10, r1, lsl #2]       @ r0<- resolved StaticField ptr
+    cmp     r0, #0                      @ is resolved entry null?
+    beq     .L${opcode}_resolve         @ yes, do resolve
+    b		.L${opcode}_finish
+
+%break
+
+.L${opcode}_finish:
+    mov     r9, rINST, lsr #8           @ r9<- AA
+// begin WITH_TAINT_TRACKING
+    ldr	    r3, [r0, #offStaticField_taint] @ r3<- taint value
+    .if $volatile
+    stmfd   sp!, {r3}    
+    add     r0, r0, #offStaticField_value @ r0<- pointer to data
+    bl      dvmQuasiAtomicRead64        @ r0/r1<- contents of field
+    ldmfd   sp!, {r3}
+    .else
+    ldrd    r0, [r0, #offStaticField_value] @ r0/r1<- field value (aligned)
+    .endif
+    add     r9, rFP, r9, lsl #3         @ r9<- &fp[AA]
+    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
+//    stmia   r9, {r2-r3}                 @ vAA/vAA+1<- r2/r3
+    str	    r0, [r9, #0]
+    str	    r3, [r9, #4]
+    str	    r1, [r9, #8]
+    str	    r3, [r9, #12]
+// end WITH_TAINT_TRACKING
+
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+    GOTO_OPCODE(ip)                     @ jump to next instruction
+
+    /*
+     * Continuation if the field has not yet been resolved.
+     *  r1:  BBBB field ref
+     *  r10: dvmDex->pResFields
+     *
+     * Returns StaticField pointer in r0.
+     */
+.L${opcode}_resolve:
+    ldr     r2, [rSELF, #offThread_method]    @ r2<- current method
+#if defined(WITH_JIT)
+    add     r10, r10, r1, lsl #2        @ r1<- &dvmDex->pResFields[field]
+#endif
+    EXPORT_PC()                         @ resolve() could throw, so export now
+    ldr     r0, [r2, #offMethod_clazz]  @ r0<- method->clazz
+    bl      dvmResolveStaticField       @ r0<- resolved StaticField ptr
+    cmp     r0, #0                      @ success?
+    beq     common_exceptionThrown      @ no, handle exception
+#if defined(WITH_JIT)
+    /*
+     * If the JIT is actively building a trace we need to make sure
+     * that the field is fully resolved before including this instruction.
+     */
+    bl      common_verifyField
+#endif
+    b       .L${opcode}_finish          @ resume
diff --git a/vm/mterp/armv5te_taint/OP_SGET_WIDE_VOLATILE.S b/vm/mterp/armv5te_taint/OP_SGET_WIDE_VOLATILE.S
new file mode 100644
index 0000000..7922ad7
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_SGET_WIDE_VOLATILE.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te_taint/OP_SGET_WIDE.S" {"volatile":"1"}
diff --git a/vm/mterp/armv5te_taint/OP_SHL_INT.S b/vm/mterp/armv5te_taint/OP_SHL_INT.S
new file mode 100644
index 0000000..dd9c2ed
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_SHL_INT.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te_taint/binop.S" {"preinstr":"and     r1, r1, #31", "instr":"mov     r0, r0, asl r1"}
diff --git a/vm/mterp/armv5te_taint/OP_SHL_INT_2ADDR.S b/vm/mterp/armv5te_taint/OP_SHL_INT_2ADDR.S
new file mode 100644
index 0000000..f201b86
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_SHL_INT_2ADDR.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te_taint/binop2addr.S" {"preinstr":"and     r1, r1, #31", "instr":"mov     r0, r0, asl r1"}
diff --git a/vm/mterp/armv5te_taint/OP_SHL_INT_LIT8.S b/vm/mterp/armv5te_taint/OP_SHL_INT_LIT8.S
new file mode 100644
index 0000000..64024da
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_SHL_INT_LIT8.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te_taint/binopLit8.S" {"preinstr":"and     r1, r1, #31", "instr":"mov     r0, r0, asl r1"}
diff --git a/vm/mterp/armv5te_taint/OP_SHL_LONG.S b/vm/mterp/armv5te_taint/OP_SHL_LONG.S
new file mode 100644
index 0000000..e25cc70
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_SHL_LONG.S
@@ -0,0 +1,50 @@
+%verify "executed"
+    /*
+     * Long integer shift.  This is different from the generic 32/64-bit
+     * binary operations because vAA/vBB are 64-bit but vCC (the shift
+     * distance) is 32-bit.  Also, Dalvik requires us to mask off the low
+     * 6 bits of the shift distance.
+     */
+    /* shl-long vAA, vBB, vCC */
+    FETCH(r0, 1)                        @ r0<- CCBB
+    mov     r9, rINST, lsr #8           @ r9<- AA
+    and     r3, r0, #255                @ r3<- BB
+    mov     r0, r0, lsr #8              @ r0<- CC
+// begin WITH_TAINT_TRACKING
+    bl      shl_long_taint_prop
+// end WITH_TAINT_TRACKING
+
+    mov     r1, r1, asl r2              @  r1<- r1 << r2
+    rsb     r3, r2, #32                 @  r3<- 32 - r2
+    orr     r1, r1, r0, lsr r3          @  r1<- r1 | (r0 << (32-r2))
+    subs    ip, r2, #32                 @  ip<- r2 - 32
+    movpl   r1, r0, asl ip              @  if r2 >= 32, r1<- r0 << (r2-32)
+    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
+    b       .L${opcode}_finish
+%break
+
+.L${opcode}_finish:
+    mov     r0, r0, asl r2              @  r0<- r0 << r2
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+// begin WITH_TAINT_TRACKING
+//    stmia   r9, {r0-r1}                 @ vAA/vAA+1<- r0/r1
+    str     r0, [r9, #0]
+    str     r10, [r9, #4]
+    str     r1, [r9, #8]
+    str     r10, [r9, #12]
+// end WITH_TAINT_TRACKING
+    GOTO_OPCODE(ip)                     @ jump to next instruction
+
+shl_long_taint_prop:
+    add     r3, rFP, r3, lsl #3         @ r3<- &fp[BB]
+    GET_VREG(r2, r0)                    @ r2<- vCC
+    SET_TAINT_FP(r1)
+    GET_VREG_TAINT(r0, r0, r1)
+//    ldmia   r3, {r0-r1}                 @ r0/r1<- vBB/vBB+1
+    ldr     r1, [r3, #4]
+    orr     r10, r0, r1
+    ldr     r0, [r3, #0]
+    ldr     r1, [r3, #8]
+    and     r2, r2, #63                 @ r2<- r2 & 0x3f
+    add     r9, rFP, r9, lsl #3         @ r9<- &fp[AA]
+    bx      lr
diff --git a/vm/mterp/armv5te_taint/OP_SHL_LONG_2ADDR.S b/vm/mterp/armv5te_taint/OP_SHL_LONG_2ADDR.S
new file mode 100644
index 0000000..1a01b78
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_SHL_LONG_2ADDR.S
@@ -0,0 +1,46 @@
+%verify "executed"
+    /*
+     * Long integer shift, 2addr version.  vA is 64-bit value/result, vB is
+     * 32-bit shift distance.
+     */
+    /* shl-long/2addr vA, vB */
+    mov     r9, rINST, lsr #8           @ r9<- A+
+    mov     r3, rINST, lsr #12          @ r3<- B
+    and     r9, r9, #15
+    GET_VREG(r2, r3)                    @ r2<- vB
+// begin WITH_TAINT_TRACKING
+    bl      shl_long_2addr_taint_prop
+// end WITH_TAINT_TRACKING
+
+    mov     r1, r1, asl r2              @  r1<- r1 << r2
+    rsb     r3, r2, #32                 @  r3<- 32 - r2
+    orr     r1, r1, r0, lsr r3          @  r1<- r1 | (r0 << (32-r2))
+    subs    ip, r2, #32                 @  ip<- r2 - 32
+    FETCH_ADVANCE_INST(1)               @ advance rPC, load rINST
+    movpl   r1, r0, asl ip              @  if r2 >= 32, r1<- r0 << (r2-32)
+    mov     r0, r0, asl r2              @  r0<- r0 << r2
+    b       .L${opcode}_finish
+%break
+
+.L${opcode}_finish:
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+// begin WITH_TAINT_TRACKING
+//    stmia   r9, {r0-r1}                 @ vAA/vAA+1<- r0/r1
+    str     r0, [r9, #0]
+    str     r10, [r9, #4]
+    str     r1, [r9, #8]
+    str     r10, [r9, #12]
+// end WITH_TAINT_TRACKING
+    GOTO_OPCODE(ip)                     @ jump to next instruction
+
+shl_long_2addr_taint_prop:
+    SET_TAINT_FP(r0)
+    GET_VREG_TAINT(r0, r3, r0)
+    add     r9, rFP, r9, lsl #3         @ r9<- &fp[A]
+    and     r2, r2, #63                 @ r2<- r2 & 0x3f
+//    ldmia   r9, {r0-r1}                 @ r0/r1<- vAA/vAA+1
+    ldr     r10, [r9, #4]
+    orr     r10, r0, r10
+    ldr     r0, [r9, #0]
+    ldr     r1, [r9, #8]
+    bx      lr
diff --git a/vm/mterp/armv5te_taint/OP_SHR_INT.S b/vm/mterp/armv5te_taint/OP_SHR_INT.S
new file mode 100644
index 0000000..36ab4f5
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_SHR_INT.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te_taint/binop.S" {"preinstr":"and     r1, r1, #31", "instr":"mov     r0, r0, asr r1"}
diff --git a/vm/mterp/armv5te_taint/OP_SHR_INT_2ADDR.S b/vm/mterp/armv5te_taint/OP_SHR_INT_2ADDR.S
new file mode 100644
index 0000000..d2e21e5
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_SHR_INT_2ADDR.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te_taint/binop2addr.S" {"preinstr":"and     r1, r1, #31", "instr":"mov     r0, r0, asr r1"}
diff --git a/vm/mterp/armv5te_taint/OP_SHR_INT_LIT8.S b/vm/mterp/armv5te_taint/OP_SHR_INT_LIT8.S
new file mode 100644
index 0000000..7ef339a
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_SHR_INT_LIT8.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te_taint/binopLit8.S" {"preinstr":"and     r1, r1, #31", "instr":"mov     r0, r0, asr r1"}
diff --git a/vm/mterp/armv5te_taint/OP_SHR_LONG.S b/vm/mterp/armv5te_taint/OP_SHR_LONG.S
new file mode 100644
index 0000000..6faa12e
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_SHR_LONG.S
@@ -0,0 +1,50 @@
+%verify "executed"
+    /*
+     * Long integer shift.  This is different from the generic 32/64-bit
+     * binary operations because vAA/vBB are 64-bit but vCC (the shift
+     * distance) is 32-bit.  Also, Dalvik requires us to mask off the low
+     * 6 bits of the shift distance.
+     */
+    /* shr-long vAA, vBB, vCC */
+    FETCH(r0, 1)                        @ r0<- CCBB
+    mov     r9, rINST, lsr #8           @ r9<- AA
+    and     r3, r0, #255                @ r3<- BB
+    mov     r0, r0, lsr #8              @ r0<- CC
+// begin WITH_TAINT_TRACKING
+    bl      shr_long_taint_prop
+// end WITH_TAINT_TRACKING
+
+    mov     r0, r0, lsr r2              @  r0<- r2 >> r2
+    rsb     r3, r2, #32                 @  r3<- 32 - r2
+    orr     r0, r0, r1, asl r3          @  r0<- r0 | (r1 << (32-r2))
+    subs    ip, r2, #32                 @  ip<- r2 - 32
+    movpl   r0, r1, asr ip              @  if r2 >= 32, r0<-r1 >> (r2-32)
+    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
+    b       .L${opcode}_finish
+%break
+
+.L${opcode}_finish:
+    mov     r1, r1, asr r2              @  r1<- r1 >> r2
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+// begin WITH_TAINT_TRACKING
+//    stmia   r9, {r0-r1}                 @ vAA/vAA+1<- r0/r1
+    str     r0, [r9, #0]
+    str     r10, [r9, #4]
+    str     r1, [r9, #8]
+    str     r10, [r9, #12]
+// end WITH_TAINT_TRACKING
+    GOTO_OPCODE(ip)                     @ jump to next instruction
+
+shr_long_taint_prop:
+    add     r3, rFP, r3, lsl #3         @ r3<- &fp[BB]
+    GET_VREG(r2, r0)                    @ r2<- vCC
+    SET_TAINT_FP(r1)
+    GET_VREG_TAINT(r0, r0, r1)
+//    ldmia   r3, {r0-r1}                 @ r0/r1<- vBB/vBB+1
+    ldr     r1, [r3, #4]
+    orr     r10, r0, r1
+    ldr     r0, [r3, #0]
+    ldr     r1, [r3, #8]
+    and     r2, r2, #63                 @ r2<- r2 & 0x3f
+    add     r9, rFP, r9, lsl #3         @ r9<- &fp[AA]
+    bx      lr
diff --git a/vm/mterp/armv5te_taint/OP_SHR_LONG_2ADDR.S b/vm/mterp/armv5te_taint/OP_SHR_LONG_2ADDR.S
new file mode 100644
index 0000000..7c8cd4f
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_SHR_LONG_2ADDR.S
@@ -0,0 +1,47 @@
+%verify "executed"
+    /*
+     * Long integer shift, 2addr version.  vA is 64-bit value/result, vB is
+     * 32-bit shift distance.
+     */
+    /* shr-long/2addr vA, vB */
+    mov     r9, rINST, lsr #8           @ r9<- A+
+    mov     r3, rINST, lsr #12          @ r3<- B
+    and     r9, r9, #15
+    GET_VREG(r2, r3)                    @ r2<- vB
+// begin WITH_TAINT_TRACKING
+    bl      shr_long_2addr_taint_prop
+// end WITH_TAINT_TRACKING
+
+    mov     r0, r0, lsr r2              @  r0<- r2 >> r2
+    rsb     r3, r2, #32                 @  r3<- 32 - r2
+    orr     r0, r0, r1, asl r3          @  r0<- r0 | (r1 << (32-r2))
+    subs    ip, r2, #32                 @  ip<- r2 - 32
+    FETCH_ADVANCE_INST(1)               @ advance rPC, load rINST
+    movpl   r0, r1, asr ip              @  if r2 >= 32, r0<-r1 >> (r2-32)
+    mov     r1, r1, asr r2              @  r1<- r1 >> r2
+    b       .L${opcode}_finish
+%break
+
+.L${opcode}_finish:
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+// begin WITH_TAINT_TRACKING
+//    stmia   r9, {r0-r1}                 @ vAA/vAA+1<- r0/r1
+    str     r0, [r9, #0]
+    str     r10, [r9, #4]
+    str     r1, [r9, #8]
+    str     r10, [r9, #12]
+// end WITH_TAINT_TRACKING
+    GOTO_OPCODE(ip)                     @ jump to next instruction
+
+// OP_SHR_LONG_2ADDR.S
+shr_long_2addr_taint_prop:
+    SET_TAINT_FP(r0)
+    GET_VREG_TAINT(r0, r3, r0)
+    add     r9, rFP, r9, lsl #3         @ r9<- &fp[A]
+    and     r2, r2, #63                 @ r2<- r2 & 0x3f
+//    ldmia   r9, {r0-r1}                 @ r0/r1<- vAA/vAA+1
+    ldr     r10, [r9, #4]
+    orr     r10, r0, r10
+    ldr     r0, [r9, #0]
+    ldr     r1, [r9, #8]
+    bx      lr
diff --git a/vm/mterp/armv5te_taint/OP_SPARSE_SWITCH.S b/vm/mterp/armv5te_taint/OP_SPARSE_SWITCH.S
new file mode 100644
index 0000000..c3fd086
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_SPARSE_SWITCH.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te_taint/OP_PACKED_SWITCH.S" { "func":"dvmInterpHandleSparseSwitch" }
diff --git a/vm/mterp/armv5te_taint/OP_SPUT.S b/vm/mterp/armv5te_taint/OP_SPUT.S
new file mode 100644
index 0000000..832b204
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_SPUT.S
@@ -0,0 +1,72 @@
+// begin WITH_TAINT_TRACKING
+%default { "prebarrier":"@ no-op", "postbarrier":"@ no-op ", "volatile":"0"}
+// end WITH_TAINT_TRACKING
+%verify "executed"
+%verify "field already resolved"
+%verify "field not yet resolved"
+%verify "field cannot be resolved"
+    /*
+     * General 32-bit SPUT handler.
+     *
+     * for: sput, sput-boolean, sput-byte, sput-char, sput-short
+     */
+    /* op vAA, field@BBBB */
+    ldr     r2, [rSELF, #offThread_methodClassDex]    @ r2<- DvmDex
+    FETCH(r1, 1)                        @ r1<- field ref BBBB
+    ldr     r10, [r2, #offDvmDex_pResFields] @ r10<- dvmDex->pResFields
+    ldr     r0, [r10, r1, lsl #2]        @ r0<- resolved StaticField ptr
+    cmp     r0, #0                      @ is resolved entry null?
+    beq     .L${opcode}_resolve         @ yes, do resolve
+.L${opcode}_finish:   @ field ptr in r0
+    mov     r2, rINST, lsr #8           @ r2<- AA
+    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
+    GET_VREG(r1, r2)                    @ r1<- fp[AA]
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+// begin WITH_TAINT_TRACKING
+    bl      .L${opcode}_taint_prop
+// end WITH_TAINT_TRACKING
+    GOTO_OPCODE(ip)                     @ jump to next instruction
+%break
+
+    /*
+     * Continuation if the field has not yet been resolved.
+     *  r1:  BBBB field ref
+     *  r10: dvmDex->pResFields
+     */
+.L${opcode}_resolve:
+    ldr     r2, [rSELF, #offThread_method]    @ r2<- current method
+#if defined(WITH_JIT)
+    add     r10, r10, r1, lsl #2        @ r10<- &dvmDex->pResFields[field]
+#endif
+    EXPORT_PC()                         @ resolve() could throw, so export now
+    ldr     r0, [r2, #offMethod_clazz]  @ r0<- method->clazz
+    bl      dvmResolveStaticField       @ r0<- resolved StaticField ptr
+    cmp     r0, #0                      @ success?
+    beq     common_exceptionThrown      @ no, handle exception
+#if defined(WITH_JIT)
+    /*
+     * If the JIT is actively building a trace we need to make sure
+     * that the field is fully resolved before including this instruction.
+     */
+    bl      common_verifyField
+#endif
+    b       .L${opcode}_finish          @ resume
+
+.L${opcode}_taint_prop:
+//    .if     $volatile
+//    add     r3, r0, #offStaticField_value   @ r3<- addr
+//    mov     r0, r1                          @ r0<- val
+//    mov     r1, r3                          @ r1<- addr
+//    SET_TAINT_FP(r3)
+//    GET_VREG_TAINT(r2, r2, r3)              @ r2<- taint
+//    bl      dvmQuasiAtomicSwap32SfieldTaint
+//    .else
+    $prebarrier                        	    @ releasing store
+    str     r1, [r0, #offStaticField_value] @ field<- vAA
+    SET_TAINT_FP(r3)
+    GET_VREG_TAINT(r1, r2, r3)
+    str	    r1, [r0, #offStaticField_taint]
+    $postbarrier
+//    .endif
+    bx      lr
+
diff --git a/vm/mterp/armv5te_taint/OP_SPUT_BOOLEAN.S b/vm/mterp/armv5te_taint/OP_SPUT_BOOLEAN.S
new file mode 100644
index 0000000..c4287d1
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_SPUT_BOOLEAN.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te_taint/OP_SPUT.S"
diff --git a/vm/mterp/armv5te_taint/OP_SPUT_BYTE.S b/vm/mterp/armv5te_taint/OP_SPUT_BYTE.S
new file mode 100644
index 0000000..c4287d1
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_SPUT_BYTE.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te_taint/OP_SPUT.S"
diff --git a/vm/mterp/armv5te_taint/OP_SPUT_CHAR.S b/vm/mterp/armv5te_taint/OP_SPUT_CHAR.S
new file mode 100644
index 0000000..c4287d1
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_SPUT_CHAR.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te_taint/OP_SPUT.S"
diff --git a/vm/mterp/armv5te_taint/OP_SPUT_OBJECT.S b/vm/mterp/armv5te_taint/OP_SPUT_OBJECT.S
new file mode 100644
index 0000000..79ab8cf
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_SPUT_OBJECT.S
@@ -0,0 +1,79 @@
+// begin WITH_TAINT_TRACKING
+%default { "postbarrier":"@ no-op ", "prebarrier":"@ no-op ", "volatile":"0" }
+// end WITH_TAINT_TRACKING
+%verify "executed"
+%verify "field already resolved"
+%verify "field not yet resolved"
+%verify "field cannot be resolved"
+    /*
+     * 32-bit SPUT handler for objects
+     *
+     * for: sput-object, sput-object-volatile
+     */
+    /* op vAA, field@BBBB */
+    ldr     r2, [rSELF, #offThread_methodClassDex]    @ r2<- DvmDex
+    FETCH(r1, 1)                        @ r1<- field ref BBBB
+    ldr     r10, [r2, #offDvmDex_pResFields] @ r10<- dvmDex->pResFields
+    ldr     r0, [r10, r1, lsl #2]        @ r0<- resolved StaticField ptr
+    cmp     r0, #0                      @ is resolved entry null?
+    beq     .L${opcode}_resolve         @ yes, do resolve
+.L${opcode}_finish:   @ field ptr in r0
+    mov     r2, rINST, lsr #8           @ r2<- AA
+    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
+    GET_VREG(r1, r2)                    @ r1<- fp[AA]
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r3)
+    GET_VREG_TAINT(r3, r2, r3)          @ r3<- taint
+//    ldr     r2, [rSELF, #offThread_cardTable]  @ r2<- card table base
+    ldr     r10, [rSELF, #offThread_cardTable]  @ r10<- card table base
+// end WITH_TAINT_TRACKING
+    ldr     r9, [r0, #offField_clazz]   @ r9<- field->clazz
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+    $prebarrier                        @ releasing store
+    b       .L${opcode}_end
+%break
+
+
+.L${opcode}_end:
+// begin WITH_TAINT_TRACKING
+//    .if     $volatile
+//    add	    r2, r0, #offStaticField_value       @ r2<- addr
+//    mov	    r0, r1                              @ r0<- val
+//    mov	    r1, r2                              @ r1<- addr
+//    mov	    r2, r3                              @ r2<- taint
+//    bl      dvmQuasiAtomicSwap32SfieldTaint
+//    cmp     r0, #0                    	        @ stored a null object?
+//    .else
+    str     r1, [r0, #offStaticField_value] @ field<- vAA
+    str	    r3, [r0, #offStaticField_taint]
+//    $postbarrier
+    cmp     r1, #0                              @ stored a null object?
+//    .endif
+//    strneb  r2, [r2, r9, lsr #GC_CARD_SHIFT]  @ mark card based on obj head
+    strneb  r10, [r10, r9, lsr #GC_CARD_SHIFT]  @ mark card based on obj head
+// end WITH_TAINT_TRACKING
+    GOTO_OPCODE(ip)                     @ jump to next instruction
+
+    /* Continuation if the field has not yet been resolved.
+     * r1:  BBBB field ref
+     * r10: dvmDex->pResFields
+     */
+.L${opcode}_resolve:
+    ldr     r2, [rSELF, #offThread_method]    @ r2<- current method
+#if defined(WITH_JIT)
+    add     r10, r10, r1, lsl #2        @ r10<- &dvmDex->pResFields[field]
+#endif
+    EXPORT_PC()                         @ resolve() could throw, so export now
+    ldr     r0, [r2, #offMethod_clazz]  @ r0<- method->clazz
+    bl      dvmResolveStaticField       @ r0<- resolved StaticField ptr
+    cmp     r0, #0                      @ success?
+    beq     common_exceptionThrown      @ no, handle exception
+#if defined(WITH_JIT)
+    /*
+     * If the JIT is actively building a trace we need to make sure
+     * that the field is fully resolved before including this instruction.
+     */
+    bl      common_verifyField
+#endif
+    b       .L${opcode}_finish          @ resume
+
diff --git a/vm/mterp/armv5te_taint/OP_SPUT_OBJECT_VOLATILE.S b/vm/mterp/armv5te_taint/OP_SPUT_OBJECT_VOLATILE.S
new file mode 100644
index 0000000..0086856
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_SPUT_OBJECT_VOLATILE.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te_taint/OP_SPUT_OBJECT.S"  {"volatile":"1"}
diff --git a/vm/mterp/armv5te_taint/OP_SPUT_SHORT.S b/vm/mterp/armv5te_taint/OP_SPUT_SHORT.S
new file mode 100644
index 0000000..c4287d1
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_SPUT_SHORT.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te_taint/OP_SPUT.S"
diff --git a/vm/mterp/armv5te_taint/OP_SPUT_VOLATILE.S b/vm/mterp/armv5te_taint/OP_SPUT_VOLATILE.S
new file mode 100644
index 0000000..cf9d410
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_SPUT_VOLATILE.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te_taint/OP_SPUT.S" {"volatile":"1"}
diff --git a/vm/mterp/armv5te_taint/OP_SPUT_WIDE.S b/vm/mterp/armv5te_taint/OP_SPUT_WIDE.S
new file mode 100644
index 0000000..841c9aa
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_SPUT_WIDE.S
@@ -0,0 +1,72 @@
+%default {"volatile":"0"}
+%verify "executed"
+%verify "field already resolved"
+%verify "field not yet resolved"
+%verify "field cannot be resolved"
+    /*
+     * 64-bit SPUT handler.
+     */
+    /* sput-wide vAA, field@BBBB */
+    ldr     r0, [rSELF, #offThread_methodClassDex]  @ r0<- DvmDex
+    FETCH(r1, 1)                        @ r1<- field ref BBBB
+    ldr     r10, [r0, #offDvmDex_pResFields] @ r10<- dvmDex->pResFields
+    mov     r9, rINST, lsr #8           @ r9<- AA
+    ldr     r2, [r10, r1, lsl #2]        @ r2<- resolved StaticField ptr
+// begin WITH_TAINT_TRACKING
+    add     r9, rFP, r9, lsl #3         @ r9<- &fp[AA]
+// end WITH_TAINT_TRACKING
+    cmp     r2, #0                      @ is resolved entry null?
+    beq     .L${opcode}_resolve         @ yes, do resolve
+.L${opcode}_finish: @ field ptr in r2, AA in r9
+    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
+// begin WITH_TAINT_TRACKING
+    bl		.L${opcode}_taint_prop
+// end WITH_TAINT_TRACKING
+    GET_INST_OPCODE(r10)                @ extract opcode from rINST
+// begin WITH_TAINT_TRACKING
+    str	    r3, [r2, #offStaticField_taint]
+// end WITH_TAINT_TRACKING
+    .if $volatile
+    add     r2, r2, #offStaticField_value @ r2<- pointer to data
+    bl      dvmQuasiAtomicSwap64Sync    @ stores r0/r1 into addr r2
+    .else
+    strd    r0, [r2, #offStaticField_value] @ field<- vAA/vAA+1
+    .endif
+    GOTO_OPCODE(r10)                    @ jump to next instruction
+%break
+
+    /*
+     * Continuation if the field has not yet been resolved.
+     *  r1:  BBBB field ref
+     *  r9:  &fp[AA]
+     *  r10: dvmDex->pResFields
+     *
+     * Returns StaticField pointer in r2.
+     */
+.L${opcode}_resolve:
+    ldr     r2, [rSELF, #offThread_method]    @ r2<- current method
+#if defined(WITH_JIT)
+    add     r10, r10, r1, lsl #2        @ r10<- &dvmDex->pResFields[field]
+#endif
+    EXPORT_PC()                         @ resolve() could throw, so export now
+    ldr     r0, [r2, #offMethod_clazz]  @ r0<- method->clazz
+    bl      dvmResolveStaticField       @ r0<- resolved StaticField ptr
+    cmp     r0, #0                      @ success?
+    mov     r2, r0                      @ copy to r2
+    beq     common_exceptionThrown      @ no, handle exception
+#if defined(WITH_JIT)
+    /*
+     * If the JIT is actively building a trace we need to make sure
+     * that the field is fully resolved before including this instruction.
+     */
+    bl      common_verifyField
+#endif
+    b       .L${opcode}_finish          @ resume
+
+.L${opcode}_taint_prop:
+//    ldmia   r9, {r0-r1}                 @ r0/r1<- vAA/vAA+1
+    ldr r3, [r9, #4]
+    ldr r0, [r9, #0]
+    ldr r1, [r9, #8]
+    bx      lr
+
diff --git a/vm/mterp/armv5te_taint/OP_SPUT_WIDE_VOLATILE.S b/vm/mterp/armv5te_taint/OP_SPUT_WIDE_VOLATILE.S
new file mode 100644
index 0000000..0f7f99e
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_SPUT_WIDE_VOLATILE.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te_taint/OP_SPUT_WIDE.S" {"volatile":"1"}
diff --git a/vm/mterp/armv5te_taint/OP_SUB_DOUBLE.S b/vm/mterp/armv5te_taint/OP_SUB_DOUBLE.S
new file mode 100644
index 0000000..b591d80
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_SUB_DOUBLE.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te_taint/binopWide.S" {"instr":"bl      __aeabi_dsub"}
diff --git a/vm/mterp/armv5te_taint/OP_SUB_DOUBLE_2ADDR.S b/vm/mterp/armv5te_taint/OP_SUB_DOUBLE_2ADDR.S
new file mode 100644
index 0000000..ad3a16a
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_SUB_DOUBLE_2ADDR.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te_taint/binopWide2addr.S" {"instr":"bl      __aeabi_dsub"}
diff --git a/vm/mterp/armv5te_taint/OP_SUB_FLOAT.S b/vm/mterp/armv5te_taint/OP_SUB_FLOAT.S
new file mode 100644
index 0000000..c25776e
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_SUB_FLOAT.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te_taint/binop.S" {"instr":"bl      __aeabi_fsub"}
diff --git a/vm/mterp/armv5te_taint/OP_SUB_FLOAT_2ADDR.S b/vm/mterp/armv5te_taint/OP_SUB_FLOAT_2ADDR.S
new file mode 100644
index 0000000..f731511
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_SUB_FLOAT_2ADDR.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te_taint/binop2addr.S" {"instr":"bl      __aeabi_fsub"}
diff --git a/vm/mterp/armv5te_taint/OP_SUB_INT.S b/vm/mterp/armv5te_taint/OP_SUB_INT.S
new file mode 100644
index 0000000..4e82c82
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_SUB_INT.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te_taint/binop.S" {"instr":"sub     r0, r0, r1"}
diff --git a/vm/mterp/armv5te_taint/OP_SUB_INT_2ADDR.S b/vm/mterp/armv5te_taint/OP_SUB_INT_2ADDR.S
new file mode 100644
index 0000000..30dbbf2
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_SUB_INT_2ADDR.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te_taint/binop2addr.S" {"instr":"sub     r0, r0, r1"}
diff --git a/vm/mterp/armv5te_taint/OP_SUB_LONG.S b/vm/mterp/armv5te_taint/OP_SUB_LONG.S
new file mode 100644
index 0000000..095a00c
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_SUB_LONG.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te_taint/binopWide.S" {"preinstr":"subs    r0, r0, r2", "instr":"sbc     r1, r1, r3"}
diff --git a/vm/mterp/armv5te_taint/OP_SUB_LONG_2ADDR.S b/vm/mterp/armv5te_taint/OP_SUB_LONG_2ADDR.S
new file mode 100644
index 0000000..105c70f
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_SUB_LONG_2ADDR.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te_taint/binopWide2addr.S" {"preinstr":"subs    r0, r0, r2", "instr":"sbc     r1, r1, r3"}
diff --git a/vm/mterp/armv5te_taint/OP_THROW.S b/vm/mterp/armv5te_taint/OP_THROW.S
new file mode 100644
index 0000000..6e157b4
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_THROW.S
@@ -0,0 +1,14 @@
+%verify "executed"
+%verify "exception for null object"
+    /*
+     * Throw an exception object in the current thread.
+     */
+    /* throw vAA */
+    mov     r2, rINST, lsr #8           @ r2<- AA
+    GET_VREG(r1, r2)                    @ r1<- vAA (exception object)
+    EXPORT_PC()                         @ exception handler can throw
+    cmp     r1, #0                      @ null object?
+    beq     common_errNullObject        @ yes, throw an NPE instead
+    @ bypass dvmSetException, just store it
+    str     r1, [rSELF, #offThread_exception]  @ thread->exception<- obj
+    b       common_exceptionThrown
diff --git a/vm/mterp/armv5te_taint/OP_THROW_VERIFICATION_ERROR.S b/vm/mterp/armv5te_taint/OP_THROW_VERIFICATION_ERROR.S
new file mode 100644
index 0000000..afe9fd8
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_THROW_VERIFICATION_ERROR.S
@@ -0,0 +1,13 @@
+%verify executed
+    /*
+     * Handle a throw-verification-error instruction.  This throws an
+     * exception for an error discovered during verification.  The
+     * exception is indicated by AA, with some detail provided by BBBB.
+     */
+    /* op AA, ref@BBBB */
+    ldr     r0, [rSELF, #offThread_method]    @ r0<- self->method
+    FETCH(r2, 1)                        @ r2<- BBBB
+    EXPORT_PC()                         @ export the PC
+    mov     r1, rINST, lsr #8           @ r1<- AA
+    bl      dvmThrowVerificationError   @ always throws
+    b       common_exceptionThrown      @ handle exception
diff --git a/vm/mterp/armv5te_taint/OP_UNUSED_3E.S b/vm/mterp/armv5te_taint/OP_UNUSED_3E.S
new file mode 100644
index 0000000..aa4635d
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_UNUSED_3E.S
@@ -0,0 +1 @@
+%include "armv5te_taint/unused.S"
diff --git a/vm/mterp/armv5te_taint/OP_UNUSED_3F.S b/vm/mterp/armv5te_taint/OP_UNUSED_3F.S
new file mode 100644
index 0000000..aa4635d
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_UNUSED_3F.S
@@ -0,0 +1 @@
+%include "armv5te_taint/unused.S"
diff --git a/vm/mterp/armv5te_taint/OP_UNUSED_40.S b/vm/mterp/armv5te_taint/OP_UNUSED_40.S
new file mode 100644
index 0000000..aa4635d
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_UNUSED_40.S
@@ -0,0 +1 @@
+%include "armv5te_taint/unused.S"
diff --git a/vm/mterp/armv5te_taint/OP_UNUSED_41.S b/vm/mterp/armv5te_taint/OP_UNUSED_41.S
new file mode 100644
index 0000000..aa4635d
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_UNUSED_41.S
@@ -0,0 +1 @@
+%include "armv5te_taint/unused.S"
diff --git a/vm/mterp/armv5te_taint/OP_UNUSED_42.S b/vm/mterp/armv5te_taint/OP_UNUSED_42.S
new file mode 100644
index 0000000..aa4635d
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_UNUSED_42.S
@@ -0,0 +1 @@
+%include "armv5te_taint/unused.S"
diff --git a/vm/mterp/armv5te_taint/OP_UNUSED_43.S b/vm/mterp/armv5te_taint/OP_UNUSED_43.S
new file mode 100644
index 0000000..aa4635d
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_UNUSED_43.S
@@ -0,0 +1 @@
+%include "armv5te_taint/unused.S"
diff --git a/vm/mterp/armv5te_taint/OP_UNUSED_73.S b/vm/mterp/armv5te_taint/OP_UNUSED_73.S
new file mode 100644
index 0000000..aa4635d
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_UNUSED_73.S
@@ -0,0 +1 @@
+%include "armv5te_taint/unused.S"
diff --git a/vm/mterp/armv5te_taint/OP_UNUSED_79.S b/vm/mterp/armv5te_taint/OP_UNUSED_79.S
new file mode 100644
index 0000000..aa4635d
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_UNUSED_79.S
@@ -0,0 +1 @@
+%include "armv5te_taint/unused.S"
diff --git a/vm/mterp/armv5te_taint/OP_UNUSED_7A.S b/vm/mterp/armv5te_taint/OP_UNUSED_7A.S
new file mode 100644
index 0000000..aa4635d
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_UNUSED_7A.S
@@ -0,0 +1 @@
+%include "armv5te_taint/unused.S"
diff --git a/vm/mterp/armv5te_taint/OP_UNUSED_FF.S b/vm/mterp/armv5te_taint/OP_UNUSED_FF.S
new file mode 100644
index 0000000..aa4635d
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_UNUSED_FF.S
@@ -0,0 +1 @@
+%include "armv5te_taint/unused.S"
diff --git a/vm/mterp/armv5te_taint/OP_USHR_INT.S b/vm/mterp/armv5te_taint/OP_USHR_INT.S
new file mode 100644
index 0000000..3a2b5df
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_USHR_INT.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te_taint/binop.S" {"preinstr":"and     r1, r1, #31", "instr":"mov     r0, r0, lsr r1"}
diff --git a/vm/mterp/armv5te_taint/OP_USHR_INT_2ADDR.S b/vm/mterp/armv5te_taint/OP_USHR_INT_2ADDR.S
new file mode 100644
index 0000000..ef27d16
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_USHR_INT_2ADDR.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te_taint/binop2addr.S" {"preinstr":"and     r1, r1, #31", "instr":"mov     r0, r0, lsr r1"}
diff --git a/vm/mterp/armv5te_taint/OP_USHR_INT_LIT8.S b/vm/mterp/armv5te_taint/OP_USHR_INT_LIT8.S
new file mode 100644
index 0000000..b66bac0
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_USHR_INT_LIT8.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te_taint/binopLit8.S" {"preinstr":"and     r1, r1, #31", "instr":"mov     r0, r0, lsr r1"}
diff --git a/vm/mterp/armv5te_taint/OP_USHR_LONG.S b/vm/mterp/armv5te_taint/OP_USHR_LONG.S
new file mode 100644
index 0000000..88226a0
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_USHR_LONG.S
@@ -0,0 +1,50 @@
+%verify "executed"
+    /*
+     * Long integer shift.  This is different from the generic 32/64-bit
+     * binary operations because vAA/vBB are 64-bit but vCC (the shift
+     * distance) is 32-bit.  Also, Dalvik requires us to mask off the low
+     * 6 bits of the shift distance.
+     */
+    /* ushr-long vAA, vBB, vCC */
+    FETCH(r0, 1)                        @ r0<- CCBB
+    mov     r9, rINST, lsr #8           @ r9<- AA
+    and     r3, r0, #255                @ r3<- BB
+    mov     r0, r0, lsr #8              @ r0<- CC
+// begin WITH_TAINT_TRACKING
+    bl      ushr_long_taint_prop
+// end WITH_TAINT_TRACKING
+
+    mov     r0, r0, lsr r2              @  r0<- r2 >> r2
+    rsb     r3, r2, #32                 @  r3<- 32 - r2
+    orr     r0, r0, r1, asl r3          @  r0<- r0 | (r1 << (32-r2))
+    subs    ip, r2, #32                 @  ip<- r2 - 32
+    movpl   r0, r1, lsr ip              @  if r2 >= 32, r0<-r1 >>> (r2-32)
+    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
+    b       .L${opcode}_finish
+%break
+
+.L${opcode}_finish:
+    mov     r1, r1, lsr r2              @  r1<- r1 >>> r2
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+// begin WITH_TAINT_TRACKING
+//    stmia   r9, {r0-r1}                 @ vAA/vAA+1<- r0/r1
+    str     r0, [r9, #0]
+    str     r10, [r9, #4]
+    str     r1, [r9, #8]
+    str     r10, [r9, #12]
+// end WITH_TAINT_TRACKING
+    GOTO_OPCODE(ip)                     @ jump to next instruction
+
+ushr_long_taint_prop:
+    add     r3, rFP, r3, lsl #3         @ r3<- &fp[BB]
+    GET_VREG(r2, r0)                    @ r2<- vCC
+    SET_TAINT_FP(r1)
+    GET_VREG_TAINT(r0, r0, r1)
+//    ldmia   r3, {r0-r1}                 @ r0/r1<- vBB/vBB+1
+    ldr     r1, [r3, #4]
+    orr     r10, r0, r1
+    ldr     r0, [r3, #0]
+    ldr     r1, [r3, #8]
+    and     r2, r2, #63                 @ r0<- r0 & 0x3f
+    add     r9, rFP, r9, lsl #3         @ r9<- &fp[AA]
+    bx      lr
diff --git a/vm/mterp/armv5te_taint/OP_USHR_LONG_2ADDR.S b/vm/mterp/armv5te_taint/OP_USHR_LONG_2ADDR.S
new file mode 100644
index 0000000..401894e
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_USHR_LONG_2ADDR.S
@@ -0,0 +1,46 @@
+%verify "executed"
+    /*
+     * Long integer shift, 2addr version.  vA is 64-bit value/result, vB is
+     * 32-bit shift distance.
+     */
+    /* ushr-long/2addr vA, vB */
+    mov     r9, rINST, lsr #8           @ r9<- A+
+    mov     r3, rINST, lsr #12          @ r3<- B
+    and     r9, r9, #15
+    GET_VREG(r2, r3)                    @ r2<- vB
+// begin WITH_TAINT_TRACKING
+    bl      ushr_long_2addr_taint_prop
+// end WITH_TAINT_TRACKING
+
+    mov     r0, r0, lsr r2              @  r0<- r2 >> r2
+    rsb     r3, r2, #32                 @  r3<- 32 - r2
+    orr     r0, r0, r1, asl r3          @  r0<- r0 | (r1 << (32-r2))
+    subs    ip, r2, #32                 @  ip<- r2 - 32
+    FETCH_ADVANCE_INST(1)               @ advance rPC, load rINST
+    movpl   r0, r1, lsr ip              @  if r2 >= 32, r0<-r1 >>> (r2-32)
+    mov     r1, r1, lsr r2              @  r1<- r1 >>> r2
+    b       .L${opcode}_finish
+%break
+
+.L${opcode}_finish:
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+// begin WITH_TAINT_TRACKING
+//    stmia   r9, {r0-r1}                 @ vAA/vAA+1<- r0/r1
+    str     r0, [r9, #0]
+    str     r10, [r9, #4]
+    str     r1, [r9, #8]
+    str     r10, [r9, #12]
+// end WITH_TAINT_TRACKING
+    GOTO_OPCODE(ip)                     @ jump to next instruction
+
+ushr_long_2addr_taint_prop:
+    SET_TAINT_FP(r0)
+    GET_VREG_TAINT(r0, r3, r0)
+    add     r9, rFP, r9, lsl #3         @ r9<- &fp[A]
+    and     r2, r2, #63                 @ r2<- r2 & 0x3f
+//    ldmia   r9, {r0-r1}                 @ r0/r1<- vAA/vAA+1
+    ldr     r10, [r9, #4]
+    orr     r10, r0, r10
+    ldr     r0, [r9, #0]
+    ldr     r1, [r9, #8]
+    bx      lr
diff --git a/vm/mterp/armv5te_taint/OP_XOR_INT.S b/vm/mterp/armv5te_taint/OP_XOR_INT.S
new file mode 100644
index 0000000..9b992c3
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_XOR_INT.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te_taint/binop.S" {"instr":"eor     r0, r0, r1"}
diff --git a/vm/mterp/armv5te_taint/OP_XOR_INT_2ADDR.S b/vm/mterp/armv5te_taint/OP_XOR_INT_2ADDR.S
new file mode 100644
index 0000000..623a33d
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_XOR_INT_2ADDR.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te_taint/binop2addr.S" {"instr":"eor     r0, r0, r1"}
diff --git a/vm/mterp/armv5te_taint/OP_XOR_INT_LIT16.S b/vm/mterp/armv5te_taint/OP_XOR_INT_LIT16.S
new file mode 100644
index 0000000..e3e7556
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_XOR_INT_LIT16.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te_taint/binopLit16.S" {"instr":"eor     r0, r0, r1"}
diff --git a/vm/mterp/armv5te_taint/OP_XOR_INT_LIT8.S b/vm/mterp/armv5te_taint/OP_XOR_INT_LIT8.S
new file mode 100644
index 0000000..8242c37
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_XOR_INT_LIT8.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te_taint/binopLit8.S" {"instr":"eor     r0, r0, r1"}
diff --git a/vm/mterp/armv5te_taint/OP_XOR_LONG.S b/vm/mterp/armv5te_taint/OP_XOR_LONG.S
new file mode 100644
index 0000000..7abf4f6
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_XOR_LONG.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te_taint/binopWide.S" {"preinstr":"eor     r0, r0, r2", "instr":"eor     r1, r1, r3"}
diff --git a/vm/mterp/armv5te_taint/OP_XOR_LONG_2ADDR.S b/vm/mterp/armv5te_taint/OP_XOR_LONG_2ADDR.S
new file mode 100644
index 0000000..b5e4f9e
--- /dev/null
+++ b/vm/mterp/armv5te_taint/OP_XOR_LONG_2ADDR.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv5te_taint/binopWide2addr.S" {"preinstr":"eor     r0, r0, r2", "instr":"eor     r1, r1, r3"}
diff --git a/vm/mterp/armv5te_taint/alt_stub.S b/vm/mterp/armv5te_taint/alt_stub.S
new file mode 100644
index 0000000..4ab5f9f
--- /dev/null
+++ b/vm/mterp/armv5te_taint/alt_stub.S
@@ -0,0 +1,18 @@
+/*
+ * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
+ * any interesting requests and then jump to the real instruction
+ * handler.    Note that the call to dvmCheckBefore is done as a tail call.
+ * rIBASE updates won't be seen until a refresh, and we can tell we have a
+ * stale rIBASE if breakFlags==0.  Always refresh rIBASE here, and then
+ * bail to the real handler if breakFlags==0.
+ */
+    ldrb   r3, [rSELF, #offThread_breakFlags]
+    adrl   lr, dvmAsmInstructionStart + (${opnum} * 64)
+    ldr    rIBASE, [rSELF, #offThread_curHandlerTable]
+    cmp    r3, #0
+    bxeq   lr                   @ nothing to do - jump to real handler
+    EXPORT_PC()
+    mov    r0, rPC              @ arg0
+    mov    r1, rFP              @ arg1
+    mov    r2, rSELF            @ arg2
+    b      dvmCheckBefore       @ (dPC,dFP,self) tail call
diff --git a/vm/mterp/armv5te_taint/bincmp.S b/vm/mterp/armv5te_taint/bincmp.S
new file mode 100644
index 0000000..12a2c8c
--- /dev/null
+++ b/vm/mterp/armv5te_taint/bincmp.S
@@ -0,0 +1,30 @@
+%verify "branch taken"
+%verify "branch not taken"
+    /*
+     * Generic two-operand compare-and-branch operation.  Provide a "revcmp"
+     * fragment that specifies the *reverse* comparison to perform, e.g.
+     * for "if-le" you would use "gt".
+     *
+     * For: if-eq, if-ne, if-lt, if-ge, if-gt, if-le
+     */
+    /* if-cmp vA, vB, +CCCC */
+    mov     r0, rINST, lsr #8           @ r0<- A+
+    mov     r1, rINST, lsr #12          @ r1<- B
+    and     r0, r0, #15
+    GET_VREG(r3, r1)                    @ r3<- vB
+    GET_VREG(r2, r0)                    @ r2<- vA
+    FETCH_S(r1, 1)                      @ r1<- branch offset, in code units
+    cmp     r2, r3                      @ compare (vA, vB)
+    mov${revcmp} r1, #2                 @ r1<- BYTE branch dist for not-taken
+    adds    r2, r1, r1                  @ convert to bytes, check sign
+    FETCH_ADVANCE_INST_RB(r2)           @ update rPC, load rINST
+#if defined(WITH_JIT)
+    ldr     r0, [rSELF, #offThread_pJitProfTable]
+    ldrmi   rIBASE, [rSELF, #offThread_curHandlerTable]  @ refresh rIBASE
+    cmp     r0,#0
+    bne     common_updateProfile
+#else
+    ldrmi   rIBASE, [rSELF, #offThread_curHandlerTable]  @ refresh rIBASE
+#endif
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+    GOTO_OPCODE(ip)                     @ jump to next instruction
diff --git a/vm/mterp/armv5te_taint/binop.S b/vm/mterp/armv5te_taint/binop.S
new file mode 100644
index 0000000..c29dd30
--- /dev/null
+++ b/vm/mterp/armv5te_taint/binop.S
@@ -0,0 +1,48 @@
+%default {"preinstr":"", "result":"r0", "chkzero":"0"}
+    /*
+     * Generic 32-bit binary operation.  Provide an "instr" line that
+     * specifies an instruction that performs "result = r0 op r1".
+     * This could be an ARM instruction or a function call.  (If the result
+     * comes back in a register other than r0, you can override "result".)
+     *
+     * If "chkzero" is set to 1, we perform a divide-by-zero check on
+     * vCC (r1).  Useful for integer division and modulus.  Note that we
+     * *don't* check for (INT_MIN / -1) here, because the ARM math lib
+     * handles it correctly.
+     *
+     * For: add-int, sub-int, mul-int, div-int, rem-int, and-int, or-int,
+     *      xor-int, shl-int, shr-int, ushr-int, add-float, sub-float,
+     *      mul-float, div-float, rem-float
+     */
+    /* binop vAA, vBB, vCC */
+    FETCH(r0, 1)                        @ r0<- CCBB
+    mov     r9, rINST, lsr #8           @ r9<- AA
+    mov     r3, r0, lsr #8              @ r3<- CC
+    and     r2, r0, #255                @ r2<- BB
+    GET_VREG(r1, r3)                    @ r1<- vCC
+    GET_VREG(r0, r2)                    @ r0<- vBB
+    .if $chkzero
+    cmp     r1, #0                      @ is second operand zero?
+    beq     common_errDivideByZero
+    .endif
+
+// begin WITH_TAINT_TRACKING
+    bl      .L${opcode}_taint_prop
+// end WITH_TAINT_TRACKING
+    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
+    $preinstr                           @ optional op; may set condition codes
+    $instr                              @ $result<- op, r0-r3 changed
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+    SET_VREG($result, r9)               @ vAA<- $result
+    GOTO_OPCODE(ip)                     @ jump to next instruction
+    /* 11-14 instructions */
+
+%break
+
+.L${opcode}_taint_prop:
+    SET_TAINT_FP(r10)
+    GET_VREG_TAINT(r3, r3, r10)
+    GET_VREG_TAINT(r2, r2, r10)
+    orr     r2, r3, r2
+    SET_VREG_TAINT(r2, r9, r10)
+    bx      lr
diff --git a/vm/mterp/armv5te_taint/binop2addr.S b/vm/mterp/armv5te_taint/binop2addr.S
new file mode 100644
index 0000000..1e3de01
--- /dev/null
+++ b/vm/mterp/armv5te_taint/binop2addr.S
@@ -0,0 +1,47 @@
+%default {"preinstr":"", "result":"r0", "chkzero":"0"}
+    /*
+     * Generic 32-bit "/2addr" binary operation.  Provide an "instr" line
+     * that specifies an instruction that performs "result = r0 op r1".
+     * This could be an ARM instruction or a function call.  (If the result
+     * comes back in a register other than r0, you can override "result".)
+     *
+     * If "chkzero" is set to 1, we perform a divide-by-zero check on
+     * vCC (r1).  Useful for integer division and modulus.
+     *
+     * For: add-int/2addr, sub-int/2addr, mul-int/2addr, div-int/2addr,
+     *      rem-int/2addr, and-int/2addr, or-int/2addr, xor-int/2addr,
+     *      shl-int/2addr, shr-int/2addr, ushr-int/2addr, add-float/2addr,
+     *      sub-float/2addr, mul-float/2addr, div-float/2addr, rem-float/2addr
+     */
+    /* binop/2addr vA, vB */
+    mov     r9, rINST, lsr #8           @ r9<- A+
+    mov     r3, rINST, lsr #12          @ r3<- B
+    and     r9, r9, #15
+    GET_VREG(r1, r3)                    @ r1<- vB
+    GET_VREG(r0, r9)                    @ r0<- vA
+    .if $chkzero
+    cmp     r1, #0                      @ is second operand zero?
+    beq     common_errDivideByZero
+    .endif
+
+// begin WITH_TAINT_TRACKING
+    bl      .L${opcode}_taint_prop
+// end WITH_TAINT_TRACKING
+    FETCH_ADVANCE_INST(1)               @ advance rPC, load rINST
+
+    $preinstr                           @ optional op; may set condition codes
+    $instr                              @ $result<- op, r0-r3 changed
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+    SET_VREG($result, r9)               @ vAA<- $result
+    GOTO_OPCODE(ip)                     @ jump to next instruction
+    /* 10-13 instructions */
+
+%break
+
+.L${opcode}_taint_prop:
+    SET_TAINT_FP(r10)
+    GET_VREG_TAINT(r3, r3, r10)
+    GET_VREG_TAINT(r2, r9, r10)
+    orr     r2, r3, r2
+    SET_VREG_TAINT(r2, r9, r10)
+    bx      lr
diff --git a/vm/mterp/armv5te_taint/binopLit16.S b/vm/mterp/armv5te_taint/binopLit16.S
new file mode 100644
index 0000000..7d560e1
--- /dev/null
+++ b/vm/mterp/armv5te_taint/binopLit16.S
@@ -0,0 +1,36 @@
+%default {"result":"r0", "chkzero":"0"}
+    /*
+     * Generic 32-bit "lit16" binary operation.  Provide an "instr" line
+     * that specifies an instruction that performs "result = r0 op r1".
+     * This could be an ARM instruction or a function call.  (If the result
+     * comes back in a register other than r0, you can override "result".)
+     *
+     * If "chkzero" is set to 1, we perform a divide-by-zero check on
+     * vCC (r1).  Useful for integer division and modulus.
+     *
+     * For: add-int/lit16, rsub-int, mul-int/lit16, div-int/lit16,
+     *      rem-int/lit16, and-int/lit16, or-int/lit16, xor-int/lit16
+     */
+    /* binop/lit16 vA, vB, #+CCCC */
+    FETCH_S(r1, 1)                      @ r1<- ssssCCCC (sign-extended)
+    mov     r2, rINST, lsr #12          @ r2<- B
+    mov     r9, rINST, lsr #8           @ r9<- A+
+    GET_VREG(r0, r2)                    @ r0<- vB
+    and     r9, r9, #15
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r3)                    @ r3<- rFP+4
+    GET_VREG_TAINT(r2, r2, r3)          @ r2<- vB.taint
+    SET_VREG_TAINT(r2, r9, r3)
+// end WITH_TAINT_TRACKING
+    .if $chkzero
+    cmp     r1, #0                      @ is second operand zero?
+    beq     common_errDivideByZero
+    .endif
+    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
+
+    $instr                              @ $result<- op, r0-r3 changed
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+    SET_VREG($result, r9)               @ vAA<- $result
+    GOTO_OPCODE(ip)                     @ jump to next instruction
+    /* 10-13 instructions */
+
diff --git a/vm/mterp/armv5te_taint/binopLit8.S b/vm/mterp/armv5te_taint/binopLit8.S
new file mode 100644
index 0000000..64d1cc5
--- /dev/null
+++ b/vm/mterp/armv5te_taint/binopLit8.S
@@ -0,0 +1,38 @@
+%default {"preinstr":"", "result":"r0", "chkzero":"0"}
+    /*
+     * Generic 32-bit "lit8" binary operation.  Provide an "instr" line
+     * that specifies an instruction that performs "result = r0 op r1".
+     * This could be an ARM instruction or a function call.  (If the result
+     * comes back in a register other than r0, you can override "result".)
+     *
+     * If "chkzero" is set to 1, we perform a divide-by-zero check on
+     * vCC (r1).  Useful for integer division and modulus.
+     *
+     * For: add-int/lit8, rsub-int/lit8, mul-int/lit8, div-int/lit8,
+     *      rem-int/lit8, and-int/lit8, or-int/lit8, xor-int/lit8,
+     *      shl-int/lit8, shr-int/lit8, ushr-int/lit8
+     */
+    /* binop/lit8 vAA, vBB, #+CC */
+    FETCH_S(r3, 1)                      @ r3<- ssssCCBB (sign-extended for CC)
+    mov     r9, rINST, lsr #8           @ r9<- AA
+    and     r2, r3, #255                @ r2<- BB
+    GET_VREG(r0, r2)                    @ r0<- vBB
+    movs    r1, r3, asr #8              @ r1<- ssssssCC (sign extended)
+    .if $chkzero
+    @cmp     r1, #0                      @ is second operand zero?
+    beq     common_errDivideByZero
+    .endif
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r10)                   @ r3<- rFP+4
+    GET_VREG_TAINT(r2, r2, r10)         @ r2<- vB.taint
+    SET_VREG_TAINT(r2, r9, r10)
+// end WITH_TAINT_TRACKING
+    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
+
+    $preinstr                           @ optional op; may set condition codes
+    $instr                              @ $result<- op, r0-r3 changed
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+    SET_VREG($result, r9)               @ vAA<- $result
+    GOTO_OPCODE(ip)                     @ jump to next instruction
+    /* 10-12 instructions */
+
diff --git a/vm/mterp/armv5te_taint/binopWide.S b/vm/mterp/armv5te_taint/binopWide.S
new file mode 100644
index 0000000..2e2eb58
--- /dev/null
+++ b/vm/mterp/armv5te_taint/binopWide.S
@@ -0,0 +1,61 @@
+%default {"preinstr":"", "result0":"r0", "result1":"r1", "chkzero":"0"}
+    /*
+     * Generic 64-bit binary operation.  Provide an "instr" line that
+     * specifies an instruction that performs "result = r0-r1 op r2-r3".
+     * This could be an ARM instruction or a function call.  (If the result
+     * comes back in a register other than r0, you can override "result".)
+     *
+     * If "chkzero" is set to 1, we perform a divide-by-zero check on
+     * vCC (r1).  Useful for integer division and modulus.
+     *
+     * for: add-long, sub-long, div-long, rem-long, and-long, or-long,
+     *      xor-long, add-double, sub-double, mul-double, div-double,
+     *      rem-double
+     *
+     * IMPORTANT: you may specify "chkzero" or "preinstr" but not both.
+     */
+    /* binop vAA, vBB, vCC */
+    FETCH(r0, 1)                        @ r0<- CCBB
+    mov     r9, rINST, lsr #8           @ r9<- AA
+    and     r2, r0, #255                @ r2<- BB
+    mov     r3, r0, lsr #8              @ r3<- CC
+// begin WITH_TAINT_TRACKING
+    bl      .L${opcode}_taint_prop
+// end WITH_TAINT_TRACKING
+    .if $chkzero
+    orrs    ip, r2, r3                  @ second arg (r2-r3) is zero?
+    beq     common_errDivideByZero
+    .endif
+    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
+
+    $preinstr                           @ optional op; may set condition codes
+    $instr                              @ result<- op, r0-r3 changed
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+// begin WITH_TAINT_TRACKING
+//    stmia   r9, {$result0,$result1}     @ vAA/vAA+1<- $result0/$result1
+    str     $result0, [r9, #0]
+    str     r10, [r9, #4]
+    str     $result1, [r9, #8]
+    str     r10, [r9, #12]
+// end WITH_TAINT_TRACKING
+    GOTO_OPCODE(ip)                     @ jump to next instruction
+    /* 14-17 instructions */
+
+%break
+
+.L${opcode}_taint_prop:
+    add     r9, rFP, r9, lsl #3         @ r9<- &fp[AA]
+    stmfd   sp!, {r9}
+    add     r2, rFP, r2, lsl #3         @ r2<- &fp[BB]
+    add     r3, rFP, r3, lsl #3         @ r3<- &fp[CC]
+//    ldmia   r2, {r0-r1}                 @ r0/r1<- vBB/vBB+1
+    ldr     r0, [r2, #0]
+    ldr     r9, [r2, #4]
+    ldr     r1, [r2, #8]
+//    ldmia   r3, {r2-r3}                 @ r2/r3<- vCC/vCC+1
+    ldr     r2, [r3, #0]
+    ldr     r10, [r3, #4]
+    ldr     r3, [r3, #8]
+    orr     r10, r9, r10
+    ldmfd   sp!, {r9}
+    bx      lr
diff --git a/vm/mterp/armv5te_taint/binopWide2addr.S b/vm/mterp/armv5te_taint/binopWide2addr.S
new file mode 100644
index 0000000..3d341a6
--- /dev/null
+++ b/vm/mterp/armv5te_taint/binopWide2addr.S
@@ -0,0 +1,58 @@
+%default {"preinstr":"", "result0":"r0", "result1":"r1", "chkzero":"0"}
+    /*
+     * Generic 64-bit "/2addr" binary operation.  Provide an "instr" line
+     * that specifies an instruction that performs "result = r0-r1 op r2-r3".
+     * This could be an ARM instruction or a function call.  (If the result
+     * comes back in a register other than r0, you can override "result".)
+     *
+     * If "chkzero" is set to 1, we perform a divide-by-zero check on
+     * vCC (r1).  Useful for integer division and modulus.
+     *
+     * For: add-long/2addr, sub-long/2addr, div-long/2addr, rem-long/2addr,
+     *      and-long/2addr, or-long/2addr, xor-long/2addr, add-double/2addr,
+     *      sub-double/2addr, mul-double/2addr, div-double/2addr,
+     *      rem-double/2addr
+     */
+    /* binop/2addr vA, vB */
+    mov     r9, rINST, lsr #8           @ r9<- A+
+    mov     r1, rINST, lsr #12          @ r1<- B
+    and     r9, r9, #15
+// begin WITH_TAINT_TRACKING
+    bl     .L${opcode}_taint_prop
+// end WITH_TAINT_TRACKING
+    .if $chkzero
+    orrs    ip, r2, r3                  @ second arg (r2-r3) is zero?
+    beq     common_errDivideByZero
+    .endif
+    FETCH_ADVANCE_INST(1)               @ advance rPC, load rINST
+
+    $preinstr                           @ optional op; may set condition codes
+    $instr                              @ result<- op, r0-r3 changed
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+// begin WITH_TAINT_TRACKING
+//    stmia   r9, {$result0,$result1}     @ vAA/vAA+1<- $result0/$result1
+    str     $result0, [r9, #0]
+    str     r10, [r9, #4]
+    str     $result1, [r9, #8]
+    str     r10, [r9, #12]
+// end WITH_TAINT_TRACKING
+    GOTO_OPCODE(ip)                     @ jump to next instruction
+    /* 12-15 instructions */
+
+%break
+
+.L${opcode}_taint_prop:
+    add     r1, rFP, r1, lsl #3         @ r1<- &fp[B]
+    add     r9, rFP, r9, lsl #3         @ r9<- &fp[A]
+//    ldmia   r1, {r2-r3}                 @ r2/r3<- vBB/vBB+1
+    ldr     r2, [r1, #0]
+    ldr     r10, [r1, #4]
+    ldr     r3, [r1, #8]
+//    ldmia   r9, {r0-r1}                 @ r0/r1<- vAA/vAA+1
+    ldr     r0, [r9, #0]
+    ldr     r1, [r9, #8]
+    stmfd   sp!, {r9}
+    ldr     r9, [r9, #4]
+    orr     r10, r9, r10
+    ldmfd   sp!, {r9}
+    bx      lr
diff --git a/vm/mterp/armv5te_taint/debug.cpp b/vm/mterp/armv5te_taint/debug.cpp
new file mode 100644
index 0000000..570e432
--- /dev/null
+++ b/vm/mterp/armv5te_taint/debug.cpp
@@ -0,0 +1,82 @@
+#include <inttypes.h>
+
+/*
+ * Dump the fixed-purpose ARM registers, along with some other info.
+ *
+ * This function MUST be compiled in ARM mode -- THUMB will yield bogus
+ * results.
+ *
+ * This will NOT preserve r0-r3/ip.
+ */
+void dvmMterpDumpArmRegs(uint32_t r0, uint32_t r1, uint32_t r2, uint32_t r3)
+{
+  // TODO: Clang does not support asm declaration syntax.
+#ifndef __clang__
+    register uint32_t rPC       asm("r4");
+    register uint32_t rFP       asm("r5");
+    register uint32_t rSELF     asm("r6");
+    register uint32_t rINST     asm("r7");
+    register uint32_t rIBASE    asm("r8");
+    register uint32_t r9        asm("r9");
+    register uint32_t r10       asm("r10");
+
+    //extern char dvmAsmInstructionStart[];
+
+    printf("REGS: r0=%08x r1=%08x r2=%08x r3=%08x\n", r0, r1, r2, r3);
+    printf("    : rPC=%08x rFP=%08x rSELF=%08x rINST=%08x\n",
+        rPC, rFP, rSELF, rINST);
+    printf("    : rIBASE=%08x r9=%08x r10=%08x\n", rIBASE, r9, r10);
+#endif
+
+    //Thread* self = (Thread*) rSELF;
+    //const Method* method = self->method;
+    printf("    + self is %p\n", dvmThreadSelf());
+    //printf("    + currently in %s.%s %s\n",
+    //    method->clazz->descriptor, method->name, method->shorty);
+    //printf("    + dvmAsmInstructionStart = %p\n", dvmAsmInstructionStart);
+    //printf("    + next handler for 0x%02x = %p\n",
+    //    rINST & 0xff, dvmAsmInstructionStart + (rINST & 0xff) * 64);
+}
+
+/*
+ * Dump the StackSaveArea for the specified frame pointer.
+ */
+void dvmDumpFp(void* fp, StackSaveArea* otherSaveArea)
+{
+    StackSaveArea* saveArea = SAVEAREA_FROM_FP(fp);
+    printf("StackSaveArea for fp %p [%p/%p]:\n", fp, saveArea, otherSaveArea);
+#ifdef EASY_GDB
+    printf("  prevSave=%p, prevFrame=%p savedPc=%p meth=%p curPc=%p\n",
+        saveArea->prevSave, saveArea->prevFrame, saveArea->savedPc,
+        saveArea->method, saveArea->xtra.currentPc);
+#else
+    printf("  prevFrame=%p savedPc=%p meth=%p curPc=%p fp[0]=0x%08x\n",
+        saveArea->prevFrame, saveArea->savedPc,
+        saveArea->method, saveArea->xtra.currentPc,
+        *(u4*)fp);
+#endif
+}
+
+/*
+ * Does the bulk of the work for common_printMethod().
+ */
+void dvmMterpPrintMethod(Method* method)
+{
+    /*
+     * It is a direct (non-virtual) method if it is static, private,
+     * or a constructor.
+     */
+    bool isDirect =
+        ((method->accessFlags & (ACC_STATIC|ACC_PRIVATE)) != 0) ||
+        (method->name[0] == '<');
+
+    char* desc = dexProtoCopyMethodDescriptor(&method->prototype);
+
+    printf("<%c:%s.%s %s> ",
+            isDirect ? 'D' : 'V',
+            method->clazz->descriptor,
+            method->name,
+            desc);
+
+    free(desc);
+}
diff --git a/vm/mterp/armv5te_taint/debug.cpp~ b/vm/mterp/armv5te_taint/debug.cpp~
new file mode 100644
index 0000000..5fcb91e
--- /dev/null
+++ b/vm/mterp/armv5te_taint/debug.cpp~
@@ -0,0 +1,81 @@
+#include <inttypes.h>
+
+/*
+ * Dump the fixed-purpose ARM registers, along with some other info.
+ *
+ * This function MUST be compiled in ARM mode -- THUMB will yield bogus
+ * results.
+ *
+ * This will NOT preserve r0-r3/ip.
+ */
+void dvmMterpDumpArmRegs(uint32_t r0, uint32_t r1, uint32_t r2, uint32_t r3)
+{
+  // TODO: Clang does not support asm declaration syntax.
+#ifndef __clang__
+    register uint32_t rPC       asm("r4");
+    register uint32_t rFP       asm("r5");
+    register uint32_t rSELF     asm("r6");
+    register uint32_t rINST     asm("r7");
+    register uint32_t rIBASE    asm("r8");
+    register uint32_t r9        asm("r9");
+    register uint32_t r10       asm("r10");
+
+    //extern char dvmAsmInstructionStart[];
+
+    printf("REGS: r0=%08x r1=%08x r2=%08x r3=%08x\n", r0, r1, r2, r3);
+    printf("    : rPC=%08x rFP=%08x rSELF=%08x rINST=%08x\n",
+        rPC, rFP, rSELF, rINST);
+    printf("    : rIBASE=%08x r9=%08x r10=%08x\n", rIBASE, r9, r10);
+
+    //Thread* self = (Thread*) rSELF;
+    //const Method* method = self->method;
+    printf("    + self is %p\n", dvmThreadSelf());
+    //printf("    + currently in %s.%s %s\n",
+    //    method->clazz->descriptor, method->name, method->shorty);
+    //printf("    + dvmAsmInstructionStart = %p\n", dvmAsmInstructionStart);
+    //printf("    + next handler for 0x%02x = %p\n",
+    //    rINST & 0xff, dvmAsmInstructionStart + (rINST & 0xff) * 64);
+}
+
+/*
+ * Dump the StackSaveArea for the specified frame pointer.
+ */
+void dvmDumpFp(void* fp, StackSaveArea* otherSaveArea)
+{
+    StackSaveArea* saveArea = SAVEAREA_FROM_FP(fp);
+    printf("StackSaveArea for fp %p [%p/%p]:\n", fp, saveArea, otherSaveArea);
+#ifdef EASY_GDB
+    printf("  prevSave=%p, prevFrame=%p savedPc=%p meth=%p curPc=%p\n",
+        saveArea->prevSave, saveArea->prevFrame, saveArea->savedPc,
+        saveArea->method, saveArea->xtra.currentPc);
+#else
+    printf("  prevFrame=%p savedPc=%p meth=%p curPc=%p fp[0]=0x%08x\n",
+        saveArea->prevFrame, saveArea->savedPc,
+        saveArea->method, saveArea->xtra.currentPc,
+        *(u4*)fp);
+#endif
+}
+
+/*
+ * Does the bulk of the work for common_printMethod().
+ */
+void dvmMterpPrintMethod(Method* method)
+{
+    /*
+     * It is a direct (non-virtual) method if it is static, private,
+     * or a constructor.
+     */
+    bool isDirect =
+        ((method->accessFlags & (ACC_STATIC|ACC_PRIVATE)) != 0) ||
+        (method->name[0] == '<');
+
+    char* desc = dexProtoCopyMethodDescriptor(&method->prototype);
+
+    printf("<%c:%s.%s %s> ",
+            isDirect ? 'D' : 'V',
+            method->clazz->descriptor,
+            method->name,
+            desc);
+
+    free(desc);
+}
diff --git a/vm/mterp/armv5te_taint/entry.S b/vm/mterp/armv5te_taint/entry.S
new file mode 100644
index 0000000..19b6d4b
--- /dev/null
+++ b/vm/mterp/armv5te_taint/entry.S
@@ -0,0 +1,130 @@
+/*
+ * Copyright (C) 2008 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+/*
+ * Interpreter entry point.
+ */
+
+/*
+ * We don't have formal stack frames, so gdb scans upward in the code
+ * to find the start of the function (a label with the %function type),
+ * and then looks at the next few instructions to figure out what
+ * got pushed onto the stack.  From this it figures out how to restore
+ * the registers, including PC, for the previous stack frame.  If gdb
+ * sees a non-function label, it stops scanning, so either we need to
+ * have nothing but assembler-local labels between the entry point and
+ * the break, or we need to fake it out.
+ *
+ * When this is defined, we add some stuff to make gdb less confused.
+ */
+#define ASSIST_DEBUGGER 1
+
+    .text
+    .align  2
+    .global dvmMterpStdRun
+    .type   dvmMterpStdRun, %function
+
+/*
+ * On entry:
+ *  r0  Thread* self
+ *
+ * The return comes via a call to dvmMterpStdBail().
+ */
+dvmMterpStdRun:
+#define MTERP_ENTRY1 \
+    .save {r4-r10,fp,lr}; \
+    stmfd   sp!, {r4-r10,fp,lr}         @ save 9 regs
+#define MTERP_ENTRY2 \
+    .pad    #4; \
+    sub     sp, sp, #4                  @ align 64
+
+    .fnstart
+    MTERP_ENTRY1
+    MTERP_ENTRY2
+
+    /* save stack pointer, add magic word for debuggerd */
+    str     sp, [r0, #offThread_bailPtr]  @ save SP for eventual return
+
+    /* set up "named" registers, figure out entry point */
+    mov     rSELF, r0                   @ set rSELF
+    LOAD_PC_FP_FROM_SELF()              @ load rPC and rFP from "thread"
+    ldr     rIBASE, [rSELF, #offThread_curHandlerTable] @ set rIBASE
+
+#if defined(WITH_JIT)
+.LentryInstr:
+    /* Entry is always a possible trace start */
+    ldr     r0, [rSELF, #offThread_pJitProfTable]
+    FETCH_INST()
+    mov     r1, #0                      @ prepare the value for the new state
+    str     r1, [rSELF, #offThread_inJitCodeCache] @ back to the interp land
+    cmp     r0,#0                       @ is profiling disabled?
+#if !defined(WITH_SELF_VERIFICATION)
+    bne     common_updateProfile        @ profiling is enabled
+#else
+    ldr     r2, [rSELF, #offThread_shadowSpace] @ to find out the jit exit state
+    beq     1f                          @ profiling is disabled
+    ldr     r3, [r2, #offShadowSpace_jitExitState]  @ jit exit state
+    cmp     r3, #kSVSTraceSelect        @ hot trace following?
+    moveq   r2,#kJitTSelectRequestHot   @ ask for trace selection
+    beq     common_selectTrace          @ go build the trace
+    cmp     r3, #kSVSNoProfile          @ don't profile the next instruction?
+    beq     1f                          @ intrepret the next instruction
+    b       common_updateProfile        @ collect profiles
+#endif
+1:
+    GET_INST_OPCODE(ip)
+    GOTO_OPCODE(ip)
+#else
+    /* start executing the instruction at rPC */
+    FETCH_INST()                        @ load rINST from rPC
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+    GOTO_OPCODE(ip)                     @ jump to next instruction
+#endif
+
+.Lbad_arg:
+    ldr     r0, strBadEntryPoint
+    @ r1 holds value of entryPoint
+    bl      printf
+    bl      dvmAbort
+    .fnend
+    .size   dvmMterpStdRun, .-dvmMterpStdRun
+
+
+    .global dvmMterpStdBail
+    .type   dvmMterpStdBail, %function
+
+/*
+ * Restore the stack pointer and PC from the save point established on entry.
+ * This is essentially the same as a longjmp, but should be cheaper.  The
+ * last instruction causes us to return to whoever called dvmMterpStdRun.
+ *
+ * We pushed some registers on the stack in dvmMterpStdRun, then saved
+ * SP and LR.  Here we restore SP, restore the registers, and then restore
+ * LR to PC.
+ *
+ * On entry:
+ *  r0  Thread* self
+ */
+dvmMterpStdBail:
+    ldr     sp, [r0, #offThread_bailPtr]    @ sp<- saved SP
+    add     sp, sp, #4                      @ un-align 64
+    ldmfd   sp!, {r4-r10,fp,pc}             @ restore 9 regs and return
+
+
+/*
+ * String references.
+ */
+strBadEntryPoint:
+    .word   .LstrBadEntryPoint
diff --git a/vm/mterp/armv5te_taint/footer.S b/vm/mterp/armv5te_taint/footer.S
new file mode 100644
index 0000000..1a4c10b
--- /dev/null
+++ b/vm/mterp/armv5te_taint/footer.S
@@ -0,0 +1,1365 @@
+/*
+ * ===========================================================================
+ *  Common subroutines and data
+ * ===========================================================================
+ */
+
+    .text
+    .align  2
+
+#if defined(WITH_JIT)
+
+#if defined(WITH_SELF_VERIFICATION)
+/*
+ * "longjmp" to a translation after single-stepping.  Before returning
+ * to translation, must save state for self-verification.
+ */
+    .global dvmJitResumeTranslation              @ (Thread* self, u4* dFP)
+dvmJitResumeTranslation:
+    mov    rSELF, r0                             @ restore self
+    mov    rPC, r1                               @ restore Dalvik pc
+    mov    rFP, r2                               @ restore Dalvik fp
+    ldr    r10, [rSELF,#offThread_jitResumeNPC]  @ resume address
+    mov    r2, #0
+    str    r2, [rSELF,#offThread_jitResumeNPC]   @ reset resume address
+    ldr    sp, [rSELF,#offThread_jitResumeNSP]   @ cut back native stack
+    b      jitSVShadowRunStart                   @ resume as if cache hit
+                                                 @ expects resume addr in r10
+
+    .global dvmJitToInterpPunt
+dvmJitToInterpPunt:
+    mov    r2,#kSVSPunt                 @ r2<- interpreter entry point
+    mov    r3, #0
+    str    r3, [rSELF, #offThread_inJitCodeCache] @ Back to the interp land
+    b      jitSVShadowRunEnd            @ doesn't return
+
+    .global dvmJitToInterpSingleStep
+dvmJitToInterpSingleStep:
+    mov    rPC, r0              @ set up dalvik pc
+    EXPORT_PC()
+    str    lr, [rSELF,#offThread_jitResumeNPC]
+    str    sp, [rSELF,#offThread_jitResumeNSP]
+    str    r1, [rSELF,#offThread_jitResumeDPC]
+    mov    r2,#kSVSSingleStep           @ r2<- interpreter entry point
+    b      jitSVShadowRunEnd            @ doesn't return
+
+
+    .global dvmJitToInterpNoChainNoProfile
+dvmJitToInterpNoChainNoProfile:
+    mov    r0,rPC                       @ pass our target PC
+    mov    r2,#kSVSNoProfile            @ r2<- interpreter entry point
+    mov    r3, #0                       @ 0 means !inJitCodeCache
+    str    r3, [rSELF, #offThread_inJitCodeCache] @ back to the interp land
+    b      jitSVShadowRunEnd            @ doesn't return
+
+    .global dvmJitToInterpTraceSelectNoChain
+dvmJitToInterpTraceSelectNoChain:
+    mov    r0,rPC                       @ pass our target PC
+    mov    r2,#kSVSTraceSelect          @ r2<- interpreter entry point
+    mov    r3, #0                       @ 0 means !inJitCodeCache
+    str    r3, [rSELF, #offThread_inJitCodeCache] @ Back to the interp land
+    b      jitSVShadowRunEnd            @ doesn't return
+
+    .global dvmJitToInterpTraceSelect
+dvmJitToInterpTraceSelect:
+    ldr    r0,[lr, #-1]                 @ pass our target PC
+    mov    r2,#kSVSTraceSelect          @ r2<- interpreter entry point
+    mov    r3, #0                       @ 0 means !inJitCodeCache
+    str    r3, [rSELF, #offThread_inJitCodeCache] @ Back to the interp land
+    b      jitSVShadowRunEnd            @ doesn't return
+
+    .global dvmJitToInterpBackwardBranch
+dvmJitToInterpBackwardBranch:
+    ldr    r0,[lr, #-1]                 @ pass our target PC
+    mov    r2,#kSVSBackwardBranch       @ r2<- interpreter entry point
+    mov    r3, #0                       @ 0 means !inJitCodeCache
+    str    r3, [rSELF, #offThread_inJitCodeCache] @ Back to the interp land
+    b      jitSVShadowRunEnd            @ doesn't return
+
+    .global dvmJitToInterpNormal
+dvmJitToInterpNormal:
+    ldr    r0,[lr, #-1]                 @ pass our target PC
+    mov    r2,#kSVSNormal               @ r2<- interpreter entry point
+    mov    r3, #0                       @ 0 means !inJitCodeCache
+    str    r3, [rSELF, #offThread_inJitCodeCache] @ Back to the interp land
+    b      jitSVShadowRunEnd            @ doesn't return
+
+    .global dvmJitToInterpNoChain
+dvmJitToInterpNoChain:
+    mov    r0,rPC                       @ pass our target PC
+    mov    r2,#kSVSNoChain              @ r2<- interpreter entry point
+    mov    r3, #0                       @ 0 means !inJitCodeCache
+    str    r3, [rSELF, #offThread_inJitCodeCache] @ Back to the interp land
+    b      jitSVShadowRunEnd            @ doesn't return
+#else
+
+/*
+ * "longjmp" to a translation after single-stepping.
+ */
+    .global dvmJitResumeTranslation              @ (Thread* self, u4* dFP)
+dvmJitResumeTranslation:
+    mov    rSELF, r0                             @ restore self
+    mov    rPC, r1                               @ restore Dalvik pc
+    mov    rFP, r2                               @ restore Dalvik fp
+    ldr    r0, [rSELF,#offThread_jitResumeNPC]
+    mov    r2, #0
+    str    r2, [rSELF,#offThread_jitResumeNPC]   @ reset resume address
+    ldr    sp, [rSELF,#offThread_jitResumeNSP]   @ cut back native stack
+    bx     r0                                    @ resume translation
+
+/*
+ * Return from the translation cache to the interpreter when the compiler is
+ * having issues translating/executing a Dalvik instruction. We have to skip
+ * the code cache lookup otherwise it is possible to indefinitely bouce
+ * between the interpreter and the code cache if the instruction that fails
+ * to be compiled happens to be at a trace start.
+ */
+    .global dvmJitToInterpPunt
+dvmJitToInterpPunt:
+    mov    rPC, r0
+#if defined(WITH_JIT_TUNING)
+    mov    r0,lr
+    bl     dvmBumpPunt;
+#endif
+    EXPORT_PC()
+    mov    r0, #0
+    str    r0, [rSELF, #offThread_inJitCodeCache] @ Back to the interp land
+    ldr    rIBASE, [rSELF, #offThread_curHandlerTable]
+    FETCH_INST()
+    GET_INST_OPCODE(ip)
+    GOTO_OPCODE(ip)
+
+/*
+ * Return to the interpreter to handle a single instruction.
+ * We'll use the normal single-stepping mechanism via interpBreak,
+ * but also save the native pc of the resume point in the translation
+ * and the native sp so that we can later do the equivalent of a
+ * longjmp() to resume.
+ * On entry:
+ *    dPC <= Dalvik PC of instrucion to interpret
+ *    lr <= resume point in translation
+ *    r1 <= Dalvik PC of next instruction
+ */
+    .global dvmJitToInterpSingleStep
+dvmJitToInterpSingleStep:
+    mov    rPC, r0              @ set up dalvik pc
+    EXPORT_PC()
+    str    lr, [rSELF,#offThread_jitResumeNPC]
+    str    sp, [rSELF,#offThread_jitResumeNSP]
+    str    r1, [rSELF,#offThread_jitResumeDPC]
+    mov    r1, #1
+    str    r1, [rSELF,#offThread_singleStepCount]  @ just step once
+    mov    r0, rSELF
+    mov    r1, #kSubModeCountedStep
+    bl     dvmEnableSubMode     @ (self, newMode)
+    ldr    rIBASE, [rSELF,#offThread_curHandlerTable]
+    FETCH_INST()
+    GET_INST_OPCODE(ip)
+    GOTO_OPCODE(ip)
+
+/*
+ * Return from the translation cache and immediately request
+ * a translation for the exit target.  Commonly used for callees.
+ */
+    .global dvmJitToInterpTraceSelectNoChain
+dvmJitToInterpTraceSelectNoChain:
+#if defined(WITH_JIT_TUNING)
+    bl     dvmBumpNoChain
+#endif
+    mov    r0,rPC
+    mov    r1,rSELF
+    bl     dvmJitGetTraceAddrThread @ (pc, self)
+    str    r0, [rSELF, #offThread_inJitCodeCache] @ set the inJitCodeCache flag
+    mov    r1, rPC                  @ arg1 of translation may need this
+    mov    lr, #0                   @  in case target is HANDLER_INTERPRET
+    cmp    r0,#0                    @ !0 means translation exists
+    bxne   r0                       @ continue native execution if so
+    b      2f                       @ branch over to use the interpreter
+
+/*
+ * Return from the translation cache and immediately request
+ * a translation for the exit target.  Commonly used following
+ * invokes.
+ */
+    .global dvmJitToInterpTraceSelect
+dvmJitToInterpTraceSelect:
+    ldr    rPC,[lr, #-1]           @ get our target PC
+    add    rINST,lr,#-5            @ save start of chain branch
+    add    rINST, #-4              @  .. which is 9 bytes back
+    mov    r0,rPC
+    mov    r1,rSELF
+    bl     dvmJitGetTraceAddrThread @ (pc, self)
+    str    r0, [rSELF, #offThread_inJitCodeCache] @ set the inJitCodeCache flag
+    cmp    r0,#0
+    beq    2f
+    mov    r1,rINST
+    bl     dvmJitChain              @ r0<- dvmJitChain(codeAddr,chainAddr)
+    mov    r1, rPC                  @ arg1 of translation may need this
+    mov    lr, #0                   @ in case target is HANDLER_INTERPRET
+    cmp    r0,#0                    @ successful chain?
+    bxne   r0                       @ continue native execution
+    b      toInterpreter            @ didn't chain - resume with interpreter
+
+/* No translation, so request one if profiling isn't disabled*/
+2:
+    ldr    rIBASE, [rSELF, #offThread_curHandlerTable]
+    ldr    r0, [rSELF, #offThread_pJitProfTable]
+    FETCH_INST()
+    cmp    r0, #0
+    movne  r2,#kJitTSelectRequestHot   @ ask for trace selection
+    bne    common_selectTrace
+    GET_INST_OPCODE(ip)
+    GOTO_OPCODE(ip)
+
+/*
+ * Return from the translation cache to the interpreter.
+ * The return was done with a BLX from thumb mode, and
+ * the following 32-bit word contains the target rPC value.
+ * Note that lr (r14) will have its low-order bit set to denote
+ * its thumb-mode origin.
+ *
+ * We'll need to stash our lr origin away, recover the new
+ * target and then check to see if there is a translation available
+ * for our new target.  If so, we do a translation chain and
+ * go back to native execution.  Otherwise, it's back to the
+ * interpreter (after treating this entry as a potential
+ * trace start).
+ */
+    .global dvmJitToInterpNormal
+dvmJitToInterpNormal:
+    ldr    rPC,[lr, #-1]           @ get our target PC
+    add    rINST,lr,#-5            @ save start of chain branch
+    add    rINST,#-4               @ .. which is 9 bytes back
+#if defined(WITH_JIT_TUNING)
+    bl     dvmBumpNormal
+#endif
+    mov    r0,rPC
+    mov    r1,rSELF
+    bl     dvmJitGetTraceAddrThread @ (pc, self)
+    str    r0, [rSELF, #offThread_inJitCodeCache] @ set the inJitCodeCache flag
+    cmp    r0,#0
+    beq    toInterpreter            @ go if not, otherwise do chain
+    mov    r1,rINST
+    bl     dvmJitChain              @ r0<- dvmJitChain(codeAddr,chainAddr)
+    mov    r1, rPC                  @ arg1 of translation may need this
+    mov    lr, #0                   @  in case target is HANDLER_INTERPRET
+    cmp    r0,#0                    @ successful chain?
+    bxne   r0                       @ continue native execution
+    b      toInterpreter            @ didn't chain - resume with interpreter
+
+/*
+ * Return from the translation cache to the interpreter to do method invocation.
+ * Check if translation exists for the callee, but don't chain to it.
+ */
+    .global dvmJitToInterpNoChainNoProfile
+dvmJitToInterpNoChainNoProfile:
+#if defined(WITH_JIT_TUNING)
+    bl     dvmBumpNoChain
+#endif
+    mov    r0,rPC
+    mov    r1,rSELF
+    bl     dvmJitGetTraceAddrThread @ (pc, self)
+    str    r0, [rSELF, #offThread_inJitCodeCache] @ set the inJitCodeCache flag
+    mov    r1, rPC                  @ arg1 of translation may need this
+    mov    lr, #0                   @  in case target is HANDLER_INTERPRET
+    cmp    r0,#0
+    bxne   r0                       @ continue native execution if so
+    EXPORT_PC()
+    ldr    rIBASE, [rSELF, #offThread_curHandlerTable]
+    FETCH_INST()
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+    GOTO_OPCODE(ip)                     @ jump to next instruction
+
+/*
+ * Return from the translation cache to the interpreter to do method invocation.
+ * Check if translation exists for the callee, but don't chain to it.
+ */
+    .global dvmJitToInterpNoChain
+dvmJitToInterpNoChain:
+#if defined(WITH_JIT_TUNING)
+    bl     dvmBumpNoChain
+#endif
+    mov    r0,rPC
+    mov    r1,rSELF
+    bl     dvmJitGetTraceAddrThread @ (pc, self)
+    str    r0, [rSELF, #offThread_inJitCodeCache] @ set the inJitCodeCache flag
+    mov    r1, rPC                  @ arg1 of translation may need this
+    mov    lr, #0                   @  in case target is HANDLER_INTERPRET
+    cmp    r0,#0
+    bxne   r0                       @ continue native execution if so
+#endif
+
+/*
+ * No translation, restore interpreter regs and start interpreting.
+ * rSELF & rFP were preserved in the translated code, and rPC has
+ * already been restored by the time we get here.  We'll need to set
+ * up rIBASE & rINST, and load the address of the JitTable into r0.
+ */
+toInterpreter:
+    EXPORT_PC()
+    ldr    rIBASE, [rSELF, #offThread_curHandlerTable]
+    FETCH_INST()
+    ldr    r0, [rSELF, #offThread_pJitProfTable]
+    ldr    rIBASE, [rSELF, #offThread_curHandlerTable]
+    @ NOTE: intended fallthrough
+
+/*
+ * Similar to common_updateProfile, but tests for null pJitProfTable
+ * r0 holds pJifProfTAble, rINST is loaded, rPC is current and
+ * rIBASE has been recently refreshed.
+ */
+common_testUpdateProfile:
+    cmp     r0, #0               @ JIT switched off?
+    beq     4f                   @ return to interp if so
+
+/*
+ * Common code to update potential trace start counter, and initiate
+ * a trace-build if appropriate.
+ * On entry here:
+ *    r0    <= pJitProfTable (verified non-NULL)
+ *    rPC   <= Dalvik PC
+ *    rINST <= next instruction
+ */
+common_updateProfile:
+    eor     r3,rPC,rPC,lsr #12 @ cheap, but fast hash function
+    lsl     r3,r3,#(32 - JIT_PROF_SIZE_LOG_2)          @ shift out excess bits
+    ldrb    r1,[r0,r3,lsr #(32 - JIT_PROF_SIZE_LOG_2)] @ get counter
+    GET_INST_OPCODE(ip)
+    subs    r1,r1,#1           @ decrement counter
+    strb    r1,[r0,r3,lsr #(32 - JIT_PROF_SIZE_LOG_2)] @ and store it
+    GOTO_OPCODE_IFNE(ip)       @ if not threshold, fallthrough otherwise */
+
+    /* Looks good, reset the counter */
+    ldr     r1, [rSELF, #offThread_jitThreshold]
+    strb    r1,[r0,r3,lsr #(32 - JIT_PROF_SIZE_LOG_2)] @ reset counter
+    EXPORT_PC()
+    mov     r0,rPC
+    mov     r1,rSELF
+    bl      dvmJitGetTraceAddrThread    @ (pc, self)
+    str     r0, [rSELF, #offThread_inJitCodeCache] @ set the inJitCodeCache flag
+    mov     r1, rPC                     @ arg1 of translation may need this
+    mov     lr, #0                      @  in case target is HANDLER_INTERPRET
+    cmp     r0,#0
+#if !defined(WITH_SELF_VERIFICATION)
+    bxne    r0                          @ jump to the translation
+    mov     r2,#kJitTSelectRequest      @ ask for trace selection
+    @ fall-through to common_selectTrace
+#else
+    moveq   r2,#kJitTSelectRequest      @ ask for trace selection
+    beq     common_selectTrace
+    /*
+     * At this point, we have a target translation.  However, if
+     * that translation is actually the interpret-only pseudo-translation
+     * we want to treat it the same as no translation.
+     */
+    mov     r10, r0                     @ save target
+    bl      dvmCompilerGetInterpretTemplate
+    cmp     r0, r10                     @ special case?
+    bne     jitSVShadowRunStart         @ set up self verification shadow space
+    @ Need to clear the inJitCodeCache flag
+    mov    r3, #0                       @ 0 means not in the JIT code cache
+    str    r3, [rSELF, #offThread_inJitCodeCache] @ back to the interp land
+    GET_INST_OPCODE(ip)
+    GOTO_OPCODE(ip)
+    /* no return */
+#endif
+
+/*
+ * On entry:
+ *  r2 is jit state.
+ */
+common_selectTrace:
+    ldrh    r0,[rSELF,#offThread_subMode]
+    ands    r0, #(kSubModeJitTraceBuild | kSubModeJitSV)
+    bne     3f                         @ already doing JIT work, continue
+    str     r2,[rSELF,#offThread_jitState]
+    mov     r0, rSELF
+/*
+ * Call out to validate trace-building request.  If successful,
+ * rIBASE will be swapped to to send us into single-stepping trace
+ * building mode, so we need to refresh before we continue.
+ */
+    EXPORT_PC()
+    SAVE_PC_FP_TO_SELF()                 @ copy of pc/fp to Thread
+    bl      dvmJitCheckTraceRequest
+3:
+    FETCH_INST()
+    ldr    rIBASE, [rSELF, #offThread_curHandlerTable]
+4:
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+    GOTO_OPCODE(ip)
+    /* no return */
+#endif
+
+#if defined(WITH_SELF_VERIFICATION)
+/*
+ * Save PC and registers to shadow memory for self verification mode
+ * before jumping to native translation.
+ * On entry:
+ *    rPC, rFP, rSELF: the values that they should contain
+ *    r10: the address of the target translation.
+ */
+jitSVShadowRunStart:
+    mov     r0,rPC                      @ r0<- program counter
+    mov     r1,rFP                      @ r1<- frame pointer
+    mov     r2,rSELF                    @ r2<- self (Thread) pointer
+    mov     r3,r10                      @ r3<- target translation
+    bl      dvmSelfVerificationSaveState @ save registers to shadow space
+    ldr     rFP,[r0,#offShadowSpace_shadowFP] @ rFP<- fp in shadow space
+    bx      r10                         @ jump to the translation
+
+/*
+ * Restore PC, registers, and interpreter state to original values
+ * before jumping back to the interpreter.
+ * On entry:
+ *   r0:  dPC
+ *   r2:  self verification state
+ */
+jitSVShadowRunEnd:
+    mov    r1,rFP                        @ pass ending fp
+    mov    r3,rSELF                      @ pass self ptr for convenience
+    bl     dvmSelfVerificationRestoreState @ restore pc and fp values
+    LOAD_PC_FP_FROM_SELF()               @ restore pc, fp
+    ldr    r1,[r0,#offShadowSpace_svState] @ get self verification state
+    cmp    r1,#0                         @ check for punt condition
+    beq    1f
+    @ Set up SV single-stepping
+    mov    r0, rSELF
+    mov    r1, #kSubModeJitSV
+    bl     dvmEnableSubMode              @ (self, subMode)
+    mov    r2,#kJitSelfVerification      @ ask for self verification
+    str    r2,[rSELF,#offThread_jitState]
+    @ intentional fallthrough
+1:                                       @ exit to interpreter without check
+    EXPORT_PC()
+    ldr    rIBASE, [rSELF, #offThread_curHandlerTable]
+    FETCH_INST()
+    GET_INST_OPCODE(ip)
+    GOTO_OPCODE(ip)
+#endif
+
+/*
+ * The equivalent of "goto bail", this calls through the "bail handler".
+ * It will end this interpreter activation, and return to the caller
+ * of dvmMterpStdRun.
+ *
+ * State registers will be saved to the "thread" area before bailing
+ * debugging purposes
+ */
+common_gotoBail:
+    SAVE_PC_FP_TO_SELF()                @ export state to "thread"
+    mov     r0, rSELF                   @ r0<- self ptr
+    b       dvmMterpStdBail             @ call(self, changeInterp)
+
+/*
+ * The JIT's invoke method needs to remember the callsite class and
+ * target pair.  Save them here so that they are available to
+ * dvmCheckJit following the interpretation of this invoke.
+ */
+#if defined(WITH_JIT)
+save_callsiteinfo:
+    cmp     r9, #0
+    ldrne   r9, [r9, #offObject_clazz]
+    str     r0, [rSELF, #offThread_methodToCall]
+    str     r9, [rSELF, #offThread_callsiteClass]
+    bx      lr
+#endif
+
+/*
+ * Common code for method invocation with range.
+ *
+ * On entry:
+ *  r0 is "Method* methodToCall", r9 is "this"
+ */
+common_invokeMethodRange:
+.LinvokeNewRange:
+#if defined(WITH_JIT)
+    ldrh    r1, [rSELF, #offThread_subMode]
+    ands    r1, #kSubModeJitTraceBuild
+    blne    save_callsiteinfo
+#endif
+    @ prepare to copy args to "outs" area of current frame
+// begin WITH_TAINT_TRACKING
+//    movs    r2, rINST, lsr #8           @ r2<- AA (arg count) -- test for zero
+    mov     r2, rINST, lsr #8           @ r2<- AA (arg count)
+    SAVEAREA_FROM_FP(r10, rFP)          @ r10<- stack save area
+//    beq     .LinvokeArgsDone            @ if no args, skip the rest
+    str     r2, [r10, #offStackSaveArea_argCount]	@ save arg count
+// end WITH_TAINT_TRACKING
+    FETCH(r1, 2)                        @ r1<- CCCC
+
+// begin WITH_TAINT_TRACKING
+    // is this a native method?
+    stmfd   sp!, {r0}                   @ push methodToCall to stack
+    ldr     r0, [r0, #offMethod_accessFlags] @ r0<- methodToCall->accessFlags
+    tst     r0, #ACC_NATIVE
+    ldmfd   sp!, {r0}                   @ restore methodToCall
+    bne     .LinvokeRangeNative
+
+.LinvokeRangeArgs:
+    @ r0=methodToCall, r1=CCCC, r2=count, r10=outs
+    @ (very few methods have > 10 args; could unroll for common cases)
+    stmfd   sp!, {r0}                   @ push methodToCall to stack
+    mov	    r9, #0
+    str     r9, [r10, #-4]              @ clear native hack
+    cmp	    r2, #0
+    beq     .LinvokeRangeDone           @ if no args, skip the rest
+    add     r3, rFP, r1, lsl #3         @ r3<- &fp[CCCC]
+    sub     r10, r10, r2, lsl #3        @ r10<- "outs" area, for call args
+    sub	    r10, r10, #4
+    //mov     r9, #0                      @ r9<- slot = 0
+1:  ldrd    r0, [r3, r9]
+    subs    r2, r2, #1                  @ count--
+    strd    r0, [r10, r9]               @ *outs++ = val
+    add	    r9, r9, #8
+    bne     1b                          @ ...while count != 0
+.LinvokeRangeDone:
+    ldmfd   sp!, {r0}                   @ restore methodToCall
+    // PJG: moved
+    //ldrh    r9, [r0, #offMethod_registersSize]  @ r9<- methodToCall->regsSize
+    //ldrh    r3, [r0, #offMethod_outsSize]   @ r3<- methodToCall->outsSize
+    b       .LinvokeArgsDone
+
+.LinvokeRangeNative:
+    @ r0=methodToCall, r1=CCCC, r2=count, r10=outs
+    @ (very few methods have > 10 args; could unroll for common cases)
+    stmfd   sp!, {r0}                   @ push methodToCall to stack
+    sub	    r10, r10, #4
+    sub     r10, r10, r2, lsl #3        @ r10<- "outs" area, for call args
+    mov	    r9, #0                      @ r9<- index
+    str     r9, [r10, r2, lsl #2]       @ clear native hack
+    cmp	    r2, #0
+    beq     .LinvokeRangeNativeDone     @ if no args, skip the rest
+    add     r3, rFP, r1, lsl #3         @ r3<- &fp[CCCC]
+    mov	    r0, r2                      @ r0<- count
+    mov	    r2, r2, lsl #2
+    add	    r2, r2, #4                  @ r2<- index (taint)
+1:  stmfd   sp!, {r0}                   @ push count
+    mov	    r0, r9, lsl #3
+    ldrd    r0, [r3, r0]
+    str	    r0, [r10, r9, lsl #2]
+    str	    r1, [r10, r2]
+    add	    r9, r9, #1
+    add	    r2, r2, #4
+    ldmfd   sp!, {r0}                   @ pop count
+    subs    r0, r0, #1                  @ count--
+    bne     1b                          @ ...while count != 0
+.LinvokeRangeNativeDone:
+    ldmfd   sp!, {r0}                   @ restore methodToCall
+    // PJG: moved
+    //ldrh    r9, [r0, #offMethod_registersSize]  @ r9<- methodToCall->regsSize
+    //ldrh    r3, [r0, #offMethod_outsSize]   @ r3<- methodToCall->outsSize
+    b       .LinvokeArgsDone
+// end WITH_TAINT_TRACKING
+
+/*
+ * Common code for method invocation without range.
+ *
+ * On entry:
+ *  r0 is "Method* methodToCall", r9 is "this"
+ */
+common_invokeMethodNoRange:
+.LinvokeNewNoRange:
+#if defined(WITH_JIT)
+    ldrh    r1, [rSELF, #offThread_subMode]
+    ands    r1, #kSubModeJitTraceBuild
+    blne    save_callsiteinfo
+#endif
+    @ prepare to copy args to "outs" area of current frame
+// begin WITH_TAINT_TRACKING
+//    movs    r2, rINST, lsr #12          @ r2<- B (arg count) -- test for zero
+    movs    r2, rINST, lsr #12          @ r2<- B (arg count)
+    SAVEAREA_FROM_FP(r10, rFP)          @ r10<- stack save area
+    str     r2, [r10, #offStackSaveArea_argCount]    @ save arg count
+    FETCH(r1, 2)                        @ r1<- GFED (load here to hide latency)
+    // is this a native method?
+    stmfd   sp!, {r0}                   @ push methodToCall to stack
+    ldr     r0, [r0, #offMethod_accessFlags] @ r0<- methodToCall->accessFlags
+    tst     r0, #ACC_NATIVE
+    bne     .LinvokeNonRangeNative
+// end WITH_TAINT_TRACKING
+    @ r0=methodToCall, r1=GFED, r2=count, r10=outs
+.LinvokeNonRange:
+// begin WITH_TAINT_TRACKING
+    stmfd   sp!, {r3}                   @ push count, outSize to stack
+    // clear native hack
+    mov	    r3, #0
+    str     r3, [r10, #-4]!
+// end WITH_TAINT_TRACKING
+    rsb     r2, r2, #5                  @ r2<- 5-r2
+    add     pc, pc, r2, lsl #4          @ computed goto, 4 instrs each
+    bl      common_abort                @ (skipped due to ARM prefetch)
+// begin WITH_TAINT_TRACKING
+5:  and     ip, rINST, #0x0f00          @ isolate A
+    mov	    r2, ip, lsr #5
+    ldrd    r2, [rFP, r2]               @ r2/r3<- vA (shift right 8, left 2) / taint
+    strd    r2, [r10, #-8]!             @ *--outs = vA
+4:  and     ip, r1, #0xf000             @ isolate G
+    mov	    r2, ip, lsr #9
+    ldrd    r2, [rFP, r2]               @ r2<- vG (shift right 12, left 2)
+    strd    r2, [r10, #-8]!             @ *--outs = vG
+3:  and     ip, r1, #0x0f00             @ isolate F
+    mov	    r2, ip, lsr #5
+    ldrd    r2, [rFP, r2]               @ r2<- vF
+    strd    r2, [r10, #-8]!             @ *--outs = vF
+2:  and     ip, r1, #0x00f0             @ isolate E
+    mov	    r2, ip, lsr #1
+    ldrd    r2, [rFP, r2]               @ r2<- vE
+    strd    r2, [r10, #-8]!             @ *--outs = vE
+1:  and     ip, r1, #0x000f             @ isolate D
+    mov	    r2, ip, lsl #3
+    ldrd    r2, [rFP, r2]               @ r2<- vD
+    strd    r2, [r10, #-8]!             @ *--outs = vD
+// end WITH_TAINT_TRACKING
+0:  @ fall through to .LinvokeArgsDone
+// begin WITH_TAINT_TRACKING
+    ldmfd   sp!, {r3}                   @ restore outSize
+    ldmfd   sp!, {r0}                   @ restore methodToCall
+    b       .LinvokeArgsDone            @ jump over .LinvokeNonRangeNative
+// end WITH_TAINT_TRACKING
+
+    @ r0=methodToCall, r1=GFED, r2=count, r10=outs
+.LinvokeNonRangeNative:
+// begin WITH_TAINT_TRACKING
+    sub	    r0, r10, r2, lsl #2         @ r0<- outs (no taint)
+    sub	    r0, r0, #4                  @ native hack
+    stmfd   sp!, {r3}                   @ push outSize to stack
+// end WITH_TAINT_TRACKING
+    rsb     r2, r2, #5                  @ r2<- 5-r2
+// begin WITH_TAINT_TRACKING
+    mov	    r3, #5
+    mul	    r2, r2, r3
+    add     pc, pc, r2, lsl #2         	@ computed goto, 5 instrs each, 4-byte instrs
+// end WITH_TAINT_TRACKING
+    bl      common_abort                @ (skipped due to ARM prefetch)
+// begin WITH_TAINT_TRACKING
+5:  and     ip, rINST, #0x0f00          @ isolate A
+    mov	    r2, ip, lsr #5
+    ldrd    r2, [rFP, r2]               @ r2/r3<- vA (shift right 8, left 2) / taint
+    str     r2, [r0, #-4]!
+    str	    r3, [r10, #-4]!
+4:  and     ip, r1, #0xf000             @ isolate G
+    mov	    r2, ip, lsr #9
+    ldrd    r2, [rFP, r2]               @ r2<- vG (shift right 12, left 2)
+    str     r2, [r0, #-4]!
+    str	    r3, [r10, #-4]!
+3:  and     ip, r1, #0x0f00             @ isolate F
+    mov	    r2, ip, lsr #5
+    ldrd    r2, [rFP, r2]               @ r2<- vF
+    str     r2, [r0, #-4]!
+    str	    r3, [r10, #-4]!
+2:  and     ip, r1, #0x00f0             @ isolate E
+    mov	    r2, ip, lsr #1
+    ldrd    r2, [rFP, r2]               @ r2<- vE
+    str     r2, [r0, #-4]!
+    str	    r3, [r10, #-4]!
+1:  and     ip, r1, #0x000f             @ isolate D
+    mov	    r2, ip, lsl #3
+    ldrd    r2, [rFP, r2]               @ r2<- vD
+    str     r2, [r0, #-4]!
+    str     r3, [r10, #-4]!
+// end WITH_TAINT_TRACKING
+0:  @ fall through to .LinvokeArgsDone
+// begin WITH_TAINT_TRACKING
+    // clear native hack
+    mov		r3, #0
+    str     r3, [r10, #-4]!
+    ldmfd   sp!, {r3}                   @ restore outSize
+    ldmfd   sp!, {r0}                   @ restore methodToCall
+// end WITH_TAINT_TRACKING
+
+.LinvokeArgsDone: @ r0=methodToCall
+    ldrh    r9, [r0, #offMethod_registersSize]  @ r9<- methodToCall->regsSize
+    ldrh    r3, [r0, #offMethod_outsSize]  @ r3<- methodToCall->outsSize
+    ldr     r2, [r0, #offMethod_insns]  @ r2<- method->insns
+    ldr     rINST, [r0, #offMethod_clazz]  @ rINST<- method->clazz
+    @ find space for the new stack frame, check for overflow
+    SAVEAREA_FROM_FP(r1, rFP)           @ r1<- stack save area
+// begin WITH_TAINT_TRACKING
+    sub     r1, r1, r9, lsl #3
+    sub	    r1, r1, #4                  @ r1<- newFp (old savearea - 2*regsSize - 4)
+// end WITH_TAINT_TRACKING
+    SAVEAREA_FROM_FP(r10, r1)           @ r10<- newSaveArea
+@    bl      common_dumpRegs
+    ldr     r9, [rSELF, #offThread_interpStackEnd]    @ r9<- interpStackEnd
+// begin WITH_TAINT_TRACKING
+    sub     r3, r10, r3, lsl #2
+    sub	    r3, r3, #4                  @ r3<- bottom (newsave - outsSize - 4)
+// end WITH_TAINT_TRACKING
+    cmp     r3, r9                      @ bottom < interpStackEnd?
+    ldrh    lr, [rSELF, #offThread_subMode]
+    ldr     r3, [r0, #offMethod_accessFlags] @ r3<- methodToCall->accessFlags
+    blo     .LstackOverflow             @ yes, this frame will overflow stack
+
+    @ set up newSaveArea
+#ifdef EASY_GDB
+    SAVEAREA_FROM_FP(ip, rFP)           @ ip<- stack save area
+    str     ip, [r10, #offStackSaveArea_prevSave]
+#endif
+    str     rFP, [r10, #offStackSaveArea_prevFrame]
+    str     rPC, [r10, #offStackSaveArea_savedPc]
+#if defined(WITH_JIT)
+    mov     r9, #0
+    str     r9, [r10, #offStackSaveArea_returnAddr]
+#endif
+    str     r0, [r10, #offStackSaveArea_method]
+
+    @ Profiling?
+    cmp     lr, #0                      @ any special modes happening?
+    bne     2f                          @ go if so
+1:
+    tst     r3, #ACC_NATIVE
+    bne     .LinvokeNative
+
+    /*
+    stmfd   sp!, {r0-r3}
+    bl      common_printNewline
+    mov     r0, rFP
+    mov     r1, #0
+    bl      dvmDumpFp
+    ldmfd   sp!, {r0-r3}
+    stmfd   sp!, {r0-r3}
+    mov     r0, r1
+    mov     r1, r10
+    bl      dvmDumpFp
+    bl      common_printNewline
+    ldmfd   sp!, {r0-r3}
+    */
+
+    ldrh    r9, [r2]                        @ r9 <- load INST from new PC
+    ldr     r3, [rINST, #offClassObject_pDvmDex] @ r3<- method->clazz->pDvmDex
+    mov     rPC, r2                         @ publish new rPC
+
+    @ Update state values for the new method
+    @ r0=methodToCall, r1=newFp, r3=newMethodClass, r9=newINST
+    str     r0, [rSELF, #offThread_method]    @ self->method = methodToCall
+    str     r3, [rSELF, #offThread_methodClassDex] @ self->methodClassDex = ...
+    mov     r2, #1
+    str     r2, [rSELF, #offThread_debugIsMethodEntry]
+#if defined(WITH_JIT)
+    ldr     r0, [rSELF, #offThread_pJitProfTable]
+    mov     rFP, r1                         @ fp = newFp
+    GET_PREFETCHED_OPCODE(ip, r9)           @ extract prefetched opcode from r9
+    mov     rINST, r9                       @ publish new rINST
+    str     r1, [rSELF, #offThread_curFrame]   @ curFrame = newFp
+    cmp     r0,#0
+    bne     common_updateProfile
+    GOTO_OPCODE(ip)                         @ jump to next instruction
+#else
+    mov     rFP, r1                         @ fp = newFp
+    GET_PREFETCHED_OPCODE(ip, r9)           @ extract prefetched opcode from r9
+    mov     rINST, r9                       @ publish new rINST
+    str     r1, [rSELF, #offThread_curFrame]   @ curFrame = newFp
+    GOTO_OPCODE(ip)                         @ jump to next instruction
+#endif
+
+2:
+    @ Profiling - record method entry.  r0: methodToCall
+    stmfd   sp!, {r0-r3}                @ preserve r0-r3
+    str     rPC, [rSELF, #offThread_pc] @ update interpSave.pc
+    mov     r1, r0
+    mov     r0, rSELF
+    bl      dvmReportInvoke             @ (self, method)
+    ldmfd   sp!, {r0-r3}                @ restore r0-r3
+    b       1b
+
+.LinvokeNative:
+    @ Prep for the native call
+    @ r0=methodToCall, r1=newFp, r10=newSaveArea
+    ldrh    lr, [rSELF, #offThread_subMode]
+    ldr     r9, [rSELF, #offThread_jniLocal_topCookie]@r9<-thread->localRef->...
+    str     r1, [rSELF, #offThread_curFrame]   @ curFrame = newFp
+    str     r9, [r10, #offStackSaveArea_localRefCookie] @newFp->localRefCookie=top
+    mov     r2, r0                      @ r2<- methodToCall
+    mov     r0, r1                      @ r0<- newFp (points to args)
+    add     r1, rSELF, #offThread_retval  @ r1<- &retval
+    mov     r3, rSELF                   @ arg3<- self
+
+#ifdef ASSIST_DEBUGGER
+    /* insert fake function header to help gdb find the stack frame */
+    b       .Lskip
+    .type   dalvik_mterp, %function
+dalvik_mterp:
+    .fnstart
+    MTERP_ENTRY1
+    MTERP_ENTRY2
+.Lskip:
+#endif
+
+    cmp     lr, #0                      @ any special SubModes active?
+    bne     11f                         @ go handle them if so
+    mov     lr, pc                      @ set return addr
+    ldr     pc, [r2, #offMethod_nativeFunc] @ pc<- methodToCall->nativeFunc
+7:
+
+    @ native return; r10=newSaveArea
+
+// begin WITH_TAINT_TRACKING
+    // set return taint
+    SAVEAREA_FROM_FP(r0, rFP)           @ r0<- stack save area
+    ldr     r1, [r0, #offStackSaveArea_argCount]    @ r1<- arg count
+    sub     r0, r0, r1, lsl #2
+    ldr     r2, [r0, #-4]               @ r2<- return taint
+    str	    r2, [rSELF, #offThread_rtaint]
+// end WITH_TAINT_TRACKING
+
+    @ equivalent to dvmPopJniLocals
+    ldr     r0, [r10, #offStackSaveArea_localRefCookie] @ r0<- saved top
+    ldr     r1, [rSELF, #offThread_exception] @ check for exception
+    str     rFP, [rSELF, #offThread_curFrame]  @ curFrame = fp
+    cmp     r1, #0                      @ null?
+    str     r0, [rSELF, #offThread_jniLocal_topCookie] @ new top <- old top
+    bne     common_exceptionThrown      @ no, handle exception
+
+    FETCH_ADVANCE_INST(3)               @ advance rPC, load rINST
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+    GOTO_OPCODE(ip)                     @ jump to next instruction
+
+11:
+    @ r0=newFp, r1=&retval, r2=methodToCall, r3=self, lr=subModes
+    stmfd   sp!, {r0-r3}                @ save all but subModes
+    mov     r0, r2                      @ r0<- methodToCall
+    mov     r1, rSELF
+    mov     r2, rFP
+    bl      dvmReportPreNativeInvoke    @ (methodToCall, self, fp)
+    ldmfd   sp, {r0-r3}                 @ refresh.  NOTE: no sp autoincrement
+
+    @ Call the native method
+    mov     lr, pc                      @ set return addr
+    ldr     pc, [r2, #offMethod_nativeFunc] @ pc<- methodToCall->nativeFunc
+
+    @ Restore the pre-call arguments
+    ldmfd   sp!, {r0-r3}                @ r2<- methodToCall (others unneeded)
+
+    @ Finish up any post-invoke subMode requirements
+    mov     r0, r2                      @ r0<- methodToCall
+    mov     r1, rSELF
+    mov     r2, rFP
+    bl      dvmReportPostNativeInvoke   @ (methodToCall, self, fp)
+    b       7b                          @ resume
+
+.LstackOverflow:    @ r0=methodToCall
+    mov     r1, r0                      @ r1<- methodToCall
+    mov     r0, rSELF                   @ r0<- self
+    bl      dvmHandleStackOverflow
+    b       common_exceptionThrown
+#ifdef ASSIST_DEBUGGER
+    .fnend
+    .size   dalvik_mterp, .-dalvik_mterp
+#endif
+
+
+    /*
+     * Common code for method invocation, calling through "glue code".
+     *
+     * TODO: now that we have range and non-range invoke handlers, this
+     *       needs to be split into two.  Maybe just create entry points
+     *       that set r9 and jump here?
+     *
+     * On entry:
+     *  r0 is "Method* methodToCall", the method we're trying to call
+     *  r9 is "bool methodCallRange", indicating if this is a /range variant
+     */
+     .if    0
+.LinvokeOld:
+    sub     sp, sp, #8                  @ space for args + pad
+    FETCH(ip, 2)                        @ ip<- FEDC or CCCC
+    mov     r2, r0                      @ A2<- methodToCall
+    mov     r0, rSELF                   @ A0<- self
+    SAVE_PC_FP_TO_SELF()                @ export state to "self"
+    mov     r1, r9                      @ A1<- methodCallRange
+    mov     r3, rINST, lsr #8           @ A3<- AA
+    str     ip, [sp, #0]                @ A4<- ip
+    bl      dvmMterp_invokeMethod       @ call the C invokeMethod
+    add     sp, sp, #8                  @ remove arg area
+    b       common_resumeAfterGlueCall  @ continue to next instruction
+    .endif
+
+
+
+/*
+ * Common code for handling a return instruction.
+ *
+ * This does not return.
+ */
+common_returnFromMethod:
+.LreturnNew:
+    ldrh    lr, [rSELF, #offThread_subMode]
+    SAVEAREA_FROM_FP(r0, rFP)
+    ldr     r9, [r0, #offStackSaveArea_savedPc] @ r9 = saveArea->savedPc
+    cmp     lr, #0                      @ any special subMode handling needed?
+    bne     19f
+14:
+    ldr     rFP, [r0, #offStackSaveArea_prevFrame] @ fp = saveArea->prevFrame
+    ldr     r2, [rFP, #(offStackSaveArea_method - sizeofStackSaveArea)]
+                                        @ r2<- method we're returning to
+    cmp     r2, #0                      @ is this a break frame?
+#if defined(WORKAROUND_CORTEX_A9_745320)
+    /* Don't use conditional loads if the HW defect exists */
+    beq     15f
+    ldr     r10, [r2, #offMethod_clazz] @ r10<- method->clazz
+15:
+#else
+    ldrne   r10, [r2, #offMethod_clazz] @ r10<- method->clazz
+#endif
+    beq     common_gotoBail             @ break frame, bail out completely
+
+    ldr     rIBASE, [rSELF, #offThread_curHandlerTable]  @ refresh rIBASE
+    PREFETCH_ADVANCE_INST(rINST, r9, 3) @ advance r9, update new rINST
+    str     r2, [rSELF, #offThread_method]@ self->method = newSave->method
+    ldr     r1, [r10, #offClassObject_pDvmDex]   @ r1<- method->clazz->pDvmDex
+    str     rFP, [rSELF, #offThread_curFrame]  @ curFrame = fp
+#if defined(WITH_JIT)
+    ldr     r10, [r0, #offStackSaveArea_returnAddr] @ r10 = saveArea->returnAddr
+    mov     rPC, r9                     @ publish new rPC
+    str     r1, [rSELF, #offThread_methodClassDex]
+    str     r10, [rSELF, #offThread_inJitCodeCache]  @ may return to JIT'ed land
+    cmp     r10, #0                      @ caller is compiled code
+    blxne   r10
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+    GOTO_OPCODE(ip)                     @ jump to next instruction
+#else
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+    mov     rPC, r9                     @ publish new rPC
+    str     r1, [rSELF, #offThread_methodClassDex]
+    GOTO_OPCODE(ip)                     @ jump to next instruction
+#endif
+
+19:
+    @ Handle special actions
+    @ On entry, r0: StackSaveArea
+    ldr     r1, [r0, #offStackSaveArea_prevFrame]  @ r2<- prevFP
+    str     rPC, [rSELF, #offThread_pc] @ update interpSave.pc
+    str     r1, [rSELF, #offThread_curFrame]   @ update interpSave.curFrame
+    mov     r0, rSELF
+    bl      dvmReportReturn             @ (self)
+    SAVEAREA_FROM_FP(r0, rFP)           @ restore StackSaveArea
+    b       14b                         @ continue
+
+    /*
+     * Return handling, calls through "glue code".
+     */
+     .if    0
+.LreturnOld:
+    SAVE_PC_FP_TO_SELF()                @ export state
+    mov     r0, rSELF                   @ arg to function
+    bl      dvmMterp_returnFromMethod
+    b       common_resumeAfterGlueCall
+    .endif
+
+
+/*
+ * Somebody has thrown an exception.  Handle it.
+ *
+ * If the exception processing code returns to us (instead of falling
+ * out of the interpreter), continue with whatever the next instruction
+ * now happens to be.
+ *
+ * This does not return.
+ */
+     .global dvmMterpCommonExceptionThrown
+dvmMterpCommonExceptionThrown:
+common_exceptionThrown:
+.LexceptionNew:
+
+    EXPORT_PC()
+
+    mov     r0, rSELF
+    bl      dvmCheckSuspendPending
+
+    ldr     r9, [rSELF, #offThread_exception] @ r9<- self->exception
+    mov     r1, rSELF                   @ r1<- self
+    mov     r0, r9                      @ r0<- exception
+    bl      dvmAddTrackedAlloc          @ don't let the exception be GCed
+    ldrh    r2, [rSELF, #offThread_subMode]  @ get subMode flags
+    mov     r3, #0                      @ r3<- NULL
+    str     r3, [rSELF, #offThread_exception] @ self->exception = NULL
+
+    @ Special subMode?
+    cmp     r2, #0                      @ any special subMode handling needed?
+    bne     7f                          @ go if so
+8:
+    /* set up args and a local for "&fp" */
+    /* (str sp, [sp, #-4]!  would be perfect here, but is discouraged) */
+    str     rFP, [sp, #-4]!             @ *--sp = fp
+    mov     ip, sp                      @ ip<- &fp
+    mov     r3, #0                      @ r3<- false
+    str     ip, [sp, #-4]!              @ *--sp = &fp
+    ldr     r1, [rSELF, #offThread_method] @ r1<- self->method
+    mov     r0, rSELF                   @ r0<- self
+    ldr     r1, [r1, #offMethod_insns]  @ r1<- method->insns
+    ldrh    lr, [rSELF, #offThread_subMode]  @ lr<- subMode flags
+    mov     r2, r9                      @ r2<- exception
+    sub     r1, rPC, r1                 @ r1<- pc - method->insns
+    mov     r1, r1, asr #1              @ r1<- offset in code units
+
+    /* call, r0 gets catchRelPc (a code-unit offset) */
+    bl      dvmFindCatchBlock           @ call(self, relPc, exc, scan?, &fp)
+
+    /* fix earlier stack overflow if necessary; may trash rFP */
+    ldrb    r1, [rSELF, #offThread_stackOverflowed]
+    cmp     r1, #0                      @ did we overflow earlier?
+    beq     1f                          @ no, skip ahead
+    mov     rFP, r0                     @ save relPc result in rFP
+    mov     r0, rSELF                   @ r0<- self
+    mov     r1, r9                      @ r1<- exception
+    bl      dvmCleanupStackOverflow     @ call(self)
+    mov     r0, rFP                     @ restore result
+1:
+
+    /* update frame pointer and check result from dvmFindCatchBlock */
+    ldr     rFP, [sp, #4]               @ retrieve the updated rFP
+    cmp     r0, #0                      @ is catchRelPc < 0?
+    add     sp, sp, #8                  @ restore stack
+    bmi     .LnotCaughtLocally
+
+    /* adjust locals to match self->interpSave.curFrame and updated PC */
+    SAVEAREA_FROM_FP(r1, rFP)           @ r1<- new save area
+    ldr     r1, [r1, #offStackSaveArea_method] @ r1<- new method
+    str     r1, [rSELF, #offThread_method]  @ self->method = new method
+    ldr     r2, [r1, #offMethod_clazz]      @ r2<- method->clazz
+    ldr     r3, [r1, #offMethod_insns]      @ r3<- method->insns
+    ldr     r2, [r2, #offClassObject_pDvmDex] @ r2<- method->clazz->pDvmDex
+    add     rPC, r3, r0, asl #1             @ rPC<- method->insns + catchRelPc
+    str     r2, [rSELF, #offThread_methodClassDex] @ self->pDvmDex = meth...
+
+    /* release the tracked alloc on the exception */
+    mov     r0, r9                      @ r0<- exception
+    mov     r1, rSELF                   @ r1<- self
+    bl      dvmReleaseTrackedAlloc      @ release the exception
+
+    /* restore the exception if the handler wants it */
+    ldr    rIBASE, [rSELF, #offThread_curHandlerTable]  @ refresh rIBASE
+    FETCH_INST()                        @ load rINST from rPC
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+    cmp     ip, #OP_MOVE_EXCEPTION      @ is it "move-exception"?
+    streq   r9, [rSELF, #offThread_exception] @ yes, restore the exception
+    GOTO_OPCODE(ip)                     @ jump to next instruction
+
+    @ Manage debugger bookkeeping
+7:
+    str     rPC, [rSELF, #offThread_pc]     @ update interpSave.pc
+    str     rFP, [rSELF, #offThread_curFrame]     @ update interpSave.curFrame
+    mov     r0, rSELF                       @ arg0<- self
+    mov     r1, r9                          @ arg1<- exception
+    bl      dvmReportExceptionThrow         @ (self, exception)
+    b       8b                              @ resume with normal handling
+
+.LnotCaughtLocally: @ r9=exception
+    /* fix stack overflow if necessary */
+    ldrb    r1, [rSELF, #offThread_stackOverflowed]
+    cmp     r1, #0                      @ did we overflow earlier?
+    movne   r0, rSELF                   @ if yes: r0<- self
+    movne   r1, r9                      @ if yes: r1<- exception
+    blne    dvmCleanupStackOverflow     @ if yes: call(self)
+
+    @ may want to show "not caught locally" debug messages here
+#if DVM_SHOW_EXCEPTION >= 2
+    /* call __android_log_print(prio, tag, format, ...) */
+    /* "Exception %s from %s:%d not caught locally" */
+    @ dvmLineNumFromPC(method, pc - method->insns)
+    ldr     r0, [rSELF, #offThread_method]
+    ldr     r1, [r0, #offMethod_insns]
+    sub     r1, rPC, r1
+    asr     r1, r1, #1
+    bl      dvmLineNumFromPC
+    str     r0, [sp, #-4]!
+    @ dvmGetMethodSourceFile(method)
+    ldr     r0, [rSELF, #offThread_method]
+    bl      dvmGetMethodSourceFile
+    str     r0, [sp, #-4]!
+    @ exception->clazz->descriptor
+    ldr     r3, [r9, #offObject_clazz]
+    ldr     r3, [r3, #offClassObject_descriptor]
+    @
+    ldr     r2, strExceptionNotCaughtLocally
+    ldr     r1, strLogTag
+    mov     r0, #3                      @ LOG_DEBUG
+    bl      __android_log_print
+#endif
+    str     r9, [rSELF, #offThread_exception] @ restore exception
+    mov     r0, r9                      @ r0<- exception
+    mov     r1, rSELF                   @ r1<- self
+    bl      dvmReleaseTrackedAlloc      @ release the exception
+    b       common_gotoBail             @ bail out
+
+
+    /*
+     * Exception handling, calls through "glue code".
+     */
+    .if     0
+.LexceptionOld:
+    SAVE_PC_FP_TO_SELF()                @ export state
+    mov     r0, rSELF                   @ arg to function
+    bl      dvmMterp_exceptionThrown
+    b       common_resumeAfterGlueCall
+    .endif
+
+#if defined(WITH_JIT)
+    /*
+     * If the JIT is actively building a trace we need to make sure
+     * that the field is fully resolved before including the current
+     * instruction.
+     *
+     * On entry:
+     *     r10: &dvmDex->pResFields[field]
+     *     r0:  field pointer (must preserve)
+     */
+common_verifyField:
+    ldrh    r3, [rSELF, #offThread_subMode]  @ r3 <- submode byte
+    ands    r3, #kSubModeJitTraceBuild
+    bxeq    lr                          @ Not building trace, continue
+    ldr     r1, [r10]                   @ r1<- reload resolved StaticField ptr
+    cmp     r1, #0                      @ resolution complete?
+    bxne    lr                          @ yes, continue
+    stmfd   sp!, {r0-r2,lr}             @ save regs
+    mov     r0, rSELF
+    mov     r1, rPC
+    bl      dvmJitEndTraceSelect        @ (self,pc) end trace before this inst
+    ldmfd   sp!, {r0-r2, lr}
+    bx      lr                          @ return
+#endif
+
+/*
+ * After returning from a "glued" function, pull out the updated
+ * values and start executing at the next instruction.
+ */
+common_resumeAfterGlueCall:
+    LOAD_PC_FP_FROM_SELF()              @ pull rPC and rFP out of thread
+    ldr     rIBASE, [rSELF, #offThread_curHandlerTable]  @ refresh
+    FETCH_INST()                        @ load rINST from rPC
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+    GOTO_OPCODE(ip)                     @ jump to next instruction
+
+/*
+ * Invalid array index. Note that our calling convention is strange; we use r1
+ * and r3 because those just happen to be the registers all our callers are
+ * using. We move r3 before calling the C function, but r1 happens to match.
+ * r1: index
+ * r3: size
+ */
+common_errArrayIndex:
+    EXPORT_PC()
+    mov     r0, r3
+    bl      dvmThrowArrayIndexOutOfBoundsException
+    b       common_exceptionThrown
+
+/*
+ * Integer divide or mod by zero.
+ */
+common_errDivideByZero:
+    EXPORT_PC()
+    ldr     r0, strDivideByZero
+    bl      dvmThrowArithmeticException
+    b       common_exceptionThrown
+
+/*
+ * Attempt to allocate an array with a negative size.
+ * On entry: length in r1
+ */
+common_errNegativeArraySize:
+    EXPORT_PC()
+    mov     r0, r1                                @ arg0 <- len
+    bl      dvmThrowNegativeArraySizeException    @ (len)
+    b       common_exceptionThrown
+
+/*
+ * Invocation of a non-existent method.
+ * On entry: method name in r1
+ */
+common_errNoSuchMethod:
+    EXPORT_PC()
+    mov     r0, r1
+    bl      dvmThrowNoSuchMethodError
+    b       common_exceptionThrown
+
+/*
+ * We encountered a null object when we weren't expecting one.  We
+ * export the PC, throw a NullPointerException, and goto the exception
+ * processing code.
+ */
+common_errNullObject:
+    EXPORT_PC()
+    mov     r0, #0
+    bl      dvmThrowNullPointerException
+    b       common_exceptionThrown
+
+/*
+ * For debugging, cause an immediate fault.  The source address will
+ * be in lr (use a bl instruction to jump here).
+ */
+common_abort:
+    ldr     pc, .LdeadFood
+.LdeadFood:
+    .word   0xdeadf00d
+
+/*
+ * Spit out a "we were here", preserving all registers.  (The attempt
+ * to save ip won't work, but we need to save an even number of
+ * registers for EABI 64-bit stack alignment.)
+ */
+    .macro  SQUEAK num
+common_squeak\num:
+    stmfd   sp!, {r0, r1, r2, r3, ip, lr}
+    ldr     r0, strSqueak
+    mov     r1, #\num
+    bl      printf
+    ldmfd   sp!, {r0, r1, r2, r3, ip, lr}
+    bx      lr
+    .endm
+
+    SQUEAK  0
+    SQUEAK  1
+    SQUEAK  2
+    SQUEAK  3
+    SQUEAK  4
+    SQUEAK  5
+
+/*
+ * Spit out the number in r0, preserving registers.
+ */
+common_printNum:
+    stmfd   sp!, {r0, r1, r2, r3, ip, lr}
+    mov     r1, r0
+    ldr     r0, strSqueak
+    bl      printf
+    ldmfd   sp!, {r0, r1, r2, r3, ip, lr}
+    bx      lr
+
+/*
+ * Print a newline, preserving registers.
+ */
+common_printNewline:
+    stmfd   sp!, {r0, r1, r2, r3, ip, lr}
+    ldr     r0, strNewline
+    bl      printf
+    ldmfd   sp!, {r0, r1, r2, r3, ip, lr}
+    bx      lr
+
+    /*
+     * Print the 32-bit quantity in r0 as a hex value, preserving registers.
+     */
+common_printHex:
+    stmfd   sp!, {r0, r1, r2, r3, ip, lr}
+    mov     r1, r0
+    ldr     r0, strPrintHex
+    bl      printf
+    ldmfd   sp!, {r0, r1, r2, r3, ip, lr}
+    bx      lr
+
+/*
+ * Print the 64-bit quantity in r0-r1, preserving registers.
+ */
+common_printLong:
+    stmfd   sp!, {r0, r1, r2, r3, ip, lr}
+    mov     r3, r1
+    mov     r2, r0
+    ldr     r0, strPrintLong
+    bl      printf
+    ldmfd   sp!, {r0, r1, r2, r3, ip, lr}
+    bx      lr
+
+/*
+ * Print full method info.  Pass the Method* in r0.  Preserves regs.
+ */
+common_printMethod:
+    stmfd   sp!, {r0, r1, r2, r3, ip, lr}
+    bl      dvmMterpPrintMethod
+    ldmfd   sp!, {r0, r1, r2, r3, ip, lr}
+    bx      lr
+
+/*
+ * Call a C helper function that dumps regs and possibly some
+ * additional info.  Requires the C function to be compiled in.
+ */
+    .if     0
+common_dumpRegs:
+    stmfd   sp!, {r0, r1, r2, r3, ip, lr}
+    bl      dvmMterpDumpArmRegs
+    ldmfd   sp!, {r0, r1, r2, r3, ip, lr}
+    bx      lr
+    .endif
+
+#if 0
+/*
+ * Experiment on VFP mode.
+ *
+ * uint32_t setFPSCR(uint32_t val, uint32_t mask)
+ *
+ * Updates the bits specified by "mask", setting them to the values in "val".
+ */
+setFPSCR:
+    and     r0, r0, r1                  @ make sure no stray bits are set
+    fmrx    r2, fpscr                   @ get VFP reg
+    mvn     r1, r1                      @ bit-invert mask
+    and     r2, r2, r1                  @ clear masked bits
+    orr     r2, r2, r0                  @ set specified bits
+    fmxr    fpscr, r2                   @ set VFP reg
+    mov     r0, r2                      @ return new value
+    bx      lr
+
+    .align  2
+    .global dvmConfigureFP
+    .type   dvmConfigureFP, %function
+dvmConfigureFP:
+    stmfd   sp!, {ip, lr}
+    /* 0x03000000 sets DN/FZ */
+    /* 0x00009f00 clears the six exception enable flags */
+    bl      common_squeak0
+    mov     r0, #0x03000000             @ r0<- 0x03000000
+    add     r1, r0, #0x9f00             @ r1<- 0x03009f00
+    bl      setFPSCR
+    ldmfd   sp!, {ip, pc}
+#endif
+
+
+/*
+ * String references, must be close to the code that uses them.
+ */
+    .align  2
+strDivideByZero:
+    .word   .LstrDivideByZero
+strLogTag:
+    .word   .LstrLogTag
+strExceptionNotCaughtLocally:
+    .word   .LstrExceptionNotCaughtLocally
+
+strNewline:
+    .word   .LstrNewline
+strSqueak:
+    .word   .LstrSqueak
+strPrintHex:
+    .word   .LstrPrintHex
+strPrintLong:
+    .word   .LstrPrintLong
+
+/*
+ * Zero-terminated ASCII string data.
+ *
+ * On ARM we have two choices: do like gcc does, and LDR from a .word
+ * with the address, or use an ADR pseudo-op to get the address
+ * directly.  ADR saves 4 bytes and an indirection, but it's using a
+ * PC-relative addressing mode and hence has a limited range, which
+ * makes it not work well with mergeable string sections.
+ */
+    .section .rodata.str1.4,"aMS",%progbits,1
+
+.LstrBadEntryPoint:
+    .asciz  "Bad entry point %d\n"
+.LstrFilledNewArrayNotImpl:
+    .asciz  "filled-new-array only implemented for objects and 'int'"
+.LstrDivideByZero:
+    .asciz  "divide by zero"
+.LstrLogTag:
+    .asciz  "mterp"
+.LstrExceptionNotCaughtLocally:
+    .asciz  "Exception %s from %s:%d not caught locally\n"
+
+.LstrNewline:
+    .asciz  "\n"
+.LstrSqueak:
+    .asciz  "<%d>"
+.LstrPrintHex:
+    .asciz  "<%#x>"
+.LstrPrintLong:
+    .asciz  "<%lld>"
diff --git a/vm/mterp/armv5te_taint/header.S b/vm/mterp/armv5te_taint/header.S
new file mode 100644
index 0000000..dc08d01
--- /dev/null
+++ b/vm/mterp/armv5te_taint/header.S
@@ -0,0 +1,210 @@
+/*
+ * Copyright (C) 2008 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+/*
+ * ARMv5 definitions and declarations.
+ */
+
+/*
+ARM EABI general notes:
+
+r0-r3 hold first 4 args to a method; they are not preserved across method calls
+r4-r8 are available for general use
+r9 is given special treatment in some situations, but not for us
+r10 (sl) seems to be generally available
+r11 (fp) is used by gcc (unless -fomit-frame-pointer is set)
+r12 (ip) is scratch -- not preserved across method calls
+r13 (sp) should be managed carefully in case a signal arrives
+r14 (lr) must be preserved
+r15 (pc) can be tinkered with directly
+
+r0 holds returns of <= 4 bytes
+r0-r1 hold returns of 8 bytes, low word in r0
+
+Callee must save/restore r4+ (except r12) if it modifies them.  If VFP
+is present, registers s16-s31 (a/k/a d8-d15, a/k/a q4-q7) must be preserved,
+s0-s15 (d0-d7, q0-a3) do not need to be.
+
+Stack is "full descending".  Only the arguments that don't fit in the first 4
+registers are placed on the stack.  "sp" points at the first stacked argument
+(i.e. the 5th arg).
+
+VFP: single-precision results in s0, double-precision results in d0.
+
+In the EABI, "sp" must be 64-bit aligned on entry to a function, and any
+64-bit quantities (long long, double) must be 64-bit aligned.
+*/
+
+/*
+Mterp and ARM notes:
+
+The following registers have fixed assignments:
+
+  reg nick      purpose
+  r4  rPC       interpreted program counter, used for fetching instructions
+  r5  rFP       interpreted frame pointer, used for accessing locals and args
+  r6  rSELF     self (Thread) pointer
+  r7  rINST     first 16-bit code unit of current instruction
+  r8  rIBASE    interpreted instruction base pointer, used for computed goto
+
+Macros are provided for common operations.  Each macro MUST emit only
+one instruction to make instruction-counting easier.  They MUST NOT alter
+unspecified registers or condition codes.
+*/
+
+/* single-purpose registers, given names for clarity */
+#define rPC     r4
+#define rFP     r5
+#define rSELF   r6
+#define rINST   r7
+#define rIBASE  r8
+
+/* save/restore the PC and/or FP from the thread struct */
+#define LOAD_PC_FROM_SELF()     ldr     rPC, [rSELF, #offThread_pc]
+#define SAVE_PC_TO_SELF()       str     rPC, [rSELF, #offThread_pc]
+#define LOAD_FP_FROM_SELF()     ldr     rFP, [rSELF, #offThread_curFrame]
+#define SAVE_FP_TO_SELF()       str     rFP, [rSELF, #offThread_curFrame]
+#define LOAD_PC_FP_FROM_SELF()  ldmia   rSELF, {rPC, rFP}
+#define SAVE_PC_FP_TO_SELF()    stmia   rSELF, {rPC, rFP}
+
+/*
+ * "export" the PC to the stack frame, f/b/o future exception objects.  Must
+ * be done *before* something throws.
+ *
+ * In C this is "SAVEAREA_FROM_FP(fp)->xtra.currentPc = pc", i.e.
+ * fp - sizeof(StackSaveArea) + offsetof(SaveArea, xtra.currentPc)
+ *
+ * It's okay to do this more than once.
+ */
+#define EXPORT_PC() \
+    str     rPC, [rFP, #(-sizeofStackSaveArea + offStackSaveArea_currentPc)]
+
+/*
+ * Given a frame pointer, find the stack save area.
+ *
+ * In C this is "((StackSaveArea*)(_fp) -1)".
+ */
+#define SAVEAREA_FROM_FP(_reg, _fpreg) \
+    sub     _reg, _fpreg, #sizeofStackSaveArea
+
+/*
+ * Fetch the next instruction from rPC into rINST.  Does not advance rPC.
+ */
+#define FETCH_INST()            ldrh    rINST, [rPC]
+
+/*
+ * Fetch the next instruction from the specified offset.  Advances rPC
+ * to point to the next instruction.  "_count" is in 16-bit code units.
+ *
+ * Because of the limited size of immediate constants on ARM, this is only
+ * suitable for small forward movements (i.e. don't try to implement "goto"
+ * with this).
+ *
+ * This must come AFTER anything that can throw an exception, or the
+ * exception catch may miss.  (This also implies that it must come after
+ * EXPORT_PC().)
+ */
+#define FETCH_ADVANCE_INST(_count) ldrh    rINST, [rPC, #((_count)*2)]!
+
+/*
+ * The operation performed here is similar to FETCH_ADVANCE_INST, except the
+ * src and dest registers are parameterized (not hard-wired to rPC and rINST).
+ */
+#define PREFETCH_ADVANCE_INST(_dreg, _sreg, _count) \
+        ldrh    _dreg, [_sreg, #((_count)*2)]!
+
+/*
+ * Fetch the next instruction from an offset specified by _reg.  Updates
+ * rPC to point to the next instruction.  "_reg" must specify the distance
+ * in bytes, *not* 16-bit code units, and may be a signed value.
+ *
+ * We want to write "ldrh rINST, [rPC, _reg, lsl #1]!", but some of the
+ * bits that hold the shift distance are used for the half/byte/sign flags.
+ * In some cases we can pre-double _reg for free, so we require a byte offset
+ * here.
+ */
+#define FETCH_ADVANCE_INST_RB(_reg) ldrh    rINST, [rPC, _reg]!
+
+/*
+ * Fetch a half-word code unit from an offset past the current PC.  The
+ * "_count" value is in 16-bit code units.  Does not advance rPC.
+ *
+ * The "_S" variant works the same but treats the value as signed.
+ */
+#define FETCH(_reg, _count)     ldrh    _reg, [rPC, #((_count)*2)]
+#define FETCH_S(_reg, _count)   ldrsh   _reg, [rPC, #((_count)*2)]
+
+/*
+ * Fetch one byte from an offset past the current PC.  Pass in the same
+ * "_count" as you would for FETCH, and an additional 0/1 indicating which
+ * byte of the halfword you want (lo/hi).
+ */
+#define FETCH_B(_reg, _count, _byte) ldrb     _reg, [rPC, #((_count)*2+(_byte))]
+
+/*
+ * Put the instruction's opcode field into the specified register.
+ */
+#define GET_INST_OPCODE(_reg)   and     _reg, rINST, #255
+
+/*
+ * Put the prefetched instruction's opcode field into the specified register.
+ */
+#define GET_PREFETCHED_OPCODE(_oreg, _ireg)   and     _oreg, _ireg, #255
+
+/*
+ * Begin executing the opcode in _reg.  Because this only jumps within the
+ * interpreter, we don't have to worry about pre-ARMv5 THUMB interwork.
+ */
+#define GOTO_OPCODE(_reg)       add     pc, rIBASE, _reg, lsl #${handler_size_bits}
+#define GOTO_OPCODE_BASE(_base,_reg)  add     pc, _base, _reg, lsl #${handler_size_bits}
+#define GOTO_OPCODE_IFEQ(_reg)  addeq   pc, rIBASE, _reg, lsl #${handler_size_bits}
+#define GOTO_OPCODE_IFNE(_reg)  addne   pc, rIBASE, _reg, lsl #${handler_size_bits}
+
+/*
+ * Get/set the 32-bit value from a Dalvik register.
+ */
+#ifdef WITH_TAINT_TRACKING
+#define SET_TAINT_FP(_reg)      add     _reg, rFP, #4
+#define SET_TAINT_CLEAR(_reg)   mov     _reg, #0
+#define GET_VREG(_reg, _vreg)   ldr     _reg, [rFP, _vreg, lsl #3]
+#define SET_VREG(_reg, _vreg)   str     _reg, [rFP, _vreg, lsl #3]
+#define GET_VREG_TAINT(_reg, _vreg, _rFP)   ldr     _reg, [_rFP, _vreg, lsl #3]
+#define SET_VREG_TAINT(_reg, _vreg, _rFP)   str     _reg, [_rFP, _vreg, lsl #3]
+#else
+#define GET_VREG(_reg, _vreg)   ldr     _reg, [rFP, _vreg, lsl #2]
+#define SET_VREG(_reg, _vreg)   str     _reg, [rFP, _vreg, lsl #2]
+#endif /*WITH_TAINT_TRACKING*/
+
+/*
+ * Convert a virtual register index into an address.
+ */
+#ifdef WITH_TAINT_TRACKING
+#define VREG_INDEX_TO_ADDR(_reg, _vreg) \
+        add     _reg, rFP, _vreg, lsl #3
+#else
+#define VREG_INDEX_TO_ADDR(_reg, _vreg) \
+        add     _reg, rFP, _vreg, lsl #2
+#endif /*WITH_TAINT_TRACKING*/
+
+/*
+ * This is a #include, not a %include, because we want the C pre-processor
+ * to expand the macros into assembler assignment statements.
+ */
+#include "../common/asm-constants.h"
+
+#if defined(WITH_JIT)
+#include "../common/jit-config.h"
+#endif
diff --git a/vm/mterp/armv5te_taint/stub.S b/vm/mterp/armv5te_taint/stub.S
new file mode 100644
index 0000000..767427b
--- /dev/null
+++ b/vm/mterp/armv5te_taint/stub.S
@@ -0,0 +1,8 @@
+    /* (stub) */
+    SAVE_PC_FP_TO_SELF()            @ only need to export these two
+    mov     r0, rSELF               @ self is first arg to function
+    bl      dvmMterp_${opcode}      @ call
+    LOAD_PC_FP_FROM_SELF()          @ retrieve updated values
+    FETCH_INST()                    @ load next instruction from rPC
+    GET_INST_OPCODE(ip)             @ ...trim down to just the opcode
+    GOTO_OPCODE(ip)                 @ ...and jump to the handler
diff --git a/vm/mterp/armv5te_taint/unop.S b/vm/mterp/armv5te_taint/unop.S
new file mode 100644
index 0000000..6dda62b
--- /dev/null
+++ b/vm/mterp/armv5te_taint/unop.S
@@ -0,0 +1,26 @@
+%default {"preinstr":""}
+    /*
+     * Generic 32-bit unary operation.  Provide an "instr" line that
+     * specifies an instruction that performs "result = op r0".
+     * This could be an ARM instruction or a function call.
+     *
+     * for: neg-int, not-int, neg-float, int-to-float, float-to-int,
+     *      int-to-byte, int-to-char, int-to-short
+     */
+    /* unop vA, vB */
+    mov     r3, rINST, lsr #12          @ r3<- B
+    mov     r9, rINST, lsr #8           @ r9<- A+
+    GET_VREG(r0, r3)                    @ r0<- vB
+    and     r9, r9, #15
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r1)
+    GET_VREG_TAINT(r2, r3, r1)          @ r2<- vB.taint
+    SET_VREG_TAINT(r2, r9, r1)
+// end WITH_TAINT_TRACKING
+    $preinstr                           @ optional op; may set condition codes
+    FETCH_ADVANCE_INST(1)               @ advance rPC, load rINST
+    $instr                              @ r0<- op, r0-r3 changed
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+    SET_VREG(r0, r9)                    @ vAA<- r0
+    GOTO_OPCODE(ip)                     @ jump to next instruction
+    /* 9-10 instructions */
diff --git a/vm/mterp/armv5te_taint/unopNarrower.S b/vm/mterp/armv5te_taint/unopNarrower.S
new file mode 100644
index 0000000..b00a73d
--- /dev/null
+++ b/vm/mterp/armv5te_taint/unopNarrower.S
@@ -0,0 +1,33 @@
+%default {"preinstr":""}
+    /*
+     * Generic 64bit-to-32bit unary operation.  Provide an "instr" line
+     * that specifies an instruction that performs "result = op r0/r1", where
+     * "result" is a 32-bit quantity in r0.
+     *
+     * For: long-to-float, double-to-int, double-to-float
+     *
+     * (This would work for long-to-int, but that instruction is actually
+     * an exact match for OP_MOVE.)
+     */
+    /* unop vA, vB */
+    mov     r3, rINST, lsr #12          @ r3<- B
+    mov     r9, rINST, lsr #8           @ r9<- A+
+// begin WITH_TAINT_TRACKING
+    add     r3, rFP, r3, lsl #3         @ r3<- &fp[B]
+    and     r9, r9, #15
+//    ldmia   r3, {r0-r1}                 @ r0/r1<- vB/vB+1
+    ldr     r0, [r3, #0]
+    ldr     r10, [r3, #4]
+    ldr     r1, [r3, #8]
+// end WITH_TAINT_TRACKING
+    FETCH_ADVANCE_INST(1)               @ advance rPC, load rINST
+    $preinstr                           @ optional op; may set condition codes
+    $instr                              @ r0<- op, r0-r3 changed
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+// begin WITH_TAINT_TRACKING
+    SET_VREG(r0, r9)                    @ vA<- r0
+    SET_TAINT_FP(r1)
+    SET_VREG_TAINT(r10, r9, r1)
+// end WITH_TAINT_TRACKING
+    GOTO_OPCODE(ip)                     @ jump to next instruction
+    /* 10-11 instructions */
diff --git a/vm/mterp/armv5te_taint/unopWide.S b/vm/mterp/armv5te_taint/unopWide.S
new file mode 100644
index 0000000..bbfad0b
--- /dev/null
+++ b/vm/mterp/armv5te_taint/unopWide.S
@@ -0,0 +1,37 @@
+%default {"preinstr":""}
+    /*
+     * Generic 64-bit unary operation.  Provide an "instr" line that
+     * specifies an instruction that performs "result = op r0/r1".
+     * This could be an ARM instruction or a function call.
+     *
+     * For: neg-long, not-long, neg-double, long-to-double, double-to-long
+     */
+    /* unop vA, vB */
+    mov     r9, rINST, lsr #8           @ r9<- A+
+    mov     r3, rINST, lsr #12          @ r3<- B
+    and     r9, r9, #15
+// begin WITH_TAINT_TRACKING
+    add     r3, rFP, r3, lsl #3         @ r3<- &fp[B]
+    add     r9, rFP, r9, lsl #3         @ r9<- &fp[A]
+//    ldmia   r3, {r0-r1}                 @ r0/r1<- vAA
+    ldr     r0, [r3, #0]
+    ldr     r1, [r3, #8]
+    ldr     r10, [r3, #4]
+// end WITH_TAINT_TRACKING
+    FETCH_ADVANCE_INST(1)               @ advance rPC, load rINST
+    $preinstr                           @ optional op; may set condition codes
+    $instr                              @ r0/r1<- op, r2-r3 changed
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+    b       .L${opcode}_finish
+%break
+
+.L${opcode}_finish:
+// begin WITH_TAINT_TRACKING
+//    stmia   r9, {r0-r1}                 @ vAA<- r0/r1
+    str     r0, [r9, #0]
+    str     r10, [r9, #4]
+    str     r1, [r9, #8]
+    str     r10, [r9, #12]
+// end WITH_TAINT_TRACKING
+    GOTO_OPCODE(ip)                     @ jump to next instruction
+    /* 12-13 instructions */
diff --git a/vm/mterp/armv5te_taint/unopWider.S b/vm/mterp/armv5te_taint/unopWider.S
new file mode 100644
index 0000000..61000aa
--- /dev/null
+++ b/vm/mterp/armv5te_taint/unopWider.S
@@ -0,0 +1,35 @@
+%default {"preinstr":""}
+    /*
+     * Generic 32bit-to-64bit unary operation.  Provide an "instr" line
+     * that specifies an instruction that performs "result = op r0", where
+     * "result" is a 64-bit quantity in r0/r1.
+     *
+     * For: int-to-long, int-to-double, float-to-long, float-to-double
+     */
+    /* unop vA, vB */
+    mov     r9, rINST, lsr #8           @ r9<- A+
+    mov     r3, rINST, lsr #12          @ r3<- B
+    and     r9, r9, #15
+    GET_VREG(r0, r3)                    @ r0<- vB
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r2)
+    GET_VREG_TAINT(r10, r3, r2)
+    add     r9, rFP, r9, lsl #3         @ r9<- &fp[A]
+// end WITH_TAINT_TRACKING
+    $preinstr                           @ optional op; may set condition codes
+    FETCH_ADVANCE_INST(1)               @ advance rPC, load rINST
+    $instr                              @ r0<- op, r0-r3 changed
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+    b      .L${opcode}_finish
+%break
+
+.L${opcode}_finish:
+// begin WITH_TAINT_TRACKING
+//    stmia   r9, {r0-r1}                 @ vA/vA+1<- r0/r1
+    str     r0, [r9, #0]
+    str     r10, [r9, #4]
+    str     r1, [r9, #8]
+    str     r10, [r9, #12]
+// end WITH_TAINT_TRACKING
+    GOTO_OPCODE(ip)                     @ jump to next instruction
+    /* 10-11 instructions */
diff --git a/vm/mterp/armv5te_taint/unused.S b/vm/mterp/armv5te_taint/unused.S
new file mode 100644
index 0000000..1c82919
--- /dev/null
+++ b/vm/mterp/armv5te_taint/unused.S
@@ -0,0 +1,2 @@
+    bl      common_abort
+
diff --git a/vm/mterp/armv5te_taint/zcmp.S b/vm/mterp/armv5te_taint/zcmp.S
new file mode 100644
index 0000000..bd63fe4
--- /dev/null
+++ b/vm/mterp/armv5te_taint/zcmp.S
@@ -0,0 +1,27 @@
+%verify "branch taken"
+%verify "branch not taken"
+    /*
+     * Generic one-operand compare-and-branch operation.  Provide a "revcmp"
+     * fragment that specifies the *reverse* comparison to perform, e.g.
+     * for "if-le" you would use "gt".
+     *
+     * for: if-eqz, if-nez, if-ltz, if-gez, if-gtz, if-lez
+     */
+    /* if-cmp vAA, +BBBB */
+    mov     r0, rINST, lsr #8           @ r0<- AA
+    GET_VREG(r2, r0)                    @ r2<- vAA
+    FETCH_S(r1, 1)                      @ r1<- branch offset, in code units
+    cmp     r2, #0                      @ compare (vA, 0)
+    mov${revcmp} r1, #2                 @ r1<- inst branch dist for not-taken
+    adds    r1, r1, r1                  @ convert to bytes & set flags
+    FETCH_ADVANCE_INST_RB(r1)           @ update rPC, load rINST
+#if defined(WITH_JIT)
+    ldr     r0, [rSELF, #offThread_pJitProfTable]
+    ldrmi   rIBASE, [rSELF, #offThread_curHandlerTable]   @ refresh table base
+    cmp     r0,#0
+    bne     common_updateProfile        @ test for JIT off at target
+#else
+    ldrmi   rIBASE, [rSELF, #offThread_curHandlerTable]   @ refresh table base
+#endif
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+    GOTO_OPCODE(ip)                     @ jump to next instruction
diff --git a/vm/mterp/armv6t2_taint/OP_ADD_FLOAT_2ADDR.S b/vm/mterp/armv6t2_taint/OP_ADD_FLOAT_2ADDR.S
new file mode 100644
index 0000000..cb00780
--- /dev/null
+++ b/vm/mterp/armv6t2_taint/OP_ADD_FLOAT_2ADDR.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv6t2_taint/binop2addr.S" {"instr":"bl      __aeabi_fadd"}
diff --git a/vm/mterp/armv6t2_taint/OP_ADD_INT_2ADDR.S b/vm/mterp/armv6t2_taint/OP_ADD_INT_2ADDR.S
new file mode 100644
index 0000000..8be2cec
--- /dev/null
+++ b/vm/mterp/armv6t2_taint/OP_ADD_INT_2ADDR.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv6t2_taint/binop2addr.S" {"instr":"add     r0, r0, r1"}
diff --git a/vm/mterp/armv6t2_taint/OP_ADD_INT_LIT16.S b/vm/mterp/armv6t2_taint/OP_ADD_INT_LIT16.S
new file mode 100644
index 0000000..7b60acb
--- /dev/null
+++ b/vm/mterp/armv6t2_taint/OP_ADD_INT_LIT16.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv6t2_taint/binopLit16.S" {"instr":"add     r0, r0, r1"}
diff --git a/vm/mterp/armv6t2_taint/OP_ADD_LONG_2ADDR.S b/vm/mterp/armv6t2_taint/OP_ADD_LONG_2ADDR.S
new file mode 100644
index 0000000..cf755ca
--- /dev/null
+++ b/vm/mterp/armv6t2_taint/OP_ADD_LONG_2ADDR.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv6t2_taint/binopWide2addr.S" {"preinstr":"adds    r0, r0, r2", "instr":"adc     r1, r1, r3"}
diff --git a/vm/mterp/armv6t2_taint/OP_AND_INT_2ADDR.S b/vm/mterp/armv6t2_taint/OP_AND_INT_2ADDR.S
new file mode 100644
index 0000000..67ca617
--- /dev/null
+++ b/vm/mterp/armv6t2_taint/OP_AND_INT_2ADDR.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv6t2_taint/binop2addr.S" {"instr":"and     r0, r0, r1"}
diff --git a/vm/mterp/armv6t2_taint/OP_AND_INT_LIT16.S b/vm/mterp/armv6t2_taint/OP_AND_INT_LIT16.S
new file mode 100644
index 0000000..9459c92
--- /dev/null
+++ b/vm/mterp/armv6t2_taint/OP_AND_INT_LIT16.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv6t2_taint/binopLit16.S" {"instr":"and     r0, r0, r1"}
diff --git a/vm/mterp/armv6t2_taint/OP_AND_LONG_2ADDR.S b/vm/mterp/armv6t2_taint/OP_AND_LONG_2ADDR.S
new file mode 100644
index 0000000..0747111
--- /dev/null
+++ b/vm/mterp/armv6t2_taint/OP_AND_LONG_2ADDR.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv6t2_taint/binopWide2addr.S" {"preinstr":"and     r0, r0, r2", "instr":"and     r1, r1, r3"}
diff --git a/vm/mterp/armv6t2_taint/OP_ARRAY_LENGTH.S b/vm/mterp/armv6t2_taint/OP_ARRAY_LENGTH.S
new file mode 100644
index 0000000..3829b48
--- /dev/null
+++ b/vm/mterp/armv6t2_taint/OP_ARRAY_LENGTH.S
@@ -0,0 +1,19 @@
+%verify "executed"
+    /*
+     * Return the length of an array.
+     */
+    mov     r1, rINST, lsr #12          @ r1<- B
+    ubfx    r2, rINST, #8, #4           @ r2<- A
+    GET_VREG(r0, r1)                    @ r0<- vB (object ref)
+    cmp     r0, #0                      @ is object null?
+    beq     common_errNullObject        @ yup, fail
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r1)
+    SET_TAINT_CLEAR(r3)
+    SET_VREG_TAINT(r3, r2, r1)
+// end WITH_TAINT_TRACKING
+    FETCH_ADVANCE_INST(1)               @ advance rPC, load rINST
+    ldr     r3, [r0, #offArrayObject_length]    @ r3<- array length
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+    SET_VREG(r3, r2)                    @ vB<- length
+    GOTO_OPCODE(ip)                     @ jump to next instruction
diff --git a/vm/mterp/armv6t2_taint/OP_CONST_4.S b/vm/mterp/armv6t2_taint/OP_CONST_4.S
new file mode 100644
index 0000000..0451517
--- /dev/null
+++ b/vm/mterp/armv6t2_taint/OP_CONST_4.S
@@ -0,0 +1,14 @@
+%verify "executed"
+    /* const/4 vA, #+B */
+    mov     r1, rINST, lsl #16          @ r1<- Bxxx0000
+    ubfx    r0, rINST, #8, #4           @ r0<- A
+    FETCH_ADVANCE_INST(1)               @ advance rPC, load rINST
+    mov     r1, r1, asr #28             @ r1<- sssssssB (sign-extended)
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r2)
+    SET_TAINT_CLEAR(r3)
+    SET_VREG_TAINT(r3, r0, r2)
+// end WITH_TAINT_TRACKING
+    GET_INST_OPCODE(ip)                 @ ip<- opcode from rINST
+    SET_VREG(r1, r0)                    @ fp[A]<- r1
+    GOTO_OPCODE(ip)                     @ execute next instruction
diff --git a/vm/mterp/armv6t2_taint/OP_DIV_FLOAT_2ADDR.S b/vm/mterp/armv6t2_taint/OP_DIV_FLOAT_2ADDR.S
new file mode 100644
index 0000000..4d2e989
--- /dev/null
+++ b/vm/mterp/armv6t2_taint/OP_DIV_FLOAT_2ADDR.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv6t2_taint/binop2addr.S" {"instr":"bl      __aeabi_fdiv"}
diff --git a/vm/mterp/armv6t2_taint/OP_DIV_INT_2ADDR.S b/vm/mterp/armv6t2_taint/OP_DIV_INT_2ADDR.S
new file mode 100644
index 0000000..5f9bc0a
--- /dev/null
+++ b/vm/mterp/armv6t2_taint/OP_DIV_INT_2ADDR.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv6t2_taint/binop2addr.S" {"instr":"bl     __aeabi_idiv","chkzero":"1"}
diff --git a/vm/mterp/armv6t2_taint/OP_DIV_INT_LIT16.S b/vm/mterp/armv6t2_taint/OP_DIV_INT_LIT16.S
new file mode 100644
index 0000000..69e5680
--- /dev/null
+++ b/vm/mterp/armv6t2_taint/OP_DIV_INT_LIT16.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv6t2_taint/binopLit16.S" {"instr":"bl     __aeabi_idiv","chkzero":"1"}
diff --git a/vm/mterp/armv6t2_taint/OP_DIV_LONG_2ADDR.S b/vm/mterp/armv6t2_taint/OP_DIV_LONG_2ADDR.S
new file mode 100644
index 0000000..5a63fd8
--- /dev/null
+++ b/vm/mterp/armv6t2_taint/OP_DIV_LONG_2ADDR.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv6t2_taint/binopWide2addr.S" {"instr":"bl      __aeabi_ldivmod", "chkzero":"1"}
diff --git a/vm/mterp/armv6t2_taint/OP_DOUBLE_TO_LONG.S b/vm/mterp/armv6t2_taint/OP_DOUBLE_TO_LONG.S
new file mode 100644
index 0000000..592ea7a
--- /dev/null
+++ b/vm/mterp/armv6t2_taint/OP_DOUBLE_TO_LONG.S
@@ -0,0 +1,54 @@
+%verify "executed"
+@include "armv6t2_taint/unopWide.S" {"instr":"bl      __aeabi_d2lz"}
+%include "armv6t2_taint/unopWide.S" {"instr":"bl      d2l_doconv"}
+
+%break
+/*
+ * Convert the double in r0/r1 to a long in r0/r1.
+ *
+ * We have to clip values to long min/max per the specification.  The
+ * expected common case is a "reasonable" value that converts directly
+ * to modest integer.  The EABI convert function isn't doing this for us.
+ */
+d2l_doconv:
+    stmfd   sp!, {r4, r5, lr}           @ save regs
+    mov     r3, #0x43000000             @ maxlong, as a double (high word)
+    add     r3, #0x00e00000             @  0x43e00000
+    mov     r2, #0                      @ maxlong, as a double (low word)
+    sub     sp, sp, #4                  @ align for EABI
+    mov     r4, r0                      @ save a copy of r0
+    mov     r5, r1                      @  and r1
+    bl      __aeabi_dcmpge              @ is arg >= maxlong?
+    cmp     r0, #0                      @ nonzero == yes
+    mvnne   r0, #0                      @ return maxlong (7fffffffffffffff)
+    mvnne   r1, #0x80000000
+    bne     1f
+
+    mov     r0, r4                      @ recover arg
+    mov     r1, r5
+    mov     r3, #0xc3000000             @ minlong, as a double (high word)
+    add     r3, #0x00e00000             @  0xc3e00000
+    mov     r2, #0                      @ minlong, as a double (low word)
+    bl      __aeabi_dcmple              @ is arg <= minlong?
+    cmp     r0, #0                      @ nonzero == yes
+    movne   r0, #0                      @ return minlong (8000000000000000)
+    movne   r1, #0x80000000
+    bne     1f
+
+    mov     r0, r4                      @ recover arg
+    mov     r1, r5
+    mov     r2, r4                      @ compare against self
+    mov     r3, r5
+    bl      __aeabi_dcmpeq              @ is arg == self?
+    cmp     r0, #0                      @ zero == no
+    moveq   r1, #0                      @ return zero for NaN
+    beq     1f
+
+    mov     r0, r4                      @ recover arg
+    mov     r1, r5
+    bl      __aeabi_d2lz                @ convert double to long
+
+1:
+    add     sp, sp, #4
+    ldmfd   sp!, {r4, r5, pc}
+
diff --git a/vm/mterp/armv6t2_taint/OP_FLOAT_TO_INT.S b/vm/mterp/armv6t2_taint/OP_FLOAT_TO_INT.S
new file mode 100644
index 0000000..86cbd74
--- /dev/null
+++ b/vm/mterp/armv6t2_taint/OP_FLOAT_TO_INT.S
@@ -0,0 +1,41 @@
+%verify "executed"
+/* EABI appears to have Java-style conversions of +inf/-inf/NaN */
+%include "armv6t2_taint/unop.S" {"instr":"bl      __aeabi_f2iz"}
+
+#if 0
+@include "armv6t2/unop.S" {"instr":"bl      f2i_doconv"}
+@break
+/*
+ * Convert the float in r0 to an int in r0.
+ *
+ * We have to clip values to int min/max per the specification.  The
+ * expected common case is a "reasonable" value that converts directly
+ * to modest integer.  The EABI convert function isn't doing this for us.
+ */
+f2i_doconv:
+    stmfd   sp!, {r4, lr}
+    mov     r1, #0x4f000000             @ (float)maxint
+    mov     r4, r0
+    bl      __aeabi_fcmpge              @ is arg >= maxint?
+    cmp     r0, #0                      @ nonzero == yes
+    mvnne   r0, #0x80000000             @ return maxint (7fffffff)
+    ldmnefd sp!, {r4, pc}
+
+    mov     r0, r4                      @ recover arg
+    mov     r1, #0xcf000000             @ (float)minint
+    bl      __aeabi_fcmple              @ is arg <= minint?
+    cmp     r0, #0                      @ nonzero == yes
+    movne   r0, #0x80000000             @ return minint (80000000)
+    ldmnefd sp!, {r4, pc}
+
+    mov     r0, r4                      @ recover arg
+    mov     r1, r4
+    bl      __aeabi_fcmpeq              @ is arg == self?
+    cmp     r0, #0                      @ zero == no
+    ldmeqfd sp!, {r4, pc}               @ return zero for NaN
+
+    mov     r0, r4                      @ recover arg
+    bl      __aeabi_f2iz                @ convert float to int
+    ldmfd   sp!, {r4, pc}
+#endif
+
diff --git a/vm/mterp/armv6t2_taint/OP_FLOAT_TO_LONG.S b/vm/mterp/armv6t2_taint/OP_FLOAT_TO_LONG.S
new file mode 100644
index 0000000..638ece8
--- /dev/null
+++ b/vm/mterp/armv6t2_taint/OP_FLOAT_TO_LONG.S
@@ -0,0 +1,41 @@
+%verify "executed"
+@include "armv6t2_taint/unopWider.S" {"instr":"bl      __aeabi_f2lz"}
+%include "armv6t2_taint/unopWider.S" {"instr":"bl      f2l_doconv"}
+
+%break
+/*
+ * Convert the float in r0 to a long in r0/r1.
+ *
+ * We have to clip values to long min/max per the specification.  The
+ * expected common case is a "reasonable" value that converts directly
+ * to modest integer.  The EABI convert function isn't doing this for us.
+ */
+f2l_doconv:
+    stmfd   sp!, {r4, lr}
+    mov     r1, #0x5f000000             @ (float)maxlong
+    mov     r4, r0
+    bl      __aeabi_fcmpge              @ is arg >= maxlong?
+    cmp     r0, #0                      @ nonzero == yes
+    mvnne   r0, #0                      @ return maxlong (7fffffff)
+    mvnne   r1, #0x80000000
+    ldmnefd sp!, {r4, pc}
+
+    mov     r0, r4                      @ recover arg
+    mov     r1, #0xdf000000             @ (float)minlong
+    bl      __aeabi_fcmple              @ is arg <= minlong?
+    cmp     r0, #0                      @ nonzero == yes
+    movne   r0, #0                      @ return minlong (80000000)
+    movne   r1, #0x80000000
+    ldmnefd sp!, {r4, pc}
+
+    mov     r0, r4                      @ recover arg
+    mov     r1, r4
+    bl      __aeabi_fcmpeq              @ is arg == self?
+    cmp     r0, #0                      @ zero == no
+    moveq   r1, #0                      @ return zero for NaN
+    ldmeqfd sp!, {r4, pc}
+
+    mov     r0, r4                      @ recover arg
+    bl      __aeabi_f2lz                @ convert float to long
+    ldmfd   sp!, {r4, pc}
+
diff --git a/vm/mterp/armv6t2_taint/OP_IF_EQ.S b/vm/mterp/armv6t2_taint/OP_IF_EQ.S
new file mode 100644
index 0000000..d33125d
--- /dev/null
+++ b/vm/mterp/armv6t2_taint/OP_IF_EQ.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv6t2_taint/bincmp.S" { "revcmp":"ne" }
diff --git a/vm/mterp/armv6t2_taint/OP_IF_GE.S b/vm/mterp/armv6t2_taint/OP_IF_GE.S
new file mode 100644
index 0000000..2fd973c
--- /dev/null
+++ b/vm/mterp/armv6t2_taint/OP_IF_GE.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv6t2_taint/bincmp.S" { "revcmp":"lt" }
diff --git a/vm/mterp/armv6t2_taint/OP_IF_GT.S b/vm/mterp/armv6t2_taint/OP_IF_GT.S
new file mode 100644
index 0000000..819e4c8
--- /dev/null
+++ b/vm/mterp/armv6t2_taint/OP_IF_GT.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv6t2_taint/bincmp.S" { "revcmp":"le" }
diff --git a/vm/mterp/armv6t2_taint/OP_IF_LE.S b/vm/mterp/armv6t2_taint/OP_IF_LE.S
new file mode 100644
index 0000000..95fa0a9
--- /dev/null
+++ b/vm/mterp/armv6t2_taint/OP_IF_LE.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv6t2_taint/bincmp.S" { "revcmp":"gt" }
diff --git a/vm/mterp/armv6t2_taint/OP_IF_LT.S b/vm/mterp/armv6t2_taint/OP_IF_LT.S
new file mode 100644
index 0000000..3e6616e
--- /dev/null
+++ b/vm/mterp/armv6t2_taint/OP_IF_LT.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv6t2_taint/bincmp.S" { "revcmp":"ge" }
diff --git a/vm/mterp/armv6t2_taint/OP_IF_NE.S b/vm/mterp/armv6t2_taint/OP_IF_NE.S
new file mode 100644
index 0000000..21ec275
--- /dev/null
+++ b/vm/mterp/armv6t2_taint/OP_IF_NE.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv6t2_taint/bincmp.S" { "revcmp":"eq" }
diff --git a/vm/mterp/armv6t2_taint/OP_IGET.S b/vm/mterp/armv6t2_taint/OP_IGET.S
new file mode 100644
index 0000000..8067b88
--- /dev/null
+++ b/vm/mterp/armv6t2_taint/OP_IGET.S
@@ -0,0 +1,62 @@
+%default { "load":"ldr", "sqnum":"0" }
+%verify "executed"
+%verify "null object"
+%verify "field already resolved"
+%verify "field not yet resolved"
+%verify "field cannot be resolved"
+    /*
+     * General 32-bit instance field get.
+     *
+     * for: iget, iget-object, iget-boolean, iget-byte, iget-char, iget-short
+     */
+    /* op vA, vB, field@CCCC */
+    mov     r0, rINST, lsr #12          @ r0<- B
+    ldr     r3, [rSELF, #offThread_methodClassDex]    @ r3<- DvmDex
+    FETCH(r1, 1)                        @ r1<- field ref CCCC
+    ldr     r2, [r3, #offDvmDex_pResFields] @ r2<- pDvmDex->pResFields
+// begin WITH_TAINT_TRACKING
+    bl      .L${opcode}_taint_prop
+// end WITH_TAINT_TRACKING
+    cmp     r0, #0                      @ is resolved entry null?
+    bne     .L${opcode}_finish          @ no, already resolved
+8:  ldr     r2, [rSELF, #offThread_method]    @ r2<- current method
+    EXPORT_PC()                         @ resolve() could throw
+    ldr     r0, [r2, #offMethod_clazz]  @ r0<- method->clazz
+    bl      dvmResolveInstField         @ r0<- resolved InstField ptr
+    cmp     r0, #0
+    bne     .L${opcode}_finish
+    b       common_exceptionThrown
+%break
+
+    /*
+     * Currently:
+     *  r0 holds resolved field
+     *  r9 holds object
+     */
+.L${opcode}_finish:
+    @bl      common_squeak${sqnum}
+    cmp     r9, #0                      @ check object for null
+    ldr     r3, [r0, #offInstField_byteOffset]  @ r3<- byte offset of field
+    beq     common_errNullObject        @ object was null
+// begin WITH_TAINT_TRACKING
+    $load   r0, [r9, r3]                @ r0<- obj.field (8/16/32 bits)
+    add     r3, r3, #4
+    ldr	    r3, [r9, r3]
+    orr     r3, r3, r10
+// end WITH_TAINT_TRACKING
+    ubfx    r2, rINST, #8, #4           @ r2<- A
+    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+    SET_VREG(r0, r2)                    @ fp[A]<- r0
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r1)
+    SET_VREG_TAINT(r3, r2, r1)
+// end WITH_TAINT_TRACKING
+    GOTO_OPCODE(ip)                     @ jump to next instruction
+
+.L${opcode}_taint_prop:
+    GET_VREG(r9, r0)                    @ r9<- fp[B], the object pointer
+    SET_TAINT_FP(r3)
+    GET_VREG_TAINT(r10, r0, r3)
+    ldr     r0, [r2, r1, lsl #2]        @ r0<- resolved InstField ptr
+    bx      lr
diff --git a/vm/mterp/armv6t2_taint/OP_IGET_QUICK.S b/vm/mterp/armv6t2_taint/OP_IGET_QUICK.S
new file mode 100644
index 0000000..8814c75
--- /dev/null
+++ b/vm/mterp/armv6t2_taint/OP_IGET_QUICK.S
@@ -0,0 +1,36 @@
+%verify "executed"
+%verify "null object"
+    /* For: iget-quick, iget-object-quick */
+    /* op vA, vB, offset@CCCC */
+    mov     r2, rINST, lsr #12          @ r2<- B
+    FETCH(r1, 1)                        @ r1<- field byte offset
+    GET_VREG(r3, r2)                    @ r3<- object we're operating on
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r0)
+    GET_VREG_TAINT(r9, r2, r0)
+// end WITH_TAINT_TRACKING
+    ubfx    r2, rINST, #8, #4           @ r2<- A
+    cmp     r3, #0                      @ check object for null
+    beq     common_errNullObject        @ object was null
+    ldr     r0, [r3, r1]                @ r0<- obj.field (always 32 bits)
+// begin WITH_TAINT_TRACKING
+    bl      .L${opcode}_taint_prop
+//    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST // in subroutine
+// end WITH_TAINT_TRACKING
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+    SET_VREG(r0, r2)                    @ fp[A]<- r0
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r0)
+    SET_VREG_TAINT(r10, r2, r0)
+// end WITH_TAINT_TRACKING
+    GOTO_OPCODE(ip)                     @ jump to next instruction
+
+%break
+
+.L${opcode}_taint_prop:
+    add     r1, r1, #4
+    ldr     r10, [r3, r1]
+    orr     r10, r9, r10
+    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
+    bx      lr
+
diff --git a/vm/mterp/armv6t2_taint/OP_IGET_WIDE.S b/vm/mterp/armv6t2_taint/OP_IGET_WIDE.S
new file mode 100644
index 0000000..4d1114c
--- /dev/null
+++ b/vm/mterp/armv6t2_taint/OP_IGET_WIDE.S
@@ -0,0 +1,61 @@
+%verify "executed"
+%verify "null object"
+%verify "field already resolved"
+%verify "field not yet resolved"
+%verify "field cannot be resolved"
+    /*
+     * Wide 32-bit instance field get.
+     */
+    /* iget-wide vA, vB, field@CCCC */
+    mov     r0, rINST, lsr #12          @ r0<- B
+    ldr     r3, [rSELF, #offThread_methodClassDex]    @ r3<- DvmDex
+    FETCH(r1, 1)                        @ r1<- field ref CCCC
+    ldr     r2, [r3, #offDvmDex_pResFields] @ r2<- pResFields
+// begin WITH_TAINT_TRACKING
+    bl      .L${opcode}_taint_prop
+// end WITH_TAINT_TRACKING
+    cmp     r0, #0                      @ is resolved entry null?
+    bne     .L${opcode}_finish          @ no, already resolved
+8:  ldr     r2, [rSELF, #offThread_method] @ r2<- current method
+    EXPORT_PC()                         @ resolve() could throw
+    ldr     r0, [r2, #offMethod_clazz]  @ r0<- method->clazz
+    bl      dvmResolveInstField         @ r0<- resolved InstField ptr
+    cmp     r0, #0
+    bne     .L${opcode}_finish
+    b       common_exceptionThrown
+%break
+
+    /*
+     * Currently:
+     *  r0 holds resolved field
+     *  r9 holds object
+     */
+.L${opcode}_finish:
+    cmp     r9, #0                      @ check object for null
+    ldr     r3, [r0, #offInstField_byteOffset]  @ r3<- byte offset of field
+    beq     common_errNullObject        @ object was null
+// begin WITH_TAINT_TRACKING
+    ldrd    r0, [r9, r3]                @ r0/r1<- obj.field (64-bit align ok)
+    add     r3, r3, #8
+    ldr     r3, [r9, r3]
+    orr	    r10, r3, r10
+    ubfx    r2, rINST, #8, #4           @ r2<- A
+    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
+    add     r3, rFP, r2, lsl #3         @ r3<- &fp[A]
+// end WITH_TAINT_TRACKING
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+// begin WITH_TAINT_TRACKING
+//    stmia   r3, {r0-r1}                 @ fp[A]<- r0/r1
+    str    r0, [r3, #0]
+    str    r10, [r3, #4]
+    str    r1, [r3, #8]
+    str    r10, [r3, #12]
+// end WITH_TAINT_TRACKING
+    GOTO_OPCODE(ip)                     @ jump to next instruction
+
+.L${opcode}_taint_prop:
+    GET_VREG(r9, r0)                    @ r9<- fp[B], the object pointer
+    SET_TAINT_FP(r3)
+    GET_VREG_TAINT(r10, r0, r3)
+    ldr     r0, [r2, r1, lsl #2]        @ r0<- resolved InstField ptr
+    bx      lr
diff --git a/vm/mterp/armv6t2_taint/OP_IGET_WIDE_QUICK.S b/vm/mterp/armv6t2_taint/OP_IGET_WIDE_QUICK.S
new file mode 100644
index 0000000..8392fae
--- /dev/null
+++ b/vm/mterp/armv6t2_taint/OP_IGET_WIDE_QUICK.S
@@ -0,0 +1,36 @@
+%verify "executed"
+%verify "null object"
+    /* iget-wide-quick vA, vB, offset@CCCC */
+    mov     r2, rINST, lsr #12          @ r2<- B
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r0)
+    GET_VREG_TAINT(r9, r2, r0)
+// end WITH_TAINT_TRACKING
+    FETCH(ip, 1)                        @ ip<- field byte offset
+    GET_VREG(r3, r2)                    @ r3<- object we're operating on
+    ubfx    r2, rINST, #8, #4           @ r2<- A
+    cmp     r3, #0                      @ check object for null
+    beq     common_errNullObject        @ object was null
+// begin WITH_TAINT_TRACKING
+    add     r10, ip, #8
+    ldrd    r0, [r3, ip]                @ r0<- obj.field (64 bits, aligned)
+    ldr     r10, [r3, r10]
+    orr     r10, r9, r10
+// end WITH_TAINT_TRACKING
+    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
+// begin WITH_TAINT_TRACKING
+    bl      iget_wide_quick_taint_prop
+// end WITH_TAINT_TRACKING
+    GOTO_OPCODE(ip)                     @ jump to next instruction
+
+%break
+
+iget_wide_quick_taint_prop:
+    add     r3, rFP, r2, lsl #3         @ r3<- &fp[A]
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+//    stmia   r3, {r0-r1}                 @ fp[A]<- r0/r1
+    str     r0, [r3, #0]
+    str     r10, [r3, #4]
+    str     r1, [r3, #8]
+    str     r10, [r3, #12]
+    bx      lr
diff --git a/vm/mterp/armv6t2_taint/OP_INT_TO_BYTE.S b/vm/mterp/armv6t2_taint/OP_INT_TO_BYTE.S
new file mode 100644
index 0000000..ec31b79
--- /dev/null
+++ b/vm/mterp/armv6t2_taint/OP_INT_TO_BYTE.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv6t2_taint/unop.S" {"instr":"sxtb    r0, r0"}
diff --git a/vm/mterp/armv6t2_taint/OP_INT_TO_CHAR.S b/vm/mterp/armv6t2_taint/OP_INT_TO_CHAR.S
new file mode 100644
index 0000000..22d41f4
--- /dev/null
+++ b/vm/mterp/armv6t2_taint/OP_INT_TO_CHAR.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv6t2_taint/unop.S" {"instr":"uxth    r0, r0"}
diff --git a/vm/mterp/armv6t2_taint/OP_INT_TO_DOUBLE.S b/vm/mterp/armv6t2_taint/OP_INT_TO_DOUBLE.S
new file mode 100644
index 0000000..715a864
--- /dev/null
+++ b/vm/mterp/armv6t2_taint/OP_INT_TO_DOUBLE.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv6t2_taint/unopWider.S" {"instr":"bl      __aeabi_i2d"}
diff --git a/vm/mterp/armv6t2_taint/OP_INT_TO_FLOAT.S b/vm/mterp/armv6t2_taint/OP_INT_TO_FLOAT.S
new file mode 100644
index 0000000..913b21a
--- /dev/null
+++ b/vm/mterp/armv6t2_taint/OP_INT_TO_FLOAT.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv6t2_taint/unop.S" {"instr":"bl      __aeabi_i2f"}
diff --git a/vm/mterp/armv6t2_taint/OP_INT_TO_LONG.S b/vm/mterp/armv6t2_taint/OP_INT_TO_LONG.S
new file mode 100644
index 0000000..2558f73
--- /dev/null
+++ b/vm/mterp/armv6t2_taint/OP_INT_TO_LONG.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv6t2_taint/unopWider.S" {"instr":"mov     r1, r0, asr #31"}
diff --git a/vm/mterp/armv6t2_taint/OP_INT_TO_SHORT.S b/vm/mterp/armv6t2_taint/OP_INT_TO_SHORT.S
new file mode 100644
index 0000000..012e420
--- /dev/null
+++ b/vm/mterp/armv6t2_taint/OP_INT_TO_SHORT.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv6t2_taint/unop.S" {"instr":"sxth    r0, r0"}
diff --git a/vm/mterp/armv6t2_taint/OP_IPUT.S b/vm/mterp/armv6t2_taint/OP_IPUT.S
new file mode 100644
index 0000000..4133a99
--- /dev/null
+++ b/vm/mterp/armv6t2_taint/OP_IPUT.S
@@ -0,0 +1,54 @@
+%default { "store":"str", "sqnum":"0" }
+%verify "executed"
+%verify "null object"
+%verify "field already resolved"
+%verify "field not yet resolved"
+%verify "field cannot be resolved"
+    /*
+     * General 32-bit instance field put.
+     *
+     * for: iput, iput-object, iput-boolean, iput-byte, iput-char, iput-short
+     */
+    /* op vA, vB, field@CCCC */
+    mov     r0, rINST, lsr #12          @ r0<- B
+    ldr     r3, [rSELF, #offThread_methodClassDex]    @ r3<- DvmDex
+    FETCH(r1, 1)                        @ r1<- field ref CCCC
+    ldr     r2, [r3, #offDvmDex_pResFields] @ r2<- pDvmDex->pResFields
+    GET_VREG(r9, r0)                    @ r9<- fp[B], the object pointer
+    ldr     r0, [r2, r1, lsl #2]        @ r0<- resolved InstField ptr
+    cmp     r0, #0                      @ is resolved entry null?
+    bne     .L${opcode}_finish          @ no, already resolved
+8:  ldr     r2, [rSELF, #offThread_method]    @ r2<- current method
+    EXPORT_PC()                         @ resolve() could throw
+    ldr     r0, [r2, #offMethod_clazz]  @ r0<- method->clazz
+    bl      dvmResolveInstField         @ r0<- resolved InstField ptr
+    cmp     r0, #0                      @ success?
+    bne     .L${opcode}_finish          @ yes, finish up
+    b       common_exceptionThrown
+%break
+
+    /*
+     * Currently:
+     *  r0 holds resolved field
+     *  r9 holds object
+     */
+.L${opcode}_finish:
+    @bl      common_squeak${sqnum}
+    ldr     r3, [r0, #offInstField_byteOffset]  @ r3<- byte offset of field
+    ubfx    r1, rINST, #8, #4           @ r1<- A
+    cmp     r9, #0                      @ check object for null
+    GET_VREG(r0, r1)                    @ r0<- fp[A]
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r2)
+    GET_VREG_TAINT(r10, r1, r2)
+// end WITH_TAINT_TRACKING
+    beq     common_errNullObject        @ object was null
+    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+    $store  r0, [r9, r3]                @ obj.field (8/16/32 bits)<- r0
+// begin WITH_TAINT_TRACKING
+    add	    r3, r3, #4
+    str	    r10, [r9, r3]
+// end WITH_TAINT_TRACKING
+    GOTO_OPCODE(ip)                     @ jump to next instruction
+
diff --git a/vm/mterp/armv6t2_taint/OP_IPUT_QUICK.S b/vm/mterp/armv6t2_taint/OP_IPUT_QUICK.S
new file mode 100644
index 0000000..12b40c8
--- /dev/null
+++ b/vm/mterp/armv6t2_taint/OP_IPUT_QUICK.S
@@ -0,0 +1,24 @@
+%verify "executed"
+%verify "null object"
+    /* For: iput-quick, iput-object-quick */
+    /* op vA, vB, offset@CCCC */
+    mov     r2, rINST, lsr #12          @ r2<- B
+    FETCH(r1, 1)                        @ r1<- field byte offset
+    GET_VREG(r3, r2)                    @ r3<- fp[B], the object pointer
+    ubfx    r2, rINST, #8, #4           @ r2<- A
+    cmp     r3, #0                      @ check object for null
+    beq     common_errNullObject        @ object was null
+    GET_VREG(r0, r2)                    @ r0<- fp[A]
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r9)
+    GET_VREG_TAINT(r10, r2, r9)
+// end WITH_TAINT_TRACKING
+    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
+    str     r0, [r3, r1]                @ obj.field (always 32 bits)<- r0
+// begin WITH_TAINT_TRACKING
+    add	    r1, r1, #4
+    str     r10, [r3, r1]
+// end WITH_TAINT_TRACKING
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+    GOTO_OPCODE(ip)                     @ jump to next instruction
+
diff --git a/vm/mterp/armv6t2_taint/OP_IPUT_WIDE.S b/vm/mterp/armv6t2_taint/OP_IPUT_WIDE.S
new file mode 100644
index 0000000..4d57fbf
--- /dev/null
+++ b/vm/mterp/armv6t2_taint/OP_IPUT_WIDE.S
@@ -0,0 +1,51 @@
+%verify "executed"
+%verify "null object"
+%verify "field already resolved"
+%verify "field not yet resolved"
+%verify "field cannot be resolved"
+    /* iput-wide vA, vB, field@CCCC */
+    mov     r0, rINST, lsr #12          @ r0<- B
+    ldr     r3, [rSELF, #offThread_methodClassDex]    @ r3<- DvmDex
+    FETCH(r1, 1)                        @ r1<- field ref CCCC
+    ldr     r2, [r3, #offDvmDex_pResFields] @ r2<- pResFields
+    GET_VREG(r9, r0)                    @ r9<- fp[B], the object pointer
+    ldr     r0, [r2, r1, lsl #2]        @ r0<- resolved InstField ptr
+    cmp     r0, #0                      @ is resolved entry null?
+    bne     .L${opcode}_finish          @ no, already resolved
+8:  ldr     r2, [rSELF, #offThread_method] @ r2<- current method
+    EXPORT_PC()                         @ resolve() could throw
+    ldr     r0, [r2, #offMethod_clazz]  @ r0<- method->clazz
+    bl      dvmResolveInstField         @ r0<- resolved InstField ptr
+    cmp     r0, #0                      @ success?
+    bne     .L${opcode}_finish          @ yes, finish up
+    b       common_exceptionThrown
+%break
+
+    /*
+     * Currently:
+     *  r0 holds resolved field
+     *  r9 holds object
+     */
+.L${opcode}_finish:
+    ubfx    r2, rINST, #8, #4           @ r2<- A
+    cmp     r9, #0                      @ check object for null
+    ldr     r3, [r0, #offInstField_byteOffset]  @ r3<- byte offset of field
+// begin WITH_TAINT_TRACKING
+    add     r2, rFP, r2, lsl #3         @ r3<- &fp[A]
+// end WITH_TAINT_TRACKING
+    beq     common_errNullObject        @ object was null
+    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
+// begin WITH_TAINT_TRACKING
+//    ldmia   r2, {r0-r1}                 @ r0/r1<- fp[A]
+    ldr	    r0, [r2, #0]
+    ldr     r1, [r2, #8]
+    ldr	    r10, [r2, #4]
+// end WITH_TAINT_TRACKING
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+    strd    r0, [r9, r3]                @ obj.field (64 bits, aligned)<- r0/r1
+// begin WITH_TAINT_TRACKING
+    add	    r3, r3, #8
+    str	    r10, [r9, r3]
+// end WITH_TAINT_TRACKING
+    GOTO_OPCODE(ip)                     @ jump to next instruction
+
diff --git a/vm/mterp/armv6t2_taint/OP_IPUT_WIDE_QUICK.S b/vm/mterp/armv6t2_taint/OP_IPUT_WIDE_QUICK.S
new file mode 100644
index 0000000..398b8c9
--- /dev/null
+++ b/vm/mterp/armv6t2_taint/OP_IPUT_WIDE_QUICK.S
@@ -0,0 +1,30 @@
+%verify "executed"
+%verify "null object"
+    /* iput-wide-quick vA, vB, offset@CCCC */
+    mov     r1, rINST, lsr #12          @ r1<- B
+    ubfx    r0, rINST, #8, #4           @ r0<- A
+    GET_VREG(r2, r1)                    @ r2<- fp[B], the object pointer
+// begin WITH_TAINT_TRACKING
+    bl iput_wide_quick_taint_prop
+// end WITH_TAINT_TRACKING
+    beq     common_errNullObject        @ object was null
+    FETCH(r3, 1)                        @ r3<- field byte offset
+    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
+    strd    r0, [r2, r3]                @ obj.field (64 bits, aligned)<- r0/r1
+// begin WITH_TAINT_TRACKING
+    add     r3, r3, #8
+    str     r9, [r2, r3]
+// end WITH_TAINT_TRACKING
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+    GOTO_OPCODE(ip)                     @ jump to next instruction
+
+%break
+
+iput_wide_quick_taint_prop:
+    add     r3, rFP, r0, lsl #3         @ r3<- &fp[A]
+    cmp     r2, #0                      @ check object for null
+//    ldmia   r3, {r0-r1}                 @ r0/r1<- fp[A]
+    ldr     r0, [r3, #0]
+    ldr     r1, [r3, #8]
+    ldr     r9, [r3, #4]
+    bx      lr
diff --git a/vm/mterp/armv6t2_taint/OP_LONG_TO_DOUBLE.S b/vm/mterp/armv6t2_taint/OP_LONG_TO_DOUBLE.S
new file mode 100644
index 0000000..f5544ad
--- /dev/null
+++ b/vm/mterp/armv6t2_taint/OP_LONG_TO_DOUBLE.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv6t2_taint/unopWide.S" {"instr":"bl      __aeabi_l2d"}
diff --git a/vm/mterp/armv6t2_taint/OP_LONG_TO_FLOAT.S b/vm/mterp/armv6t2_taint/OP_LONG_TO_FLOAT.S
new file mode 100644
index 0000000..068eb15
--- /dev/null
+++ b/vm/mterp/armv6t2_taint/OP_LONG_TO_FLOAT.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv6t2_taint/unopNarrower.S" {"instr":"bl      __aeabi_l2f"}
diff --git a/vm/mterp/armv6t2_taint/OP_MOVE.S b/vm/mterp/armv6t2_taint/OP_MOVE.S
new file mode 100644
index 0000000..984bd97
--- /dev/null
+++ b/vm/mterp/armv6t2_taint/OP_MOVE.S
@@ -0,0 +1,16 @@
+%verify "executed"
+    /* for move, move-object, long-to-int */
+    /* op vA, vB */
+    mov     r1, rINST, lsr #12          @ r1<- B from 15:12
+    ubfx    r0, rINST, #8, #4           @ r0<- A from 11:8
+    FETCH_ADVANCE_INST(1)               @ advance rPC, load rINST
+    GET_VREG(r2, r1)                    @ r2<- fp[B]
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r3)
+    GET_VREG_TAINT(r1, r1, r3)
+    SET_VREG_TAINT(r1, r0, r3)
+// end WITH_TAINT_TRACKING
+    GET_INST_OPCODE(ip)                 @ ip<- opcode from rINST
+    SET_VREG(r2, r0)                    @ fp[A]<- r2
+    GOTO_OPCODE(ip)                     @ execute next instruction
+
diff --git a/vm/mterp/armv6t2_taint/OP_MOVE_WIDE.S b/vm/mterp/armv6t2_taint/OP_MOVE_WIDE.S
new file mode 100644
index 0000000..90ee0f4
--- /dev/null
+++ b/vm/mterp/armv6t2_taint/OP_MOVE_WIDE.S
@@ -0,0 +1,17 @@
+%verify "executed"
+    /* move-wide vA, vB */
+    /* NOTE: regs can overlap, e.g. "move v6,v7" or "move v7,v6" */
+    mov     r3, rINST, lsr #12          @ r3<- B
+    ubfx    r2, rINST, #8, #4           @ r2<- A
+// begin WITH_TAINT_TRACKING
+    add     r3, rFP, r3, lsl #3         @ r3<- &fp[B]
+    add     r9, rFP, r2, lsl #3         @ r9<- &fp[A]
+    ldmia   r3, {r0-r3}                 @ r0/r1<- fp[B]
+// end WITH_TAINT_TRACKING
+    FETCH_ADVANCE_INST(1)               @ advance rPC, load rINST
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+// begin WITH_TAINT_TRACKING
+    stmia   r9, {r0-r3}                 @ fp[A]<- r0/r1
+// end WITH_TAINT_TRACKING
+    GOTO_OPCODE(ip)                     @ jump to next instruction
+
diff --git a/vm/mterp/armv6t2_taint/OP_MUL_FLOAT_2ADDR.S b/vm/mterp/armv6t2_taint/OP_MUL_FLOAT_2ADDR.S
new file mode 100644
index 0000000..248a878
--- /dev/null
+++ b/vm/mterp/armv6t2_taint/OP_MUL_FLOAT_2ADDR.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv6t2_taint/binop2addr.S" {"instr":"bl      __aeabi_fmul"}
diff --git a/vm/mterp/armv6t2_taint/OP_MUL_INT_2ADDR.S b/vm/mterp/armv6t2_taint/OP_MUL_INT_2ADDR.S
new file mode 100644
index 0000000..b7ecd0f
--- /dev/null
+++ b/vm/mterp/armv6t2_taint/OP_MUL_INT_2ADDR.S
@@ -0,0 +1,3 @@
+%verify "executed"
+/* must be "mul r0, r1, r0" -- "r0, r0, r1" is illegal */
+%include "armv6t2_taint/binop2addr.S" {"instr":"mul     r0, r1, r0"}
diff --git a/vm/mterp/armv6t2_taint/OP_MUL_INT_LIT16.S b/vm/mterp/armv6t2_taint/OP_MUL_INT_LIT16.S
new file mode 100644
index 0000000..2545107
--- /dev/null
+++ b/vm/mterp/armv6t2_taint/OP_MUL_INT_LIT16.S
@@ -0,0 +1,3 @@
+%verify "executed"
+/* must be "mul r0, r1, r0" -- "r0, r0, r1" is illegal */
+%include "armv6t2_taint/binopLit16.S" {"instr":"mul     r0, r1, r0"}
diff --git a/vm/mterp/armv6t2_taint/OP_MUL_LONG_2ADDR.S b/vm/mterp/armv6t2_taint/OP_MUL_LONG_2ADDR.S
new file mode 100644
index 0000000..19c89e0
--- /dev/null
+++ b/vm/mterp/armv6t2_taint/OP_MUL_LONG_2ADDR.S
@@ -0,0 +1,48 @@
+%verify "executed"
+    /*
+     * Signed 64-bit integer multiply, "/2addr" version.
+     *
+     * See OP_MUL_LONG for an explanation.
+     *
+     * We get a little tight on registers, so to avoid looking up &fp[A]
+     * again we stuff it into rINST.
+     */
+    /* mul-long/2addr vA, vB */
+    mov     r1, rINST, lsr #12          @ r1<- B
+// begin WITH_TAINT_TRACKING
+    bl      mul_long_2addr_taint_prop
+// end WITH_TAINT_TRACKING
+    umull   r9, r10, r2, r0             @  r9/r10 <- ZxX
+    mla     r2, r0, r3, ip              @  r2<- YxX + (ZxW)
+    mov     r0, rINST                   @ r0<- &fp[A] (free up rINST)
+    FETCH_ADVANCE_INST(1)               @ advance rPC, load rINST
+    add     r10, r2, r10                @  r10<- r10 + low(ZxW + (YxX))
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+// begin WITH_TAINT_TRACKING
+//    stmia   r0, {r9-r10}                @ vAA/vAA+1<- r9/r10
+    str     r9, [r0, #0]
+    str     r10, [r0, #8]
+    str     r10, [r0, #12]
+    ldmfd   sp!, {r10}
+    str     r10, [r0, #4]
+// end WITH_TAINT_TRACKING
+    GOTO_OPCODE(ip)                     @ jump to next instruction
+
+%break
+
+mul_long_2addr_taint_prop:
+    ubfx    r9, rINST, #8, #4           @ r9<- A
+    add     r1, rFP, r1, lsl #3         @ r1<- &fp[B]
+    add     rINST, rFP, r9, lsl #3      @ rINST<- &fp[A]
+//    ldmia   r1, {r2-r3}                 @ r2/r3<- vBB/vBB+1
+    ldr     r2, [r1, #0]
+    ldr     r9, [r1, #4]
+    ldr     r3, [r1, #8]
+//    ldmia   rINST, {r0-r1}              @ r0/r1<- vAA/vAA+1
+    ldr     r0, [rINST, #0]
+    ldr     r10, [rINST, #4]
+    ldr     r1, [rINST, #8]
+    orr     r10, r9, r10
+    stmfd   sp!, {r10}
+    mul     ip, r2, r1                  @  ip<- ZxW
+    bx      lr
diff --git a/vm/mterp/armv6t2_taint/OP_NEG_DOUBLE.S b/vm/mterp/armv6t2_taint/OP_NEG_DOUBLE.S
new file mode 100644
index 0000000..3f2af4e
--- /dev/null
+++ b/vm/mterp/armv6t2_taint/OP_NEG_DOUBLE.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv6t2_taint/unopWide.S" {"instr":"add     r1, r1, #0x80000000"}
diff --git a/vm/mterp/armv6t2_taint/OP_NEG_FLOAT.S b/vm/mterp/armv6t2_taint/OP_NEG_FLOAT.S
new file mode 100644
index 0000000..55a2f9c
--- /dev/null
+++ b/vm/mterp/armv6t2_taint/OP_NEG_FLOAT.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv6t2_taint/unop.S" {"instr":"add     r0, r0, #0x80000000"}
diff --git a/vm/mterp/armv6t2_taint/OP_NEG_INT.S b/vm/mterp/armv6t2_taint/OP_NEG_INT.S
new file mode 100644
index 0000000..fdaa2b1
--- /dev/null
+++ b/vm/mterp/armv6t2_taint/OP_NEG_INT.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv6t2_taint/unop.S" {"instr":"rsb     r0, r0, #0"}
diff --git a/vm/mterp/armv6t2_taint/OP_NEG_LONG.S b/vm/mterp/armv6t2_taint/OP_NEG_LONG.S
new file mode 100644
index 0000000..5f78487
--- /dev/null
+++ b/vm/mterp/armv6t2_taint/OP_NEG_LONG.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv6t2_taint/unopWide.S" {"preinstr":"rsbs    r0, r0, #0", "instr":"rsc     r1, r1, #0"}
diff --git a/vm/mterp/armv6t2_taint/OP_NOT_INT.S b/vm/mterp/armv6t2_taint/OP_NOT_INT.S
new file mode 100644
index 0000000..1cdf86b
--- /dev/null
+++ b/vm/mterp/armv6t2_taint/OP_NOT_INT.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv6t2_taint/unop.S" {"instr":"mvn     r0, r0"}
diff --git a/vm/mterp/armv6t2_taint/OP_NOT_LONG.S b/vm/mterp/armv6t2_taint/OP_NOT_LONG.S
new file mode 100644
index 0000000..f2400c8
--- /dev/null
+++ b/vm/mterp/armv6t2_taint/OP_NOT_LONG.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv6t2_taint/unopWide.S" {"preinstr":"mvn     r0, r0", "instr":"mvn     r1, r1"}
diff --git a/vm/mterp/armv6t2_taint/OP_OR_INT_2ADDR.S b/vm/mterp/armv6t2_taint/OP_OR_INT_2ADDR.S
new file mode 100644
index 0000000..eef1c59
--- /dev/null
+++ b/vm/mterp/armv6t2_taint/OP_OR_INT_2ADDR.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv6t2_taint/binop2addr.S" {"instr":"orr     r0, r0, r1"}
diff --git a/vm/mterp/armv6t2_taint/OP_OR_INT_LIT16.S b/vm/mterp/armv6t2_taint/OP_OR_INT_LIT16.S
new file mode 100644
index 0000000..3d63930
--- /dev/null
+++ b/vm/mterp/armv6t2_taint/OP_OR_INT_LIT16.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv6t2_taint/binopLit16.S" {"instr":"orr     r0, r0, r1"}
diff --git a/vm/mterp/armv6t2_taint/OP_OR_LONG_2ADDR.S b/vm/mterp/armv6t2_taint/OP_OR_LONG_2ADDR.S
new file mode 100644
index 0000000..3e6080f
--- /dev/null
+++ b/vm/mterp/armv6t2_taint/OP_OR_LONG_2ADDR.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv6t2_taint/binopWide2addr.S" {"preinstr":"orr     r0, r0, r2", "instr":"orr     r1, r1, r3"}
diff --git a/vm/mterp/armv6t2_taint/OP_REM_DOUBLE_2ADDR.S b/vm/mterp/armv6t2_taint/OP_REM_DOUBLE_2ADDR.S
new file mode 100644
index 0000000..ac3cc31
--- /dev/null
+++ b/vm/mterp/armv6t2_taint/OP_REM_DOUBLE_2ADDR.S
@@ -0,0 +1,3 @@
+%verify "executed"
+/* EABI doesn't define a double remainder function, but libm does */
+%include "armv6t2_taint/binopWide2addr.S" {"instr":"bl      fmod"}
diff --git a/vm/mterp/armv6t2_taint/OP_REM_FLOAT_2ADDR.S b/vm/mterp/armv6t2_taint/OP_REM_FLOAT_2ADDR.S
new file mode 100644
index 0000000..ba71069
--- /dev/null
+++ b/vm/mterp/armv6t2_taint/OP_REM_FLOAT_2ADDR.S
@@ -0,0 +1,3 @@
+%verify "executed"
+/* EABI doesn't define a float remainder function, but libm does */
+%include "armv6t2_taint/binop2addr.S" {"instr":"bl      fmodf"}
diff --git a/vm/mterp/armv6t2_taint/OP_REM_INT_2ADDR.S b/vm/mterp/armv6t2_taint/OP_REM_INT_2ADDR.S
new file mode 100644
index 0000000..10f055b
--- /dev/null
+++ b/vm/mterp/armv6t2_taint/OP_REM_INT_2ADDR.S
@@ -0,0 +1,3 @@
+%verify "executed"
+/* idivmod returns quotient in r0 and remainder in r1 */
+%include "armv6t2_taint/binop2addr.S" {"instr":"bl      __aeabi_idivmod", "result":"r1", "chkzero":"1"}
diff --git a/vm/mterp/armv6t2_taint/OP_REM_INT_LIT16.S b/vm/mterp/armv6t2_taint/OP_REM_INT_LIT16.S
new file mode 100644
index 0000000..830f93e
--- /dev/null
+++ b/vm/mterp/armv6t2_taint/OP_REM_INT_LIT16.S
@@ -0,0 +1,3 @@
+%verify "executed"
+/* idivmod returns quotient in r0 and remainder in r1 */
+%include "armv6t2_taint/binopLit16.S" {"instr":"bl      __aeabi_idivmod", "result":"r1", "chkzero":"1"}
diff --git a/vm/mterp/armv6t2_taint/OP_REM_LONG_2ADDR.S b/vm/mterp/armv6t2_taint/OP_REM_LONG_2ADDR.S
new file mode 100644
index 0000000..a509730
--- /dev/null
+++ b/vm/mterp/armv6t2_taint/OP_REM_LONG_2ADDR.S
@@ -0,0 +1,3 @@
+%verify "executed"
+/* ldivmod returns quotient in r0/r1 and remainder in r2/r3 */
+%include "armv6t2_taint/binopWide2addr.S" {"instr":"bl      __aeabi_ldivmod", "result0":"r2", "result1":"r3", "chkzero":"1"}
diff --git a/vm/mterp/armv6t2_taint/OP_RSUB_INT.S b/vm/mterp/armv6t2_taint/OP_RSUB_INT.S
new file mode 100644
index 0000000..9f834cb
--- /dev/null
+++ b/vm/mterp/armv6t2_taint/OP_RSUB_INT.S
@@ -0,0 +1,3 @@
+%verify "executed"
+/* this op is "rsub-int", but can be thought of as "rsub-int/lit16" */
+%include "armv6t2_taint/binopLit16.S" {"instr":"rsb     r0, r0, r1"}
diff --git a/vm/mterp/armv6t2_taint/OP_SHL_INT_2ADDR.S b/vm/mterp/armv6t2_taint/OP_SHL_INT_2ADDR.S
new file mode 100644
index 0000000..eed4d96
--- /dev/null
+++ b/vm/mterp/armv6t2_taint/OP_SHL_INT_2ADDR.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv6t2_taint/binop2addr.S" {"preinstr":"and     r1, r1, #31", "instr":"mov     r0, r0, asl r1"}
diff --git a/vm/mterp/armv6t2_taint/OP_SHL_LONG_2ADDR.S b/vm/mterp/armv6t2_taint/OP_SHL_LONG_2ADDR.S
new file mode 100644
index 0000000..21cbae5
--- /dev/null
+++ b/vm/mterp/armv6t2_taint/OP_SHL_LONG_2ADDR.S
@@ -0,0 +1,45 @@
+%verify "executed"
+    /*
+     * Long integer shift, 2addr version.  vA is 64-bit value/result, vB is
+     * 32-bit shift distance.
+     */
+    /* shl-long/2addr vA, vB */
+    mov     r3, rINST, lsr #12          @ r3<- B
+    ubfx    r9, rINST, #8, #4           @ r9<- A
+    GET_VREG(r2, r3)                    @ r2<- vB
+// begin WITH_TAINT_TRACKING
+    bl      shl_long_2addr_taint_prop
+// end WITH_TAINT_TRACKING
+
+    mov     r1, r1, asl r2              @  r1<- r1 << r2
+    rsb     r3, r2, #32                 @  r3<- 32 - r2
+    orr     r1, r1, r0, lsr r3          @  r1<- r1 | (r0 << (32-r2))
+    subs    ip, r2, #32                 @  ip<- r2 - 32
+    FETCH_ADVANCE_INST(1)               @ advance rPC, load rINST
+    movpl   r1, r0, asl ip              @  if r2 >= 32, r1<- r0 << (r2-32)
+    mov     r0, r0, asl r2              @  r0<- r0 << r2
+    b       .L${opcode}_finish
+%break
+
+.L${opcode}_finish:
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+// begin WITH_TAINT_TRACKING
+//    stmia   r9, {r0-r1}                 @ vAA/vAA+1<- r0/r1
+    str     r0, [r9, #0]
+    str     r10, [r9, #4]
+    str     r1, [r9, #8]
+    str     r10, [r9, #12]
+// end WITH_TAINT_TRACKING
+    GOTO_OPCODE(ip)                     @ jump to next instruction
+
+shl_long_2addr_taint_prop:
+    SET_TAINT_FP(r0)
+    GET_VREG_TAINT(r0, r3, r0)
+    add     r9, rFP, r9, lsl #3         @ r9<- &fp[A]
+    and     r2, r2, #63                 @ r2<- r2 & 0x3f
+//    ldmia   r9, {r0-r1}                 @ r0/r1<- vAA/vAA+1
+    ldr     r10, [r9, #4]
+    orr     r10, r0, r10
+    ldr     r0, [r9, #0]
+    ldr     r1, [r9, #8]
+    bx      lr
diff --git a/vm/mterp/armv6t2_taint/OP_SHR_INT_2ADDR.S b/vm/mterp/armv6t2_taint/OP_SHR_INT_2ADDR.S
new file mode 100644
index 0000000..b3e4517
--- /dev/null
+++ b/vm/mterp/armv6t2_taint/OP_SHR_INT_2ADDR.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv6t2_taint/binop2addr.S" {"preinstr":"and     r1, r1, #31", "instr":"mov     r0, r0, asr r1"}
diff --git a/vm/mterp/armv6t2_taint/OP_SHR_LONG_2ADDR.S b/vm/mterp/armv6t2_taint/OP_SHR_LONG_2ADDR.S
new file mode 100644
index 0000000..e3c9f32
--- /dev/null
+++ b/vm/mterp/armv6t2_taint/OP_SHR_LONG_2ADDR.S
@@ -0,0 +1,46 @@
+%verify "executed"
+    /*
+     * Long integer shift, 2addr version.  vA is 64-bit value/result, vB is
+     * 32-bit shift distance.
+     */
+    /* shr-long/2addr vA, vB */
+    mov     r3, rINST, lsr #12          @ r3<- B
+    ubfx    r9, rINST, #8, #4           @ r9<- A
+    GET_VREG(r2, r3)                    @ r2<- vB
+// begin WITH_TAINT_TRACKING
+    bl      shr_long_2addr_taint_prop
+// end WITH_TAINT_TRACKING
+
+    mov     r0, r0, lsr r2              @  r0<- r2 >> r2
+    rsb     r3, r2, #32                 @  r3<- 32 - r2
+    orr     r0, r0, r1, asl r3          @  r0<- r0 | (r1 << (32-r2))
+    subs    ip, r2, #32                 @  ip<- r2 - 32
+    FETCH_ADVANCE_INST(1)               @ advance rPC, load rINST
+    movpl   r0, r1, asr ip              @  if r2 >= 32, r0<-r1 >> (r2-32)
+    mov     r1, r1, asr r2              @  r1<- r1 >> r2
+    b       .L${opcode}_finish
+%break
+
+.L${opcode}_finish:
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+// begin WITH_TAINT_TRACKING
+//    stmia   r9, {r0-r1}                 @ vAA/vAA+1<- r0/r1
+    str     r0, [r9, #0]
+    str     r10, [r9, #4]
+    str     r1, [r9, #8]
+    str     r10, [r9, #12]
+// end WITH_TAINT_TRACKING
+    GOTO_OPCODE(ip)                     @ jump to next instruction
+
+// OP_SHR_LONG_2ADDR.S
+shr_long_2addr_taint_prop:
+    SET_TAINT_FP(r0)
+    GET_VREG_TAINT(r0, r3, r0)
+    add     r9, rFP, r9, lsl #3         @ r9<- &fp[A]
+    and     r2, r2, #63                 @ r2<- r2 & 0x3f
+//    ldmia   r9, {r0-r1}                 @ r0/r1<- vAA/vAA+1
+    ldr     r10, [r9, #4]
+    orr     r10, r0, r10
+    ldr     r0, [r9, #0]
+    ldr     r1, [r9, #8]
+    bx      lr
diff --git a/vm/mterp/armv6t2_taint/OP_SUB_FLOAT_2ADDR.S b/vm/mterp/armv6t2_taint/OP_SUB_FLOAT_2ADDR.S
new file mode 100644
index 0000000..c785f88
--- /dev/null
+++ b/vm/mterp/armv6t2_taint/OP_SUB_FLOAT_2ADDR.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv6t2_taint/binop2addr.S" {"instr":"bl      __aeabi_fsub"}
diff --git a/vm/mterp/armv6t2_taint/OP_SUB_INT_2ADDR.S b/vm/mterp/armv6t2_taint/OP_SUB_INT_2ADDR.S
new file mode 100644
index 0000000..25446b1
--- /dev/null
+++ b/vm/mterp/armv6t2_taint/OP_SUB_INT_2ADDR.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv6t2_taint/binop2addr.S" {"instr":"sub     r0, r0, r1"}
diff --git a/vm/mterp/armv6t2_taint/OP_SUB_LONG_2ADDR.S b/vm/mterp/armv6t2_taint/OP_SUB_LONG_2ADDR.S
new file mode 100644
index 0000000..6a3aded
--- /dev/null
+++ b/vm/mterp/armv6t2_taint/OP_SUB_LONG_2ADDR.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv6t2_taint/binopWide2addr.S" {"preinstr":"subs    r0, r0, r2", "instr":"sbc     r1, r1, r3"}
diff --git a/vm/mterp/armv6t2_taint/OP_USHR_INT_2ADDR.S b/vm/mterp/armv6t2_taint/OP_USHR_INT_2ADDR.S
new file mode 100644
index 0000000..3ea64bd
--- /dev/null
+++ b/vm/mterp/armv6t2_taint/OP_USHR_INT_2ADDR.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv6t2_taint/binop2addr.S" {"preinstr":"and     r1, r1, #31", "instr":"mov     r0, r0, lsr r1"}
diff --git a/vm/mterp/armv6t2_taint/OP_USHR_LONG_2ADDR.S b/vm/mterp/armv6t2_taint/OP_USHR_LONG_2ADDR.S
new file mode 100644
index 0000000..bbe6e67
--- /dev/null
+++ b/vm/mterp/armv6t2_taint/OP_USHR_LONG_2ADDR.S
@@ -0,0 +1,45 @@
+%verify "executed"
+    /*
+     * Long integer shift, 2addr version.  vA is 64-bit value/result, vB is
+     * 32-bit shift distance.
+     */
+    /* ushr-long/2addr vA, vB */
+    mov     r3, rINST, lsr #12          @ r3<- B
+    ubfx    r9, rINST, #8, #4           @ r9<- A
+    GET_VREG(r2, r3)                    @ r2<- vB
+// begin WITH_TAINT_TRACKING
+    bl      ushr_long_2addr_taint_prop
+// end WITH_TAINT_TRACKING
+
+    mov     r0, r0, lsr r2              @  r0<- r2 >> r2
+    rsb     r3, r2, #32                 @  r3<- 32 - r2
+    orr     r0, r0, r1, asl r3          @  r0<- r0 | (r1 << (32-r2))
+    subs    ip, r2, #32                 @  ip<- r2 - 32
+    FETCH_ADVANCE_INST(1)               @ advance rPC, load rINST
+    movpl   r0, r1, lsr ip              @  if r2 >= 32, r0<-r1 >>> (r2-32)
+    mov     r1, r1, lsr r2              @  r1<- r1 >>> r2
+    b       .L${opcode}_finish
+%break
+
+.L${opcode}_finish:
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+// begin WITH_TAINT_TRACKING
+//    stmia   r9, {r0-r1}                 @ vAA/vAA+1<- r0/r1
+    str     r0, [r9, #0]
+    str     r10, [r9, #4]
+    str     r1, [r9, #8]
+    str     r10, [r9, #12]
+// end WITH_TAINT_TRACKING
+    GOTO_OPCODE(ip)                     @ jump to next instruction
+
+ushr_long_2addr_taint_prop:
+    SET_TAINT_FP(r0)
+    GET_VREG_TAINT(r0, r3, r0)
+    add     r9, rFP, r9, lsl #3         @ r9<- &fp[A]
+    and     r2, r2, #63                 @ r2<- r2 & 0x3f
+//    ldmia   r9, {r0-r1}                 @ r0/r1<- vAA/vAA+1
+    ldr     r10, [r9, #4]
+    orr     r10, r0, r10
+    ldr     r0, [r9, #0]
+    ldr     r1, [r9, #8]
+    bx      lr
diff --git a/vm/mterp/armv6t2_taint/OP_XOR_INT_2ADDR.S b/vm/mterp/armv6t2_taint/OP_XOR_INT_2ADDR.S
new file mode 100644
index 0000000..bfa3726
--- /dev/null
+++ b/vm/mterp/armv6t2_taint/OP_XOR_INT_2ADDR.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv6t2_taint/binop2addr.S" {"instr":"eor     r0, r0, r1"}
diff --git a/vm/mterp/armv6t2_taint/OP_XOR_INT_LIT16.S b/vm/mterp/armv6t2_taint/OP_XOR_INT_LIT16.S
new file mode 100644
index 0000000..7e03925
--- /dev/null
+++ b/vm/mterp/armv6t2_taint/OP_XOR_INT_LIT16.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv6t2_taint/binopLit16.S" {"instr":"eor     r0, r0, r1"}
diff --git a/vm/mterp/armv6t2_taint/OP_XOR_LONG_2ADDR.S b/vm/mterp/armv6t2_taint/OP_XOR_LONG_2ADDR.S
new file mode 100644
index 0000000..8131321
--- /dev/null
+++ b/vm/mterp/armv6t2_taint/OP_XOR_LONG_2ADDR.S
@@ -0,0 +1,2 @@
+%verify "executed"
+%include "armv6t2_taint/binopWide2addr.S" {"preinstr":"eor     r0, r0, r2", "instr":"eor     r1, r1, r3"}
diff --git a/vm/mterp/armv6t2_taint/bincmp.S b/vm/mterp/armv6t2_taint/bincmp.S
new file mode 100644
index 0000000..8d8c48d
--- /dev/null
+++ b/vm/mterp/armv6t2_taint/bincmp.S
@@ -0,0 +1,29 @@
+%verify "branch taken"
+%verify "branch not taken"
+    /*
+     * Generic two-operand compare-and-branch operation.  Provide a "revcmp"
+     * fragment that specifies the *reverse* comparison to perform, e.g.
+     * for "if-le" you would use "gt".
+     *
+     * For: if-eq, if-ne, if-lt, if-ge, if-gt, if-le
+     */
+    /* if-cmp vA, vB, +CCCC */
+    mov     r1, rINST, lsr #12          @ r1<- B
+    ubfx    r0, rINST, #8, #4           @ r0<- A
+    GET_VREG(r3, r1)                    @ r3<- vB
+    GET_VREG(r2, r0)                    @ r2<- vA
+    FETCH_S(r1, 1)                      @ r1<- branch offset, in code units
+    cmp     r2, r3                      @ compare (vA, vB)
+    mov${revcmp} r1, #2                 @ r1<- BYTE branch dist for not-taken
+    adds    r2, r1, r1                  @ convert to bytes, check sign
+    FETCH_ADVANCE_INST_RB(r2)           @ update rPC, load rINST
+#if defined(WITH_JIT)
+    ldr     r0, [rSELF, #offThread_pJitProfTable]
+    ldrmi   rIBASE, [rSELF, #offThread_curHandlerTable]  @ refresh rIBASE
+    cmp     r0, #0
+    bne     common_updateProfile
+#else
+    ldrmi   rIBASE, [rSELF, #offThread_curHandlerTable]  @ refresh rIBASE
+#endif
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+    GOTO_OPCODE(ip)                     @ jump to next instruction
diff --git a/vm/mterp/armv6t2_taint/binop2addr.S b/vm/mterp/armv6t2_taint/binop2addr.S
new file mode 100644
index 0000000..31a7bf9
--- /dev/null
+++ b/vm/mterp/armv6t2_taint/binop2addr.S
@@ -0,0 +1,46 @@
+%default {"preinstr":"", "result":"r0", "chkzero":"0"}
+    /*
+     * Generic 32-bit "/2addr" binary operation.  Provide an "instr" line
+     * that specifies an instruction that performs "result = r0 op r1".
+     * This could be an ARM instruction or a function call.  (If the result
+     * comes back in a register other than r0, you can override "result".)
+     *
+     * If "chkzero" is set to 1, we perform a divide-by-zero check on
+     * vCC (r1).  Useful for integer division and modulus.
+     *
+     * For: add-int/2addr, sub-int/2addr, mul-int/2addr, div-int/2addr,
+     *      rem-int/2addr, and-int/2addr, or-int/2addr, xor-int/2addr,
+     *      shl-int/2addr, shr-int/2addr, ushr-int/2addr, add-float/2addr,
+     *      sub-float/2addr, mul-float/2addr, div-float/2addr, rem-float/2addr
+     */
+    /* binop/2addr vA, vB */
+    mov     r3, rINST, lsr #12          @ r3<- B
+    ubfx    r9, rINST, #8, #4           @ r9<- A
+    GET_VREG(r1, r3)                    @ r1<- vB
+    GET_VREG(r0, r9)                    @ r0<- vA
+    .if $chkzero
+    cmp     r1, #0                      @ is second operand zero?
+    beq     common_errDivideByZero
+    .endif
+
+// begin WITH_TAINT_TRACKING
+    bl      .L${opcode}_taint_prop
+// end WITH_TAINT_TRACKING
+    FETCH_ADVANCE_INST(1)               @ advance rPC, load rINST
+
+    $preinstr                           @ optional op; may set condition codes
+    $instr                              @ $result<- op, r0-r3 changed
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+    SET_VREG($result, r9)               @ vAA<- $result
+    GOTO_OPCODE(ip)                     @ jump to next instruction
+    /* 10-13 instructions */
+
+%break
+
+.L${opcode}_taint_prop:
+    SET_TAINT_FP(r2)
+    GET_VREG_TAINT(r3, r3, r2)
+    GET_VREG_TAINT(r10, r9, r2)
+    orr     r10, r3, r10
+    SET_VREG_TAINT(r10, r9, r2)
+    bx      lr
diff --git a/vm/mterp/armv6t2_taint/binopLit16.S b/vm/mterp/armv6t2_taint/binopLit16.S
new file mode 100644
index 0000000..a16025b
--- /dev/null
+++ b/vm/mterp/armv6t2_taint/binopLit16.S
@@ -0,0 +1,35 @@
+%default {"result":"r0", "chkzero":"0"}
+    /*
+     * Generic 32-bit "lit16" binary operation.  Provide an "instr" line
+     * that specifies an instruction that performs "result = r0 op r1".
+     * This could be an ARM instruction or a function call.  (If the result
+     * comes back in a register other than r0, you can override "result".)
+     *
+     * If "chkzero" is set to 1, we perform a divide-by-zero check on
+     * vCC (r1).  Useful for integer division and modulus.
+     *
+     * For: add-int/lit16, rsub-int, mul-int/lit16, div-int/lit16,
+     *      rem-int/lit16, and-int/lit16, or-int/lit16, xor-int/lit16
+     */
+    /* binop/lit16 vA, vB, #+CCCC */
+    FETCH_S(r1, 1)                      @ r1<- ssssCCCC (sign-extended)
+    mov     r2, rINST, lsr #12          @ r2<- B
+    ubfx    r9, rINST, #8, #4           @ r9<- A
+    GET_VREG(r0, r2)                    @ r0<- vB
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r3)                    @ r3<- rFP+4
+    GET_VREG_TAINT(r2, r2, r3)          @ r2<- vB.taint
+    SET_VREG_TAINT(r2, r9, r3)
+// end WITH_TAINT_TRACKING
+    .if $chkzero
+    cmp     r1, #0                      @ is second operand zero?
+    beq     common_errDivideByZero
+    .endif
+    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
+
+    $instr                              @ $result<- op, r0-r3 changed
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+    SET_VREG($result, r9)               @ vAA<- $result
+    GOTO_OPCODE(ip)                     @ jump to next instruction
+    /* 10-13 instructions */
+
diff --git a/vm/mterp/armv6t2_taint/binopWide2addr.S b/vm/mterp/armv6t2_taint/binopWide2addr.S
new file mode 100644
index 0000000..505c0dc
--- /dev/null
+++ b/vm/mterp/armv6t2_taint/binopWide2addr.S
@@ -0,0 +1,57 @@
+%default {"preinstr":"", "result0":"r0", "result1":"r1", "chkzero":"0"}
+    /*
+     * Generic 64-bit "/2addr" binary operation.  Provide an "instr" line
+     * that specifies an instruction that performs "result = r0-r1 op r2-r3".
+     * This could be an ARM instruction or a function call.  (If the result
+     * comes back in a register other than r0, you can override "result".)
+     *
+     * If "chkzero" is set to 1, we perform a divide-by-zero check on
+     * vCC (r1).  Useful for integer division and modulus.
+     *
+     * For: add-long/2addr, sub-long/2addr, div-long/2addr, rem-long/2addr,
+     *      and-long/2addr, or-long/2addr, xor-long/2addr, add-double/2addr,
+     *      sub-double/2addr, mul-double/2addr, div-double/2addr,
+     *      rem-double/2addr
+     */
+    /* binop/2addr vA, vB */
+    mov     r1, rINST, lsr #12          @ r1<- B
+    ubfx    r9, rINST, #8, #4           @ r9<- A
+// begin WITH_TAINT_TRACKING
+    bl     .L${opcode}_taint_prop
+// end WITH_TAINT_TRACKING
+    .if $chkzero
+    orrs    ip, r2, r3                  @ second arg (r2-r3) is zero?
+    beq     common_errDivideByZero
+    .endif
+    FETCH_ADVANCE_INST(1)               @ advance rPC, load rINST
+
+    $preinstr                           @ optional op; may set condition codes
+    $instr                              @ result<- op, r0-r3 changed
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+// begin WITH_TAINT_TRACKING
+//    stmia   r9, {$result0,$result1}     @ vAA/vAA+1<- $result0/$result1
+    str     $result0, [r9, #0]
+    str     r10, [r9, #4]
+    str     $result1, [r9, #8]
+    str     r10, [r9, #12]
+// end WITH_TAINT_TRACKING
+    GOTO_OPCODE(ip)                     @ jump to next instruction
+    /* 12-15 instructions */
+
+%break
+
+.L${opcode}_taint_prop:
+    add     r1, rFP, r1, lsl #3         @ r1<- &fp[B]
+    add     r9, rFP, r9, lsl #3         @ r9<- &fp[A]
+//    ldmia   r1, {r2-r3}                 @ r2/r3<- vBB/vBB+1
+    ldr     r2, [r1, #0]
+    ldr     r10, [r1, #4]
+    ldr     r3, [r1, #8]
+//    ldmia   r9, {r0-r1}                 @ r0/r1<- vAA/vAA+1
+    ldr     r0, [r9, #0]
+    ldr     r1, [r9, #8]
+    stmfd   sp!, {r9}
+    ldr     r9, [r9, #4]
+    orr     r10, r9, r10
+    ldmfd   sp!, {r9}
+    bx      lr
diff --git a/vm/mterp/armv6t2_taint/unop.S b/vm/mterp/armv6t2_taint/unop.S
new file mode 100644
index 0000000..6b89cf2
--- /dev/null
+++ b/vm/mterp/armv6t2_taint/unop.S
@@ -0,0 +1,25 @@
+%default {"preinstr":""}
+    /*
+     * Generic 32-bit unary operation.  Provide an "instr" line that
+     * specifies an instruction that performs "result = op r0".
+     * This could be an ARM instruction or a function call.
+     *
+     * for: neg-int, not-int, neg-float, int-to-float, float-to-int,
+     *      int-to-byte, int-to-char, int-to-short
+     */
+    /* unop vA, vB */
+    mov     r3, rINST, lsr #12          @ r3<- B
+    ubfx    r9, rINST, #8, #4           @ r9<- A
+    GET_VREG(r0, r3)                    @ r0<- vB
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r1)
+    GET_VREG_TAINT(r2, r3, r1)          @ r2<- vB.taint
+    SET_VREG_TAINT(r2, r9, r1)
+// end WITH_TAINT_TRACKING
+    $preinstr                           @ optional op; may set condition codes
+    FETCH_ADVANCE_INST(1)               @ advance rPC, load rINST
+    $instr                              @ r0<- op, r0-r3 changed
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+    SET_VREG(r0, r9)                    @ vAA<- r0
+    GOTO_OPCODE(ip)                     @ jump to next instruction
+    /* 8-9 instructions */
diff --git a/vm/mterp/armv6t2_taint/unopNarrower.S b/vm/mterp/armv6t2_taint/unopNarrower.S
new file mode 100644
index 0000000..ea02a25
--- /dev/null
+++ b/vm/mterp/armv6t2_taint/unopNarrower.S
@@ -0,0 +1,32 @@
+%default {"preinstr":""}
+    /*
+     * Generic 64bit-to-32bit unary operation.  Provide an "instr" line
+     * that specifies an instruction that performs "result = op r0/r1", where
+     * "result" is a 32-bit quantity in r0.
+     *
+     * For: long-to-float, double-to-int, double-to-float
+     *
+     * (This would work for long-to-int, but that instruction is actually
+     * an exact match for OP_MOVE.)
+     */
+    /* unop vA, vB */
+    mov     r3, rINST, lsr #12          @ r3<- B
+    ubfx    r9, rINST, #8, #4           @ r9<- A
+// begin WITH_TAINT_TRACKING
+    add     r3, rFP, r3, lsl #3         @ r3<- &fp[B]
+//    ldmia   r3, {r0-r1}                 @ r0/r1<- vB/vB+1
+    ldr     r0, [r3, #0]
+    ldr     r10, [r3, #4]
+    ldr     r1, [r3, #8]
+// end WITH_TAINT_TRACKING
+    FETCH_ADVANCE_INST(1)               @ advance rPC, load rINST
+    $preinstr                           @ optional op; may set condition codes
+    $instr                              @ r0<- op, r0-r3 changed
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+// begin WITH_TAINT_TRACKING
+    SET_VREG(r0, r9)                    @ vA<- r0
+    SET_TAINT_FP(r1)
+    SET_VREG_TAINT(r10, r9, r1)
+// end WITH_TAINT_TRACKING
+    GOTO_OPCODE(ip)                     @ jump to next instruction
+    /* 9-10 instructions */
diff --git a/vm/mterp/armv6t2_taint/unopWide.S b/vm/mterp/armv6t2_taint/unopWide.S
new file mode 100644
index 0000000..84dd1af
--- /dev/null
+++ b/vm/mterp/armv6t2_taint/unopWide.S
@@ -0,0 +1,36 @@
+%default {"preinstr":""}
+    /*
+     * Generic 64-bit unary operation.  Provide an "instr" line that
+     * specifies an instruction that performs "result = op r0/r1".
+     * This could be an ARM instruction or a function call.
+     *
+     * For: neg-long, not-long, neg-double, long-to-double, double-to-long
+     */
+    /* unop vA, vB */
+    mov     r3, rINST, lsr #12          @ r3<- B
+    ubfx    r9, rINST, #8, #4           @ r9<- A
+// begin WITH_TAINT_TRACKING
+    add     r3, rFP, r3, lsl #3         @ r3<- &fp[B]
+    add     r9, rFP, r9, lsl #3         @ r9<- &fp[A]
+//    ldmia   r3, {r0-r1}                 @ r0/r1<- vAA
+    ldr     r0, [r3, #0]
+    ldr     r1, [r3, #8]
+    ldr     r10, [r3, #4]
+// end WITH_TAINT_TRACKING
+    FETCH_ADVANCE_INST(1)               @ advance rPC, load rINST
+    $preinstr                           @ optional op; may set condition codes
+    $instr                              @ r0/r1<- op, r2-r3 changed
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+    b       .L${opcode}_finish
+%break
+
+.L${opcode}_finish:
+// begin WITH_TAINT_TRACKING
+//    stmia   r9, {r0-r1}                 @ vAA<- r0/r1
+    str     r0, [r9, #0]
+    str     r10, [r9, #4]
+    str     r1, [r9, #8]
+    str     r10, [r9, #12]
+// end WITH_TAINT_TRACKING
+    GOTO_OPCODE(ip)                     @ jump to next instruction
+    /* 10-11 instructions */
diff --git a/vm/mterp/armv6t2_taint/unopWider.S b/vm/mterp/armv6t2_taint/unopWider.S
new file mode 100644
index 0000000..1faf51a
--- /dev/null
+++ b/vm/mterp/armv6t2_taint/unopWider.S
@@ -0,0 +1,34 @@
+%default {"preinstr":""}
+    /*
+     * Generic 32bit-to-64bit unary operation.  Provide an "instr" line
+     * that specifies an instruction that performs "result = op r0", where
+     * "result" is a 64-bit quantity in r0/r1.
+     *
+     * For: int-to-long, int-to-double, float-to-long, float-to-double
+     */
+    /* unop vA, vB */
+    mov     r3, rINST, lsr #12          @ r3<- B
+    ubfx    r9, rINST, #8, #4           @ r9<- A
+    GET_VREG(r0, r3)                    @ r0<- vB
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r2)
+    GET_VREG_TAINT(r10, r3, r2)
+    add     r9, rFP, r9, lsl #3         @ r9<- &fp[A]
+// end WITH_TAINT_TRACKING
+    $preinstr                           @ optional op; may set condition codes
+    FETCH_ADVANCE_INST(1)               @ advance rPC, load rINST
+    $instr                              @ r0<- op, r0-r3 changed
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+    b      .L${opcode}_finish
+%break
+
+.L${opcode}_finish:
+// begin WITH_TAINT_TRACKING
+//    stmia   r9, {r0-r1}                 @ vA/vA+1<- r0/r1
+    str     r0, [r9, #0]
+    str     r10, [r9, #4]
+    str     r1, [r9, #8]
+    str     r10, [r9, #12]
+// end WITH_TAINT_TRACKING
+    GOTO_OPCODE(ip)                     @ jump to next instruction
+    /* 9-10 instructions */
diff --git a/vm/mterp/c/OP_APUT_OBJECT.cpp b/vm/mterp/c/OP_APUT_OBJECT.cpp
index 9318648..12fb634 100644
--- a/vm/mterp/c/OP_APUT_OBJECT.cpp
+++ b/vm/mterp/c/OP_APUT_OBJECT.cpp
@@ -8,7 +8,7 @@ HANDLE_OPCODE(OP_APUT_OBJECT /*vAA, vBB, vCC*/)
         arrayInfo = FETCH(1);
         vsrc1 = arrayInfo & 0xff;   /* BB: array ptr */
         vsrc2 = arrayInfo >> 8;     /* CC: index */
-        ILOGV("|aput%s v%d,v%d,v%d", "-object", vdst, vsrc1, vsrc2);
+        ALOGV("|aput%s v%d,v%d,v%d", "-object", vdst, vsrc1, vsrc2);
         arrayObj = (ArrayObject*) GET_REGISTER(vsrc1);
         if (!checkForNull((Object*) arrayObj))
             GOTO_exceptionThrown();
@@ -33,6 +33,11 @@ HANDLE_OPCODE(OP_APUT_OBJECT /*vAA, vBB, vCC*/)
         dvmSetObjectArrayElement(arrayObj,
                                  GET_REGISTER(vsrc2),
                                  (Object *)GET_REGISTER(vdst));
+/* ifdef WITH_TAINT_TRACKING */
+	SET_ARRAY_TAINT(arrayObj,
+		(GET_ARRAY_TAINT(arrayObj) |
+		 GET_REGISTER_TAINT(vdst)) );
+/* endif */
     }
     FINISH(2);
 OP_END
diff --git a/vm/mterp/c/OP_ARRAY_LENGTH.cpp b/vm/mterp/c/OP_ARRAY_LENGTH.cpp
index 0d5a933..06f05bb 100644
--- a/vm/mterp/c/OP_ARRAY_LENGTH.cpp
+++ b/vm/mterp/c/OP_ARRAY_LENGTH.cpp
@@ -10,6 +10,9 @@ HANDLE_OPCODE(OP_ARRAY_LENGTH /*vA, vB*/)
             GOTO_exceptionThrown();
         /* verifier guarantees this is an array reference */
         SET_REGISTER(vdst, arrayObj->length);
+/* ifdef WITH_TAINT_TRACKING */
+	SET_REGISTER_TAINT(vdst, TAINT_CLEAR);
+/* endif */
     }
     FINISH(1);
 OP_END
diff --git a/vm/mterp/c/OP_CONST.cpp b/vm/mterp/c/OP_CONST.cpp
index e281a51..af7904e 100644
--- a/vm/mterp/c/OP_CONST.cpp
+++ b/vm/mterp/c/OP_CONST.cpp
@@ -7,6 +7,9 @@ HANDLE_OPCODE(OP_CONST /*vAA, #+BBBBBBBB*/)
         tmp |= (u4)FETCH(2) << 16;
         ILOGV("|const v%d,#0x%08x", vdst, tmp);
         SET_REGISTER(vdst, tmp);
+/* ifdef WITH_TAINT_TRACKING */
+	SET_REGISTER_TAINT(vdst, TAINT_CLEAR);
+/* endif */
     }
     FINISH(3);
 OP_END
diff --git a/vm/mterp/c/OP_CONST_16.cpp b/vm/mterp/c/OP_CONST_16.cpp
index f58f50c..a8c85c2 100644
--- a/vm/mterp/c/OP_CONST_16.cpp
+++ b/vm/mterp/c/OP_CONST_16.cpp
@@ -3,5 +3,8 @@ HANDLE_OPCODE(OP_CONST_16 /*vAA, #+BBBB*/)
     vsrc1 = FETCH(1);
     ILOGV("|const/16 v%d,#0x%04x", vdst, (s2)vsrc1);
     SET_REGISTER(vdst, (s2) vsrc1);
+/* ifdef WITH_TAINT_TRACKING */
+    SET_REGISTER_TAINT(vdst, TAINT_CLEAR);
+/* endif */
     FINISH(2);
 OP_END
diff --git a/vm/mterp/c/OP_CONST_4.cpp b/vm/mterp/c/OP_CONST_4.cpp
index 800ef9a..a5c2630 100644
--- a/vm/mterp/c/OP_CONST_4.cpp
+++ b/vm/mterp/c/OP_CONST_4.cpp
@@ -6,6 +6,9 @@ HANDLE_OPCODE(OP_CONST_4 /*vA, #+B*/)
         tmp = (s4) (INST_B(inst) << 28) >> 28;  // sign extend 4-bit value
         ILOGV("|const/4 v%d,#0x%02x", vdst, (s4)tmp);
         SET_REGISTER(vdst, tmp);
+/* ifdef WITH_TAINT_TRACKING */
+	SET_REGISTER_TAINT(vdst, TAINT_CLEAR);
+/* endif */
     }
     FINISH(1);
 OP_END
diff --git a/vm/mterp/c/OP_CONST_CLASS.cpp b/vm/mterp/c/OP_CONST_CLASS.cpp
index 9c60a27..180afcf 100644
--- a/vm/mterp/c/OP_CONST_CLASS.cpp
+++ b/vm/mterp/c/OP_CONST_CLASS.cpp
@@ -13,6 +13,9 @@ HANDLE_OPCODE(OP_CONST_CLASS /*vAA, class@BBBB*/)
                 GOTO_exceptionThrown();
         }
         SET_REGISTER(vdst, (u4) clazz);
+/* ifdef WITH_TAINT_TRACKING */
+	SET_REGISTER_TAINT(vdst, TAINT_CLEAR);
+/* endif */
     }
     FINISH(2);
 OP_END
diff --git a/vm/mterp/c/OP_CONST_HIGH16.cpp b/vm/mterp/c/OP_CONST_HIGH16.cpp
index 26b22f4..a3e530a 100644
--- a/vm/mterp/c/OP_CONST_HIGH16.cpp
+++ b/vm/mterp/c/OP_CONST_HIGH16.cpp
@@ -3,5 +3,8 @@ HANDLE_OPCODE(OP_CONST_HIGH16 /*vAA, #+BBBB0000*/)
     vsrc1 = FETCH(1);
     ILOGV("|const/high16 v%d,#0x%04x0000", vdst, vsrc1);
     SET_REGISTER(vdst, vsrc1 << 16);
+/* ifdef WITH_TAINT_TRACKING */
+    SET_REGISTER_TAINT(vdst, TAINT_CLEAR);
+/* endif */
     FINISH(2);
 OP_END
diff --git a/vm/mterp/c/OP_CONST_STRING.cpp b/vm/mterp/c/OP_CONST_STRING.cpp
index 748119a..1f5d905 100644
--- a/vm/mterp/c/OP_CONST_STRING.cpp
+++ b/vm/mterp/c/OP_CONST_STRING.cpp
@@ -13,6 +13,9 @@ HANDLE_OPCODE(OP_CONST_STRING /*vAA, string@BBBB*/)
                 GOTO_exceptionThrown();
         }
         SET_REGISTER(vdst, (u4) strObj);
+/* ifdef WITH_TAINT_TRACKING */
+	SET_REGISTER_TAINT(vdst, TAINT_CLEAR);
+/* endif */
     }
     FINISH(2);
 OP_END
diff --git a/vm/mterp/c/OP_CONST_STRING_JUMBO.cpp b/vm/mterp/c/OP_CONST_STRING_JUMBO.cpp
index 435b34c..ac4f87a 100644
--- a/vm/mterp/c/OP_CONST_STRING_JUMBO.cpp
+++ b/vm/mterp/c/OP_CONST_STRING_JUMBO.cpp
@@ -15,6 +15,9 @@ HANDLE_OPCODE(OP_CONST_STRING_JUMBO /*vAA, string@BBBBBBBB*/)
                 GOTO_exceptionThrown();
         }
         SET_REGISTER(vdst, (u4) strObj);
+/* ifdef WITH_TAINT_TRACKING */
+	SET_REGISTER_TAINT(vdst, TAINT_CLEAR);
+/* endif */
     }
     FINISH(3);
 OP_END
diff --git a/vm/mterp/c/OP_CONST_WIDE.cpp b/vm/mterp/c/OP_CONST_WIDE.cpp
index ccb3955..ab0215b 100644
--- a/vm/mterp/c/OP_CONST_WIDE.cpp
+++ b/vm/mterp/c/OP_CONST_WIDE.cpp
@@ -9,6 +9,9 @@ HANDLE_OPCODE(OP_CONST_WIDE /*vAA, #+BBBBBBBBBBBBBBBB*/)
         tmp |= (u8)FETCH(4) << 48;
         ILOGV("|const-wide v%d,#0x%08llx", vdst, tmp);
         SET_REGISTER_WIDE(vdst, tmp);
+/* ifdef WITH_TAINT_TRACKING */
+	SET_REGISTER_TAINT_WIDE(vdst, TAINT_CLEAR);
+/* endif */
     }
     FINISH(5);
 OP_END
diff --git a/vm/mterp/c/OP_CONST_WIDE_16.cpp b/vm/mterp/c/OP_CONST_WIDE_16.cpp
index da69f37..ca5efbf 100644
--- a/vm/mterp/c/OP_CONST_WIDE_16.cpp
+++ b/vm/mterp/c/OP_CONST_WIDE_16.cpp
@@ -3,5 +3,8 @@ HANDLE_OPCODE(OP_CONST_WIDE_16 /*vAA, #+BBBB*/)
     vsrc1 = FETCH(1);
     ILOGV("|const-wide/16 v%d,#0x%04x", vdst, (s2)vsrc1);
     SET_REGISTER_WIDE(vdst, (s2)vsrc1);
+/* ifdef WITH_TAINT_TRACKING */
+    SET_REGISTER_TAINT_WIDE(vdst, TAINT_CLEAR);
+/* endif */
     FINISH(2);
 OP_END
diff --git a/vm/mterp/c/OP_CONST_WIDE_32.cpp b/vm/mterp/c/OP_CONST_WIDE_32.cpp
index ad4acbb..5b27752 100644
--- a/vm/mterp/c/OP_CONST_WIDE_32.cpp
+++ b/vm/mterp/c/OP_CONST_WIDE_32.cpp
@@ -7,6 +7,9 @@ HANDLE_OPCODE(OP_CONST_WIDE_32 /*vAA, #+BBBBBBBB*/)
         tmp |= (u4)FETCH(2) << 16;
         ILOGV("|const-wide/32 v%d,#0x%08x", vdst, tmp);
         SET_REGISTER_WIDE(vdst, (s4) tmp);
+/* ifdef WITH_TAINT_TRACKING */
+	SET_REGISTER_TAINT_WIDE(vdst, TAINT_CLEAR);
+/* endif */
     }
     FINISH(3);
 OP_END
diff --git a/vm/mterp/c/OP_CONST_WIDE_HIGH16.cpp b/vm/mterp/c/OP_CONST_WIDE_HIGH16.cpp
index bcc0664..fcab504 100644
--- a/vm/mterp/c/OP_CONST_WIDE_HIGH16.cpp
+++ b/vm/mterp/c/OP_CONST_WIDE_HIGH16.cpp
@@ -3,5 +3,8 @@ HANDLE_OPCODE(OP_CONST_WIDE_HIGH16 /*vAA, #+BBBB000000000000*/)
     vsrc1 = FETCH(1);
     ILOGV("|const-wide/high16 v%d,#0x%04x000000000000", vdst, vsrc1);
     SET_REGISTER_WIDE(vdst, ((u8) vsrc1) << 48);
+/* ifdef WITH_TAINT_TRACKING */
+    SET_REGISTER_TAINT_WIDE(vdst, TAINT_CLEAR);
+/* endif */
     FINISH(2);
 OP_END
diff --git a/vm/mterp/c/OP_EXECUTE_INLINE.cpp b/vm/mterp/c/OP_EXECUTE_INLINE.cpp
index 8d20764..f0f6e54 100644
--- a/vm/mterp/c/OP_EXECUTE_INLINE.cpp
+++ b/vm/mterp/c/OP_EXECUTE_INLINE.cpp
@@ -19,6 +19,11 @@ HANDLE_OPCODE(OP_EXECUTE_INLINE /*vB, {vD, vE, vF, vG}, inline@CCCC*/)
         u4 arg0, arg1, arg2, arg3;
         arg0 = arg1 = arg2 = arg3 = 0;
 
+#ifdef WITH_TAINT_TRACKING
+	u4 arg0_taint, arg1_taint;
+	arg0_taint = arg1_taint = 0;
+#endif /*WITH_TAINT_TRACKING*/
+
         EXPORT_PC();
 
         vsrc1 = INST_B(inst);       /* #of args */
@@ -39,20 +44,36 @@ HANDLE_OPCODE(OP_EXECUTE_INLINE /*vB, {vD, vE, vF, vG}, inline@CCCC*/)
             /* fall through */
         case 2:
             arg1 = GET_REGISTER((vdst & 0x00f0) >> 4);
+#ifdef WITH_TAINT_TRACKING
+	    arg1_taint = GET_REGISTER_TAINT((vdst & 0x00f0) >> 4);
+#endif /*WITH_TAINT_TRACKING*/
             /* fall through */
         case 1:
             arg0 = GET_REGISTER(vdst & 0x0f);
+#ifdef WITH_TAINT_TRACKING
+            arg0_taint = GET_REGISTER_TAINT(vdst & 0x0f);
+#endif /*WITH_TAINT_TRACKING*/
             /* fall through */
         default:        // case 0
             ;
         }
 
         if (self->interpBreak.ctl.subMode & kSubModeDebuggerActive) {
+#ifdef WITH_TAINT_TRACKING
+            if (!dvmPerformInlineOp4Dbg(arg0, arg1, arg2, arg3, arg0_taint, arg1_taint, &rtaint, &retval, ref))
+                GOTO_exceptionThrown();
+#else
             if (!dvmPerformInlineOp4Dbg(arg0, arg1, arg2, arg3, &retval, ref))
                 GOTO_exceptionThrown();
+#endif /*WITH_TAINT_TRACKING*/
         } else {
+#ifdef WITH_TAINT_TRACKING
+            if (!dvmPerformInlineOp4Std(arg0, arg1, arg2, arg3, arg0_taint, arg1_taint, &rtaint, &retval, ref))
+                GOTO_exceptionThrown();
+#else
             if (!dvmPerformInlineOp4Std(arg0, arg1, arg2, arg3, &retval, ref))
                 GOTO_exceptionThrown();
+#endif /*WITH_TAINT_TRACKING*/
         }
     }
     FINISH(3);
diff --git a/vm/mterp/c/OP_EXECUTE_INLINE_RANGE.cpp b/vm/mterp/c/OP_EXECUTE_INLINE_RANGE.cpp
index 664ada4..3602850 100644
--- a/vm/mterp/c/OP_EXECUTE_INLINE_RANGE.cpp
+++ b/vm/mterp/c/OP_EXECUTE_INLINE_RANGE.cpp
@@ -3,6 +3,11 @@ HANDLE_OPCODE(OP_EXECUTE_INLINE_RANGE /*{vCCCC..v(CCCC+AA-1)}, inline@BBBB*/)
         u4 arg0, arg1, arg2, arg3;
         arg0 = arg1 = arg2 = arg3 = 0;      /* placate gcc */
 
+#ifdef WITH_TAINT_TRACKING
+	u4 arg0_taint, arg1_taint;
+	arg0_taint = arg1_taint = 0;
+#endif /*WITH_TAINT_TRACKING*/
+
         EXPORT_PC();
 
         vsrc1 = INST_AA(inst);      /* #of args */
@@ -23,20 +28,36 @@ HANDLE_OPCODE(OP_EXECUTE_INLINE_RANGE /*{vCCCC..v(CCCC+AA-1)}, inline@BBBB*/)
             /* fall through */
         case 2:
             arg1 = GET_REGISTER(vdst+1);
+#ifdef WITH_TAINT_TRACKING
+	    arg1_taint = GET_REGISTER_TAINT(vdst+1);
+#endif /*WITH_TAINT_TRACKING*/
             /* fall through */
         case 1:
             arg0 = GET_REGISTER(vdst+0);
+#ifdef WITH_TAINT_TRACKING
+            arg0_taint = GET_REGISTER_TAINT(vdst+0);
+#endif /*WITH_TAINT_TRACKING*/
             /* fall through */
         default:        // case 0
             ;
         }
 
         if (self->interpBreak.ctl.subMode & kSubModeDebuggerActive) {
+#ifdef WITH_TAINT_TRACKING
+            if (!dvmPerformInlineOp4Dbg(arg0, arg1, arg2, arg3, arg0_taint, arg1_taint, &rtaint, &retval, ref))
+                GOTO_exceptionThrown();
+#else
             if (!dvmPerformInlineOp4Dbg(arg0, arg1, arg2, arg3, &retval, ref))
                 GOTO_exceptionThrown();
+#endif /*WITH_TAINT_TRACKING*/
         } else {
+#ifdef WITH_TAINT_TRACKING
+            if (!dvmPerformInlineOp4Std(arg0, arg1, arg2, arg3, arg0_taint, arg1_taint, &rtaint, &retval, ref))
+                GOTO_exceptionThrown();
+#else
             if (!dvmPerformInlineOp4Std(arg0, arg1, arg2, arg3, &retval, ref))
                 GOTO_exceptionThrown();
+#endif /*WITH_TAINT_TRACKING*/
         }
     }
     FINISH(3);
diff --git a/vm/mterp/c/OP_INSTANCE_OF.cpp b/vm/mterp/c/OP_INSTANCE_OF.cpp
index 8b8f9d3..8e9e7e5 100644
--- a/vm/mterp/c/OP_INSTANCE_OF.cpp
+++ b/vm/mterp/c/OP_INSTANCE_OF.cpp
@@ -11,6 +11,9 @@ HANDLE_OPCODE(OP_INSTANCE_OF /*vA, vB, class@CCCC*/)
         obj = (Object*)GET_REGISTER(vsrc1);
         if (obj == NULL) {
             SET_REGISTER(vdst, 0);
+/* ifdef WITH_TAINT_TRACKING */
+	    SET_REGISTER_TAINT(vdst, TAINT_CLEAR);
+/* endif */
         } else {
 #if defined(WITH_EXTRA_OBJECT_VALIDATION)
             if (!checkForNullExportPC(obj, fp, pc))
@@ -24,6 +27,9 @@ HANDLE_OPCODE(OP_INSTANCE_OF /*vA, vB, class@CCCC*/)
                     GOTO_exceptionThrown();
             }
             SET_REGISTER(vdst, dvmInstanceof(obj->clazz, clazz));
+/* ifdef WITH_TAINT_TRACKING */
+	    SET_REGISTER_TAINT(vdst, TAINT_CLEAR);
+/* endif */
         }
     }
     FINISH(2);
diff --git a/vm/mterp/c/OP_MOVE.cpp b/vm/mterp/c/OP_MOVE.cpp
index 6666199..8d93d43 100644
--- a/vm/mterp/c/OP_MOVE.cpp
+++ b/vm/mterp/c/OP_MOVE.cpp
@@ -5,5 +5,8 @@ HANDLE_OPCODE($opcode /*vA, vB*/)
         (INST_INST(inst) == OP_MOVE) ? "" : "-object", vdst, vsrc1,
         kSpacing, vdst, GET_REGISTER(vsrc1));
     SET_REGISTER(vdst, GET_REGISTER(vsrc1));
+/* ifdef WITH_TAINT_TRACKING */
+    SET_REGISTER_TAINT(vdst, GET_REGISTER_TAINT(vsrc1));
+/* endif */
     FINISH(1);
 OP_END
diff --git a/vm/mterp/c/OP_MOVE_16.cpp b/vm/mterp/c/OP_MOVE_16.cpp
index 53af5d5..97fc0e9 100644
--- a/vm/mterp/c/OP_MOVE_16.cpp
+++ b/vm/mterp/c/OP_MOVE_16.cpp
@@ -5,5 +5,8 @@ HANDLE_OPCODE($opcode /*vAAAA, vBBBB*/)
         (INST_INST(inst) == OP_MOVE_16) ? "" : "-object", vdst, vsrc1,
         kSpacing, vdst, GET_REGISTER(vsrc1));
     SET_REGISTER(vdst, GET_REGISTER(vsrc1));
+/* ifdef WITH_TAINT_TRACKING */
+    SET_REGISTER_TAINT(vdst, GET_REGISTER_TAINT(vsrc1));
+/* endif */
     FINISH(3);
 OP_END
diff --git a/vm/mterp/c/OP_MOVE_EXCEPTION.cpp b/vm/mterp/c/OP_MOVE_EXCEPTION.cpp
index 86587ca..776f618 100644
--- a/vm/mterp/c/OP_MOVE_EXCEPTION.cpp
+++ b/vm/mterp/c/OP_MOVE_EXCEPTION.cpp
@@ -3,6 +3,9 @@ HANDLE_OPCODE(OP_MOVE_EXCEPTION /*vAA*/)
     ILOGV("|move-exception v%d", vdst);
     assert(self->exception != NULL);
     SET_REGISTER(vdst, (u4)self->exception);
+/* ifdef WITH_TAINT_TRACKING */
+    SET_REGISTER_TAINT(vdst, TAINT_CLEAR);
+/* endif */
     dvmClearException(self);
     FINISH(1);
 OP_END
diff --git a/vm/mterp/c/OP_MOVE_FROM16.cpp b/vm/mterp/c/OP_MOVE_FROM16.cpp
index 59fc285..296f865 100644
--- a/vm/mterp/c/OP_MOVE_FROM16.cpp
+++ b/vm/mterp/c/OP_MOVE_FROM16.cpp
@@ -5,5 +5,8 @@ HANDLE_OPCODE($opcode /*vAA, vBBBB*/)
         (INST_INST(inst) == OP_MOVE_FROM16) ? "" : "-object", vdst, vsrc1,
         kSpacing, vdst, GET_REGISTER(vsrc1));
     SET_REGISTER(vdst, GET_REGISTER(vsrc1));
+/* ifdef WITH_TAINT_TRACKING */
+    SET_REGISTER_TAINT(vdst, GET_REGISTER_TAINT(vsrc1));
+/* endif */
     FINISH(2);
 OP_END
diff --git a/vm/mterp/c/OP_MOVE_RESULT.cpp b/vm/mterp/c/OP_MOVE_RESULT.cpp
index ddf535b..9d49287 100644
--- a/vm/mterp/c/OP_MOVE_RESULT.cpp
+++ b/vm/mterp/c/OP_MOVE_RESULT.cpp
@@ -4,5 +4,8 @@ HANDLE_OPCODE($opcode /*vAA*/)
          (INST_INST(inst) == OP_MOVE_RESULT) ? "" : "-object",
          vdst, kSpacing+4, vdst,retval.i);
     SET_REGISTER(vdst, retval.i);
+/* ifdef WITH_TAINT_TRACKING */
+    SET_REGISTER_TAINT(vdst, GET_RETURN_TAINT());
+/* endif */
     FINISH(1);
 OP_END
diff --git a/vm/mterp/c/OP_MOVE_RESULT_WIDE.cpp b/vm/mterp/c/OP_MOVE_RESULT_WIDE.cpp
index f6ec8d9..0f488d4 100644
--- a/vm/mterp/c/OP_MOVE_RESULT_WIDE.cpp
+++ b/vm/mterp/c/OP_MOVE_RESULT_WIDE.cpp
@@ -2,5 +2,8 @@ HANDLE_OPCODE(OP_MOVE_RESULT_WIDE /*vAA*/)
     vdst = INST_AA(inst);
     ILOGV("|move-result-wide v%d %s(0x%08llx)", vdst, kSpacing, retval.j);
     SET_REGISTER_WIDE(vdst, retval.j);
+/* ifdef WITH_TAINT_TRACKING */
+    SET_REGISTER_TAINT_WIDE(vdst, GET_RETURN_TAINT());
+/* endif */
     FINISH(1);
 OP_END
diff --git a/vm/mterp/c/OP_MOVE_WIDE.cpp b/vm/mterp/c/OP_MOVE_WIDE.cpp
index 9ee323d..ace1812 100644
--- a/vm/mterp/c/OP_MOVE_WIDE.cpp
+++ b/vm/mterp/c/OP_MOVE_WIDE.cpp
@@ -6,5 +6,8 @@ HANDLE_OPCODE(OP_MOVE_WIDE /*vA, vB*/)
     ILOGV("|move-wide v%d,v%d %s(v%d=0x%08llx)", vdst, vsrc1,
         kSpacing+5, vdst, GET_REGISTER_WIDE(vsrc1));
     SET_REGISTER_WIDE(vdst, GET_REGISTER_WIDE(vsrc1));
+/* ifdef WITH_TAINT_TRACKING */
+    SET_REGISTER_TAINT_WIDE(vdst, GET_REGISTER_TAINT_WIDE(vsrc1));
+/* endif */
     FINISH(1);
 OP_END
diff --git a/vm/mterp/c/OP_MOVE_WIDE_16.cpp b/vm/mterp/c/OP_MOVE_WIDE_16.cpp
index e3d0e16..361de26 100644
--- a/vm/mterp/c/OP_MOVE_WIDE_16.cpp
+++ b/vm/mterp/c/OP_MOVE_WIDE_16.cpp
@@ -4,5 +4,8 @@ HANDLE_OPCODE(OP_MOVE_WIDE_16 /*vAAAA, vBBBB*/)
     ILOGV("|move-wide/16 v%d,v%d %s(v%d=0x%08llx)", vdst, vsrc1,
         kSpacing+8, vdst, GET_REGISTER_WIDE(vsrc1));
     SET_REGISTER_WIDE(vdst, GET_REGISTER_WIDE(vsrc1));
+/* ifdef WITH_TAINT_TRACKING */
+    SET_REGISTER_TAINT_WIDE(vdst, GET_REGISTER_TAINT_WIDE(vsrc1));
+/* endif */
     FINISH(3);
 OP_END
diff --git a/vm/mterp/c/OP_MOVE_WIDE_FROM16.cpp b/vm/mterp/c/OP_MOVE_WIDE_FROM16.cpp
index cdbaa2e..a7190fc 100644
--- a/vm/mterp/c/OP_MOVE_WIDE_FROM16.cpp
+++ b/vm/mterp/c/OP_MOVE_WIDE_FROM16.cpp
@@ -4,5 +4,8 @@ HANDLE_OPCODE(OP_MOVE_WIDE_FROM16 /*vAA, vBBBB*/)
     ILOGV("|move-wide/from16 v%d,v%d  (v%d=0x%08llx)", vdst, vsrc1,
         vdst, GET_REGISTER_WIDE(vsrc1));
     SET_REGISTER_WIDE(vdst, GET_REGISTER_WIDE(vsrc1));
+/* ifdef WITH_TAINT_TRACKING */
+    SET_REGISTER_TAINT_WIDE(vdst, GET_REGISTER_TAINT_WIDE(vsrc1));
+/* endif */
     FINISH(2);
 OP_END
diff --git a/vm/mterp/c/OP_NEW_ARRAY.cpp b/vm/mterp/c/OP_NEW_ARRAY.cpp
index 6d6771a..f6f2a6b 100644
--- a/vm/mterp/c/OP_NEW_ARRAY.cpp
+++ b/vm/mterp/c/OP_NEW_ARRAY.cpp
@@ -30,6 +30,9 @@ HANDLE_OPCODE(OP_NEW_ARRAY /*vA, vB, class@CCCC*/)
         if (newArray == NULL)
             GOTO_exceptionThrown();
         SET_REGISTER(vdst, (u4) newArray);
+/* ifdef WITH_TAINT_TRACKING */
+        SET_REGISTER_TAINT(vdst, TAINT_CLEAR);
+/* endif */
     }
     FINISH(2);
 OP_END
diff --git a/vm/mterp/c/OP_NEW_INSTANCE.cpp b/vm/mterp/c/OP_NEW_INSTANCE.cpp
index b0b9c18..d201670 100644
--- a/vm/mterp/c/OP_NEW_INSTANCE.cpp
+++ b/vm/mterp/c/OP_NEW_INSTANCE.cpp
@@ -43,6 +43,9 @@ HANDLE_OPCODE(OP_NEW_INSTANCE /*vAA, class@BBBB*/)
         if (newObj == NULL)
             GOTO_exceptionThrown();
         SET_REGISTER(vdst, (u4) newObj);
+/* ifdef WITH_TAINT_TRACKING */
+        SET_REGISTER_TAINT(vdst, TAINT_CLEAR);
+/* endif */
     }
     FINISH(2);
 OP_END
diff --git a/vm/mterp/c/OP_REM_DOUBLE.cpp b/vm/mterp/c/OP_REM_DOUBLE.cpp
index 343e25e..62d5350 100644
--- a/vm/mterp/c/OP_REM_DOUBLE.cpp
+++ b/vm/mterp/c/OP_REM_DOUBLE.cpp
@@ -8,6 +8,10 @@ HANDLE_OPCODE(OP_REM_DOUBLE /*vAA, vBB, vCC*/)
         ILOGV("|%s-double v%d,v%d,v%d", "mod", vdst, vsrc1, vsrc2);
         SET_REGISTER_DOUBLE(vdst,
             fmod(GET_REGISTER_DOUBLE(vsrc1), GET_REGISTER_DOUBLE(vsrc2)));
+/* ifdef WITH_TAINT_TRACKING */
+        SET_REGISTER_TAINT_DOUBLE(vdst,
+	    (GET_REGISTER_TAINT_DOUBLE(vsrc1)|GET_REGISTER_TAINT_DOUBLE(vsrc2)));
+/* endif */
     }
     FINISH(2);
 OP_END
diff --git a/vm/mterp/c/OP_REM_DOUBLE_2ADDR.cpp b/vm/mterp/c/OP_REM_DOUBLE_2ADDR.cpp
index 392eacf..2ca5f1c 100644
--- a/vm/mterp/c/OP_REM_DOUBLE_2ADDR.cpp
+++ b/vm/mterp/c/OP_REM_DOUBLE_2ADDR.cpp
@@ -4,5 +4,9 @@ HANDLE_OPCODE(OP_REM_DOUBLE_2ADDR /*vA, vB*/)
     ILOGV("|%s-double-2addr v%d,v%d", "mod", vdst, vsrc1);
     SET_REGISTER_DOUBLE(vdst,
         fmod(GET_REGISTER_DOUBLE(vdst), GET_REGISTER_DOUBLE(vsrc1)));
+/* ifdef WITH_TAINT_TRACKING */
+        SET_REGISTER_TAINT_DOUBLE(vdst,
+	    (GET_REGISTER_TAINT_DOUBLE(vdst)|GET_REGISTER_TAINT_DOUBLE(vsrc1)));
+/* endif */
     FINISH(1);
 OP_END
diff --git a/vm/mterp/c/OP_REM_FLOAT.cpp b/vm/mterp/c/OP_REM_FLOAT.cpp
index 9604b30..34999e7 100644
--- a/vm/mterp/c/OP_REM_FLOAT.cpp
+++ b/vm/mterp/c/OP_REM_FLOAT.cpp
@@ -8,6 +8,12 @@ HANDLE_OPCODE(OP_REM_FLOAT /*vAA, vBB, vCC*/)
         ILOGV("|%s-float v%d,v%d,v%d", "mod", vdst, vsrc1, vsrc2);
         SET_REGISTER_FLOAT(vdst,
             fmodf(GET_REGISTER_FLOAT(vsrc1), GET_REGISTER_FLOAT(vsrc2)));
+/* ifdef WITH_TAINT_TRACKING */
+#ifdef WITH_TAINT_TRACKING
+        SET_REGISTER_TAINT_FLOAT(vdst,
+	    (GET_REGISTER_TAINT_FLOAT(vsrc1)|GET_REGISTER_TAINT_FLOAT(vsrc2)));
+#endif /*WITH_TAINT_TRACKING*/
+/* endif */
     }
     FINISH(2);
 OP_END
diff --git a/vm/mterp/c/OP_REM_FLOAT_2ADDR.cpp b/vm/mterp/c/OP_REM_FLOAT_2ADDR.cpp
index 87bb31e..3e7fb41 100644
--- a/vm/mterp/c/OP_REM_FLOAT_2ADDR.cpp
+++ b/vm/mterp/c/OP_REM_FLOAT_2ADDR.cpp
@@ -4,5 +4,11 @@ HANDLE_OPCODE(OP_REM_FLOAT_2ADDR /*vA, vB*/)
     ILOGV("|%s-float-2addr v%d,v%d", "mod", vdst, vsrc1);
     SET_REGISTER_FLOAT(vdst,
         fmodf(GET_REGISTER_FLOAT(vdst), GET_REGISTER_FLOAT(vsrc1)));
+/* ifdef WITH_TAINT_TRACKING */
+#ifdef WITH_TAINT_TRACKING
+        SET_REGISTER_TAINT_FLOAT(vdst,
+	    (GET_REGISTER_TAINT_FLOAT(vdst)|GET_REGISTER_TAINT_FLOAT(vsrc1)));
+#endif /*WITH_TAINT_TRACKING*/
+/* endif */
     FINISH(1);
 OP_END
diff --git a/vm/mterp/c/OP_RETURN.cpp b/vm/mterp/c/OP_RETURN.cpp
index 89d3b3b..dbad4c1 100644
--- a/vm/mterp/c/OP_RETURN.cpp
+++ b/vm/mterp/c/OP_RETURN.cpp
@@ -3,5 +3,8 @@ HANDLE_OPCODE($opcode /*vAA*/)
     ILOGV("|return%s v%d",
         (INST_INST(inst) == OP_RETURN) ? "" : "-object", vsrc1);
     retval.i = GET_REGISTER(vsrc1);
+/* ifdef WITH_TAINT_TRACKING */
+    SET_RETURN_TAINT(GET_REGISTER_TAINT(vsrc1));
+/* endif */
     GOTO_returnFromMethod();
 OP_END
diff --git a/vm/mterp/c/OP_RETURN_VOID.cpp b/vm/mterp/c/OP_RETURN_VOID.cpp
index 7431f60..4323fa1 100644
--- a/vm/mterp/c/OP_RETURN_VOID.cpp
+++ b/vm/mterp/c/OP_RETURN_VOID.cpp
@@ -3,5 +3,8 @@ HANDLE_OPCODE(OP_RETURN_VOID /**/)
 #ifndef NDEBUG
     retval.j = 0xababababULL;    // placate valgrind
 #endif
+/* ifdef WITH_TAINT_TRACKING */
+    SET_RETURN_TAINT(TAINT_CLEAR);
+/* endif */
     GOTO_returnFromMethod();
 OP_END
diff --git a/vm/mterp/c/OP_RETURN_VOID_BARRIER.cpp b/vm/mterp/c/OP_RETURN_VOID_BARRIER.cpp
index 312402e..ed78ba1 100644
--- a/vm/mterp/c/OP_RETURN_VOID_BARRIER.cpp
+++ b/vm/mterp/c/OP_RETURN_VOID_BARRIER.cpp
@@ -3,6 +3,9 @@ HANDLE_OPCODE(OP_RETURN_VOID_BARRIER /**/)
 #ifndef NDEBUG
     retval.j = 0xababababULL;   /* placate valgrind */
 #endif
+/* ifdef WITH_TAINT_TRACKING */
+    SET_RETURN_TAINT(TAINT_CLEAR);
+/* endif */
     ANDROID_MEMBAR_STORE();
     GOTO_returnFromMethod();
 OP_END
diff --git a/vm/mterp/c/OP_RETURN_WIDE.cpp b/vm/mterp/c/OP_RETURN_WIDE.cpp
index a27bfd4..acc53a1 100644
--- a/vm/mterp/c/OP_RETURN_WIDE.cpp
+++ b/vm/mterp/c/OP_RETURN_WIDE.cpp
@@ -2,5 +2,8 @@ HANDLE_OPCODE(OP_RETURN_WIDE /*vAA*/)
     vsrc1 = INST_AA(inst);
     ILOGV("|return-wide v%d", vsrc1);
     retval.j = GET_REGISTER_WIDE(vsrc1);
+/* ifdef WITH_TAINT_TRACKING */
+    SET_RETURN_TAINT(GET_REGISTER_TAINT_WIDE(vsrc1));
+/* endif */
     GOTO_returnFromMethod();
 OP_END
diff --git a/vm/mterp/c/OP_RSUB_INT.cpp b/vm/mterp/c/OP_RSUB_INT.cpp
index 336ca55..3cf5e9d 100644
--- a/vm/mterp/c/OP_RSUB_INT.cpp
+++ b/vm/mterp/c/OP_RSUB_INT.cpp
@@ -5,6 +5,9 @@ HANDLE_OPCODE(OP_RSUB_INT /*vA, vB, #+CCCC*/)
         vsrc2 = FETCH(1);
         ILOGV("|rsub-int v%d,v%d,#+0x%04x", vdst, vsrc1, vsrc2);
         SET_REGISTER(vdst, (s2) vsrc2 - (s4) GET_REGISTER(vsrc1));
+/* ifdef WITH_TAINT_TRACKING */
+        SET_REGISTER_TAINT(vdst, GET_REGISTER_TAINT(vsrc1));
+/* endif */
     }
     FINISH(2);
 OP_END
diff --git a/vm/mterp/c/OP_RSUB_INT_LIT8.cpp b/vm/mterp/c/OP_RSUB_INT_LIT8.cpp
index 742854b..25d77a5 100644
--- a/vm/mterp/c/OP_RSUB_INT_LIT8.cpp
+++ b/vm/mterp/c/OP_RSUB_INT_LIT8.cpp
@@ -7,6 +7,9 @@ HANDLE_OPCODE(OP_RSUB_INT_LIT8 /*vAA, vBB, #+CC*/)
         vsrc2 = litInfo >> 8;
         ILOGV("|%s-int/lit8 v%d,v%d,#+0x%02x", "rsub", vdst, vsrc1, vsrc2);
         SET_REGISTER(vdst, (s1) vsrc2 - (s4) GET_REGISTER(vsrc1));
+/* ifdef WITH_TAINT_TRACKING */
+        SET_REGISTER_TAINT(vdst, GET_REGISTER_TAINT(vsrc1));
+/* endif */
     }
     FINISH(2);
 OP_END
diff --git a/vm/mterp/c/gotoTargets.cpp b/vm/mterp/c/gotoTargets.cpp
index 2c05038..8916f93 100644
--- a/vm/mterp/c/gotoTargets.cpp
+++ b/vm/mterp/c/gotoTargets.cpp
@@ -98,6 +98,9 @@ GOTO_TARGET(filledNewArray, bool methodCallRange, bool)
         }
 
         retval.l = (Object*)newArray;
+/* ifdef WITH_TAINT_TRACKING */
+        SET_RETURN_TAINT(TAINT_CLEAR);
+/* endif */
     }
     FINISH(3);
 GOTO_TARGET_END
@@ -767,6 +770,9 @@ GOTO_TARGET(invokeMethod, bool methodCallRange, const Method* _methodToCall,
 
         u4* outs;
         int i;
+#ifdef WITH_TAINT_TRACKING
+        bool nativeTarget = dvmIsNativeMethod(methodToCall);
+#endif
 
         /*
          * Copy args.  This may corrupt vsrc1/vdst.
@@ -777,8 +783,31 @@ GOTO_TARGET(invokeMethod, bool methodCallRange, const Method* _methodToCall,
             assert(vsrc1 <= curMethod->outsSize);
             assert(vsrc1 == methodToCall->insSize);
             outs = OUTS_FROM_FP(fp, vsrc1);
+#ifdef WITH_TAINT_TRACKING
+            if (nativeTarget) {
+            	for (i = 0; i < vsrc1; i++) {
+            		outs[i] = GET_REGISTER(vdst+i);
+            	}
+            	/* clear return taint (vsrc1 is the count) */
+            	outs[vsrc1] = TAINT_CLEAR;
+            	/* copy the taint tags (vsrc1 is the count) */
+            	for (i = 0; i < vsrc1; i++) {
+            		outs[vsrc1+1+i] = GET_REGISTER_TAINT(vdst+i);
+            	}
+            } else {
+            	int slot = 0;
+            	for (i = 0; i < vsrc1; i++) {
+            		slot = i << 1;
+            		outs[slot] = GET_REGISTER(vdst+i);
+            		outs[slot+1] = GET_REGISTER_TAINT(vdst+i);
+            	}
+            	/* clear native hack (vsrc1 is the count)*/
+            	outs[vsrc1<<1] = TAINT_CLEAR;
+            }
+#else
             for (i = 0; i < vsrc1; i++)
                 outs[i] = GET_REGISTER(vdst+i);
+#endif
         } else {
             u4 count = vsrc1 >> 4;
 
@@ -800,6 +829,53 @@ GOTO_TARGET(invokeMethod, bool methodCallRange, const Method* _methodToCall,
             // This version executes fewer instructions but is larger
             // overall.  Seems to be a teensy bit faster.
             assert((vdst >> 16) == 0);  // 16 bits -or- high 16 bits clear
+#ifdef WITH_TAINT_TRACKING
+            if (nativeTarget) {
+            	switch (count) {
+            	case 5:
+            		outs[4] = GET_REGISTER(vsrc1 & 0x0f);
+            		outs[count+5] = GET_REGISTER_TAINT(vsrc1 & 0x0f);
+            	case 4:
+            		outs[3] = GET_REGISTER(vdst >> 12);
+            		outs[count+4] = GET_REGISTER_TAINT(vdst >> 12);
+            	case 3:
+            		outs[2] = GET_REGISTER((vdst & 0x0f00) >> 8);
+            		outs[count+3] = GET_REGISTER_TAINT((vdst & 0x0f00) >> 8);
+            	case 2:
+            		outs[1] = GET_REGISTER((vdst & 0x00f0) >> 4);
+            		outs[count+2] = GET_REGISTER_TAINT((vdst & 0x00f0) >> 4);
+            	case 1:
+            		outs[0] = GET_REGISTER(vdst & 0x0f);
+            		outs[count+1] = GET_REGISTER_TAINT(vdst & 0x0f);
+            	default:
+            		;
+            	}
+            	/* clear the native hack */
+            	outs[count] = TAINT_CLEAR;
+            } else { /* interpreted target */
+            	switch (count) {
+            	case 5:
+            		outs[8] = GET_REGISTER(vsrc1 & 0x0f);
+            		outs[9] = GET_REGISTER_TAINT(vsrc1 & 0x0f);
+            	case 4:
+            		outs[6] = GET_REGISTER(vdst >> 12);
+            		outs[7] = GET_REGISTER_TAINT(vdst >> 12);
+            	case 3:
+            		outs[4] = GET_REGISTER((vdst & 0x0f00) >> 8);
+            		outs[5] = GET_REGISTER_TAINT((vdst & 0x0f00) >> 8);
+            	case 2:
+            		outs[2] = GET_REGISTER((vdst & 0x00f0) >> 4);
+            		outs[3] = GET_REGISTER_TAINT((vdst & 0x00f0) >> 4);
+            	case 1:
+            		outs[0] = GET_REGISTER(vdst & 0x0f);
+            		outs[1] = GET_REGISTER_TAINT(vdst & 0x0f);
+           	default:
+            		;
+              	}
+            	/* clear the native hack */
+            	outs[count<<1] = TAINT_CLEAR;
+            }
+#else /* ndef WITH_TAINT_TRACKING */
             switch (count) {
             case 5:
                 outs[4] = GET_REGISTER(vsrc1 & 0x0f);
@@ -814,6 +890,7 @@ GOTO_TARGET(invokeMethod, bool methodCallRange, const Method* _methodToCall,
             default:
                 ;
             }
+#endif /* WITH_TAINT_TRACKING */
 #endif
         }
     }
@@ -835,13 +912,23 @@ GOTO_TARGET(invokeMethod, bool methodCallRange, const Method* _methodToCall,
             methodToCall->clazz->descriptor, methodToCall->name,
             methodToCall->shorty);
 
+#ifdef WITH_TAINT_TRACKING
+        newFp = (u4*) SAVEAREA_FROM_FP(fp) -
+	    ((methodToCall->registersSize << 1) + 1);
+#else
         newFp = (u4*) SAVEAREA_FROM_FP(fp) - methodToCall->registersSize;
+#endif
         newSaveArea = SAVEAREA_FROM_FP(newFp);
 
         /* verify that we have enough space */
         if (true) {
             u1* bottom;
+#ifdef WITH_TAINT_TRACKING
+            bottom = (u1*) newSaveArea -
+            		(methodToCall->outsSize * sizeof(u4) + 4);
+#else
             bottom = (u1*) newSaveArea - methodToCall->outsSize * sizeof(u4);
+#endif
             if (bottom < self->interpStackEnd) {
                 /* stack overflow */
                 ALOGV("Stack overflow on method call (start=%p end=%p newBot=%p(%d) size=%d '%s')",
@@ -864,8 +951,15 @@ GOTO_TARGET(invokeMethod, bool methodCallRange, const Method* _methodToCall,
              * messages are disabled -- we want valgrind to report any
              * used-before-initialized issues.
              */
+#ifdef WITH_TAINT_TRACKING
+	    /* Don't need to worry about native target, because if
+	     * native target, registerSize = insSize */
+            memset(newFp, 0xcc,
+                (methodToCall->registersSize - methodToCall->insSize) * 8);
+#else
             memset(newFp, 0xcc,
                 (methodToCall->registersSize - methodToCall->insSize) * 4);
+#endif
         }
 #endif
 
@@ -930,6 +1024,16 @@ GOTO_TARGET(invokeMethod, bool methodCallRange, const Method* _methodToCall,
              */
             (*methodToCall->nativeFunc)(newFp, &retval, methodToCall, self);
 
+#ifdef WITH_TAINT_TRACKING
+            /* Get the return taint if available */
+            {
+            	/* use same logic as above to calculate count */
+            	u4 count = (methodCallRange) ? vsrc1 : vsrc1 >> 4;
+            	u4* outs = OUTS_FROM_FP(fp, count);
+            	SET_RETURN_TAINT(outs[count]);
+            }
+#endif
+
             if (self->interpBreak.ctl.subMode != 0) {
                 dvmReportPostNativeInvoke(methodToCall, self, fp);
             }
diff --git a/vm/mterp/c/header.cpp b/vm/mterp/c/header.cpp
index d0e55f5..e720919 100644
--- a/vm/mterp/c/header.cpp
+++ b/vm/mterp/c/header.cpp
@@ -136,6 +136,31 @@ static const char kSpacing[] = "            ";
 # define DUMP_REGS(_meth, _frame, _inOnly) ((void)0)
 #endif
 
+/*
+ * If enabled, log taint propagation
+ */
+#ifdef WITH_TAINT_TRACKING
+# define TLOGD(...) TLOG(LOG_DEBUG, __VA_ARGS__)
+# define TLOGV(...) TLOG(LOG_VERBOSE, __VA_ARGS__)
+# define TLOGW(...) TLOG(LOG_WARN, __VA_ARGS__)
+# define TLOGE(...) TLOG(LOG_ERROR, __VA_ARGS__)
+# define TLOG(_level, ...) do {                                             \
+        char debugStrBuf[128];                                              \
+        snprintf(debugStrBuf, sizeof(debugStrBuf), __VA_ARGS__);            \
+        if (curMethod != NULL)                                              \
+            ALOG(_level, LOG_TAG"t", "%-2d|%04x|%s.%s:%s\n",                \
+                self->threadId, (int)(pc - curMethod->insns), curMethod->clazz->descriptor, curMethod->name, debugStrBuf); \
+        else                                                                \
+            ALOG(_level, LOG_TAG"t", "%-2d|####%s\n",                       \
+                self->threadId, debugStrBuf);                               \
+    } while(false)
+#else
+# define TLOGD(...) ((void)0)
+# define TLOGV(...) ((void)0)
+# define TLOGW(...) ((void)0)
+# define TLOGE(...) ((void)0)
+#endif
+
 /* get a long from an array of u4 */
 static inline s8 getLongFromArray(const u4* ptr, int idx)
 {
@@ -153,6 +178,20 @@ static inline s8 getLongFromArray(const u4* ptr, int idx)
 #endif
 }
 
+#ifdef WITH_TAINT_TRACKING
+/* get a long from an array of u4 */
+static inline s8 getLongFromArrayTaint(const u4* ptr, int idx)
+{
+    /* Need to use the "union" version for taint tracking */
+    union { s8 ll; u4 parts[2]; } conv;
+
+    ptr += idx;
+    conv.parts[0] = ptr[0];
+    conv.parts[1] = ptr[2];
+    return conv.ll;
+}
+#endif
+
 /* store a long into an array of u4 */
 static inline void putLongToArray(u4* ptr, int idx, s8 val)
 {
@@ -168,6 +207,20 @@ static inline void putLongToArray(u4* ptr, int idx, s8 val)
 #endif
 }
 
+#ifdef WITH_TAINT_TRACKING
+/* store a long into an array of u4 */
+static inline void putLongToArrayTaint(u4* ptr, int idx, s8 val)
+{
+    /* Need to use the "union" version for taint tracking */
+    union { s8 ll; u4 parts[2]; } conv;
+
+    ptr += idx;
+    conv.ll = val;
+    ptr[0] = conv.parts[0];
+    ptr[2] = conv.parts[1];
+}
+#endif
+
 /* get a double from an array of u4 */
 static inline double getDoubleFromArray(const u4* ptr, int idx)
 {
@@ -185,6 +238,20 @@ static inline double getDoubleFromArray(const u4* ptr, int idx)
 #endif
 }
 
+#ifdef WITH_TAINT_TRACKING
+/* get a double from an array of u4 */
+static inline double getDoubleFromArrayTaint(const u4* ptr, int idx)
+{
+    /* Need to use the "union" version for taint tracking */
+    union { double d; u4 parts[2]; } conv;
+
+    ptr += idx;
+    conv.parts[0] = ptr[0];
+    conv.parts[1] = ptr[2];
+    return conv.d;
+}
+#endif
+
 /* store a double into an array of u4 */
 static inline void putDoubleToArray(u4* ptr, int idx, double dval)
 {
@@ -200,6 +267,20 @@ static inline void putDoubleToArray(u4* ptr, int idx, double dval)
 #endif
 }
 
+#ifdef WITH_TAINT_TRACKING
+/* store a double into an array of u4 */
+static inline void putDoubleToArrayTaint(u4* ptr, int idx, double dval)
+{
+    /* Need to use the "union" version for taint tracking */
+    union { double d; u4 parts[2]; } conv;
+
+    ptr += idx;
+    conv.d = dval;
+    ptr[0] = conv.parts[0];
+    ptr[2] = conv.parts[1];
+}
+#endif
+
 /*
  * If enabled, validate the register number on every access.  Otherwise,
  * just do an array access.
@@ -208,6 +289,55 @@ static inline void putDoubleToArray(u4* ptr, int idx, double dval)
  *
  * "_idx" may be referenced more than once.
  */
+#ifdef WITH_TAINT_TRACKING
+/* -- Begin Taint Tracking version ------------------------------- */
+/* Taint tags are interleaved between registers. All indexes must
+ * be multiplied by 2 (i.e., left bit shift by 1) */
+#ifdef CHECK_REGISTER_INDICES
+# define GET_REGISTER(_idx) \
+    ( (_idx) < curMethod->registersSize ? \
+        (fp[(_idx)<<1]) : (assert(!"bad reg"),1969) )
+# define SET_REGISTER(_idx, _val) \
+    ( (_idx) < curMethod->registersSize ? \
+        (fp[(_idx)<<1] = (u4)(_val)) : (assert(!"bad reg"),1969) )
+# define GET_REGISTER_AS_OBJECT(_idx)       ((Object *)GET_REGISTER(_idx))
+# define SET_REGISTER_AS_OBJECT(_idx, _val) SET_REGISTER(_idx, (s4)_val)
+# define GET_REGISTER_INT(_idx) ((s4) GET_REGISTER(_idx))
+# define SET_REGISTER_INT(_idx, _val) SET_REGISTER(_idx, (s4)_val)
+# define GET_REGISTER_WIDE(_idx) \
+    ( (_idx) < curMethod->registersSize-1 ? \
+        getLongFromArrayTaint(fp, ((_idx)<<1)) : (assert(!"bad reg"),1969) )
+# define SET_REGISTER_WIDE(_idx, _val) \
+    ( (_idx) < curMethod->registersSize-1 ? \
+        putLongToArrayTaint(fp, ((_idx)<<1), (_val)) : (assert(!"bad reg"),1969) )
+# define GET_REGISTER_FLOAT(_idx) \
+    ( (_idx) < curMethod->registersSize ? \
+        (*((float*) &fp[(_idx)<<1])) : (assert(!"bad reg"),1969.0f) )
+# define SET_REGISTER_FLOAT(_idx, _val) \
+    ( (_idx) < curMethod->registersSize ? \
+        (*((float*) &fp[(_idx)<<1]) = (_val)) : (assert(!"bad reg"),1969.0f) )
+# define GET_REGISTER_DOUBLE(_idx) \
+    ( (_idx) < curMethod->registersSize-1 ? \
+        getDoubleFromArrayTaint(fp, ((_idx)<<1)) : (assert(!"bad reg"),1969.0) )
+# define SET_REGISTER_DOUBLE(_idx, _val) \
+    ( (_idx) < curMethod->registersSize-1 ? \
+        putDoubleToArrayTaint(fp, ((_idx)<<1), (_val)) : (assert(!"bad reg"),1969.0) )
+#else
+# define GET_REGISTER(_idx)                 (fp[(_idx)<<1])
+# define SET_REGISTER(_idx, _val)           (fp[(_idx)<<1] = (_val))
+# define GET_REGISTER_AS_OBJECT(_idx)       ((Object*) fp[(_idx)<<1])
+# define SET_REGISTER_AS_OBJECT(_idx, _val) (fp[(_idx)<<1] = (u4)(_val))
+# define GET_REGISTER_INT(_idx)             ((s4)GET_REGISTER(_idx))
+# define SET_REGISTER_INT(_idx, _val)       SET_REGISTER(_idx, (s4)_val)
+# define GET_REGISTER_WIDE(_idx)            getLongFromArrayTaint(fp, ((_idx)<<1))
+# define SET_REGISTER_WIDE(_idx, _val)      putLongToArrayTaint(fp, ((_idx)<<1), (_val))
+# define GET_REGISTER_FLOAT(_idx)           (*((float*) &fp[(_idx)<<1]))
+# define SET_REGISTER_FLOAT(_idx, _val)     (*((float*) &fp[(_idx)<<1]) = (_val))
+# define GET_REGISTER_DOUBLE(_idx)          getDoubleFromArrayTaint(fp, ((_idx)<<1))
+# define SET_REGISTER_DOUBLE(_idx, _val)    putDoubleToArrayTaint(fp, ((_idx)<<1), (_val))
+#endif
+/* -- End Taint Tracking version ---------------------------------- */
+#else /* no taint tracking */
 #ifdef CHECK_REGISTER_INDICES
 # define GET_REGISTER(_idx) \
     ( (_idx) < curMethod->registersSize ? \
@@ -251,6 +381,48 @@ static inline void putDoubleToArray(u4* ptr, int idx, double dval)
 # define GET_REGISTER_DOUBLE(_idx)          getDoubleFromArray(fp, (_idx))
 # define SET_REGISTER_DOUBLE(_idx, _val)    putDoubleToArray(fp, (_idx), (_val))
 #endif
+#endif /* end no taint tracking */
+
+#ifdef WITH_TAINT_TRACKING
+/* Core get and set macros */
+# define GET_REGISTER_TAINT(_idx)	     (fp[((_idx)<<1)+1])
+# define SET_REGISTER_TAINT(_idx, _val)	     (fp[((_idx)<<1)+1] = (u4)(_val))
+# define GET_REGISTER_TAINT_WIDE(_idx)       (fp[((_idx)<<1)+1])
+# define SET_REGISTER_TAINT_WIDE(_idx, _val) (fp[((_idx)<<1)+1] = \
+	                                      fp[((_idx)<<1)+3] = (u4)(_val))
+/* Alternate interfaces to help dereference register width */
+# define GET_REGISTER_TAINT_INT(_idx)	          GET_REGISTER_TAINT(_idx)
+# define SET_REGISTER_TAINT_INT(_idx, _val)       SET_REGISTER_TAINT(_idx, _val)
+# define GET_REGISTER_TAINT_FLOAT(_idx)	          GET_REGISTER_TAINT(_idx)
+# define SET_REGISTER_TAINT_FLOAT(_idx, _val)     SET_REGISTER_TAINT(_idx, _val)
+# define GET_REGISTER_TAINT_DOUBLE(_idx)          GET_REGISTER_TAINT_WIDE(_idx)
+# define SET_REGISTER_TAINT_DOUBLE(_idx, _val)    SET_REGISTER_TAINT_WIDE(_idx, _val)
+# define GET_REGISTER_TAINT_AS_OBJECT(_idx)       GET_REGISTER_TAINT(_idx)
+# define SET_REGISTER_TAINT_AS_OBJECT(_idx, _val) SET_REGISTER_TAINT(_idx, _val)
+
+/* Object Taint interface */
+# define GET_ARRAY_TAINT(_arr)		      ((_arr)->taint.tag)
+# define SET_ARRAY_TAINT(_arr, _val)	      ((_arr)->taint.tag = (u4)(_val))
+
+/* Return value taint (assumes rtaint variable is in scope */
+# define GET_RETURN_TAINT()		      (rtaint.tag)
+# define SET_RETURN_TAINT(_val)		      (rtaint.tag = (u4)(_val))
+#else
+# define GET_REGISTER_TAINT(_idx)		    ((void)0)
+# define SET_REGISTER_TAINT(_idx, _val)		    ((void)0)
+# define GET_REGISTER_TAINT_WIDE(_idx)		    ((void)0)
+# define SET_REGISTER_TAINT_WIDE(_idx, _val)	    ((void)0)
+# define GET_REGISTER_TAINT_INT(_idx)		    ((void)0)
+# define SET_REGISTER_TAINT_INT(_idx, _val)	    ((void)0)
+# define GET_REGISTER_TAINT_DOUBLE(_idx)	    ((void)0)
+# define SET_REGISTER_TAINT_DOUBLE(_idx, _val)	    ((void)0)
+# define GET_REGISTER_TAINT_AS_OBJECT(_idx)	    ((void)0)
+# define SET_REGISTER_TAINT_AS_OBJECT(_idx, _val)   ((void)0)
+# define GET_ARRAY_TAINT(_field)                    ((void)0)
+# define SET_ARRAY_TAINT(_field, _val)              ((void)0)
+# define GET_RETURN_TAINT()			    ((void)0)
+# define SET_RETURN_TAINT(_val)			    ((void)0)
+#endif
 
 /*
  * Get 16 bits from the specified offset of the program counter.  We always
diff --git a/vm/mterp/c/opcommon.cpp b/vm/mterp/c/opcommon.cpp
index 991df86..c995b1a 100644
--- a/vm/mterp/c/opcommon.cpp
+++ b/vm/mterp/c/opcommon.cpp
@@ -31,6 +31,10 @@ GOTO_TARGET_DECL(exceptionThrown);
         ILOGV("|%s v%d,v%d", (_opname), vdst, vsrc1);                       \
         SET_REGISTER##_totype(vdst,                                         \
             GET_REGISTER##_fromtype(vsrc1));                                \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT##_totype(vdst,                                   \
+	    GET_REGISTER_TAINT##_fromtype(vsrc1));                          \
+/* endif */                                                                 \
         FINISH(1);
 
 #define HANDLE_FLOAT_TO_INT(_opcode, _opname, _fromvtype, _fromrtype,       \
@@ -56,6 +60,10 @@ GOTO_TARGET_DECL(exceptionThrown);
         else                                                                \
             result = (_tovtype) val;                                        \
         SET_REGISTER##_tortype(vdst, result);                               \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT##_tortype(vdst,                                  \
+	    GET_REGISTER_TAINT##_fromrtype(vsrc1));                         \
+/* endif */                                                                 \
     }                                                                       \
     FINISH(1);
 
@@ -65,6 +73,9 @@ GOTO_TARGET_DECL(exceptionThrown);
         vsrc1 = INST_B(inst);                                               \
         ILOGV("|int-to-%s v%d,v%d", (_opname), vdst, vsrc1);                \
         SET_REGISTER(vdst, (_type) GET_REGISTER(vsrc1));                    \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT(vdst, GET_REGISTER_TAINT(vsrc1));                \
+/* endif */                                                                 \
         FINISH(1);
 
 /* NOTE: the comparison result is always a signed 4-byte integer */
@@ -91,6 +102,9 @@ GOTO_TARGET_DECL(exceptionThrown);
             result = (_nanVal);                                             \
         ILOGV("+ result=%d", result);                                       \
         SET_REGISTER(vdst, result);                                         \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT(vdst, TAINT_CLEAR);				    \
+/* endif */                                                                 \
     }                                                                       \
     FINISH(2);
 
@@ -132,6 +146,9 @@ GOTO_TARGET_DECL(exceptionThrown);
         vsrc1 = INST_B(inst);                                               \
         ILOGV("|%s v%d,v%d", (_opname), vdst, vsrc1);                       \
         SET_REGISTER##_type(vdst, _pfx GET_REGISTER##_type(vsrc1) _sfx);    \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT##_type(vdst, GET_REGISTER_TAINT##_type(vsrc1));  \
+/* endif */                                                                 \
         FINISH(1);
 
 #define HANDLE_OP_X_INT(_opcode, _opname, _op, _chkdiv)                     \
@@ -166,6 +183,10 @@ GOTO_TARGET_DECL(exceptionThrown);
             SET_REGISTER(vdst,                                              \
                 (s4) GET_REGISTER(vsrc1) _op (s4) GET_REGISTER(vsrc2));     \
         }                                                                   \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT(vdst,                                            \
+	    (GET_REGISTER_TAINT(vsrc1)|GET_REGISTER_TAINT(vsrc2)) );        \
+/* endif */                                                                 \
     }                                                                       \
     FINISH(2);
 
@@ -180,6 +201,10 @@ GOTO_TARGET_DECL(exceptionThrown);
         ILOGV("|%s-int v%d,v%d", (_opname), vdst, vsrc1);                   \
         SET_REGISTER(vdst,                                                  \
             _cast GET_REGISTER(vsrc1) _op (GET_REGISTER(vsrc2) & 0x1f));    \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT(vdst,                                            \
+	    (GET_REGISTER_TAINT(vsrc1)|GET_REGISTER_TAINT(vsrc2)) );        \
+/* endif */                                                                 \
     }                                                                       \
     FINISH(2);
 
@@ -196,7 +221,7 @@ GOTO_TARGET_DECL(exceptionThrown);
             if ((s2) vsrc2 == 0) {                                          \
                 EXPORT_PC();                                                \
                 dvmThrowArithmeticException("divide by zero");              \
-                GOTO_exceptionThrown();                                     \
+                GOTO_exceptionThrown();                                      \
             }                                                               \
             if ((u4)firstVal == 0x80000000 && ((s2) vsrc2) == -1) {         \
                 /* won't generate /lit16 instr for this; check anyway */    \
@@ -212,6 +237,9 @@ GOTO_TARGET_DECL(exceptionThrown);
             /* non-div/rem case */                                          \
             SET_REGISTER(vdst, GET_REGISTER(vsrc1) _op (s2) vsrc2);         \
         }                                                                   \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT(vdst, GET_REGISTER_TAINT(vsrc1));                \
+/* endif */                                                                 \
         FINISH(2);
 
 #define HANDLE_OP_X_INT_LIT8(_opcode, _opname, _op, _chkdiv)                \
@@ -245,6 +273,9 @@ GOTO_TARGET_DECL(exceptionThrown);
             SET_REGISTER(vdst,                                              \
                 (s4) GET_REGISTER(vsrc1) _op (s1) vsrc2);                   \
         }                                                                   \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT(vdst, GET_REGISTER_TAINT(vsrc1));                \
+/* endif */                                                                 \
     }                                                                       \
     FINISH(2);
 
@@ -260,6 +291,9 @@ GOTO_TARGET_DECL(exceptionThrown);
             (_opname), vdst, vsrc1, vsrc2);                                 \
         SET_REGISTER(vdst,                                                  \
             _cast GET_REGISTER(vsrc1) _op (vsrc2 & 0x1f));                  \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT(vdst, GET_REGISTER_TAINT(vsrc1));                \
+/* endif */                                                                 \
     }                                                                       \
     FINISH(2);
 
@@ -290,6 +324,10 @@ GOTO_TARGET_DECL(exceptionThrown);
             SET_REGISTER(vdst,                                              \
                 (s4) GET_REGISTER(vdst) _op (s4) GET_REGISTER(vsrc1));      \
         }                                                                   \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT(vdst,                                            \
+	    (GET_REGISTER_TAINT(vdst)|GET_REGISTER_TAINT(vsrc1)) );         \
+/* endif */                                                                 \
         FINISH(1);
 
 #define HANDLE_OP_SHX_INT_2ADDR(_opcode, _opname, _cast, _op)               \
@@ -299,6 +337,10 @@ GOTO_TARGET_DECL(exceptionThrown);
         ILOGV("|%s-int-2addr v%d,v%d", (_opname), vdst, vsrc1);             \
         SET_REGISTER(vdst,                                                  \
             _cast GET_REGISTER(vdst) _op (GET_REGISTER(vsrc1) & 0x1f));     \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT(vdst,                                            \
+	    (GET_REGISTER_TAINT(vdst)|GET_REGISTER_TAINT(vsrc1)) );         \
+/* endif */                                                                 \
         FINISH(1);
 
 #define HANDLE_OP_X_LONG(_opcode, _opname, _op, _chkdiv)                    \
@@ -334,6 +376,10 @@ GOTO_TARGET_DECL(exceptionThrown);
             SET_REGISTER_WIDE(vdst,                                         \
                 (s8) GET_REGISTER_WIDE(vsrc1) _op (s8) GET_REGISTER_WIDE(vsrc2)); \
         }                                                                   \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT_WIDE(vdst,                                       \
+	   (GET_REGISTER_TAINT_WIDE(vsrc1)|GET_REGISTER_TAINT_WIDE(vsrc2)));\
+/* endif */                                                                 \
     }                                                                       \
     FINISH(2);
 
@@ -348,6 +394,10 @@ GOTO_TARGET_DECL(exceptionThrown);
         ILOGV("|%s-long v%d,v%d,v%d", (_opname), vdst, vsrc1, vsrc2);       \
         SET_REGISTER_WIDE(vdst,                                             \
             _cast GET_REGISTER_WIDE(vsrc1) _op (GET_REGISTER(vsrc2) & 0x3f)); \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT_WIDE(vdst,                                       \
+	   (GET_REGISTER_TAINT_WIDE(vsrc1)|GET_REGISTER_TAINT_WIDE(vsrc2)));\
+/* endif */                                                                 \
     }                                                                       \
     FINISH(2);
 
@@ -380,6 +430,10 @@ GOTO_TARGET_DECL(exceptionThrown);
             SET_REGISTER_WIDE(vdst,                                         \
                 (s8) GET_REGISTER_WIDE(vdst) _op (s8)GET_REGISTER_WIDE(vsrc1));\
         }                                                                   \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT_WIDE(vdst,                                       \
+	    (GET_REGISTER_TAINT_WIDE(vdst)|GET_REGISTER_TAINT_WIDE(vsrc1)));\
+/* endif */                                                                 \
         FINISH(1);
 
 #define HANDLE_OP_SHX_LONG_2ADDR(_opcode, _opname, _cast, _op)              \
@@ -389,6 +443,10 @@ GOTO_TARGET_DECL(exceptionThrown);
         ILOGV("|%s-long-2addr v%d,v%d", (_opname), vdst, vsrc1);            \
         SET_REGISTER_WIDE(vdst,                                             \
             _cast GET_REGISTER_WIDE(vdst) _op (GET_REGISTER(vsrc1) & 0x3f)); \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT_WIDE(vdst,                                       \
+	    (GET_REGISTER_TAINT_WIDE(vdst)|GET_REGISTER_TAINT_WIDE(vsrc1)));\
+/* endif */                                                                 \
         FINISH(1);
 
 #define HANDLE_OP_X_FLOAT(_opcode, _opname, _op)                            \
@@ -402,6 +460,10 @@ GOTO_TARGET_DECL(exceptionThrown);
         ILOGV("|%s-float v%d,v%d,v%d", (_opname), vdst, vsrc1, vsrc2);      \
         SET_REGISTER_FLOAT(vdst,                                            \
             GET_REGISTER_FLOAT(vsrc1) _op GET_REGISTER_FLOAT(vsrc2));       \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT_FLOAT(vdst,                                      \
+	    (GET_REGISTER_TAINT_FLOAT(vsrc1)|GET_REGISTER_TAINT_FLOAT(vsrc2)));\
+/* endif */                                                                 \
     }                                                                       \
     FINISH(2);
 
@@ -416,6 +478,10 @@ GOTO_TARGET_DECL(exceptionThrown);
         ILOGV("|%s-double v%d,v%d,v%d", (_opname), vdst, vsrc1, vsrc2);     \
         SET_REGISTER_DOUBLE(vdst,                                           \
             GET_REGISTER_DOUBLE(vsrc1) _op GET_REGISTER_DOUBLE(vsrc2));     \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT_DOUBLE(vdst,                                     \
+	    (GET_REGISTER_TAINT_DOUBLE(vsrc1)|GET_REGISTER_TAINT_DOUBLE(vsrc2)));\
+/* endif */                                                                 \
     }                                                                       \
     FINISH(2);
 
@@ -426,6 +492,10 @@ GOTO_TARGET_DECL(exceptionThrown);
         ILOGV("|%s-float-2addr v%d,v%d", (_opname), vdst, vsrc1);           \
         SET_REGISTER_FLOAT(vdst,                                            \
             GET_REGISTER_FLOAT(vdst) _op GET_REGISTER_FLOAT(vsrc1));        \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT_FLOAT(vdst,                                      \
+	    (GET_REGISTER_TAINT_FLOAT(vdst)|GET_REGISTER_TAINT_FLOAT(vsrc1)));\
+/* endif */                                                                 \
         FINISH(1);
 
 #define HANDLE_OP_X_DOUBLE_2ADDR(_opcode, _opname, _op)                     \
@@ -435,6 +505,10 @@ GOTO_TARGET_DECL(exceptionThrown);
         ILOGV("|%s-double-2addr v%d,v%d", (_opname), vdst, vsrc1);          \
         SET_REGISTER_DOUBLE(vdst,                                           \
             GET_REGISTER_DOUBLE(vdst) _op GET_REGISTER_DOUBLE(vsrc1));      \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT_DOUBLE(vdst,                                     \
+	    (GET_REGISTER_TAINT_DOUBLE(vdst)|GET_REGISTER_TAINT_DOUBLE(vsrc1)));\
+/* endif */                                                                 \
         FINISH(1);
 
 #define HANDLE_OP_AGET(_opcode, _opname, _type, _regsize)                   \
@@ -459,6 +533,11 @@ GOTO_TARGET_DECL(exceptionThrown);
         SET_REGISTER##_regsize(vdst,                                        \
             ((_type*)(void*)arrayObj->contents)[GET_REGISTER(vsrc2)]);      \
         ILOGV("+ AGET[%d]=%#x", GET_REGISTER(vsrc2), GET_REGISTER(vdst));   \
+/* ifdef WITH_TAINT_TRACKING */						    \
+	SET_REGISTER_TAINT##_regsize(vdst,                                  \
+	    (GET_ARRAY_TAINT(arrayObj)|GET_REGISTER_TAINT(vsrc2)));         \
+/* endif */								    \
+        ILOGV("+ AGET[%d]=0x%x", GET_REGISTER(vsrc2), GET_REGISTER(vdst));  \
     }                                                                       \
     FINISH(2);
 
@@ -484,6 +563,11 @@ GOTO_TARGET_DECL(exceptionThrown);
         ILOGV("+ APUT[%d]=0x%08x", GET_REGISTER(vsrc2), GET_REGISTER(vdst));\
         ((_type*)(void*)arrayObj->contents)[GET_REGISTER(vsrc2)] =          \
             GET_REGISTER##_regsize(vdst);                                   \
+/* ifdef WITH_TAINT_TRACKING */						    \
+	SET_ARRAY_TAINT(arrayObj,                                           \
+		(GET_ARRAY_TAINT(arrayObj) |                                \
+		 GET_REGISTER_TAINT##_regsize(vdst)) );                     \
+/* endif */								    \
     }                                                                       \
     FINISH(2);
 
@@ -527,6 +611,11 @@ GOTO_TARGET_DECL(exceptionThrown);
             dvmGetField##_ftype(obj, ifield->byteOffset));                  \
         ILOGV("+ IGET '%s'=0x%08llx", ifield->field.name,                   \
             (u8) GET_REGISTER##_regsize(vdst));                             \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+	SET_REGISTER_TAINT##_regsize(vdst,                                  \
+	    (GET_REGISTER_TAINT(vsrc1)|                                     \
+	     dvmGetFieldTaint##_ftype(obj,ifield->byteOffset)) );           \
+/* endif */                                                                 \
     }                                                                       \
     FINISH(2);
 
@@ -545,6 +634,13 @@ GOTO_TARGET_DECL(exceptionThrown);
         SET_REGISTER##_regsize(vdst, dvmGetField##_ftype(obj, ref));        \
         ILOGV("+ IGETQ %d=0x%08llx", ref,                                   \
             (u8) GET_REGISTER##_regsize(vdst));                             \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+	/*TLOGW("|IGETQ not supported by taint tracking!!!");*/             \
+	/* compile flag WITH_TAINT_ODEX controls this now */                \
+	SET_REGISTER_TAINT##_regsize(vdst,                                  \
+	    (GET_REGISTER_TAINT(vsrc1)|                                     \
+	     dvmGetFieldTaint##_ftype(obj,ref)) );                          \
+/* endif */                                                                 \
     }                                                                       \
     FINISH(2);
 
@@ -571,6 +667,10 @@ GOTO_TARGET_DECL(exceptionThrown);
             GET_REGISTER##_regsize(vdst));                                  \
         ILOGV("+ IPUT '%s'=0x%08llx", ifield->field.name,                   \
             (u8) GET_REGISTER##_regsize(vdst));                             \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+	dvmSetFieldTaint##_ftype(obj, ifield->byteOffset,                   \
+		GET_REGISTER_TAINT##_regsize(vdst));                        \
+/* endif */                                                                 \
     }                                                                       \
     FINISH(2);
 
@@ -589,6 +689,12 @@ GOTO_TARGET_DECL(exceptionThrown);
         dvmSetField##_ftype(obj, ref, GET_REGISTER##_regsize(vdst));        \
         ILOGV("+ IPUTQ %d=0x%08llx", ref,                                   \
             (u8) GET_REGISTER##_regsize(vdst));                             \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+	/*TLOGW("|IPUTQ not supported by taint tracking!!!");*/             \
+	/* compile flag WITH_TAINT_ODEX controls this now */                \
+	dvmSetFieldTaint##_ftype(obj, ref,                                  \
+		GET_REGISTER_TAINT##_regsize(vdst));                        \
+/* endif */                                                                 \
     }                                                                       \
     FINISH(2);
 
@@ -620,6 +726,9 @@ GOTO_TARGET_DECL(exceptionThrown);
         SET_REGISTER##_regsize(vdst, dvmGetStaticField##_ftype(sfield));    \
         ILOGV("+ SGET '%s'=0x%08llx",                                       \
             sfield->field.name, (u8)GET_REGISTER##_regsize(vdst));          \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+	SET_REGISTER_TAINT##_regsize(vdst, dvmGetStaticFieldTaint##_ftype(sfield));\
+/* endif */                                                                 \
     }                                                                       \
     FINISH(2);
 
@@ -643,5 +752,10 @@ GOTO_TARGET_DECL(exceptionThrown);
         dvmSetStaticField##_ftype(sfield, GET_REGISTER##_regsize(vdst));    \
         ILOGV("+ SPUT '%s'=0x%08llx",                                       \
             sfield->field.name, (u8)GET_REGISTER##_regsize(vdst));          \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+	dvmSetStaticFieldTaint##_ftype(sfield,                              \
+		GET_REGISTER_TAINT##_regsize(vdst));                        \
+/* endif */                                                                 \
     }                                                                       \
     FINISH(2);
+
diff --git a/vm/mterp/c_notaint/OP_ADD_DOUBLE.cpp b/vm/mterp/c_notaint/OP_ADD_DOUBLE.cpp
new file mode 100644
index 0000000..571aeb8
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_ADD_DOUBLE.cpp
@@ -0,0 +1,2 @@
+HANDLE_OP_X_DOUBLE(OP_ADD_DOUBLE, "add", +)
+OP_END
diff --git a/vm/mterp/c_notaint/OP_ADD_DOUBLE_2ADDR.cpp b/vm/mterp/c_notaint/OP_ADD_DOUBLE_2ADDR.cpp
new file mode 100644
index 0000000..af952cb
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_ADD_DOUBLE_2ADDR.cpp
@@ -0,0 +1,2 @@
+HANDLE_OP_X_DOUBLE_2ADDR(OP_ADD_DOUBLE_2ADDR, "add", +)
+OP_END
diff --git a/vm/mterp/c_notaint/OP_ADD_FLOAT.cpp b/vm/mterp/c_notaint/OP_ADD_FLOAT.cpp
new file mode 100644
index 0000000..dab7d33
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_ADD_FLOAT.cpp
@@ -0,0 +1,2 @@
+HANDLE_OP_X_FLOAT(OP_ADD_FLOAT, "add", +)
+OP_END
diff --git a/vm/mterp/c_notaint/OP_ADD_FLOAT_2ADDR.cpp b/vm/mterp/c_notaint/OP_ADD_FLOAT_2ADDR.cpp
new file mode 100644
index 0000000..a068fd0
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_ADD_FLOAT_2ADDR.cpp
@@ -0,0 +1,2 @@
+HANDLE_OP_X_FLOAT_2ADDR(OP_ADD_FLOAT_2ADDR, "add", +)
+OP_END
diff --git a/vm/mterp/c_notaint/OP_ADD_INT.cpp b/vm/mterp/c_notaint/OP_ADD_INT.cpp
new file mode 100644
index 0000000..bfaa590
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_ADD_INT.cpp
@@ -0,0 +1,2 @@
+HANDLE_OP_X_INT(OP_ADD_INT, "add", +, 0)
+OP_END
diff --git a/vm/mterp/c_notaint/OP_ADD_INT_2ADDR.cpp b/vm/mterp/c_notaint/OP_ADD_INT_2ADDR.cpp
new file mode 100644
index 0000000..dfd3289
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_ADD_INT_2ADDR.cpp
@@ -0,0 +1,2 @@
+HANDLE_OP_X_INT_2ADDR(OP_ADD_INT_2ADDR, "add", +, 0)
+OP_END
diff --git a/vm/mterp/c_notaint/OP_ADD_INT_LIT16.cpp b/vm/mterp/c_notaint/OP_ADD_INT_LIT16.cpp
new file mode 100644
index 0000000..442ab40
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_ADD_INT_LIT16.cpp
@@ -0,0 +1,2 @@
+HANDLE_OP_X_INT_LIT16(OP_ADD_INT_LIT16, "add", +, 0)
+OP_END
diff --git a/vm/mterp/c_notaint/OP_ADD_INT_LIT8.cpp b/vm/mterp/c_notaint/OP_ADD_INT_LIT8.cpp
new file mode 100644
index 0000000..1455599
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_ADD_INT_LIT8.cpp
@@ -0,0 +1,2 @@
+HANDLE_OP_X_INT_LIT8(OP_ADD_INT_LIT8,   "add", +, 0)
+OP_END
diff --git a/vm/mterp/c_notaint/OP_ADD_LONG.cpp b/vm/mterp/c_notaint/OP_ADD_LONG.cpp
new file mode 100644
index 0000000..25d1f47
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_ADD_LONG.cpp
@@ -0,0 +1,2 @@
+HANDLE_OP_X_LONG(OP_ADD_LONG, "add", +, 0)
+OP_END
diff --git a/vm/mterp/c_notaint/OP_ADD_LONG_2ADDR.cpp b/vm/mterp/c_notaint/OP_ADD_LONG_2ADDR.cpp
new file mode 100644
index 0000000..4ae71bb
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_ADD_LONG_2ADDR.cpp
@@ -0,0 +1,2 @@
+HANDLE_OP_X_LONG_2ADDR(OP_ADD_LONG_2ADDR, "add", +, 0)
+OP_END
diff --git a/vm/mterp/c_notaint/OP_AGET.cpp b/vm/mterp/c_notaint/OP_AGET.cpp
new file mode 100644
index 0000000..766beaf
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_AGET.cpp
@@ -0,0 +1,2 @@
+HANDLE_OP_AGET(OP_AGET, "", u4, )
+OP_END
diff --git a/vm/mterp/c_notaint/OP_AGET_BOOLEAN.cpp b/vm/mterp/c_notaint/OP_AGET_BOOLEAN.cpp
new file mode 100644
index 0000000..d63bc10
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_AGET_BOOLEAN.cpp
@@ -0,0 +1,2 @@
+HANDLE_OP_AGET(OP_AGET_BOOLEAN, "-boolean", u1, )
+OP_END
diff --git a/vm/mterp/c_notaint/OP_AGET_BYTE.cpp b/vm/mterp/c_notaint/OP_AGET_BYTE.cpp
new file mode 100644
index 0000000..61ecc05
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_AGET_BYTE.cpp
@@ -0,0 +1,2 @@
+HANDLE_OP_AGET(OP_AGET_BYTE, "-byte", s1, )
+OP_END
diff --git a/vm/mterp/c_notaint/OP_AGET_CHAR.cpp b/vm/mterp/c_notaint/OP_AGET_CHAR.cpp
new file mode 100644
index 0000000..55e16ef
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_AGET_CHAR.cpp
@@ -0,0 +1,2 @@
+HANDLE_OP_AGET(OP_AGET_CHAR, "-char", u2, )
+OP_END
diff --git a/vm/mterp/c_notaint/OP_AGET_OBJECT.cpp b/vm/mterp/c_notaint/OP_AGET_OBJECT.cpp
new file mode 100644
index 0000000..903637c
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_AGET_OBJECT.cpp
@@ -0,0 +1,2 @@
+HANDLE_OP_AGET(OP_AGET_OBJECT, "-object", u4, )
+OP_END
diff --git a/vm/mterp/c_notaint/OP_AGET_SHORT.cpp b/vm/mterp/c_notaint/OP_AGET_SHORT.cpp
new file mode 100644
index 0000000..176b4a6
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_AGET_SHORT.cpp
@@ -0,0 +1,2 @@
+HANDLE_OP_AGET(OP_AGET_SHORT, "-short", s2, )
+OP_END
diff --git a/vm/mterp/c_notaint/OP_AGET_WIDE.cpp b/vm/mterp/c_notaint/OP_AGET_WIDE.cpp
new file mode 100644
index 0000000..e7974cb
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_AGET_WIDE.cpp
@@ -0,0 +1,2 @@
+HANDLE_OP_AGET(OP_AGET_WIDE, "-wide", s8, _WIDE)
+OP_END
diff --git a/vm/mterp/c_notaint/OP_AND_INT.cpp b/vm/mterp/c_notaint/OP_AND_INT.cpp
new file mode 100644
index 0000000..3cf31cb
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_AND_INT.cpp
@@ -0,0 +1,2 @@
+HANDLE_OP_X_INT(OP_AND_INT, "and", &, 0)
+OP_END
diff --git a/vm/mterp/c_notaint/OP_AND_INT_2ADDR.cpp b/vm/mterp/c_notaint/OP_AND_INT_2ADDR.cpp
new file mode 100644
index 0000000..9f69292
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_AND_INT_2ADDR.cpp
@@ -0,0 +1,2 @@
+HANDLE_OP_X_INT_2ADDR(OP_AND_INT_2ADDR, "and", &, 0)
+OP_END
diff --git a/vm/mterp/c_notaint/OP_AND_INT_LIT16.cpp b/vm/mterp/c_notaint/OP_AND_INT_LIT16.cpp
new file mode 100644
index 0000000..19f825b
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_AND_INT_LIT16.cpp
@@ -0,0 +1,2 @@
+HANDLE_OP_X_INT_LIT16(OP_AND_INT_LIT16, "and", &, 0)
+OP_END
diff --git a/vm/mterp/c_notaint/OP_AND_INT_LIT8.cpp b/vm/mterp/c_notaint/OP_AND_INT_LIT8.cpp
new file mode 100644
index 0000000..c0e1315
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_AND_INT_LIT8.cpp
@@ -0,0 +1,2 @@
+HANDLE_OP_X_INT_LIT8(OP_AND_INT_LIT8,   "and", &, 0)
+OP_END
diff --git a/vm/mterp/c_notaint/OP_AND_LONG.cpp b/vm/mterp/c_notaint/OP_AND_LONG.cpp
new file mode 100644
index 0000000..1c638fb
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_AND_LONG.cpp
@@ -0,0 +1,2 @@
+HANDLE_OP_X_LONG(OP_AND_LONG, "and", &, 0)
+OP_END
diff --git a/vm/mterp/c_notaint/OP_AND_LONG_2ADDR.cpp b/vm/mterp/c_notaint/OP_AND_LONG_2ADDR.cpp
new file mode 100644
index 0000000..23c464d
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_AND_LONG_2ADDR.cpp
@@ -0,0 +1,2 @@
+HANDLE_OP_X_LONG_2ADDR(OP_AND_LONG_2ADDR, "and", &, 0)
+OP_END
diff --git a/vm/mterp/c_notaint/OP_APUT.cpp b/vm/mterp/c_notaint/OP_APUT.cpp
new file mode 100644
index 0000000..07d3e04
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_APUT.cpp
@@ -0,0 +1,2 @@
+HANDLE_OP_APUT(OP_APUT, "", u4, )
+OP_END
diff --git a/vm/mterp/c_notaint/OP_APUT_BOOLEAN.cpp b/vm/mterp/c_notaint/OP_APUT_BOOLEAN.cpp
new file mode 100644
index 0000000..fc69147
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_APUT_BOOLEAN.cpp
@@ -0,0 +1,2 @@
+HANDLE_OP_APUT(OP_APUT_BOOLEAN, "-boolean", u1, )
+OP_END
diff --git a/vm/mterp/c_notaint/OP_APUT_BYTE.cpp b/vm/mterp/c_notaint/OP_APUT_BYTE.cpp
new file mode 100644
index 0000000..45aeb0b
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_APUT_BYTE.cpp
@@ -0,0 +1,2 @@
+HANDLE_OP_APUT(OP_APUT_BYTE, "-byte", s1, )
+OP_END
diff --git a/vm/mterp/c_notaint/OP_APUT_CHAR.cpp b/vm/mterp/c_notaint/OP_APUT_CHAR.cpp
new file mode 100644
index 0000000..1553c27
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_APUT_CHAR.cpp
@@ -0,0 +1,2 @@
+HANDLE_OP_APUT(OP_APUT_CHAR, "-char", u2, )
+OP_END
diff --git a/vm/mterp/c_notaint/OP_APUT_OBJECT.cpp b/vm/mterp/c_notaint/OP_APUT_OBJECT.cpp
new file mode 100644
index 0000000..9318648
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_APUT_OBJECT.cpp
@@ -0,0 +1,38 @@
+HANDLE_OPCODE(OP_APUT_OBJECT /*vAA, vBB, vCC*/)
+    {
+        ArrayObject* arrayObj;
+        Object* obj;
+        u2 arrayInfo;
+        EXPORT_PC();
+        vdst = INST_AA(inst);       /* AA: source value */
+        arrayInfo = FETCH(1);
+        vsrc1 = arrayInfo & 0xff;   /* BB: array ptr */
+        vsrc2 = arrayInfo >> 8;     /* CC: index */
+        ILOGV("|aput%s v%d,v%d,v%d", "-object", vdst, vsrc1, vsrc2);
+        arrayObj = (ArrayObject*) GET_REGISTER(vsrc1);
+        if (!checkForNull((Object*) arrayObj))
+            GOTO_exceptionThrown();
+        if (GET_REGISTER(vsrc2) >= arrayObj->length) {
+            dvmThrowArrayIndexOutOfBoundsException(
+                arrayObj->length, GET_REGISTER(vsrc2));
+            GOTO_exceptionThrown();
+        }
+        obj = (Object*) GET_REGISTER(vdst);
+        if (obj != NULL) {
+            if (!checkForNull(obj))
+                GOTO_exceptionThrown();
+            if (!dvmCanPutArrayElement(obj->clazz, arrayObj->clazz)) {
+                ALOGV("Can't put a '%s'(%p) into array type='%s'(%p)",
+                    obj->clazz->descriptor, obj,
+                    arrayObj->obj.clazz->descriptor, arrayObj);
+                dvmThrowArrayStoreExceptionIncompatibleElement(obj->clazz, arrayObj->clazz);
+                GOTO_exceptionThrown();
+            }
+        }
+        ILOGV("+ APUT[%d]=0x%08x", GET_REGISTER(vsrc2), GET_REGISTER(vdst));
+        dvmSetObjectArrayElement(arrayObj,
+                                 GET_REGISTER(vsrc2),
+                                 (Object *)GET_REGISTER(vdst));
+    }
+    FINISH(2);
+OP_END
diff --git a/vm/mterp/c_notaint/OP_APUT_SHORT.cpp b/vm/mterp/c_notaint/OP_APUT_SHORT.cpp
new file mode 100644
index 0000000..a72b5ea
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_APUT_SHORT.cpp
@@ -0,0 +1,2 @@
+HANDLE_OP_APUT(OP_APUT_SHORT, "-short", s2, )
+OP_END
diff --git a/vm/mterp/c_notaint/OP_APUT_WIDE.cpp b/vm/mterp/c_notaint/OP_APUT_WIDE.cpp
new file mode 100644
index 0000000..39c8cfa
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_APUT_WIDE.cpp
@@ -0,0 +1,2 @@
+HANDLE_OP_APUT(OP_APUT_WIDE, "-wide", s8, _WIDE)
+OP_END
diff --git a/vm/mterp/c_notaint/OP_ARRAY_LENGTH.cpp b/vm/mterp/c_notaint/OP_ARRAY_LENGTH.cpp
new file mode 100644
index 0000000..0d5a933
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_ARRAY_LENGTH.cpp
@@ -0,0 +1,15 @@
+HANDLE_OPCODE(OP_ARRAY_LENGTH /*vA, vB*/)
+    {
+        ArrayObject* arrayObj;
+
+        vdst = INST_A(inst);
+        vsrc1 = INST_B(inst);
+        arrayObj = (ArrayObject*) GET_REGISTER(vsrc1);
+        ILOGV("|array-length v%d,v%d  (%p)", vdst, vsrc1, arrayObj);
+        if (!checkForNullExportPC((Object*) arrayObj, fp, pc))
+            GOTO_exceptionThrown();
+        /* verifier guarantees this is an array reference */
+        SET_REGISTER(vdst, arrayObj->length);
+    }
+    FINISH(1);
+OP_END
diff --git a/vm/mterp/c_notaint/OP_BREAKPOINT.cpp b/vm/mterp/c_notaint/OP_BREAKPOINT.cpp
new file mode 100644
index 0000000..3041190
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_BREAKPOINT.cpp
@@ -0,0 +1,24 @@
+HANDLE_OPCODE(OP_BREAKPOINT)
+    {
+        /*
+         * Restart this instruction with the original opcode.  We do
+         * this by simply jumping to the handler.
+         *
+         * It's probably not necessary to update "inst", but we do it
+         * for the sake of anything that needs to do disambiguation in a
+         * common handler with INST_INST.
+         *
+         * The breakpoint itself is handled over in updateDebugger(),
+         * because we need to detect other events (method entry, single
+         * step) and report them in the same event packet, and we're not
+         * yet handling those through breakpoint instructions.  By the
+         * time we get here, the breakpoint has already been handled and
+         * the thread resumed.
+         */
+        u1 originalOpcode = dvmGetOriginalOpcode(pc);
+        ALOGV("+++ break 0x%02x (0x%04x -> 0x%04x)", originalOpcode, inst,
+            INST_REPLACE_OP(inst, originalOpcode));
+        inst = INST_REPLACE_OP(inst, originalOpcode);
+        FINISH_BKPT(originalOpcode);
+    }
+OP_END
diff --git a/vm/mterp/c_notaint/OP_CHECK_CAST.cpp b/vm/mterp/c_notaint/OP_CHECK_CAST.cpp
new file mode 100644
index 0000000..2c4a304
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_CHECK_CAST.cpp
@@ -0,0 +1,31 @@
+HANDLE_OPCODE(OP_CHECK_CAST /*vAA, class@BBBB*/)
+    {
+        ClassObject* clazz;
+        Object* obj;
+
+        EXPORT_PC();
+
+        vsrc1 = INST_AA(inst);
+        ref = FETCH(1);         /* class to check against */
+        ILOGV("|check-cast v%d,class@0x%04x", vsrc1, ref);
+
+        obj = (Object*)GET_REGISTER(vsrc1);
+        if (obj != NULL) {
+#if defined(WITH_EXTRA_OBJECT_VALIDATION)
+            if (!checkForNull(obj))
+                GOTO_exceptionThrown();
+#endif
+            clazz = dvmDexGetResolvedClass(methodClassDex, ref);
+            if (clazz == NULL) {
+                clazz = dvmResolveClass(curMethod->clazz, ref, false);
+                if (clazz == NULL)
+                    GOTO_exceptionThrown();
+            }
+            if (!dvmInstanceof(obj->clazz, clazz)) {
+                dvmThrowClassCastException(obj->clazz, clazz);
+                GOTO_exceptionThrown();
+            }
+        }
+    }
+    FINISH(2);
+OP_END
diff --git a/vm/mterp/c_notaint/OP_CMPG_DOUBLE.cpp b/vm/mterp/c_notaint/OP_CMPG_DOUBLE.cpp
new file mode 100644
index 0000000..3f4082c
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_CMPG_DOUBLE.cpp
@@ -0,0 +1,2 @@
+HANDLE_OP_CMPX(OP_CMPG_DOUBLE, "g-double", double, _DOUBLE, 1)
+OP_END
diff --git a/vm/mterp/c_notaint/OP_CMPG_FLOAT.cpp b/vm/mterp/c_notaint/OP_CMPG_FLOAT.cpp
new file mode 100644
index 0000000..0bba49e
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_CMPG_FLOAT.cpp
@@ -0,0 +1,2 @@
+HANDLE_OP_CMPX(OP_CMPG_FLOAT, "g-float", float, _FLOAT, 1)
+OP_END
diff --git a/vm/mterp/c_notaint/OP_CMPL_DOUBLE.cpp b/vm/mterp/c_notaint/OP_CMPL_DOUBLE.cpp
new file mode 100644
index 0000000..4da18b4
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_CMPL_DOUBLE.cpp
@@ -0,0 +1,2 @@
+HANDLE_OP_CMPX(OP_CMPL_DOUBLE, "l-double", double, _DOUBLE, -1)
+OP_END
diff --git a/vm/mterp/c_notaint/OP_CMPL_FLOAT.cpp b/vm/mterp/c_notaint/OP_CMPL_FLOAT.cpp
new file mode 100644
index 0000000..7916193
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_CMPL_FLOAT.cpp
@@ -0,0 +1,2 @@
+HANDLE_OP_CMPX(OP_CMPL_FLOAT, "l-float", float, _FLOAT, -1)
+OP_END
diff --git a/vm/mterp/c_notaint/OP_CMP_LONG.cpp b/vm/mterp/c_notaint/OP_CMP_LONG.cpp
new file mode 100644
index 0000000..a0e412c
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_CMP_LONG.cpp
@@ -0,0 +1,2 @@
+HANDLE_OP_CMPX(OP_CMP_LONG, "-long", s8, _WIDE, 0)
+OP_END
diff --git a/vm/mterp/c_notaint/OP_CONST.cpp b/vm/mterp/c_notaint/OP_CONST.cpp
new file mode 100644
index 0000000..e281a51
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_CONST.cpp
@@ -0,0 +1,12 @@
+HANDLE_OPCODE(OP_CONST /*vAA, #+BBBBBBBB*/)
+    {
+        u4 tmp;
+
+        vdst = INST_AA(inst);
+        tmp = FETCH(1);
+        tmp |= (u4)FETCH(2) << 16;
+        ILOGV("|const v%d,#0x%08x", vdst, tmp);
+        SET_REGISTER(vdst, tmp);
+    }
+    FINISH(3);
+OP_END
diff --git a/vm/mterp/c_notaint/OP_CONST_16.cpp b/vm/mterp/c_notaint/OP_CONST_16.cpp
new file mode 100644
index 0000000..f58f50c
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_CONST_16.cpp
@@ -0,0 +1,7 @@
+HANDLE_OPCODE(OP_CONST_16 /*vAA, #+BBBB*/)
+    vdst = INST_AA(inst);
+    vsrc1 = FETCH(1);
+    ILOGV("|const/16 v%d,#0x%04x", vdst, (s2)vsrc1);
+    SET_REGISTER(vdst, (s2) vsrc1);
+    FINISH(2);
+OP_END
diff --git a/vm/mterp/c_notaint/OP_CONST_4.cpp b/vm/mterp/c_notaint/OP_CONST_4.cpp
new file mode 100644
index 0000000..800ef9a
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_CONST_4.cpp
@@ -0,0 +1,11 @@
+HANDLE_OPCODE(OP_CONST_4 /*vA, #+B*/)
+    {
+        s4 tmp;
+
+        vdst = INST_A(inst);
+        tmp = (s4) (INST_B(inst) << 28) >> 28;  // sign extend 4-bit value
+        ILOGV("|const/4 v%d,#0x%02x", vdst, (s4)tmp);
+        SET_REGISTER(vdst, tmp);
+    }
+    FINISH(1);
+OP_END
diff --git a/vm/mterp/c_notaint/OP_CONST_CLASS.cpp b/vm/mterp/c_notaint/OP_CONST_CLASS.cpp
new file mode 100644
index 0000000..9c60a27
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_CONST_CLASS.cpp
@@ -0,0 +1,18 @@
+HANDLE_OPCODE(OP_CONST_CLASS /*vAA, class@BBBB*/)
+    {
+        ClassObject* clazz;
+
+        vdst = INST_AA(inst);
+        ref = FETCH(1);
+        ILOGV("|const-class v%d class@0x%04x", vdst, ref);
+        clazz = dvmDexGetResolvedClass(methodClassDex, ref);
+        if (clazz == NULL) {
+            EXPORT_PC();
+            clazz = dvmResolveClass(curMethod->clazz, ref, true);
+            if (clazz == NULL)
+                GOTO_exceptionThrown();
+        }
+        SET_REGISTER(vdst, (u4) clazz);
+    }
+    FINISH(2);
+OP_END
diff --git a/vm/mterp/c_notaint/OP_CONST_HIGH16.cpp b/vm/mterp/c_notaint/OP_CONST_HIGH16.cpp
new file mode 100644
index 0000000..26b22f4
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_CONST_HIGH16.cpp
@@ -0,0 +1,7 @@
+HANDLE_OPCODE(OP_CONST_HIGH16 /*vAA, #+BBBB0000*/)
+    vdst = INST_AA(inst);
+    vsrc1 = FETCH(1);
+    ILOGV("|const/high16 v%d,#0x%04x0000", vdst, vsrc1);
+    SET_REGISTER(vdst, vsrc1 << 16);
+    FINISH(2);
+OP_END
diff --git a/vm/mterp/c_notaint/OP_CONST_STRING.cpp b/vm/mterp/c_notaint/OP_CONST_STRING.cpp
new file mode 100644
index 0000000..748119a
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_CONST_STRING.cpp
@@ -0,0 +1,18 @@
+HANDLE_OPCODE(OP_CONST_STRING /*vAA, string@BBBB*/)
+    {
+        StringObject* strObj;
+
+        vdst = INST_AA(inst);
+        ref = FETCH(1);
+        ILOGV("|const-string v%d string@0x%04x", vdst, ref);
+        strObj = dvmDexGetResolvedString(methodClassDex, ref);
+        if (strObj == NULL) {
+            EXPORT_PC();
+            strObj = dvmResolveString(curMethod->clazz, ref);
+            if (strObj == NULL)
+                GOTO_exceptionThrown();
+        }
+        SET_REGISTER(vdst, (u4) strObj);
+    }
+    FINISH(2);
+OP_END
diff --git a/vm/mterp/c_notaint/OP_CONST_STRING_JUMBO.cpp b/vm/mterp/c_notaint/OP_CONST_STRING_JUMBO.cpp
new file mode 100644
index 0000000..435b34c
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_CONST_STRING_JUMBO.cpp
@@ -0,0 +1,20 @@
+HANDLE_OPCODE(OP_CONST_STRING_JUMBO /*vAA, string@BBBBBBBB*/)
+    {
+        StringObject* strObj;
+        u4 tmp;
+
+        vdst = INST_AA(inst);
+        tmp = FETCH(1);
+        tmp |= (u4)FETCH(2) << 16;
+        ILOGV("|const-string/jumbo v%d string@0x%08x", vdst, tmp);
+        strObj = dvmDexGetResolvedString(methodClassDex, tmp);
+        if (strObj == NULL) {
+            EXPORT_PC();
+            strObj = dvmResolveString(curMethod->clazz, tmp);
+            if (strObj == NULL)
+                GOTO_exceptionThrown();
+        }
+        SET_REGISTER(vdst, (u4) strObj);
+    }
+    FINISH(3);
+OP_END
diff --git a/vm/mterp/c_notaint/OP_CONST_WIDE.cpp b/vm/mterp/c_notaint/OP_CONST_WIDE.cpp
new file mode 100644
index 0000000..ccb3955
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_CONST_WIDE.cpp
@@ -0,0 +1,14 @@
+HANDLE_OPCODE(OP_CONST_WIDE /*vAA, #+BBBBBBBBBBBBBBBB*/)
+    {
+        u8 tmp;
+
+        vdst = INST_AA(inst);
+        tmp = FETCH(1);
+        tmp |= (u8)FETCH(2) << 16;
+        tmp |= (u8)FETCH(3) << 32;
+        tmp |= (u8)FETCH(4) << 48;
+        ILOGV("|const-wide v%d,#0x%08llx", vdst, tmp);
+        SET_REGISTER_WIDE(vdst, tmp);
+    }
+    FINISH(5);
+OP_END
diff --git a/vm/mterp/c_notaint/OP_CONST_WIDE_16.cpp b/vm/mterp/c_notaint/OP_CONST_WIDE_16.cpp
new file mode 100644
index 0000000..da69f37
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_CONST_WIDE_16.cpp
@@ -0,0 +1,7 @@
+HANDLE_OPCODE(OP_CONST_WIDE_16 /*vAA, #+BBBB*/)
+    vdst = INST_AA(inst);
+    vsrc1 = FETCH(1);
+    ILOGV("|const-wide/16 v%d,#0x%04x", vdst, (s2)vsrc1);
+    SET_REGISTER_WIDE(vdst, (s2)vsrc1);
+    FINISH(2);
+OP_END
diff --git a/vm/mterp/c_notaint/OP_CONST_WIDE_32.cpp b/vm/mterp/c_notaint/OP_CONST_WIDE_32.cpp
new file mode 100644
index 0000000..ad4acbb
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_CONST_WIDE_32.cpp
@@ -0,0 +1,12 @@
+HANDLE_OPCODE(OP_CONST_WIDE_32 /*vAA, #+BBBBBBBB*/)
+    {
+        u4 tmp;
+
+        vdst = INST_AA(inst);
+        tmp = FETCH(1);
+        tmp |= (u4)FETCH(2) << 16;
+        ILOGV("|const-wide/32 v%d,#0x%08x", vdst, tmp);
+        SET_REGISTER_WIDE(vdst, (s4) tmp);
+    }
+    FINISH(3);
+OP_END
diff --git a/vm/mterp/c_notaint/OP_CONST_WIDE_HIGH16.cpp b/vm/mterp/c_notaint/OP_CONST_WIDE_HIGH16.cpp
new file mode 100644
index 0000000..bcc0664
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_CONST_WIDE_HIGH16.cpp
@@ -0,0 +1,7 @@
+HANDLE_OPCODE(OP_CONST_WIDE_HIGH16 /*vAA, #+BBBB000000000000*/)
+    vdst = INST_AA(inst);
+    vsrc1 = FETCH(1);
+    ILOGV("|const-wide/high16 v%d,#0x%04x000000000000", vdst, vsrc1);
+    SET_REGISTER_WIDE(vdst, ((u8) vsrc1) << 48);
+    FINISH(2);
+OP_END
diff --git a/vm/mterp/c_notaint/OP_DIV_DOUBLE.cpp b/vm/mterp/c_notaint/OP_DIV_DOUBLE.cpp
new file mode 100644
index 0000000..d6e4b55
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_DIV_DOUBLE.cpp
@@ -0,0 +1,2 @@
+HANDLE_OP_X_DOUBLE(OP_DIV_DOUBLE, "div", /)
+OP_END
diff --git a/vm/mterp/c_notaint/OP_DIV_DOUBLE_2ADDR.cpp b/vm/mterp/c_notaint/OP_DIV_DOUBLE_2ADDR.cpp
new file mode 100644
index 0000000..85a1523
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_DIV_DOUBLE_2ADDR.cpp
@@ -0,0 +1,2 @@
+HANDLE_OP_X_DOUBLE_2ADDR(OP_DIV_DOUBLE_2ADDR, "div", /)
+OP_END
diff --git a/vm/mterp/c_notaint/OP_DIV_FLOAT.cpp b/vm/mterp/c_notaint/OP_DIV_FLOAT.cpp
new file mode 100644
index 0000000..2c5049b
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_DIV_FLOAT.cpp
@@ -0,0 +1,2 @@
+HANDLE_OP_X_FLOAT(OP_DIV_FLOAT, "div", /)
+OP_END
diff --git a/vm/mterp/c_notaint/OP_DIV_FLOAT_2ADDR.cpp b/vm/mterp/c_notaint/OP_DIV_FLOAT_2ADDR.cpp
new file mode 100644
index 0000000..cd7b4d9
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_DIV_FLOAT_2ADDR.cpp
@@ -0,0 +1,2 @@
+HANDLE_OP_X_FLOAT_2ADDR(OP_DIV_FLOAT_2ADDR, "div", /)
+OP_END
diff --git a/vm/mterp/c_notaint/OP_DIV_INT.cpp b/vm/mterp/c_notaint/OP_DIV_INT.cpp
new file mode 100644
index 0000000..af6e8c6
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_DIV_INT.cpp
@@ -0,0 +1,2 @@
+HANDLE_OP_X_INT(OP_DIV_INT, "div", /, 1)
+OP_END
diff --git a/vm/mterp/c_notaint/OP_DIV_INT_2ADDR.cpp b/vm/mterp/c_notaint/OP_DIV_INT_2ADDR.cpp
new file mode 100644
index 0000000..80c0da7
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_DIV_INT_2ADDR.cpp
@@ -0,0 +1,2 @@
+HANDLE_OP_X_INT_2ADDR(OP_DIV_INT_2ADDR, "div", /, 1)
+OP_END
diff --git a/vm/mterp/c_notaint/OP_DIV_INT_LIT16.cpp b/vm/mterp/c_notaint/OP_DIV_INT_LIT16.cpp
new file mode 100644
index 0000000..4e8d901
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_DIV_INT_LIT16.cpp
@@ -0,0 +1,2 @@
+HANDLE_OP_X_INT_LIT16(OP_DIV_INT_LIT16, "div", /, 1)
+OP_END
diff --git a/vm/mterp/c_notaint/OP_DIV_INT_LIT8.cpp b/vm/mterp/c_notaint/OP_DIV_INT_LIT8.cpp
new file mode 100644
index 0000000..eec5389
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_DIV_INT_LIT8.cpp
@@ -0,0 +1,2 @@
+HANDLE_OP_X_INT_LIT8(OP_DIV_INT_LIT8,   "div", /, 1)
+OP_END
diff --git a/vm/mterp/c_notaint/OP_DIV_LONG.cpp b/vm/mterp/c_notaint/OP_DIV_LONG.cpp
new file mode 100644
index 0000000..557b56b
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_DIV_LONG.cpp
@@ -0,0 +1,2 @@
+HANDLE_OP_X_LONG(OP_DIV_LONG, "div", /, 1)
+OP_END
diff --git a/vm/mterp/c_notaint/OP_DIV_LONG_2ADDR.cpp b/vm/mterp/c_notaint/OP_DIV_LONG_2ADDR.cpp
new file mode 100644
index 0000000..00e0e6c
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_DIV_LONG_2ADDR.cpp
@@ -0,0 +1,2 @@
+HANDLE_OP_X_LONG_2ADDR(OP_DIV_LONG_2ADDR, "div", /, 1)
+OP_END
diff --git a/vm/mterp/c_notaint/OP_DOUBLE_TO_FLOAT.cpp b/vm/mterp/c_notaint/OP_DOUBLE_TO_FLOAT.cpp
new file mode 100644
index 0000000..152e5fd
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_DOUBLE_TO_FLOAT.cpp
@@ -0,0 +1,2 @@
+HANDLE_NUMCONV(OP_DOUBLE_TO_FLOAT,      "double-to-float", _DOUBLE, _FLOAT)
+OP_END
diff --git a/vm/mterp/c_notaint/OP_DOUBLE_TO_INT.cpp b/vm/mterp/c_notaint/OP_DOUBLE_TO_INT.cpp
new file mode 100644
index 0000000..e210b92
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_DOUBLE_TO_INT.cpp
@@ -0,0 +1,3 @@
+HANDLE_FLOAT_TO_INT(OP_DOUBLE_TO_INT,   "double-to-int",
+    double, _DOUBLE, s4, _INT)
+OP_END
diff --git a/vm/mterp/c_notaint/OP_DOUBLE_TO_LONG.cpp b/vm/mterp/c_notaint/OP_DOUBLE_TO_LONG.cpp
new file mode 100644
index 0000000..44d548c
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_DOUBLE_TO_LONG.cpp
@@ -0,0 +1,3 @@
+HANDLE_FLOAT_TO_INT(OP_DOUBLE_TO_LONG,  "double-to-long",
+    double, _DOUBLE, s8, _WIDE)
+OP_END
diff --git a/vm/mterp/c_notaint/OP_EXECUTE_INLINE.cpp b/vm/mterp/c_notaint/OP_EXECUTE_INLINE.cpp
new file mode 100644
index 0000000..8d20764
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_EXECUTE_INLINE.cpp
@@ -0,0 +1,59 @@
+HANDLE_OPCODE(OP_EXECUTE_INLINE /*vB, {vD, vE, vF, vG}, inline@CCCC*/)
+    {
+        /*
+         * This has the same form as other method calls, but we ignore
+         * the 5th argument (vA).  This is chiefly because the first four
+         * arguments to a function on ARM are in registers.
+         *
+         * We only set the arguments that are actually used, leaving
+         * the rest uninitialized.  We're assuming that, if the method
+         * needs them, they'll be specified in the call.
+         *
+         * However, this annoys gcc when optimizations are enabled,
+         * causing a "may be used uninitialized" warning.  Quieting
+         * the warnings incurs a slight penalty (5%: 373ns vs. 393ns
+         * on empty method).  Note that valgrind is perfectly happy
+         * either way as the uninitialiezd values are never actually
+         * used.
+         */
+        u4 arg0, arg1, arg2, arg3;
+        arg0 = arg1 = arg2 = arg3 = 0;
+
+        EXPORT_PC();
+
+        vsrc1 = INST_B(inst);       /* #of args */
+        ref = FETCH(1);             /* inline call "ref" */
+        vdst = FETCH(2);            /* 0-4 register indices */
+        ILOGV("|execute-inline args=%d @%d {regs=0x%04x}",
+            vsrc1, ref, vdst);
+
+        assert((vdst >> 16) == 0);  // 16-bit type -or- high 16 bits clear
+        assert(vsrc1 <= 4);
+
+        switch (vsrc1) {
+        case 4:
+            arg3 = GET_REGISTER(vdst >> 12);
+            /* fall through */
+        case 3:
+            arg2 = GET_REGISTER((vdst & 0x0f00) >> 8);
+            /* fall through */
+        case 2:
+            arg1 = GET_REGISTER((vdst & 0x00f0) >> 4);
+            /* fall through */
+        case 1:
+            arg0 = GET_REGISTER(vdst & 0x0f);
+            /* fall through */
+        default:        // case 0
+            ;
+        }
+
+        if (self->interpBreak.ctl.subMode & kSubModeDebuggerActive) {
+            if (!dvmPerformInlineOp4Dbg(arg0, arg1, arg2, arg3, &retval, ref))
+                GOTO_exceptionThrown();
+        } else {
+            if (!dvmPerformInlineOp4Std(arg0, arg1, arg2, arg3, &retval, ref))
+                GOTO_exceptionThrown();
+        }
+    }
+    FINISH(3);
+OP_END
diff --git a/vm/mterp/c_notaint/OP_EXECUTE_INLINE_RANGE.cpp b/vm/mterp/c_notaint/OP_EXECUTE_INLINE_RANGE.cpp
new file mode 100644
index 0000000..664ada4
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_EXECUTE_INLINE_RANGE.cpp
@@ -0,0 +1,43 @@
+HANDLE_OPCODE(OP_EXECUTE_INLINE_RANGE /*{vCCCC..v(CCCC+AA-1)}, inline@BBBB*/)
+    {
+        u4 arg0, arg1, arg2, arg3;
+        arg0 = arg1 = arg2 = arg3 = 0;      /* placate gcc */
+
+        EXPORT_PC();
+
+        vsrc1 = INST_AA(inst);      /* #of args */
+        ref = FETCH(1);             /* inline call "ref" */
+        vdst = FETCH(2);            /* range base */
+        ILOGV("|execute-inline-range args=%d @%d {regs=v%d-v%d}",
+            vsrc1, ref, vdst, vdst+vsrc1-1);
+
+        assert((vdst >> 16) == 0);  // 16-bit type -or- high 16 bits clear
+        assert(vsrc1 <= 4);
+
+        switch (vsrc1) {
+        case 4:
+            arg3 = GET_REGISTER(vdst+3);
+            /* fall through */
+        case 3:
+            arg2 = GET_REGISTER(vdst+2);
+            /* fall through */
+        case 2:
+            arg1 = GET_REGISTER(vdst+1);
+            /* fall through */
+        case 1:
+            arg0 = GET_REGISTER(vdst+0);
+            /* fall through */
+        default:        // case 0
+            ;
+        }
+
+        if (self->interpBreak.ctl.subMode & kSubModeDebuggerActive) {
+            if (!dvmPerformInlineOp4Dbg(arg0, arg1, arg2, arg3, &retval, ref))
+                GOTO_exceptionThrown();
+        } else {
+            if (!dvmPerformInlineOp4Std(arg0, arg1, arg2, arg3, &retval, ref))
+                GOTO_exceptionThrown();
+        }
+    }
+    FINISH(3);
+OP_END
diff --git a/vm/mterp/c_notaint/OP_FILLED_NEW_ARRAY.cpp b/vm/mterp/c_notaint/OP_FILLED_NEW_ARRAY.cpp
new file mode 100644
index 0000000..fad7dbb
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_FILLED_NEW_ARRAY.cpp
@@ -0,0 +1,3 @@
+HANDLE_OPCODE(OP_FILLED_NEW_ARRAY /*vB, {vD, vE, vF, vG, vA}, class@CCCC*/)
+    GOTO_invoke(filledNewArray, false);
+OP_END
diff --git a/vm/mterp/c_notaint/OP_FILLED_NEW_ARRAY_RANGE.cpp b/vm/mterp/c_notaint/OP_FILLED_NEW_ARRAY_RANGE.cpp
new file mode 100644
index 0000000..06c3a79
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_FILLED_NEW_ARRAY_RANGE.cpp
@@ -0,0 +1,3 @@
+HANDLE_OPCODE(OP_FILLED_NEW_ARRAY_RANGE /*{vCCCC..v(CCCC+AA-1)}, class@BBBB*/)
+    GOTO_invoke(filledNewArray, true);
+OP_END
diff --git a/vm/mterp/c_notaint/OP_FILL_ARRAY_DATA.cpp b/vm/mterp/c_notaint/OP_FILL_ARRAY_DATA.cpp
new file mode 100644
index 0000000..678bb32
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_FILL_ARRAY_DATA.cpp
@@ -0,0 +1,27 @@
+HANDLE_OPCODE(OP_FILL_ARRAY_DATA)   /*vAA, +BBBBBBBB*/
+    {
+        const u2* arrayData;
+        s4 offset;
+        ArrayObject* arrayObj;
+
+        EXPORT_PC();
+        vsrc1 = INST_AA(inst);
+        offset = FETCH(1) | (((s4) FETCH(2)) << 16);
+        ILOGV("|fill-array-data v%d +0x%04x", vsrc1, offset);
+        arrayData = pc + offset;       // offset in 16-bit units
+#ifndef NDEBUG
+        if (arrayData < curMethod->insns ||
+            arrayData >= curMethod->insns + dvmGetMethodInsnsSize(curMethod))
+        {
+            /* should have been caught in verifier */
+            dvmThrowInternalError("bad fill array data");
+            GOTO_exceptionThrown();
+        }
+#endif
+        arrayObj = (ArrayObject*) GET_REGISTER(vsrc1);
+        if (!dvmInterpHandleFillArrayData(arrayObj, arrayData)) {
+            GOTO_exceptionThrown();
+        }
+        FINISH(3);
+    }
+OP_END
diff --git a/vm/mterp/c_notaint/OP_FLOAT_TO_DOUBLE.cpp b/vm/mterp/c_notaint/OP_FLOAT_TO_DOUBLE.cpp
new file mode 100644
index 0000000..ea5e7a6
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_FLOAT_TO_DOUBLE.cpp
@@ -0,0 +1,2 @@
+HANDLE_NUMCONV(OP_FLOAT_TO_DOUBLE,      "float-to-double", _FLOAT, _DOUBLE)
+OP_END
diff --git a/vm/mterp/c_notaint/OP_FLOAT_TO_INT.cpp b/vm/mterp/c_notaint/OP_FLOAT_TO_INT.cpp
new file mode 100644
index 0000000..15522f8
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_FLOAT_TO_INT.cpp
@@ -0,0 +1,3 @@
+HANDLE_FLOAT_TO_INT(OP_FLOAT_TO_INT,    "float-to-int",
+    float, _FLOAT, s4, _INT)
+OP_END
diff --git a/vm/mterp/c_notaint/OP_FLOAT_TO_LONG.cpp b/vm/mterp/c_notaint/OP_FLOAT_TO_LONG.cpp
new file mode 100644
index 0000000..03bd30d
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_FLOAT_TO_LONG.cpp
@@ -0,0 +1,3 @@
+HANDLE_FLOAT_TO_INT(OP_FLOAT_TO_LONG,   "float-to-long",
+    float, _FLOAT, s8, _WIDE)
+OP_END
diff --git a/vm/mterp/c_notaint/OP_GOTO.cpp b/vm/mterp/c_notaint/OP_GOTO.cpp
new file mode 100644
index 0000000..0e10384
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_GOTO.cpp
@@ -0,0 +1,11 @@
+HANDLE_OPCODE(OP_GOTO /*+AA*/)
+    vdst = INST_AA(inst);
+    if ((s1)vdst < 0)
+        ILOGV("|goto -0x%02x", -((s1)vdst));
+    else
+        ILOGV("|goto +0x%02x", ((s1)vdst));
+    ILOGV("> branch taken");
+    if ((s1)vdst < 0)
+        PERIODIC_CHECKS((s1)vdst);
+    FINISH((s1)vdst);
+OP_END
diff --git a/vm/mterp/c_notaint/OP_GOTO_16.cpp b/vm/mterp/c_notaint/OP_GOTO_16.cpp
new file mode 100644
index 0000000..f0541fd
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_GOTO_16.cpp
@@ -0,0 +1,14 @@
+HANDLE_OPCODE(OP_GOTO_16 /*+AAAA*/)
+    {
+        s4 offset = (s2) FETCH(1);          /* sign-extend next code unit */
+
+        if (offset < 0)
+            ILOGV("|goto/16 -0x%04x", -offset);
+        else
+            ILOGV("|goto/16 +0x%04x", offset);
+        ILOGV("> branch taken");
+        if (offset < 0)
+            PERIODIC_CHECKS(offset);
+        FINISH(offset);
+    }
+OP_END
diff --git a/vm/mterp/c_notaint/OP_GOTO_32.cpp b/vm/mterp/c_notaint/OP_GOTO_32.cpp
new file mode 100644
index 0000000..1b1815c
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_GOTO_32.cpp
@@ -0,0 +1,15 @@
+HANDLE_OPCODE(OP_GOTO_32 /*+AAAAAAAA*/)
+    {
+        s4 offset = FETCH(1);               /* low-order 16 bits */
+        offset |= ((s4) FETCH(2)) << 16;    /* high-order 16 bits */
+
+        if (offset < 0)
+            ILOGV("|goto/32 -0x%08x", -offset);
+        else
+            ILOGV("|goto/32 +0x%08x", offset);
+        ILOGV("> branch taken");
+        if (offset <= 0)    /* allowed to branch to self */
+            PERIODIC_CHECKS(offset);
+        FINISH(offset);
+    }
+OP_END
diff --git a/vm/mterp/c_notaint/OP_IF_EQ.cpp b/vm/mterp/c_notaint/OP_IF_EQ.cpp
new file mode 100644
index 0000000..2c3b9b5
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_IF_EQ.cpp
@@ -0,0 +1,2 @@
+HANDLE_OP_IF_XX(OP_IF_EQ, "eq", ==)
+OP_END
diff --git a/vm/mterp/c_notaint/OP_IF_EQZ.cpp b/vm/mterp/c_notaint/OP_IF_EQZ.cpp
new file mode 100644
index 0000000..d2dd1aa
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_IF_EQZ.cpp
@@ -0,0 +1,2 @@
+HANDLE_OP_IF_XXZ(OP_IF_EQZ, "eqz", ==)
+OP_END
diff --git a/vm/mterp/c_notaint/OP_IF_GE.cpp b/vm/mterp/c_notaint/OP_IF_GE.cpp
new file mode 100644
index 0000000..8aa85c4
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_IF_GE.cpp
@@ -0,0 +1,2 @@
+HANDLE_OP_IF_XX(OP_IF_GE, "ge", >=)
+OP_END
diff --git a/vm/mterp/c_notaint/OP_IF_GEZ.cpp b/vm/mterp/c_notaint/OP_IF_GEZ.cpp
new file mode 100644
index 0000000..8c4b78a
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_IF_GEZ.cpp
@@ -0,0 +1,2 @@
+HANDLE_OP_IF_XXZ(OP_IF_GEZ, "gez", >=)
+OP_END
diff --git a/vm/mterp/c_notaint/OP_IF_GT.cpp b/vm/mterp/c_notaint/OP_IF_GT.cpp
new file mode 100644
index 0000000..d35eb29
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_IF_GT.cpp
@@ -0,0 +1,2 @@
+HANDLE_OP_IF_XX(OP_IF_GT, "gt", >)
+OP_END
diff --git a/vm/mterp/c_notaint/OP_IF_GTZ.cpp b/vm/mterp/c_notaint/OP_IF_GTZ.cpp
new file mode 100644
index 0000000..63a0073
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_IF_GTZ.cpp
@@ -0,0 +1,2 @@
+HANDLE_OP_IF_XXZ(OP_IF_GTZ, "gtz", >)
+OP_END
diff --git a/vm/mterp/c_notaint/OP_IF_LE.cpp b/vm/mterp/c_notaint/OP_IF_LE.cpp
new file mode 100644
index 0000000..f4b213a
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_IF_LE.cpp
@@ -0,0 +1,2 @@
+HANDLE_OP_IF_XX(OP_IF_LE, "le", <=)
+OP_END
diff --git a/vm/mterp/c_notaint/OP_IF_LEZ.cpp b/vm/mterp/c_notaint/OP_IF_LEZ.cpp
new file mode 100644
index 0000000..1d57a50
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_IF_LEZ.cpp
@@ -0,0 +1,2 @@
+HANDLE_OP_IF_XXZ(OP_IF_LEZ, "lez", <=)
+OP_END
diff --git a/vm/mterp/c_notaint/OP_IF_LT.cpp b/vm/mterp/c_notaint/OP_IF_LT.cpp
new file mode 100644
index 0000000..0233892
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_IF_LT.cpp
@@ -0,0 +1,2 @@
+HANDLE_OP_IF_XX(OP_IF_LT, "lt", <)
+OP_END
diff --git a/vm/mterp/c_notaint/OP_IF_LTZ.cpp b/vm/mterp/c_notaint/OP_IF_LTZ.cpp
new file mode 100644
index 0000000..b4b9be2
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_IF_LTZ.cpp
@@ -0,0 +1,2 @@
+HANDLE_OP_IF_XXZ(OP_IF_LTZ, "ltz", <)
+OP_END
diff --git a/vm/mterp/c_notaint/OP_IF_NE.cpp b/vm/mterp/c_notaint/OP_IF_NE.cpp
new file mode 100644
index 0000000..8da70a5
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_IF_NE.cpp
@@ -0,0 +1,2 @@
+HANDLE_OP_IF_XX(OP_IF_NE, "ne", !=)
+OP_END
diff --git a/vm/mterp/c_notaint/OP_IF_NEZ.cpp b/vm/mterp/c_notaint/OP_IF_NEZ.cpp
new file mode 100644
index 0000000..209e836
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_IF_NEZ.cpp
@@ -0,0 +1,2 @@
+HANDLE_OP_IF_XXZ(OP_IF_NEZ, "nez", !=)
+OP_END
diff --git a/vm/mterp/c_notaint/OP_IGET.cpp b/vm/mterp/c_notaint/OP_IGET.cpp
new file mode 100644
index 0000000..c6333e5
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_IGET.cpp
@@ -0,0 +1,2 @@
+HANDLE_IGET_X(OP_IGET,                  "", Int, )
+OP_END
diff --git a/vm/mterp/c_notaint/OP_IGET_BOOLEAN.cpp b/vm/mterp/c_notaint/OP_IGET_BOOLEAN.cpp
new file mode 100644
index 0000000..a5a47be
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_IGET_BOOLEAN.cpp
@@ -0,0 +1,2 @@
+HANDLE_IGET_X(OP_IGET_BOOLEAN,          "", Int, )
+OP_END
diff --git a/vm/mterp/c_notaint/OP_IGET_BYTE.cpp b/vm/mterp/c_notaint/OP_IGET_BYTE.cpp
new file mode 100644
index 0000000..647f311
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_IGET_BYTE.cpp
@@ -0,0 +1,2 @@
+HANDLE_IGET_X(OP_IGET_BYTE,             "", Int, )
+OP_END
diff --git a/vm/mterp/c_notaint/OP_IGET_CHAR.cpp b/vm/mterp/c_notaint/OP_IGET_CHAR.cpp
new file mode 100644
index 0000000..9a8adb0
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_IGET_CHAR.cpp
@@ -0,0 +1,2 @@
+HANDLE_IGET_X(OP_IGET_CHAR,             "", Int, )
+OP_END
diff --git a/vm/mterp/c_notaint/OP_IGET_OBJECT.cpp b/vm/mterp/c_notaint/OP_IGET_OBJECT.cpp
new file mode 100644
index 0000000..03c9e50
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_IGET_OBJECT.cpp
@@ -0,0 +1,2 @@
+HANDLE_IGET_X(OP_IGET_OBJECT,           "-object", Object, _AS_OBJECT)
+OP_END
diff --git a/vm/mterp/c_notaint/OP_IGET_OBJECT_QUICK.cpp b/vm/mterp/c_notaint/OP_IGET_OBJECT_QUICK.cpp
new file mode 100644
index 0000000..2ac3a54
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_IGET_OBJECT_QUICK.cpp
@@ -0,0 +1,2 @@
+HANDLE_IGET_X_QUICK(OP_IGET_OBJECT_QUICK,   "-object", Object, _AS_OBJECT)
+OP_END
diff --git a/vm/mterp/c_notaint/OP_IGET_OBJECT_VOLATILE.cpp b/vm/mterp/c_notaint/OP_IGET_OBJECT_VOLATILE.cpp
new file mode 100644
index 0000000..3577552
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_IGET_OBJECT_VOLATILE.cpp
@@ -0,0 +1,2 @@
+HANDLE_IGET_X(OP_IGET_OBJECT_VOLATILE,  "-object-volatile", ObjectVolatile, _AS_OBJECT)
+OP_END
diff --git a/vm/mterp/c_notaint/OP_IGET_QUICK.cpp b/vm/mterp/c_notaint/OP_IGET_QUICK.cpp
new file mode 100644
index 0000000..b5724cc
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_IGET_QUICK.cpp
@@ -0,0 +1,2 @@
+HANDLE_IGET_X_QUICK(OP_IGET_QUICK,          "", Int, )
+OP_END
diff --git a/vm/mterp/c_notaint/OP_IGET_SHORT.cpp b/vm/mterp/c_notaint/OP_IGET_SHORT.cpp
new file mode 100644
index 0000000..3e77789
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_IGET_SHORT.cpp
@@ -0,0 +1,2 @@
+HANDLE_IGET_X(OP_IGET_SHORT,            "", Int, )
+OP_END
diff --git a/vm/mterp/c_notaint/OP_IGET_VOLATILE.cpp b/vm/mterp/c_notaint/OP_IGET_VOLATILE.cpp
new file mode 100644
index 0000000..7a3be56
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_IGET_VOLATILE.cpp
@@ -0,0 +1,2 @@
+HANDLE_IGET_X(OP_IGET_VOLATILE,         "-volatile", IntVolatile, )
+OP_END
diff --git a/vm/mterp/c_notaint/OP_IGET_WIDE.cpp b/vm/mterp/c_notaint/OP_IGET_WIDE.cpp
new file mode 100644
index 0000000..cb1fcca
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_IGET_WIDE.cpp
@@ -0,0 +1,2 @@
+HANDLE_IGET_X(OP_IGET_WIDE,             "-wide", Long, _WIDE)
+OP_END
diff --git a/vm/mterp/c_notaint/OP_IGET_WIDE_QUICK.cpp b/vm/mterp/c_notaint/OP_IGET_WIDE_QUICK.cpp
new file mode 100644
index 0000000..adb4fc1
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_IGET_WIDE_QUICK.cpp
@@ -0,0 +1,2 @@
+HANDLE_IGET_X_QUICK(OP_IGET_WIDE_QUICK,     "-wide", Long, _WIDE)
+OP_END
diff --git a/vm/mterp/c_notaint/OP_IGET_WIDE_VOLATILE.cpp b/vm/mterp/c_notaint/OP_IGET_WIDE_VOLATILE.cpp
new file mode 100644
index 0000000..a080823
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_IGET_WIDE_VOLATILE.cpp
@@ -0,0 +1,2 @@
+HANDLE_IGET_X(OP_IGET_WIDE_VOLATILE,    "-wide-volatile", LongVolatile, _WIDE)
+OP_END
diff --git a/vm/mterp/c_notaint/OP_INSTANCE_OF.cpp b/vm/mterp/c_notaint/OP_INSTANCE_OF.cpp
new file mode 100644
index 0000000..8b8f9d3
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_INSTANCE_OF.cpp
@@ -0,0 +1,30 @@
+HANDLE_OPCODE(OP_INSTANCE_OF /*vA, vB, class@CCCC*/)
+    {
+        ClassObject* clazz;
+        Object* obj;
+
+        vdst = INST_A(inst);
+        vsrc1 = INST_B(inst);   /* object to check */
+        ref = FETCH(1);         /* class to check against */
+        ILOGV("|instance-of v%d,v%d,class@0x%04x", vdst, vsrc1, ref);
+
+        obj = (Object*)GET_REGISTER(vsrc1);
+        if (obj == NULL) {
+            SET_REGISTER(vdst, 0);
+        } else {
+#if defined(WITH_EXTRA_OBJECT_VALIDATION)
+            if (!checkForNullExportPC(obj, fp, pc))
+                GOTO_exceptionThrown();
+#endif
+            clazz = dvmDexGetResolvedClass(methodClassDex, ref);
+            if (clazz == NULL) {
+                EXPORT_PC();
+                clazz = dvmResolveClass(curMethod->clazz, ref, true);
+                if (clazz == NULL)
+                    GOTO_exceptionThrown();
+            }
+            SET_REGISTER(vdst, dvmInstanceof(obj->clazz, clazz));
+        }
+    }
+    FINISH(2);
+OP_END
diff --git a/vm/mterp/c_notaint/OP_INT_TO_BYTE.cpp b/vm/mterp/c_notaint/OP_INT_TO_BYTE.cpp
new file mode 100644
index 0000000..ea75747
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_INT_TO_BYTE.cpp
@@ -0,0 +1,2 @@
+HANDLE_INT_TO_SMALL(OP_INT_TO_BYTE,     "byte", s1)
+OP_END
diff --git a/vm/mterp/c_notaint/OP_INT_TO_CHAR.cpp b/vm/mterp/c_notaint/OP_INT_TO_CHAR.cpp
new file mode 100644
index 0000000..45ae0df
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_INT_TO_CHAR.cpp
@@ -0,0 +1,2 @@
+HANDLE_INT_TO_SMALL(OP_INT_TO_CHAR,     "char", u2)
+OP_END
diff --git a/vm/mterp/c_notaint/OP_INT_TO_DOUBLE.cpp b/vm/mterp/c_notaint/OP_INT_TO_DOUBLE.cpp
new file mode 100644
index 0000000..624c702
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_INT_TO_DOUBLE.cpp
@@ -0,0 +1,2 @@
+HANDLE_NUMCONV(OP_INT_TO_DOUBLE,        "int-to-double", _INT, _DOUBLE)
+OP_END
diff --git a/vm/mterp/c_notaint/OP_INT_TO_FLOAT.cpp b/vm/mterp/c_notaint/OP_INT_TO_FLOAT.cpp
new file mode 100644
index 0000000..fd15199
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_INT_TO_FLOAT.cpp
@@ -0,0 +1,2 @@
+HANDLE_NUMCONV(OP_INT_TO_FLOAT,         "int-to-float", _INT, _FLOAT)
+OP_END
diff --git a/vm/mterp/c_notaint/OP_INT_TO_LONG.cpp b/vm/mterp/c_notaint/OP_INT_TO_LONG.cpp
new file mode 100644
index 0000000..8bc4223
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_INT_TO_LONG.cpp
@@ -0,0 +1,2 @@
+HANDLE_NUMCONV(OP_INT_TO_LONG,          "int-to-long", _INT, _WIDE)
+OP_END
diff --git a/vm/mterp/c_notaint/OP_INT_TO_SHORT.cpp b/vm/mterp/c_notaint/OP_INT_TO_SHORT.cpp
new file mode 100644
index 0000000..0f06739
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_INT_TO_SHORT.cpp
@@ -0,0 +1,2 @@
+HANDLE_INT_TO_SMALL(OP_INT_TO_SHORT,    "short", s2)    /* want sign bit */
+OP_END
diff --git a/vm/mterp/c_notaint/OP_INVOKE_DIRECT.cpp b/vm/mterp/c_notaint/OP_INVOKE_DIRECT.cpp
new file mode 100644
index 0000000..58cfe5b
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_INVOKE_DIRECT.cpp
@@ -0,0 +1,3 @@
+HANDLE_OPCODE(OP_INVOKE_DIRECT /*vB, {vD, vE, vF, vG, vA}, meth@CCCC*/)
+    GOTO_invoke(invokeDirect, false);
+OP_END
diff --git a/vm/mterp/c_notaint/OP_INVOKE_DIRECT_RANGE.cpp b/vm/mterp/c_notaint/OP_INVOKE_DIRECT_RANGE.cpp
new file mode 100644
index 0000000..9877bbe
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_INVOKE_DIRECT_RANGE.cpp
@@ -0,0 +1,3 @@
+HANDLE_OPCODE(OP_INVOKE_DIRECT_RANGE /*{vCCCC..v(CCCC+AA-1)}, meth@BBBB*/)
+    GOTO_invoke(invokeDirect, true);
+OP_END
diff --git a/vm/mterp/c_notaint/OP_INVOKE_INTERFACE.cpp b/vm/mterp/c_notaint/OP_INVOKE_INTERFACE.cpp
new file mode 100644
index 0000000..9c639d5
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_INVOKE_INTERFACE.cpp
@@ -0,0 +1,3 @@
+HANDLE_OPCODE(OP_INVOKE_INTERFACE /*vB, {vD, vE, vF, vG, vA}, meth@CCCC*/)
+    GOTO_invoke(invokeInterface, false);
+OP_END
diff --git a/vm/mterp/c_notaint/OP_INVOKE_INTERFACE_RANGE.cpp b/vm/mterp/c_notaint/OP_INVOKE_INTERFACE_RANGE.cpp
new file mode 100644
index 0000000..6244c9e
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_INVOKE_INTERFACE_RANGE.cpp
@@ -0,0 +1,3 @@
+HANDLE_OPCODE(OP_INVOKE_INTERFACE_RANGE /*{vCCCC..v(CCCC+AA-1)}, meth@BBBB*/)
+    GOTO_invoke(invokeInterface, true);
+OP_END
diff --git a/vm/mterp/c_notaint/OP_INVOKE_OBJECT_INIT_RANGE.cpp b/vm/mterp/c_notaint/OP_INVOKE_OBJECT_INIT_RANGE.cpp
new file mode 100644
index 0000000..a22446f
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_INVOKE_OBJECT_INIT_RANGE.cpp
@@ -0,0 +1,29 @@
+HANDLE_OPCODE(OP_INVOKE_OBJECT_INIT_RANGE /*{vCCCC..v(CCCC+AA-1)}, meth@BBBB*/)
+    {
+        Object* obj;
+
+        vsrc1 = FETCH(2);               /* reg number of "this" pointer */
+        obj = GET_REGISTER_AS_OBJECT(vsrc1);
+
+        if (!checkForNullExportPC(obj, fp, pc))
+            GOTO_exceptionThrown();
+
+        /*
+         * The object should be marked "finalizable" when Object.<init>
+         * completes normally.  We're going to assume it does complete
+         * (by virtue of being nothing but a return-void) and set it now.
+         */
+        if (IS_CLASS_FLAG_SET(obj->clazz, CLASS_ISFINALIZABLE)) {
+            EXPORT_PC();
+            dvmSetFinalizable(obj);
+            if (dvmGetException(self))
+                GOTO_exceptionThrown();
+        }
+
+        if (self->interpBreak.ctl.subMode & kSubModeDebuggerActive) {
+            /* behave like OP_INVOKE_DIRECT_RANGE */
+            GOTO_invoke(invokeDirect, true);
+        }
+        FINISH(3);
+    }
+OP_END
diff --git a/vm/mterp/c_notaint/OP_INVOKE_STATIC.cpp b/vm/mterp/c_notaint/OP_INVOKE_STATIC.cpp
new file mode 100644
index 0000000..81f3d62
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_INVOKE_STATIC.cpp
@@ -0,0 +1,3 @@
+HANDLE_OPCODE(OP_INVOKE_STATIC /*vB, {vD, vE, vF, vG, vA}, meth@CCCC*/)
+    GOTO_invoke(invokeStatic, false);
+OP_END
diff --git a/vm/mterp/c_notaint/OP_INVOKE_STATIC_RANGE.cpp b/vm/mterp/c_notaint/OP_INVOKE_STATIC_RANGE.cpp
new file mode 100644
index 0000000..3fc4c35
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_INVOKE_STATIC_RANGE.cpp
@@ -0,0 +1,3 @@
+HANDLE_OPCODE(OP_INVOKE_STATIC_RANGE /*{vCCCC..v(CCCC+AA-1)}, meth@BBBB*/)
+    GOTO_invoke(invokeStatic, true);
+OP_END
diff --git a/vm/mterp/c_notaint/OP_INVOKE_SUPER.cpp b/vm/mterp/c_notaint/OP_INVOKE_SUPER.cpp
new file mode 100644
index 0000000..e7baea4
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_INVOKE_SUPER.cpp
@@ -0,0 +1,3 @@
+HANDLE_OPCODE(OP_INVOKE_SUPER /*vB, {vD, vE, vF, vG, vA}, meth@CCCC*/)
+    GOTO_invoke(invokeSuper, false);
+OP_END
diff --git a/vm/mterp/c_notaint/OP_INVOKE_SUPER_QUICK.cpp b/vm/mterp/c_notaint/OP_INVOKE_SUPER_QUICK.cpp
new file mode 100644
index 0000000..b66e033
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_INVOKE_SUPER_QUICK.cpp
@@ -0,0 +1,3 @@
+HANDLE_OPCODE(OP_INVOKE_SUPER_QUICK /*vB, {vD, vE, vF, vG, vA}, meth@CCCC*/)
+    GOTO_invoke(invokeSuperQuick, false);
+OP_END
diff --git a/vm/mterp/c_notaint/OP_INVOKE_SUPER_QUICK_RANGE.cpp b/vm/mterp/c_notaint/OP_INVOKE_SUPER_QUICK_RANGE.cpp
new file mode 100644
index 0000000..879497b
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_INVOKE_SUPER_QUICK_RANGE.cpp
@@ -0,0 +1,3 @@
+HANDLE_OPCODE(OP_INVOKE_SUPER_QUICK_RANGE /*{vCCCC..v(CCCC+AA-1)}, meth@BBBB*/)
+    GOTO_invoke(invokeSuperQuick, true);
+OP_END
diff --git a/vm/mterp/c_notaint/OP_INVOKE_SUPER_RANGE.cpp b/vm/mterp/c_notaint/OP_INVOKE_SUPER_RANGE.cpp
new file mode 100644
index 0000000..724e3a0
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_INVOKE_SUPER_RANGE.cpp
@@ -0,0 +1,3 @@
+HANDLE_OPCODE(OP_INVOKE_SUPER_RANGE /*{vCCCC..v(CCCC+AA-1)}, meth@BBBB*/)
+    GOTO_invoke(invokeSuper, true);
+OP_END
diff --git a/vm/mterp/c_notaint/OP_INVOKE_VIRTUAL.cpp b/vm/mterp/c_notaint/OP_INVOKE_VIRTUAL.cpp
new file mode 100644
index 0000000..29a4560
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_INVOKE_VIRTUAL.cpp
@@ -0,0 +1,3 @@
+HANDLE_OPCODE(OP_INVOKE_VIRTUAL /*vB, {vD, vE, vF, vG, vA}, meth@CCCC*/)
+    GOTO_invoke(invokeVirtual, false);
+OP_END
diff --git a/vm/mterp/c_notaint/OP_INVOKE_VIRTUAL_QUICK.cpp b/vm/mterp/c_notaint/OP_INVOKE_VIRTUAL_QUICK.cpp
new file mode 100644
index 0000000..244fed4
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_INVOKE_VIRTUAL_QUICK.cpp
@@ -0,0 +1,3 @@
+HANDLE_OPCODE(OP_INVOKE_VIRTUAL_QUICK /*vB, {vD, vE, vF, vG, vA}, meth@CCCC*/)
+    GOTO_invoke(invokeVirtualQuick, false);
+OP_END
diff --git a/vm/mterp/c_notaint/OP_INVOKE_VIRTUAL_QUICK_RANGE.cpp b/vm/mterp/c_notaint/OP_INVOKE_VIRTUAL_QUICK_RANGE.cpp
new file mode 100644
index 0000000..9adb4ad
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_INVOKE_VIRTUAL_QUICK_RANGE.cpp
@@ -0,0 +1,3 @@
+HANDLE_OPCODE(OP_INVOKE_VIRTUAL_QUICK_RANGE/*{vCCCC..v(CCCC+AA-1)}, meth@BBBB*/)
+    GOTO_invoke(invokeVirtualQuick, true);
+OP_END
diff --git a/vm/mterp/c_notaint/OP_INVOKE_VIRTUAL_RANGE.cpp b/vm/mterp/c_notaint/OP_INVOKE_VIRTUAL_RANGE.cpp
new file mode 100644
index 0000000..94671ae
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_INVOKE_VIRTUAL_RANGE.cpp
@@ -0,0 +1,3 @@
+HANDLE_OPCODE(OP_INVOKE_VIRTUAL_RANGE /*{vCCCC..v(CCCC+AA-1)}, meth@BBBB*/)
+    GOTO_invoke(invokeVirtual, true);
+OP_END
diff --git a/vm/mterp/c_notaint/OP_IPUT.cpp b/vm/mterp/c_notaint/OP_IPUT.cpp
new file mode 100644
index 0000000..9d503ef
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_IPUT.cpp
@@ -0,0 +1,2 @@
+HANDLE_IPUT_X(OP_IPUT,                  "", Int, )
+OP_END
diff --git a/vm/mterp/c_notaint/OP_IPUT_BOOLEAN.cpp b/vm/mterp/c_notaint/OP_IPUT_BOOLEAN.cpp
new file mode 100644
index 0000000..7fe4929
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_IPUT_BOOLEAN.cpp
@@ -0,0 +1,2 @@
+HANDLE_IPUT_X(OP_IPUT_BOOLEAN,          "", Int, )
+OP_END
diff --git a/vm/mterp/c_notaint/OP_IPUT_BYTE.cpp b/vm/mterp/c_notaint/OP_IPUT_BYTE.cpp
new file mode 100644
index 0000000..8a49fb7
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_IPUT_BYTE.cpp
@@ -0,0 +1,2 @@
+HANDLE_IPUT_X(OP_IPUT_BYTE,             "", Int, )
+OP_END
diff --git a/vm/mterp/c_notaint/OP_IPUT_CHAR.cpp b/vm/mterp/c_notaint/OP_IPUT_CHAR.cpp
new file mode 100644
index 0000000..b2812c2
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_IPUT_CHAR.cpp
@@ -0,0 +1,2 @@
+HANDLE_IPUT_X(OP_IPUT_CHAR,             "", Int, )
+OP_END
diff --git a/vm/mterp/c_notaint/OP_IPUT_OBJECT.cpp b/vm/mterp/c_notaint/OP_IPUT_OBJECT.cpp
new file mode 100644
index 0000000..dbfb5ab
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_IPUT_OBJECT.cpp
@@ -0,0 +1,13 @@
+/*
+ * The VM spec says we should verify that the reference being stored into
+ * the field is assignment compatible.  In practice, many popular VMs don't
+ * do this because it slows down a very common operation.  It's not so bad
+ * for us, since "dexopt" quickens it whenever possible, but it's still an
+ * issue.
+ *
+ * To make this spec-complaint, we'd need to add a ClassObject pointer to
+ * the Field struct, resolve the field's type descriptor at link or class
+ * init time, and then verify the type here.
+ */
+HANDLE_IPUT_X(OP_IPUT_OBJECT,           "-object", Object, _AS_OBJECT)
+OP_END
diff --git a/vm/mterp/c_notaint/OP_IPUT_OBJECT_QUICK.cpp b/vm/mterp/c_notaint/OP_IPUT_OBJECT_QUICK.cpp
new file mode 100644
index 0000000..8670188
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_IPUT_OBJECT_QUICK.cpp
@@ -0,0 +1,2 @@
+HANDLE_IPUT_X_QUICK(OP_IPUT_OBJECT_QUICK,   "-object", Object, _AS_OBJECT)
+OP_END
diff --git a/vm/mterp/c_notaint/OP_IPUT_OBJECT_VOLATILE.cpp b/vm/mterp/c_notaint/OP_IPUT_OBJECT_VOLATILE.cpp
new file mode 100644
index 0000000..cce63c1
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_IPUT_OBJECT_VOLATILE.cpp
@@ -0,0 +1,2 @@
+HANDLE_IPUT_X(OP_IPUT_OBJECT_VOLATILE,  "-object-volatile", ObjectVolatile, _AS_OBJECT)
+OP_END
diff --git a/vm/mterp/c_notaint/OP_IPUT_QUICK.cpp b/vm/mterp/c_notaint/OP_IPUT_QUICK.cpp
new file mode 100644
index 0000000..483b9b1
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_IPUT_QUICK.cpp
@@ -0,0 +1,2 @@
+HANDLE_IPUT_X_QUICK(OP_IPUT_QUICK,          "", Int, )
+OP_END
diff --git a/vm/mterp/c_notaint/OP_IPUT_SHORT.cpp b/vm/mterp/c_notaint/OP_IPUT_SHORT.cpp
new file mode 100644
index 0000000..0a63ebc
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_IPUT_SHORT.cpp
@@ -0,0 +1,2 @@
+HANDLE_IPUT_X(OP_IPUT_SHORT,            "", Int, )
+OP_END
diff --git a/vm/mterp/c_notaint/OP_IPUT_VOLATILE.cpp b/vm/mterp/c_notaint/OP_IPUT_VOLATILE.cpp
new file mode 100644
index 0000000..814379e
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_IPUT_VOLATILE.cpp
@@ -0,0 +1,2 @@
+HANDLE_IPUT_X(OP_IPUT_VOLATILE,         "-volatile", IntVolatile, )
+OP_END
diff --git a/vm/mterp/c_notaint/OP_IPUT_WIDE.cpp b/vm/mterp/c_notaint/OP_IPUT_WIDE.cpp
new file mode 100644
index 0000000..bb4926c
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_IPUT_WIDE.cpp
@@ -0,0 +1,2 @@
+HANDLE_IPUT_X(OP_IPUT_WIDE,             "-wide", Long, _WIDE)
+OP_END
diff --git a/vm/mterp/c_notaint/OP_IPUT_WIDE_QUICK.cpp b/vm/mterp/c_notaint/OP_IPUT_WIDE_QUICK.cpp
new file mode 100644
index 0000000..691630b
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_IPUT_WIDE_QUICK.cpp
@@ -0,0 +1,2 @@
+HANDLE_IPUT_X_QUICK(OP_IPUT_WIDE_QUICK,     "-wide", Long, _WIDE)
+OP_END
diff --git a/vm/mterp/c_notaint/OP_IPUT_WIDE_VOLATILE.cpp b/vm/mterp/c_notaint/OP_IPUT_WIDE_VOLATILE.cpp
new file mode 100644
index 0000000..d888b4a
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_IPUT_WIDE_VOLATILE.cpp
@@ -0,0 +1,2 @@
+HANDLE_IPUT_X(OP_IPUT_WIDE_VOLATILE,    "-wide-volatile", LongVolatile, _WIDE)
+OP_END
diff --git a/vm/mterp/c_notaint/OP_LONG_TO_DOUBLE.cpp b/vm/mterp/c_notaint/OP_LONG_TO_DOUBLE.cpp
new file mode 100644
index 0000000..91b5eb2
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_LONG_TO_DOUBLE.cpp
@@ -0,0 +1,2 @@
+HANDLE_NUMCONV(OP_LONG_TO_DOUBLE,       "long-to-double", _WIDE, _DOUBLE)
+OP_END
diff --git a/vm/mterp/c_notaint/OP_LONG_TO_FLOAT.cpp b/vm/mterp/c_notaint/OP_LONG_TO_FLOAT.cpp
new file mode 100644
index 0000000..ff1f5fb
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_LONG_TO_FLOAT.cpp
@@ -0,0 +1,2 @@
+HANDLE_NUMCONV(OP_LONG_TO_FLOAT,        "long-to-float", _WIDE, _FLOAT)
+OP_END
diff --git a/vm/mterp/c_notaint/OP_LONG_TO_INT.cpp b/vm/mterp/c_notaint/OP_LONG_TO_INT.cpp
new file mode 100644
index 0000000..87c9a2e
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_LONG_TO_INT.cpp
@@ -0,0 +1,2 @@
+HANDLE_NUMCONV(OP_LONG_TO_INT,          "long-to-int", _WIDE, _INT)
+OP_END
diff --git a/vm/mterp/c_notaint/OP_MONITOR_ENTER.cpp b/vm/mterp/c_notaint/OP_MONITOR_ENTER.cpp
new file mode 100644
index 0000000..976aab3
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_MONITOR_ENTER.cpp
@@ -0,0 +1,16 @@
+HANDLE_OPCODE(OP_MONITOR_ENTER /*vAA*/)
+    {
+        Object* obj;
+
+        vsrc1 = INST_AA(inst);
+        ILOGV("|monitor-enter v%d %s(0x%08x)",
+            vsrc1, kSpacing+6, GET_REGISTER(vsrc1));
+        obj = (Object*)GET_REGISTER(vsrc1);
+        if (!checkForNullExportPC(obj, fp, pc))
+            GOTO_exceptionThrown();
+        ILOGV("+ locking %p %s", obj, obj->clazz->descriptor);
+        EXPORT_PC();    /* need for precise GC */
+        dvmLockObject(self, obj);
+    }
+    FINISH(1);
+OP_END
diff --git a/vm/mterp/c_notaint/OP_MONITOR_EXIT.cpp b/vm/mterp/c_notaint/OP_MONITOR_EXIT.cpp
new file mode 100644
index 0000000..c26585d
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_MONITOR_EXIT.cpp
@@ -0,0 +1,30 @@
+HANDLE_OPCODE(OP_MONITOR_EXIT /*vAA*/)
+    {
+        Object* obj;
+
+        EXPORT_PC();
+
+        vsrc1 = INST_AA(inst);
+        ILOGV("|monitor-exit v%d %s(0x%08x)",
+            vsrc1, kSpacing+5, GET_REGISTER(vsrc1));
+        obj = (Object*)GET_REGISTER(vsrc1);
+        if (!checkForNull(obj)) {
+            /*
+             * The exception needs to be processed at the *following*
+             * instruction, not the current instruction (see the Dalvik
+             * spec).  Because we're jumping to an exception handler,
+             * we're not actually at risk of skipping an instruction
+             * by doing so.
+             */
+            ADJUST_PC(1);           /* monitor-exit width is 1 */
+            GOTO_exceptionThrown();
+        }
+        ILOGV("+ unlocking %p %s", obj, obj->clazz->descriptor);
+        if (!dvmUnlockObject(self, obj)) {
+            assert(dvmCheckException(self));
+            ADJUST_PC(1);
+            GOTO_exceptionThrown();
+        }
+    }
+    FINISH(1);
+OP_END
diff --git a/vm/mterp/c_notaint/OP_MOVE.cpp b/vm/mterp/c_notaint/OP_MOVE.cpp
new file mode 100644
index 0000000..6666199
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_MOVE.cpp
@@ -0,0 +1,9 @@
+HANDLE_OPCODE($opcode /*vA, vB*/)
+    vdst = INST_A(inst);
+    vsrc1 = INST_B(inst);
+    ILOGV("|move%s v%d,v%d %s(v%d=0x%08x)",
+        (INST_INST(inst) == OP_MOVE) ? "" : "-object", vdst, vsrc1,
+        kSpacing, vdst, GET_REGISTER(vsrc1));
+    SET_REGISTER(vdst, GET_REGISTER(vsrc1));
+    FINISH(1);
+OP_END
diff --git a/vm/mterp/c_notaint/OP_MOVE_16.cpp b/vm/mterp/c_notaint/OP_MOVE_16.cpp
new file mode 100644
index 0000000..53af5d5
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_MOVE_16.cpp
@@ -0,0 +1,9 @@
+HANDLE_OPCODE($opcode /*vAAAA, vBBBB*/)
+    vdst = FETCH(1);
+    vsrc1 = FETCH(2);
+    ILOGV("|move%s/16 v%d,v%d %s(v%d=0x%08x)",
+        (INST_INST(inst) == OP_MOVE_16) ? "" : "-object", vdst, vsrc1,
+        kSpacing, vdst, GET_REGISTER(vsrc1));
+    SET_REGISTER(vdst, GET_REGISTER(vsrc1));
+    FINISH(3);
+OP_END
diff --git a/vm/mterp/c_notaint/OP_MOVE_EXCEPTION.cpp b/vm/mterp/c_notaint/OP_MOVE_EXCEPTION.cpp
new file mode 100644
index 0000000..86587ca
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_MOVE_EXCEPTION.cpp
@@ -0,0 +1,8 @@
+HANDLE_OPCODE(OP_MOVE_EXCEPTION /*vAA*/)
+    vdst = INST_AA(inst);
+    ILOGV("|move-exception v%d", vdst);
+    assert(self->exception != NULL);
+    SET_REGISTER(vdst, (u4)self->exception);
+    dvmClearException(self);
+    FINISH(1);
+OP_END
diff --git a/vm/mterp/c_notaint/OP_MOVE_FROM16.cpp b/vm/mterp/c_notaint/OP_MOVE_FROM16.cpp
new file mode 100644
index 0000000..59fc285
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_MOVE_FROM16.cpp
@@ -0,0 +1,9 @@
+HANDLE_OPCODE($opcode /*vAA, vBBBB*/)
+    vdst = INST_AA(inst);
+    vsrc1 = FETCH(1);
+    ILOGV("|move%s/from16 v%d,v%d %s(v%d=0x%08x)",
+        (INST_INST(inst) == OP_MOVE_FROM16) ? "" : "-object", vdst, vsrc1,
+        kSpacing, vdst, GET_REGISTER(vsrc1));
+    SET_REGISTER(vdst, GET_REGISTER(vsrc1));
+    FINISH(2);
+OP_END
diff --git a/vm/mterp/c_notaint/OP_MOVE_OBJECT.cpp b/vm/mterp/c_notaint/OP_MOVE_OBJECT.cpp
new file mode 100644
index 0000000..579095f
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_MOVE_OBJECT.cpp
@@ -0,0 +1 @@
+%include "c/OP_MOVE.cpp"
diff --git a/vm/mterp/c_notaint/OP_MOVE_OBJECT_16.cpp b/vm/mterp/c_notaint/OP_MOVE_OBJECT_16.cpp
new file mode 100644
index 0000000..89cfb77
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_MOVE_OBJECT_16.cpp
@@ -0,0 +1 @@
+%include "c/OP_MOVE_16.cpp"
diff --git a/vm/mterp/c_notaint/OP_MOVE_OBJECT_FROM16.cpp b/vm/mterp/c_notaint/OP_MOVE_OBJECT_FROM16.cpp
new file mode 100644
index 0000000..9451b9e
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_MOVE_OBJECT_FROM16.cpp
@@ -0,0 +1 @@
+%include "c/OP_MOVE_FROM16.cpp"
diff --git a/vm/mterp/c_notaint/OP_MOVE_RESULT.cpp b/vm/mterp/c_notaint/OP_MOVE_RESULT.cpp
new file mode 100644
index 0000000..ddf535b
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_MOVE_RESULT.cpp
@@ -0,0 +1,8 @@
+HANDLE_OPCODE($opcode /*vAA*/)
+    vdst = INST_AA(inst);
+    ILOGV("|move-result%s v%d %s(v%d=0x%08x)",
+         (INST_INST(inst) == OP_MOVE_RESULT) ? "" : "-object",
+         vdst, kSpacing+4, vdst,retval.i);
+    SET_REGISTER(vdst, retval.i);
+    FINISH(1);
+OP_END
diff --git a/vm/mterp/c_notaint/OP_MOVE_RESULT_OBJECT.cpp b/vm/mterp/c_notaint/OP_MOVE_RESULT_OBJECT.cpp
new file mode 100644
index 0000000..08c5c02
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_MOVE_RESULT_OBJECT.cpp
@@ -0,0 +1 @@
+%include "c/OP_MOVE_RESULT.cpp"
diff --git a/vm/mterp/c_notaint/OP_MOVE_RESULT_WIDE.cpp b/vm/mterp/c_notaint/OP_MOVE_RESULT_WIDE.cpp
new file mode 100644
index 0000000..f6ec8d9
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_MOVE_RESULT_WIDE.cpp
@@ -0,0 +1,6 @@
+HANDLE_OPCODE(OP_MOVE_RESULT_WIDE /*vAA*/)
+    vdst = INST_AA(inst);
+    ILOGV("|move-result-wide v%d %s(0x%08llx)", vdst, kSpacing, retval.j);
+    SET_REGISTER_WIDE(vdst, retval.j);
+    FINISH(1);
+OP_END
diff --git a/vm/mterp/c_notaint/OP_MOVE_WIDE.cpp b/vm/mterp/c_notaint/OP_MOVE_WIDE.cpp
new file mode 100644
index 0000000..9ee323d
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_MOVE_WIDE.cpp
@@ -0,0 +1,10 @@
+HANDLE_OPCODE(OP_MOVE_WIDE /*vA, vB*/)
+    /* IMPORTANT: must correctly handle overlapping registers, e.g. both
+     * "move-wide v6, v7" and "move-wide v7, v6" */
+    vdst = INST_A(inst);
+    vsrc1 = INST_B(inst);
+    ILOGV("|move-wide v%d,v%d %s(v%d=0x%08llx)", vdst, vsrc1,
+        kSpacing+5, vdst, GET_REGISTER_WIDE(vsrc1));
+    SET_REGISTER_WIDE(vdst, GET_REGISTER_WIDE(vsrc1));
+    FINISH(1);
+OP_END
diff --git a/vm/mterp/c_notaint/OP_MOVE_WIDE_16.cpp b/vm/mterp/c_notaint/OP_MOVE_WIDE_16.cpp
new file mode 100644
index 0000000..e3d0e16
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_MOVE_WIDE_16.cpp
@@ -0,0 +1,8 @@
+HANDLE_OPCODE(OP_MOVE_WIDE_16 /*vAAAA, vBBBB*/)
+    vdst = FETCH(1);
+    vsrc1 = FETCH(2);
+    ILOGV("|move-wide/16 v%d,v%d %s(v%d=0x%08llx)", vdst, vsrc1,
+        kSpacing+8, vdst, GET_REGISTER_WIDE(vsrc1));
+    SET_REGISTER_WIDE(vdst, GET_REGISTER_WIDE(vsrc1));
+    FINISH(3);
+OP_END
diff --git a/vm/mterp/c_notaint/OP_MOVE_WIDE_FROM16.cpp b/vm/mterp/c_notaint/OP_MOVE_WIDE_FROM16.cpp
new file mode 100644
index 0000000..cdbaa2e
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_MOVE_WIDE_FROM16.cpp
@@ -0,0 +1,8 @@
+HANDLE_OPCODE(OP_MOVE_WIDE_FROM16 /*vAA, vBBBB*/)
+    vdst = INST_AA(inst);
+    vsrc1 = FETCH(1);
+    ILOGV("|move-wide/from16 v%d,v%d  (v%d=0x%08llx)", vdst, vsrc1,
+        vdst, GET_REGISTER_WIDE(vsrc1));
+    SET_REGISTER_WIDE(vdst, GET_REGISTER_WIDE(vsrc1));
+    FINISH(2);
+OP_END
diff --git a/vm/mterp/c_notaint/OP_MUL_DOUBLE.cpp b/vm/mterp/c_notaint/OP_MUL_DOUBLE.cpp
new file mode 100644
index 0000000..3e65efa
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_MUL_DOUBLE.cpp
@@ -0,0 +1,2 @@
+HANDLE_OP_X_DOUBLE(OP_MUL_DOUBLE, "mul", *)
+OP_END
diff --git a/vm/mterp/c_notaint/OP_MUL_DOUBLE_2ADDR.cpp b/vm/mterp/c_notaint/OP_MUL_DOUBLE_2ADDR.cpp
new file mode 100644
index 0000000..905b6a7
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_MUL_DOUBLE_2ADDR.cpp
@@ -0,0 +1,2 @@
+HANDLE_OP_X_DOUBLE_2ADDR(OP_MUL_DOUBLE_2ADDR, "mul", *)
+OP_END
diff --git a/vm/mterp/c_notaint/OP_MUL_FLOAT.cpp b/vm/mterp/c_notaint/OP_MUL_FLOAT.cpp
new file mode 100644
index 0000000..310495c
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_MUL_FLOAT.cpp
@@ -0,0 +1,2 @@
+HANDLE_OP_X_FLOAT(OP_MUL_FLOAT, "mul", *)
+OP_END
diff --git a/vm/mterp/c_notaint/OP_MUL_FLOAT_2ADDR.cpp b/vm/mterp/c_notaint/OP_MUL_FLOAT_2ADDR.cpp
new file mode 100644
index 0000000..03623ca
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_MUL_FLOAT_2ADDR.cpp
@@ -0,0 +1,2 @@
+HANDLE_OP_X_FLOAT_2ADDR(OP_MUL_FLOAT_2ADDR, "mul", *)
+OP_END
diff --git a/vm/mterp/c_notaint/OP_MUL_INT.cpp b/vm/mterp/c_notaint/OP_MUL_INT.cpp
new file mode 100644
index 0000000..b723a29
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_MUL_INT.cpp
@@ -0,0 +1,2 @@
+HANDLE_OP_X_INT(OP_MUL_INT, "mul", *, 0)
+OP_END
diff --git a/vm/mterp/c_notaint/OP_MUL_INT_2ADDR.cpp b/vm/mterp/c_notaint/OP_MUL_INT_2ADDR.cpp
new file mode 100644
index 0000000..f7a179c
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_MUL_INT_2ADDR.cpp
@@ -0,0 +1,2 @@
+HANDLE_OP_X_INT_2ADDR(OP_MUL_INT_2ADDR, "mul", *, 0)
+OP_END
diff --git a/vm/mterp/c_notaint/OP_MUL_INT_LIT16.cpp b/vm/mterp/c_notaint/OP_MUL_INT_LIT16.cpp
new file mode 100644
index 0000000..3a34dbc
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_MUL_INT_LIT16.cpp
@@ -0,0 +1,2 @@
+HANDLE_OP_X_INT_LIT16(OP_MUL_INT_LIT16, "mul", *, 0)
+OP_END
diff --git a/vm/mterp/c_notaint/OP_MUL_INT_LIT8.cpp b/vm/mterp/c_notaint/OP_MUL_INT_LIT8.cpp
new file mode 100644
index 0000000..2ca0036
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_MUL_INT_LIT8.cpp
@@ -0,0 +1,2 @@
+HANDLE_OP_X_INT_LIT8(OP_MUL_INT_LIT8,   "mul", *, 0)
+OP_END
diff --git a/vm/mterp/c_notaint/OP_MUL_LONG.cpp b/vm/mterp/c_notaint/OP_MUL_LONG.cpp
new file mode 100644
index 0000000..768a2ad
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_MUL_LONG.cpp
@@ -0,0 +1,2 @@
+HANDLE_OP_X_LONG(OP_MUL_LONG, "mul", *, 0)
+OP_END
diff --git a/vm/mterp/c_notaint/OP_MUL_LONG_2ADDR.cpp b/vm/mterp/c_notaint/OP_MUL_LONG_2ADDR.cpp
new file mode 100644
index 0000000..1469a22
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_MUL_LONG_2ADDR.cpp
@@ -0,0 +1,2 @@
+HANDLE_OP_X_LONG_2ADDR(OP_MUL_LONG_2ADDR, "mul", *, 0)
+OP_END
diff --git a/vm/mterp/c_notaint/OP_NEG_DOUBLE.cpp b/vm/mterp/c_notaint/OP_NEG_DOUBLE.cpp
new file mode 100644
index 0000000..805082c
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_NEG_DOUBLE.cpp
@@ -0,0 +1,2 @@
+HANDLE_UNOP(OP_NEG_DOUBLE, "neg-double", -, , _DOUBLE)
+OP_END
diff --git a/vm/mterp/c_notaint/OP_NEG_FLOAT.cpp b/vm/mterp/c_notaint/OP_NEG_FLOAT.cpp
new file mode 100644
index 0000000..00e14f5
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_NEG_FLOAT.cpp
@@ -0,0 +1,2 @@
+HANDLE_UNOP(OP_NEG_FLOAT, "neg-float", -, , _FLOAT)
+OP_END
diff --git a/vm/mterp/c_notaint/OP_NEG_INT.cpp b/vm/mterp/c_notaint/OP_NEG_INT.cpp
new file mode 100644
index 0000000..9b97bef
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_NEG_INT.cpp
@@ -0,0 +1,2 @@
+HANDLE_UNOP(OP_NEG_INT, "neg-int", -, , )
+OP_END
diff --git a/vm/mterp/c_notaint/OP_NEG_LONG.cpp b/vm/mterp/c_notaint/OP_NEG_LONG.cpp
new file mode 100644
index 0000000..52d553a
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_NEG_LONG.cpp
@@ -0,0 +1,2 @@
+HANDLE_UNOP(OP_NEG_LONG, "neg-long", -, , _WIDE)
+OP_END
diff --git a/vm/mterp/c_notaint/OP_NEW_ARRAY.cpp b/vm/mterp/c_notaint/OP_NEW_ARRAY.cpp
new file mode 100644
index 0000000..6d6771a
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_NEW_ARRAY.cpp
@@ -0,0 +1,35 @@
+HANDLE_OPCODE(OP_NEW_ARRAY /*vA, vB, class@CCCC*/)
+    {
+        ClassObject* arrayClass;
+        ArrayObject* newArray;
+        s4 length;
+
+        EXPORT_PC();
+
+        vdst = INST_A(inst);
+        vsrc1 = INST_B(inst);       /* length reg */
+        ref = FETCH(1);
+        ILOGV("|new-array v%d,v%d,class@0x%04x  (%d elements)",
+            vdst, vsrc1, ref, (s4) GET_REGISTER(vsrc1));
+        length = (s4) GET_REGISTER(vsrc1);
+        if (length < 0) {
+            dvmThrowNegativeArraySizeException(length);
+            GOTO_exceptionThrown();
+        }
+        arrayClass = dvmDexGetResolvedClass(methodClassDex, ref);
+        if (arrayClass == NULL) {
+            arrayClass = dvmResolveClass(curMethod->clazz, ref, false);
+            if (arrayClass == NULL)
+                GOTO_exceptionThrown();
+        }
+        /* verifier guarantees this is an array class */
+        assert(dvmIsArrayClass(arrayClass));
+        assert(dvmIsClassInitialized(arrayClass));
+
+        newArray = dvmAllocArrayByClass(arrayClass, length, ALLOC_DONT_TRACK);
+        if (newArray == NULL)
+            GOTO_exceptionThrown();
+        SET_REGISTER(vdst, (u4) newArray);
+    }
+    FINISH(2);
+OP_END
diff --git a/vm/mterp/c_notaint/OP_NEW_INSTANCE.cpp b/vm/mterp/c_notaint/OP_NEW_INSTANCE.cpp
new file mode 100644
index 0000000..b0b9c18
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_NEW_INSTANCE.cpp
@@ -0,0 +1,48 @@
+HANDLE_OPCODE(OP_NEW_INSTANCE /*vAA, class@BBBB*/)
+    {
+        ClassObject* clazz;
+        Object* newObj;
+
+        EXPORT_PC();
+
+        vdst = INST_AA(inst);
+        ref = FETCH(1);
+        ILOGV("|new-instance v%d,class@0x%04x", vdst, ref);
+        clazz = dvmDexGetResolvedClass(methodClassDex, ref);
+        if (clazz == NULL) {
+            clazz = dvmResolveClass(curMethod->clazz, ref, false);
+            if (clazz == NULL)
+                GOTO_exceptionThrown();
+        }
+
+        if (!dvmIsClassInitialized(clazz) && !dvmInitClass(clazz))
+            GOTO_exceptionThrown();
+
+#if defined(WITH_JIT)
+        /*
+         * The JIT needs dvmDexGetResolvedClass() to return non-null.
+         * Since we use the portable interpreter to build the trace, this extra
+         * check is not needed for mterp.
+         */
+        if ((self->interpBreak.ctl.subMode & kSubModeJitTraceBuild) &&
+            (!dvmDexGetResolvedClass(methodClassDex, ref))) {
+            /* Class initialization is still ongoing - end the trace */
+            dvmJitEndTraceSelect(self,pc);
+        }
+#endif
+
+        /*
+         * Verifier now tests for interface/abstract class.
+         */
+        //if (dvmIsInterfaceClass(clazz) || dvmIsAbstractClass(clazz)) {
+        //    dvmThrowExceptionWithClassMessage(gDvm.exInstantiationError,
+        //        clazz->descriptor);
+        //    GOTO_exceptionThrown();
+        //}
+        newObj = dvmAllocObject(clazz, ALLOC_DONT_TRACK);
+        if (newObj == NULL)
+            GOTO_exceptionThrown();
+        SET_REGISTER(vdst, (u4) newObj);
+    }
+    FINISH(2);
+OP_END
diff --git a/vm/mterp/c_notaint/OP_NOP.cpp b/vm/mterp/c_notaint/OP_NOP.cpp
new file mode 100644
index 0000000..d9fd744
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_NOP.cpp
@@ -0,0 +1,3 @@
+HANDLE_OPCODE(OP_NOP)
+    FINISH(1);
+OP_END
diff --git a/vm/mterp/c_notaint/OP_NOT_INT.cpp b/vm/mterp/c_notaint/OP_NOT_INT.cpp
new file mode 100644
index 0000000..e585f62
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_NOT_INT.cpp
@@ -0,0 +1,2 @@
+HANDLE_UNOP(OP_NOT_INT, "not-int", , ^ 0xffffffff, )
+OP_END
diff --git a/vm/mterp/c_notaint/OP_NOT_LONG.cpp b/vm/mterp/c_notaint/OP_NOT_LONG.cpp
new file mode 100644
index 0000000..4fb393a
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_NOT_LONG.cpp
@@ -0,0 +1,2 @@
+HANDLE_UNOP(OP_NOT_LONG, "not-long", , ^ 0xffffffffffffffffULL, _WIDE)
+OP_END
diff --git a/vm/mterp/c_notaint/OP_OR_INT.cpp b/vm/mterp/c_notaint/OP_OR_INT.cpp
new file mode 100644
index 0000000..19e397b
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_OR_INT.cpp
@@ -0,0 +1,2 @@
+HANDLE_OP_X_INT(OP_OR_INT,  "or",  |, 0)
+OP_END
diff --git a/vm/mterp/c_notaint/OP_OR_INT_2ADDR.cpp b/vm/mterp/c_notaint/OP_OR_INT_2ADDR.cpp
new file mode 100644
index 0000000..5d5fde0
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_OR_INT_2ADDR.cpp
@@ -0,0 +1,2 @@
+HANDLE_OP_X_INT_2ADDR(OP_OR_INT_2ADDR,  "or", |, 0)
+OP_END
diff --git a/vm/mterp/c_notaint/OP_OR_INT_LIT16.cpp b/vm/mterp/c_notaint/OP_OR_INT_LIT16.cpp
new file mode 100644
index 0000000..5a682fa
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_OR_INT_LIT16.cpp
@@ -0,0 +1,2 @@
+HANDLE_OP_X_INT_LIT16(OP_OR_INT_LIT16,  "or",  |, 0)
+OP_END
diff --git a/vm/mterp/c_notaint/OP_OR_INT_LIT8.cpp b/vm/mterp/c_notaint/OP_OR_INT_LIT8.cpp
new file mode 100644
index 0000000..40b9837
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_OR_INT_LIT8.cpp
@@ -0,0 +1,2 @@
+HANDLE_OP_X_INT_LIT8(OP_OR_INT_LIT8,    "or",  |, 0)
+OP_END
diff --git a/vm/mterp/c_notaint/OP_OR_LONG.cpp b/vm/mterp/c_notaint/OP_OR_LONG.cpp
new file mode 100644
index 0000000..62f4dd3
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_OR_LONG.cpp
@@ -0,0 +1,2 @@
+HANDLE_OP_X_LONG(OP_OR_LONG,  "or", |, 0)
+OP_END
diff --git a/vm/mterp/c_notaint/OP_OR_LONG_2ADDR.cpp b/vm/mterp/c_notaint/OP_OR_LONG_2ADDR.cpp
new file mode 100644
index 0000000..03a7c65
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_OR_LONG_2ADDR.cpp
@@ -0,0 +1,2 @@
+HANDLE_OP_X_LONG_2ADDR(OP_OR_LONG_2ADDR,  "or", |, 0)
+OP_END
diff --git a/vm/mterp/c_notaint/OP_PACKED_SWITCH.cpp b/vm/mterp/c_notaint/OP_PACKED_SWITCH.cpp
new file mode 100644
index 0000000..3922e46
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_PACKED_SWITCH.cpp
@@ -0,0 +1,29 @@
+HANDLE_OPCODE(OP_PACKED_SWITCH /*vAA, +BBBB*/)
+    {
+        const u2* switchData;
+        u4 testVal;
+        s4 offset;
+
+        vsrc1 = INST_AA(inst);
+        offset = FETCH(1) | (((s4) FETCH(2)) << 16);
+        ILOGV("|packed-switch v%d +0x%04x", vsrc1, vsrc2);
+        switchData = pc + offset;       // offset in 16-bit units
+#ifndef NDEBUG
+        if (switchData < curMethod->insns ||
+            switchData >= curMethod->insns + dvmGetMethodInsnsSize(curMethod))
+        {
+            /* should have been caught in verifier */
+            EXPORT_PC();
+            dvmThrowInternalError("bad packed switch");
+            GOTO_exceptionThrown();
+        }
+#endif
+        testVal = GET_REGISTER(vsrc1);
+
+        offset = dvmInterpHandlePackedSwitch(switchData, testVal);
+        ILOGV("> branch taken (0x%04x)", offset);
+        if (offset <= 0)  /* uncommon */
+            PERIODIC_CHECKS(offset);
+        FINISH(offset);
+    }
+OP_END
diff --git a/vm/mterp/c_notaint/OP_REM_DOUBLE.cpp b/vm/mterp/c_notaint/OP_REM_DOUBLE.cpp
new file mode 100644
index 0000000..343e25e
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_REM_DOUBLE.cpp
@@ -0,0 +1,13 @@
+HANDLE_OPCODE(OP_REM_DOUBLE /*vAA, vBB, vCC*/)
+    {
+        u2 srcRegs;
+        vdst = INST_AA(inst);
+        srcRegs = FETCH(1);
+        vsrc1 = srcRegs & 0xff;
+        vsrc2 = srcRegs >> 8;
+        ILOGV("|%s-double v%d,v%d,v%d", "mod", vdst, vsrc1, vsrc2);
+        SET_REGISTER_DOUBLE(vdst,
+            fmod(GET_REGISTER_DOUBLE(vsrc1), GET_REGISTER_DOUBLE(vsrc2)));
+    }
+    FINISH(2);
+OP_END
diff --git a/vm/mterp/c_notaint/OP_REM_DOUBLE_2ADDR.cpp b/vm/mterp/c_notaint/OP_REM_DOUBLE_2ADDR.cpp
new file mode 100644
index 0000000..392eacf
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_REM_DOUBLE_2ADDR.cpp
@@ -0,0 +1,8 @@
+HANDLE_OPCODE(OP_REM_DOUBLE_2ADDR /*vA, vB*/)
+    vdst = INST_A(inst);
+    vsrc1 = INST_B(inst);
+    ILOGV("|%s-double-2addr v%d,v%d", "mod", vdst, vsrc1);
+    SET_REGISTER_DOUBLE(vdst,
+        fmod(GET_REGISTER_DOUBLE(vdst), GET_REGISTER_DOUBLE(vsrc1)));
+    FINISH(1);
+OP_END
diff --git a/vm/mterp/c_notaint/OP_REM_FLOAT.cpp b/vm/mterp/c_notaint/OP_REM_FLOAT.cpp
new file mode 100644
index 0000000..9604b30
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_REM_FLOAT.cpp
@@ -0,0 +1,13 @@
+HANDLE_OPCODE(OP_REM_FLOAT /*vAA, vBB, vCC*/)
+    {
+        u2 srcRegs;
+        vdst = INST_AA(inst);
+        srcRegs = FETCH(1);
+        vsrc1 = srcRegs & 0xff;
+        vsrc2 = srcRegs >> 8;
+        ILOGV("|%s-float v%d,v%d,v%d", "mod", vdst, vsrc1, vsrc2);
+        SET_REGISTER_FLOAT(vdst,
+            fmodf(GET_REGISTER_FLOAT(vsrc1), GET_REGISTER_FLOAT(vsrc2)));
+    }
+    FINISH(2);
+OP_END
diff --git a/vm/mterp/c_notaint/OP_REM_FLOAT_2ADDR.cpp b/vm/mterp/c_notaint/OP_REM_FLOAT_2ADDR.cpp
new file mode 100644
index 0000000..87bb31e
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_REM_FLOAT_2ADDR.cpp
@@ -0,0 +1,8 @@
+HANDLE_OPCODE(OP_REM_FLOAT_2ADDR /*vA, vB*/)
+    vdst = INST_A(inst);
+    vsrc1 = INST_B(inst);
+    ILOGV("|%s-float-2addr v%d,v%d", "mod", vdst, vsrc1);
+    SET_REGISTER_FLOAT(vdst,
+        fmodf(GET_REGISTER_FLOAT(vdst), GET_REGISTER_FLOAT(vsrc1)));
+    FINISH(1);
+OP_END
diff --git a/vm/mterp/c_notaint/OP_REM_INT.cpp b/vm/mterp/c_notaint/OP_REM_INT.cpp
new file mode 100644
index 0000000..0e3efe6
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_REM_INT.cpp
@@ -0,0 +1,2 @@
+HANDLE_OP_X_INT(OP_REM_INT, "rem", %, 2)
+OP_END
diff --git a/vm/mterp/c_notaint/OP_REM_INT_2ADDR.cpp b/vm/mterp/c_notaint/OP_REM_INT_2ADDR.cpp
new file mode 100644
index 0000000..5801f35
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_REM_INT_2ADDR.cpp
@@ -0,0 +1,2 @@
+HANDLE_OP_X_INT_2ADDR(OP_REM_INT_2ADDR, "rem", %, 2)
+OP_END
diff --git a/vm/mterp/c_notaint/OP_REM_INT_LIT16.cpp b/vm/mterp/c_notaint/OP_REM_INT_LIT16.cpp
new file mode 100644
index 0000000..a4dabe8
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_REM_INT_LIT16.cpp
@@ -0,0 +1,2 @@
+HANDLE_OP_X_INT_LIT16(OP_REM_INT_LIT16, "rem", %, 2)
+OP_END
diff --git a/vm/mterp/c_notaint/OP_REM_INT_LIT8.cpp b/vm/mterp/c_notaint/OP_REM_INT_LIT8.cpp
new file mode 100644
index 0000000..2bc88be
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_REM_INT_LIT8.cpp
@@ -0,0 +1,2 @@
+HANDLE_OP_X_INT_LIT8(OP_REM_INT_LIT8,   "rem", %, 2)
+OP_END
diff --git a/vm/mterp/c_notaint/OP_REM_LONG.cpp b/vm/mterp/c_notaint/OP_REM_LONG.cpp
new file mode 100644
index 0000000..fb2ba71
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_REM_LONG.cpp
@@ -0,0 +1,2 @@
+HANDLE_OP_X_LONG(OP_REM_LONG, "rem", %, 2)
+OP_END
diff --git a/vm/mterp/c_notaint/OP_REM_LONG_2ADDR.cpp b/vm/mterp/c_notaint/OP_REM_LONG_2ADDR.cpp
new file mode 100644
index 0000000..3049770
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_REM_LONG_2ADDR.cpp
@@ -0,0 +1,2 @@
+HANDLE_OP_X_LONG_2ADDR(OP_REM_LONG_2ADDR, "rem", %, 2)
+OP_END
diff --git a/vm/mterp/c_notaint/OP_RETURN.cpp b/vm/mterp/c_notaint/OP_RETURN.cpp
new file mode 100644
index 0000000..89d3b3b
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_RETURN.cpp
@@ -0,0 +1,7 @@
+HANDLE_OPCODE($opcode /*vAA*/)
+    vsrc1 = INST_AA(inst);
+    ILOGV("|return%s v%d",
+        (INST_INST(inst) == OP_RETURN) ? "" : "-object", vsrc1);
+    retval.i = GET_REGISTER(vsrc1);
+    GOTO_returnFromMethod();
+OP_END
diff --git a/vm/mterp/c_notaint/OP_RETURN_OBJECT.cpp b/vm/mterp/c_notaint/OP_RETURN_OBJECT.cpp
new file mode 100644
index 0000000..d8bae43
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_RETURN_OBJECT.cpp
@@ -0,0 +1 @@
+%include "c/OP_RETURN.cpp"
diff --git a/vm/mterp/c_notaint/OP_RETURN_VOID.cpp b/vm/mterp/c_notaint/OP_RETURN_VOID.cpp
new file mode 100644
index 0000000..7431f60
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_RETURN_VOID.cpp
@@ -0,0 +1,7 @@
+HANDLE_OPCODE(OP_RETURN_VOID /**/)
+    ILOGV("|return-void");
+#ifndef NDEBUG
+    retval.j = 0xababababULL;    // placate valgrind
+#endif
+    GOTO_returnFromMethod();
+OP_END
diff --git a/vm/mterp/c_notaint/OP_RETURN_VOID_BARRIER.cpp b/vm/mterp/c_notaint/OP_RETURN_VOID_BARRIER.cpp
new file mode 100644
index 0000000..312402e
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_RETURN_VOID_BARRIER.cpp
@@ -0,0 +1,8 @@
+HANDLE_OPCODE(OP_RETURN_VOID_BARRIER /**/)
+    ILOGV("|return-void");
+#ifndef NDEBUG
+    retval.j = 0xababababULL;   /* placate valgrind */
+#endif
+    ANDROID_MEMBAR_STORE();
+    GOTO_returnFromMethod();
+OP_END
diff --git a/vm/mterp/c_notaint/OP_RETURN_WIDE.cpp b/vm/mterp/c_notaint/OP_RETURN_WIDE.cpp
new file mode 100644
index 0000000..a27bfd4
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_RETURN_WIDE.cpp
@@ -0,0 +1,6 @@
+HANDLE_OPCODE(OP_RETURN_WIDE /*vAA*/)
+    vsrc1 = INST_AA(inst);
+    ILOGV("|return-wide v%d", vsrc1);
+    retval.j = GET_REGISTER_WIDE(vsrc1);
+    GOTO_returnFromMethod();
+OP_END
diff --git a/vm/mterp/c_notaint/OP_RSUB_INT.cpp b/vm/mterp/c_notaint/OP_RSUB_INT.cpp
new file mode 100644
index 0000000..336ca55
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_RSUB_INT.cpp
@@ -0,0 +1,10 @@
+HANDLE_OPCODE(OP_RSUB_INT /*vA, vB, #+CCCC*/)
+    {
+        vdst = INST_A(inst);
+        vsrc1 = INST_B(inst);
+        vsrc2 = FETCH(1);
+        ILOGV("|rsub-int v%d,v%d,#+0x%04x", vdst, vsrc1, vsrc2);
+        SET_REGISTER(vdst, (s2) vsrc2 - (s4) GET_REGISTER(vsrc1));
+    }
+    FINISH(2);
+OP_END
diff --git a/vm/mterp/c_notaint/OP_RSUB_INT_LIT8.cpp b/vm/mterp/c_notaint/OP_RSUB_INT_LIT8.cpp
new file mode 100644
index 0000000..742854b
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_RSUB_INT_LIT8.cpp
@@ -0,0 +1,12 @@
+HANDLE_OPCODE(OP_RSUB_INT_LIT8 /*vAA, vBB, #+CC*/)
+    {
+        u2 litInfo;
+        vdst = INST_AA(inst);
+        litInfo = FETCH(1);
+        vsrc1 = litInfo & 0xff;
+        vsrc2 = litInfo >> 8;
+        ILOGV("|%s-int/lit8 v%d,v%d,#+0x%02x", "rsub", vdst, vsrc1, vsrc2);
+        SET_REGISTER(vdst, (s1) vsrc2 - (s4) GET_REGISTER(vsrc1));
+    }
+    FINISH(2);
+OP_END
diff --git a/vm/mterp/c_notaint/OP_SGET.cpp b/vm/mterp/c_notaint/OP_SGET.cpp
new file mode 100644
index 0000000..5297cd7
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_SGET.cpp
@@ -0,0 +1,2 @@
+HANDLE_SGET_X(OP_SGET,                  "", Int, )
+OP_END
diff --git a/vm/mterp/c_notaint/OP_SGET_BOOLEAN.cpp b/vm/mterp/c_notaint/OP_SGET_BOOLEAN.cpp
new file mode 100644
index 0000000..7c5d45e
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_SGET_BOOLEAN.cpp
@@ -0,0 +1,2 @@
+HANDLE_SGET_X(OP_SGET_BOOLEAN,          "", Int, )
+OP_END
diff --git a/vm/mterp/c_notaint/OP_SGET_BYTE.cpp b/vm/mterp/c_notaint/OP_SGET_BYTE.cpp
new file mode 100644
index 0000000..b37cab4
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_SGET_BYTE.cpp
@@ -0,0 +1,2 @@
+HANDLE_SGET_X(OP_SGET_BYTE,             "", Int, )
+OP_END
diff --git a/vm/mterp/c_notaint/OP_SGET_CHAR.cpp b/vm/mterp/c_notaint/OP_SGET_CHAR.cpp
new file mode 100644
index 0000000..7ede5ec
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_SGET_CHAR.cpp
@@ -0,0 +1,2 @@
+HANDLE_SGET_X(OP_SGET_CHAR,             "", Int, )
+OP_END
diff --git a/vm/mterp/c_notaint/OP_SGET_OBJECT.cpp b/vm/mterp/c_notaint/OP_SGET_OBJECT.cpp
new file mode 100644
index 0000000..9f3b63d
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_SGET_OBJECT.cpp
@@ -0,0 +1,2 @@
+HANDLE_SGET_X(OP_SGET_OBJECT,           "-object", Object, _AS_OBJECT)
+OP_END
diff --git a/vm/mterp/c_notaint/OP_SGET_OBJECT_VOLATILE.cpp b/vm/mterp/c_notaint/OP_SGET_OBJECT_VOLATILE.cpp
new file mode 100644
index 0000000..0a9049f
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_SGET_OBJECT_VOLATILE.cpp
@@ -0,0 +1,2 @@
+HANDLE_SGET_X(OP_SGET_OBJECT_VOLATILE,  "-object-volatile", ObjectVolatile, _AS_OBJECT)
+OP_END
diff --git a/vm/mterp/c_notaint/OP_SGET_SHORT.cpp b/vm/mterp/c_notaint/OP_SGET_SHORT.cpp
new file mode 100644
index 0000000..cd1fe4c
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_SGET_SHORT.cpp
@@ -0,0 +1,2 @@
+HANDLE_SGET_X(OP_SGET_SHORT,            "", Int, )
+OP_END
diff --git a/vm/mterp/c_notaint/OP_SGET_VOLATILE.cpp b/vm/mterp/c_notaint/OP_SGET_VOLATILE.cpp
new file mode 100644
index 0000000..6713a54
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_SGET_VOLATILE.cpp
@@ -0,0 +1,2 @@
+HANDLE_SGET_X(OP_SGET_VOLATILE,         "-volatile", IntVolatile, )
+OP_END
diff --git a/vm/mterp/c_notaint/OP_SGET_WIDE.cpp b/vm/mterp/c_notaint/OP_SGET_WIDE.cpp
new file mode 100644
index 0000000..817c6e7
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_SGET_WIDE.cpp
@@ -0,0 +1,2 @@
+HANDLE_SGET_X(OP_SGET_WIDE,             "-wide", Long, _WIDE)
+OP_END
diff --git a/vm/mterp/c_notaint/OP_SGET_WIDE_VOLATILE.cpp b/vm/mterp/c_notaint/OP_SGET_WIDE_VOLATILE.cpp
new file mode 100644
index 0000000..26a67bf
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_SGET_WIDE_VOLATILE.cpp
@@ -0,0 +1,2 @@
+HANDLE_SGET_X(OP_SGET_WIDE_VOLATILE,    "-wide-volatile", LongVolatile, _WIDE)
+OP_END
diff --git a/vm/mterp/c_notaint/OP_SHL_INT.cpp b/vm/mterp/c_notaint/OP_SHL_INT.cpp
new file mode 100644
index 0000000..e32af49
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_SHL_INT.cpp
@@ -0,0 +1,2 @@
+HANDLE_OP_SHX_INT(OP_SHL_INT, "shl", (s4), <<)
+OP_END
diff --git a/vm/mterp/c_notaint/OP_SHL_INT_2ADDR.cpp b/vm/mterp/c_notaint/OP_SHL_INT_2ADDR.cpp
new file mode 100644
index 0000000..c5f5399
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_SHL_INT_2ADDR.cpp
@@ -0,0 +1,2 @@
+HANDLE_OP_SHX_INT_2ADDR(OP_SHL_INT_2ADDR, "shl", (s4), <<)
+OP_END
diff --git a/vm/mterp/c_notaint/OP_SHL_INT_LIT8.cpp b/vm/mterp/c_notaint/OP_SHL_INT_LIT8.cpp
new file mode 100644
index 0000000..009d14e
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_SHL_INT_LIT8.cpp
@@ -0,0 +1,2 @@
+HANDLE_OP_SHX_INT_LIT8(OP_SHL_INT_LIT8,   "shl", (s4), <<)
+OP_END
diff --git a/vm/mterp/c_notaint/OP_SHL_LONG.cpp b/vm/mterp/c_notaint/OP_SHL_LONG.cpp
new file mode 100644
index 0000000..f6b502a
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_SHL_LONG.cpp
@@ -0,0 +1,2 @@
+HANDLE_OP_SHX_LONG(OP_SHL_LONG, "shl", (s8), <<)
+OP_END
diff --git a/vm/mterp/c_notaint/OP_SHL_LONG_2ADDR.cpp b/vm/mterp/c_notaint/OP_SHL_LONG_2ADDR.cpp
new file mode 100644
index 0000000..b8a9954
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_SHL_LONG_2ADDR.cpp
@@ -0,0 +1,2 @@
+HANDLE_OP_SHX_LONG_2ADDR(OP_SHL_LONG_2ADDR, "shl", (s8), <<)
+OP_END
diff --git a/vm/mterp/c_notaint/OP_SHR_INT.cpp b/vm/mterp/c_notaint/OP_SHR_INT.cpp
new file mode 100644
index 0000000..3834824
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_SHR_INT.cpp
@@ -0,0 +1,2 @@
+HANDLE_OP_SHX_INT(OP_SHR_INT, "shr", (s4), >>)
+OP_END
diff --git a/vm/mterp/c_notaint/OP_SHR_INT_2ADDR.cpp b/vm/mterp/c_notaint/OP_SHR_INT_2ADDR.cpp
new file mode 100644
index 0000000..c76c178
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_SHR_INT_2ADDR.cpp
@@ -0,0 +1,2 @@
+HANDLE_OP_SHX_INT_2ADDR(OP_SHR_INT_2ADDR, "shr", (s4), >>)
+OP_END
diff --git a/vm/mterp/c_notaint/OP_SHR_INT_LIT8.cpp b/vm/mterp/c_notaint/OP_SHR_INT_LIT8.cpp
new file mode 100644
index 0000000..e2657d7
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_SHR_INT_LIT8.cpp
@@ -0,0 +1,2 @@
+HANDLE_OP_SHX_INT_LIT8(OP_SHR_INT_LIT8,   "shr", (s4), >>)
+OP_END
diff --git a/vm/mterp/c_notaint/OP_SHR_LONG.cpp b/vm/mterp/c_notaint/OP_SHR_LONG.cpp
new file mode 100644
index 0000000..357a666
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_SHR_LONG.cpp
@@ -0,0 +1,2 @@
+HANDLE_OP_SHX_LONG(OP_SHR_LONG, "shr", (s8), >>)
+OP_END
diff --git a/vm/mterp/c_notaint/OP_SHR_LONG_2ADDR.cpp b/vm/mterp/c_notaint/OP_SHR_LONG_2ADDR.cpp
new file mode 100644
index 0000000..43e27ea
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_SHR_LONG_2ADDR.cpp
@@ -0,0 +1,2 @@
+HANDLE_OP_SHX_LONG_2ADDR(OP_SHR_LONG_2ADDR, "shr", (s8), >>)
+OP_END
diff --git a/vm/mterp/c_notaint/OP_SPARSE_SWITCH.cpp b/vm/mterp/c_notaint/OP_SPARSE_SWITCH.cpp
new file mode 100644
index 0000000..f48d06e
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_SPARSE_SWITCH.cpp
@@ -0,0 +1,29 @@
+HANDLE_OPCODE(OP_SPARSE_SWITCH /*vAA, +BBBB*/)
+    {
+        const u2* switchData;
+        u4 testVal;
+        s4 offset;
+
+        vsrc1 = INST_AA(inst);
+        offset = FETCH(1) | (((s4) FETCH(2)) << 16);
+        ILOGV("|sparse-switch v%d +0x%04x", vsrc1, vsrc2);
+        switchData = pc + offset;       // offset in 16-bit units
+#ifndef NDEBUG
+        if (switchData < curMethod->insns ||
+            switchData >= curMethod->insns + dvmGetMethodInsnsSize(curMethod))
+        {
+            /* should have been caught in verifier */
+            EXPORT_PC();
+            dvmThrowInternalError("bad sparse switch");
+            GOTO_exceptionThrown();
+        }
+#endif
+        testVal = GET_REGISTER(vsrc1);
+
+        offset = dvmInterpHandleSparseSwitch(switchData, testVal);
+        ILOGV("> branch taken (0x%04x)", offset);
+        if (offset <= 0)  /* uncommon */
+            PERIODIC_CHECKS(offset);
+        FINISH(offset);
+    }
+OP_END
diff --git a/vm/mterp/c_notaint/OP_SPUT.cpp b/vm/mterp/c_notaint/OP_SPUT.cpp
new file mode 100644
index 0000000..286e64c
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_SPUT.cpp
@@ -0,0 +1,2 @@
+HANDLE_SPUT_X(OP_SPUT,                  "", Int, )
+OP_END
diff --git a/vm/mterp/c_notaint/OP_SPUT_BOOLEAN.cpp b/vm/mterp/c_notaint/OP_SPUT_BOOLEAN.cpp
new file mode 100644
index 0000000..55ceb11
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_SPUT_BOOLEAN.cpp
@@ -0,0 +1,2 @@
+HANDLE_SPUT_X(OP_SPUT_BOOLEAN,          "", Int, )
+OP_END
diff --git a/vm/mterp/c_notaint/OP_SPUT_BYTE.cpp b/vm/mterp/c_notaint/OP_SPUT_BYTE.cpp
new file mode 100644
index 0000000..d242fe1
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_SPUT_BYTE.cpp
@@ -0,0 +1,2 @@
+HANDLE_SPUT_X(OP_SPUT_BYTE,             "", Int, )
+OP_END
diff --git a/vm/mterp/c_notaint/OP_SPUT_CHAR.cpp b/vm/mterp/c_notaint/OP_SPUT_CHAR.cpp
new file mode 100644
index 0000000..18a2f06
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_SPUT_CHAR.cpp
@@ -0,0 +1,2 @@
+HANDLE_SPUT_X(OP_SPUT_CHAR,             "", Int, )
+OP_END
diff --git a/vm/mterp/c_notaint/OP_SPUT_OBJECT.cpp b/vm/mterp/c_notaint/OP_SPUT_OBJECT.cpp
new file mode 100644
index 0000000..fb223d6
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_SPUT_OBJECT.cpp
@@ -0,0 +1,2 @@
+HANDLE_SPUT_X(OP_SPUT_OBJECT,           "-object", Object, _AS_OBJECT)
+OP_END
diff --git a/vm/mterp/c_notaint/OP_SPUT_OBJECT_VOLATILE.cpp b/vm/mterp/c_notaint/OP_SPUT_OBJECT_VOLATILE.cpp
new file mode 100644
index 0000000..38d6c0d
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_SPUT_OBJECT_VOLATILE.cpp
@@ -0,0 +1,2 @@
+HANDLE_SPUT_X(OP_SPUT_OBJECT_VOLATILE,  "-object-volatile", ObjectVolatile, _AS_OBJECT)
+OP_END
diff --git a/vm/mterp/c_notaint/OP_SPUT_SHORT.cpp b/vm/mterp/c_notaint/OP_SPUT_SHORT.cpp
new file mode 100644
index 0000000..c6cd8d6
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_SPUT_SHORT.cpp
@@ -0,0 +1,2 @@
+HANDLE_SPUT_X(OP_SPUT_SHORT,            "", Int, )
+OP_END
diff --git a/vm/mterp/c_notaint/OP_SPUT_VOLATILE.cpp b/vm/mterp/c_notaint/OP_SPUT_VOLATILE.cpp
new file mode 100644
index 0000000..7899d05
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_SPUT_VOLATILE.cpp
@@ -0,0 +1,2 @@
+HANDLE_SPUT_X(OP_SPUT_VOLATILE,         "-volatile", IntVolatile, )
+OP_END
diff --git a/vm/mterp/c_notaint/OP_SPUT_WIDE.cpp b/vm/mterp/c_notaint/OP_SPUT_WIDE.cpp
new file mode 100644
index 0000000..0c74651
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_SPUT_WIDE.cpp
@@ -0,0 +1,2 @@
+HANDLE_SPUT_X(OP_SPUT_WIDE,             "-wide", Long, _WIDE)
+OP_END
diff --git a/vm/mterp/c_notaint/OP_SPUT_WIDE_VOLATILE.cpp b/vm/mterp/c_notaint/OP_SPUT_WIDE_VOLATILE.cpp
new file mode 100644
index 0000000..bdf552c
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_SPUT_WIDE_VOLATILE.cpp
@@ -0,0 +1,2 @@
+HANDLE_SPUT_X(OP_SPUT_WIDE_VOLATILE,    "-wide-volatile", LongVolatile, _WIDE)
+OP_END
diff --git a/vm/mterp/c_notaint/OP_SUB_DOUBLE.cpp b/vm/mterp/c_notaint/OP_SUB_DOUBLE.cpp
new file mode 100644
index 0000000..64a112d
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_SUB_DOUBLE.cpp
@@ -0,0 +1,2 @@
+HANDLE_OP_X_DOUBLE(OP_SUB_DOUBLE, "sub", -)
+OP_END
diff --git a/vm/mterp/c_notaint/OP_SUB_DOUBLE_2ADDR.cpp b/vm/mterp/c_notaint/OP_SUB_DOUBLE_2ADDR.cpp
new file mode 100644
index 0000000..5870400
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_SUB_DOUBLE_2ADDR.cpp
@@ -0,0 +1,2 @@
+HANDLE_OP_X_DOUBLE_2ADDR(OP_SUB_DOUBLE_2ADDR, "sub", -)
+OP_END
diff --git a/vm/mterp/c_notaint/OP_SUB_FLOAT.cpp b/vm/mterp/c_notaint/OP_SUB_FLOAT.cpp
new file mode 100644
index 0000000..96c5fbd
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_SUB_FLOAT.cpp
@@ -0,0 +1,2 @@
+HANDLE_OP_X_FLOAT(OP_SUB_FLOAT, "sub", -)
+OP_END
diff --git a/vm/mterp/c_notaint/OP_SUB_FLOAT_2ADDR.cpp b/vm/mterp/c_notaint/OP_SUB_FLOAT_2ADDR.cpp
new file mode 100644
index 0000000..802935c
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_SUB_FLOAT_2ADDR.cpp
@@ -0,0 +1,2 @@
+HANDLE_OP_X_FLOAT_2ADDR(OP_SUB_FLOAT_2ADDR, "sub", -)
+OP_END
diff --git a/vm/mterp/c_notaint/OP_SUB_INT.cpp b/vm/mterp/c_notaint/OP_SUB_INT.cpp
new file mode 100644
index 0000000..2c1006d
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_SUB_INT.cpp
@@ -0,0 +1,2 @@
+HANDLE_OP_X_INT(OP_SUB_INT, "sub", -, 0)
+OP_END
diff --git a/vm/mterp/c_notaint/OP_SUB_INT_2ADDR.cpp b/vm/mterp/c_notaint/OP_SUB_INT_2ADDR.cpp
new file mode 100644
index 0000000..328ed33
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_SUB_INT_2ADDR.cpp
@@ -0,0 +1,2 @@
+HANDLE_OP_X_INT_2ADDR(OP_SUB_INT_2ADDR, "sub", -, 0)
+OP_END
diff --git a/vm/mterp/c_notaint/OP_SUB_LONG.cpp b/vm/mterp/c_notaint/OP_SUB_LONG.cpp
new file mode 100644
index 0000000..bace11a
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_SUB_LONG.cpp
@@ -0,0 +1,2 @@
+HANDLE_OP_X_LONG(OP_SUB_LONG, "sub", -, 0)
+OP_END
diff --git a/vm/mterp/c_notaint/OP_SUB_LONG_2ADDR.cpp b/vm/mterp/c_notaint/OP_SUB_LONG_2ADDR.cpp
new file mode 100644
index 0000000..f234dd4
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_SUB_LONG_2ADDR.cpp
@@ -0,0 +1,2 @@
+HANDLE_OP_X_LONG_2ADDR(OP_SUB_LONG_2ADDR, "sub", -, 0)
+OP_END
diff --git a/vm/mterp/c_notaint/OP_THROW.cpp b/vm/mterp/c_notaint/OP_THROW.cpp
new file mode 100644
index 0000000..6fde0cc
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_THROW.cpp
@@ -0,0 +1,24 @@
+HANDLE_OPCODE(OP_THROW /*vAA*/)
+    {
+        Object* obj;
+
+        /*
+         * We don't create an exception here, but the process of searching
+         * for a catch block can do class lookups and throw exceptions.
+         * We need to update the saved PC.
+         */
+        EXPORT_PC();
+
+        vsrc1 = INST_AA(inst);
+        ILOGV("|throw v%d  (%p)", vsrc1, (void*)GET_REGISTER(vsrc1));
+        obj = (Object*) GET_REGISTER(vsrc1);
+        if (!checkForNull(obj)) {
+            /* will throw a null pointer exception */
+            LOGVV("Bad exception");
+        } else {
+            /* use the requested exception */
+            dvmSetException(self, obj);
+        }
+        GOTO_exceptionThrown();
+    }
+OP_END
diff --git a/vm/mterp/c_notaint/OP_THROW_VERIFICATION_ERROR.cpp b/vm/mterp/c_notaint/OP_THROW_VERIFICATION_ERROR.cpp
new file mode 100644
index 0000000..85cc8fb
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_THROW_VERIFICATION_ERROR.cpp
@@ -0,0 +1,7 @@
+HANDLE_OPCODE(OP_THROW_VERIFICATION_ERROR)
+    EXPORT_PC();
+    vsrc1 = INST_AA(inst);
+    ref = FETCH(1);             /* class/field/method ref */
+    dvmThrowVerificationError(curMethod, vsrc1, ref);
+    GOTO_exceptionThrown();
+OP_END
diff --git a/vm/mterp/c_notaint/OP_UNUSED_3E.cpp b/vm/mterp/c_notaint/OP_UNUSED_3E.cpp
new file mode 100644
index 0000000..9ecf8e3
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_UNUSED_3E.cpp
@@ -0,0 +1,2 @@
+HANDLE_OPCODE(OP_UNUSED_3E)
+OP_END
diff --git a/vm/mterp/c_notaint/OP_UNUSED_3F.cpp b/vm/mterp/c_notaint/OP_UNUSED_3F.cpp
new file mode 100644
index 0000000..9d1d68d
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_UNUSED_3F.cpp
@@ -0,0 +1,2 @@
+HANDLE_OPCODE(OP_UNUSED_3F)
+OP_END
diff --git a/vm/mterp/c_notaint/OP_UNUSED_40.cpp b/vm/mterp/c_notaint/OP_UNUSED_40.cpp
new file mode 100644
index 0000000..f73a59c
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_UNUSED_40.cpp
@@ -0,0 +1,2 @@
+HANDLE_OPCODE(OP_UNUSED_40)
+OP_END
diff --git a/vm/mterp/c_notaint/OP_UNUSED_41.cpp b/vm/mterp/c_notaint/OP_UNUSED_41.cpp
new file mode 100644
index 0000000..38747e6
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_UNUSED_41.cpp
@@ -0,0 +1,2 @@
+HANDLE_OPCODE(OP_UNUSED_41)
+OP_END
diff --git a/vm/mterp/c_notaint/OP_UNUSED_42.cpp b/vm/mterp/c_notaint/OP_UNUSED_42.cpp
new file mode 100644
index 0000000..154d293
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_UNUSED_42.cpp
@@ -0,0 +1,2 @@
+HANDLE_OPCODE(OP_UNUSED_42)
+OP_END
diff --git a/vm/mterp/c_notaint/OP_UNUSED_43.cpp b/vm/mterp/c_notaint/OP_UNUSED_43.cpp
new file mode 100644
index 0000000..c7e702c
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_UNUSED_43.cpp
@@ -0,0 +1,2 @@
+HANDLE_OPCODE(OP_UNUSED_43)
+OP_END
diff --git a/vm/mterp/c_notaint/OP_UNUSED_73.cpp b/vm/mterp/c_notaint/OP_UNUSED_73.cpp
new file mode 100644
index 0000000..85aa95f
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_UNUSED_73.cpp
@@ -0,0 +1,2 @@
+HANDLE_OPCODE(OP_UNUSED_73)
+OP_END
diff --git a/vm/mterp/c_notaint/OP_UNUSED_79.cpp b/vm/mterp/c_notaint/OP_UNUSED_79.cpp
new file mode 100644
index 0000000..1fa86e9
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_UNUSED_79.cpp
@@ -0,0 +1,2 @@
+HANDLE_OPCODE(OP_UNUSED_79)
+OP_END
diff --git a/vm/mterp/c_notaint/OP_UNUSED_7A.cpp b/vm/mterp/c_notaint/OP_UNUSED_7A.cpp
new file mode 100644
index 0000000..beab006
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_UNUSED_7A.cpp
@@ -0,0 +1,2 @@
+HANDLE_OPCODE(OP_UNUSED_7A)
+OP_END
diff --git a/vm/mterp/c_notaint/OP_UNUSED_FF.cpp b/vm/mterp/c_notaint/OP_UNUSED_FF.cpp
new file mode 100644
index 0000000..1348aec
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_UNUSED_FF.cpp
@@ -0,0 +1,8 @@
+HANDLE_OPCODE(OP_UNUSED_FF)
+    /*
+     * In portable interp, most unused opcodes will fall through to here.
+     */
+    ALOGE("unknown opcode 0x%02x\n", INST_INST(inst));
+    dvmAbort();
+    FINISH(1);
+OP_END
diff --git a/vm/mterp/c_notaint/OP_USHR_INT.cpp b/vm/mterp/c_notaint/OP_USHR_INT.cpp
new file mode 100644
index 0000000..7596c94
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_USHR_INT.cpp
@@ -0,0 +1,2 @@
+HANDLE_OP_SHX_INT(OP_USHR_INT, "ushr", (u4), >>)
+OP_END
diff --git a/vm/mterp/c_notaint/OP_USHR_INT_2ADDR.cpp b/vm/mterp/c_notaint/OP_USHR_INT_2ADDR.cpp
new file mode 100644
index 0000000..5fa2b94
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_USHR_INT_2ADDR.cpp
@@ -0,0 +1,2 @@
+HANDLE_OP_SHX_INT_2ADDR(OP_USHR_INT_2ADDR, "ushr", (u4), >>)
+OP_END
diff --git a/vm/mterp/c_notaint/OP_USHR_INT_LIT8.cpp b/vm/mterp/c_notaint/OP_USHR_INT_LIT8.cpp
new file mode 100644
index 0000000..0d325d7
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_USHR_INT_LIT8.cpp
@@ -0,0 +1,2 @@
+HANDLE_OP_SHX_INT_LIT8(OP_USHR_INT_LIT8,  "ushr", (u4), >>)
+OP_END
diff --git a/vm/mterp/c_notaint/OP_USHR_LONG.cpp b/vm/mterp/c_notaint/OP_USHR_LONG.cpp
new file mode 100644
index 0000000..9b7e757
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_USHR_LONG.cpp
@@ -0,0 +1,2 @@
+HANDLE_OP_SHX_LONG(OP_USHR_LONG, "ushr", (u8), >>)
+OP_END
diff --git a/vm/mterp/c_notaint/OP_USHR_LONG_2ADDR.cpp b/vm/mterp/c_notaint/OP_USHR_LONG_2ADDR.cpp
new file mode 100644
index 0000000..4ac0598
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_USHR_LONG_2ADDR.cpp
@@ -0,0 +1,2 @@
+HANDLE_OP_SHX_LONG_2ADDR(OP_USHR_LONG_2ADDR, "ushr", (u8), >>)
+OP_END
diff --git a/vm/mterp/c_notaint/OP_XOR_INT.cpp b/vm/mterp/c_notaint/OP_XOR_INT.cpp
new file mode 100644
index 0000000..d591909
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_XOR_INT.cpp
@@ -0,0 +1,2 @@
+HANDLE_OP_X_INT(OP_XOR_INT, "xor", ^, 0)
+OP_END
diff --git a/vm/mterp/c_notaint/OP_XOR_INT_2ADDR.cpp b/vm/mterp/c_notaint/OP_XOR_INT_2ADDR.cpp
new file mode 100644
index 0000000..7d32879
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_XOR_INT_2ADDR.cpp
@@ -0,0 +1,2 @@
+HANDLE_OP_X_INT_2ADDR(OP_XOR_INT_2ADDR, "xor", ^, 0)
+OP_END
diff --git a/vm/mterp/c_notaint/OP_XOR_INT_LIT16.cpp b/vm/mterp/c_notaint/OP_XOR_INT_LIT16.cpp
new file mode 100644
index 0000000..c204b79
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_XOR_INT_LIT16.cpp
@@ -0,0 +1,2 @@
+HANDLE_OP_X_INT_LIT16(OP_XOR_INT_LIT16, "xor", ^, 0)
+OP_END
diff --git a/vm/mterp/c_notaint/OP_XOR_INT_LIT8.cpp b/vm/mterp/c_notaint/OP_XOR_INT_LIT8.cpp
new file mode 100644
index 0000000..f01773a
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_XOR_INT_LIT8.cpp
@@ -0,0 +1,2 @@
+HANDLE_OP_X_INT_LIT8(OP_XOR_INT_LIT8,   "xor", ^, 0)
+OP_END
diff --git a/vm/mterp/c_notaint/OP_XOR_LONG.cpp b/vm/mterp/c_notaint/OP_XOR_LONG.cpp
new file mode 100644
index 0000000..d3dbc4c
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_XOR_LONG.cpp
@@ -0,0 +1,2 @@
+HANDLE_OP_X_LONG(OP_XOR_LONG, "xor", ^, 0)
+OP_END
diff --git a/vm/mterp/c_notaint/OP_XOR_LONG_2ADDR.cpp b/vm/mterp/c_notaint/OP_XOR_LONG_2ADDR.cpp
new file mode 100644
index 0000000..e7a50f4
--- /dev/null
+++ b/vm/mterp/c_notaint/OP_XOR_LONG_2ADDR.cpp
@@ -0,0 +1,2 @@
+HANDLE_OP_X_LONG_2ADDR(OP_XOR_LONG_2ADDR, "xor", ^, 0)
+OP_END
diff --git a/vm/mterp/c_notaint/gotoTargets.cpp b/vm/mterp/c_notaint/gotoTargets.cpp
new file mode 100644
index 0000000..2c05038
--- /dev/null
+++ b/vm/mterp/c_notaint/gotoTargets.cpp
@@ -0,0 +1,970 @@
+/*
+ * C footer.  This has some common code shared by the various targets.
+ */
+
+/*
+ * Everything from here on is a "goto target".  In the basic interpreter
+ * we jump into these targets and then jump directly to the handler for
+ * next instruction.  Here, these are subroutines that return to the caller.
+ */
+
+GOTO_TARGET(filledNewArray, bool methodCallRange, bool)
+    {
+        ClassObject* arrayClass;
+        ArrayObject* newArray;
+        u4* contents;
+        char typeCh;
+        int i;
+        u4 arg5;
+
+        EXPORT_PC();
+
+        ref = FETCH(1);             /* class ref */
+        vdst = FETCH(2);            /* first 4 regs -or- range base */
+
+        if (methodCallRange) {
+            vsrc1 = INST_AA(inst);  /* #of elements */
+            arg5 = -1;              /* silence compiler warning */
+            ILOGV("|filled-new-array-range args=%d @0x%04x {regs=v%d-v%d}",
+                vsrc1, ref, vdst, vdst+vsrc1-1);
+        } else {
+            arg5 = INST_A(inst);
+            vsrc1 = INST_B(inst);   /* #of elements */
+            ILOGV("|filled-new-array args=%d @0x%04x {regs=0x%04x %x}",
+               vsrc1, ref, vdst, arg5);
+        }
+
+        /*
+         * Resolve the array class.
+         */
+        arrayClass = dvmDexGetResolvedClass(methodClassDex, ref);
+        if (arrayClass == NULL) {
+            arrayClass = dvmResolveClass(curMethod->clazz, ref, false);
+            if (arrayClass == NULL)
+                GOTO_exceptionThrown();
+        }
+        /*
+        if (!dvmIsArrayClass(arrayClass)) {
+            dvmThrowRuntimeException(
+                "filled-new-array needs array class");
+            GOTO_exceptionThrown();
+        }
+        */
+        /* verifier guarantees this is an array class */
+        assert(dvmIsArrayClass(arrayClass));
+        assert(dvmIsClassInitialized(arrayClass));
+
+        /*
+         * Create an array of the specified type.
+         */
+        LOGVV("+++ filled-new-array type is '%s'", arrayClass->descriptor);
+        typeCh = arrayClass->descriptor[1];
+        if (typeCh == 'D' || typeCh == 'J') {
+            /* category 2 primitives not allowed */
+            dvmThrowRuntimeException("bad filled array req");
+            GOTO_exceptionThrown();
+        } else if (typeCh != 'L' && typeCh != '[' && typeCh != 'I') {
+            /* TODO: requires multiple "fill in" loops with different widths */
+            ALOGE("non-int primitives not implemented");
+            dvmThrowInternalError(
+                "filled-new-array not implemented for anything but 'int'");
+            GOTO_exceptionThrown();
+        }
+
+        newArray = dvmAllocArrayByClass(arrayClass, vsrc1, ALLOC_DONT_TRACK);
+        if (newArray == NULL)
+            GOTO_exceptionThrown();
+
+        /*
+         * Fill in the elements.  It's legal for vsrc1 to be zero.
+         */
+        contents = (u4*)(void*)newArray->contents;
+        if (methodCallRange) {
+            for (i = 0; i < vsrc1; i++)
+                contents[i] = GET_REGISTER(vdst+i);
+        } else {
+            assert(vsrc1 <= 5);
+            if (vsrc1 == 5) {
+                contents[4] = GET_REGISTER(arg5);
+                vsrc1--;
+            }
+            for (i = 0; i < vsrc1; i++) {
+                contents[i] = GET_REGISTER(vdst & 0x0f);
+                vdst >>= 4;
+            }
+        }
+        if (typeCh == 'L' || typeCh == '[') {
+            dvmWriteBarrierArray(newArray, 0, newArray->length);
+        }
+
+        retval.l = (Object*)newArray;
+    }
+    FINISH(3);
+GOTO_TARGET_END
+
+
+GOTO_TARGET(invokeVirtual, bool methodCallRange, bool)
+    {
+        Method* baseMethod;
+        Object* thisPtr;
+
+        EXPORT_PC();
+
+        vsrc1 = INST_AA(inst);      /* AA (count) or BA (count + arg 5) */
+        ref = FETCH(1);             /* method ref */
+        vdst = FETCH(2);            /* 4 regs -or- first reg */
+
+        /*
+         * The object against which we are executing a method is always
+         * in the first argument.
+         */
+        if (methodCallRange) {
+            assert(vsrc1 > 0);
+            ILOGV("|invoke-virtual-range args=%d @0x%04x {regs=v%d-v%d}",
+                vsrc1, ref, vdst, vdst+vsrc1-1);
+            thisPtr = (Object*) GET_REGISTER(vdst);
+        } else {
+            assert((vsrc1>>4) > 0);
+            ILOGV("|invoke-virtual args=%d @0x%04x {regs=0x%04x %x}",
+                vsrc1 >> 4, ref, vdst, vsrc1 & 0x0f);
+            thisPtr = (Object*) GET_REGISTER(vdst & 0x0f);
+        }
+
+        if (!checkForNull(thisPtr))
+            GOTO_exceptionThrown();
+
+        /*
+         * Resolve the method.  This is the correct method for the static
+         * type of the object.  We also verify access permissions here.
+         */
+        baseMethod = dvmDexGetResolvedMethod(methodClassDex, ref);
+        if (baseMethod == NULL) {
+            baseMethod = dvmResolveMethod(curMethod->clazz, ref,METHOD_VIRTUAL);
+            if (baseMethod == NULL) {
+                ILOGV("+ unknown method or access denied");
+                GOTO_exceptionThrown();
+            }
+        }
+
+        /*
+         * Combine the object we found with the vtable offset in the
+         * method.
+         */
+        assert(baseMethod->methodIndex < thisPtr->clazz->vtableCount);
+        methodToCall = thisPtr->clazz->vtable[baseMethod->methodIndex];
+
+#if defined(WITH_JIT) && defined(MTERP_STUB)
+        self->methodToCall = methodToCall;
+        self->callsiteClass = thisPtr->clazz;
+#endif
+
+#if 0
+        if (dvmIsAbstractMethod(methodToCall)) {
+            /*
+             * This can happen if you create two classes, Base and Sub, where
+             * Sub is a sub-class of Base.  Declare a protected abstract
+             * method foo() in Base, and invoke foo() from a method in Base.
+             * Base is an "abstract base class" and is never instantiated
+             * directly.  Now, Override foo() in Sub, and use Sub.  This
+             * Works fine unless Sub stops providing an implementation of
+             * the method.
+             */
+            dvmThrowAbstractMethodError("abstract method not implemented");
+            GOTO_exceptionThrown();
+        }
+#else
+        assert(!dvmIsAbstractMethod(methodToCall) ||
+            methodToCall->nativeFunc != NULL);
+#endif
+
+        LOGVV("+++ base=%s.%s virtual[%d]=%s.%s",
+            baseMethod->clazz->descriptor, baseMethod->name,
+            (u4) baseMethod->methodIndex,
+            methodToCall->clazz->descriptor, methodToCall->name);
+        assert(methodToCall != NULL);
+
+#if 0
+        if (vsrc1 != methodToCall->insSize) {
+            ALOGW("WRONG METHOD: base=%s.%s virtual[%d]=%s.%s",
+                baseMethod->clazz->descriptor, baseMethod->name,
+                (u4) baseMethod->methodIndex,
+                methodToCall->clazz->descriptor, methodToCall->name);
+            //dvmDumpClass(baseMethod->clazz);
+            //dvmDumpClass(methodToCall->clazz);
+            dvmDumpAllClasses(0);
+        }
+#endif
+
+        GOTO_invokeMethod(methodCallRange, methodToCall, vsrc1, vdst);
+    }
+GOTO_TARGET_END
+
+GOTO_TARGET(invokeSuper, bool methodCallRange)
+    {
+        Method* baseMethod;
+        u2 thisReg;
+
+        EXPORT_PC();
+
+        vsrc1 = INST_AA(inst);      /* AA (count) or BA (count + arg 5) */
+        ref = FETCH(1);             /* method ref */
+        vdst = FETCH(2);            /* 4 regs -or- first reg */
+
+        if (methodCallRange) {
+            ILOGV("|invoke-super-range args=%d @0x%04x {regs=v%d-v%d}",
+                vsrc1, ref, vdst, vdst+vsrc1-1);
+            thisReg = vdst;
+        } else {
+            ILOGV("|invoke-super args=%d @0x%04x {regs=0x%04x %x}",
+                vsrc1 >> 4, ref, vdst, vsrc1 & 0x0f);
+            thisReg = vdst & 0x0f;
+        }
+
+        /* impossible in well-formed code, but we must check nevertheless */
+        if (!checkForNull((Object*) GET_REGISTER(thisReg)))
+            GOTO_exceptionThrown();
+
+        /*
+         * Resolve the method.  This is the correct method for the static
+         * type of the object.  We also verify access permissions here.
+         * The first arg to dvmResolveMethod() is just the referring class
+         * (used for class loaders and such), so we don't want to pass
+         * the superclass into the resolution call.
+         */
+        baseMethod = dvmDexGetResolvedMethod(methodClassDex, ref);
+        if (baseMethod == NULL) {
+            baseMethod = dvmResolveMethod(curMethod->clazz, ref,METHOD_VIRTUAL);
+            if (baseMethod == NULL) {
+                ILOGV("+ unknown method or access denied");
+                GOTO_exceptionThrown();
+            }
+        }
+
+        /*
+         * Combine the object we found with the vtable offset in the
+         * method's class.
+         *
+         * We're using the current method's class' superclass, not the
+         * superclass of "this".  This is because we might be executing
+         * in a method inherited from a superclass, and we want to run
+         * in that class' superclass.
+         */
+        if (baseMethod->methodIndex >= curMethod->clazz->super->vtableCount) {
+            /*
+             * Method does not exist in the superclass.  Could happen if
+             * superclass gets updated.
+             */
+            dvmThrowNoSuchMethodError(baseMethod->name);
+            GOTO_exceptionThrown();
+        }
+        methodToCall = curMethod->clazz->super->vtable[baseMethod->methodIndex];
+
+#if 0
+        if (dvmIsAbstractMethod(methodToCall)) {
+            dvmThrowAbstractMethodError("abstract method not implemented");
+            GOTO_exceptionThrown();
+        }
+#else
+        assert(!dvmIsAbstractMethod(methodToCall) ||
+            methodToCall->nativeFunc != NULL);
+#endif
+        LOGVV("+++ base=%s.%s super-virtual=%s.%s",
+            baseMethod->clazz->descriptor, baseMethod->name,
+            methodToCall->clazz->descriptor, methodToCall->name);
+        assert(methodToCall != NULL);
+
+        GOTO_invokeMethod(methodCallRange, methodToCall, vsrc1, vdst);
+    }
+GOTO_TARGET_END
+
+GOTO_TARGET(invokeInterface, bool methodCallRange)
+    {
+        Object* thisPtr;
+        ClassObject* thisClass;
+
+        EXPORT_PC();
+
+        vsrc1 = INST_AA(inst);      /* AA (count) or BA (count + arg 5) */
+        ref = FETCH(1);             /* method ref */
+        vdst = FETCH(2);            /* 4 regs -or- first reg */
+
+        /*
+         * The object against which we are executing a method is always
+         * in the first argument.
+         */
+        if (methodCallRange) {
+            assert(vsrc1 > 0);
+            ILOGV("|invoke-interface-range args=%d @0x%04x {regs=v%d-v%d}",
+                vsrc1, ref, vdst, vdst+vsrc1-1);
+            thisPtr = (Object*) GET_REGISTER(vdst);
+        } else {
+            assert((vsrc1>>4) > 0);
+            ILOGV("|invoke-interface args=%d @0x%04x {regs=0x%04x %x}",
+                vsrc1 >> 4, ref, vdst, vsrc1 & 0x0f);
+            thisPtr = (Object*) GET_REGISTER(vdst & 0x0f);
+        }
+
+        if (!checkForNull(thisPtr))
+            GOTO_exceptionThrown();
+
+        thisClass = thisPtr->clazz;
+
+        /*
+         * Given a class and a method index, find the Method* with the
+         * actual code we want to execute.
+         */
+        methodToCall = dvmFindInterfaceMethodInCache(thisClass, ref, curMethod,
+                        methodClassDex);
+#if defined(WITH_JIT) && defined(MTERP_STUB)
+        self->callsiteClass = thisClass;
+        self->methodToCall = methodToCall;
+#endif
+        if (methodToCall == NULL) {
+            assert(dvmCheckException(self));
+            GOTO_exceptionThrown();
+        }
+
+        GOTO_invokeMethod(methodCallRange, methodToCall, vsrc1, vdst);
+    }
+GOTO_TARGET_END
+
+GOTO_TARGET(invokeDirect, bool methodCallRange)
+    {
+        u2 thisReg;
+
+        EXPORT_PC();
+
+        vsrc1 = INST_AA(inst);      /* AA (count) or BA (count + arg 5) */
+        ref = FETCH(1);             /* method ref */
+        vdst = FETCH(2);            /* 4 regs -or- first reg */
+
+        if (methodCallRange) {
+            ILOGV("|invoke-direct-range args=%d @0x%04x {regs=v%d-v%d}",
+                vsrc1, ref, vdst, vdst+vsrc1-1);
+            thisReg = vdst;
+        } else {
+            ILOGV("|invoke-direct args=%d @0x%04x {regs=0x%04x %x}",
+                vsrc1 >> 4, ref, vdst, vsrc1 & 0x0f);
+            thisReg = vdst & 0x0f;
+        }
+
+        if (!checkForNull((Object*) GET_REGISTER(thisReg)))
+            GOTO_exceptionThrown();
+
+        methodToCall = dvmDexGetResolvedMethod(methodClassDex, ref);
+        if (methodToCall == NULL) {
+            methodToCall = dvmResolveMethod(curMethod->clazz, ref,
+                            METHOD_DIRECT);
+            if (methodToCall == NULL) {
+                ILOGV("+ unknown direct method");     // should be impossible
+                GOTO_exceptionThrown();
+            }
+        }
+        GOTO_invokeMethod(methodCallRange, methodToCall, vsrc1, vdst);
+    }
+GOTO_TARGET_END
+
+GOTO_TARGET(invokeStatic, bool methodCallRange)
+    EXPORT_PC();
+
+    vsrc1 = INST_AA(inst);      /* AA (count) or BA (count + arg 5) */
+    ref = FETCH(1);             /* method ref */
+    vdst = FETCH(2);            /* 4 regs -or- first reg */
+
+    if (methodCallRange)
+        ILOGV("|invoke-static-range args=%d @0x%04x {regs=v%d-v%d}",
+            vsrc1, ref, vdst, vdst+vsrc1-1);
+    else
+        ILOGV("|invoke-static args=%d @0x%04x {regs=0x%04x %x}",
+            vsrc1 >> 4, ref, vdst, vsrc1 & 0x0f);
+
+    methodToCall = dvmDexGetResolvedMethod(methodClassDex, ref);
+    if (methodToCall == NULL) {
+        methodToCall = dvmResolveMethod(curMethod->clazz, ref, METHOD_STATIC);
+        if (methodToCall == NULL) {
+            ILOGV("+ unknown method");
+            GOTO_exceptionThrown();
+        }
+
+#if defined(WITH_JIT) && defined(MTERP_STUB)
+        /*
+         * The JIT needs dvmDexGetResolvedMethod() to return non-null.
+         * Include the check if this code is being used as a stub
+         * called from the assembly interpreter.
+         */
+        if ((self->interpBreak.ctl.subMode & kSubModeJitTraceBuild) &&
+            (dvmDexGetResolvedMethod(methodClassDex, ref) == NULL)) {
+            /* Class initialization is still ongoing */
+            dvmJitEndTraceSelect(self,pc);
+        }
+#endif
+    }
+    GOTO_invokeMethod(methodCallRange, methodToCall, vsrc1, vdst);
+GOTO_TARGET_END
+
+GOTO_TARGET(invokeVirtualQuick, bool methodCallRange)
+    {
+        Object* thisPtr;
+
+        EXPORT_PC();
+
+        vsrc1 = INST_AA(inst);      /* AA (count) or BA (count + arg 5) */
+        ref = FETCH(1);             /* vtable index */
+        vdst = FETCH(2);            /* 4 regs -or- first reg */
+
+        /*
+         * The object against which we are executing a method is always
+         * in the first argument.
+         */
+        if (methodCallRange) {
+            assert(vsrc1 > 0);
+            ILOGV("|invoke-virtual-quick-range args=%d @0x%04x {regs=v%d-v%d}",
+                vsrc1, ref, vdst, vdst+vsrc1-1);
+            thisPtr = (Object*) GET_REGISTER(vdst);
+        } else {
+            assert((vsrc1>>4) > 0);
+            ILOGV("|invoke-virtual-quick args=%d @0x%04x {regs=0x%04x %x}",
+                vsrc1 >> 4, ref, vdst, vsrc1 & 0x0f);
+            thisPtr = (Object*) GET_REGISTER(vdst & 0x0f);
+        }
+
+        if (!checkForNull(thisPtr))
+            GOTO_exceptionThrown();
+
+
+        /*
+         * Combine the object we found with the vtable offset in the
+         * method.
+         */
+        assert(ref < (unsigned int) thisPtr->clazz->vtableCount);
+        methodToCall = thisPtr->clazz->vtable[ref];
+#if defined(WITH_JIT) && defined(MTERP_STUB)
+        self->callsiteClass = thisPtr->clazz;
+        self->methodToCall = methodToCall;
+#endif
+
+#if 0
+        if (dvmIsAbstractMethod(methodToCall)) {
+            dvmThrowAbstractMethodError("abstract method not implemented");
+            GOTO_exceptionThrown();
+        }
+#else
+        assert(!dvmIsAbstractMethod(methodToCall) ||
+            methodToCall->nativeFunc != NULL);
+#endif
+
+        LOGVV("+++ virtual[%d]=%s.%s",
+            ref, methodToCall->clazz->descriptor, methodToCall->name);
+        assert(methodToCall != NULL);
+
+        GOTO_invokeMethod(methodCallRange, methodToCall, vsrc1, vdst);
+    }
+GOTO_TARGET_END
+
+GOTO_TARGET(invokeSuperQuick, bool methodCallRange)
+    {
+        u2 thisReg;
+
+        EXPORT_PC();
+
+        vsrc1 = INST_AA(inst);      /* AA (count) or BA (count + arg 5) */
+        ref = FETCH(1);             /* vtable index */
+        vdst = FETCH(2);            /* 4 regs -or- first reg */
+
+        if (methodCallRange) {
+            ILOGV("|invoke-super-quick-range args=%d @0x%04x {regs=v%d-v%d}",
+                vsrc1, ref, vdst, vdst+vsrc1-1);
+            thisReg = vdst;
+        } else {
+            ILOGV("|invoke-super-quick args=%d @0x%04x {regs=0x%04x %x}",
+                vsrc1 >> 4, ref, vdst, vsrc1 & 0x0f);
+            thisReg = vdst & 0x0f;
+        }
+        /* impossible in well-formed code, but we must check nevertheless */
+        if (!checkForNull((Object*) GET_REGISTER(thisReg)))
+            GOTO_exceptionThrown();
+
+#if 0   /* impossible in optimized + verified code */
+        if (ref >= curMethod->clazz->super->vtableCount) {
+            dvmThrowNoSuchMethodError(NULL);
+            GOTO_exceptionThrown();
+        }
+#else
+        assert(ref < (unsigned int) curMethod->clazz->super->vtableCount);
+#endif
+
+        /*
+         * Combine the object we found with the vtable offset in the
+         * method's class.
+         *
+         * We're using the current method's class' superclass, not the
+         * superclass of "this".  This is because we might be executing
+         * in a method inherited from a superclass, and we want to run
+         * in the method's class' superclass.
+         */
+        methodToCall = curMethod->clazz->super->vtable[ref];
+
+#if 0
+        if (dvmIsAbstractMethod(methodToCall)) {
+            dvmThrowAbstractMethodError("abstract method not implemented");
+            GOTO_exceptionThrown();
+        }
+#else
+        assert(!dvmIsAbstractMethod(methodToCall) ||
+            methodToCall->nativeFunc != NULL);
+#endif
+        LOGVV("+++ super-virtual[%d]=%s.%s",
+            ref, methodToCall->clazz->descriptor, methodToCall->name);
+        assert(methodToCall != NULL);
+        GOTO_invokeMethod(methodCallRange, methodToCall, vsrc1, vdst);
+    }
+GOTO_TARGET_END
+
+
+    /*
+     * General handling for return-void, return, and return-wide.  Put the
+     * return value in "retval" before jumping here.
+     */
+GOTO_TARGET(returnFromMethod)
+    {
+        StackSaveArea* saveArea;
+
+        /*
+         * We must do this BEFORE we pop the previous stack frame off, so
+         * that the GC can see the return value (if any) in the local vars.
+         *
+         * Since this is now an interpreter switch point, we must do it before
+         * we do anything at all.
+         */
+        PERIODIC_CHECKS(0);
+
+        ILOGV("> retval=0x%llx (leaving %s.%s %s)",
+            retval.j, curMethod->clazz->descriptor, curMethod->name,
+            curMethod->shorty);
+        //DUMP_REGS(curMethod, fp);
+
+        saveArea = SAVEAREA_FROM_FP(fp);
+
+#ifdef EASY_GDB
+        debugSaveArea = saveArea;
+#endif
+
+        /* back up to previous frame and see if we hit a break */
+        fp = (u4*)saveArea->prevFrame;
+        assert(fp != NULL);
+
+        /* Handle any special subMode requirements */
+        if (self->interpBreak.ctl.subMode != 0) {
+            PC_FP_TO_SELF();
+            dvmReportReturn(self);
+        }
+
+        if (dvmIsBreakFrame(fp)) {
+            /* bail without popping the method frame from stack */
+            LOGVV("+++ returned into break frame");
+            GOTO_bail();
+        }
+
+        /* update thread FP, and reset local variables */
+        self->interpSave.curFrame = fp;
+        curMethod = SAVEAREA_FROM_FP(fp)->method;
+        self->interpSave.method = curMethod;
+        //methodClass = curMethod->clazz;
+        methodClassDex = curMethod->clazz->pDvmDex;
+        pc = saveArea->savedPc;
+        ILOGD("> (return to %s.%s %s)", curMethod->clazz->descriptor,
+            curMethod->name, curMethod->shorty);
+
+        /* use FINISH on the caller's invoke instruction */
+        //u2 invokeInstr = INST_INST(FETCH(0));
+        if (true /*invokeInstr >= OP_INVOKE_VIRTUAL &&
+            invokeInstr <= OP_INVOKE_INTERFACE*/)
+        {
+            FINISH(3);
+        } else {
+            //ALOGE("Unknown invoke instr %02x at %d",
+            //    invokeInstr, (int) (pc - curMethod->insns));
+            assert(false);
+        }
+    }
+GOTO_TARGET_END
+
+
+    /*
+     * Jump here when the code throws an exception.
+     *
+     * By the time we get here, the Throwable has been created and the stack
+     * trace has been saved off.
+     */
+GOTO_TARGET(exceptionThrown)
+    {
+        Object* exception;
+        int catchRelPc;
+
+        PERIODIC_CHECKS(0);
+
+        /*
+         * We save off the exception and clear the exception status.  While
+         * processing the exception we might need to load some Throwable
+         * classes, and we don't want class loader exceptions to get
+         * confused with this one.
+         */
+        assert(dvmCheckException(self));
+        exception = dvmGetException(self);
+        dvmAddTrackedAlloc(exception, self);
+        dvmClearException(self);
+
+        ALOGV("Handling exception %s at %s:%d",
+            exception->clazz->descriptor, curMethod->name,
+            dvmLineNumFromPC(curMethod, pc - curMethod->insns));
+
+        /*
+         * Report the exception throw to any "subMode" watchers.
+         *
+         * TODO: if the exception was thrown by interpreted code, control
+         * fell through native, and then back to us, we will report the
+         * exception at the point of the throw and again here.  We can avoid
+         * this by not reporting exceptions when we jump here directly from
+         * the native call code above, but then we won't report exceptions
+         * that were thrown *from* the JNI code (as opposed to *through* it).
+         *
+         * The correct solution is probably to ignore from-native exceptions
+         * here, and have the JNI exception code do the reporting to the
+         * debugger.
+         */
+        if (self->interpBreak.ctl.subMode != 0) {
+            PC_FP_TO_SELF();
+            dvmReportExceptionThrow(self, exception);
+        }
+
+        /*
+         * We need to unroll to the catch block or the nearest "break"
+         * frame.
+         *
+         * A break frame could indicate that we have reached an intermediate
+         * native call, or have gone off the top of the stack and the thread
+         * needs to exit.  Either way, we return from here, leaving the
+         * exception raised.
+         *
+         * If we do find a catch block, we want to transfer execution to
+         * that point.
+         *
+         * Note this can cause an exception while resolving classes in
+         * the "catch" blocks.
+         */
+        catchRelPc = dvmFindCatchBlock(self, pc - curMethod->insns,
+                    exception, false, (void**)(void*)&fp);
+
+        /*
+         * Restore the stack bounds after an overflow.  This isn't going to
+         * be correct in all circumstances, e.g. if JNI code devours the
+         * exception this won't happen until some other exception gets
+         * thrown.  If the code keeps pushing the stack bounds we'll end
+         * up aborting the VM.
+         *
+         * Note we want to do this *after* the call to dvmFindCatchBlock,
+         * because that may need extra stack space to resolve exception
+         * classes (e.g. through a class loader).
+         *
+         * It's possible for the stack overflow handling to cause an
+         * exception (specifically, class resolution in a "catch" block
+         * during the call above), so we could see the thread's overflow
+         * flag raised but actually be running in a "nested" interpreter
+         * frame.  We don't allow doubled-up StackOverflowErrors, so
+         * we can check for this by just looking at the exception type
+         * in the cleanup function.  Also, we won't unroll past the SOE
+         * point because the more-recent exception will hit a break frame
+         * as it unrolls to here.
+         */
+        if (self->stackOverflowed)
+            dvmCleanupStackOverflow(self, exception);
+
+        if (catchRelPc < 0) {
+            /* falling through to JNI code or off the bottom of the stack */
+#if DVM_SHOW_EXCEPTION >= 2
+            ALOGD("Exception %s from %s:%d not caught locally",
+                exception->clazz->descriptor, dvmGetMethodSourceFile(curMethod),
+                dvmLineNumFromPC(curMethod, pc - curMethod->insns));
+#endif
+            dvmSetException(self, exception);
+            dvmReleaseTrackedAlloc(exception, self);
+            GOTO_bail();
+        }
+
+#if DVM_SHOW_EXCEPTION >= 3
+        {
+            const Method* catchMethod = SAVEAREA_FROM_FP(fp)->method;
+            ALOGD("Exception %s thrown from %s:%d to %s:%d",
+                exception->clazz->descriptor, dvmGetMethodSourceFile(curMethod),
+                dvmLineNumFromPC(curMethod, pc - curMethod->insns),
+                dvmGetMethodSourceFile(catchMethod),
+                dvmLineNumFromPC(catchMethod, catchRelPc));
+        }
+#endif
+
+        /*
+         * Adjust local variables to match self->interpSave.curFrame and the
+         * updated PC.
+         */
+        //fp = (u4*) self->interpSave.curFrame;
+        curMethod = SAVEAREA_FROM_FP(fp)->method;
+        self->interpSave.method = curMethod;
+        //methodClass = curMethod->clazz;
+        methodClassDex = curMethod->clazz->pDvmDex;
+        pc = curMethod->insns + catchRelPc;
+        ILOGV("> pc <-- %s.%s %s", curMethod->clazz->descriptor,
+            curMethod->name, curMethod->shorty);
+        DUMP_REGS(curMethod, fp, false);            // show all regs
+
+        /*
+         * Restore the exception if the handler wants it.
+         *
+         * The Dalvik spec mandates that, if an exception handler wants to
+         * do something with the exception, the first instruction executed
+         * must be "move-exception".  We can pass the exception along
+         * through the thread struct, and let the move-exception instruction
+         * clear it for us.
+         *
+         * If the handler doesn't call move-exception, we don't want to
+         * finish here with an exception still pending.
+         */
+        if (INST_INST(FETCH(0)) == OP_MOVE_EXCEPTION)
+            dvmSetException(self, exception);
+
+        dvmReleaseTrackedAlloc(exception, self);
+        FINISH(0);
+    }
+GOTO_TARGET_END
+
+
+
+    /*
+     * General handling for invoke-{virtual,super,direct,static,interface},
+     * including "quick" variants.
+     *
+     * Set "methodToCall" to the Method we're calling, and "methodCallRange"
+     * depending on whether this is a "/range" instruction.
+     *
+     * For a range call:
+     *  "vsrc1" holds the argument count (8 bits)
+     *  "vdst" holds the first argument in the range
+     * For a non-range call:
+     *  "vsrc1" holds the argument count (4 bits) and the 5th argument index
+     *  "vdst" holds four 4-bit register indices
+     *
+     * The caller must EXPORT_PC before jumping here, because any method
+     * call can throw a stack overflow exception.
+     */
+GOTO_TARGET(invokeMethod, bool methodCallRange, const Method* _methodToCall,
+    u2 count, u2 regs)
+    {
+        STUB_HACK(vsrc1 = count; vdst = regs; methodToCall = _methodToCall;);
+
+        //printf("range=%d call=%p count=%d regs=0x%04x\n",
+        //    methodCallRange, methodToCall, count, regs);
+        //printf(" --> %s.%s %s\n", methodToCall->clazz->descriptor,
+        //    methodToCall->name, methodToCall->shorty);
+
+        u4* outs;
+        int i;
+
+        /*
+         * Copy args.  This may corrupt vsrc1/vdst.
+         */
+        if (methodCallRange) {
+            // could use memcpy or a "Duff's device"; most functions have
+            // so few args it won't matter much
+            assert(vsrc1 <= curMethod->outsSize);
+            assert(vsrc1 == methodToCall->insSize);
+            outs = OUTS_FROM_FP(fp, vsrc1);
+            for (i = 0; i < vsrc1; i++)
+                outs[i] = GET_REGISTER(vdst+i);
+        } else {
+            u4 count = vsrc1 >> 4;
+
+            assert(count <= curMethod->outsSize);
+            assert(count == methodToCall->insSize);
+            assert(count <= 5);
+
+            outs = OUTS_FROM_FP(fp, count);
+#if 0
+            if (count == 5) {
+                outs[4] = GET_REGISTER(vsrc1 & 0x0f);
+                count--;
+            }
+            for (i = 0; i < (int) count; i++) {
+                outs[i] = GET_REGISTER(vdst & 0x0f);
+                vdst >>= 4;
+            }
+#else
+            // This version executes fewer instructions but is larger
+            // overall.  Seems to be a teensy bit faster.
+            assert((vdst >> 16) == 0);  // 16 bits -or- high 16 bits clear
+            switch (count) {
+            case 5:
+                outs[4] = GET_REGISTER(vsrc1 & 0x0f);
+            case 4:
+                outs[3] = GET_REGISTER(vdst >> 12);
+            case 3:
+                outs[2] = GET_REGISTER((vdst & 0x0f00) >> 8);
+            case 2:
+                outs[1] = GET_REGISTER((vdst & 0x00f0) >> 4);
+            case 1:
+                outs[0] = GET_REGISTER(vdst & 0x0f);
+            default:
+                ;
+            }
+#endif
+        }
+    }
+
+    /*
+     * (This was originally a "goto" target; I've kept it separate from the
+     * stuff above in case we want to refactor things again.)
+     *
+     * At this point, we have the arguments stored in the "outs" area of
+     * the current method's stack frame, and the method to call in
+     * "methodToCall".  Push a new stack frame.
+     */
+    {
+        StackSaveArea* newSaveArea;
+        u4* newFp;
+
+        ILOGV("> %s%s.%s %s",
+            dvmIsNativeMethod(methodToCall) ? "(NATIVE) " : "",
+            methodToCall->clazz->descriptor, methodToCall->name,
+            methodToCall->shorty);
+
+        newFp = (u4*) SAVEAREA_FROM_FP(fp) - methodToCall->registersSize;
+        newSaveArea = SAVEAREA_FROM_FP(newFp);
+
+        /* verify that we have enough space */
+        if (true) {
+            u1* bottom;
+            bottom = (u1*) newSaveArea - methodToCall->outsSize * sizeof(u4);
+            if (bottom < self->interpStackEnd) {
+                /* stack overflow */
+                ALOGV("Stack overflow on method call (start=%p end=%p newBot=%p(%d) size=%d '%s')",
+                    self->interpStackStart, self->interpStackEnd, bottom,
+                    (u1*) fp - bottom, self->interpStackSize,
+                    methodToCall->name);
+                dvmHandleStackOverflow(self, methodToCall);
+                assert(dvmCheckException(self));
+                GOTO_exceptionThrown();
+            }
+            //ALOGD("+++ fp=%p newFp=%p newSave=%p bottom=%p",
+            //    fp, newFp, newSaveArea, bottom);
+        }
+
+#ifdef LOG_INSTR
+        if (methodToCall->registersSize > methodToCall->insSize) {
+            /*
+             * This makes valgrind quiet when we print registers that
+             * haven't been initialized.  Turn it off when the debug
+             * messages are disabled -- we want valgrind to report any
+             * used-before-initialized issues.
+             */
+            memset(newFp, 0xcc,
+                (methodToCall->registersSize - methodToCall->insSize) * 4);
+        }
+#endif
+
+#ifdef EASY_GDB
+        newSaveArea->prevSave = SAVEAREA_FROM_FP(fp);
+#endif
+        newSaveArea->prevFrame = fp;
+        newSaveArea->savedPc = pc;
+#if defined(WITH_JIT) && defined(MTERP_STUB)
+        newSaveArea->returnAddr = 0;
+#endif
+        newSaveArea->method = methodToCall;
+
+        if (self->interpBreak.ctl.subMode != 0) {
+            /*
+             * We mark ENTER here for both native and non-native
+             * calls.  For native calls, we'll mark EXIT on return.
+             * For non-native calls, EXIT is marked in the RETURN op.
+             */
+            PC_TO_SELF();
+            dvmReportInvoke(self, methodToCall);
+        }
+
+        if (!dvmIsNativeMethod(methodToCall)) {
+            /*
+             * "Call" interpreted code.  Reposition the PC, update the
+             * frame pointer and other local state, and continue.
+             */
+            curMethod = methodToCall;
+            self->interpSave.method = curMethod;
+            methodClassDex = curMethod->clazz->pDvmDex;
+            pc = methodToCall->insns;
+            fp = newFp;
+            self->interpSave.curFrame = fp;
+#ifdef EASY_GDB
+            debugSaveArea = SAVEAREA_FROM_FP(newFp);
+#endif
+            self->debugIsMethodEntry = true;        // profiling, debugging
+            ILOGD("> pc <-- %s.%s %s", curMethod->clazz->descriptor,
+                curMethod->name, curMethod->shorty);
+            DUMP_REGS(curMethod, fp, true);         // show input args
+            FINISH(0);                              // jump to method start
+        } else {
+            /* set this up for JNI locals, even if not a JNI native */
+            newSaveArea->xtra.localRefCookie = self->jniLocalRefTable.segmentState.all;
+
+            self->interpSave.curFrame = newFp;
+
+            DUMP_REGS(methodToCall, newFp, true);   // show input args
+
+            if (self->interpBreak.ctl.subMode != 0) {
+                dvmReportPreNativeInvoke(methodToCall, self, fp);
+            }
+
+            ILOGD("> native <-- %s.%s %s", methodToCall->clazz->descriptor,
+                  methodToCall->name, methodToCall->shorty);
+
+            /*
+             * Jump through native call bridge.  Because we leave no
+             * space for locals on native calls, "newFp" points directly
+             * to the method arguments.
+             */
+            (*methodToCall->nativeFunc)(newFp, &retval, methodToCall, self);
+
+            if (self->interpBreak.ctl.subMode != 0) {
+                dvmReportPostNativeInvoke(methodToCall, self, fp);
+            }
+
+            /* pop frame off */
+            dvmPopJniLocals(self, newSaveArea);
+            self->interpSave.curFrame = fp;
+
+            /*
+             * If the native code threw an exception, or interpreted code
+             * invoked by the native call threw one and nobody has cleared
+             * it, jump to our local exception handling.
+             */
+            if (dvmCheckException(self)) {
+                ALOGV("Exception thrown by/below native code");
+                GOTO_exceptionThrown();
+            }
+
+            ILOGD("> retval=0x%llx (leaving native)", retval.j);
+            ILOGD("> (return from native %s.%s to %s.%s %s)",
+                methodToCall->clazz->descriptor, methodToCall->name,
+                curMethod->clazz->descriptor, curMethod->name,
+                curMethod->shorty);
+
+            //u2 invokeInstr = INST_INST(FETCH(0));
+            if (true /*invokeInstr >= OP_INVOKE_VIRTUAL &&
+                invokeInstr <= OP_INVOKE_INTERFACE*/)
+            {
+                FINISH(3);
+            } else {
+                //ALOGE("Unknown invoke instr %02x at %d",
+                //    invokeInstr, (int) (pc - curMethod->insns));
+                assert(false);
+            }
+        }
+    }
+    assert(false);      // should not get here
+GOTO_TARGET_END
diff --git a/vm/mterp/c_notaint/header.cpp b/vm/mterp/c_notaint/header.cpp
new file mode 100644
index 0000000..d0e55f5
--- /dev/null
+++ b/vm/mterp/c_notaint/header.cpp
@@ -0,0 +1,361 @@
+/*
+ * Copyright (C) 2008 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+/* common includes */
+#include "Dalvik.h"
+#include "interp/InterpDefs.h"
+#include "mterp/Mterp.h"
+#include <math.h>                   // needed for fmod, fmodf
+#include "mterp/common/FindInterface.h"
+
+/*
+ * Configuration defines.  These affect the C implementations, i.e. the
+ * portable interpreter(s) and C stubs.
+ *
+ * Some defines are controlled by the Makefile, e.g.:
+ *   WITH_INSTR_CHECKS
+ *   WITH_TRACKREF_CHECKS
+ *   EASY_GDB
+ *   NDEBUG
+ */
+
+#ifdef WITH_INSTR_CHECKS            /* instruction-level paranoia (slow!) */
+# define CHECK_BRANCH_OFFSETS
+# define CHECK_REGISTER_INDICES
+#endif
+
+/*
+ * Some architectures require 64-bit alignment for access to 64-bit data
+ * types.  We can't just use pointers to copy 64-bit values out of our
+ * interpreted register set, because gcc may assume the pointer target is
+ * aligned and generate invalid code.
+ *
+ * There are two common approaches:
+ *  (1) Use a union that defines a 32-bit pair and a 64-bit value.
+ *  (2) Call memcpy().
+ *
+ * Depending upon what compiler you're using and what options are specified,
+ * one may be faster than the other.  For example, the compiler might
+ * convert a memcpy() of 8 bytes into a series of instructions and omit
+ * the call.  The union version could cause some strange side-effects,
+ * e.g. for a while ARM gcc thought it needed separate storage for each
+ * inlined instance, and generated instructions to zero out ~700 bytes of
+ * stack space at the top of the interpreter.
+ *
+ * The default is to use memcpy().  The current gcc for ARM seems to do
+ * better with the union.
+ */
+#if defined(__ARM_EABI__)
+# define NO_UNALIGN_64__UNION
+#endif
+
+
+//#define LOG_INSTR                   /* verbose debugging */
+/* set and adjust ANDROID_LOG_TAGS='*:i jdwp:i dalvikvm:i dalvikvmi:i' */
+
+/*
+ * Export another copy of the PC on every instruction; this is largely
+ * redundant with EXPORT_PC and the debugger code.  This value can be
+ * compared against what we have stored on the stack with EXPORT_PC to
+ * help ensure that we aren't missing any export calls.
+ */
+#if WITH_EXTRA_GC_CHECKS > 1
+# define EXPORT_EXTRA_PC() (self->currentPc2 = pc)
+#else
+# define EXPORT_EXTRA_PC()
+#endif
+
+/*
+ * Adjust the program counter.  "_offset" is a signed int, in 16-bit units.
+ *
+ * Assumes the existence of "const u2* pc" and "const u2* curMethod->insns".
+ *
+ * We don't advance the program counter until we finish an instruction or
+ * branch, because we do want to have to unroll the PC if there's an
+ * exception.
+ */
+#ifdef CHECK_BRANCH_OFFSETS
+# define ADJUST_PC(_offset) do {                                            \
+        int myoff = _offset;        /* deref only once */                   \
+        if (pc + myoff < curMethod->insns ||                                \
+            pc + myoff >= curMethod->insns + dvmGetMethodInsnsSize(curMethod)) \
+        {                                                                   \
+            char* desc;                                                     \
+            desc = dexProtoCopyMethodDescriptor(&curMethod->prototype);     \
+            ALOGE("Invalid branch %d at 0x%04x in %s.%s %s",                 \
+                myoff, (int) (pc - curMethod->insns),                       \
+                curMethod->clazz->descriptor, curMethod->name, desc);       \
+            free(desc);                                                     \
+            dvmAbort();                                                     \
+        }                                                                   \
+        pc += myoff;                                                        \
+        EXPORT_EXTRA_PC();                                                  \
+    } while (false)
+#else
+# define ADJUST_PC(_offset) do {                                            \
+        pc += _offset;                                                      \
+        EXPORT_EXTRA_PC();                                                  \
+    } while (false)
+#endif
+
+/*
+ * If enabled, log instructions as we execute them.
+ */
+#ifdef LOG_INSTR
+# define ILOGD(...) ILOG(LOG_DEBUG, __VA_ARGS__)
+# define ILOGV(...) ILOG(LOG_VERBOSE, __VA_ARGS__)
+# define ILOG(_level, ...) do {                                             \
+        char debugStrBuf[128];                                              \
+        snprintf(debugStrBuf, sizeof(debugStrBuf), __VA_ARGS__);            \
+        if (curMethod != NULL)                                              \
+            ALOG(_level, LOG_TAG"i", "%-2d|%04x%s",                          \
+                self->threadId, (int)(pc - curMethod->insns), debugStrBuf); \
+        else                                                                \
+            ALOG(_level, LOG_TAG"i", "%-2d|####%s",                          \
+                self->threadId, debugStrBuf);                               \
+    } while(false)
+void dvmDumpRegs(const Method* method, const u4* framePtr, bool inOnly);
+# define DUMP_REGS(_meth, _frame, _inOnly) dvmDumpRegs(_meth, _frame, _inOnly)
+static const char kSpacing[] = "            ";
+#else
+# define ILOGD(...) ((void)0)
+# define ILOGV(...) ((void)0)
+# define DUMP_REGS(_meth, _frame, _inOnly) ((void)0)
+#endif
+
+/* get a long from an array of u4 */
+static inline s8 getLongFromArray(const u4* ptr, int idx)
+{
+#if defined(NO_UNALIGN_64__UNION)
+    union { s8 ll; u4 parts[2]; } conv;
+
+    ptr += idx;
+    conv.parts[0] = ptr[0];
+    conv.parts[1] = ptr[1];
+    return conv.ll;
+#else
+    s8 val;
+    memcpy(&val, &ptr[idx], 8);
+    return val;
+#endif
+}
+
+/* store a long into an array of u4 */
+static inline void putLongToArray(u4* ptr, int idx, s8 val)
+{
+#if defined(NO_UNALIGN_64__UNION)
+    union { s8 ll; u4 parts[2]; } conv;
+
+    ptr += idx;
+    conv.ll = val;
+    ptr[0] = conv.parts[0];
+    ptr[1] = conv.parts[1];
+#else
+    memcpy(&ptr[idx], &val, 8);
+#endif
+}
+
+/* get a double from an array of u4 */
+static inline double getDoubleFromArray(const u4* ptr, int idx)
+{
+#if defined(NO_UNALIGN_64__UNION)
+    union { double d; u4 parts[2]; } conv;
+
+    ptr += idx;
+    conv.parts[0] = ptr[0];
+    conv.parts[1] = ptr[1];
+    return conv.d;
+#else
+    double dval;
+    memcpy(&dval, &ptr[idx], 8);
+    return dval;
+#endif
+}
+
+/* store a double into an array of u4 */
+static inline void putDoubleToArray(u4* ptr, int idx, double dval)
+{
+#if defined(NO_UNALIGN_64__UNION)
+    union { double d; u4 parts[2]; } conv;
+
+    ptr += idx;
+    conv.d = dval;
+    ptr[0] = conv.parts[0];
+    ptr[1] = conv.parts[1];
+#else
+    memcpy(&ptr[idx], &dval, 8);
+#endif
+}
+
+/*
+ * If enabled, validate the register number on every access.  Otherwise,
+ * just do an array access.
+ *
+ * Assumes the existence of "u4* fp".
+ *
+ * "_idx" may be referenced more than once.
+ */
+#ifdef CHECK_REGISTER_INDICES
+# define GET_REGISTER(_idx) \
+    ( (_idx) < curMethod->registersSize ? \
+        (fp[(_idx)]) : (assert(!"bad reg"),1969) )
+# define SET_REGISTER(_idx, _val) \
+    ( (_idx) < curMethod->registersSize ? \
+        (fp[(_idx)] = (u4)(_val)) : (assert(!"bad reg"),1969) )
+# define GET_REGISTER_AS_OBJECT(_idx)       ((Object *)GET_REGISTER(_idx))
+# define SET_REGISTER_AS_OBJECT(_idx, _val) SET_REGISTER(_idx, (s4)_val)
+# define GET_REGISTER_INT(_idx) ((s4) GET_REGISTER(_idx))
+# define SET_REGISTER_INT(_idx, _val) SET_REGISTER(_idx, (s4)_val)
+# define GET_REGISTER_WIDE(_idx) \
+    ( (_idx) < curMethod->registersSize-1 ? \
+        getLongFromArray(fp, (_idx)) : (assert(!"bad reg"),1969) )
+# define SET_REGISTER_WIDE(_idx, _val) \
+    ( (_idx) < curMethod->registersSize-1 ? \
+        (void)putLongToArray(fp, (_idx), (_val)) : assert(!"bad reg") )
+# define GET_REGISTER_FLOAT(_idx) \
+    ( (_idx) < curMethod->registersSize ? \
+        (*((float*) &fp[(_idx)])) : (assert(!"bad reg"),1969.0f) )
+# define SET_REGISTER_FLOAT(_idx, _val) \
+    ( (_idx) < curMethod->registersSize ? \
+        (*((float*) &fp[(_idx)]) = (_val)) : (assert(!"bad reg"),1969.0f) )
+# define GET_REGISTER_DOUBLE(_idx) \
+    ( (_idx) < curMethod->registersSize-1 ? \
+        getDoubleFromArray(fp, (_idx)) : (assert(!"bad reg"),1969.0) )
+# define SET_REGISTER_DOUBLE(_idx, _val) \
+    ( (_idx) < curMethod->registersSize-1 ? \
+        (void)putDoubleToArray(fp, (_idx), (_val)) : assert(!"bad reg") )
+#else
+# define GET_REGISTER(_idx)                 (fp[(_idx)])
+# define SET_REGISTER(_idx, _val)           (fp[(_idx)] = (_val))
+# define GET_REGISTER_AS_OBJECT(_idx)       ((Object*) fp[(_idx)])
+# define SET_REGISTER_AS_OBJECT(_idx, _val) (fp[(_idx)] = (u4)(_val))
+# define GET_REGISTER_INT(_idx)             ((s4)GET_REGISTER(_idx))
+# define SET_REGISTER_INT(_idx, _val)       SET_REGISTER(_idx, (s4)_val)
+# define GET_REGISTER_WIDE(_idx)            getLongFromArray(fp, (_idx))
+# define SET_REGISTER_WIDE(_idx, _val)      putLongToArray(fp, (_idx), (_val))
+# define GET_REGISTER_FLOAT(_idx)           (*((float*) &fp[(_idx)]))
+# define SET_REGISTER_FLOAT(_idx, _val)     (*((float*) &fp[(_idx)]) = (_val))
+# define GET_REGISTER_DOUBLE(_idx)          getDoubleFromArray(fp, (_idx))
+# define SET_REGISTER_DOUBLE(_idx, _val)    putDoubleToArray(fp, (_idx), (_val))
+#endif
+
+/*
+ * Get 16 bits from the specified offset of the program counter.  We always
+ * want to load 16 bits at a time from the instruction stream -- it's more
+ * efficient than 8 and won't have the alignment problems that 32 might.
+ *
+ * Assumes existence of "const u2* pc".
+ */
+#define FETCH(_offset)     (pc[(_offset)])
+
+/*
+ * Extract instruction byte from 16-bit fetch (_inst is a u2).
+ */
+#define INST_INST(_inst)    ((_inst) & 0xff)
+
+/*
+ * Replace the opcode (used when handling breakpoints).  _opcode is a u1.
+ */
+#define INST_REPLACE_OP(_inst, _opcode) (((_inst) & 0xff00) | _opcode)
+
+/*
+ * Extract the "vA, vB" 4-bit registers from the instruction word (_inst is u2).
+ */
+#define INST_A(_inst)       (((_inst) >> 8) & 0x0f)
+#define INST_B(_inst)       ((_inst) >> 12)
+
+/*
+ * Get the 8-bit "vAA" 8-bit register index from the instruction word.
+ * (_inst is u2)
+ */
+#define INST_AA(_inst)      ((_inst) >> 8)
+
+/*
+ * The current PC must be available to Throwable constructors, e.g.
+ * those created by the various exception throw routines, so that the
+ * exception stack trace can be generated correctly.  If we don't do this,
+ * the offset within the current method won't be shown correctly.  See the
+ * notes in Exception.c.
+ *
+ * This is also used to determine the address for precise GC.
+ *
+ * Assumes existence of "u4* fp" and "const u2* pc".
+ */
+#define EXPORT_PC()         (SAVEAREA_FROM_FP(fp)->xtra.currentPc = pc)
+
+/*
+ * Check to see if "obj" is NULL.  If so, throw an exception.  Assumes the
+ * pc has already been exported to the stack.
+ *
+ * Perform additional checks on debug builds.
+ *
+ * Use this to check for NULL when the instruction handler calls into
+ * something that could throw an exception (so we have already called
+ * EXPORT_PC at the top).
+ */
+static inline bool checkForNull(Object* obj)
+{
+    if (obj == NULL) {
+        dvmThrowNullPointerException(NULL);
+        return false;
+    }
+#ifdef WITH_EXTRA_OBJECT_VALIDATION
+    if (!dvmIsHeapAddress(obj)) {
+        ALOGE("Invalid object %p", obj);
+        dvmAbort();
+    }
+#endif
+#ifndef NDEBUG
+    if (obj->clazz == NULL || ((u4) obj->clazz) <= 65536) {
+        /* probable heap corruption */
+        ALOGE("Invalid object class %p (in %p)", obj->clazz, obj);
+        dvmAbort();
+    }
+#endif
+    return true;
+}
+
+/*
+ * Check to see if "obj" is NULL.  If so, export the PC into the stack
+ * frame and throw an exception.
+ *
+ * Perform additional checks on debug builds.
+ *
+ * Use this to check for NULL when the instruction handler doesn't do
+ * anything else that can throw an exception.
+ */
+static inline bool checkForNullExportPC(Object* obj, u4* fp, const u2* pc)
+{
+    if (obj == NULL) {
+        EXPORT_PC();
+        dvmThrowNullPointerException(NULL);
+        return false;
+    }
+#ifdef WITH_EXTRA_OBJECT_VALIDATION
+    if (!dvmIsHeapAddress(obj)) {
+        ALOGE("Invalid object %p", obj);
+        dvmAbort();
+    }
+#endif
+#ifndef NDEBUG
+    if (obj->clazz == NULL || ((u4) obj->clazz) <= 65536) {
+        /* probable heap corruption */
+        ALOGE("Invalid object class %p (in %p)", obj->clazz, obj);
+        dvmAbort();
+    }
+#endif
+    return true;
+}
diff --git a/vm/mterp/c_notaint/opcommon.cpp b/vm/mterp/c_notaint/opcommon.cpp
new file mode 100644
index 0000000..991df86
--- /dev/null
+++ b/vm/mterp/c_notaint/opcommon.cpp
@@ -0,0 +1,647 @@
+/* forward declarations of goto targets */
+GOTO_TARGET_DECL(filledNewArray, bool methodCallRange);
+GOTO_TARGET_DECL(invokeVirtual, bool methodCallRange);
+GOTO_TARGET_DECL(invokeSuper, bool methodCallRange);
+GOTO_TARGET_DECL(invokeInterface, bool methodCallRange);
+GOTO_TARGET_DECL(invokeDirect, bool methodCallRange);
+GOTO_TARGET_DECL(invokeStatic, bool methodCallRange);
+GOTO_TARGET_DECL(invokeVirtualQuick, bool methodCallRange);
+GOTO_TARGET_DECL(invokeSuperQuick, bool methodCallRange);
+GOTO_TARGET_DECL(invokeMethod, bool methodCallRange, const Method* methodToCall,
+    u2 count, u2 regs);
+GOTO_TARGET_DECL(returnFromMethod);
+GOTO_TARGET_DECL(exceptionThrown);
+
+/*
+ * ===========================================================================
+ *
+ * What follows are opcode definitions shared between multiple opcodes with
+ * minor substitutions handled by the C pre-processor.  These should probably
+ * use the mterp substitution mechanism instead, with the code here moved
+ * into common fragment files (like the asm "binop.S"), although it's hard
+ * to give up the C preprocessor in favor of the much simpler text subst.
+ *
+ * ===========================================================================
+ */
+
+#define HANDLE_NUMCONV(_opcode, _opname, _fromtype, _totype)                \
+    HANDLE_OPCODE(_opcode /*vA, vB*/)                                       \
+        vdst = INST_A(inst);                                                \
+        vsrc1 = INST_B(inst);                                               \
+        ILOGV("|%s v%d,v%d", (_opname), vdst, vsrc1);                       \
+        SET_REGISTER##_totype(vdst,                                         \
+            GET_REGISTER##_fromtype(vsrc1));                                \
+        FINISH(1);
+
+#define HANDLE_FLOAT_TO_INT(_opcode, _opname, _fromvtype, _fromrtype,       \
+        _tovtype, _tortype)                                                 \
+    HANDLE_OPCODE(_opcode /*vA, vB*/)                                       \
+    {                                                                       \
+        /* spec defines specific handling for +/- inf and NaN values */     \
+        _fromvtype val;                                                     \
+        _tovtype intMin, intMax, result;                                    \
+        vdst = INST_A(inst);                                                \
+        vsrc1 = INST_B(inst);                                               \
+        ILOGV("|%s v%d,v%d", (_opname), vdst, vsrc1);                       \
+        val = GET_REGISTER##_fromrtype(vsrc1);                              \
+        intMin = (_tovtype) 1 << (sizeof(_tovtype) * 8 -1);                 \
+        intMax = ~intMin;                                                   \
+        result = (_tovtype) val;                                            \
+        if (val >= intMax)          /* +inf */                              \
+            result = intMax;                                                \
+        else if (val <= intMin)     /* -inf */                              \
+            result = intMin;                                                \
+        else if (val != val)        /* NaN */                               \
+            result = 0;                                                     \
+        else                                                                \
+            result = (_tovtype) val;                                        \
+        SET_REGISTER##_tortype(vdst, result);                               \
+    }                                                                       \
+    FINISH(1);
+
+#define HANDLE_INT_TO_SMALL(_opcode, _opname, _type)                        \
+    HANDLE_OPCODE(_opcode /*vA, vB*/)                                       \
+        vdst = INST_A(inst);                                                \
+        vsrc1 = INST_B(inst);                                               \
+        ILOGV("|int-to-%s v%d,v%d", (_opname), vdst, vsrc1);                \
+        SET_REGISTER(vdst, (_type) GET_REGISTER(vsrc1));                    \
+        FINISH(1);
+
+/* NOTE: the comparison result is always a signed 4-byte integer */
+#define HANDLE_OP_CMPX(_opcode, _opname, _varType, _type, _nanVal)          \
+    HANDLE_OPCODE(_opcode /*vAA, vBB, vCC*/)                                \
+    {                                                                       \
+        int result;                                                         \
+        u2 regs;                                                            \
+        _varType val1, val2;                                                \
+        vdst = INST_AA(inst);                                               \
+        regs = FETCH(1);                                                    \
+        vsrc1 = regs & 0xff;                                                \
+        vsrc2 = regs >> 8;                                                  \
+        ILOGV("|cmp%s v%d,v%d,v%d", (_opname), vdst, vsrc1, vsrc2);         \
+        val1 = GET_REGISTER##_type(vsrc1);                                  \
+        val2 = GET_REGISTER##_type(vsrc2);                                  \
+        if (val1 == val2)                                                   \
+            result = 0;                                                     \
+        else if (val1 < val2)                                               \
+            result = -1;                                                    \
+        else if (val1 > val2)                                               \
+            result = 1;                                                     \
+        else                                                                \
+            result = (_nanVal);                                             \
+        ILOGV("+ result=%d", result);                                       \
+        SET_REGISTER(vdst, result);                                         \
+    }                                                                       \
+    FINISH(2);
+
+#define HANDLE_OP_IF_XX(_opcode, _opname, _cmp)                             \
+    HANDLE_OPCODE(_opcode /*vA, vB, +CCCC*/)                                \
+        vsrc1 = INST_A(inst);                                               \
+        vsrc2 = INST_B(inst);                                               \
+        if ((s4) GET_REGISTER(vsrc1) _cmp (s4) GET_REGISTER(vsrc2)) {       \
+            int branchOffset = (s2)FETCH(1);    /* sign-extended */         \
+            ILOGV("|if-%s v%d,v%d,+0x%04x", (_opname), vsrc1, vsrc2,        \
+                branchOffset);                                              \
+            ILOGV("> branch taken");                                        \
+            if (branchOffset < 0)                                           \
+                PERIODIC_CHECKS(branchOffset);                              \
+            FINISH(branchOffset);                                           \
+        } else {                                                            \
+            ILOGV("|if-%s v%d,v%d,-", (_opname), vsrc1, vsrc2);             \
+            FINISH(2);                                                      \
+        }
+
+#define HANDLE_OP_IF_XXZ(_opcode, _opname, _cmp)                            \
+    HANDLE_OPCODE(_opcode /*vAA, +BBBB*/)                                   \
+        vsrc1 = INST_AA(inst);                                              \
+        if ((s4) GET_REGISTER(vsrc1) _cmp 0) {                              \
+            int branchOffset = (s2)FETCH(1);    /* sign-extended */         \
+            ILOGV("|if-%s v%d,+0x%04x", (_opname), vsrc1, branchOffset);    \
+            ILOGV("> branch taken");                                        \
+            if (branchOffset < 0)                                           \
+                PERIODIC_CHECKS(branchOffset);                              \
+            FINISH(branchOffset);                                           \
+        } else {                                                            \
+            ILOGV("|if-%s v%d,-", (_opname), vsrc1);                        \
+            FINISH(2);                                                      \
+        }
+
+#define HANDLE_UNOP(_opcode, _opname, _pfx, _sfx, _type)                    \
+    HANDLE_OPCODE(_opcode /*vA, vB*/)                                       \
+        vdst = INST_A(inst);                                                \
+        vsrc1 = INST_B(inst);                                               \
+        ILOGV("|%s v%d,v%d", (_opname), vdst, vsrc1);                       \
+        SET_REGISTER##_type(vdst, _pfx GET_REGISTER##_type(vsrc1) _sfx);    \
+        FINISH(1);
+
+#define HANDLE_OP_X_INT(_opcode, _opname, _op, _chkdiv)                     \
+    HANDLE_OPCODE(_opcode /*vAA, vBB, vCC*/)                                \
+    {                                                                       \
+        u2 srcRegs;                                                         \
+        vdst = INST_AA(inst);                                               \
+        srcRegs = FETCH(1);                                                 \
+        vsrc1 = srcRegs & 0xff;                                             \
+        vsrc2 = srcRegs >> 8;                                               \
+        ILOGV("|%s-int v%d,v%d", (_opname), vdst, vsrc1);                   \
+        if (_chkdiv != 0) {                                                 \
+            s4 firstVal, secondVal, result;                                 \
+            firstVal = GET_REGISTER(vsrc1);                                 \
+            secondVal = GET_REGISTER(vsrc2);                                \
+            if (secondVal == 0) {                                           \
+                EXPORT_PC();                                                \
+                dvmThrowArithmeticException("divide by zero");              \
+                GOTO_exceptionThrown();                                     \
+            }                                                               \
+            if ((u4)firstVal == 0x80000000 && secondVal == -1) {            \
+                if (_chkdiv == 1)                                           \
+                    result = firstVal;  /* division */                      \
+                else                                                        \
+                    result = 0;         /* remainder */                     \
+            } else {                                                        \
+                result = firstVal _op secondVal;                            \
+            }                                                               \
+            SET_REGISTER(vdst, result);                                     \
+        } else {                                                            \
+            /* non-div/rem case */                                          \
+            SET_REGISTER(vdst,                                              \
+                (s4) GET_REGISTER(vsrc1) _op (s4) GET_REGISTER(vsrc2));     \
+        }                                                                   \
+    }                                                                       \
+    FINISH(2);
+
+#define HANDLE_OP_SHX_INT(_opcode, _opname, _cast, _op)                     \
+    HANDLE_OPCODE(_opcode /*vAA, vBB, vCC*/)                                \
+    {                                                                       \
+        u2 srcRegs;                                                         \
+        vdst = INST_AA(inst);                                               \
+        srcRegs = FETCH(1);                                                 \
+        vsrc1 = srcRegs & 0xff;                                             \
+        vsrc2 = srcRegs >> 8;                                               \
+        ILOGV("|%s-int v%d,v%d", (_opname), vdst, vsrc1);                   \
+        SET_REGISTER(vdst,                                                  \
+            _cast GET_REGISTER(vsrc1) _op (GET_REGISTER(vsrc2) & 0x1f));    \
+    }                                                                       \
+    FINISH(2);
+
+#define HANDLE_OP_X_INT_LIT16(_opcode, _opname, _op, _chkdiv)               \
+    HANDLE_OPCODE(_opcode /*vA, vB, #+CCCC*/)                               \
+        vdst = INST_A(inst);                                                \
+        vsrc1 = INST_B(inst);                                               \
+        vsrc2 = FETCH(1);                                                   \
+        ILOGV("|%s-int/lit16 v%d,v%d,#+0x%04x",                             \
+            (_opname), vdst, vsrc1, vsrc2);                                 \
+        if (_chkdiv != 0) {                                                 \
+            s4 firstVal, result;                                            \
+            firstVal = GET_REGISTER(vsrc1);                                 \
+            if ((s2) vsrc2 == 0) {                                          \
+                EXPORT_PC();                                                \
+                dvmThrowArithmeticException("divide by zero");              \
+                GOTO_exceptionThrown();                                     \
+            }                                                               \
+            if ((u4)firstVal == 0x80000000 && ((s2) vsrc2) == -1) {         \
+                /* won't generate /lit16 instr for this; check anyway */    \
+                if (_chkdiv == 1)                                           \
+                    result = firstVal;  /* division */                      \
+                else                                                        \
+                    result = 0;         /* remainder */                     \
+            } else {                                                        \
+                result = firstVal _op (s2) vsrc2;                           \
+            }                                                               \
+            SET_REGISTER(vdst, result);                                     \
+        } else {                                                            \
+            /* non-div/rem case */                                          \
+            SET_REGISTER(vdst, GET_REGISTER(vsrc1) _op (s2) vsrc2);         \
+        }                                                                   \
+        FINISH(2);
+
+#define HANDLE_OP_X_INT_LIT8(_opcode, _opname, _op, _chkdiv)                \
+    HANDLE_OPCODE(_opcode /*vAA, vBB, #+CC*/)                               \
+    {                                                                       \
+        u2 litInfo;                                                         \
+        vdst = INST_AA(inst);                                               \
+        litInfo = FETCH(1);                                                 \
+        vsrc1 = litInfo & 0xff;                                             \
+        vsrc2 = litInfo >> 8;       /* constant */                          \
+        ILOGV("|%s-int/lit8 v%d,v%d,#+0x%02x",                              \
+            (_opname), vdst, vsrc1, vsrc2);                                 \
+        if (_chkdiv != 0) {                                                 \
+            s4 firstVal, result;                                            \
+            firstVal = GET_REGISTER(vsrc1);                                 \
+            if ((s1) vsrc2 == 0) {                                          \
+                EXPORT_PC();                                                \
+                dvmThrowArithmeticException("divide by zero");              \
+                GOTO_exceptionThrown();                                     \
+            }                                                               \
+            if ((u4)firstVal == 0x80000000 && ((s1) vsrc2) == -1) {         \
+                if (_chkdiv == 1)                                           \
+                    result = firstVal;  /* division */                      \
+                else                                                        \
+                    result = 0;         /* remainder */                     \
+            } else {                                                        \
+                result = firstVal _op ((s1) vsrc2);                         \
+            }                                                               \
+            SET_REGISTER(vdst, result);                                     \
+        } else {                                                            \
+            SET_REGISTER(vdst,                                              \
+                (s4) GET_REGISTER(vsrc1) _op (s1) vsrc2);                   \
+        }                                                                   \
+    }                                                                       \
+    FINISH(2);
+
+#define HANDLE_OP_SHX_INT_LIT8(_opcode, _opname, _cast, _op)                \
+    HANDLE_OPCODE(_opcode /*vAA, vBB, #+CC*/)                               \
+    {                                                                       \
+        u2 litInfo;                                                         \
+        vdst = INST_AA(inst);                                               \
+        litInfo = FETCH(1);                                                 \
+        vsrc1 = litInfo & 0xff;                                             \
+        vsrc2 = litInfo >> 8;       /* constant */                          \
+        ILOGV("|%s-int/lit8 v%d,v%d,#+0x%02x",                              \
+            (_opname), vdst, vsrc1, vsrc2);                                 \
+        SET_REGISTER(vdst,                                                  \
+            _cast GET_REGISTER(vsrc1) _op (vsrc2 & 0x1f));                  \
+    }                                                                       \
+    FINISH(2);
+
+#define HANDLE_OP_X_INT_2ADDR(_opcode, _opname, _op, _chkdiv)               \
+    HANDLE_OPCODE(_opcode /*vA, vB*/)                                       \
+        vdst = INST_A(inst);                                                \
+        vsrc1 = INST_B(inst);                                               \
+        ILOGV("|%s-int-2addr v%d,v%d", (_opname), vdst, vsrc1);             \
+        if (_chkdiv != 0) {                                                 \
+            s4 firstVal, secondVal, result;                                 \
+            firstVal = GET_REGISTER(vdst);                                  \
+            secondVal = GET_REGISTER(vsrc1);                                \
+            if (secondVal == 0) {                                           \
+                EXPORT_PC();                                                \
+                dvmThrowArithmeticException("divide by zero");              \
+                GOTO_exceptionThrown();                                     \
+            }                                                               \
+            if ((u4)firstVal == 0x80000000 && secondVal == -1) {            \
+                if (_chkdiv == 1)                                           \
+                    result = firstVal;  /* division */                      \
+                else                                                        \
+                    result = 0;         /* remainder */                     \
+            } else {                                                        \
+                result = firstVal _op secondVal;                            \
+            }                                                               \
+            SET_REGISTER(vdst, result);                                     \
+        } else {                                                            \
+            SET_REGISTER(vdst,                                              \
+                (s4) GET_REGISTER(vdst) _op (s4) GET_REGISTER(vsrc1));      \
+        }                                                                   \
+        FINISH(1);
+
+#define HANDLE_OP_SHX_INT_2ADDR(_opcode, _opname, _cast, _op)               \
+    HANDLE_OPCODE(_opcode /*vA, vB*/)                                       \
+        vdst = INST_A(inst);                                                \
+        vsrc1 = INST_B(inst);                                               \
+        ILOGV("|%s-int-2addr v%d,v%d", (_opname), vdst, vsrc1);             \
+        SET_REGISTER(vdst,                                                  \
+            _cast GET_REGISTER(vdst) _op (GET_REGISTER(vsrc1) & 0x1f));     \
+        FINISH(1);
+
+#define HANDLE_OP_X_LONG(_opcode, _opname, _op, _chkdiv)                    \
+    HANDLE_OPCODE(_opcode /*vAA, vBB, vCC*/)                                \
+    {                                                                       \
+        u2 srcRegs;                                                         \
+        vdst = INST_AA(inst);                                               \
+        srcRegs = FETCH(1);                                                 \
+        vsrc1 = srcRegs & 0xff;                                             \
+        vsrc2 = srcRegs >> 8;                                               \
+        ILOGV("|%s-long v%d,v%d,v%d", (_opname), vdst, vsrc1, vsrc2);       \
+        if (_chkdiv != 0) {                                                 \
+            s8 firstVal, secondVal, result;                                 \
+            firstVal = GET_REGISTER_WIDE(vsrc1);                            \
+            secondVal = GET_REGISTER_WIDE(vsrc2);                           \
+            if (secondVal == 0LL) {                                         \
+                EXPORT_PC();                                                \
+                dvmThrowArithmeticException("divide by zero");              \
+                GOTO_exceptionThrown();                                     \
+            }                                                               \
+            if ((u8)firstVal == 0x8000000000000000ULL &&                    \
+                secondVal == -1LL)                                          \
+            {                                                               \
+                if (_chkdiv == 1)                                           \
+                    result = firstVal;  /* division */                      \
+                else                                                        \
+                    result = 0;         /* remainder */                     \
+            } else {                                                        \
+                result = firstVal _op secondVal;                            \
+            }                                                               \
+            SET_REGISTER_WIDE(vdst, result);                                \
+        } else {                                                            \
+            SET_REGISTER_WIDE(vdst,                                         \
+                (s8) GET_REGISTER_WIDE(vsrc1) _op (s8) GET_REGISTER_WIDE(vsrc2)); \
+        }                                                                   \
+    }                                                                       \
+    FINISH(2);
+
+#define HANDLE_OP_SHX_LONG(_opcode, _opname, _cast, _op)                    \
+    HANDLE_OPCODE(_opcode /*vAA, vBB, vCC*/)                                \
+    {                                                                       \
+        u2 srcRegs;                                                         \
+        vdst = INST_AA(inst);                                               \
+        srcRegs = FETCH(1);                                                 \
+        vsrc1 = srcRegs & 0xff;                                             \
+        vsrc2 = srcRegs >> 8;                                               \
+        ILOGV("|%s-long v%d,v%d,v%d", (_opname), vdst, vsrc1, vsrc2);       \
+        SET_REGISTER_WIDE(vdst,                                             \
+            _cast GET_REGISTER_WIDE(vsrc1) _op (GET_REGISTER(vsrc2) & 0x3f)); \
+    }                                                                       \
+    FINISH(2);
+
+#define HANDLE_OP_X_LONG_2ADDR(_opcode, _opname, _op, _chkdiv)              \
+    HANDLE_OPCODE(_opcode /*vA, vB*/)                                       \
+        vdst = INST_A(inst);                                                \
+        vsrc1 = INST_B(inst);                                               \
+        ILOGV("|%s-long-2addr v%d,v%d", (_opname), vdst, vsrc1);            \
+        if (_chkdiv != 0) {                                                 \
+            s8 firstVal, secondVal, result;                                 \
+            firstVal = GET_REGISTER_WIDE(vdst);                             \
+            secondVal = GET_REGISTER_WIDE(vsrc1);                           \
+            if (secondVal == 0LL) {                                         \
+                EXPORT_PC();                                                \
+                dvmThrowArithmeticException("divide by zero");              \
+                GOTO_exceptionThrown();                                     \
+            }                                                               \
+            if ((u8)firstVal == 0x8000000000000000ULL &&                    \
+                secondVal == -1LL)                                          \
+            {                                                               \
+                if (_chkdiv == 1)                                           \
+                    result = firstVal;  /* division */                      \
+                else                                                        \
+                    result = 0;         /* remainder */                     \
+            } else {                                                        \
+                result = firstVal _op secondVal;                            \
+            }                                                               \
+            SET_REGISTER_WIDE(vdst, result);                                \
+        } else {                                                            \
+            SET_REGISTER_WIDE(vdst,                                         \
+                (s8) GET_REGISTER_WIDE(vdst) _op (s8)GET_REGISTER_WIDE(vsrc1));\
+        }                                                                   \
+        FINISH(1);
+
+#define HANDLE_OP_SHX_LONG_2ADDR(_opcode, _opname, _cast, _op)              \
+    HANDLE_OPCODE(_opcode /*vA, vB*/)                                       \
+        vdst = INST_A(inst);                                                \
+        vsrc1 = INST_B(inst);                                               \
+        ILOGV("|%s-long-2addr v%d,v%d", (_opname), vdst, vsrc1);            \
+        SET_REGISTER_WIDE(vdst,                                             \
+            _cast GET_REGISTER_WIDE(vdst) _op (GET_REGISTER(vsrc1) & 0x3f)); \
+        FINISH(1);
+
+#define HANDLE_OP_X_FLOAT(_opcode, _opname, _op)                            \
+    HANDLE_OPCODE(_opcode /*vAA, vBB, vCC*/)                                \
+    {                                                                       \
+        u2 srcRegs;                                                         \
+        vdst = INST_AA(inst);                                               \
+        srcRegs = FETCH(1);                                                 \
+        vsrc1 = srcRegs & 0xff;                                             \
+        vsrc2 = srcRegs >> 8;                                               \
+        ILOGV("|%s-float v%d,v%d,v%d", (_opname), vdst, vsrc1, vsrc2);      \
+        SET_REGISTER_FLOAT(vdst,                                            \
+            GET_REGISTER_FLOAT(vsrc1) _op GET_REGISTER_FLOAT(vsrc2));       \
+    }                                                                       \
+    FINISH(2);
+
+#define HANDLE_OP_X_DOUBLE(_opcode, _opname, _op)                           \
+    HANDLE_OPCODE(_opcode /*vAA, vBB, vCC*/)                                \
+    {                                                                       \
+        u2 srcRegs;                                                         \
+        vdst = INST_AA(inst);                                               \
+        srcRegs = FETCH(1);                                                 \
+        vsrc1 = srcRegs & 0xff;                                             \
+        vsrc2 = srcRegs >> 8;                                               \
+        ILOGV("|%s-double v%d,v%d,v%d", (_opname), vdst, vsrc1, vsrc2);     \
+        SET_REGISTER_DOUBLE(vdst,                                           \
+            GET_REGISTER_DOUBLE(vsrc1) _op GET_REGISTER_DOUBLE(vsrc2));     \
+    }                                                                       \
+    FINISH(2);
+
+#define HANDLE_OP_X_FLOAT_2ADDR(_opcode, _opname, _op)                      \
+    HANDLE_OPCODE(_opcode /*vA, vB*/)                                       \
+        vdst = INST_A(inst);                                                \
+        vsrc1 = INST_B(inst);                                               \
+        ILOGV("|%s-float-2addr v%d,v%d", (_opname), vdst, vsrc1);           \
+        SET_REGISTER_FLOAT(vdst,                                            \
+            GET_REGISTER_FLOAT(vdst) _op GET_REGISTER_FLOAT(vsrc1));        \
+        FINISH(1);
+
+#define HANDLE_OP_X_DOUBLE_2ADDR(_opcode, _opname, _op)                     \
+    HANDLE_OPCODE(_opcode /*vA, vB*/)                                       \
+        vdst = INST_A(inst);                                                \
+        vsrc1 = INST_B(inst);                                               \
+        ILOGV("|%s-double-2addr v%d,v%d", (_opname), vdst, vsrc1);          \
+        SET_REGISTER_DOUBLE(vdst,                                           \
+            GET_REGISTER_DOUBLE(vdst) _op GET_REGISTER_DOUBLE(vsrc1));      \
+        FINISH(1);
+
+#define HANDLE_OP_AGET(_opcode, _opname, _type, _regsize)                   \
+    HANDLE_OPCODE(_opcode /*vAA, vBB, vCC*/)                                \
+    {                                                                       \
+        ArrayObject* arrayObj;                                              \
+        u2 arrayInfo;                                                       \
+        EXPORT_PC();                                                        \
+        vdst = INST_AA(inst);                                               \
+        arrayInfo = FETCH(1);                                               \
+        vsrc1 = arrayInfo & 0xff;    /* array ptr */                        \
+        vsrc2 = arrayInfo >> 8;      /* index */                            \
+        ILOGV("|aget%s v%d,v%d,v%d", (_opname), vdst, vsrc1, vsrc2);        \
+        arrayObj = (ArrayObject*) GET_REGISTER(vsrc1);                      \
+        if (!checkForNull((Object*) arrayObj))                              \
+            GOTO_exceptionThrown();                                         \
+        if (GET_REGISTER(vsrc2) >= arrayObj->length) {                      \
+            dvmThrowArrayIndexOutOfBoundsException(                         \
+                arrayObj->length, GET_REGISTER(vsrc2));                     \
+            GOTO_exceptionThrown();                                         \
+        }                                                                   \
+        SET_REGISTER##_regsize(vdst,                                        \
+            ((_type*)(void*)arrayObj->contents)[GET_REGISTER(vsrc2)]);      \
+        ILOGV("+ AGET[%d]=%#x", GET_REGISTER(vsrc2), GET_REGISTER(vdst));   \
+    }                                                                       \
+    FINISH(2);
+
+#define HANDLE_OP_APUT(_opcode, _opname, _type, _regsize)                   \
+    HANDLE_OPCODE(_opcode /*vAA, vBB, vCC*/)                                \
+    {                                                                       \
+        ArrayObject* arrayObj;                                              \
+        u2 arrayInfo;                                                       \
+        EXPORT_PC();                                                        \
+        vdst = INST_AA(inst);       /* AA: source value */                  \
+        arrayInfo = FETCH(1);                                               \
+        vsrc1 = arrayInfo & 0xff;   /* BB: array ptr */                     \
+        vsrc2 = arrayInfo >> 8;     /* CC: index */                         \
+        ILOGV("|aput%s v%d,v%d,v%d", (_opname), vdst, vsrc1, vsrc2);        \
+        arrayObj = (ArrayObject*) GET_REGISTER(vsrc1);                      \
+        if (!checkForNull((Object*) arrayObj))                              \
+            GOTO_exceptionThrown();                                         \
+        if (GET_REGISTER(vsrc2) >= arrayObj->length) {                      \
+            dvmThrowArrayIndexOutOfBoundsException(                         \
+                arrayObj->length, GET_REGISTER(vsrc2));                     \
+            GOTO_exceptionThrown();                                         \
+        }                                                                   \
+        ILOGV("+ APUT[%d]=0x%08x", GET_REGISTER(vsrc2), GET_REGISTER(vdst));\
+        ((_type*)(void*)arrayObj->contents)[GET_REGISTER(vsrc2)] =          \
+            GET_REGISTER##_regsize(vdst);                                   \
+    }                                                                       \
+    FINISH(2);
+
+/*
+ * It's possible to get a bad value out of a field with sub-32-bit stores
+ * because the -quick versions always operate on 32 bits.  Consider:
+ *   short foo = -1  (sets a 32-bit register to 0xffffffff)
+ *   iput-quick foo  (writes all 32 bits to the field)
+ *   short bar = 1   (sets a 32-bit register to 0x00000001)
+ *   iput-short      (writes the low 16 bits to the field)
+ *   iget-quick foo  (reads all 32 bits from the field, yielding 0xffff0001)
+ * This can only happen when optimized and non-optimized code has interleaved
+ * access to the same field.  This is unlikely but possible.
+ *
+ * The easiest way to fix this is to always read/write 32 bits at a time.  On
+ * a device with a 16-bit data bus this is sub-optimal.  (The alternative
+ * approach is to have sub-int versions of iget-quick, but now we're wasting
+ * Dalvik instruction space and making it less likely that handler code will
+ * already be in the CPU i-cache.)
+ */
+#define HANDLE_IGET_X(_opcode, _opname, _ftype, _regsize)                   \
+    HANDLE_OPCODE(_opcode /*vA, vB, field@CCCC*/)                           \
+    {                                                                       \
+        InstField* ifield;                                                  \
+        Object* obj;                                                        \
+        EXPORT_PC();                                                        \
+        vdst = INST_A(inst);                                                \
+        vsrc1 = INST_B(inst);   /* object ptr */                            \
+        ref = FETCH(1);         /* field ref */                             \
+        ILOGV("|iget%s v%d,v%d,field@0x%04x", (_opname), vdst, vsrc1, ref); \
+        obj = (Object*) GET_REGISTER(vsrc1);                                \
+        if (!checkForNull(obj))                                             \
+            GOTO_exceptionThrown();                                         \
+        ifield = (InstField*) dvmDexGetResolvedField(methodClassDex, ref);  \
+        if (ifield == NULL) {                                               \
+            ifield = dvmResolveInstField(curMethod->clazz, ref);            \
+            if (ifield == NULL)                                             \
+                GOTO_exceptionThrown();                                     \
+        }                                                                   \
+        SET_REGISTER##_regsize(vdst,                                        \
+            dvmGetField##_ftype(obj, ifield->byteOffset));                  \
+        ILOGV("+ IGET '%s'=0x%08llx", ifield->field.name,                   \
+            (u8) GET_REGISTER##_regsize(vdst));                             \
+    }                                                                       \
+    FINISH(2);
+
+#define HANDLE_IGET_X_QUICK(_opcode, _opname, _ftype, _regsize)             \
+    HANDLE_OPCODE(_opcode /*vA, vB, field@CCCC*/)                           \
+    {                                                                       \
+        Object* obj;                                                        \
+        vdst = INST_A(inst);                                                \
+        vsrc1 = INST_B(inst);   /* object ptr */                            \
+        ref = FETCH(1);         /* field offset */                          \
+        ILOGV("|iget%s-quick v%d,v%d,field@+%u",                            \
+            (_opname), vdst, vsrc1, ref);                                   \
+        obj = (Object*) GET_REGISTER(vsrc1);                                \
+        if (!checkForNullExportPC(obj, fp, pc))                             \
+            GOTO_exceptionThrown();                                         \
+        SET_REGISTER##_regsize(vdst, dvmGetField##_ftype(obj, ref));        \
+        ILOGV("+ IGETQ %d=0x%08llx", ref,                                   \
+            (u8) GET_REGISTER##_regsize(vdst));                             \
+    }                                                                       \
+    FINISH(2);
+
+#define HANDLE_IPUT_X(_opcode, _opname, _ftype, _regsize)                   \
+    HANDLE_OPCODE(_opcode /*vA, vB, field@CCCC*/)                           \
+    {                                                                       \
+        InstField* ifield;                                                  \
+        Object* obj;                                                        \
+        EXPORT_PC();                                                        \
+        vdst = INST_A(inst);                                                \
+        vsrc1 = INST_B(inst);   /* object ptr */                            \
+        ref = FETCH(1);         /* field ref */                             \
+        ILOGV("|iput%s v%d,v%d,field@0x%04x", (_opname), vdst, vsrc1, ref); \
+        obj = (Object*) GET_REGISTER(vsrc1);                                \
+        if (!checkForNull(obj))                                             \
+            GOTO_exceptionThrown();                                         \
+        ifield = (InstField*) dvmDexGetResolvedField(methodClassDex, ref);  \
+        if (ifield == NULL) {                                               \
+            ifield = dvmResolveInstField(curMethod->clazz, ref);            \
+            if (ifield == NULL)                                             \
+                GOTO_exceptionThrown();                                     \
+        }                                                                   \
+        dvmSetField##_ftype(obj, ifield->byteOffset,                        \
+            GET_REGISTER##_regsize(vdst));                                  \
+        ILOGV("+ IPUT '%s'=0x%08llx", ifield->field.name,                   \
+            (u8) GET_REGISTER##_regsize(vdst));                             \
+    }                                                                       \
+    FINISH(2);
+
+#define HANDLE_IPUT_X_QUICK(_opcode, _opname, _ftype, _regsize)             \
+    HANDLE_OPCODE(_opcode /*vA, vB, field@CCCC*/)                           \
+    {                                                                       \
+        Object* obj;                                                        \
+        vdst = INST_A(inst);                                                \
+        vsrc1 = INST_B(inst);   /* object ptr */                            \
+        ref = FETCH(1);         /* field offset */                          \
+        ILOGV("|iput%s-quick v%d,v%d,field@0x%04x",                         \
+            (_opname), vdst, vsrc1, ref);                                   \
+        obj = (Object*) GET_REGISTER(vsrc1);                                \
+        if (!checkForNullExportPC(obj, fp, pc))                             \
+            GOTO_exceptionThrown();                                         \
+        dvmSetField##_ftype(obj, ref, GET_REGISTER##_regsize(vdst));        \
+        ILOGV("+ IPUTQ %d=0x%08llx", ref,                                   \
+            (u8) GET_REGISTER##_regsize(vdst));                             \
+    }                                                                       \
+    FINISH(2);
+
+/*
+ * The JIT needs dvmDexGetResolvedField() to return non-null.
+ * Because the portable interpreter is not involved with the JIT
+ * and trace building, we only need the extra check here when this
+ * code is massaged into a stub called from an assembly interpreter.
+ * This is controlled by the JIT_STUB_HACK maco.
+ */
+
+#define HANDLE_SGET_X(_opcode, _opname, _ftype, _regsize)                   \
+    HANDLE_OPCODE(_opcode /*vAA, field@BBBB*/)                              \
+    {                                                                       \
+        StaticField* sfield;                                                \
+        vdst = INST_AA(inst);                                               \
+        ref = FETCH(1);         /* field ref */                             \
+        ILOGV("|sget%s v%d,sfield@0x%04x", (_opname), vdst, ref);           \
+        sfield = (StaticField*)dvmDexGetResolvedField(methodClassDex, ref); \
+        if (sfield == NULL) {                                               \
+            EXPORT_PC();                                                    \
+            sfield = dvmResolveStaticField(curMethod->clazz, ref);          \
+            if (sfield == NULL)                                             \
+                GOTO_exceptionThrown();                                     \
+            if (dvmDexGetResolvedField(methodClassDex, ref) == NULL) {      \
+                JIT_STUB_HACK(dvmJitEndTraceSelect(self,pc));               \
+            }                                                               \
+        }                                                                   \
+        SET_REGISTER##_regsize(vdst, dvmGetStaticField##_ftype(sfield));    \
+        ILOGV("+ SGET '%s'=0x%08llx",                                       \
+            sfield->field.name, (u8)GET_REGISTER##_regsize(vdst));          \
+    }                                                                       \
+    FINISH(2);
+
+#define HANDLE_SPUT_X(_opcode, _opname, _ftype, _regsize)                   \
+    HANDLE_OPCODE(_opcode /*vAA, field@BBBB*/)                              \
+    {                                                                       \
+        StaticField* sfield;                                                \
+        vdst = INST_AA(inst);                                               \
+        ref = FETCH(1);         /* field ref */                             \
+        ILOGV("|sput%s v%d,sfield@0x%04x", (_opname), vdst, ref);           \
+        sfield = (StaticField*)dvmDexGetResolvedField(methodClassDex, ref); \
+        if (sfield == NULL) {                                               \
+            EXPORT_PC();                                                    \
+            sfield = dvmResolveStaticField(curMethod->clazz, ref);          \
+            if (sfield == NULL)                                             \
+                GOTO_exceptionThrown();                                     \
+            if (dvmDexGetResolvedField(methodClassDex, ref) == NULL) {      \
+                JIT_STUB_HACK(dvmJitEndTraceSelect(self,pc));               \
+            }                                                               \
+        }                                                                   \
+        dvmSetStaticField##_ftype(sfield, GET_REGISTER##_regsize(vdst));    \
+        ILOGV("+ SPUT '%s'=0x%08llx",                                       \
+            sfield->field.name, (u8)GET_REGISTER##_regsize(vdst));          \
+    }                                                                       \
+    FINISH(2);
diff --git a/vm/mterp/common/asm-constants.h b/vm/mterp/common/asm-constants.h
index e1a4df6..db1a6ca 100644
--- a/vm/mterp/common/asm-constants.h
+++ b/vm/mterp/common/asm-constants.h
@@ -81,6 +81,7 @@
  * values are incorrect.
  */
 
+
 /* DvmDex fields */
 MTERP_OFFSET(offDvmDex_pResStrings,     DvmDex, pResStrings, 8)
 MTERP_OFFSET(offDvmDex_pResClasses,     DvmDex, pResClasses, 12)
@@ -88,6 +89,35 @@ MTERP_OFFSET(offDvmDex_pResMethods,     DvmDex, pResMethods, 16)
 MTERP_OFFSET(offDvmDex_pResFields,      DvmDex, pResFields, 20)
 MTERP_OFFSET(offDvmDex_pInterfaceCache, DvmDex, pInterfaceCache, 24)
 
+#ifdef WITH_TAINT_TRACKING
+// need to store arg count for native methods
+
+/* StackSaveArea fields */
+#ifdef EASY_GDB
+MTERP_OFFSET(offStackSaveArea_prevSave, StackSaveArea, prevSave, 0)
+MTERP_OFFSET(offStackSaveArea_prevFrame, StackSaveArea, prevFrame, 4)
+MTERP_OFFSET(offStackSaveArea_savedPc,  StackSaveArea, savedPc, 8)
+MTERP_OFFSET(offStackSaveArea_method,   StackSaveArea, method, 12)
+MTERP_OFFSET(offStackSaveArea_argCount, StackSaveArea, argCount, 16)
+MTERP_OFFSET(offStackSaveArea_currentPc, StackSaveArea, xtra.currentPc, 20)
+MTERP_OFFSET(offStackSaveArea_localRefCookie, \
+                                        StackSaveArea, xtra.localRefCookie, 20)
+MTERP_OFFSET(offStackSaveArea_returnAddr, StackSaveArea, returnAddr, 24)
+MTERP_SIZEOF(sizeofStackSaveArea,       StackSaveArea, 28)
+#else
+MTERP_OFFSET(offStackSaveArea_prevFrame, StackSaveArea, prevFrame, 0)
+MTERP_OFFSET(offStackSaveArea_savedPc,  StackSaveArea, savedPc, 4)
+MTERP_OFFSET(offStackSaveArea_method,   StackSaveArea, method, 8)
+MTERP_OFFSET(offStackSaveArea_argCount, StackSaveArea, argCount, 12)
+MTERP_OFFSET(offStackSaveArea_currentPc, StackSaveArea, xtra.currentPc, 16)
+MTERP_OFFSET(offStackSaveArea_localRefCookie, \
+                                        StackSaveArea, xtra.localRefCookie, 16)
+MTERP_OFFSET(offStackSaveArea_returnAddr, StackSaveArea, returnAddr, 20)
+MTERP_SIZEOF(sizeofStackSaveArea,       StackSaveArea, 24)
+#endif
+
+#else
+
 /* StackSaveArea fields */
 #ifdef EASY_GDB
 MTERP_OFFSET(offStackSaveArea_prevSave, StackSaveArea, prevSave, 0)
@@ -110,6 +140,8 @@ MTERP_OFFSET(offStackSaveArea_returnAddr, StackSaveArea, returnAddr, 16)
 MTERP_SIZEOF(sizeofStackSaveArea,       StackSaveArea, 20)
 #endif
 
+#endif /*WITH_TAINT_TRACKING*/
+
   /* ShadowSpace fields */
 #if defined(WITH_JIT) && defined(WITH_SELF_VERIFICATION)
 MTERP_OFFSET(offShadowSpace_startPC,     ShadowSpace, startPC, 0)
@@ -117,10 +149,18 @@ MTERP_OFFSET(offShadowSpace_fp,          ShadowSpace, fp, 4)
 MTERP_OFFSET(offShadowSpace_method,      ShadowSpace, method, 8)
 MTERP_OFFSET(offShadowSpace_methodClassDex, ShadowSpace, methodClassDex, 12)
 MTERP_OFFSET(offShadowSpace_retval,      ShadowSpace, retval, 16)
+#ifdef WITH_TAINT_TRACKING
+MTERP_OFFSET(offShadowSpace_rtaint,      ShadowSpace, rtaint, 24)
+MTERP_OFFSET(offShadowSpace_interpStackEnd, ShadowSpace, interpStackEnd, 28)
+MTERP_OFFSET(offShadowSpace_jitExitState,ShadowSpace, jitExitState, 32)
+MTERP_OFFSET(offShadowSpace_svState,     ShadowSpace, selfVerificationState, 36)
+MTERP_OFFSET(offShadowSpace_shadowFP,    ShadowSpace, shadowFP, 44)
+#else
 MTERP_OFFSET(offShadowSpace_interpStackEnd, ShadowSpace, interpStackEnd, 24)
 MTERP_OFFSET(offShadowSpace_jitExitState,ShadowSpace, jitExitState, 28)
 MTERP_OFFSET(offShadowSpace_svState,     ShadowSpace, selfVerificationState, 32)
 MTERP_OFFSET(offShadowSpace_shadowFP,    ShadowSpace, shadowFP, 40)
+#endif /*WITH_TAINT_TRACKING*/
 #endif
 
 /* InstField fields */
@@ -130,7 +170,12 @@ MTERP_OFFSET(offInstField_byteOffset,   InstField, byteOffset, 16)
 MTERP_OFFSET(offField_clazz,            Field, clazz, 0)
 
 /* StaticField fields */
+#ifdef WITH_TAINT_TRACKING
+MTERP_OFFSET(offStaticField_value,      StaticField, value, 16)
+MTERP_OFFSET(offStaticField_taint,		StaticField, taint, 24)
+#else
 MTERP_OFFSET(offStaticField_value,      StaticField, value, 16)
+#endif
 
 /* Method fields */
 MTERP_OFFSET(offMethod_clazz,           Method, clazz, 0)
@@ -156,6 +201,56 @@ MTERP_OFFSET(offThread_retval_z,          Thread, interpSave.retval.z, 16)
 MTERP_OFFSET(offThread_retval_i,          Thread, interpSave.retval.i, 16)
 MTERP_OFFSET(offThread_retval_j,          Thread, interpSave.retval.j, 16)
 MTERP_OFFSET(offThread_retval_l,          Thread, interpSave.retval.l, 16)
+
+/*-----------------------------------------------------------------*/
+#ifdef WITH_TAINT_TRACKING
+/* Adjustments required for Thread, interpSave.rtaint */
+MTERP_OFFSET(offThread_rtaint,		Thread, interpSave.rtaint, 24)
+MTERP_OFFSET(offThread_bailPtr,           Thread, interpSave.bailPtr, 28)
+MTERP_OFFSET(offThread_threadId,          Thread, threadId, 40)
+
+//40
+MTERP_OFFSET(offThread_subMode, \
+                               Thread, interpBreak.ctl.subMode, 48)
+MTERP_OFFSET(offThread_breakFlags, \
+                               Thread, interpBreak.ctl.breakFlags, 50)
+MTERP_OFFSET(offThread_curHandlerTable, \
+                               Thread, interpBreak.ctl.curHandlerTable, 52)
+MTERP_OFFSET(offThread_suspendCount,      Thread, suspendCount, 56);
+MTERP_OFFSET(offThread_dbgSuspendCount,   Thread, dbgSuspendCount, 60);
+MTERP_OFFSET(offThread_cardTable,         Thread, cardTable, 64)
+MTERP_OFFSET(offThread_interpStackEnd,    Thread, interpStackEnd, 68)
+MTERP_OFFSET(offThread_exception,         Thread, exception, 76)
+MTERP_OFFSET(offThread_debugIsMethodEntry, Thread, debugIsMethodEntry, 80)
+MTERP_OFFSET(offThread_interpStackSize,   Thread, interpStackSize, 84)
+MTERP_OFFSET(offThread_stackOverflowed,   Thread, stackOverflowed, 88)
+MTERP_OFFSET(offThread_mainHandlerTable,  Thread, mainHandlerTable, 96)
+MTERP_OFFSET(offThread_singleStepCount,   Thread, singleStepCount, 104)
+
+#ifdef WITH_JIT
+MTERP_OFFSET(offThread_jitToInterpEntries,Thread, jitToInterpEntries, 108)
+MTERP_OFFSET(offThread_inJitCodeCache,    Thread, inJitCodeCache, 132)
+MTERP_OFFSET(offThread_pJitProfTable,     Thread, pJitProfTable, 136)
+MTERP_OFFSET(offThread_jitThreshold,      Thread, jitThreshold, 140)
+MTERP_OFFSET(offThread_jitResumeNPC,      Thread, jitResumeNPC, 144)
+MTERP_OFFSET(offThread_jitResumeNSP,      Thread, jitResumeNSP, 148)
+MTERP_OFFSET(offThread_jitResumeDPC,      Thread, jitResumeDPC, 152)
+MTERP_OFFSET(offThread_jitState,          Thread, jitState, 156)
+MTERP_OFFSET(offThread_icRechainCount,    Thread, icRechainCount, 160)
+MTERP_OFFSET(offThread_pProfileCountdown, Thread, pProfileCountdown, 164)
+MTERP_OFFSET(offThread_callsiteClass,     Thread, callsiteClass, 168)
+MTERP_OFFSET(offThread_methodToCall,      Thread, methodToCall, 172)
+MTERP_OFFSET(offThread_jniLocal_topCookie, \
+                                Thread, jniLocalRefTable.segmentState.all, 176)
+#if defined(WITH_SELF_VERIFICATION)
+MTERP_OFFSET(offThread_shadowSpace,       Thread, shadowSpace, 196)
+#endif
+#else
+MTERP_OFFSET(offThread_jniLocal_topCookie, \
+                                Thread, jniLocalRefTable.segmentState.all, 104)
+#endif
+/*-----------------------------------------------------------------*/
+#else /* ndef WITH_TAINT_TRACKING */
 MTERP_OFFSET(offThread_bailPtr,           Thread, interpSave.bailPtr, 24)
 MTERP_OFFSET(offThread_threadId,          Thread, threadId, 36)
 
@@ -193,12 +288,14 @@ MTERP_OFFSET(offThread_methodToCall,      Thread, methodToCall, 164)
 MTERP_OFFSET(offThread_jniLocal_topCookie, \
                                 Thread, jniLocalRefTable.segmentState.all, 168)
 #if defined(WITH_SELF_VERIFICATION)
-MTERP_OFFSET(offThread_shadowSpace,       Thread, shadowSpace, 188)
+MTERP_OFFSET(offThread_shadowSpace,       Thread, shadowSpace, 192)
 #endif
 #else
 MTERP_OFFSET(offThread_jniLocal_topCookie, \
                                 Thread, jniLocalRefTable.segmentState.all, 100)
 #endif
+#endif /* ndef WITH_TAINT_TRACKING */
+/*-----------------------------------------------------------------*/
 
 /* Object fields */
 MTERP_OFFSET(offObject_clazz,           Object, clazz, 0)
@@ -210,17 +307,41 @@ MTERP_CONSTANT(LW_HASH_STATE_SHIFT, 1)
 
 /* ArrayObject fields */
 MTERP_OFFSET(offArrayObject_length,     ArrayObject, length, 8)
+#ifdef WITH_TAINT_TRACKING
+MTERP_OFFSET(offArrayObject_taint,	ArrayObject, taint, 12)
+#endif
+
+#ifdef WITH_TAINT_TRACKING
+/*-----------------------------------------------------------------*/
+/* The extra 4 bytes for the taint tag makes these the same */
+#ifdef MTERP_NO_UNALIGN_64
+MTERP_OFFSET(offArrayObject_contents,   ArrayObject, contents, 16)
+#else
+MTERP_OFFSET(offArrayObject_contents,   ArrayObject, contents, 16)
+#endif
+/*-----------------------------------------------------------------*/
+#else /* ndef WITH_TAINT_TRACKING */
+/*-----------------------------------------------------------------*/
 #ifdef MTERP_NO_UNALIGN_64
 MTERP_OFFSET(offArrayObject_contents,   ArrayObject, contents, 16)
 #else
 MTERP_OFFSET(offArrayObject_contents,   ArrayObject, contents, 12)
 #endif
+/*-----------------------------------------------------------------*/
+#endif /* WITH_TAINT_TRACKING */
 
 /* String fields */
+#ifdef WITH_TAINT_TRACKING
+MTERP_CONSTANT(STRING_FIELDOFF_VALUE,     8)
+MTERP_CONSTANT(STRING_FIELDOFF_HASHCODE, 16)
+MTERP_CONSTANT(STRING_FIELDOFF_OFFSET,   24)
+MTERP_CONSTANT(STRING_FIELDOFF_COUNT,    32)
+#else
 MTERP_CONSTANT(STRING_FIELDOFF_VALUE,     8)
 MTERP_CONSTANT(STRING_FIELDOFF_HASHCODE, 12)
 MTERP_CONSTANT(STRING_FIELDOFF_OFFSET,   16)
 MTERP_CONSTANT(STRING_FIELDOFF_COUNT,    20)
+#endif /* WITH_TAINT_TRACKING */
 
 #if defined(WITH_JIT)
 /*
@@ -237,6 +358,16 @@ MTERP_CONSTANT(JIT_CALLEE_SAVE_DOUBLE_COUNT,   8)
 #endif
 
 /* ClassObject fields */
+#ifdef WITH_TAINT_TRACKING
+// taint tags interleaved with instance data
+MTERP_OFFSET(offClassObject_descriptor, ClassObject, descriptor, 40)
+MTERP_OFFSET(offClassObject_accessFlags, ClassObject, accessFlags, 48)
+MTERP_OFFSET(offClassObject_pDvmDex,    ClassObject, pDvmDex, 56)
+MTERP_OFFSET(offClassObject_status,     ClassObject, status, 60)
+MTERP_OFFSET(offClassObject_super,      ClassObject, super, 88)
+MTERP_OFFSET(offClassObject_vtableCount, ClassObject, vtableCount, 128)
+MTERP_OFFSET(offClassObject_vtable,     ClassObject, vtable, 132)
+#else
 MTERP_OFFSET(offClassObject_descriptor, ClassObject, descriptor, 24)
 MTERP_OFFSET(offClassObject_accessFlags, ClassObject, accessFlags, 32)
 MTERP_OFFSET(offClassObject_pDvmDex,    ClassObject, pDvmDex, 40)
@@ -244,6 +375,7 @@ MTERP_OFFSET(offClassObject_status,     ClassObject, status, 44)
 MTERP_OFFSET(offClassObject_super,      ClassObject, super, 72)
 MTERP_OFFSET(offClassObject_vtableCount, ClassObject, vtableCount, 112)
 MTERP_OFFSET(offClassObject_vtable,     ClassObject, vtable, 116)
+#endif /*WITH_TAINT_TRACKING*/
 
 #if defined(WITH_JIT)
 MTERP_CONSTANT(kJitNot,                 0)
diff --git a/vm/mterp/config-armv7-a b/vm/mterp/config-armv7-a
index eadaeca..4ffbc06 100644
--- a/vm/mterp/config-armv7-a
+++ b/vm/mterp/config-armv7-a
@@ -25,14 +25,14 @@ handler-style computed-goto
 handler-size 64
 
 # source for the instruction table stub
-asm-stub armv5te/stub.S
+asm-stub armv5te_taint/stub.S
 
 # source for alternate entry stub
-asm-alt-stub armv5te/alt_stub.S
+asm-alt-stub armv5te_taint/alt_stub.S
 
 # file header and basic definitions
 import c/header.cpp
-import armv5te/header.S
+import armv5te_taint/header.S
 
 # C pre-processor defines for stub C instructions
 import cstubs/stubdefs.cpp
@@ -44,118 +44,103 @@ import armv7-a/platform.S
 import c/opcommon.cpp
 
 # arch-specific entry point to interpreter
-import armv5te/entry.S
+import armv5te_taint/entry.S
 
 # opcode list; argument to op-start is default directory
-op-start armv5te
+op-start armv5te_taint
     # handlers that take advantage of >= ARMv6T2 instructions
-    op OP_ADD_DOUBLE_2ADDR armv6t2
-    op OP_ADD_FLOAT_2ADDR armv6t2
-    op OP_ADD_INT_2ADDR armv6t2
-    op OP_ADD_INT_LIT16 armv6t2
-    op OP_ADD_LONG_2ADDR armv6t2
-    op OP_AND_INT_2ADDR armv6t2
-    op OP_AND_INT_LIT16 armv6t2
-    op OP_AND_LONG_2ADDR armv6t2
-    op OP_ARRAY_LENGTH armv6t2
-    op OP_CONST_4 armv6t2
-    op OP_DIV_DOUBLE_2ADDR armv6t2
-    op OP_DIV_FLOAT_2ADDR armv6t2
-    op OP_DIV_INT_2ADDR armv6t2
-    op OP_DIV_INT_LIT16 armv6t2
-    op OP_DIV_LONG_2ADDR armv6t2
-    op OP_DOUBLE_TO_FLOAT armv6t2
-    op OP_DOUBLE_TO_INT armv6t2
-    op OP_DOUBLE_TO_LONG armv6t2
-    op OP_FLOAT_TO_DOUBLE armv6t2
-    op OP_FLOAT_TO_INT armv6t2
-    op OP_FLOAT_TO_LONG armv6t2
-    op OP_IF_EQ armv6t2
-    op OP_IF_GE armv6t2
-    op OP_IF_GT armv6t2
-    op OP_IF_LE armv6t2
-    op OP_IF_LT armv6t2
-    op OP_IF_NE armv6t2
-    op OP_IGET armv6t2
-    op OP_IGET_QUICK armv6t2
-    op OP_IGET_WIDE armv6t2
-    op OP_IGET_WIDE_QUICK armv6t2
-    op OP_INT_TO_BYTE armv6t2
-    op OP_INT_TO_CHAR armv6t2
-    op OP_INT_TO_DOUBLE armv6t2
-    op OP_INT_TO_FLOAT armv6t2
-    op OP_INT_TO_LONG armv6t2
-    op OP_INT_TO_SHORT armv6t2
-    op OP_IPUT armv6t2
-    op OP_IPUT_QUICK armv6t2
-    op OP_IPUT_WIDE armv6t2
-    op OP_IPUT_WIDE_QUICK armv6t2
-    op OP_LONG_TO_DOUBLE armv6t2
-    op OP_LONG_TO_FLOAT armv6t2
-    op OP_MOVE armv6t2
-    op OP_MOVE_WIDE armv6t2
-    op OP_MUL_DOUBLE_2ADDR armv6t2
-    op OP_MUL_FLOAT_2ADDR armv6t2
-    op OP_MUL_INT_2ADDR armv6t2
-    op OP_MUL_INT_LIT16 armv6t2
-    op OP_MUL_LONG_2ADDR armv6t2
-    op OP_NEG_DOUBLE armv6t2
-    op OP_NEG_FLOAT armv6t2
-    op OP_NEG_INT armv6t2
-    op OP_NEG_LONG armv6t2
-    op OP_NOT_INT armv6t2
-    op OP_NOT_LONG armv6t2
-    op OP_OR_INT_2ADDR armv6t2
-    op OP_OR_INT_LIT16 armv6t2
-    op OP_OR_LONG_2ADDR armv6t2
-    op OP_REM_DOUBLE_2ADDR armv6t2
-    op OP_REM_FLOAT_2ADDR armv6t2
-    op OP_REM_INT_2ADDR armv6t2
-    op OP_REM_INT_LIT16 armv6t2
-    op OP_REM_LONG_2ADDR armv6t2
-    op OP_RSUB_INT armv6t2
-    op OP_SHL_INT_2ADDR armv6t2
-    op OP_SHL_LONG_2ADDR armv6t2
-    op OP_SHR_INT_2ADDR armv6t2
-    op OP_SHR_LONG_2ADDR armv6t2
-    op OP_SUB_DOUBLE_2ADDR armv6t2
-    op OP_SUB_FLOAT_2ADDR armv6t2
-    op OP_SUB_INT_2ADDR armv6t2
-    op OP_SUB_LONG_2ADDR armv6t2
-    op OP_USHR_INT_2ADDR armv6t2
-    op OP_USHR_LONG_2ADDR armv6t2
-    op OP_XOR_INT_2ADDR armv6t2
-    op OP_XOR_INT_LIT16 armv6t2
-    op OP_XOR_LONG_2ADDR armv6t2
+    op OP_ADD_INT_2ADDR armv6t2_taint
+    op OP_ADD_INT_LIT16 armv6t2_taint
+    op OP_ADD_LONG_2ADDR armv6t2_taint
+    op OP_AND_INT_2ADDR armv6t2_taint
+    op OP_AND_INT_LIT16 armv6t2_taint
+    op OP_AND_LONG_2ADDR armv6t2_taint
+    op OP_ARRAY_LENGTH armv6t2_taint
+    op OP_CONST_4 armv6t2_taint
+    op OP_DIV_INT_2ADDR armv6t2_taint
+    op OP_DIV_INT_LIT16 armv6t2_taint
+    op OP_DIV_LONG_2ADDR armv6t2_taint
+    op OP_DOUBLE_TO_LONG armv6t2_taint
+    op OP_FLOAT_TO_LONG armv6t2_taint
+    op OP_IF_EQ armv6t2_taint
+    op OP_IF_GE armv6t2_taint
+    op OP_IF_GT armv6t2_taint
+    op OP_IF_LE armv6t2_taint
+    op OP_IF_LT armv6t2_taint
+    op OP_IF_NE armv6t2_taint
+    op OP_IGET armv6t2_taint
+    op OP_IGET_QUICK armv6t2_taint
+    op OP_IGET_WIDE armv6t2_taint
+    op OP_IGET_WIDE_QUICK armv6t2_taint
+    op OP_INT_TO_BYTE armv6t2_taint
+    op OP_INT_TO_CHAR armv6t2_taint
+    op OP_INT_TO_LONG armv6t2_taint
+    op OP_INT_TO_SHORT armv6t2_taint
+    op OP_IPUT armv6t2_taint
+    op OP_IPUT_QUICK armv6t2_taint
+    op OP_IPUT_WIDE armv6t2_taint
+    op OP_IPUT_WIDE_QUICK armv6t2_taint
+    op OP_LONG_TO_DOUBLE armv6t2_taint
+    op OP_LONG_TO_FLOAT armv6t2_taint
+    op OP_MOVE armv6t2_taint
+    op OP_MOVE_WIDE armv6t2_taint
+    op OP_MUL_INT_2ADDR armv6t2_taint
+    op OP_MUL_INT_LIT16 armv6t2_taint
+    op OP_MUL_LONG_2ADDR armv6t2_taint
+    op OP_NEG_DOUBLE armv6t2_taint
+    op OP_NEG_FLOAT armv6t2_taint
+    op OP_NEG_INT armv6t2_taint
+    op OP_NEG_LONG armv6t2_taint
+    op OP_NOT_INT armv6t2_taint
+    op OP_NOT_LONG armv6t2_taint
+    op OP_OR_INT_2ADDR armv6t2_taint
+    op OP_OR_INT_LIT16 armv6t2_taint
+    op OP_OR_LONG_2ADDR armv6t2_taint
+    op OP_REM_DOUBLE_2ADDR armv6t2_taint
+    op OP_REM_FLOAT_2ADDR armv6t2_taint
+    op OP_REM_INT_2ADDR armv6t2_taint
+    op OP_REM_INT_LIT16 armv6t2_taint
+    op OP_REM_LONG_2ADDR armv6t2_taint
+    op OP_RSUB_INT armv6t2_taint
+    op OP_SHL_INT_2ADDR armv6t2_taint
+    op OP_SHL_LONG_2ADDR armv6t2_taint
+    op OP_SHR_INT_2ADDR armv6t2_taint
+    op OP_SHR_LONG_2ADDR armv6t2_taint
+    op OP_SUB_INT_2ADDR armv6t2_taint
+    op OP_SUB_LONG_2ADDR armv6t2_taint
+    op OP_USHR_INT_2ADDR armv6t2_taint
+    op OP_USHR_LONG_2ADDR armv6t2_taint
+    op OP_XOR_INT_2ADDR armv6t2_taint
+    op OP_XOR_INT_LIT16 armv6t2_taint
+    op OP_XOR_LONG_2ADDR armv6t2_taint
 
     # floating point handlers that use VFP
-    # these override the handlers specified earlier
-    op OP_ADD_DOUBLE arm-vfp
-    op OP_ADD_DOUBLE_2ADDR arm-vfp
-    op OP_ADD_FLOAT arm-vfp
-    op OP_ADD_FLOAT_2ADDR arm-vfp
-    op OP_CMPG_DOUBLE arm-vfp
-    op OP_CMPG_FLOAT arm-vfp
-    op OP_CMPL_DOUBLE arm-vfp
-    op OP_CMPL_FLOAT arm-vfp
-    op OP_DIV_DOUBLE arm-vfp
-    op OP_DIV_DOUBLE_2ADDR arm-vfp
-    op OP_DIV_FLOAT arm-vfp
-    op OP_DIV_FLOAT_2ADDR arm-vfp
-    op OP_DOUBLE_TO_FLOAT arm-vfp
-    op OP_DOUBLE_TO_INT arm-vfp
-    op OP_FLOAT_TO_DOUBLE arm-vfp
-    op OP_FLOAT_TO_INT arm-vfp
-    op OP_INT_TO_DOUBLE arm-vfp
-    op OP_INT_TO_FLOAT arm-vfp
-    op OP_MUL_DOUBLE arm-vfp
-    op OP_MUL_DOUBLE_2ADDR arm-vfp
-    op OP_MUL_FLOAT arm-vfp
-    op OP_MUL_FLOAT_2ADDR arm-vfp
-    op OP_SUB_DOUBLE arm-vfp
-    op OP_SUB_DOUBLE_2ADDR arm-vfp
-    op OP_SUB_FLOAT arm-vfp
-    op OP_SUB_FLOAT_2ADDR arm-vfp
+    op OP_ADD_DOUBLE arm-vfp_taint
+    op OP_ADD_DOUBLE_2ADDR arm-vfp_taint
+    op OP_ADD_FLOAT arm-vfp_taint
+    op OP_ADD_FLOAT_2ADDR arm-vfp_taint
+    op OP_CMPG_DOUBLE arm-vfp_taint
+    op OP_CMPG_FLOAT arm-vfp_taint
+    op OP_CMPL_DOUBLE arm-vfp_taint
+    op OP_CMPL_FLOAT arm-vfp_taint
+    op OP_DIV_DOUBLE arm-vfp_taint
+    op OP_DIV_DOUBLE_2ADDR arm-vfp_taint
+    op OP_DIV_FLOAT arm-vfp_taint
+    op OP_DIV_FLOAT_2ADDR arm-vfp_taint
+    op OP_DOUBLE_TO_FLOAT arm-vfp_taint
+    op OP_DOUBLE_TO_INT arm-vfp_taint
+    op OP_FLOAT_TO_DOUBLE arm-vfp_taint
+    op OP_FLOAT_TO_INT arm-vfp_taint
+    op OP_INT_TO_DOUBLE arm-vfp_taint
+    op OP_INT_TO_FLOAT arm-vfp_taint
+    op OP_MUL_DOUBLE arm-vfp_taint
+    op OP_MUL_DOUBLE_2ADDR arm-vfp_taint
+    op OP_MUL_FLOAT arm-vfp_taint
+    op OP_MUL_FLOAT_2ADDR arm-vfp_taint
+    op OP_SUB_DOUBLE arm-vfp_taint
+    op OP_SUB_DOUBLE_2ADDR arm-vfp_taint
+    op OP_SUB_FLOAT arm-vfp_taint
+    op OP_SUB_FLOAT_2ADDR arm-vfp_taint
 op-end
 
 # "helper" code for C; include if you use any of the C stubs (this generates
@@ -168,5 +153,5 @@ op-end
 import cstubs/enddefs.cpp
 
 # common subroutines for asm
-import armv5te/footer.S
-import armv5te/debug.cpp
+import armv5te_taint/footer.S
+import armv5te_taint/debug.cpp
diff --git a/vm/mterp/config-armv7-a-neon b/vm/mterp/config-armv7-a-neon
index 5f91365..c3b6c88 100644
--- a/vm/mterp/config-armv7-a-neon
+++ b/vm/mterp/config-armv7-a-neon
@@ -25,14 +25,14 @@ handler-style computed-goto
 handler-size 64
 
 # source for the instruction table stub
-asm-stub armv5te/stub.S
+asm-stub armv5te_taint/stub.S
 
 # source for alternate entry stub
-asm-alt-stub armv5te/alt_stub.S
+asm-alt-stub armv5te_taint/alt_stub.S
 
 # file header and basic definitions
 import c/header.cpp
-import armv5te/header.S
+import armv5te_taint/header.S
 
 # C pre-processor defines for stub C instructions
 import cstubs/stubdefs.cpp
@@ -44,118 +44,103 @@ import armv7-a/platform.S
 import c/opcommon.cpp
 
 # arch-specific entry point to interpreter
-import armv5te/entry.S
+import armv5te_taint/entry.S
 
 # opcode list; argument to op-start is default directory
-op-start armv5te
+op-start armv5te_taint
     # handlers that take advantage of >= ARMv6T2 instructions
-    op OP_ADD_DOUBLE_2ADDR armv6t2
-    op OP_ADD_FLOAT_2ADDR armv6t2
-    op OP_ADD_INT_2ADDR armv6t2
-    op OP_ADD_INT_LIT16 armv6t2
-    op OP_ADD_LONG_2ADDR armv6t2
-    op OP_AND_INT_2ADDR armv6t2
-    op OP_AND_INT_LIT16 armv6t2
-    op OP_AND_LONG_2ADDR armv6t2
-    op OP_ARRAY_LENGTH armv6t2
-    op OP_CONST_4 armv6t2
-    op OP_DIV_DOUBLE_2ADDR armv6t2
-    op OP_DIV_FLOAT_2ADDR armv6t2
-    op OP_DIV_INT_2ADDR armv6t2
-    op OP_DIV_INT_LIT16 armv6t2
-    op OP_DIV_LONG_2ADDR armv6t2
-    op OP_DOUBLE_TO_FLOAT armv6t2
-    op OP_DOUBLE_TO_INT armv6t2
-    op OP_DOUBLE_TO_LONG armv6t2
-    op OP_FLOAT_TO_DOUBLE armv6t2
-    op OP_FLOAT_TO_INT armv6t2
-    op OP_FLOAT_TO_LONG armv6t2
-    op OP_IF_EQ armv6t2
-    op OP_IF_GE armv6t2
-    op OP_IF_GT armv6t2
-    op OP_IF_LE armv6t2
-    op OP_IF_LT armv6t2
-    op OP_IF_NE armv6t2
-    op OP_IGET armv6t2
-    op OP_IGET_QUICK armv6t2
-    op OP_IGET_WIDE armv6t2
-    op OP_IGET_WIDE_QUICK armv6t2
-    op OP_INT_TO_BYTE armv6t2
-    op OP_INT_TO_CHAR armv6t2
-    op OP_INT_TO_DOUBLE armv6t2
-    op OP_INT_TO_FLOAT armv6t2
-    op OP_INT_TO_LONG armv6t2
-    op OP_INT_TO_SHORT armv6t2
-    op OP_IPUT armv6t2
-    op OP_IPUT_QUICK armv6t2
-    op OP_IPUT_WIDE armv6t2
-    op OP_IPUT_WIDE_QUICK armv6t2
-    op OP_LONG_TO_DOUBLE armv6t2
-    op OP_LONG_TO_FLOAT armv6t2
-    op OP_MOVE armv6t2
-    op OP_MOVE_WIDE armv6t2
-    op OP_MUL_DOUBLE_2ADDR armv6t2
-    op OP_MUL_FLOAT_2ADDR armv6t2
-    op OP_MUL_INT_2ADDR armv6t2
-    op OP_MUL_INT_LIT16 armv6t2
-    op OP_MUL_LONG_2ADDR armv6t2
-    op OP_NEG_DOUBLE armv6t2
-    op OP_NEG_FLOAT armv6t2
-    op OP_NEG_INT armv6t2
-    op OP_NEG_LONG armv6t2
-    op OP_NOT_INT armv6t2
-    op OP_NOT_LONG armv6t2
-    op OP_OR_INT_2ADDR armv6t2
-    op OP_OR_INT_LIT16 armv6t2
-    op OP_OR_LONG_2ADDR armv6t2
-    op OP_REM_DOUBLE_2ADDR armv6t2
-    op OP_REM_FLOAT_2ADDR armv6t2
-    op OP_REM_INT_2ADDR armv6t2
-    op OP_REM_INT_LIT16 armv6t2
-    op OP_REM_LONG_2ADDR armv6t2
-    op OP_RSUB_INT armv6t2
-    op OP_SHL_INT_2ADDR armv6t2
-    op OP_SHL_LONG_2ADDR armv6t2
-    op OP_SHR_INT_2ADDR armv6t2
-    op OP_SHR_LONG_2ADDR armv6t2
-    op OP_SUB_DOUBLE_2ADDR armv6t2
-    op OP_SUB_FLOAT_2ADDR armv6t2
-    op OP_SUB_INT_2ADDR armv6t2
-    op OP_SUB_LONG_2ADDR armv6t2
-    op OP_USHR_INT_2ADDR armv6t2
-    op OP_USHR_LONG_2ADDR armv6t2
-    op OP_XOR_INT_2ADDR armv6t2
-    op OP_XOR_INT_LIT16 armv6t2
-    op OP_XOR_LONG_2ADDR armv6t2
+    op OP_ADD_INT_2ADDR armv6t2_taint
+    op OP_ADD_INT_LIT16 armv6t2_taint
+    op OP_ADD_LONG_2ADDR armv6t2_taint
+    op OP_AND_INT_2ADDR armv6t2_taint
+    op OP_AND_INT_LIT16 armv6t2_taint
+    op OP_AND_LONG_2ADDR armv6t2_taint
+    op OP_ARRAY_LENGTH armv6t2_taint
+    op OP_CONST_4 armv6t2_taint
+    op OP_DIV_INT_2ADDR armv6t2_taint
+    op OP_DIV_INT_LIT16 armv6t2_taint
+    op OP_DIV_LONG_2ADDR armv6t2_taint
+    op OP_DOUBLE_TO_LONG armv6t2_taint
+    op OP_FLOAT_TO_LONG armv6t2_taint
+    op OP_IF_EQ armv6t2_taint
+    op OP_IF_GE armv6t2_taint
+    op OP_IF_GT armv6t2_taint
+    op OP_IF_LE armv6t2_taint
+    op OP_IF_LT armv6t2_taint
+    op OP_IF_NE armv6t2_taint
+    op OP_IGET armv6t2_taint
+    op OP_IGET_QUICK armv6t2_taint
+    op OP_IGET_WIDE armv6t2_taint
+    op OP_IGET_WIDE_QUICK armv6t2_taint
+    op OP_INT_TO_BYTE armv6t2_taint
+    op OP_INT_TO_CHAR armv6t2_taint
+    op OP_INT_TO_LONG armv6t2_taint
+    op OP_INT_TO_SHORT armv6t2_taint
+    op OP_IPUT armv6t2_taint
+    op OP_IPUT_QUICK armv6t2_taint
+    op OP_IPUT_WIDE armv6t2_taint
+    op OP_IPUT_WIDE_QUICK armv6t2_taint
+    op OP_LONG_TO_DOUBLE armv6t2_taint
+    op OP_LONG_TO_FLOAT armv6t2_taint
+    op OP_MOVE armv6t2_taint
+    op OP_MOVE_WIDE armv6t2_taint
+    op OP_MUL_INT_2ADDR armv6t2_taint
+    op OP_MUL_INT_LIT16 armv6t2_taint
+    op OP_MUL_LONG_2ADDR armv6t2_taint
+    op OP_NEG_DOUBLE armv6t2_taint
+    op OP_NEG_FLOAT armv6t2_taint
+    op OP_NEG_INT armv6t2_taint
+    op OP_NEG_LONG armv6t2_taint
+    op OP_NOT_INT armv6t2_taint
+    op OP_NOT_LONG armv6t2_taint
+    op OP_OR_INT_2ADDR armv6t2_taint
+    op OP_OR_INT_LIT16 armv6t2_taint
+    op OP_OR_LONG_2ADDR armv6t2_taint
+    op OP_REM_DOUBLE_2ADDR armv6t2_taint
+    op OP_REM_FLOAT_2ADDR armv6t2_taint
+    op OP_REM_INT_2ADDR armv6t2_taint
+    op OP_REM_INT_LIT16 armv6t2_taint
+    op OP_REM_LONG_2ADDR armv6t2_taint
+    op OP_RSUB_INT armv6t2_taint
+    op OP_SHL_INT_2ADDR armv6t2_taint
+    op OP_SHL_LONG_2ADDR armv6t2_taint
+    op OP_SHR_INT_2ADDR armv6t2_taint
+    op OP_SHR_LONG_2ADDR armv6t2_taint
+    op OP_SUB_INT_2ADDR armv6t2_taint
+    op OP_SUB_LONG_2ADDR armv6t2_taint
+    op OP_USHR_INT_2ADDR armv6t2_taint
+    op OP_USHR_LONG_2ADDR armv6t2_taint
+    op OP_XOR_INT_2ADDR armv6t2_taint
+    op OP_XOR_INT_LIT16 armv6t2_taint
+    op OP_XOR_LONG_2ADDR armv6t2_taint
 
     # floating point handlers that use VFP
-    # these override the handlers specified earlier
-    op OP_ADD_DOUBLE arm-vfp
-    op OP_ADD_DOUBLE_2ADDR arm-vfp
-    op OP_ADD_FLOAT arm-vfp
-    op OP_ADD_FLOAT_2ADDR arm-vfp
-    op OP_CMPG_DOUBLE arm-vfp
-    op OP_CMPG_FLOAT arm-vfp
-    op OP_CMPL_DOUBLE arm-vfp
-    op OP_CMPL_FLOAT arm-vfp
-    op OP_DIV_DOUBLE arm-vfp
-    op OP_DIV_DOUBLE_2ADDR arm-vfp
-    op OP_DIV_FLOAT arm-vfp
-    op OP_DIV_FLOAT_2ADDR arm-vfp
-    op OP_DOUBLE_TO_FLOAT arm-vfp
-    op OP_DOUBLE_TO_INT arm-vfp
-    op OP_FLOAT_TO_DOUBLE arm-vfp
-    op OP_FLOAT_TO_INT arm-vfp
-    op OP_INT_TO_DOUBLE arm-vfp
-    op OP_INT_TO_FLOAT arm-vfp
-    op OP_MUL_DOUBLE arm-vfp
-    op OP_MUL_DOUBLE_2ADDR arm-vfp
-    op OP_MUL_FLOAT arm-vfp
-    op OP_MUL_FLOAT_2ADDR arm-vfp
-    op OP_SUB_DOUBLE arm-vfp
-    op OP_SUB_DOUBLE_2ADDR arm-vfp
-    op OP_SUB_FLOAT arm-vfp
-    op OP_SUB_FLOAT_2ADDR arm-vfp
+    op OP_ADD_DOUBLE arm-vfp_taint
+    op OP_ADD_DOUBLE_2ADDR arm-vfp_taint
+    op OP_ADD_FLOAT arm-vfp_taint
+    op OP_ADD_FLOAT_2ADDR arm-vfp_taint
+    op OP_CMPG_DOUBLE arm-vfp_taint
+    op OP_CMPG_FLOAT arm-vfp_taint
+    op OP_CMPL_DOUBLE arm-vfp_taint
+    op OP_CMPL_FLOAT arm-vfp_taint
+    op OP_DIV_DOUBLE arm-vfp_taint
+    op OP_DIV_DOUBLE_2ADDR arm-vfp_taint
+    op OP_DIV_FLOAT arm-vfp_taint
+    op OP_DIV_FLOAT_2ADDR arm-vfp_taint
+    op OP_DOUBLE_TO_FLOAT arm-vfp_taint
+    op OP_DOUBLE_TO_INT arm-vfp_taint
+    op OP_FLOAT_TO_DOUBLE arm-vfp_taint
+    op OP_FLOAT_TO_INT arm-vfp_taint
+    op OP_INT_TO_DOUBLE arm-vfp_taint
+    op OP_INT_TO_FLOAT arm-vfp_taint
+    op OP_MUL_DOUBLE arm-vfp_taint
+    op OP_MUL_DOUBLE_2ADDR arm-vfp_taint
+    op OP_MUL_FLOAT arm-vfp_taint
+    op OP_MUL_FLOAT_2ADDR arm-vfp_taint
+    op OP_SUB_DOUBLE arm-vfp_taint
+    op OP_SUB_DOUBLE_2ADDR arm-vfp_taint
+    op OP_SUB_FLOAT arm-vfp_taint
+    op OP_SUB_FLOAT_2ADDR arm-vfp_taint
 op-end
 
 # "helper" code for C; include if you use any of the C stubs (this generates
@@ -166,5 +151,5 @@ op-end
 import cstubs/enddefs.cpp
 
 # common subroutines for asm
-import armv5te/footer.S
-import armv5te/debug.cpp
+import armv5te_taint/footer.S
+import armv5te_taint/debug.cpp
diff --git a/vm/mterp/config-armv7-a-neon.notaint b/vm/mterp/config-armv7-a-neon.notaint
new file mode 100644
index 0000000..5f91365
--- /dev/null
+++ b/vm/mterp/config-armv7-a-neon.notaint
@@ -0,0 +1,170 @@
+# Copyright (C) 2009 The Android Open Source Project
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#      http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+#
+# Configuration for ARMv7-A targets.
+#
+# This target includes Thumb-2 and Thumb2-EE support, as well as VFPLite.
+#
+# The difference in performance between this and ARMv5TE appears to be
+# negligible on a Cortex-A8 CPU, so this is really just an experiment.
+#
+
+handler-style computed-goto
+handler-size 64
+
+# source for the instruction table stub
+asm-stub armv5te/stub.S
+
+# source for alternate entry stub
+asm-alt-stub armv5te/alt_stub.S
+
+# file header and basic definitions
+import c/header.cpp
+import armv5te/header.S
+
+# C pre-processor defines for stub C instructions
+import cstubs/stubdefs.cpp
+
+# highly-platform-specific defs
+import armv7-a/platform.S
+
+# common defs for the C helpers; include this before the instruction handlers
+import c/opcommon.cpp
+
+# arch-specific entry point to interpreter
+import armv5te/entry.S
+
+# opcode list; argument to op-start is default directory
+op-start armv5te
+    # handlers that take advantage of >= ARMv6T2 instructions
+    op OP_ADD_DOUBLE_2ADDR armv6t2
+    op OP_ADD_FLOAT_2ADDR armv6t2
+    op OP_ADD_INT_2ADDR armv6t2
+    op OP_ADD_INT_LIT16 armv6t2
+    op OP_ADD_LONG_2ADDR armv6t2
+    op OP_AND_INT_2ADDR armv6t2
+    op OP_AND_INT_LIT16 armv6t2
+    op OP_AND_LONG_2ADDR armv6t2
+    op OP_ARRAY_LENGTH armv6t2
+    op OP_CONST_4 armv6t2
+    op OP_DIV_DOUBLE_2ADDR armv6t2
+    op OP_DIV_FLOAT_2ADDR armv6t2
+    op OP_DIV_INT_2ADDR armv6t2
+    op OP_DIV_INT_LIT16 armv6t2
+    op OP_DIV_LONG_2ADDR armv6t2
+    op OP_DOUBLE_TO_FLOAT armv6t2
+    op OP_DOUBLE_TO_INT armv6t2
+    op OP_DOUBLE_TO_LONG armv6t2
+    op OP_FLOAT_TO_DOUBLE armv6t2
+    op OP_FLOAT_TO_INT armv6t2
+    op OP_FLOAT_TO_LONG armv6t2
+    op OP_IF_EQ armv6t2
+    op OP_IF_GE armv6t2
+    op OP_IF_GT armv6t2
+    op OP_IF_LE armv6t2
+    op OP_IF_LT armv6t2
+    op OP_IF_NE armv6t2
+    op OP_IGET armv6t2
+    op OP_IGET_QUICK armv6t2
+    op OP_IGET_WIDE armv6t2
+    op OP_IGET_WIDE_QUICK armv6t2
+    op OP_INT_TO_BYTE armv6t2
+    op OP_INT_TO_CHAR armv6t2
+    op OP_INT_TO_DOUBLE armv6t2
+    op OP_INT_TO_FLOAT armv6t2
+    op OP_INT_TO_LONG armv6t2
+    op OP_INT_TO_SHORT armv6t2
+    op OP_IPUT armv6t2
+    op OP_IPUT_QUICK armv6t2
+    op OP_IPUT_WIDE armv6t2
+    op OP_IPUT_WIDE_QUICK armv6t2
+    op OP_LONG_TO_DOUBLE armv6t2
+    op OP_LONG_TO_FLOAT armv6t2
+    op OP_MOVE armv6t2
+    op OP_MOVE_WIDE armv6t2
+    op OP_MUL_DOUBLE_2ADDR armv6t2
+    op OP_MUL_FLOAT_2ADDR armv6t2
+    op OP_MUL_INT_2ADDR armv6t2
+    op OP_MUL_INT_LIT16 armv6t2
+    op OP_MUL_LONG_2ADDR armv6t2
+    op OP_NEG_DOUBLE armv6t2
+    op OP_NEG_FLOAT armv6t2
+    op OP_NEG_INT armv6t2
+    op OP_NEG_LONG armv6t2
+    op OP_NOT_INT armv6t2
+    op OP_NOT_LONG armv6t2
+    op OP_OR_INT_2ADDR armv6t2
+    op OP_OR_INT_LIT16 armv6t2
+    op OP_OR_LONG_2ADDR armv6t2
+    op OP_REM_DOUBLE_2ADDR armv6t2
+    op OP_REM_FLOAT_2ADDR armv6t2
+    op OP_REM_INT_2ADDR armv6t2
+    op OP_REM_INT_LIT16 armv6t2
+    op OP_REM_LONG_2ADDR armv6t2
+    op OP_RSUB_INT armv6t2
+    op OP_SHL_INT_2ADDR armv6t2
+    op OP_SHL_LONG_2ADDR armv6t2
+    op OP_SHR_INT_2ADDR armv6t2
+    op OP_SHR_LONG_2ADDR armv6t2
+    op OP_SUB_DOUBLE_2ADDR armv6t2
+    op OP_SUB_FLOAT_2ADDR armv6t2
+    op OP_SUB_INT_2ADDR armv6t2
+    op OP_SUB_LONG_2ADDR armv6t2
+    op OP_USHR_INT_2ADDR armv6t2
+    op OP_USHR_LONG_2ADDR armv6t2
+    op OP_XOR_INT_2ADDR armv6t2
+    op OP_XOR_INT_LIT16 armv6t2
+    op OP_XOR_LONG_2ADDR armv6t2
+
+    # floating point handlers that use VFP
+    # these override the handlers specified earlier
+    op OP_ADD_DOUBLE arm-vfp
+    op OP_ADD_DOUBLE_2ADDR arm-vfp
+    op OP_ADD_FLOAT arm-vfp
+    op OP_ADD_FLOAT_2ADDR arm-vfp
+    op OP_CMPG_DOUBLE arm-vfp
+    op OP_CMPG_FLOAT arm-vfp
+    op OP_CMPL_DOUBLE arm-vfp
+    op OP_CMPL_FLOAT arm-vfp
+    op OP_DIV_DOUBLE arm-vfp
+    op OP_DIV_DOUBLE_2ADDR arm-vfp
+    op OP_DIV_FLOAT arm-vfp
+    op OP_DIV_FLOAT_2ADDR arm-vfp
+    op OP_DOUBLE_TO_FLOAT arm-vfp
+    op OP_DOUBLE_TO_INT arm-vfp
+    op OP_FLOAT_TO_DOUBLE arm-vfp
+    op OP_FLOAT_TO_INT arm-vfp
+    op OP_INT_TO_DOUBLE arm-vfp
+    op OP_INT_TO_FLOAT arm-vfp
+    op OP_MUL_DOUBLE arm-vfp
+    op OP_MUL_DOUBLE_2ADDR arm-vfp
+    op OP_MUL_FLOAT arm-vfp
+    op OP_MUL_FLOAT_2ADDR arm-vfp
+    op OP_SUB_DOUBLE arm-vfp
+    op OP_SUB_DOUBLE_2ADDR arm-vfp
+    op OP_SUB_FLOAT arm-vfp
+    op OP_SUB_FLOAT_2ADDR arm-vfp
+op-end
+
+# "helper" code for C; include if you use any of the C stubs (this generates
+# object code, so it's normally excluded)
+##import c/gotoTargets.cpp
+
+# end of defs; include this when cstubs/stubdefs.cpp is included
+import cstubs/enddefs.cpp
+
+# common subroutines for asm
+import armv5te/footer.S
+import armv5te/debug.cpp
diff --git a/vm/mterp/config-armv7-a.notaint b/vm/mterp/config-armv7-a.notaint
new file mode 100644
index 0000000..eadaeca
--- /dev/null
+++ b/vm/mterp/config-armv7-a.notaint
@@ -0,0 +1,172 @@
+# Copyright (C) 2009 The Android Open Source Project
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#      http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+#
+# Configuration for ARMv7-A targets.
+#
+# This target includes Thumb-2 and Thumb2-EE support, as well as VFPLite.
+#
+# The difference in performance between this and ARMv5TE appears to be
+# negligible on a Cortex-A8 CPU, so this is really just an experiment.
+#
+
+handler-style computed-goto
+handler-size 64
+
+# source for the instruction table stub
+asm-stub armv5te/stub.S
+
+# source for alternate entry stub
+asm-alt-stub armv5te/alt_stub.S
+
+# file header and basic definitions
+import c/header.cpp
+import armv5te/header.S
+
+# C pre-processor defines for stub C instructions
+import cstubs/stubdefs.cpp
+
+# highly-platform-specific defs
+import armv7-a/platform.S
+
+# common defs for the C helpers; include this before the instruction handlers
+import c/opcommon.cpp
+
+# arch-specific entry point to interpreter
+import armv5te/entry.S
+
+# opcode list; argument to op-start is default directory
+op-start armv5te
+    # handlers that take advantage of >= ARMv6T2 instructions
+    op OP_ADD_DOUBLE_2ADDR armv6t2
+    op OP_ADD_FLOAT_2ADDR armv6t2
+    op OP_ADD_INT_2ADDR armv6t2
+    op OP_ADD_INT_LIT16 armv6t2
+    op OP_ADD_LONG_2ADDR armv6t2
+    op OP_AND_INT_2ADDR armv6t2
+    op OP_AND_INT_LIT16 armv6t2
+    op OP_AND_LONG_2ADDR armv6t2
+    op OP_ARRAY_LENGTH armv6t2
+    op OP_CONST_4 armv6t2
+    op OP_DIV_DOUBLE_2ADDR armv6t2
+    op OP_DIV_FLOAT_2ADDR armv6t2
+    op OP_DIV_INT_2ADDR armv6t2
+    op OP_DIV_INT_LIT16 armv6t2
+    op OP_DIV_LONG_2ADDR armv6t2
+    op OP_DOUBLE_TO_FLOAT armv6t2
+    op OP_DOUBLE_TO_INT armv6t2
+    op OP_DOUBLE_TO_LONG armv6t2
+    op OP_FLOAT_TO_DOUBLE armv6t2
+    op OP_FLOAT_TO_INT armv6t2
+    op OP_FLOAT_TO_LONG armv6t2
+    op OP_IF_EQ armv6t2
+    op OP_IF_GE armv6t2
+    op OP_IF_GT armv6t2
+    op OP_IF_LE armv6t2
+    op OP_IF_LT armv6t2
+    op OP_IF_NE armv6t2
+    op OP_IGET armv6t2
+    op OP_IGET_QUICK armv6t2
+    op OP_IGET_WIDE armv6t2
+    op OP_IGET_WIDE_QUICK armv6t2
+    op OP_INT_TO_BYTE armv6t2
+    op OP_INT_TO_CHAR armv6t2
+    op OP_INT_TO_DOUBLE armv6t2
+    op OP_INT_TO_FLOAT armv6t2
+    op OP_INT_TO_LONG armv6t2
+    op OP_INT_TO_SHORT armv6t2
+    op OP_IPUT armv6t2
+    op OP_IPUT_QUICK armv6t2
+    op OP_IPUT_WIDE armv6t2
+    op OP_IPUT_WIDE_QUICK armv6t2
+    op OP_LONG_TO_DOUBLE armv6t2
+    op OP_LONG_TO_FLOAT armv6t2
+    op OP_MOVE armv6t2
+    op OP_MOVE_WIDE armv6t2
+    op OP_MUL_DOUBLE_2ADDR armv6t2
+    op OP_MUL_FLOAT_2ADDR armv6t2
+    op OP_MUL_INT_2ADDR armv6t2
+    op OP_MUL_INT_LIT16 armv6t2
+    op OP_MUL_LONG_2ADDR armv6t2
+    op OP_NEG_DOUBLE armv6t2
+    op OP_NEG_FLOAT armv6t2
+    op OP_NEG_INT armv6t2
+    op OP_NEG_LONG armv6t2
+    op OP_NOT_INT armv6t2
+    op OP_NOT_LONG armv6t2
+    op OP_OR_INT_2ADDR armv6t2
+    op OP_OR_INT_LIT16 armv6t2
+    op OP_OR_LONG_2ADDR armv6t2
+    op OP_REM_DOUBLE_2ADDR armv6t2
+    op OP_REM_FLOAT_2ADDR armv6t2
+    op OP_REM_INT_2ADDR armv6t2
+    op OP_REM_INT_LIT16 armv6t2
+    op OP_REM_LONG_2ADDR armv6t2
+    op OP_RSUB_INT armv6t2
+    op OP_SHL_INT_2ADDR armv6t2
+    op OP_SHL_LONG_2ADDR armv6t2
+    op OP_SHR_INT_2ADDR armv6t2
+    op OP_SHR_LONG_2ADDR armv6t2
+    op OP_SUB_DOUBLE_2ADDR armv6t2
+    op OP_SUB_FLOAT_2ADDR armv6t2
+    op OP_SUB_INT_2ADDR armv6t2
+    op OP_SUB_LONG_2ADDR armv6t2
+    op OP_USHR_INT_2ADDR armv6t2
+    op OP_USHR_LONG_2ADDR armv6t2
+    op OP_XOR_INT_2ADDR armv6t2
+    op OP_XOR_INT_LIT16 armv6t2
+    op OP_XOR_LONG_2ADDR armv6t2
+
+    # floating point handlers that use VFP
+    # these override the handlers specified earlier
+    op OP_ADD_DOUBLE arm-vfp
+    op OP_ADD_DOUBLE_2ADDR arm-vfp
+    op OP_ADD_FLOAT arm-vfp
+    op OP_ADD_FLOAT_2ADDR arm-vfp
+    op OP_CMPG_DOUBLE arm-vfp
+    op OP_CMPG_FLOAT arm-vfp
+    op OP_CMPL_DOUBLE arm-vfp
+    op OP_CMPL_FLOAT arm-vfp
+    op OP_DIV_DOUBLE arm-vfp
+    op OP_DIV_DOUBLE_2ADDR arm-vfp
+    op OP_DIV_FLOAT arm-vfp
+    op OP_DIV_FLOAT_2ADDR arm-vfp
+    op OP_DOUBLE_TO_FLOAT arm-vfp
+    op OP_DOUBLE_TO_INT arm-vfp
+    op OP_FLOAT_TO_DOUBLE arm-vfp
+    op OP_FLOAT_TO_INT arm-vfp
+    op OP_INT_TO_DOUBLE arm-vfp
+    op OP_INT_TO_FLOAT arm-vfp
+    op OP_MUL_DOUBLE arm-vfp
+    op OP_MUL_DOUBLE_2ADDR arm-vfp
+    op OP_MUL_FLOAT arm-vfp
+    op OP_MUL_FLOAT_2ADDR arm-vfp
+    op OP_SUB_DOUBLE arm-vfp
+    op OP_SUB_DOUBLE_2ADDR arm-vfp
+    op OP_SUB_FLOAT arm-vfp
+    op OP_SUB_FLOAT_2ADDR arm-vfp
+op-end
+
+# "helper" code for C; include if you use any of the C stubs (this generates
+# object code, so it's normally excluded)
+#
+# Add this if you see linker failures for stuff like "dvmMterp_exceptionThrown".
+##import c/gotoTargets.cpp
+
+# end of defs; include this when cstubs/stubdefs.cpp is included
+import cstubs/enddefs.cpp
+
+# common subroutines for asm
+import armv5te/footer.S
+import armv5te/debug.cpp
diff --git a/vm/mterp/cstubs/enddefs.cpp b/vm/mterp/cstubs/enddefs.cpp
index cac74bf..bf8686c 100644
--- a/vm/mterp/cstubs/enddefs.cpp
+++ b/vm/mterp/cstubs/enddefs.cpp
@@ -7,3 +7,8 @@
 #undef methodClassDex
 #undef self
 #undef debugTrackedRefStart
+
+#ifdef WITH_TAINT_TRACKING
+#undef rtaint
+#endif
+
diff --git a/vm/mterp/cstubs/stubdefs.cpp b/vm/mterp/cstubs/stubdefs.cpp
index ed0e4da..f077e44 100644
--- a/vm/mterp/cstubs/stubdefs.cpp
+++ b/vm/mterp/cstubs/stubdefs.cpp
@@ -29,6 +29,10 @@
 #define methodClassDex          self->interpSave.methodClassDex
 #define debugTrackedRefStart    self->interpSave.debugTrackedRefStart
 
+#ifdef WITH_TAINT_TRACKING
+#define rtaint			self->interpSave.rtaint
+#endif
+
 /* ugh */
 #define STUB_HACK(x) x
 #if defined(WITH_JIT)
diff --git a/vm/mterp/out/InterpAsm-armv7-a-neon.S b/vm/mterp/out/InterpAsm-armv7-a-neon.S
index 2bed3ef..aaed30e 100644
--- a/vm/mterp/out/InterpAsm-armv7-a-neon.S
+++ b/vm/mterp/out/InterpAsm-armv7-a-neon.S
@@ -4,7 +4,7 @@
  * --> DO NOT EDIT <--
  */
 
-/* File: armv5te/header.S */
+/* File: armv5te_taint/header.S */
 /*
  * Copyright (C) 2008 The Android Open Source Project
  *
@@ -183,14 +183,28 @@ unspecified registers or condition codes.
 /*
  * Get/set the 32-bit value from a Dalvik register.
  */
+#ifdef WITH_TAINT_TRACKING
+#define SET_TAINT_FP(_reg)      add     _reg, rFP, #4
+#define SET_TAINT_CLEAR(_reg)   mov     _reg, #0
+#define GET_VREG(_reg, _vreg)   ldr     _reg, [rFP, _vreg, lsl #3]
+#define SET_VREG(_reg, _vreg)   str     _reg, [rFP, _vreg, lsl #3]
+#define GET_VREG_TAINT(_reg, _vreg, _rFP)   ldr     _reg, [_rFP, _vreg, lsl #3]
+#define SET_VREG_TAINT(_reg, _vreg, _rFP)   str     _reg, [_rFP, _vreg, lsl #3]
+#else
 #define GET_VREG(_reg, _vreg)   ldr     _reg, [rFP, _vreg, lsl #2]
 #define SET_VREG(_reg, _vreg)   str     _reg, [rFP, _vreg, lsl #2]
+#endif /*WITH_TAINT_TRACKING*/
 
 /*
  * Convert a virtual register index into an address.
  */
+#ifdef WITH_TAINT_TRACKING
+#define VREG_INDEX_TO_ADDR(_reg, _vreg) \
+        add     _reg, rFP, _vreg, lsl #3
+#else
 #define VREG_INDEX_TO_ADDR(_reg, _vreg) \
         add     _reg, rFP, _vreg, lsl #2
+#endif /*WITH_TAINT_TRACKING*/
 
 /*
  * This is a #include, not a %include, because we want the C pre-processor
@@ -235,7 +249,7 @@ unspecified registers or condition codes.
 #endif
 .endm
 
-/* File: armv5te/entry.S */
+/* File: armv5te_taint/entry.S */
 /*
  * Copyright (C) 2008 The Android Open Source Project
  *
@@ -376,7 +390,7 @@ dvmAsmInstructionStart = .L_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_OP_NOP: /* 0x00 */
-/* File: armv5te/OP_NOP.S */
+/* File: armv5te_taint/OP_NOP.S */
     FETCH_ADVANCE_INST(1)               @ advance to next instr, load rINST
     GET_INST_OPCODE(ip)                 @ ip<- opcode from rINST
     GOTO_OPCODE(ip)                     @ execute it
@@ -391,101 +405,135 @@ dalvik_inst:
     .fnend
 #endif
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_MOVE: /* 0x01 */
-/* File: armv6t2/OP_MOVE.S */
+/* File: armv6t2_taint/OP_MOVE.S */
     /* for move, move-object, long-to-int */
     /* op vA, vB */
     mov     r1, rINST, lsr #12          @ r1<- B from 15:12
     ubfx    r0, rINST, #8, #4           @ r0<- A from 11:8
     FETCH_ADVANCE_INST(1)               @ advance rPC, load rINST
     GET_VREG(r2, r1)                    @ r2<- fp[B]
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r3)
+    GET_VREG_TAINT(r1, r1, r3)
+    SET_VREG_TAINT(r1, r0, r3)
+// end WITH_TAINT_TRACKING
     GET_INST_OPCODE(ip)                 @ ip<- opcode from rINST
     SET_VREG(r2, r0)                    @ fp[A]<- r2
     GOTO_OPCODE(ip)                     @ execute next instruction
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_MOVE_FROM16: /* 0x02 */
-/* File: armv5te/OP_MOVE_FROM16.S */
+/* File: armv5te_taint/OP_MOVE_FROM16.S */
     /* for: move/from16, move-object/from16 */
     /* op vAA, vBBBB */
     FETCH(r1, 1)                        @ r1<- BBBB
     mov     r0, rINST, lsr #8           @ r0<- AA
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
     GET_VREG(r2, r1)                    @ r2<- fp[BBBB]
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r3)
+    GET_VREG_TAINT(r1, r1, r3)
+    SET_VREG_TAINT(r1, r0, r3)
+// end WITH_TAINT_TRACKING
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
     SET_VREG(r2, r0)                    @ fp[AA]<- r2
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_MOVE_16: /* 0x03 */
-/* File: armv5te/OP_MOVE_16.S */
+/* File: armv5te_taint/OP_MOVE_16.S */
     /* for: move/16, move-object/16 */
     /* op vAAAA, vBBBB */
     FETCH(r1, 2)                        @ r1<- BBBB
     FETCH(r0, 1)                        @ r0<- AAAA
     FETCH_ADVANCE_INST(3)               @ advance rPC, load rINST
     GET_VREG(r2, r1)                    @ r2<- fp[BBBB]
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r3)
+    GET_VREG_TAINT(r1, r1, r3)
+    SET_VREG_TAINT(r1, r0, r3)
+// end WITH_TAINT_TRACKING
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
     SET_VREG(r2, r0)                    @ fp[AAAA]<- r2
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_MOVE_WIDE: /* 0x04 */
-/* File: armv6t2/OP_MOVE_WIDE.S */
+/* File: armv6t2_taint/OP_MOVE_WIDE.S */
     /* move-wide vA, vB */
     /* NOTE: regs can overlap, e.g. "move v6,v7" or "move v7,v6" */
     mov     r3, rINST, lsr #12          @ r3<- B
     ubfx    r2, rINST, #8, #4           @ r2<- A
-    add     r3, rFP, r3, lsl #2         @ r3<- &fp[B]
-    add     r2, rFP, r2, lsl #2         @ r2<- &fp[A]
-    ldmia   r3, {r0-r1}                 @ r0/r1<- fp[B]
+// begin WITH_TAINT_TRACKING
+    add     r3, rFP, r3, lsl #3         @ r3<- &fp[B]
+    add     r9, rFP, r2, lsl #3         @ r9<- &fp[A]
+    ldmia   r3, {r0-r3}                 @ r0/r1<- fp[B]
+// end WITH_TAINT_TRACKING
     FETCH_ADVANCE_INST(1)               @ advance rPC, load rINST
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    stmia   r2, {r0-r1}                 @ fp[A]<- r0/r1
+// begin WITH_TAINT_TRACKING
+    stmia   r9, {r0-r3}                 @ fp[A]<- r0/r1
+// end WITH_TAINT_TRACKING
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_MOVE_WIDE_FROM16: /* 0x05 */
-/* File: armv5te/OP_MOVE_WIDE_FROM16.S */
+/* File: armv5te_taint/OP_MOVE_WIDE_FROM16.S */
     /* move-wide/from16 vAA, vBBBB */
     /* NOTE: regs can overlap, e.g. "move v6,v7" or "move v7,v6" */
     FETCH(r3, 1)                        @ r3<- BBBB
     mov     r2, rINST, lsr #8           @ r2<- AA
-    add     r3, rFP, r3, lsl #2         @ r3<- &fp[BBBB]
-    add     r2, rFP, r2, lsl #2         @ r2<- &fp[AA]
-    ldmia   r3, {r0-r1}                 @ r0/r1<- fp[BBBB]
+// begin WITH_TAINT_TRACKING
+    add     r3, rFP, r3, lsl #3         @ r3<- &fp[BBBB]
+    add     r9, rFP, r2, lsl #3         @ r9<- &fp[AA]
+    ldmia   r3, {r0-r3}                 @ r0/r1<- fp[BBBB]
+// end WITH_TAINT_TRACKING
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    stmia   r2, {r0-r1}                 @ fp[AA]<- r0/r1
+// begin WITH_TAINT_TRACKING
+    stmia   r9, {r0-r3}                 @ fp[AA]<- r0/r1
+// end WITH_TAINT_TRACKING
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_MOVE_WIDE_16: /* 0x06 */
-/* File: armv5te/OP_MOVE_WIDE_16.S */
+/* File: armv5te_taint/OP_MOVE_WIDE_16.S */
     /* move-wide/16 vAAAA, vBBBB */
     /* NOTE: regs can overlap, e.g. "move v6,v7" or "move v7,v6" */
     FETCH(r3, 2)                        @ r3<- BBBB
     FETCH(r2, 1)                        @ r2<- AAAA
-    add     r3, rFP, r3, lsl #2         @ r3<- &fp[BBBB]
-    add     r2, rFP, r2, lsl #2         @ r2<- &fp[AAAA]
-    ldmia   r3, {r0-r1}                 @ r0/r1<- fp[BBBB]
+// begin WITH_TAINT_TRACKING
+    add     r3, rFP, r3, lsl #3         @ r3<- &fp[BBBB]
+    add     r9, rFP, r2, lsl #3         @ r9<- &fp[AAAA]
+    ldmia   r3, {r0-r3}                 @ r0/r1<- fp[BBBB]
+// end WITH_TAINT_TRACKING
     FETCH_ADVANCE_INST(3)               @ advance rPC, load rINST
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    stmia   r2, {r0-r1}                 @ fp[AAAA]<- r0/r1
+// begin WITH_TAINT_TRACKING
+    stmia   r9, {r0-r3}                 @ fp[AAAA]<- r0/r1
+// end WITH_TAINT_TRACKING
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_MOVE_OBJECT: /* 0x07 */
-/* File: armv5te/OP_MOVE_OBJECT.S */
-/* File: armv5te/OP_MOVE.S */
+/* File: armv5te_taint/OP_MOVE_OBJECT.S */
+/* File: armv5te_taint/OP_MOVE.S */
     /* for move, move-object, long-to-int */
     /* op vA, vB */
     mov     r1, rINST, lsr #12          @ r1<- B from 15:12
@@ -493,47 +541,65 @@ dalvik_inst:
     FETCH_ADVANCE_INST(1)               @ advance rPC, load rINST
     GET_VREG(r2, r1)                    @ r2<- fp[B]
     and     r0, r0, #15
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r3)
+    GET_VREG_TAINT(r1, r1, r3)
+    SET_VREG_TAINT(r1, r0, r3)
+// end WITH_TAINT_TRACKING
     GET_INST_OPCODE(ip)                 @ ip<- opcode from rINST
     SET_VREG(r2, r0)                    @ fp[A]<- r2
     GOTO_OPCODE(ip)                     @ execute next instruction
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_MOVE_OBJECT_FROM16: /* 0x08 */
-/* File: armv5te/OP_MOVE_OBJECT_FROM16.S */
-/* File: armv5te/OP_MOVE_FROM16.S */
+/* File: armv5te_taint/OP_MOVE_OBJECT_FROM16.S */
+/* File: armv5te_taint/OP_MOVE_FROM16.S */
     /* for: move/from16, move-object/from16 */
     /* op vAA, vBBBB */
     FETCH(r1, 1)                        @ r1<- BBBB
     mov     r0, rINST, lsr #8           @ r0<- AA
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
     GET_VREG(r2, r1)                    @ r2<- fp[BBBB]
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r3)
+    GET_VREG_TAINT(r1, r1, r3)
+    SET_VREG_TAINT(r1, r0, r3)
+// end WITH_TAINT_TRACKING
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
     SET_VREG(r2, r0)                    @ fp[AA]<- r2
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_MOVE_OBJECT_16: /* 0x09 */
-/* File: armv5te/OP_MOVE_OBJECT_16.S */
-/* File: armv5te/OP_MOVE_16.S */
+/* File: armv5te_taint/OP_MOVE_OBJECT_16.S */
+/* File: armv5te_taint/OP_MOVE_16.S */
     /* for: move/16, move-object/16 */
     /* op vAAAA, vBBBB */
     FETCH(r1, 2)                        @ r1<- BBBB
     FETCH(r0, 1)                        @ r0<- AAAA
     FETCH_ADVANCE_INST(3)               @ advance rPC, load rINST
     GET_VREG(r2, r1)                    @ r2<- fp[BBBB]
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r3)
+    GET_VREG_TAINT(r1, r1, r3)
+    SET_VREG_TAINT(r1, r0, r3)
+// end WITH_TAINT_TRACKING
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
     SET_VREG(r2, r0)                    @ fp[AAAA]<- r2
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_MOVE_RESULT: /* 0x0a */
-/* File: armv5te/OP_MOVE_RESULT.S */
+/* File: armv5te_taint/OP_MOVE_RESULT.S */
     /* for: move-result, move-result-object */
     /* op vAA */
     mov     r2, rINST, lsr #8           @ r2<- AA
@@ -541,27 +607,42 @@ dalvik_inst:
     ldr     r0, [rSELF, #offThread_retval]    @ r0<- self->retval.i
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
     SET_VREG(r0, r2)                    @ fp[AA]<- r0
+// begin WITH_TAINT_TRACKING
+    ldr     r0, [rSELF, #offThread_rtaint]
+    SET_TAINT_FP(r1)
+    SET_VREG_TAINT(r0, r2, r1)
+// end WITH_TAINT_TRACKING
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
 /* ------------------------------ */
     .balign 64
 .L_OP_MOVE_RESULT_WIDE: /* 0x0b */
-/* File: armv5te/OP_MOVE_RESULT_WIDE.S */
+/* File: armv5te_taint/OP_MOVE_RESULT_WIDE.S */
     /* move-result-wide vAA */
     mov     r2, rINST, lsr #8           @ r2<- AA
     add     r3, rSELF, #offThread_retval  @ r3<- &self->retval
-    add     r2, rFP, r2, lsl #2         @ r2<- &fp[AA]
+// begin WITH_TAINT_TRACKING
+    add     r2, rFP, r2, lsl #3         @ r2<- &fp[AA]
+// end WITH_TAINT_TRACKING
     ldmia   r3, {r0-r1}                 @ r0/r1<- retval.j
     FETCH_ADVANCE_INST(1)               @ advance rPC, load rINST
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    stmia   r2, {r0-r1}                 @ fp[AA]<- r0/r1
+// begin WITH_TAINT_TRACKING
+//    stmia   r2, {r0-r1}                 @ fp[AA]<- r0/r1
+    ldr r3, [rSELF, #offThread_rtaint]
+    str r0, [r2, #0]
+    str r3, [r2, #4]
+    str r1, [r2, #8]
+    str r3, [r2, #12]
+// end WITH_TAINT_TRACKING
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_MOVE_RESULT_OBJECT: /* 0x0c */
-/* File: armv5te/OP_MOVE_RESULT_OBJECT.S */
-/* File: armv5te/OP_MOVE_RESULT.S */
+/* File: armv5te_taint/OP_MOVE_RESULT_OBJECT.S */
+/* File: armv5te_taint/OP_MOVE_RESULT.S */
     /* for: move-result, move-result-object */
     /* op vAA */
     mov     r2, rINST, lsr #8           @ r2<- AA
@@ -569,19 +650,29 @@ dalvik_inst:
     ldr     r0, [rSELF, #offThread_retval]    @ r0<- self->retval.i
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
     SET_VREG(r0, r2)                    @ fp[AA]<- r0
+// begin WITH_TAINT_TRACKING
+    ldr     r0, [rSELF, #offThread_rtaint]
+    SET_TAINT_FP(r1)
+    SET_VREG_TAINT(r0, r2, r1)
+// end WITH_TAINT_TRACKING
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
 
 /* ------------------------------ */
     .balign 64
 .L_OP_MOVE_EXCEPTION: /* 0x0d */
-/* File: armv5te/OP_MOVE_EXCEPTION.S */
+/* File: armv5te_taint/OP_MOVE_EXCEPTION.S */
     /* move-exception vAA */
     mov     r2, rINST, lsr #8           @ r2<- AA
     ldr     r3, [rSELF, #offThread_exception]  @ r3<- dvmGetException bypass
     mov     r1, #0                      @ r1<- 0
     FETCH_ADVANCE_INST(1)               @ advance rPC, load rINST
     SET_VREG(r3, r2)                    @ fp[AA]<- exception obj
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r3)
+    SET_TAINT_CLEAR(r9)
+    SET_VREG_TAINT(r9, r2, r3)
+// end WITH_TAINT_TRACKING
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
     str     r1, [rSELF, #offThread_exception]  @ dvmClearException bypass
     GOTO_OPCODE(ip)                     @ jump to next instruction
@@ -589,13 +680,16 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_RETURN_VOID: /* 0x0e */
-/* File: armv5te/OP_RETURN_VOID.S */
+/* File: armv5te_taint/OP_RETURN_VOID.S */
+    SET_TAINT_CLEAR(r1)
+    str     r1, [rSELF, #offThread_rtaint]
     b       common_returnFromMethod
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_RETURN: /* 0x0f */
-/* File: armv5te/OP_RETURN.S */
+/* File: armv5te_taint/OP_RETURN.S */
     /*
      * Return a 32-bit value.  Copies the return value into the "thread"
      * structure, then jumps to the return handler.
@@ -605,30 +699,43 @@ dalvik_inst:
     /* op vAA */
     mov     r2, rINST, lsr #8           @ r2<- AA
     GET_VREG(r0, r2)                    @ r0<- vAA
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r1)
+    GET_VREG_TAINT(r3, r2, r1)
+    str     r3, [rSELF, #offThread_rtaint]
+// end WITH_TAINT_TRACKING
     str     r0, [rSELF, #offThread_retval] @ retval.i <- vAA
     b       common_returnFromMethod
 
 /* ------------------------------ */
     .balign 64
 .L_OP_RETURN_WIDE: /* 0x10 */
-/* File: armv5te/OP_RETURN_WIDE.S */
+/* File: armv5te_taint/OP_RETURN_WIDE.S */
     /*
      * Return a 64-bit value.  Copies the return value into the "thread"
      * structure, then jumps to the return handler.
      */
     /* return-wide vAA */
     mov     r2, rINST, lsr #8           @ r2<- AA
-    add     r2, rFP, r2, lsl #2         @ r2<- &fp[AA]
+// begin WITH_TAINT_TRACKING
+    add     r2, rFP, r2, lsl #3         @ r2<- &fp[AA]
+// end WITH_TAINT_TRACKING
     add     r3, rSELF, #offThread_retval  @ r3<- &self->retval
-    ldmia   r2, {r0-r1}                 @ r0/r1 <- vAA/vAA+1
+// begin WITH_TAINT_TRACKING
+//    ldmia   r2, {r0-r1}                 @ r0/r1 <- vAA/vAA+1
+    ldr     r0, [r2, #0]
+    ldr     r1, [r2, #8]
+    ldr     r9, [r2, #4]
+    str     r9, [rSELF, #offThread_rtaint]
+// end WITH_TAINT_TRACKING
     stmia   r3, {r0-r1}                 @ retval<- r0/r1
     b       common_returnFromMethod
 
 /* ------------------------------ */
     .balign 64
 .L_OP_RETURN_OBJECT: /* 0x11 */
-/* File: armv5te/OP_RETURN_OBJECT.S */
-/* File: armv5te/OP_RETURN.S */
+/* File: armv5te_taint/OP_RETURN_OBJECT.S */
+/* File: armv5te_taint/OP_RETURN.S */
     /*
      * Return a 32-bit value.  Copies the return value into the "thread"
      * structure, then jumps to the return handler.
@@ -638,6 +745,11 @@ dalvik_inst:
     /* op vAA */
     mov     r2, rINST, lsr #8           @ r2<- AA
     GET_VREG(r0, r2)                    @ r0<- vAA
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r1)
+    GET_VREG_TAINT(r3, r2, r1)
+    str     r3, [rSELF, #offThread_rtaint]
+// end WITH_TAINT_TRACKING
     str     r0, [rSELF, #offThread_retval] @ retval.i <- vAA
     b       common_returnFromMethod
 
@@ -645,12 +757,17 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_CONST_4: /* 0x12 */
-/* File: armv6t2/OP_CONST_4.S */
+/* File: armv6t2_taint/OP_CONST_4.S */
     /* const/4 vA, #+B */
     mov     r1, rINST, lsl #16          @ r1<- Bxxx0000
     ubfx    r0, rINST, #8, #4           @ r0<- A
     FETCH_ADVANCE_INST(1)               @ advance rPC, load rINST
     mov     r1, r1, asr #28             @ r1<- sssssssB (sign-extended)
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r2)
+    SET_TAINT_CLEAR(r3)
+    SET_VREG_TAINT(r3, r0, r2)
+// end WITH_TAINT_TRACKING
     GET_INST_OPCODE(ip)                 @ ip<- opcode from rINST
     SET_VREG(r1, r0)                    @ fp[A]<- r1
     GOTO_OPCODE(ip)                     @ execute next instruction
@@ -658,76 +775,110 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_CONST_16: /* 0x13 */
-/* File: armv5te/OP_CONST_16.S */
+/* File: armv5te_taint/OP_CONST_16.S */
     /* const/16 vAA, #+BBBB */
     FETCH_S(r0, 1)                      @ r0<- ssssBBBB (sign-extended)
     mov     r3, rINST, lsr #8           @ r3<- AA
+// BEGIN WITH_TAINT_TRACKING
+	SET_TAINT_FP(r1)
+	SET_TAINT_CLEAR(r2)
+    SET_VREG_TAINT(r2, r3, r1)
+// END WITH_TAINT_TRACKING
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
     SET_VREG(r0, r3)                    @ vAA<- r0
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_CONST: /* 0x14 */
-/* File: armv5te/OP_CONST.S */
+/* File: armv5te_taint/OP_CONST.S */
     /* const vAA, #+BBBBbbbb */
     mov     r3, rINST, lsr #8           @ r3<- AA
     FETCH(r0, 1)                        @ r0<- bbbb (low)
     FETCH(r1, 2)                        @ r1<- BBBB (high)
     FETCH_ADVANCE_INST(3)               @ advance rPC, load rINST
     orr     r0, r0, r1, lsl #16         @ r0<- BBBBbbbb
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r2)
+    SET_TAINT_CLEAR(r1)
+    SET_VREG_TAINT(r1, r3, r2)
+// end WITH_TAINT_TRACKING
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
     SET_VREG(r0, r3)                    @ vAA<- r0
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_CONST_HIGH16: /* 0x15 */
-/* File: armv5te/OP_CONST_HIGH16.S */
+/* File: armv5te_taint/OP_CONST_HIGH16.S */
     /* const/high16 vAA, #+BBBB0000 */
     FETCH(r0, 1)                        @ r0<- 0000BBBB (zero-extended)
     mov     r3, rINST, lsr #8           @ r3<- AA
     mov     r0, r0, lsl #16             @ r0<- BBBB0000
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r2)
+    SET_TAINT_CLEAR(r1)
+    SET_VREG_TAINT(r1, r3, r2)
+// end WITH_TAINT_TRACKING
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
     SET_VREG(r0, r3)                    @ vAA<- r0
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_CONST_WIDE_16: /* 0x16 */
-/* File: armv5te/OP_CONST_WIDE_16.S */
+/* File: armv5te_taint/OP_CONST_WIDE_16.S */
     /* const-wide/16 vAA, #+BBBB */
     FETCH_S(r0, 1)                      @ r0<- ssssBBBB (sign-extended)
     mov     r3, rINST, lsr #8           @ r3<- AA
-    mov     r1, r0, asr #31             @ r1<- ssssssss
+// begin WITH_TAINT_TRACKING
+    mov     r2, r0, asr #31             @ r1<- ssssssss
+// end WITH_TAINT_TRACKING
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
-    add     r3, rFP, r3, lsl #2         @ r3<- &fp[AA]
+// begin WITH_TAINT_TRACKING
+    add     r9, rFP, r3, lsl #3         @ r3<- &fp[AA]
+// end WITH_TAINT_TRACKING
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    stmia   r3, {r0-r1}                 @ vAA<- r0/r1
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_CLEAR(r1)
+    SET_TAINT_CLEAR(r3)
+    stmia   r9, {r0-r3}                 @ vAA<- r0/r1
+// end WITH_TAINT_TRACKING
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_CONST_WIDE_32: /* 0x17 */
-/* File: armv5te/OP_CONST_WIDE_32.S */
+/* File: armv5te_taint/OP_CONST_WIDE_32.S */
     /* const-wide/32 vAA, #+BBBBbbbb */
     FETCH(r0, 1)                        @ r0<- 0000bbbb (low)
     mov     r3, rINST, lsr #8           @ r3<- AA
     FETCH_S(r2, 2)                      @ r2<- ssssBBBB (high)
     FETCH_ADVANCE_INST(3)               @ advance rPC, load rINST
     orr     r0, r0, r2, lsl #16         @ r0<- BBBBbbbb
-    add     r3, rFP, r3, lsl #2         @ r3<- &fp[AA]
-    mov     r1, r0, asr #31             @ r1<- ssssssss
+// begin WITH_TAINT_TRACKING
+    add     r9, rFP, r3, lsl #3         @ r9<- &fp[AA]
+    mov     r2, r0, asr #31             @ r2<- ssssssss
+// end WITH_TAINT_TRACKING
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    stmia   r3, {r0-r1}                 @ vAA<- r0/r1
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_CLEAR(r1)
+    SET_TAINT_CLEAR(r3)
+    stmia   r9, {r0-r3}                 @ vAA<- r0/r1
+// end WITH_TAINT_TRACKING
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_CONST_WIDE: /* 0x18 */
-/* File: armv5te/OP_CONST_WIDE.S */
+/* File: armv5te_taint/OP_CONST_WIDE.S */
     /* const-wide vAA, #+HHHHhhhhBBBBbbbb */
     FETCH(r0, 1)                        @ r0<- bbbb (low)
     FETCH(r1, 2)                        @ r1<- BBBB (low middle)
@@ -735,32 +886,50 @@ dalvik_inst:
     orr     r0, r0, r1, lsl #16         @ r0<- BBBBbbbb (low word)
     FETCH(r3, 4)                        @ r3<- HHHH (high)
     mov     r9, rINST, lsr #8           @ r9<- AA
-    orr     r1, r2, r3, lsl #16         @ r1<- HHHHhhhh (high word)
+// begin WITH_TAINT_TRACKING
+    orr     r2, r2, r3, lsl #16         @ r2<- HHHHhhhh (high word)
+// end WITH_TAINT_TRACKING
     FETCH_ADVANCE_INST(5)               @ advance rPC, load rINST
-    add     r9, rFP, r9, lsl #2         @ r9<- &fp[AA]
+// begin WITH_TAINT_TRACKING
+    add     r9, rFP, r9, lsl #3         @ r9<- &fp[AA]
+// end WITH_TAINT_TRACKING
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    stmia   r9, {r0-r1}                 @ vAA<- r0/r1
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_CLEAR(r1)
+    SET_TAINT_CLEAR(r3)
+    stmia   r9, {r0-r3}                 @ vAA<- r0/r1
+// end WITH_TAINT_TRACKING
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_CONST_WIDE_HIGH16: /* 0x19 */
-/* File: armv5te/OP_CONST_WIDE_HIGH16.S */
+/* File: armv5te_taint/OP_CONST_WIDE_HIGH16.S */
     /* const-wide/high16 vAA, #+BBBB000000000000 */
     FETCH(r1, 1)                        @ r1<- 0000BBBB (zero-extended)
     mov     r3, rINST, lsr #8           @ r3<- AA
     mov     r0, #0                      @ r0<- 00000000
-    mov     r1, r1, lsl #16             @ r1<- BBBB0000
+// begin WITH_TAINT_TRACKING
+    mov     r2, r1, lsl #16             @ r1<- BBBB0000
+// end WITH_TAINT_TRACKING
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
-    add     r3, rFP, r3, lsl #2         @ r3<- &fp[AA]
+// begin WITH_TAINT_TRACKING
+    add     r9, rFP, r3, lsl #3         @ r3<- &fp[AA]
+// end WITH_TAINT_TRACKING
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    stmia   r3, {r0-r1}                 @ vAA<- r0/r1
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_CLEAR(r1)
+    SET_TAINT_CLEAR(r3)
+    stmia   r9, {r0-r3}                 @ vAA<- r0/r1
+// end WITH_TAINT_TRACKING
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_CONST_STRING: /* 0x1a */
-/* File: armv5te/OP_CONST_STRING.S */
+/* File: armv5te_taint/OP_CONST_STRING.S */
     /* const/string vAA, String@BBBB */
     FETCH(r1, 1)                        @ r1<- BBBB
     ldr     r2, [rSELF, #offThread_methodClassDex]  @ r2<- self->methodClassDex
@@ -769,6 +938,11 @@ dalvik_inst:
     ldr     r0, [r2, r1, lsl #2]        @ r0<- pResStrings[BBBB]
     cmp     r0, #0                      @ not yet resolved?
     beq     .LOP_CONST_STRING_resolve
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r2)
+    SET_TAINT_CLEAR(r3)
+    SET_VREG_TAINT(r3, r9, r2)
+// end WITH_TAINT_TRACKING
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
     SET_VREG(r0, r9)                    @ vAA<- r0
@@ -777,7 +951,7 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_CONST_STRING_JUMBO: /* 0x1b */
-/* File: armv5te/OP_CONST_STRING_JUMBO.S */
+/* File: armv5te_taint/OP_CONST_STRING_JUMBO.S */
     /* const/string vAA, String@BBBBBBBB */
     FETCH(r0, 1)                        @ r0<- bbbb (low)
     FETCH(r1, 2)                        @ r1<- BBBB (high)
@@ -788,6 +962,11 @@ dalvik_inst:
     ldr     r0, [r2, r1, lsl #2]        @ r0<- pResStrings[BBBB]
     cmp     r0, #0
     beq     .LOP_CONST_STRING_JUMBO_resolve
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r2)
+    SET_TAINT_CLEAR(r3)
+    SET_VREG_TAINT(r3, r9, r2)
+// end WITH_TAINT_TRACKING
     FETCH_ADVANCE_INST(3)               @ advance rPC, load rINST
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
     SET_VREG(r0, r9)                    @ vAA<- r0
@@ -796,7 +975,7 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_CONST_CLASS: /* 0x1c */
-/* File: armv5te/OP_CONST_CLASS.S */
+/* File: armv5te_taint/OP_CONST_CLASS.S */
     /* const/class vAA, Class@BBBB */
     FETCH(r1, 1)                        @ r1<- BBBB
     ldr     r2, [rSELF, #offThread_methodClassDex]  @ r2<- self->methodClassDex
@@ -805,6 +984,11 @@ dalvik_inst:
     ldr     r0, [r2, r1, lsl #2]        @ r0<- pResClasses[BBBB]
     cmp     r0, #0                      @ not yet resolved?
     beq     .LOP_CONST_CLASS_resolve
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r2)
+    SET_TAINT_CLEAR(r3)
+    SET_VREG_TAINT(r3, r9, r2)
+// end WITH_TAINT_TRACKING
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
     SET_VREG(r0, r9)                    @ vAA<- r0
@@ -813,7 +997,7 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_MONITOR_ENTER: /* 0x1d */
-/* File: armv5te/OP_MONITOR_ENTER.S */
+/* File: armv5te_taint/OP_MONITOR_ENTER.S */
     /*
      * Synchronize on an object.
      */
@@ -832,7 +1016,7 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_MONITOR_EXIT: /* 0x1e */
-/* File: armv5te/OP_MONITOR_EXIT.S */
+/* File: armv5te_taint/OP_MONITOR_EXIT.S */
     /*
      * Unlock an object.
      *
@@ -860,7 +1044,7 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_CHECK_CAST: /* 0x1f */
-/* File: armv5te/OP_CHECK_CAST.S */
+/* File: armv5te_taint/OP_CHECK_CAST.S */
     /*
      * Check to see if a cast from one class to another is allowed.
      */
@@ -887,7 +1071,7 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_INSTANCE_OF: /* 0x20 */
-/* File: armv5te/OP_INSTANCE_OF.S */
+/* File: armv5te_taint/OP_INSTANCE_OF.S */
     /*
      * Check to see if an object reference is an instance of a class.
      *
@@ -916,7 +1100,7 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_ARRAY_LENGTH: /* 0x21 */
-/* File: armv6t2/OP_ARRAY_LENGTH.S */
+/* File: armv6t2_taint/OP_ARRAY_LENGTH.S */
     /*
      * Return the length of an array.
      */
@@ -925,6 +1109,11 @@ dalvik_inst:
     GET_VREG(r0, r1)                    @ r0<- vB (object ref)
     cmp     r0, #0                      @ is object null?
     beq     common_errNullObject        @ yup, fail
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r1)
+    SET_TAINT_CLEAR(r3)
+    SET_VREG_TAINT(r3, r2, r1)
+// end WITH_TAINT_TRACKING
     FETCH_ADVANCE_INST(1)               @ advance rPC, load rINST
     ldr     r3, [r0, #offArrayObject_length]    @ r3<- array length
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
@@ -934,7 +1123,7 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_NEW_INSTANCE: /* 0x22 */
-/* File: armv5te/OP_NEW_INSTANCE.S */
+/* File: armv5te_taint/OP_NEW_INSTANCE.S */
     /*
      * Create a new instance of a class.
      */
@@ -961,7 +1150,7 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_NEW_ARRAY: /* 0x23 */
-/* File: armv5te/OP_NEW_ARRAY.S */
+/* File: armv5te_taint/OP_NEW_ARRAY.S */
     /*
      * Allocate an array of objects, specified with the array class
      * and a count.
@@ -986,7 +1175,7 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_FILLED_NEW_ARRAY: /* 0x24 */
-/* File: armv5te/OP_FILLED_NEW_ARRAY.S */
+/* File: armv5te_taint/OP_FILLED_NEW_ARRAY.S */
     /*
      * Create a new array with elements filled from registers.
      *
@@ -1013,8 +1202,8 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_FILLED_NEW_ARRAY_RANGE: /* 0x25 */
-/* File: armv5te/OP_FILLED_NEW_ARRAY_RANGE.S */
-/* File: armv5te/OP_FILLED_NEW_ARRAY.S */
+/* File: armv5te_taint/OP_FILLED_NEW_ARRAY_RANGE.S */
+/* File: armv5te_taint/OP_FILLED_NEW_ARRAY.S */
     /*
      * Create a new array with elements filled from registers.
      *
@@ -1042,7 +1231,7 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_FILL_ARRAY_DATA: /* 0x26 */
-/* File: armv5te/OP_FILL_ARRAY_DATA.S */
+/* File: armv5te_taint/OP_FILL_ARRAY_DATA.S */
     /* fill-array-data vAA, +BBBBBBBB */
     FETCH(r0, 1)                        @ r0<- bbbb (lo)
     FETCH(r1, 2)                        @ r1<- BBBB (hi)
@@ -1061,7 +1250,7 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_THROW: /* 0x27 */
-/* File: armv5te/OP_THROW.S */
+/* File: armv5te_taint/OP_THROW.S */
     /*
      * Throw an exception object in the current thread.
      */
@@ -1078,7 +1267,7 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_GOTO: /* 0x28 */
-/* File: armv5te/OP_GOTO.S */
+/* File: armv5te_taint/OP_GOTO.S */
     /*
      * Unconditional branch, 8-bit offset.
      *
@@ -1103,7 +1292,7 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_GOTO_16: /* 0x29 */
-/* File: armv5te/OP_GOTO_16.S */
+/* File: armv5te_taint/OP_GOTO_16.S */
     /*
      * Unconditional branch, 16-bit offset.
      *
@@ -1125,7 +1314,7 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_GOTO_32: /* 0x2a */
-/* File: armv5te/OP_GOTO_32.S */
+/* File: armv5te_taint/OP_GOTO_32.S */
     /*
      * Unconditional branch, 32-bit offset.
      *
@@ -1157,7 +1346,7 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_PACKED_SWITCH: /* 0x2b */
-/* File: armv5te/OP_PACKED_SWITCH.S */
+/* File: armv5te_taint/OP_PACKED_SWITCH.S */
     /*
      * Handle a packed-switch or sparse-switch instruction.  In both cases
      * we decode it and hand it off to a helper function.
@@ -1195,8 +1384,8 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_SPARSE_SWITCH: /* 0x2c */
-/* File: armv5te/OP_SPARSE_SWITCH.S */
-/* File: armv5te/OP_PACKED_SWITCH.S */
+/* File: armv5te_taint/OP_SPARSE_SWITCH.S */
+/* File: armv5te_taint/OP_PACKED_SWITCH.S */
     /*
      * Handle a packed-switch or sparse-switch instruction.  In both cases
      * we decode it and hand it off to a helper function.
@@ -1235,7 +1424,7 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_CMPL_FLOAT: /* 0x2d */
-/* File: arm-vfp/OP_CMPL_FLOAT.S */
+/* File: arm-vfp_taint/OP_CMPL_FLOAT.S */
     /*
      * Compare two floating-point values.  Puts 0, 1, or -1 into the
      * destination register based on the results of the comparison.
@@ -1274,7 +1463,7 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_CMPG_FLOAT: /* 0x2e */
-/* File: arm-vfp/OP_CMPG_FLOAT.S */
+/* File: arm-vfp_taint/OP_CMPG_FLOAT.S */
     /*
      * Compare two floating-point values.  Puts 0, 1, or -1 into the
      * destination register based on the results of the comparison.
@@ -1313,7 +1502,7 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_CMPL_DOUBLE: /* 0x2f */
-/* File: arm-vfp/OP_CMPL_DOUBLE.S */
+/* File: arm-vfp_taint/OP_CMPL_DOUBLE.S */
     /*
      * Compare two floating-point values.  Puts 0, 1, or -1 into the
      * destination register based on the results of the comparison.
@@ -1337,22 +1526,25 @@ dalvik_inst:
     mov     r3, r0, lsr #8              @ r3<- CC
     VREG_INDEX_TO_ADDR(r2, r2)          @ r2<- &vBB
     VREG_INDEX_TO_ADDR(r3, r3)          @ r3<- &vCC
-    fldd    d0, [r2]                    @ d0<- vBB
-    fldd    d1, [r3]                    @ d1<- vCC
+// begin WITH_TAINT_TRACKING
+//    fldd    d0, [r2]                    @ d0<- vBB
+    flds    s0, [r2]
+    flds    s1, [r2, #8]
+//    fldd    d1, [r3]                    @ d1<- vCC
+    flds    s2, [r3]
+    flds    s3, [r3, #8]
+// end WITH_TAINT_TRACKING
     fcmped  d0, d1                      @ compare (vBB, vCC)
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
     mvn     r0, #0                      @ r0<- -1 (default)
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    fmstat                              @ export status flags
-    movgt   r0, #1                      @ (greater than) r1<- 1
-    moveq   r0, #0                      @ (equal) r1<- 0
     b       .LOP_CMPL_DOUBLE_finish          @ argh
 
 
 /* ------------------------------ */
     .balign 64
 .L_OP_CMPG_DOUBLE: /* 0x30 */
-/* File: arm-vfp/OP_CMPG_DOUBLE.S */
+/* File: arm-vfp_taint/OP_CMPG_DOUBLE.S */
     /*
      * Compare two floating-point values.  Puts 0, 1, or -1 into the
      * destination register based on the results of the comparison.
@@ -1376,22 +1568,25 @@ dalvik_inst:
     mov     r3, r0, lsr #8              @ r3<- CC
     VREG_INDEX_TO_ADDR(r2, r2)          @ r2<- &vBB
     VREG_INDEX_TO_ADDR(r3, r3)          @ r3<- &vCC
-    fldd    d0, [r2]                    @ d0<- vBB
-    fldd    d1, [r3]                    @ d1<- vCC
+// begin WITH_TAINT_TRACKING
+//    fldd    d0, [r2]                    @ d0<- vBB
+    flds    s0, [r2]
+    flds    s1, [r2, #8]
+//    fldd    d1, [r3]                    @ d1<- vCC
+    flds    s2, [r3]
+    flds    s3, [r3, #8]
+// end WITH_TAINT_TRACKING
     fcmped  d0, d1                      @ compare (vBB, vCC)
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
     mov     r0, #1                      @ r0<- 1 (default)
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    fmstat                              @ export status flags
-    mvnmi   r0, #0                      @ (less than) r1<- -1
-    moveq   r0, #0                      @ (equal) r1<- 0
     b       .LOP_CMPG_DOUBLE_finish          @ argh
 
 
 /* ------------------------------ */
     .balign 64
 .L_OP_CMP_LONG: /* 0x31 */
-/* File: armv5te/OP_CMP_LONG.S */
+/* File: armv5te_taint/OP_CMP_LONG.S */
     /*
      * Compare two 64-bit values.  Puts 0, 1, or -1 into the destination
      * register based on the results of the comparison.
@@ -1417,10 +1612,9 @@ dalvik_inst:
     mov     r9, rINST, lsr #8           @ r9<- AA
     and     r2, r0, #255                @ r2<- BB
     mov     r3, r0, lsr #8              @ r3<- CC
-    add     r2, rFP, r2, lsl #2         @ r2<- &fp[BB]
-    add     r3, rFP, r3, lsl #2         @ r3<- &fp[CC]
-    ldmia   r2, {r0-r1}                 @ r0/r1<- vBB/vBB+1
-    ldmia   r3, {r2-r3}                 @ r2/r3<- vCC/vCC+1
+// begin WITH_TAINT_TRACKING
+    bl      cmp_long_taint_prop
+// end WITH_TAINT_TRACKING
     cmp     r1, r3                      @ compare (vBB+1, vCC+1)
     blt     .LOP_CMP_LONG_less            @ signed compare on high part
     bgt     .LOP_CMP_LONG_greater
@@ -1432,8 +1626,8 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_IF_EQ: /* 0x32 */
-/* File: armv6t2/OP_IF_EQ.S */
-/* File: armv6t2/bincmp.S */
+/* File: armv6t2_taint/OP_IF_EQ.S */
+/* File: armv6t2_taint/bincmp.S */
     /*
      * Generic two-operand compare-and-branch operation.  Provide a "revcmp"
      * fragment that specifies the *reverse* comparison to perform, e.g.
@@ -1466,8 +1660,8 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_IF_NE: /* 0x33 */
-/* File: armv6t2/OP_IF_NE.S */
-/* File: armv6t2/bincmp.S */
+/* File: armv6t2_taint/OP_IF_NE.S */
+/* File: armv6t2_taint/bincmp.S */
     /*
      * Generic two-operand compare-and-branch operation.  Provide a "revcmp"
      * fragment that specifies the *reverse* comparison to perform, e.g.
@@ -1500,8 +1694,8 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_IF_LT: /* 0x34 */
-/* File: armv6t2/OP_IF_LT.S */
-/* File: armv6t2/bincmp.S */
+/* File: armv6t2_taint/OP_IF_LT.S */
+/* File: armv6t2_taint/bincmp.S */
     /*
      * Generic two-operand compare-and-branch operation.  Provide a "revcmp"
      * fragment that specifies the *reverse* comparison to perform, e.g.
@@ -1534,8 +1728,8 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_IF_GE: /* 0x35 */
-/* File: armv6t2/OP_IF_GE.S */
-/* File: armv6t2/bincmp.S */
+/* File: armv6t2_taint/OP_IF_GE.S */
+/* File: armv6t2_taint/bincmp.S */
     /*
      * Generic two-operand compare-and-branch operation.  Provide a "revcmp"
      * fragment that specifies the *reverse* comparison to perform, e.g.
@@ -1568,8 +1762,8 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_IF_GT: /* 0x36 */
-/* File: armv6t2/OP_IF_GT.S */
-/* File: armv6t2/bincmp.S */
+/* File: armv6t2_taint/OP_IF_GT.S */
+/* File: armv6t2_taint/bincmp.S */
     /*
      * Generic two-operand compare-and-branch operation.  Provide a "revcmp"
      * fragment that specifies the *reverse* comparison to perform, e.g.
@@ -1602,8 +1796,8 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_IF_LE: /* 0x37 */
-/* File: armv6t2/OP_IF_LE.S */
-/* File: armv6t2/bincmp.S */
+/* File: armv6t2_taint/OP_IF_LE.S */
+/* File: armv6t2_taint/bincmp.S */
     /*
      * Generic two-operand compare-and-branch operation.  Provide a "revcmp"
      * fragment that specifies the *reverse* comparison to perform, e.g.
@@ -1636,8 +1830,8 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_IF_EQZ: /* 0x38 */
-/* File: armv5te/OP_IF_EQZ.S */
-/* File: armv5te/zcmp.S */
+/* File: armv5te_taint/OP_IF_EQZ.S */
+/* File: armv5te_taint/zcmp.S */
     /*
      * Generic one-operand compare-and-branch operation.  Provide a "revcmp"
      * fragment that specifies the *reverse* comparison to perform, e.g.
@@ -1668,8 +1862,8 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_IF_NEZ: /* 0x39 */
-/* File: armv5te/OP_IF_NEZ.S */
-/* File: armv5te/zcmp.S */
+/* File: armv5te_taint/OP_IF_NEZ.S */
+/* File: armv5te_taint/zcmp.S */
     /*
      * Generic one-operand compare-and-branch operation.  Provide a "revcmp"
      * fragment that specifies the *reverse* comparison to perform, e.g.
@@ -1700,8 +1894,8 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_IF_LTZ: /* 0x3a */
-/* File: armv5te/OP_IF_LTZ.S */
-/* File: armv5te/zcmp.S */
+/* File: armv5te_taint/OP_IF_LTZ.S */
+/* File: armv5te_taint/zcmp.S */
     /*
      * Generic one-operand compare-and-branch operation.  Provide a "revcmp"
      * fragment that specifies the *reverse* comparison to perform, e.g.
@@ -1732,8 +1926,8 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_IF_GEZ: /* 0x3b */
-/* File: armv5te/OP_IF_GEZ.S */
-/* File: armv5te/zcmp.S */
+/* File: armv5te_taint/OP_IF_GEZ.S */
+/* File: armv5te_taint/zcmp.S */
     /*
      * Generic one-operand compare-and-branch operation.  Provide a "revcmp"
      * fragment that specifies the *reverse* comparison to perform, e.g.
@@ -1764,8 +1958,8 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_IF_GTZ: /* 0x3c */
-/* File: armv5te/OP_IF_GTZ.S */
-/* File: armv5te/zcmp.S */
+/* File: armv5te_taint/OP_IF_GTZ.S */
+/* File: armv5te_taint/zcmp.S */
     /*
      * Generic one-operand compare-and-branch operation.  Provide a "revcmp"
      * fragment that specifies the *reverse* comparison to perform, e.g.
@@ -1796,8 +1990,8 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_IF_LEZ: /* 0x3d */
-/* File: armv5te/OP_IF_LEZ.S */
-/* File: armv5te/zcmp.S */
+/* File: armv5te_taint/OP_IF_LEZ.S */
+/* File: armv5te_taint/zcmp.S */
     /*
      * Generic one-operand compare-and-branch operation.  Provide a "revcmp"
      * fragment that specifies the *reverse* comparison to perform, e.g.
@@ -1828,55 +2022,61 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_UNUSED_3E: /* 0x3e */
-/* File: armv5te/OP_UNUSED_3E.S */
-/* File: armv5te/unused.S */
+/* File: armv5te_taint/OP_UNUSED_3E.S */
+/* File: armv5te_taint/unused.S */
     bl      common_abort
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_UNUSED_3F: /* 0x3f */
-/* File: armv5te/OP_UNUSED_3F.S */
-/* File: armv5te/unused.S */
+/* File: armv5te_taint/OP_UNUSED_3F.S */
+/* File: armv5te_taint/unused.S */
     bl      common_abort
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_UNUSED_40: /* 0x40 */
-/* File: armv5te/OP_UNUSED_40.S */
-/* File: armv5te/unused.S */
+/* File: armv5te_taint/OP_UNUSED_40.S */
+/* File: armv5te_taint/unused.S */
     bl      common_abort
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_UNUSED_41: /* 0x41 */
-/* File: armv5te/OP_UNUSED_41.S */
-/* File: armv5te/unused.S */
+/* File: armv5te_taint/OP_UNUSED_41.S */
+/* File: armv5te_taint/unused.S */
     bl      common_abort
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_UNUSED_42: /* 0x42 */
-/* File: armv5te/OP_UNUSED_42.S */
-/* File: armv5te/unused.S */
+/* File: armv5te_taint/OP_UNUSED_42.S */
+/* File: armv5te_taint/unused.S */
     bl      common_abort
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_UNUSED_43: /* 0x43 */
-/* File: armv5te/OP_UNUSED_43.S */
-/* File: armv5te/unused.S */
+/* File: armv5te_taint/OP_UNUSED_43.S */
+/* File: armv5te_taint/unused.S */
     bl      common_abort
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_AGET: /* 0x44 */
-/* File: armv5te/OP_AGET.S */
+/* File: armv5te_taint/OP_AGET.S */
     /*
      * Array get, 32 bits or less.  vAA <- vBB[vCC].
      *
@@ -1893,20 +2093,27 @@ dalvik_inst:
     GET_VREG(r1, r3)                    @ r1<- vCC (requested index)
     cmp     r0, #0                      @ null array object?
     beq     common_errNullObject        @ yes, bail
+// begin WITH_TAINT_TRACKING
+    bl		.LOP_AGET_taint_prop_1
+// end WITH_TAINT_TRACKING
     ldr     r3, [r0, #offArrayObject_length]    @ r3<- arrayObj->length
     add     r0, r0, r1, lsl #2     @ r0<- arrayObj + index*width
     cmp     r1, r3                      @ compare unsigned index, length
-    bcs     common_errArrayIndex        @ index >= length, bail
-    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
+// begin WITH_TAINT_TRACKING
+//    bcs     common_errArrayIndex        @ index >= length, bail	// in subroutine
+//    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST // in subroutine
+    bl		.LOP_AGET_taint_prop_2
+// end WITH_TAINT_TRACKING
     ldr   r2, [r0, #offArrayObject_contents]  @ r2<- vBB[vCC]
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
     SET_VREG(r2, r9)                    @ vAA<- r2
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_AGET_WIDE: /* 0x45 */
-/* File: armv5te/OP_AGET_WIDE.S */
+/* File: armv5te_taint/OP_AGET_WIDE.S */
     /*
      * Array get, 64 bits.  vAA <- vBB[vCC].
      *
@@ -1921,6 +2128,9 @@ dalvik_inst:
     GET_VREG(r1, r3)                    @ r1<- vCC (requested index)
     cmp     r0, #0                      @ null array object?
     beq     common_errNullObject        @ yes, bail
+// begin WITH_TAINT_TRACKING
+    bl      .LOP_AGET_WIDE_taint_prop      @ r10<- taint
+// end WITH_TAINT_TRACKING
     ldr     r3, [r0, #offArrayObject_length]    @ r3<- arrayObj->length
     add     r0, r0, r1, lsl #3          @ r0<- arrayObj + index*width
     cmp     r1, r3                      @ compare unsigned index, length
@@ -1933,8 +2143,8 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_AGET_OBJECT: /* 0x46 */
-/* File: armv5te/OP_AGET_OBJECT.S */
-/* File: armv5te/OP_AGET.S */
+/* File: armv5te_taint/OP_AGET_OBJECT.S */
+/* File: armv5te_taint/OP_AGET.S */
     /*
      * Array get, 32 bits or less.  vAA <- vBB[vCC].
      *
@@ -1951,22 +2161,29 @@ dalvik_inst:
     GET_VREG(r1, r3)                    @ r1<- vCC (requested index)
     cmp     r0, #0                      @ null array object?
     beq     common_errNullObject        @ yes, bail
+// begin WITH_TAINT_TRACKING
+    bl		.LOP_AGET_OBJECT_taint_prop_1
+// end WITH_TAINT_TRACKING
     ldr     r3, [r0, #offArrayObject_length]    @ r3<- arrayObj->length
     add     r0, r0, r1, lsl #2     @ r0<- arrayObj + index*width
     cmp     r1, r3                      @ compare unsigned index, length
-    bcs     common_errArrayIndex        @ index >= length, bail
-    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
+// begin WITH_TAINT_TRACKING
+//    bcs     common_errArrayIndex        @ index >= length, bail	// in subroutine
+//    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST // in subroutine
+    bl		.LOP_AGET_OBJECT_taint_prop_2
+// end WITH_TAINT_TRACKING
     ldr   r2, [r0, #offArrayObject_contents]  @ r2<- vBB[vCC]
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
     SET_VREG(r2, r9)                    @ vAA<- r2
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_AGET_BOOLEAN: /* 0x47 */
-/* File: armv5te/OP_AGET_BOOLEAN.S */
-/* File: armv5te/OP_AGET.S */
+/* File: armv5te_taint/OP_AGET_BOOLEAN.S */
+/* File: armv5te_taint/OP_AGET.S */
     /*
      * Array get, 32 bits or less.  vAA <- vBB[vCC].
      *
@@ -1983,22 +2200,29 @@ dalvik_inst:
     GET_VREG(r1, r3)                    @ r1<- vCC (requested index)
     cmp     r0, #0                      @ null array object?
     beq     common_errNullObject        @ yes, bail
+// begin WITH_TAINT_TRACKING
+    bl		.LOP_AGET_BOOLEAN_taint_prop_1
+// end WITH_TAINT_TRACKING
     ldr     r3, [r0, #offArrayObject_length]    @ r3<- arrayObj->length
     add     r0, r0, r1, lsl #0     @ r0<- arrayObj + index*width
     cmp     r1, r3                      @ compare unsigned index, length
-    bcs     common_errArrayIndex        @ index >= length, bail
-    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
+// begin WITH_TAINT_TRACKING
+//    bcs     common_errArrayIndex        @ index >= length, bail	// in subroutine
+//    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST // in subroutine
+    bl		.LOP_AGET_BOOLEAN_taint_prop_2
+// end WITH_TAINT_TRACKING
     ldrb   r2, [r0, #offArrayObject_contents]  @ r2<- vBB[vCC]
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
     SET_VREG(r2, r9)                    @ vAA<- r2
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_AGET_BYTE: /* 0x48 */
-/* File: armv5te/OP_AGET_BYTE.S */
-/* File: armv5te/OP_AGET.S */
+/* File: armv5te_taint/OP_AGET_BYTE.S */
+/* File: armv5te_taint/OP_AGET.S */
     /*
      * Array get, 32 bits or less.  vAA <- vBB[vCC].
      *
@@ -2015,22 +2239,29 @@ dalvik_inst:
     GET_VREG(r1, r3)                    @ r1<- vCC (requested index)
     cmp     r0, #0                      @ null array object?
     beq     common_errNullObject        @ yes, bail
+// begin WITH_TAINT_TRACKING
+    bl		.LOP_AGET_BYTE_taint_prop_1
+// end WITH_TAINT_TRACKING
     ldr     r3, [r0, #offArrayObject_length]    @ r3<- arrayObj->length
     add     r0, r0, r1, lsl #0     @ r0<- arrayObj + index*width
     cmp     r1, r3                      @ compare unsigned index, length
-    bcs     common_errArrayIndex        @ index >= length, bail
-    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
+// begin WITH_TAINT_TRACKING
+//    bcs     common_errArrayIndex        @ index >= length, bail	// in subroutine
+//    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST // in subroutine
+    bl		.LOP_AGET_BYTE_taint_prop_2
+// end WITH_TAINT_TRACKING
     ldrsb   r2, [r0, #offArrayObject_contents]  @ r2<- vBB[vCC]
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
     SET_VREG(r2, r9)                    @ vAA<- r2
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_AGET_CHAR: /* 0x49 */
-/* File: armv5te/OP_AGET_CHAR.S */
-/* File: armv5te/OP_AGET.S */
+/* File: armv5te_taint/OP_AGET_CHAR.S */
+/* File: armv5te_taint/OP_AGET.S */
     /*
      * Array get, 32 bits or less.  vAA <- vBB[vCC].
      *
@@ -2047,22 +2278,29 @@ dalvik_inst:
     GET_VREG(r1, r3)                    @ r1<- vCC (requested index)
     cmp     r0, #0                      @ null array object?
     beq     common_errNullObject        @ yes, bail
+// begin WITH_TAINT_TRACKING
+    bl		.LOP_AGET_CHAR_taint_prop_1
+// end WITH_TAINT_TRACKING
     ldr     r3, [r0, #offArrayObject_length]    @ r3<- arrayObj->length
     add     r0, r0, r1, lsl #1     @ r0<- arrayObj + index*width
     cmp     r1, r3                      @ compare unsigned index, length
-    bcs     common_errArrayIndex        @ index >= length, bail
-    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
+// begin WITH_TAINT_TRACKING
+//    bcs     common_errArrayIndex        @ index >= length, bail	// in subroutine
+//    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST // in subroutine
+    bl		.LOP_AGET_CHAR_taint_prop_2
+// end WITH_TAINT_TRACKING
     ldrh   r2, [r0, #offArrayObject_contents]  @ r2<- vBB[vCC]
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
     SET_VREG(r2, r9)                    @ vAA<- r2
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_AGET_SHORT: /* 0x4a */
-/* File: armv5te/OP_AGET_SHORT.S */
-/* File: armv5te/OP_AGET.S */
+/* File: armv5te_taint/OP_AGET_SHORT.S */
+/* File: armv5te_taint/OP_AGET.S */
     /*
      * Array get, 32 bits or less.  vAA <- vBB[vCC].
      *
@@ -2079,21 +2317,28 @@ dalvik_inst:
     GET_VREG(r1, r3)                    @ r1<- vCC (requested index)
     cmp     r0, #0                      @ null array object?
     beq     common_errNullObject        @ yes, bail
+// begin WITH_TAINT_TRACKING
+    bl		.LOP_AGET_SHORT_taint_prop_1
+// end WITH_TAINT_TRACKING
     ldr     r3, [r0, #offArrayObject_length]    @ r3<- arrayObj->length
     add     r0, r0, r1, lsl #1     @ r0<- arrayObj + index*width
     cmp     r1, r3                      @ compare unsigned index, length
-    bcs     common_errArrayIndex        @ index >= length, bail
-    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
+// begin WITH_TAINT_TRACKING
+//    bcs     common_errArrayIndex        @ index >= length, bail	// in subroutine
+//    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST // in subroutine
+    bl		.LOP_AGET_SHORT_taint_prop_2
+// end WITH_TAINT_TRACKING
     ldrsh   r2, [r0, #offArrayObject_contents]  @ r2<- vBB[vCC]
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
     SET_VREG(r2, r9)                    @ vAA<- r2
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_APUT: /* 0x4b */
-/* File: armv5te/OP_APUT.S */
+/* File: armv5te_taint/OP_APUT.S */
     /*
      * Array put, 32 bits or less.  vBB[vCC] <- vAA.
      *
@@ -2114,16 +2359,19 @@ dalvik_inst:
     add     r0, r0, r1, lsl #2     @ r0<- arrayObj + index*width
     cmp     r1, r3                      @ compare unsigned index, length
     bcs     common_errArrayIndex        @ index >= length, bail
-    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
+// begin WITH_TAINT_TRACKING
+    bl	.LOP_APUT_taint_prop
+// end WITH_TAINT_TRACKING
     GET_VREG(r2, r9)                    @ r2<- vAA
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
     str  r2, [r0, #offArrayObject_contents]  @ vBB[vCC]<- r2
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_APUT_WIDE: /* 0x4c */
-/* File: armv5te/OP_APUT_WIDE.S */
+/* File: armv5te_taint/OP_APUT_WIDE.S */
     /*
      * Array put, 64 bits.  vBB[vCC] <- vAA.
      *
@@ -2139,9 +2387,14 @@ dalvik_inst:
     cmp     r0, #0                      @ null array object?
     beq     common_errNullObject        @ yes, bail
     ldr     r3, [r0, #offArrayObject_length]    @ r3<- arrayObj->length
+// begin WITH_TAINT_TRACKING
+    mov     r10, r0
+// end WITH_TAINT_TRACKING
     add     r0, r0, r1, lsl #3          @ r0<- arrayObj + index*width
     cmp     r1, r3                      @ compare unsigned index, length
-    add     r9, rFP, r9, lsl #2         @ r9<- &fp[AA]
+// begin WITH_TAINT_TRACKING
+    add     r9, rFP, r9, lsl #3         @ r9<- &fp[AA]
+// end WITH_TAINT_TRACKING
     bcc     .LOP_APUT_WIDE_finish          @ okay, continue below
     b       common_errArrayIndex        @ index >= length, bail
     @ May want to swap the order of these two branches depending on how the
@@ -2151,7 +2404,7 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_APUT_OBJECT: /* 0x4d */
-/* File: armv5te/OP_APUT_OBJECT.S */
+/* File: armv5te_taint/OP_APUT_OBJECT.S */
     /*
      * Store an object into an array.  vBB[vCC] <- vAA.
      */
@@ -2162,9 +2415,15 @@ dalvik_inst:
     mov     r3, r0, lsr #8              @ r3<- CC
     GET_VREG(rINST, r2)                 @ rINST<- vBB (array object)
     GET_VREG(r1, r3)                    @ r1<- vCC (requested index)
+// begin WITH_TAINT_TRACKING
+    bl      .LOP_APUT_OBJECT_taint_prop_1
+// end WITH_TAINT_TRACKING
     cmp     rINST, #0                   @ null array object?
     GET_VREG(r9, r9)                    @ r9<- vAA
     beq     common_errNullObject        @ yes, bail
+// begin WITH_TAINT_TRACKING
+    bl      .LOP_APUT_OBJECT_taint_prop_2
+// end WITH_TAINT_TRACKING
     ldr     r3, [rINST, #offArrayObject_length]   @ r3<- arrayObj->length
     add     r10, rINST, r1, lsl #2      @ r10<- arrayObj + index*width
     cmp     r1, r3                      @ compare unsigned index, length
@@ -2175,8 +2434,8 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_APUT_BOOLEAN: /* 0x4e */
-/* File: armv5te/OP_APUT_BOOLEAN.S */
-/* File: armv5te/OP_APUT.S */
+/* File: armv5te_taint/OP_APUT_BOOLEAN.S */
+/* File: armv5te_taint/OP_APUT.S */
     /*
      * Array put, 32 bits or less.  vBB[vCC] <- vAA.
      *
@@ -2197,18 +2456,21 @@ dalvik_inst:
     add     r0, r0, r1, lsl #0     @ r0<- arrayObj + index*width
     cmp     r1, r3                      @ compare unsigned index, length
     bcs     common_errArrayIndex        @ index >= length, bail
-    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
+// begin WITH_TAINT_TRACKING
+    bl	.LOP_APUT_BOOLEAN_taint_prop
+// end WITH_TAINT_TRACKING
     GET_VREG(r2, r9)                    @ r2<- vAA
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
     strb  r2, [r0, #offArrayObject_contents]  @ vBB[vCC]<- r2
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_APUT_BYTE: /* 0x4f */
-/* File: armv5te/OP_APUT_BYTE.S */
-/* File: armv5te/OP_APUT.S */
+/* File: armv5te_taint/OP_APUT_BYTE.S */
+/* File: armv5te_taint/OP_APUT.S */
     /*
      * Array put, 32 bits or less.  vBB[vCC] <- vAA.
      *
@@ -2229,18 +2491,21 @@ dalvik_inst:
     add     r0, r0, r1, lsl #0     @ r0<- arrayObj + index*width
     cmp     r1, r3                      @ compare unsigned index, length
     bcs     common_errArrayIndex        @ index >= length, bail
-    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
+// begin WITH_TAINT_TRACKING
+    bl	.LOP_APUT_BYTE_taint_prop
+// end WITH_TAINT_TRACKING
     GET_VREG(r2, r9)                    @ r2<- vAA
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
     strb  r2, [r0, #offArrayObject_contents]  @ vBB[vCC]<- r2
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_APUT_CHAR: /* 0x50 */
-/* File: armv5te/OP_APUT_CHAR.S */
-/* File: armv5te/OP_APUT.S */
+/* File: armv5te_taint/OP_APUT_CHAR.S */
+/* File: armv5te_taint/OP_APUT.S */
     /*
      * Array put, 32 bits or less.  vBB[vCC] <- vAA.
      *
@@ -2261,18 +2526,21 @@ dalvik_inst:
     add     r0, r0, r1, lsl #1     @ r0<- arrayObj + index*width
     cmp     r1, r3                      @ compare unsigned index, length
     bcs     common_errArrayIndex        @ index >= length, bail
-    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
+// begin WITH_TAINT_TRACKING
+    bl	.LOP_APUT_CHAR_taint_prop
+// end WITH_TAINT_TRACKING
     GET_VREG(r2, r9)                    @ r2<- vAA
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
     strh  r2, [r0, #offArrayObject_contents]  @ vBB[vCC]<- r2
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_APUT_SHORT: /* 0x51 */
-/* File: armv5te/OP_APUT_SHORT.S */
-/* File: armv5te/OP_APUT.S */
+/* File: armv5te_taint/OP_APUT_SHORT.S */
+/* File: armv5te_taint/OP_APUT.S */
     /*
      * Array put, 32 bits or less.  vBB[vCC] <- vAA.
      *
@@ -2293,17 +2561,20 @@ dalvik_inst:
     add     r0, r0, r1, lsl #1     @ r0<- arrayObj + index*width
     cmp     r1, r3                      @ compare unsigned index, length
     bcs     common_errArrayIndex        @ index >= length, bail
-    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
+// begin WITH_TAINT_TRACKING
+    bl	.LOP_APUT_SHORT_taint_prop
+// end WITH_TAINT_TRACKING
     GET_VREG(r2, r9)                    @ r2<- vAA
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
     strh  r2, [r0, #offArrayObject_contents]  @ vBB[vCC]<- r2
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_IGET: /* 0x52 */
-/* File: armv6t2/OP_IGET.S */
+/* File: armv6t2_taint/OP_IGET.S */
     /*
      * General 32-bit instance field get.
      *
@@ -2314,8 +2585,9 @@ dalvik_inst:
     ldr     r3, [rSELF, #offThread_methodClassDex]    @ r3<- DvmDex
     FETCH(r1, 1)                        @ r1<- field ref CCCC
     ldr     r2, [r3, #offDvmDex_pResFields] @ r2<- pDvmDex->pResFields
-    GET_VREG(r9, r0)                    @ r9<- fp[B], the object pointer
-    ldr     r0, [r2, r1, lsl #2]        @ r0<- resolved InstField ptr
+// begin WITH_TAINT_TRACKING
+    bl      .LOP_IGET_taint_prop
+// end WITH_TAINT_TRACKING
     cmp     r0, #0                      @ is resolved entry null?
     bne     .LOP_IGET_finish          @ no, already resolved
 8:  ldr     r2, [rSELF, #offThread_method]    @ r2<- current method
@@ -2329,7 +2601,7 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_IGET_WIDE: /* 0x53 */
-/* File: armv6t2/OP_IGET_WIDE.S */
+/* File: armv6t2_taint/OP_IGET_WIDE.S */
     /*
      * Wide 32-bit instance field get.
      */
@@ -2338,8 +2610,9 @@ dalvik_inst:
     ldr     r3, [rSELF, #offThread_methodClassDex]    @ r3<- DvmDex
     FETCH(r1, 1)                        @ r1<- field ref CCCC
     ldr     r2, [r3, #offDvmDex_pResFields] @ r2<- pResFields
-    GET_VREG(r9, r0)                    @ r9<- fp[B], the object pointer
-    ldr     r0, [r2, r1, lsl #2]        @ r0<- resolved InstField ptr
+// begin WITH_TAINT_TRACKING
+    bl      .LOP_IGET_WIDE_taint_prop
+// end WITH_TAINT_TRACKING
     cmp     r0, #0                      @ is resolved entry null?
     bne     .LOP_IGET_WIDE_finish          @ no, already resolved
 8:  ldr     r2, [rSELF, #offThread_method] @ r2<- current method
@@ -2353,8 +2626,10 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_IGET_OBJECT: /* 0x54 */
-/* File: armv5te/OP_IGET_OBJECT.S */
-/* File: armv5te/OP_IGET.S */
+/* File: armv5te_taint/OP_IGET_OBJECT.S */
+/* File: armv5te_taint/OP_IGET.S */
+// begin WITH_TAINT_TRACKING
+// end WITH_TAINT_TRACKING
     /*
      * General 32-bit instance field get.
      *
@@ -2365,8 +2640,9 @@ dalvik_inst:
     ldr     r3, [rSELF, #offThread_methodClassDex]    @ r3<- DvmDex
     FETCH(r1, 1)                        @ r1<- field ref CCCC
     ldr     r2, [r3, #offDvmDex_pResFields] @ r2<- pDvmDex->pResFields
-    GET_VREG(r9, r0)                    @ r9<- fp[B], the object pointer
-    ldr     r0, [r2, r1, lsl #2]        @ r0<- resolved InstField ptr
+// begin WITH_TAINT_TRACKING
+    bl      .LOP_IGET_OBJECT_taint_prop
+// end WITH_TAINT_TRACKING
     cmp     r0, #0                      @ is resolved entry null?
     bne     .LOP_IGET_OBJECT_finish          @ no, already resolved
 8:  ldr     r2, [rSELF, #offThread_method]    @ r2<- current method
@@ -2381,9 +2657,11 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_IGET_BOOLEAN: /* 0x55 */
-/* File: armv5te/OP_IGET_BOOLEAN.S */
-@include "armv5te/OP_IGET.S" { "load":"ldrb", "sqnum":"1" }
-/* File: armv5te/OP_IGET.S */
+/* File: armv5te_taint/OP_IGET_BOOLEAN.S */
+@include "armv5te_taint/OP_IGET.S" { "load":"ldrb", "sqnum":"1" }
+/* File: armv5te_taint/OP_IGET.S */
+// begin WITH_TAINT_TRACKING
+// end WITH_TAINT_TRACKING
     /*
      * General 32-bit instance field get.
      *
@@ -2394,8 +2672,9 @@ dalvik_inst:
     ldr     r3, [rSELF, #offThread_methodClassDex]    @ r3<- DvmDex
     FETCH(r1, 1)                        @ r1<- field ref CCCC
     ldr     r2, [r3, #offDvmDex_pResFields] @ r2<- pDvmDex->pResFields
-    GET_VREG(r9, r0)                    @ r9<- fp[B], the object pointer
-    ldr     r0, [r2, r1, lsl #2]        @ r0<- resolved InstField ptr
+// begin WITH_TAINT_TRACKING
+    bl      .LOP_IGET_BOOLEAN_taint_prop
+// end WITH_TAINT_TRACKING
     cmp     r0, #0                      @ is resolved entry null?
     bne     .LOP_IGET_BOOLEAN_finish          @ no, already resolved
 8:  ldr     r2, [rSELF, #offThread_method]    @ r2<- current method
@@ -2410,9 +2689,11 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_IGET_BYTE: /* 0x56 */
-/* File: armv5te/OP_IGET_BYTE.S */
-@include "armv5te/OP_IGET.S" { "load":"ldrsb", "sqnum":"2" }
-/* File: armv5te/OP_IGET.S */
+/* File: armv5te_taint/OP_IGET_BYTE.S */
+@include "armv5te_taint/OP_IGET.S" { "load":"ldrsb", "sqnum":"2" }
+/* File: armv5te_taint/OP_IGET.S */
+// begin WITH_TAINT_TRACKING
+// end WITH_TAINT_TRACKING
     /*
      * General 32-bit instance field get.
      *
@@ -2423,8 +2704,9 @@ dalvik_inst:
     ldr     r3, [rSELF, #offThread_methodClassDex]    @ r3<- DvmDex
     FETCH(r1, 1)                        @ r1<- field ref CCCC
     ldr     r2, [r3, #offDvmDex_pResFields] @ r2<- pDvmDex->pResFields
-    GET_VREG(r9, r0)                    @ r9<- fp[B], the object pointer
-    ldr     r0, [r2, r1, lsl #2]        @ r0<- resolved InstField ptr
+// begin WITH_TAINT_TRACKING
+    bl      .LOP_IGET_BYTE_taint_prop
+// end WITH_TAINT_TRACKING
     cmp     r0, #0                      @ is resolved entry null?
     bne     .LOP_IGET_BYTE_finish          @ no, already resolved
 8:  ldr     r2, [rSELF, #offThread_method]    @ r2<- current method
@@ -2439,9 +2721,11 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_IGET_CHAR: /* 0x57 */
-/* File: armv5te/OP_IGET_CHAR.S */
-@include "armv5te/OP_IGET.S" { "load":"ldrh", "sqnum":"3" }
-/* File: armv5te/OP_IGET.S */
+/* File: armv5te_taint/OP_IGET_CHAR.S */
+@include "armv5te_taint/OP_IGET.S" { "load":"ldrh", "sqnum":"3" }
+/* File: armv5te_taint/OP_IGET.S */
+// begin WITH_TAINT_TRACKING
+// end WITH_TAINT_TRACKING
     /*
      * General 32-bit instance field get.
      *
@@ -2452,8 +2736,9 @@ dalvik_inst:
     ldr     r3, [rSELF, #offThread_methodClassDex]    @ r3<- DvmDex
     FETCH(r1, 1)                        @ r1<- field ref CCCC
     ldr     r2, [r3, #offDvmDex_pResFields] @ r2<- pDvmDex->pResFields
-    GET_VREG(r9, r0)                    @ r9<- fp[B], the object pointer
-    ldr     r0, [r2, r1, lsl #2]        @ r0<- resolved InstField ptr
+// begin WITH_TAINT_TRACKING
+    bl      .LOP_IGET_CHAR_taint_prop
+// end WITH_TAINT_TRACKING
     cmp     r0, #0                      @ is resolved entry null?
     bne     .LOP_IGET_CHAR_finish          @ no, already resolved
 8:  ldr     r2, [rSELF, #offThread_method]    @ r2<- current method
@@ -2465,12 +2750,15 @@ dalvik_inst:
     b       common_exceptionThrown
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_IGET_SHORT: /* 0x58 */
-/* File: armv5te/OP_IGET_SHORT.S */
-@include "armv5te/OP_IGET.S" { "load":"ldrsh", "sqnum":"4" }
-/* File: armv5te/OP_IGET.S */
+/* File: armv5te_taint/OP_IGET_SHORT.S */
+@include "armv5te_taint/OP_IGET.S" { "load":"ldrsh", "sqnum":"4" }
+/* File: armv5te_taint/OP_IGET.S */
+// begin WITH_TAINT_TRACKING
+// end WITH_TAINT_TRACKING
     /*
      * General 32-bit instance field get.
      *
@@ -2481,8 +2769,9 @@ dalvik_inst:
     ldr     r3, [rSELF, #offThread_methodClassDex]    @ r3<- DvmDex
     FETCH(r1, 1)                        @ r1<- field ref CCCC
     ldr     r2, [r3, #offDvmDex_pResFields] @ r2<- pDvmDex->pResFields
-    GET_VREG(r9, r0)                    @ r9<- fp[B], the object pointer
-    ldr     r0, [r2, r1, lsl #2]        @ r0<- resolved InstField ptr
+// begin WITH_TAINT_TRACKING
+    bl      .LOP_IGET_SHORT_taint_prop
+// end WITH_TAINT_TRACKING
     cmp     r0, #0                      @ is resolved entry null?
     bne     .LOP_IGET_SHORT_finish          @ no, already resolved
 8:  ldr     r2, [rSELF, #offThread_method]    @ r2<- current method
@@ -2497,7 +2786,7 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_IPUT: /* 0x59 */
-/* File: armv6t2/OP_IPUT.S */
+/* File: armv6t2_taint/OP_IPUT.S */
     /*
      * General 32-bit instance field put.
      *
@@ -2523,7 +2812,7 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_IPUT_WIDE: /* 0x5a */
-/* File: armv6t2/OP_IPUT_WIDE.S */
+/* File: armv6t2_taint/OP_IPUT_WIDE.S */
     /* iput-wide vA, vB, field@CCCC */
     mov     r0, rINST, lsr #12          @ r0<- B
     ldr     r3, [rSELF, #offThread_methodClassDex]    @ r3<- DvmDex
@@ -2544,7 +2833,9 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_IPUT_OBJECT: /* 0x5b */
-/* File: armv5te/OP_IPUT_OBJECT.S */
+/* File: armv5te_taint/OP_IPUT_OBJECT.S */
+// begin WITH_TAINT_TRACKING
+// end WITH_TAINT_TRACKING
     /*
      * 32-bit instance field put.
      *
@@ -2570,9 +2861,11 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_IPUT_BOOLEAN: /* 0x5c */
-/* File: armv5te/OP_IPUT_BOOLEAN.S */
-@include "armv5te/OP_IPUT.S" { "store":"strb", "sqnum":"1" }
-/* File: armv5te/OP_IPUT.S */
+/* File: armv5te_taint/OP_IPUT_BOOLEAN.S */
+@include "armv5te_taint/OP_IPUT.S" { "store":"strb", "sqnum":"1" }
+/* File: armv5te_taint/OP_IPUT.S */
+// begin WITH_TAINT_TRACKING
+// end WITH_TAINT_TRACKING
     /*
      * General 32-bit instance field put.
      *
@@ -2599,9 +2892,11 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_IPUT_BYTE: /* 0x5d */
-/* File: armv5te/OP_IPUT_BYTE.S */
-@include "armv5te/OP_IPUT.S" { "store":"strb", "sqnum":"2" }
-/* File: armv5te/OP_IPUT.S */
+/* File: armv5te_taint/OP_IPUT_BYTE.S */
+@include "armv5te_taint/OP_IPUT.S" { "store":"strb", "sqnum":"2" }
+/* File: armv5te_taint/OP_IPUT.S */
+// begin WITH_TAINT_TRACKING
+// end WITH_TAINT_TRACKING
     /*
      * General 32-bit instance field put.
      *
@@ -2628,9 +2923,11 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_IPUT_CHAR: /* 0x5e */
-/* File: armv5te/OP_IPUT_CHAR.S */
-@include "armv5te/OP_IPUT.S" { "store":"strh", "sqnum":"3" }
-/* File: armv5te/OP_IPUT.S */
+/* File: armv5te_taint/OP_IPUT_CHAR.S */
+@include "armv5te_taint/OP_IPUT.S" { "store":"strh", "sqnum":"3" }
+/* File: armv5te_taint/OP_IPUT.S */
+// begin WITH_TAINT_TRACKING
+// end WITH_TAINT_TRACKING
     /*
      * General 32-bit instance field put.
      *
@@ -2657,9 +2954,11 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_IPUT_SHORT: /* 0x5f */
-/* File: armv5te/OP_IPUT_SHORT.S */
-@include "armv5te/OP_IPUT.S" { "store":"strh", "sqnum":"4" }
-/* File: armv5te/OP_IPUT.S */
+/* File: armv5te_taint/OP_IPUT_SHORT.S */
+@include "armv5te_taint/OP_IPUT.S" { "store":"strh", "sqnum":"4" }
+/* File: armv5te_taint/OP_IPUT.S */
+// begin WITH_TAINT_TRACKING
+// end WITH_TAINT_TRACKING
     /*
      * General 32-bit instance field put.
      *
@@ -2686,7 +2985,9 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_SGET: /* 0x60 */
-/* File: armv5te/OP_SGET.S */
+/* File: armv5te_taint/OP_SGET.S */
+// begin WITH_TAINT_TRACKING
+// end WITH_TAINT_TRACKING
     /*
      * General 32-bit SGET handler.
      *
@@ -2700,18 +3001,18 @@ dalvik_inst:
     cmp     r0, #0                      @ is resolved entry null?
     beq     .LOP_SGET_resolve         @ yes, do resolve
 .LOP_SGET_finish: @ field ptr in r0
-    ldr     r1, [r0, #offStaticField_value] @ r1<- field value
-    @ no-op                             @ acquiring load
-    mov     r2, rINST, lsr #8           @ r2<- AA
+// begin WITH_TAINT_TRACKING
+    bl		.LOP_SGET_taint_prop
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
-    SET_VREG(r1, r2)                    @ fp[AA]<- r1
+    SET_VREG(r0, r2)                    @ fp[AA]<- r0
+// end WITH_TAINT_TRACKING
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
 /* ------------------------------ */
     .balign 64
 .L_OP_SGET_WIDE: /* 0x61 */
-/* File: armv5te/OP_SGET_WIDE.S */
+/* File: armv5te_taint/OP_SGET_WIDE.S */
     /*
      * 64-bit SGET handler.
      */
@@ -2722,25 +3023,16 @@ dalvik_inst:
     ldr     r0, [r10, r1, lsl #2]       @ r0<- resolved StaticField ptr
     cmp     r0, #0                      @ is resolved entry null?
     beq     .LOP_SGET_WIDE_resolve         @ yes, do resolve
-.LOP_SGET_WIDE_finish:
-    mov     r9, rINST, lsr #8           @ r9<- AA
-    .if 0
-    add     r0, r0, #offStaticField_value @ r0<- pointer to data
-    bl      dvmQuasiAtomicRead64        @ r0/r1<- contents of field
-    .else
-    ldrd    r0, [r0, #offStaticField_value] @ r0/r1<- field value (aligned)
-    .endif
-    add     r9, rFP, r9, lsl #2         @ r9<- &fp[AA]
-    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
-    stmia   r9, {r0-r1}                 @ vAA/vAA+1<- r0/r1
-    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    GOTO_OPCODE(ip)                     @ jump to next instruction
+    b		.LOP_SGET_WIDE_finish
+
 
 /* ------------------------------ */
     .balign 64
 .L_OP_SGET_OBJECT: /* 0x62 */
-/* File: armv5te/OP_SGET_OBJECT.S */
-/* File: armv5te/OP_SGET.S */
+/* File: armv5te_taint/OP_SGET_OBJECT.S */
+/* File: armv5te_taint/OP_SGET.S */
+// begin WITH_TAINT_TRACKING
+// end WITH_TAINT_TRACKING
     /*
      * General 32-bit SGET handler.
      *
@@ -2754,11 +3046,11 @@ dalvik_inst:
     cmp     r0, #0                      @ is resolved entry null?
     beq     .LOP_SGET_OBJECT_resolve         @ yes, do resolve
 .LOP_SGET_OBJECT_finish: @ field ptr in r0
-    ldr     r1, [r0, #offStaticField_value] @ r1<- field value
-    @ no-op                             @ acquiring load
-    mov     r2, rINST, lsr #8           @ r2<- AA
+// begin WITH_TAINT_TRACKING
+    bl		.LOP_SGET_OBJECT_taint_prop
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
-    SET_VREG(r1, r2)                    @ fp[AA]<- r1
+    SET_VREG(r0, r2)                    @ fp[AA]<- r0
+// end WITH_TAINT_TRACKING
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
@@ -2766,8 +3058,10 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_SGET_BOOLEAN: /* 0x63 */
-/* File: armv5te/OP_SGET_BOOLEAN.S */
-/* File: armv5te/OP_SGET.S */
+/* File: armv5te_taint/OP_SGET_BOOLEAN.S */
+/* File: armv5te_taint/OP_SGET.S */
+// begin WITH_TAINT_TRACKING
+// end WITH_TAINT_TRACKING
     /*
      * General 32-bit SGET handler.
      *
@@ -2781,11 +3075,11 @@ dalvik_inst:
     cmp     r0, #0                      @ is resolved entry null?
     beq     .LOP_SGET_BOOLEAN_resolve         @ yes, do resolve
 .LOP_SGET_BOOLEAN_finish: @ field ptr in r0
-    ldr     r1, [r0, #offStaticField_value] @ r1<- field value
-    @ no-op                             @ acquiring load
-    mov     r2, rINST, lsr #8           @ r2<- AA
+// begin WITH_TAINT_TRACKING
+    bl		.LOP_SGET_BOOLEAN_taint_prop
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
-    SET_VREG(r1, r2)                    @ fp[AA]<- r1
+    SET_VREG(r0, r2)                    @ fp[AA]<- r0
+// end WITH_TAINT_TRACKING
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
@@ -2793,8 +3087,10 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_SGET_BYTE: /* 0x64 */
-/* File: armv5te/OP_SGET_BYTE.S */
-/* File: armv5te/OP_SGET.S */
+/* File: armv5te_taint/OP_SGET_BYTE.S */
+/* File: armv5te_taint/OP_SGET.S */
+// begin WITH_TAINT_TRACKING
+// end WITH_TAINT_TRACKING
     /*
      * General 32-bit SGET handler.
      *
@@ -2808,11 +3104,11 @@ dalvik_inst:
     cmp     r0, #0                      @ is resolved entry null?
     beq     .LOP_SGET_BYTE_resolve         @ yes, do resolve
 .LOP_SGET_BYTE_finish: @ field ptr in r0
-    ldr     r1, [r0, #offStaticField_value] @ r1<- field value
-    @ no-op                             @ acquiring load
-    mov     r2, rINST, lsr #8           @ r2<- AA
+// begin WITH_TAINT_TRACKING
+    bl		.LOP_SGET_BYTE_taint_prop
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
-    SET_VREG(r1, r2)                    @ fp[AA]<- r1
+    SET_VREG(r0, r2)                    @ fp[AA]<- r0
+// end WITH_TAINT_TRACKING
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
@@ -2820,8 +3116,10 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_SGET_CHAR: /* 0x65 */
-/* File: armv5te/OP_SGET_CHAR.S */
-/* File: armv5te/OP_SGET.S */
+/* File: armv5te_taint/OP_SGET_CHAR.S */
+/* File: armv5te_taint/OP_SGET.S */
+// begin WITH_TAINT_TRACKING
+// end WITH_TAINT_TRACKING
     /*
      * General 32-bit SGET handler.
      *
@@ -2835,11 +3133,11 @@ dalvik_inst:
     cmp     r0, #0                      @ is resolved entry null?
     beq     .LOP_SGET_CHAR_resolve         @ yes, do resolve
 .LOP_SGET_CHAR_finish: @ field ptr in r0
-    ldr     r1, [r0, #offStaticField_value] @ r1<- field value
-    @ no-op                             @ acquiring load
-    mov     r2, rINST, lsr #8           @ r2<- AA
+// begin WITH_TAINT_TRACKING
+    bl		.LOP_SGET_CHAR_taint_prop
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
-    SET_VREG(r1, r2)                    @ fp[AA]<- r1
+    SET_VREG(r0, r2)                    @ fp[AA]<- r0
+// end WITH_TAINT_TRACKING
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
@@ -2847,8 +3145,10 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_SGET_SHORT: /* 0x66 */
-/* File: armv5te/OP_SGET_SHORT.S */
-/* File: armv5te/OP_SGET.S */
+/* File: armv5te_taint/OP_SGET_SHORT.S */
+/* File: armv5te_taint/OP_SGET.S */
+// begin WITH_TAINT_TRACKING
+// end WITH_TAINT_TRACKING
     /*
      * General 32-bit SGET handler.
      *
@@ -2862,11 +3162,11 @@ dalvik_inst:
     cmp     r0, #0                      @ is resolved entry null?
     beq     .LOP_SGET_SHORT_resolve         @ yes, do resolve
 .LOP_SGET_SHORT_finish: @ field ptr in r0
-    ldr     r1, [r0, #offStaticField_value] @ r1<- field value
-    @ no-op                             @ acquiring load
-    mov     r2, rINST, lsr #8           @ r2<- AA
+// begin WITH_TAINT_TRACKING
+    bl		.LOP_SGET_SHORT_taint_prop
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
-    SET_VREG(r1, r2)                    @ fp[AA]<- r1
+    SET_VREG(r0, r2)                    @ fp[AA]<- r0
+// end WITH_TAINT_TRACKING
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
@@ -2874,7 +3174,9 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_SPUT: /* 0x67 */
-/* File: armv5te/OP_SPUT.S */
+/* File: armv5te_taint/OP_SPUT.S */
+// begin WITH_TAINT_TRACKING
+// end WITH_TAINT_TRACKING
     /*
      * General 32-bit SPUT handler.
      *
@@ -2892,15 +3194,15 @@ dalvik_inst:
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
     GET_VREG(r1, r2)                    @ r1<- fp[AA]
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    @ no-op                        @ releasing store
-    str     r1, [r0, #offStaticField_value] @ field<- vAA
-    @ no-op 
+// begin WITH_TAINT_TRACKING
+    bl      .LOP_SPUT_taint_prop
+// end WITH_TAINT_TRACKING
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
 /* ------------------------------ */
     .balign 64
 .L_OP_SPUT_WIDE: /* 0x68 */
-/* File: armv5te/OP_SPUT_WIDE.S */
+/* File: armv5te_taint/OP_SPUT_WIDE.S */
     /*
      * 64-bit SPUT handler.
      */
@@ -2910,13 +3212,20 @@ dalvik_inst:
     ldr     r10, [r0, #offDvmDex_pResFields] @ r10<- dvmDex->pResFields
     mov     r9, rINST, lsr #8           @ r9<- AA
     ldr     r2, [r10, r1, lsl #2]        @ r2<- resolved StaticField ptr
-    add     r9, rFP, r9, lsl #2         @ r9<- &fp[AA]
+// begin WITH_TAINT_TRACKING
+    add     r9, rFP, r9, lsl #3         @ r9<- &fp[AA]
+// end WITH_TAINT_TRACKING
     cmp     r2, #0                      @ is resolved entry null?
     beq     .LOP_SPUT_WIDE_resolve         @ yes, do resolve
 .LOP_SPUT_WIDE_finish: @ field ptr in r2, AA in r9
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
-    ldmia   r9, {r0-r1}                 @ r0/r1<- vAA/vAA+1
+// begin WITH_TAINT_TRACKING
+    bl		.LOP_SPUT_WIDE_taint_prop
+// end WITH_TAINT_TRACKING
     GET_INST_OPCODE(r10)                @ extract opcode from rINST
+// begin WITH_TAINT_TRACKING
+    str	    r3, [r2, #offStaticField_taint]
+// end WITH_TAINT_TRACKING
     .if 0
     add     r2, r2, #offStaticField_value @ r2<- pointer to data
     bl      dvmQuasiAtomicSwap64Sync    @ stores r0/r1 into addr r2
@@ -2928,7 +3237,9 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_SPUT_OBJECT: /* 0x69 */
-/* File: armv5te/OP_SPUT_OBJECT.S */
+/* File: armv5te_taint/OP_SPUT_OBJECT.S */
+// begin WITH_TAINT_TRACKING
+// end WITH_TAINT_TRACKING
     /*
      * 32-bit SPUT handler for objects
      *
@@ -2945,7 +3256,12 @@ dalvik_inst:
     mov     r2, rINST, lsr #8           @ r2<- AA
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
     GET_VREG(r1, r2)                    @ r1<- fp[AA]
-    ldr     r2, [rSELF, #offThread_cardTable]  @ r2<- card table base
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r3)
+    GET_VREG_TAINT(r3, r2, r3)          @ r3<- taint
+//    ldr     r2, [rSELF, #offThread_cardTable]  @ r2<- card table base
+    ldr     r10, [rSELF, #offThread_cardTable]  @ r10<- card table base
+// end WITH_TAINT_TRACKING
     ldr     r9, [r0, #offField_clazz]   @ r9<- field->clazz
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
     @ no-op                         @ releasing store
@@ -2954,8 +3270,10 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_SPUT_BOOLEAN: /* 0x6a */
-/* File: armv5te/OP_SPUT_BOOLEAN.S */
-/* File: armv5te/OP_SPUT.S */
+/* File: armv5te_taint/OP_SPUT_BOOLEAN.S */
+/* File: armv5te_taint/OP_SPUT.S */
+// begin WITH_TAINT_TRACKING
+// end WITH_TAINT_TRACKING
     /*
      * General 32-bit SPUT handler.
      *
@@ -2973,17 +3291,19 @@ dalvik_inst:
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
     GET_VREG(r1, r2)                    @ r1<- fp[AA]
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    @ no-op                        @ releasing store
-    str     r1, [r0, #offStaticField_value] @ field<- vAA
-    @ no-op 
+// begin WITH_TAINT_TRACKING
+    bl      .LOP_SPUT_BOOLEAN_taint_prop
+// end WITH_TAINT_TRACKING
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
 
 /* ------------------------------ */
     .balign 64
 .L_OP_SPUT_BYTE: /* 0x6b */
-/* File: armv5te/OP_SPUT_BYTE.S */
-/* File: armv5te/OP_SPUT.S */
+/* File: armv5te_taint/OP_SPUT_BYTE.S */
+/* File: armv5te_taint/OP_SPUT.S */
+// begin WITH_TAINT_TRACKING
+// end WITH_TAINT_TRACKING
     /*
      * General 32-bit SPUT handler.
      *
@@ -3001,17 +3321,19 @@ dalvik_inst:
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
     GET_VREG(r1, r2)                    @ r1<- fp[AA]
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    @ no-op                        @ releasing store
-    str     r1, [r0, #offStaticField_value] @ field<- vAA
-    @ no-op 
+// begin WITH_TAINT_TRACKING
+    bl      .LOP_SPUT_BYTE_taint_prop
+// end WITH_TAINT_TRACKING
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
 
 /* ------------------------------ */
     .balign 64
 .L_OP_SPUT_CHAR: /* 0x6c */
-/* File: armv5te/OP_SPUT_CHAR.S */
-/* File: armv5te/OP_SPUT.S */
+/* File: armv5te_taint/OP_SPUT_CHAR.S */
+/* File: armv5te_taint/OP_SPUT.S */
+// begin WITH_TAINT_TRACKING
+// end WITH_TAINT_TRACKING
     /*
      * General 32-bit SPUT handler.
      *
@@ -3029,17 +3351,19 @@ dalvik_inst:
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
     GET_VREG(r1, r2)                    @ r1<- fp[AA]
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    @ no-op                        @ releasing store
-    str     r1, [r0, #offStaticField_value] @ field<- vAA
-    @ no-op 
+// begin WITH_TAINT_TRACKING
+    bl      .LOP_SPUT_CHAR_taint_prop
+// end WITH_TAINT_TRACKING
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
 
 /* ------------------------------ */
     .balign 64
 .L_OP_SPUT_SHORT: /* 0x6d */
-/* File: armv5te/OP_SPUT_SHORT.S */
-/* File: armv5te/OP_SPUT.S */
+/* File: armv5te_taint/OP_SPUT_SHORT.S */
+/* File: armv5te_taint/OP_SPUT.S */
+// begin WITH_TAINT_TRACKING
+// end WITH_TAINT_TRACKING
     /*
      * General 32-bit SPUT handler.
      *
@@ -3057,16 +3381,16 @@ dalvik_inst:
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
     GET_VREG(r1, r2)                    @ r1<- fp[AA]
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    @ no-op                        @ releasing store
-    str     r1, [r0, #offStaticField_value] @ field<- vAA
-    @ no-op 
+// begin WITH_TAINT_TRACKING
+    bl      .LOP_SPUT_SHORT_taint_prop
+// end WITH_TAINT_TRACKING
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
 
 /* ------------------------------ */
     .balign 64
 .L_OP_INVOKE_VIRTUAL: /* 0x6e */
-/* File: armv5te/OP_INVOKE_VIRTUAL.S */
+/* File: armv5te_taint/OP_INVOKE_VIRTUAL.S */
     /*
      * Handle a virtual method call.
      *
@@ -3096,7 +3420,7 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_INVOKE_SUPER: /* 0x6f */
-/* File: armv5te/OP_INVOKE_SUPER.S */
+/* File: armv5te_taint/OP_INVOKE_SUPER.S */
     /*
      * Handle a "super" method call.
      *
@@ -3125,7 +3449,7 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_INVOKE_DIRECT: /* 0x70 */
-/* File: armv5te/OP_INVOKE_DIRECT.S */
+/* File: armv5te_taint/OP_INVOKE_DIRECT.S */
     /*
      * Handle a direct method call.
      *
@@ -3158,7 +3482,7 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_INVOKE_STATIC: /* 0x71 */
-/* File: armv5te/OP_INVOKE_STATIC.S */
+/* File: armv5te_taint/OP_INVOKE_STATIC.S */
     /*
      * Handle a static method call.
      *
@@ -3182,7 +3506,7 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_INVOKE_INTERFACE: /* 0x72 */
-/* File: armv5te/OP_INVOKE_INTERFACE.S */
+/* File: armv5te_taint/OP_INVOKE_INTERFACE.S */
     /*
      * Handle an interface method call.
      *
@@ -3210,16 +3534,17 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_UNUSED_73: /* 0x73 */
-/* File: armv5te/OP_UNUSED_73.S */
-/* File: armv5te/unused.S */
+/* File: armv5te_taint/OP_UNUSED_73.S */
+/* File: armv5te_taint/unused.S */
     bl      common_abort
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_INVOKE_VIRTUAL_RANGE: /* 0x74 */
-/* File: armv5te/OP_INVOKE_VIRTUAL_RANGE.S */
-/* File: armv5te/OP_INVOKE_VIRTUAL.S */
+/* File: armv5te_taint/OP_INVOKE_VIRTUAL_RANGE.S */
+/* File: armv5te_taint/OP_INVOKE_VIRTUAL.S */
     /*
      * Handle a virtual method call.
      *
@@ -3250,8 +3575,8 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_INVOKE_SUPER_RANGE: /* 0x75 */
-/* File: armv5te/OP_INVOKE_SUPER_RANGE.S */
-/* File: armv5te/OP_INVOKE_SUPER.S */
+/* File: armv5te_taint/OP_INVOKE_SUPER_RANGE.S */
+/* File: armv5te_taint/OP_INVOKE_SUPER.S */
     /*
      * Handle a "super" method call.
      *
@@ -3281,8 +3606,8 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_INVOKE_DIRECT_RANGE: /* 0x76 */
-/* File: armv5te/OP_INVOKE_DIRECT_RANGE.S */
-/* File: armv5te/OP_INVOKE_DIRECT.S */
+/* File: armv5te_taint/OP_INVOKE_DIRECT_RANGE.S */
+/* File: armv5te_taint/OP_INVOKE_DIRECT.S */
     /*
      * Handle a direct method call.
      *
@@ -3316,8 +3641,8 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_INVOKE_STATIC_RANGE: /* 0x77 */
-/* File: armv5te/OP_INVOKE_STATIC_RANGE.S */
-/* File: armv5te/OP_INVOKE_STATIC.S */
+/* File: armv5te_taint/OP_INVOKE_STATIC_RANGE.S */
+/* File: armv5te_taint/OP_INVOKE_STATIC.S */
     /*
      * Handle a static method call.
      *
@@ -3342,8 +3667,8 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_INVOKE_INTERFACE_RANGE: /* 0x78 */
-/* File: armv5te/OP_INVOKE_INTERFACE_RANGE.S */
-/* File: armv5te/OP_INVOKE_INTERFACE.S */
+/* File: armv5te_taint/OP_INVOKE_INTERFACE_RANGE.S */
+/* File: armv5te_taint/OP_INVOKE_INTERFACE.S */
     /*
      * Handle an interface method call.
      *
@@ -3372,24 +3697,26 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_UNUSED_79: /* 0x79 */
-/* File: armv5te/OP_UNUSED_79.S */
-/* File: armv5te/unused.S */
+/* File: armv5te_taint/OP_UNUSED_79.S */
+/* File: armv5te_taint/unused.S */
     bl      common_abort
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_UNUSED_7A: /* 0x7a */
-/* File: armv5te/OP_UNUSED_7A.S */
-/* File: armv5te/unused.S */
+/* File: armv5te_taint/OP_UNUSED_7A.S */
+/* File: armv5te_taint/unused.S */
     bl      common_abort
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_NEG_INT: /* 0x7b */
-/* File: armv6t2/OP_NEG_INT.S */
-/* File: armv6t2/unop.S */
+/* File: armv6t2_taint/OP_NEG_INT.S */
+/* File: armv6t2_taint/unop.S */
     /*
      * Generic 32-bit unary operation.  Provide an "instr" line that
      * specifies an instruction that performs "result = op r0".
@@ -3402,6 +3729,11 @@ dalvik_inst:
     mov     r3, rINST, lsr #12          @ r3<- B
     ubfx    r9, rINST, #8, #4           @ r9<- A
     GET_VREG(r0, r3)                    @ r0<- vB
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r1)
+    GET_VREG_TAINT(r2, r3, r1)          @ r2<- vB.taint
+    SET_VREG_TAINT(r2, r9, r1)
+// end WITH_TAINT_TRACKING
                                @ optional op; may set condition codes
     FETCH_ADVANCE_INST(1)               @ advance rPC, load rINST
     rsb     r0, r0, #0                              @ r0<- op, r0-r3 changed
@@ -3414,8 +3746,8 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_NOT_INT: /* 0x7c */
-/* File: armv6t2/OP_NOT_INT.S */
-/* File: armv6t2/unop.S */
+/* File: armv6t2_taint/OP_NOT_INT.S */
+/* File: armv6t2_taint/unop.S */
     /*
      * Generic 32-bit unary operation.  Provide an "instr" line that
      * specifies an instruction that performs "result = op r0".
@@ -3428,6 +3760,11 @@ dalvik_inst:
     mov     r3, rINST, lsr #12          @ r3<- B
     ubfx    r9, rINST, #8, #4           @ r9<- A
     GET_VREG(r0, r3)                    @ r0<- vB
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r1)
+    GET_VREG_TAINT(r2, r3, r1)          @ r2<- vB.taint
+    SET_VREG_TAINT(r2, r9, r1)
+// end WITH_TAINT_TRACKING
                                @ optional op; may set condition codes
     FETCH_ADVANCE_INST(1)               @ advance rPC, load rINST
     mvn     r0, r0                              @ r0<- op, r0-r3 changed
@@ -3440,8 +3777,8 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_NEG_LONG: /* 0x7d */
-/* File: armv6t2/OP_NEG_LONG.S */
-/* File: armv6t2/unopWide.S */
+/* File: armv6t2_taint/OP_NEG_LONG.S */
+/* File: armv6t2_taint/unopWide.S */
     /*
      * Generic 64-bit unary operation.  Provide an "instr" line that
      * specifies an instruction that performs "result = op r0/r1".
@@ -3452,23 +3789,26 @@ dalvik_inst:
     /* unop vA, vB */
     mov     r3, rINST, lsr #12          @ r3<- B
     ubfx    r9, rINST, #8, #4           @ r9<- A
-    add     r3, rFP, r3, lsl #2         @ r3<- &fp[B]
-    add     r9, rFP, r9, lsl #2         @ r9<- &fp[A]
-    ldmia   r3, {r0-r1}                 @ r0/r1<- vAA
+// begin WITH_TAINT_TRACKING
+    add     r3, rFP, r3, lsl #3         @ r3<- &fp[B]
+    add     r9, rFP, r9, lsl #3         @ r9<- &fp[A]
+//    ldmia   r3, {r0-r1}                 @ r0/r1<- vAA
+    ldr     r0, [r3, #0]
+    ldr     r1, [r3, #8]
+    ldr     r10, [r3, #4]
+// end WITH_TAINT_TRACKING
     FETCH_ADVANCE_INST(1)               @ advance rPC, load rINST
     rsbs    r0, r0, #0                           @ optional op; may set condition codes
     rsc     r1, r1, #0                              @ r0/r1<- op, r2-r3 changed
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    stmia   r9, {r0-r1}                 @ vAA<- r0/r1
-    GOTO_OPCODE(ip)                     @ jump to next instruction
-    /* 10-11 instructions */
+    b       .LOP_NEG_LONG_finish
 
 
 /* ------------------------------ */
     .balign 64
 .L_OP_NOT_LONG: /* 0x7e */
-/* File: armv6t2/OP_NOT_LONG.S */
-/* File: armv6t2/unopWide.S */
+/* File: armv6t2_taint/OP_NOT_LONG.S */
+/* File: armv6t2_taint/unopWide.S */
     /*
      * Generic 64-bit unary operation.  Provide an "instr" line that
      * specifies an instruction that performs "result = op r0/r1".
@@ -3479,23 +3819,26 @@ dalvik_inst:
     /* unop vA, vB */
     mov     r3, rINST, lsr #12          @ r3<- B
     ubfx    r9, rINST, #8, #4           @ r9<- A
-    add     r3, rFP, r3, lsl #2         @ r3<- &fp[B]
-    add     r9, rFP, r9, lsl #2         @ r9<- &fp[A]
-    ldmia   r3, {r0-r1}                 @ r0/r1<- vAA
+// begin WITH_TAINT_TRACKING
+    add     r3, rFP, r3, lsl #3         @ r3<- &fp[B]
+    add     r9, rFP, r9, lsl #3         @ r9<- &fp[A]
+//    ldmia   r3, {r0-r1}                 @ r0/r1<- vAA
+    ldr     r0, [r3, #0]
+    ldr     r1, [r3, #8]
+    ldr     r10, [r3, #4]
+// end WITH_TAINT_TRACKING
     FETCH_ADVANCE_INST(1)               @ advance rPC, load rINST
     mvn     r0, r0                           @ optional op; may set condition codes
     mvn     r1, r1                              @ r0/r1<- op, r2-r3 changed
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    stmia   r9, {r0-r1}                 @ vAA<- r0/r1
-    GOTO_OPCODE(ip)                     @ jump to next instruction
-    /* 10-11 instructions */
+    b       .LOP_NOT_LONG_finish
 
 
 /* ------------------------------ */
     .balign 64
 .L_OP_NEG_FLOAT: /* 0x7f */
-/* File: armv6t2/OP_NEG_FLOAT.S */
-/* File: armv6t2/unop.S */
+/* File: armv6t2_taint/OP_NEG_FLOAT.S */
+/* File: armv6t2_taint/unop.S */
     /*
      * Generic 32-bit unary operation.  Provide an "instr" line that
      * specifies an instruction that performs "result = op r0".
@@ -3508,6 +3851,11 @@ dalvik_inst:
     mov     r3, rINST, lsr #12          @ r3<- B
     ubfx    r9, rINST, #8, #4           @ r9<- A
     GET_VREG(r0, r3)                    @ r0<- vB
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r1)
+    GET_VREG_TAINT(r2, r3, r1)          @ r2<- vB.taint
+    SET_VREG_TAINT(r2, r9, r1)
+// end WITH_TAINT_TRACKING
                                @ optional op; may set condition codes
     FETCH_ADVANCE_INST(1)               @ advance rPC, load rINST
     add     r0, r0, #0x80000000                              @ r0<- op, r0-r3 changed
@@ -3520,8 +3868,8 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_NEG_DOUBLE: /* 0x80 */
-/* File: armv6t2/OP_NEG_DOUBLE.S */
-/* File: armv6t2/unopWide.S */
+/* File: armv6t2_taint/OP_NEG_DOUBLE.S */
+/* File: armv6t2_taint/unopWide.S */
     /*
      * Generic 64-bit unary operation.  Provide an "instr" line that
      * specifies an instruction that performs "result = op r0/r1".
@@ -3532,23 +3880,26 @@ dalvik_inst:
     /* unop vA, vB */
     mov     r3, rINST, lsr #12          @ r3<- B
     ubfx    r9, rINST, #8, #4           @ r9<- A
-    add     r3, rFP, r3, lsl #2         @ r3<- &fp[B]
-    add     r9, rFP, r9, lsl #2         @ r9<- &fp[A]
-    ldmia   r3, {r0-r1}                 @ r0/r1<- vAA
+// begin WITH_TAINT_TRACKING
+    add     r3, rFP, r3, lsl #3         @ r3<- &fp[B]
+    add     r9, rFP, r9, lsl #3         @ r9<- &fp[A]
+//    ldmia   r3, {r0-r1}                 @ r0/r1<- vAA
+    ldr     r0, [r3, #0]
+    ldr     r1, [r3, #8]
+    ldr     r10, [r3, #4]
+// end WITH_TAINT_TRACKING
     FETCH_ADVANCE_INST(1)               @ advance rPC, load rINST
                                @ optional op; may set condition codes
     add     r1, r1, #0x80000000                              @ r0/r1<- op, r2-r3 changed
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    stmia   r9, {r0-r1}                 @ vAA<- r0/r1
-    GOTO_OPCODE(ip)                     @ jump to next instruction
-    /* 10-11 instructions */
+    b       .LOP_NEG_DOUBLE_finish
 
 
 /* ------------------------------ */
     .balign 64
 .L_OP_INT_TO_LONG: /* 0x81 */
-/* File: armv6t2/OP_INT_TO_LONG.S */
-/* File: armv6t2/unopWider.S */
+/* File: armv6t2_taint/OP_INT_TO_LONG.S */
+/* File: armv6t2_taint/unopWider.S */
     /*
      * Generic 32bit-to-64bit unary operation.  Provide an "instr" line
      * that specifies an instruction that performs "result = op r0", where
@@ -3560,21 +3911,23 @@ dalvik_inst:
     mov     r3, rINST, lsr #12          @ r3<- B
     ubfx    r9, rINST, #8, #4           @ r9<- A
     GET_VREG(r0, r3)                    @ r0<- vB
-    add     r9, rFP, r9, lsl #2         @ r9<- &fp[A]
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r2)
+    GET_VREG_TAINT(r10, r3, r2)
+    add     r9, rFP, r9, lsl #3         @ r9<- &fp[A]
+// end WITH_TAINT_TRACKING
                                @ optional op; may set condition codes
     FETCH_ADVANCE_INST(1)               @ advance rPC, load rINST
     mov     r1, r0, asr #31                              @ r0<- op, r0-r3 changed
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    stmia   r9, {r0-r1}                 @ vA/vA+1<- r0/r1
-    GOTO_OPCODE(ip)                     @ jump to next instruction
-    /* 9-10 instructions */
+    b      .LOP_INT_TO_LONG_finish
 
 
 /* ------------------------------ */
     .balign 64
 .L_OP_INT_TO_FLOAT: /* 0x82 */
-/* File: arm-vfp/OP_INT_TO_FLOAT.S */
-/* File: arm-vfp/funop.S */
+/* File: arm-vfp_taint/OP_INT_TO_FLOAT.S */
+/* File: arm-vfp_taint/funop.S */
     /*
      * Generic 32-bit unary floating-point operation.  Provide an "instr"
      * line that specifies an instruction that performs "s1 = op s0".
@@ -3586,20 +3939,26 @@ dalvik_inst:
     mov     r9, rINST, lsr #8           @ r9<- A+
     VREG_INDEX_TO_ADDR(r3, r3)          @ r3<- &vB
     flds    s0, [r3]                    @ s0<- vB
+// begin WITH_TAINT_TRACKING
+    ldr     r0, [r3, #4]
+// end WITH_TAINT_TRACKING
     FETCH_ADVANCE_INST(1)               @ advance rPC, load rINST
     and     r9, r9, #15                 @ r9<- A
     fsitos  s1, s0                              @ s1<- op
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
     VREG_INDEX_TO_ADDR(r9, r9)          @ r9<- &vA
     fsts    s1, [r9]                    @ vA<- s1
+// begin WITH_TAINT_TRACKING
+    str     r0, [r9, #4]
+// end WITH_TAINT_TRACKING
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
 
 /* ------------------------------ */
     .balign 64
 .L_OP_INT_TO_DOUBLE: /* 0x83 */
-/* File: arm-vfp/OP_INT_TO_DOUBLE.S */
-/* File: arm-vfp/funopWider.S */
+/* File: arm-vfp_taint/OP_INT_TO_DOUBLE.S */
+/* File: arm-vfp_taint/funopWider.S */
     /*
      * Generic 32bit-to-64bit floating point unary operation.  Provide an
      * "instr" line that specifies an instruction that performs "d0 = op s0".
@@ -3611,21 +3970,30 @@ dalvik_inst:
     mov     r9, rINST, lsr #8           @ r9<- A+
     VREG_INDEX_TO_ADDR(r3, r3)          @ r3<- &vB
     flds    s0, [r3]                    @ s0<- vB
+// begin WITH_TAINT_TRACKING
+    ldr     r0, [r3, #4]
+// end WITH_TAINT_TRACKING
     FETCH_ADVANCE_INST(1)               @ advance rPC, load rINST
     and     r9, r9, #15                 @ r9<- A
     fsitod  d0, s0                              @ d0<- op
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
     VREG_INDEX_TO_ADDR(r9, r9)          @ r9<- &vA
-    fstd    d0, [r9]                    @ vA<- d0
+// begin WITH_TAINT_TRACKING
+//    fstd    d0, [r9]                    @ vA<- d0
+    fsts    s0, [r9]
+    fsts    s1, [r9, #8]
+    str     r0, [r9, #4]
+    str     r0, [r9, #12]
+// end WITH_TAINT_TRACKING
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
 
 /* ------------------------------ */
     .balign 64
 .L_OP_LONG_TO_INT: /* 0x84 */
-/* File: armv5te/OP_LONG_TO_INT.S */
+/* File: armv5te_taint/OP_LONG_TO_INT.S */
 /* we ignore the high word, making this equivalent to a 32-bit reg move */
-/* File: armv5te/OP_MOVE.S */
+/* File: armv5te_taint/OP_MOVE.S */
     /* for move, move-object, long-to-int */
     /* op vA, vB */
     mov     r1, rINST, lsr #12          @ r1<- B from 15:12
@@ -3633,16 +4001,22 @@ dalvik_inst:
     FETCH_ADVANCE_INST(1)               @ advance rPC, load rINST
     GET_VREG(r2, r1)                    @ r2<- fp[B]
     and     r0, r0, #15
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r3)
+    GET_VREG_TAINT(r1, r1, r3)
+    SET_VREG_TAINT(r1, r0, r3)
+// end WITH_TAINT_TRACKING
     GET_INST_OPCODE(ip)                 @ ip<- opcode from rINST
     SET_VREG(r2, r0)                    @ fp[A]<- r2
     GOTO_OPCODE(ip)                     @ execute next instruction
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_LONG_TO_FLOAT: /* 0x85 */
-/* File: armv6t2/OP_LONG_TO_FLOAT.S */
-/* File: armv6t2/unopNarrower.S */
+/* File: armv6t2_taint/OP_LONG_TO_FLOAT.S */
+/* File: armv6t2_taint/unopNarrower.S */
     /*
      * Generic 64bit-to-32bit unary operation.  Provide an "instr" line
      * that specifies an instruction that performs "result = op r0/r1", where
@@ -3656,13 +4030,22 @@ dalvik_inst:
     /* unop vA, vB */
     mov     r3, rINST, lsr #12          @ r3<- B
     ubfx    r9, rINST, #8, #4           @ r9<- A
-    add     r3, rFP, r3, lsl #2         @ r3<- &fp[B]
-    ldmia   r3, {r0-r1}                 @ r0/r1<- vB/vB+1
+// begin WITH_TAINT_TRACKING
+    add     r3, rFP, r3, lsl #3         @ r3<- &fp[B]
+//    ldmia   r3, {r0-r1}                 @ r0/r1<- vB/vB+1
+    ldr     r0, [r3, #0]
+    ldr     r10, [r3, #4]
+    ldr     r1, [r3, #8]
+// end WITH_TAINT_TRACKING
     FETCH_ADVANCE_INST(1)               @ advance rPC, load rINST
                                @ optional op; may set condition codes
     bl      __aeabi_l2f                              @ r0<- op, r0-r3 changed
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+// begin WITH_TAINT_TRACKING
     SET_VREG(r0, r9)                    @ vA<- r0
+    SET_TAINT_FP(r1)
+    SET_VREG_TAINT(r10, r9, r1)
+// end WITH_TAINT_TRACKING
     GOTO_OPCODE(ip)                     @ jump to next instruction
     /* 9-10 instructions */
 
@@ -3670,8 +4053,8 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_LONG_TO_DOUBLE: /* 0x86 */
-/* File: armv6t2/OP_LONG_TO_DOUBLE.S */
-/* File: armv6t2/unopWide.S */
+/* File: armv6t2_taint/OP_LONG_TO_DOUBLE.S */
+/* File: armv6t2_taint/unopWide.S */
     /*
      * Generic 64-bit unary operation.  Provide an "instr" line that
      * specifies an instruction that performs "result = op r0/r1".
@@ -3682,23 +4065,26 @@ dalvik_inst:
     /* unop vA, vB */
     mov     r3, rINST, lsr #12          @ r3<- B
     ubfx    r9, rINST, #8, #4           @ r9<- A
-    add     r3, rFP, r3, lsl #2         @ r3<- &fp[B]
-    add     r9, rFP, r9, lsl #2         @ r9<- &fp[A]
-    ldmia   r3, {r0-r1}                 @ r0/r1<- vAA
+// begin WITH_TAINT_TRACKING
+    add     r3, rFP, r3, lsl #3         @ r3<- &fp[B]
+    add     r9, rFP, r9, lsl #3         @ r9<- &fp[A]
+//    ldmia   r3, {r0-r1}                 @ r0/r1<- vAA
+    ldr     r0, [r3, #0]
+    ldr     r1, [r3, #8]
+    ldr     r10, [r3, #4]
+// end WITH_TAINT_TRACKING
     FETCH_ADVANCE_INST(1)               @ advance rPC, load rINST
                                @ optional op; may set condition codes
     bl      __aeabi_l2d                              @ r0/r1<- op, r2-r3 changed
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    stmia   r9, {r0-r1}                 @ vAA<- r0/r1
-    GOTO_OPCODE(ip)                     @ jump to next instruction
-    /* 10-11 instructions */
+    b       .LOP_LONG_TO_DOUBLE_finish
 
 
 /* ------------------------------ */
     .balign 64
 .L_OP_FLOAT_TO_INT: /* 0x87 */
-/* File: arm-vfp/OP_FLOAT_TO_INT.S */
-/* File: arm-vfp/funop.S */
+/* File: arm-vfp_taint/OP_FLOAT_TO_INT.S */
+/* File: arm-vfp_taint/funop.S */
     /*
      * Generic 32-bit unary floating-point operation.  Provide an "instr"
      * line that specifies an instruction that performs "s1 = op s0".
@@ -3710,21 +4096,27 @@ dalvik_inst:
     mov     r9, rINST, lsr #8           @ r9<- A+
     VREG_INDEX_TO_ADDR(r3, r3)          @ r3<- &vB
     flds    s0, [r3]                    @ s0<- vB
+// begin WITH_TAINT_TRACKING
+    ldr     r0, [r3, #4]
+// end WITH_TAINT_TRACKING
     FETCH_ADVANCE_INST(1)               @ advance rPC, load rINST
     and     r9, r9, #15                 @ r9<- A
     ftosizs s1, s0                              @ s1<- op
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
     VREG_INDEX_TO_ADDR(r9, r9)          @ r9<- &vA
     fsts    s1, [r9]                    @ vA<- s1
+// begin WITH_TAINT_TRACKING
+    str     r0, [r9, #4]
+// end WITH_TAINT_TRACKING
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
 
 /* ------------------------------ */
     .balign 64
 .L_OP_FLOAT_TO_LONG: /* 0x88 */
-/* File: armv6t2/OP_FLOAT_TO_LONG.S */
-@include "armv6t2/unopWider.S" {"instr":"bl      __aeabi_f2lz"}
-/* File: armv6t2/unopWider.S */
+/* File: armv6t2_taint/OP_FLOAT_TO_LONG.S */
+@include "armv6t2_taint/unopWider.S" {"instr":"bl      __aeabi_f2lz"}
+/* File: armv6t2_taint/unopWider.S */
     /*
      * Generic 32bit-to-64bit unary operation.  Provide an "instr" line
      * that specifies an instruction that performs "result = op r0", where
@@ -3736,22 +4128,24 @@ dalvik_inst:
     mov     r3, rINST, lsr #12          @ r3<- B
     ubfx    r9, rINST, #8, #4           @ r9<- A
     GET_VREG(r0, r3)                    @ r0<- vB
-    add     r9, rFP, r9, lsl #2         @ r9<- &fp[A]
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r2)
+    GET_VREG_TAINT(r10, r3, r2)
+    add     r9, rFP, r9, lsl #3         @ r9<- &fp[A]
+// end WITH_TAINT_TRACKING
                                @ optional op; may set condition codes
     FETCH_ADVANCE_INST(1)               @ advance rPC, load rINST
     bl      f2l_doconv                              @ r0<- op, r0-r3 changed
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    stmia   r9, {r0-r1}                 @ vA/vA+1<- r0/r1
-    GOTO_OPCODE(ip)                     @ jump to next instruction
-    /* 9-10 instructions */
+    b      .LOP_FLOAT_TO_LONG_finish
 
 
 
 /* ------------------------------ */
     .balign 64
 .L_OP_FLOAT_TO_DOUBLE: /* 0x89 */
-/* File: arm-vfp/OP_FLOAT_TO_DOUBLE.S */
-/* File: arm-vfp/funopWider.S */
+/* File: arm-vfp_taint/OP_FLOAT_TO_DOUBLE.S */
+/* File: arm-vfp_taint/funopWider.S */
     /*
      * Generic 32bit-to-64bit floating point unary operation.  Provide an
      * "instr" line that specifies an instruction that performs "d0 = op s0".
@@ -3763,20 +4157,29 @@ dalvik_inst:
     mov     r9, rINST, lsr #8           @ r9<- A+
     VREG_INDEX_TO_ADDR(r3, r3)          @ r3<- &vB
     flds    s0, [r3]                    @ s0<- vB
+// begin WITH_TAINT_TRACKING
+    ldr     r0, [r3, #4]
+// end WITH_TAINT_TRACKING
     FETCH_ADVANCE_INST(1)               @ advance rPC, load rINST
     and     r9, r9, #15                 @ r9<- A
     fcvtds  d0, s0                              @ d0<- op
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
     VREG_INDEX_TO_ADDR(r9, r9)          @ r9<- &vA
-    fstd    d0, [r9]                    @ vA<- d0
+// begin WITH_TAINT_TRACKING
+//    fstd    d0, [r9]                    @ vA<- d0
+    fsts    s0, [r9]
+    fsts    s1, [r9, #8]
+    str     r0, [r9, #4]
+    str     r0, [r9, #12]
+// end WITH_TAINT_TRACKING
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
 
 /* ------------------------------ */
     .balign 64
 .L_OP_DOUBLE_TO_INT: /* 0x8a */
-/* File: arm-vfp/OP_DOUBLE_TO_INT.S */
-/* File: arm-vfp/funopNarrower.S */
+/* File: arm-vfp_taint/OP_DOUBLE_TO_INT.S */
+/* File: arm-vfp_taint/funopNarrower.S */
     /*
      * Generic 64bit-to-32bit unary floating point operation.  Provide an
      * "instr" line that specifies an instruction that performs "s0 = op d0".
@@ -3787,22 +4190,30 @@ dalvik_inst:
     mov     r3, rINST, lsr #12          @ r3<- B
     mov     r9, rINST, lsr #8           @ r9<- A+
     VREG_INDEX_TO_ADDR(r3, r3)          @ r3<- &vB
-    fldd    d0, [r3]                    @ d0<- vB
+// begin WITH_TAINT_TRACKING
+//    fldd    d0, [r3]                    @ d0<- vB
+    flds    s0, [r3]
+    flds    s1, [r3, #8]
+    ldr     r0, [r3, #4]
+// end WITH_TAINT_TRACKING
     FETCH_ADVANCE_INST(1)               @ advance rPC, load rINST
     and     r9, r9, #15                 @ r9<- A
     ftosizd  s0, d0                              @ s0<- op
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
     VREG_INDEX_TO_ADDR(r9, r9)          @ r9<- &vA
     fsts    s0, [r9]                    @ vA<- s0
+// begin WITH_TAINT_TRACKING
+    str     r0, [r9, #4]
+// end WITH_TAINT_TRACKING
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
 
 /* ------------------------------ */
     .balign 64
 .L_OP_DOUBLE_TO_LONG: /* 0x8b */
-/* File: armv6t2/OP_DOUBLE_TO_LONG.S */
-@include "armv6t2/unopWide.S" {"instr":"bl      __aeabi_d2lz"}
-/* File: armv6t2/unopWide.S */
+/* File: armv6t2_taint/OP_DOUBLE_TO_LONG.S */
+@include "armv6t2_taint/unopWide.S" {"instr":"bl      __aeabi_d2lz"}
+/* File: armv6t2_taint/unopWide.S */
     /*
      * Generic 64-bit unary operation.  Provide an "instr" line that
      * specifies an instruction that performs "result = op r0/r1".
@@ -3813,24 +4224,27 @@ dalvik_inst:
     /* unop vA, vB */
     mov     r3, rINST, lsr #12          @ r3<- B
     ubfx    r9, rINST, #8, #4           @ r9<- A
-    add     r3, rFP, r3, lsl #2         @ r3<- &fp[B]
-    add     r9, rFP, r9, lsl #2         @ r9<- &fp[A]
-    ldmia   r3, {r0-r1}                 @ r0/r1<- vAA
+// begin WITH_TAINT_TRACKING
+    add     r3, rFP, r3, lsl #3         @ r3<- &fp[B]
+    add     r9, rFP, r9, lsl #3         @ r9<- &fp[A]
+//    ldmia   r3, {r0-r1}                 @ r0/r1<- vAA
+    ldr     r0, [r3, #0]
+    ldr     r1, [r3, #8]
+    ldr     r10, [r3, #4]
+// end WITH_TAINT_TRACKING
     FETCH_ADVANCE_INST(1)               @ advance rPC, load rINST
                                @ optional op; may set condition codes
     bl      d2l_doconv                              @ r0/r1<- op, r2-r3 changed
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    stmia   r9, {r0-r1}                 @ vAA<- r0/r1
-    GOTO_OPCODE(ip)                     @ jump to next instruction
-    /* 10-11 instructions */
+    b       .LOP_DOUBLE_TO_LONG_finish
 
 
 
 /* ------------------------------ */
     .balign 64
 .L_OP_DOUBLE_TO_FLOAT: /* 0x8c */
-/* File: arm-vfp/OP_DOUBLE_TO_FLOAT.S */
-/* File: arm-vfp/funopNarrower.S */
+/* File: arm-vfp_taint/OP_DOUBLE_TO_FLOAT.S */
+/* File: arm-vfp_taint/funopNarrower.S */
     /*
      * Generic 64bit-to-32bit unary floating point operation.  Provide an
      * "instr" line that specifies an instruction that performs "s0 = op d0".
@@ -3841,21 +4255,29 @@ dalvik_inst:
     mov     r3, rINST, lsr #12          @ r3<- B
     mov     r9, rINST, lsr #8           @ r9<- A+
     VREG_INDEX_TO_ADDR(r3, r3)          @ r3<- &vB
-    fldd    d0, [r3]                    @ d0<- vB
+// begin WITH_TAINT_TRACKING
+//    fldd    d0, [r3]                    @ d0<- vB
+    flds    s0, [r3]
+    flds    s1, [r3, #8]
+    ldr     r0, [r3, #4]
+// end WITH_TAINT_TRACKING
     FETCH_ADVANCE_INST(1)               @ advance rPC, load rINST
     and     r9, r9, #15                 @ r9<- A
     fcvtsd  s0, d0                              @ s0<- op
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
     VREG_INDEX_TO_ADDR(r9, r9)          @ r9<- &vA
     fsts    s0, [r9]                    @ vA<- s0
+// begin WITH_TAINT_TRACKING
+    str     r0, [r9, #4]
+// end WITH_TAINT_TRACKING
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
 
 /* ------------------------------ */
     .balign 64
 .L_OP_INT_TO_BYTE: /* 0x8d */
-/* File: armv6t2/OP_INT_TO_BYTE.S */
-/* File: armv6t2/unop.S */
+/* File: armv6t2_taint/OP_INT_TO_BYTE.S */
+/* File: armv6t2_taint/unop.S */
     /*
      * Generic 32-bit unary operation.  Provide an "instr" line that
      * specifies an instruction that performs "result = op r0".
@@ -3868,6 +4290,11 @@ dalvik_inst:
     mov     r3, rINST, lsr #12          @ r3<- B
     ubfx    r9, rINST, #8, #4           @ r9<- A
     GET_VREG(r0, r3)                    @ r0<- vB
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r1)
+    GET_VREG_TAINT(r2, r3, r1)          @ r2<- vB.taint
+    SET_VREG_TAINT(r2, r9, r1)
+// end WITH_TAINT_TRACKING
                                @ optional op; may set condition codes
     FETCH_ADVANCE_INST(1)               @ advance rPC, load rINST
     sxtb    r0, r0                              @ r0<- op, r0-r3 changed
@@ -3880,8 +4307,8 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_INT_TO_CHAR: /* 0x8e */
-/* File: armv6t2/OP_INT_TO_CHAR.S */
-/* File: armv6t2/unop.S */
+/* File: armv6t2_taint/OP_INT_TO_CHAR.S */
+/* File: armv6t2_taint/unop.S */
     /*
      * Generic 32-bit unary operation.  Provide an "instr" line that
      * specifies an instruction that performs "result = op r0".
@@ -3894,6 +4321,11 @@ dalvik_inst:
     mov     r3, rINST, lsr #12          @ r3<- B
     ubfx    r9, rINST, #8, #4           @ r9<- A
     GET_VREG(r0, r3)                    @ r0<- vB
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r1)
+    GET_VREG_TAINT(r2, r3, r1)          @ r2<- vB.taint
+    SET_VREG_TAINT(r2, r9, r1)
+// end WITH_TAINT_TRACKING
                                @ optional op; may set condition codes
     FETCH_ADVANCE_INST(1)               @ advance rPC, load rINST
     uxth    r0, r0                              @ r0<- op, r0-r3 changed
@@ -3906,8 +4338,8 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_INT_TO_SHORT: /* 0x8f */
-/* File: armv6t2/OP_INT_TO_SHORT.S */
-/* File: armv6t2/unop.S */
+/* File: armv6t2_taint/OP_INT_TO_SHORT.S */
+/* File: armv6t2_taint/unop.S */
     /*
      * Generic 32-bit unary operation.  Provide an "instr" line that
      * specifies an instruction that performs "result = op r0".
@@ -3920,6 +4352,11 @@ dalvik_inst:
     mov     r3, rINST, lsr #12          @ r3<- B
     ubfx    r9, rINST, #8, #4           @ r9<- A
     GET_VREG(r0, r3)                    @ r0<- vB
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r1)
+    GET_VREG_TAINT(r2, r3, r1)          @ r2<- vB.taint
+    SET_VREG_TAINT(r2, r9, r1)
+// end WITH_TAINT_TRACKING
                                @ optional op; may set condition codes
     FETCH_ADVANCE_INST(1)               @ advance rPC, load rINST
     sxth    r0, r0                              @ r0<- op, r0-r3 changed
@@ -3932,8 +4369,8 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_ADD_INT: /* 0x90 */
-/* File: armv5te/OP_ADD_INT.S */
-/* File: armv5te/binop.S */
+/* File: armv5te_taint/OP_ADD_INT.S */
+/* File: armv5te_taint/binop.S */
     /*
      * Generic 32-bit binary operation.  Provide an "instr" line that
      * specifies an instruction that performs "result = r0 op r1".
@@ -3961,6 +4398,9 @@ dalvik_inst:
     beq     common_errDivideByZero
     .endif
 
+// begin WITH_TAINT_TRACKING
+    bl      .LOP_ADD_INT_taint_prop
+// end WITH_TAINT_TRACKING
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
                                @ optional op; may set condition codes
     add     r0, r0, r1                              @ r0<- op, r0-r3 changed
@@ -3970,11 +4410,12 @@ dalvik_inst:
     /* 11-14 instructions */
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_SUB_INT: /* 0x91 */
-/* File: armv5te/OP_SUB_INT.S */
-/* File: armv5te/binop.S */
+/* File: armv5te_taint/OP_SUB_INT.S */
+/* File: armv5te_taint/binop.S */
     /*
      * Generic 32-bit binary operation.  Provide an "instr" line that
      * specifies an instruction that performs "result = r0 op r1".
@@ -4002,6 +4443,9 @@ dalvik_inst:
     beq     common_errDivideByZero
     .endif
 
+// begin WITH_TAINT_TRACKING
+    bl      .LOP_SUB_INT_taint_prop
+// end WITH_TAINT_TRACKING
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
                                @ optional op; may set condition codes
     sub     r0, r0, r1                              @ r0<- op, r0-r3 changed
@@ -4011,12 +4455,13 @@ dalvik_inst:
     /* 11-14 instructions */
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_MUL_INT: /* 0x92 */
-/* File: armv5te/OP_MUL_INT.S */
+/* File: armv5te_taint/OP_MUL_INT.S */
 /* must be "mul r0, r1, r0" -- "r0, r0, r1" is illegal */
-/* File: armv5te/binop.S */
+/* File: armv5te_taint/binop.S */
     /*
      * Generic 32-bit binary operation.  Provide an "instr" line that
      * specifies an instruction that performs "result = r0 op r1".
@@ -4044,6 +4489,9 @@ dalvik_inst:
     beq     common_errDivideByZero
     .endif
 
+// begin WITH_TAINT_TRACKING
+    bl      .LOP_MUL_INT_taint_prop
+// end WITH_TAINT_TRACKING
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
                                @ optional op; may set condition codes
     mul     r0, r1, r0                              @ r0<- op, r0-r3 changed
@@ -4053,11 +4501,12 @@ dalvik_inst:
     /* 11-14 instructions */
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_DIV_INT: /* 0x93 */
-/* File: armv5te/OP_DIV_INT.S */
-/* File: armv5te/binop.S */
+/* File: armv5te_taint/OP_DIV_INT.S */
+/* File: armv5te_taint/binop.S */
     /*
      * Generic 32-bit binary operation.  Provide an "instr" line that
      * specifies an instruction that performs "result = r0 op r1".
@@ -4085,6 +4534,9 @@ dalvik_inst:
     beq     common_errDivideByZero
     .endif
 
+// begin WITH_TAINT_TRACKING
+    bl      .LOP_DIV_INT_taint_prop
+// end WITH_TAINT_TRACKING
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
                                @ optional op; may set condition codes
     bl     __aeabi_idiv                              @ r0<- op, r0-r3 changed
@@ -4094,12 +4546,13 @@ dalvik_inst:
     /* 11-14 instructions */
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_REM_INT: /* 0x94 */
-/* File: armv5te/OP_REM_INT.S */
+/* File: armv5te_taint/OP_REM_INT.S */
 /* idivmod returns quotient in r0 and remainder in r1 */
-/* File: armv5te/binop.S */
+/* File: armv5te_taint/binop.S */
     /*
      * Generic 32-bit binary operation.  Provide an "instr" line that
      * specifies an instruction that performs "result = r0 op r1".
@@ -4127,6 +4580,9 @@ dalvik_inst:
     beq     common_errDivideByZero
     .endif
 
+// begin WITH_TAINT_TRACKING
+    bl      .LOP_REM_INT_taint_prop
+// end WITH_TAINT_TRACKING
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
                                @ optional op; may set condition codes
     bl      __aeabi_idivmod                              @ r1<- op, r0-r3 changed
@@ -4136,11 +4592,12 @@ dalvik_inst:
     /* 11-14 instructions */
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_AND_INT: /* 0x95 */
-/* File: armv5te/OP_AND_INT.S */
-/* File: armv5te/binop.S */
+/* File: armv5te_taint/OP_AND_INT.S */
+/* File: armv5te_taint/binop.S */
     /*
      * Generic 32-bit binary operation.  Provide an "instr" line that
      * specifies an instruction that performs "result = r0 op r1".
@@ -4168,6 +4625,9 @@ dalvik_inst:
     beq     common_errDivideByZero
     .endif
 
+// begin WITH_TAINT_TRACKING
+    bl      .LOP_AND_INT_taint_prop
+// end WITH_TAINT_TRACKING
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
                                @ optional op; may set condition codes
     and     r0, r0, r1                              @ r0<- op, r0-r3 changed
@@ -4177,11 +4637,12 @@ dalvik_inst:
     /* 11-14 instructions */
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_OR_INT: /* 0x96 */
-/* File: armv5te/OP_OR_INT.S */
-/* File: armv5te/binop.S */
+/* File: armv5te_taint/OP_OR_INT.S */
+/* File: armv5te_taint/binop.S */
     /*
      * Generic 32-bit binary operation.  Provide an "instr" line that
      * specifies an instruction that performs "result = r0 op r1".
@@ -4209,6 +4670,9 @@ dalvik_inst:
     beq     common_errDivideByZero
     .endif
 
+// begin WITH_TAINT_TRACKING
+    bl      .LOP_OR_INT_taint_prop
+// end WITH_TAINT_TRACKING
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
                                @ optional op; may set condition codes
     orr     r0, r0, r1                              @ r0<- op, r0-r3 changed
@@ -4218,11 +4682,12 @@ dalvik_inst:
     /* 11-14 instructions */
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_XOR_INT: /* 0x97 */
-/* File: armv5te/OP_XOR_INT.S */
-/* File: armv5te/binop.S */
+/* File: armv5te_taint/OP_XOR_INT.S */
+/* File: armv5te_taint/binop.S */
     /*
      * Generic 32-bit binary operation.  Provide an "instr" line that
      * specifies an instruction that performs "result = r0 op r1".
@@ -4250,6 +4715,9 @@ dalvik_inst:
     beq     common_errDivideByZero
     .endif
 
+// begin WITH_TAINT_TRACKING
+    bl      .LOP_XOR_INT_taint_prop
+// end WITH_TAINT_TRACKING
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
                                @ optional op; may set condition codes
     eor     r0, r0, r1                              @ r0<- op, r0-r3 changed
@@ -4259,11 +4727,12 @@ dalvik_inst:
     /* 11-14 instructions */
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_SHL_INT: /* 0x98 */
-/* File: armv5te/OP_SHL_INT.S */
-/* File: armv5te/binop.S */
+/* File: armv5te_taint/OP_SHL_INT.S */
+/* File: armv5te_taint/binop.S */
     /*
      * Generic 32-bit binary operation.  Provide an "instr" line that
      * specifies an instruction that performs "result = r0 op r1".
@@ -4291,6 +4760,9 @@ dalvik_inst:
     beq     common_errDivideByZero
     .endif
 
+// begin WITH_TAINT_TRACKING
+    bl      .LOP_SHL_INT_taint_prop
+// end WITH_TAINT_TRACKING
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
     and     r1, r1, #31                           @ optional op; may set condition codes
     mov     r0, r0, asl r1                              @ r0<- op, r0-r3 changed
@@ -4300,11 +4772,12 @@ dalvik_inst:
     /* 11-14 instructions */
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_SHR_INT: /* 0x99 */
-/* File: armv5te/OP_SHR_INT.S */
-/* File: armv5te/binop.S */
+/* File: armv5te_taint/OP_SHR_INT.S */
+/* File: armv5te_taint/binop.S */
     /*
      * Generic 32-bit binary operation.  Provide an "instr" line that
      * specifies an instruction that performs "result = r0 op r1".
@@ -4332,6 +4805,9 @@ dalvik_inst:
     beq     common_errDivideByZero
     .endif
 
+// begin WITH_TAINT_TRACKING
+    bl      .LOP_SHR_INT_taint_prop
+// end WITH_TAINT_TRACKING
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
     and     r1, r1, #31                           @ optional op; may set condition codes
     mov     r0, r0, asr r1                              @ r0<- op, r0-r3 changed
@@ -4341,11 +4817,12 @@ dalvik_inst:
     /* 11-14 instructions */
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_USHR_INT: /* 0x9a */
-/* File: armv5te/OP_USHR_INT.S */
-/* File: armv5te/binop.S */
+/* File: armv5te_taint/OP_USHR_INT.S */
+/* File: armv5te_taint/binop.S */
     /*
      * Generic 32-bit binary operation.  Provide an "instr" line that
      * specifies an instruction that performs "result = r0 op r1".
@@ -4373,6 +4850,9 @@ dalvik_inst:
     beq     common_errDivideByZero
     .endif
 
+// begin WITH_TAINT_TRACKING
+    bl      .LOP_USHR_INT_taint_prop
+// end WITH_TAINT_TRACKING
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
     and     r1, r1, #31                           @ optional op; may set condition codes
     mov     r0, r0, lsr r1                              @ r0<- op, r0-r3 changed
@@ -4382,11 +4862,12 @@ dalvik_inst:
     /* 11-14 instructions */
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_ADD_LONG: /* 0x9b */
-/* File: armv5te/OP_ADD_LONG.S */
-/* File: armv5te/binopWide.S */
+/* File: armv5te_taint/OP_ADD_LONG.S */
+/* File: armv5te_taint/binopWide.S */
     /*
      * Generic 64-bit binary operation.  Provide an "instr" line that
      * specifies an instruction that performs "result = r0-r1 op r2-r3".
@@ -4407,11 +4888,9 @@ dalvik_inst:
     mov     r9, rINST, lsr #8           @ r9<- AA
     and     r2, r0, #255                @ r2<- BB
     mov     r3, r0, lsr #8              @ r3<- CC
-    add     r9, rFP, r9, lsl #2         @ r9<- &fp[AA]
-    add     r2, rFP, r2, lsl #2         @ r2<- &fp[BB]
-    add     r3, rFP, r3, lsl #2         @ r3<- &fp[CC]
-    ldmia   r2, {r0-r1}                 @ r0/r1<- vBB/vBB+1
-    ldmia   r3, {r2-r3}                 @ r2/r3<- vCC/vCC+1
+// begin WITH_TAINT_TRACKING
+    bl      .LOP_ADD_LONG_taint_prop
+// end WITH_TAINT_TRACKING
     .if 0
     orrs    ip, r2, r3                  @ second arg (r2-r3) is zero?
     beq     common_errDivideByZero
@@ -4421,16 +4900,23 @@ dalvik_inst:
     adds    r0, r0, r2                           @ optional op; may set condition codes
     adc     r1, r1, r3                              @ result<- op, r0-r3 changed
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    stmia   r9, {r0,r1}     @ vAA/vAA+1<- r0/r1
+// begin WITH_TAINT_TRACKING
+//    stmia   r9, {r0,r1}     @ vAA/vAA+1<- r0/r1
+    str     r0, [r9, #0]
+    str     r10, [r9, #4]
+    str     r1, [r9, #8]
+    str     r10, [r9, #12]
+// end WITH_TAINT_TRACKING
     GOTO_OPCODE(ip)                     @ jump to next instruction
     /* 14-17 instructions */
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_SUB_LONG: /* 0x9c */
-/* File: armv5te/OP_SUB_LONG.S */
-/* File: armv5te/binopWide.S */
+/* File: armv5te_taint/OP_SUB_LONG.S */
+/* File: armv5te_taint/binopWide.S */
     /*
      * Generic 64-bit binary operation.  Provide an "instr" line that
      * specifies an instruction that performs "result = r0-r1 op r2-r3".
@@ -4451,11 +4937,9 @@ dalvik_inst:
     mov     r9, rINST, lsr #8           @ r9<- AA
     and     r2, r0, #255                @ r2<- BB
     mov     r3, r0, lsr #8              @ r3<- CC
-    add     r9, rFP, r9, lsl #2         @ r9<- &fp[AA]
-    add     r2, rFP, r2, lsl #2         @ r2<- &fp[BB]
-    add     r3, rFP, r3, lsl #2         @ r3<- &fp[CC]
-    ldmia   r2, {r0-r1}                 @ r0/r1<- vBB/vBB+1
-    ldmia   r3, {r2-r3}                 @ r2/r3<- vCC/vCC+1
+// begin WITH_TAINT_TRACKING
+    bl      .LOP_SUB_LONG_taint_prop
+// end WITH_TAINT_TRACKING
     .if 0
     orrs    ip, r2, r3                  @ second arg (r2-r3) is zero?
     beq     common_errDivideByZero
@@ -4465,15 +4949,22 @@ dalvik_inst:
     subs    r0, r0, r2                           @ optional op; may set condition codes
     sbc     r1, r1, r3                              @ result<- op, r0-r3 changed
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    stmia   r9, {r0,r1}     @ vAA/vAA+1<- r0/r1
+// begin WITH_TAINT_TRACKING
+//    stmia   r9, {r0,r1}     @ vAA/vAA+1<- r0/r1
+    str     r0, [r9, #0]
+    str     r10, [r9, #4]
+    str     r1, [r9, #8]
+    str     r10, [r9, #12]
+// end WITH_TAINT_TRACKING
     GOTO_OPCODE(ip)                     @ jump to next instruction
     /* 14-17 instructions */
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_MUL_LONG: /* 0x9d */
-/* File: armv5te/OP_MUL_LONG.S */
+/* File: armv5te_taint/OP_MUL_LONG.S */
     /*
      * Signed 64-bit integer multiply.
      *
@@ -4496,24 +4987,25 @@ dalvik_inst:
     FETCH(r0, 1)                        @ r0<- CCBB
     and     r2, r0, #255                @ r2<- BB
     mov     r3, r0, lsr #8              @ r3<- CC
-    add     r2, rFP, r2, lsl #2         @ r2<- &fp[BB]
-    add     r3, rFP, r3, lsl #2         @ r3<- &fp[CC]
-    ldmia   r2, {r0-r1}                 @ r0/r1<- vBB/vBB+1
-    ldmia   r3, {r2-r3}                 @ r2/r3<- vCC/vCC+1
+// begin WITH_TAINT_TRACKING
+    bl		mul_long_taint_prop
+// end WITH_TAINT_TRACKING
     mul     ip, r2, r1                  @  ip<- ZxW
     umull   r9, r10, r2, r0             @  r9/r10 <- ZxX
     mla     r2, r0, r3, ip              @  r2<- YxX + (ZxW)
     mov     r0, rINST, lsr #8           @ r0<- AA
     add     r10, r2, r10                @  r10<- r10 + low(ZxW + (YxX))
-    add     r0, rFP, r0, lsl #2         @ r0<- &fp[AA]
+// begin WITH_TAINT_TRACKING
+    add     r0, rFP, r0, lsl #3         @ r0<- &fp[AA]
+// end WITH_TAINT_TRACKING
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
     b       .LOP_MUL_LONG_finish
 
 /* ------------------------------ */
     .balign 64
 .L_OP_DIV_LONG: /* 0x9e */
-/* File: armv5te/OP_DIV_LONG.S */
-/* File: armv5te/binopWide.S */
+/* File: armv5te_taint/OP_DIV_LONG.S */
+/* File: armv5te_taint/binopWide.S */
     /*
      * Generic 64-bit binary operation.  Provide an "instr" line that
      * specifies an instruction that performs "result = r0-r1 op r2-r3".
@@ -4534,11 +5026,9 @@ dalvik_inst:
     mov     r9, rINST, lsr #8           @ r9<- AA
     and     r2, r0, #255                @ r2<- BB
     mov     r3, r0, lsr #8              @ r3<- CC
-    add     r9, rFP, r9, lsl #2         @ r9<- &fp[AA]
-    add     r2, rFP, r2, lsl #2         @ r2<- &fp[BB]
-    add     r3, rFP, r3, lsl #2         @ r3<- &fp[CC]
-    ldmia   r2, {r0-r1}                 @ r0/r1<- vBB/vBB+1
-    ldmia   r3, {r2-r3}                 @ r2/r3<- vCC/vCC+1
+// begin WITH_TAINT_TRACKING
+    bl      .LOP_DIV_LONG_taint_prop
+// end WITH_TAINT_TRACKING
     .if 1
     orrs    ip, r2, r3                  @ second arg (r2-r3) is zero?
     beq     common_errDivideByZero
@@ -4548,17 +5038,24 @@ dalvik_inst:
                                @ optional op; may set condition codes
     bl      __aeabi_ldivmod                              @ result<- op, r0-r3 changed
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    stmia   r9, {r0,r1}     @ vAA/vAA+1<- r0/r1
+// begin WITH_TAINT_TRACKING
+//    stmia   r9, {r0,r1}     @ vAA/vAA+1<- r0/r1
+    str     r0, [r9, #0]
+    str     r10, [r9, #4]
+    str     r1, [r9, #8]
+    str     r10, [r9, #12]
+// end WITH_TAINT_TRACKING
     GOTO_OPCODE(ip)                     @ jump to next instruction
     /* 14-17 instructions */
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_REM_LONG: /* 0x9f */
-/* File: armv5te/OP_REM_LONG.S */
+/* File: armv5te_taint/OP_REM_LONG.S */
 /* ldivmod returns quotient in r0/r1 and remainder in r2/r3 */
-/* File: armv5te/binopWide.S */
+/* File: armv5te_taint/binopWide.S */
     /*
      * Generic 64-bit binary operation.  Provide an "instr" line that
      * specifies an instruction that performs "result = r0-r1 op r2-r3".
@@ -4579,11 +5076,9 @@ dalvik_inst:
     mov     r9, rINST, lsr #8           @ r9<- AA
     and     r2, r0, #255                @ r2<- BB
     mov     r3, r0, lsr #8              @ r3<- CC
-    add     r9, rFP, r9, lsl #2         @ r9<- &fp[AA]
-    add     r2, rFP, r2, lsl #2         @ r2<- &fp[BB]
-    add     r3, rFP, r3, lsl #2         @ r3<- &fp[CC]
-    ldmia   r2, {r0-r1}                 @ r0/r1<- vBB/vBB+1
-    ldmia   r3, {r2-r3}                 @ r2/r3<- vCC/vCC+1
+// begin WITH_TAINT_TRACKING
+    bl      .LOP_REM_LONG_taint_prop
+// end WITH_TAINT_TRACKING
     .if 1
     orrs    ip, r2, r3                  @ second arg (r2-r3) is zero?
     beq     common_errDivideByZero
@@ -4593,16 +5088,23 @@ dalvik_inst:
                                @ optional op; may set condition codes
     bl      __aeabi_ldivmod                              @ result<- op, r0-r3 changed
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    stmia   r9, {r2,r3}     @ vAA/vAA+1<- r2/r3
+// begin WITH_TAINT_TRACKING
+//    stmia   r9, {r2,r3}     @ vAA/vAA+1<- r2/r3
+    str     r2, [r9, #0]
+    str     r10, [r9, #4]
+    str     r3, [r9, #8]
+    str     r10, [r9, #12]
+// end WITH_TAINT_TRACKING
     GOTO_OPCODE(ip)                     @ jump to next instruction
     /* 14-17 instructions */
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_AND_LONG: /* 0xa0 */
-/* File: armv5te/OP_AND_LONG.S */
-/* File: armv5te/binopWide.S */
+/* File: armv5te_taint/OP_AND_LONG.S */
+/* File: armv5te_taint/binopWide.S */
     /*
      * Generic 64-bit binary operation.  Provide an "instr" line that
      * specifies an instruction that performs "result = r0-r1 op r2-r3".
@@ -4623,11 +5125,9 @@ dalvik_inst:
     mov     r9, rINST, lsr #8           @ r9<- AA
     and     r2, r0, #255                @ r2<- BB
     mov     r3, r0, lsr #8              @ r3<- CC
-    add     r9, rFP, r9, lsl #2         @ r9<- &fp[AA]
-    add     r2, rFP, r2, lsl #2         @ r2<- &fp[BB]
-    add     r3, rFP, r3, lsl #2         @ r3<- &fp[CC]
-    ldmia   r2, {r0-r1}                 @ r0/r1<- vBB/vBB+1
-    ldmia   r3, {r2-r3}                 @ r2/r3<- vCC/vCC+1
+// begin WITH_TAINT_TRACKING
+    bl      .LOP_AND_LONG_taint_prop
+// end WITH_TAINT_TRACKING
     .if 0
     orrs    ip, r2, r3                  @ second arg (r2-r3) is zero?
     beq     common_errDivideByZero
@@ -4637,16 +5137,23 @@ dalvik_inst:
     and     r0, r0, r2                           @ optional op; may set condition codes
     and     r1, r1, r3                              @ result<- op, r0-r3 changed
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    stmia   r9, {r0,r1}     @ vAA/vAA+1<- r0/r1
+// begin WITH_TAINT_TRACKING
+//    stmia   r9, {r0,r1}     @ vAA/vAA+1<- r0/r1
+    str     r0, [r9, #0]
+    str     r10, [r9, #4]
+    str     r1, [r9, #8]
+    str     r10, [r9, #12]
+// end WITH_TAINT_TRACKING
     GOTO_OPCODE(ip)                     @ jump to next instruction
     /* 14-17 instructions */
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_OR_LONG: /* 0xa1 */
-/* File: armv5te/OP_OR_LONG.S */
-/* File: armv5te/binopWide.S */
+/* File: armv5te_taint/OP_OR_LONG.S */
+/* File: armv5te_taint/binopWide.S */
     /*
      * Generic 64-bit binary operation.  Provide an "instr" line that
      * specifies an instruction that performs "result = r0-r1 op r2-r3".
@@ -4667,11 +5174,9 @@ dalvik_inst:
     mov     r9, rINST, lsr #8           @ r9<- AA
     and     r2, r0, #255                @ r2<- BB
     mov     r3, r0, lsr #8              @ r3<- CC
-    add     r9, rFP, r9, lsl #2         @ r9<- &fp[AA]
-    add     r2, rFP, r2, lsl #2         @ r2<- &fp[BB]
-    add     r3, rFP, r3, lsl #2         @ r3<- &fp[CC]
-    ldmia   r2, {r0-r1}                 @ r0/r1<- vBB/vBB+1
-    ldmia   r3, {r2-r3}                 @ r2/r3<- vCC/vCC+1
+// begin WITH_TAINT_TRACKING
+    bl      .LOP_OR_LONG_taint_prop
+// end WITH_TAINT_TRACKING
     .if 0
     orrs    ip, r2, r3                  @ second arg (r2-r3) is zero?
     beq     common_errDivideByZero
@@ -4681,16 +5186,23 @@ dalvik_inst:
     orr     r0, r0, r2                           @ optional op; may set condition codes
     orr     r1, r1, r3                              @ result<- op, r0-r3 changed
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    stmia   r9, {r0,r1}     @ vAA/vAA+1<- r0/r1
+// begin WITH_TAINT_TRACKING
+//    stmia   r9, {r0,r1}     @ vAA/vAA+1<- r0/r1
+    str     r0, [r9, #0]
+    str     r10, [r9, #4]
+    str     r1, [r9, #8]
+    str     r10, [r9, #12]
+// end WITH_TAINT_TRACKING
     GOTO_OPCODE(ip)                     @ jump to next instruction
     /* 14-17 instructions */
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_XOR_LONG: /* 0xa2 */
-/* File: armv5te/OP_XOR_LONG.S */
-/* File: armv5te/binopWide.S */
+/* File: armv5te_taint/OP_XOR_LONG.S */
+/* File: armv5te_taint/binopWide.S */
     /*
      * Generic 64-bit binary operation.  Provide an "instr" line that
      * specifies an instruction that performs "result = r0-r1 op r2-r3".
@@ -4711,11 +5223,9 @@ dalvik_inst:
     mov     r9, rINST, lsr #8           @ r9<- AA
     and     r2, r0, #255                @ r2<- BB
     mov     r3, r0, lsr #8              @ r3<- CC
-    add     r9, rFP, r9, lsl #2         @ r9<- &fp[AA]
-    add     r2, rFP, r2, lsl #2         @ r2<- &fp[BB]
-    add     r3, rFP, r3, lsl #2         @ r3<- &fp[CC]
-    ldmia   r2, {r0-r1}                 @ r0/r1<- vBB/vBB+1
-    ldmia   r3, {r2-r3}                 @ r2/r3<- vCC/vCC+1
+// begin WITH_TAINT_TRACKING
+    bl      .LOP_XOR_LONG_taint_prop
+// end WITH_TAINT_TRACKING
     .if 0
     orrs    ip, r2, r3                  @ second arg (r2-r3) is zero?
     beq     common_errDivideByZero
@@ -4725,15 +5235,22 @@ dalvik_inst:
     eor     r0, r0, r2                           @ optional op; may set condition codes
     eor     r1, r1, r3                              @ result<- op, r0-r3 changed
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    stmia   r9, {r0,r1}     @ vAA/vAA+1<- r0/r1
+// begin WITH_TAINT_TRACKING
+//    stmia   r9, {r0,r1}     @ vAA/vAA+1<- r0/r1
+    str     r0, [r9, #0]
+    str     r10, [r9, #4]
+    str     r1, [r9, #8]
+    str     r10, [r9, #12]
+// end WITH_TAINT_TRACKING
     GOTO_OPCODE(ip)                     @ jump to next instruction
     /* 14-17 instructions */
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_SHL_LONG: /* 0xa3 */
-/* File: armv5te/OP_SHL_LONG.S */
+/* File: armv5te_taint/OP_SHL_LONG.S */
     /*
      * Long integer shift.  This is different from the generic 32/64-bit
      * binary operations because vAA/vBB are 64-bit but vCC (the shift
@@ -4745,11 +5262,9 @@ dalvik_inst:
     mov     r9, rINST, lsr #8           @ r9<- AA
     and     r3, r0, #255                @ r3<- BB
     mov     r0, r0, lsr #8              @ r0<- CC
-    add     r3, rFP, r3, lsl #2         @ r3<- &fp[BB]
-    GET_VREG(r2, r0)                    @ r2<- vCC
-    ldmia   r3, {r0-r1}                 @ r0/r1<- vBB/vBB+1
-    and     r2, r2, #63                 @ r2<- r2 & 0x3f
-    add     r9, rFP, r9, lsl #2         @ r9<- &fp[AA]
+// begin WITH_TAINT_TRACKING
+    bl      shl_long_taint_prop
+// end WITH_TAINT_TRACKING
 
     mov     r1, r1, asl r2              @  r1<- r1 << r2
     rsb     r3, r2, #32                 @  r3<- 32 - r2
@@ -4762,7 +5277,7 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_SHR_LONG: /* 0xa4 */
-/* File: armv5te/OP_SHR_LONG.S */
+/* File: armv5te_taint/OP_SHR_LONG.S */
     /*
      * Long integer shift.  This is different from the generic 32/64-bit
      * binary operations because vAA/vBB are 64-bit but vCC (the shift
@@ -4774,11 +5289,9 @@ dalvik_inst:
     mov     r9, rINST, lsr #8           @ r9<- AA
     and     r3, r0, #255                @ r3<- BB
     mov     r0, r0, lsr #8              @ r0<- CC
-    add     r3, rFP, r3, lsl #2         @ r3<- &fp[BB]
-    GET_VREG(r2, r0)                    @ r2<- vCC
-    ldmia   r3, {r0-r1}                 @ r0/r1<- vBB/vBB+1
-    and     r2, r2, #63                 @ r0<- r0 & 0x3f
-    add     r9, rFP, r9, lsl #2         @ r9<- &fp[AA]
+// begin WITH_TAINT_TRACKING
+    bl      shr_long_taint_prop
+// end WITH_TAINT_TRACKING
 
     mov     r0, r0, lsr r2              @  r0<- r2 >> r2
     rsb     r3, r2, #32                 @  r3<- 32 - r2
@@ -4791,7 +5304,7 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_USHR_LONG: /* 0xa5 */
-/* File: armv5te/OP_USHR_LONG.S */
+/* File: armv5te_taint/OP_USHR_LONG.S */
     /*
      * Long integer shift.  This is different from the generic 32/64-bit
      * binary operations because vAA/vBB are 64-bit but vCC (the shift
@@ -4803,11 +5316,9 @@ dalvik_inst:
     mov     r9, rINST, lsr #8           @ r9<- AA
     and     r3, r0, #255                @ r3<- BB
     mov     r0, r0, lsr #8              @ r0<- CC
-    add     r3, rFP, r3, lsl #2         @ r3<- &fp[BB]
-    GET_VREG(r2, r0)                    @ r2<- vCC
-    ldmia   r3, {r0-r1}                 @ r0/r1<- vBB/vBB+1
-    and     r2, r2, #63                 @ r0<- r0 & 0x3f
-    add     r9, rFP, r9, lsl #2         @ r9<- &fp[AA]
+// begin WITH_TAINT_TRACKING
+    bl      ushr_long_taint_prop
+// end WITH_TAINT_TRACKING
 
     mov     r0, r0, lsr r2              @  r0<- r2 >> r2
     rsb     r3, r2, #32                 @  r3<- 32 - r2
@@ -4820,8 +5331,8 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_ADD_FLOAT: /* 0xa6 */
-/* File: arm-vfp/OP_ADD_FLOAT.S */
-/* File: arm-vfp/fbinop.S */
+/* File: arm-vfp_taint/OP_ADD_FLOAT.S */
+/* File: arm-vfp_taint/fbinop.S */
     /*
      * Generic 32-bit floating-point operation.  Provide an "instr" line that
      * specifies an instruction that performs "s2 = s0 op s1".  Because we
@@ -4838,20 +5349,19 @@ dalvik_inst:
     VREG_INDEX_TO_ADDR(r2, r2)          @ r2<- &vBB
     flds    s1, [r3]                    @ s1<- vCC
     flds    s0, [r2]                    @ s0<- vBB
-
-    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
-    fadds   s2, s0, s1                              @ s2<- op
-    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    VREG_INDEX_TO_ADDR(r9, r9)          @ r9<- &vAA
-    fsts    s2, [r9]                    @ vAA<- s2
-    GOTO_OPCODE(ip)                     @ jump to next instruction
+// begin WITH_TAINT_TRACKING
+    ldr     r0, [r3, #4]
+    ldr     r1, [r2, #4]
+    orr     r0, r0, r1
+// end WITH_TAINT_TRACKING
+    b     .LOP_ADD_FLOAT_finish
 
 
 /* ------------------------------ */
     .balign 64
 .L_OP_SUB_FLOAT: /* 0xa7 */
-/* File: arm-vfp/OP_SUB_FLOAT.S */
-/* File: arm-vfp/fbinop.S */
+/* File: arm-vfp_taint/OP_SUB_FLOAT.S */
+/* File: arm-vfp_taint/fbinop.S */
     /*
      * Generic 32-bit floating-point operation.  Provide an "instr" line that
      * specifies an instruction that performs "s2 = s0 op s1".  Because we
@@ -4868,20 +5378,19 @@ dalvik_inst:
     VREG_INDEX_TO_ADDR(r2, r2)          @ r2<- &vBB
     flds    s1, [r3]                    @ s1<- vCC
     flds    s0, [r2]                    @ s0<- vBB
-
-    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
-    fsubs   s2, s0, s1                              @ s2<- op
-    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    VREG_INDEX_TO_ADDR(r9, r9)          @ r9<- &vAA
-    fsts    s2, [r9]                    @ vAA<- s2
-    GOTO_OPCODE(ip)                     @ jump to next instruction
+// begin WITH_TAINT_TRACKING
+    ldr     r0, [r3, #4]
+    ldr     r1, [r2, #4]
+    orr     r0, r0, r1
+// end WITH_TAINT_TRACKING
+    b     .LOP_SUB_FLOAT_finish
 
 
 /* ------------------------------ */
     .balign 64
 .L_OP_MUL_FLOAT: /* 0xa8 */
-/* File: arm-vfp/OP_MUL_FLOAT.S */
-/* File: arm-vfp/fbinop.S */
+/* File: arm-vfp_taint/OP_MUL_FLOAT.S */
+/* File: arm-vfp_taint/fbinop.S */
     /*
      * Generic 32-bit floating-point operation.  Provide an "instr" line that
      * specifies an instruction that performs "s2 = s0 op s1".  Because we
@@ -4898,20 +5407,19 @@ dalvik_inst:
     VREG_INDEX_TO_ADDR(r2, r2)          @ r2<- &vBB
     flds    s1, [r3]                    @ s1<- vCC
     flds    s0, [r2]                    @ s0<- vBB
-
-    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
-    fmuls   s2, s0, s1                              @ s2<- op
-    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    VREG_INDEX_TO_ADDR(r9, r9)          @ r9<- &vAA
-    fsts    s2, [r9]                    @ vAA<- s2
-    GOTO_OPCODE(ip)                     @ jump to next instruction
+// begin WITH_TAINT_TRACKING
+    ldr     r0, [r3, #4]
+    ldr     r1, [r2, #4]
+    orr     r0, r0, r1
+// end WITH_TAINT_TRACKING
+    b     .LOP_MUL_FLOAT_finish
 
 
 /* ------------------------------ */
     .balign 64
 .L_OP_DIV_FLOAT: /* 0xa9 */
-/* File: arm-vfp/OP_DIV_FLOAT.S */
-/* File: arm-vfp/fbinop.S */
+/* File: arm-vfp_taint/OP_DIV_FLOAT.S */
+/* File: arm-vfp_taint/fbinop.S */
     /*
      * Generic 32-bit floating-point operation.  Provide an "instr" line that
      * specifies an instruction that performs "s2 = s0 op s1".  Because we
@@ -4928,21 +5436,20 @@ dalvik_inst:
     VREG_INDEX_TO_ADDR(r2, r2)          @ r2<- &vBB
     flds    s1, [r3]                    @ s1<- vCC
     flds    s0, [r2]                    @ s0<- vBB
-
-    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
-    fdivs   s2, s0, s1                              @ s2<- op
-    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    VREG_INDEX_TO_ADDR(r9, r9)          @ r9<- &vAA
-    fsts    s2, [r9]                    @ vAA<- s2
-    GOTO_OPCODE(ip)                     @ jump to next instruction
+// begin WITH_TAINT_TRACKING
+    ldr     r0, [r3, #4]
+    ldr     r1, [r2, #4]
+    orr     r0, r0, r1
+// end WITH_TAINT_TRACKING
+    b     .LOP_DIV_FLOAT_finish
 
 
 /* ------------------------------ */
     .balign 64
 .L_OP_REM_FLOAT: /* 0xaa */
-/* File: armv5te/OP_REM_FLOAT.S */
+/* File: armv5te_taint/OP_REM_FLOAT.S */
 /* EABI doesn't define a float remainder function, but libm does */
-/* File: armv5te/binop.S */
+/* File: armv5te_taint/binop.S */
     /*
      * Generic 32-bit binary operation.  Provide an "instr" line that
      * specifies an instruction that performs "result = r0 op r1".
@@ -4970,6 +5477,9 @@ dalvik_inst:
     beq     common_errDivideByZero
     .endif
 
+// begin WITH_TAINT_TRACKING
+    bl      .LOP_REM_FLOAT_taint_prop
+// end WITH_TAINT_TRACKING
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
                                @ optional op; may set condition codes
     bl      fmodf                              @ r0<- op, r0-r3 changed
@@ -4979,11 +5489,12 @@ dalvik_inst:
     /* 11-14 instructions */
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_ADD_DOUBLE: /* 0xab */
-/* File: arm-vfp/OP_ADD_DOUBLE.S */
-/* File: arm-vfp/fbinopWide.S */
+/* File: arm-vfp_taint/OP_ADD_DOUBLE.S */
+/* File: arm-vfp_taint/fbinopWide.S */
     /*
      * Generic 64-bit double-precision floating point binary operation.
      * Provide an "instr" line that specifies an instruction that performs
@@ -4998,22 +5509,25 @@ dalvik_inst:
     and     r2, r0, #255                @ r2<- BB
     VREG_INDEX_TO_ADDR(r3, r3)          @ r3<- &vCC
     VREG_INDEX_TO_ADDR(r2, r2)          @ r2<- &vBB
-    fldd    d1, [r3]                    @ d1<- vCC
-    fldd    d0, [r2]                    @ d0<- vBB
-
-    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
-    faddd   d2, d0, d1                              @ s2<- op
-    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    VREG_INDEX_TO_ADDR(r9, r9)          @ r9<- &vAA
-    fstd    d2, [r9]                    @ vAA<- d2
-    GOTO_OPCODE(ip)                     @ jump to next instruction
+// begin WITH_TAINT_TRACKING
+//    fldd    d1, [r3]                    @ d1<- vCC
+//    fldd    d0, [r2]                    @ d0<- vBB
+    flds    s2, [r3]
+    flds    s3, [r3, #8]
+    flds    s0, [r2]
+    flds    s1, [r2, #8]
+    ldr     r0, [r3, #4]
+    ldr     r1, [r2, #4]
+    orr     r0, r0, r1
+// end WITH_TAINT_TRACKING
+    b     .LOP_ADD_DOUBLE_finish
 
 
 /* ------------------------------ */
     .balign 64
 .L_OP_SUB_DOUBLE: /* 0xac */
-/* File: arm-vfp/OP_SUB_DOUBLE.S */
-/* File: arm-vfp/fbinopWide.S */
+/* File: arm-vfp_taint/OP_SUB_DOUBLE.S */
+/* File: arm-vfp_taint/fbinopWide.S */
     /*
      * Generic 64-bit double-precision floating point binary operation.
      * Provide an "instr" line that specifies an instruction that performs
@@ -5028,22 +5542,25 @@ dalvik_inst:
     and     r2, r0, #255                @ r2<- BB
     VREG_INDEX_TO_ADDR(r3, r3)          @ r3<- &vCC
     VREG_INDEX_TO_ADDR(r2, r2)          @ r2<- &vBB
-    fldd    d1, [r3]                    @ d1<- vCC
-    fldd    d0, [r2]                    @ d0<- vBB
-
-    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
-    fsubd   d2, d0, d1                              @ s2<- op
-    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    VREG_INDEX_TO_ADDR(r9, r9)          @ r9<- &vAA
-    fstd    d2, [r9]                    @ vAA<- d2
-    GOTO_OPCODE(ip)                     @ jump to next instruction
+// begin WITH_TAINT_TRACKING
+//    fldd    d1, [r3]                    @ d1<- vCC
+//    fldd    d0, [r2]                    @ d0<- vBB
+    flds    s2, [r3]
+    flds    s3, [r3, #8]
+    flds    s0, [r2]
+    flds    s1, [r2, #8]
+    ldr     r0, [r3, #4]
+    ldr     r1, [r2, #4]
+    orr     r0, r0, r1
+// end WITH_TAINT_TRACKING
+    b     .LOP_SUB_DOUBLE_finish
 
 
 /* ------------------------------ */
     .balign 64
 .L_OP_MUL_DOUBLE: /* 0xad */
-/* File: arm-vfp/OP_MUL_DOUBLE.S */
-/* File: arm-vfp/fbinopWide.S */
+/* File: arm-vfp_taint/OP_MUL_DOUBLE.S */
+/* File: arm-vfp_taint/fbinopWide.S */
     /*
      * Generic 64-bit double-precision floating point binary operation.
      * Provide an "instr" line that specifies an instruction that performs
@@ -5058,22 +5575,25 @@ dalvik_inst:
     and     r2, r0, #255                @ r2<- BB
     VREG_INDEX_TO_ADDR(r3, r3)          @ r3<- &vCC
     VREG_INDEX_TO_ADDR(r2, r2)          @ r2<- &vBB
-    fldd    d1, [r3]                    @ d1<- vCC
-    fldd    d0, [r2]                    @ d0<- vBB
-
-    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
-    fmuld   d2, d0, d1                              @ s2<- op
-    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    VREG_INDEX_TO_ADDR(r9, r9)          @ r9<- &vAA
-    fstd    d2, [r9]                    @ vAA<- d2
-    GOTO_OPCODE(ip)                     @ jump to next instruction
+// begin WITH_TAINT_TRACKING
+//    fldd    d1, [r3]                    @ d1<- vCC
+//    fldd    d0, [r2]                    @ d0<- vBB
+    flds    s2, [r3]
+    flds    s3, [r3, #8]
+    flds    s0, [r2]
+    flds    s1, [r2, #8]
+    ldr     r0, [r3, #4]
+    ldr     r1, [r2, #4]
+    orr     r0, r0, r1
+// end WITH_TAINT_TRACKING
+    b     .LOP_MUL_DOUBLE_finish
 
 
 /* ------------------------------ */
     .balign 64
 .L_OP_DIV_DOUBLE: /* 0xae */
-/* File: arm-vfp/OP_DIV_DOUBLE.S */
-/* File: arm-vfp/fbinopWide.S */
+/* File: arm-vfp_taint/OP_DIV_DOUBLE.S */
+/* File: arm-vfp_taint/fbinopWide.S */
     /*
      * Generic 64-bit double-precision floating point binary operation.
      * Provide an "instr" line that specifies an instruction that performs
@@ -5088,23 +5608,26 @@ dalvik_inst:
     and     r2, r0, #255                @ r2<- BB
     VREG_INDEX_TO_ADDR(r3, r3)          @ r3<- &vCC
     VREG_INDEX_TO_ADDR(r2, r2)          @ r2<- &vBB
-    fldd    d1, [r3]                    @ d1<- vCC
-    fldd    d0, [r2]                    @ d0<- vBB
-
-    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
-    fdivd   d2, d0, d1                              @ s2<- op
-    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    VREG_INDEX_TO_ADDR(r9, r9)          @ r9<- &vAA
-    fstd    d2, [r9]                    @ vAA<- d2
-    GOTO_OPCODE(ip)                     @ jump to next instruction
+// begin WITH_TAINT_TRACKING
+//    fldd    d1, [r3]                    @ d1<- vCC
+//    fldd    d0, [r2]                    @ d0<- vBB
+    flds    s2, [r3]
+    flds    s3, [r3, #8]
+    flds    s0, [r2]
+    flds    s1, [r2, #8]
+    ldr     r0, [r3, #4]
+    ldr     r1, [r2, #4]
+    orr     r0, r0, r1
+// end WITH_TAINT_TRACKING
+    b     .LOP_DIV_DOUBLE_finish
 
 
 /* ------------------------------ */
     .balign 64
 .L_OP_REM_DOUBLE: /* 0xaf */
-/* File: armv5te/OP_REM_DOUBLE.S */
+/* File: armv5te_taint/OP_REM_DOUBLE.S */
 /* EABI doesn't define a double remainder function, but libm does */
-/* File: armv5te/binopWide.S */
+/* File: armv5te_taint/binopWide.S */
     /*
      * Generic 64-bit binary operation.  Provide an "instr" line that
      * specifies an instruction that performs "result = r0-r1 op r2-r3".
@@ -5125,11 +5648,9 @@ dalvik_inst:
     mov     r9, rINST, lsr #8           @ r9<- AA
     and     r2, r0, #255                @ r2<- BB
     mov     r3, r0, lsr #8              @ r3<- CC
-    add     r9, rFP, r9, lsl #2         @ r9<- &fp[AA]
-    add     r2, rFP, r2, lsl #2         @ r2<- &fp[BB]
-    add     r3, rFP, r3, lsl #2         @ r3<- &fp[CC]
-    ldmia   r2, {r0-r1}                 @ r0/r1<- vBB/vBB+1
-    ldmia   r3, {r2-r3}                 @ r2/r3<- vCC/vCC+1
+// begin WITH_TAINT_TRACKING
+    bl      .LOP_REM_DOUBLE_taint_prop
+// end WITH_TAINT_TRACKING
     .if 0
     orrs    ip, r2, r3                  @ second arg (r2-r3) is zero?
     beq     common_errDivideByZero
@@ -5139,16 +5660,23 @@ dalvik_inst:
                                @ optional op; may set condition codes
     bl      fmod                              @ result<- op, r0-r3 changed
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    stmia   r9, {r0,r1}     @ vAA/vAA+1<- r0/r1
+// begin WITH_TAINT_TRACKING
+//    stmia   r9, {r0,r1}     @ vAA/vAA+1<- r0/r1
+    str     r0, [r9, #0]
+    str     r10, [r9, #4]
+    str     r1, [r9, #8]
+    str     r10, [r9, #12]
+// end WITH_TAINT_TRACKING
     GOTO_OPCODE(ip)                     @ jump to next instruction
     /* 14-17 instructions */
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_ADD_INT_2ADDR: /* 0xb0 */
-/* File: armv6t2/OP_ADD_INT_2ADDR.S */
-/* File: armv6t2/binop2addr.S */
+/* File: armv6t2_taint/OP_ADD_INT_2ADDR.S */
+/* File: armv6t2_taint/binop2addr.S */
     /*
      * Generic 32-bit "/2addr" binary operation.  Provide an "instr" line
      * that specifies an instruction that performs "result = r0 op r1".
@@ -5172,6 +5700,10 @@ dalvik_inst:
     cmp     r1, #0                      @ is second operand zero?
     beq     common_errDivideByZero
     .endif
+
+// begin WITH_TAINT_TRACKING
+    bl      .LOP_ADD_INT_2ADDR_taint_prop
+// end WITH_TAINT_TRACKING
     FETCH_ADVANCE_INST(1)               @ advance rPC, load rINST
 
                                @ optional op; may set condition codes
@@ -5182,11 +5714,12 @@ dalvik_inst:
     /* 10-13 instructions */
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_SUB_INT_2ADDR: /* 0xb1 */
-/* File: armv6t2/OP_SUB_INT_2ADDR.S */
-/* File: armv6t2/binop2addr.S */
+/* File: armv6t2_taint/OP_SUB_INT_2ADDR.S */
+/* File: armv6t2_taint/binop2addr.S */
     /*
      * Generic 32-bit "/2addr" binary operation.  Provide an "instr" line
      * that specifies an instruction that performs "result = r0 op r1".
@@ -5210,6 +5743,10 @@ dalvik_inst:
     cmp     r1, #0                      @ is second operand zero?
     beq     common_errDivideByZero
     .endif
+
+// begin WITH_TAINT_TRACKING
+    bl      .LOP_SUB_INT_2ADDR_taint_prop
+// end WITH_TAINT_TRACKING
     FETCH_ADVANCE_INST(1)               @ advance rPC, load rINST
 
                                @ optional op; may set condition codes
@@ -5220,12 +5757,13 @@ dalvik_inst:
     /* 10-13 instructions */
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_MUL_INT_2ADDR: /* 0xb2 */
-/* File: armv6t2/OP_MUL_INT_2ADDR.S */
+/* File: armv6t2_taint/OP_MUL_INT_2ADDR.S */
 /* must be "mul r0, r1, r0" -- "r0, r0, r1" is illegal */
-/* File: armv6t2/binop2addr.S */
+/* File: armv6t2_taint/binop2addr.S */
     /*
      * Generic 32-bit "/2addr" binary operation.  Provide an "instr" line
      * that specifies an instruction that performs "result = r0 op r1".
@@ -5249,6 +5787,10 @@ dalvik_inst:
     cmp     r1, #0                      @ is second operand zero?
     beq     common_errDivideByZero
     .endif
+
+// begin WITH_TAINT_TRACKING
+    bl      .LOP_MUL_INT_2ADDR_taint_prop
+// end WITH_TAINT_TRACKING
     FETCH_ADVANCE_INST(1)               @ advance rPC, load rINST
 
                                @ optional op; may set condition codes
@@ -5259,11 +5801,12 @@ dalvik_inst:
     /* 10-13 instructions */
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_DIV_INT_2ADDR: /* 0xb3 */
-/* File: armv6t2/OP_DIV_INT_2ADDR.S */
-/* File: armv6t2/binop2addr.S */
+/* File: armv6t2_taint/OP_DIV_INT_2ADDR.S */
+/* File: armv6t2_taint/binop2addr.S */
     /*
      * Generic 32-bit "/2addr" binary operation.  Provide an "instr" line
      * that specifies an instruction that performs "result = r0 op r1".
@@ -5287,6 +5830,10 @@ dalvik_inst:
     cmp     r1, #0                      @ is second operand zero?
     beq     common_errDivideByZero
     .endif
+
+// begin WITH_TAINT_TRACKING
+    bl      .LOP_DIV_INT_2ADDR_taint_prop
+// end WITH_TAINT_TRACKING
     FETCH_ADVANCE_INST(1)               @ advance rPC, load rINST
 
                                @ optional op; may set condition codes
@@ -5297,12 +5844,13 @@ dalvik_inst:
     /* 10-13 instructions */
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_REM_INT_2ADDR: /* 0xb4 */
-/* File: armv6t2/OP_REM_INT_2ADDR.S */
+/* File: armv6t2_taint/OP_REM_INT_2ADDR.S */
 /* idivmod returns quotient in r0 and remainder in r1 */
-/* File: armv6t2/binop2addr.S */
+/* File: armv6t2_taint/binop2addr.S */
     /*
      * Generic 32-bit "/2addr" binary operation.  Provide an "instr" line
      * that specifies an instruction that performs "result = r0 op r1".
@@ -5326,6 +5874,10 @@ dalvik_inst:
     cmp     r1, #0                      @ is second operand zero?
     beq     common_errDivideByZero
     .endif
+
+// begin WITH_TAINT_TRACKING
+    bl      .LOP_REM_INT_2ADDR_taint_prop
+// end WITH_TAINT_TRACKING
     FETCH_ADVANCE_INST(1)               @ advance rPC, load rINST
 
                                @ optional op; may set condition codes
@@ -5336,11 +5888,12 @@ dalvik_inst:
     /* 10-13 instructions */
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_AND_INT_2ADDR: /* 0xb5 */
-/* File: armv6t2/OP_AND_INT_2ADDR.S */
-/* File: armv6t2/binop2addr.S */
+/* File: armv6t2_taint/OP_AND_INT_2ADDR.S */
+/* File: armv6t2_taint/binop2addr.S */
     /*
      * Generic 32-bit "/2addr" binary operation.  Provide an "instr" line
      * that specifies an instruction that performs "result = r0 op r1".
@@ -5364,6 +5917,10 @@ dalvik_inst:
     cmp     r1, #0                      @ is second operand zero?
     beq     common_errDivideByZero
     .endif
+
+// begin WITH_TAINT_TRACKING
+    bl      .LOP_AND_INT_2ADDR_taint_prop
+// end WITH_TAINT_TRACKING
     FETCH_ADVANCE_INST(1)               @ advance rPC, load rINST
 
                                @ optional op; may set condition codes
@@ -5374,11 +5931,12 @@ dalvik_inst:
     /* 10-13 instructions */
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_OR_INT_2ADDR: /* 0xb6 */
-/* File: armv6t2/OP_OR_INT_2ADDR.S */
-/* File: armv6t2/binop2addr.S */
+/* File: armv6t2_taint/OP_OR_INT_2ADDR.S */
+/* File: armv6t2_taint/binop2addr.S */
     /*
      * Generic 32-bit "/2addr" binary operation.  Provide an "instr" line
      * that specifies an instruction that performs "result = r0 op r1".
@@ -5402,6 +5960,10 @@ dalvik_inst:
     cmp     r1, #0                      @ is second operand zero?
     beq     common_errDivideByZero
     .endif
+
+// begin WITH_TAINT_TRACKING
+    bl      .LOP_OR_INT_2ADDR_taint_prop
+// end WITH_TAINT_TRACKING
     FETCH_ADVANCE_INST(1)               @ advance rPC, load rINST
 
                                @ optional op; may set condition codes
@@ -5412,11 +5974,12 @@ dalvik_inst:
     /* 10-13 instructions */
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_XOR_INT_2ADDR: /* 0xb7 */
-/* File: armv6t2/OP_XOR_INT_2ADDR.S */
-/* File: armv6t2/binop2addr.S */
+/* File: armv6t2_taint/OP_XOR_INT_2ADDR.S */
+/* File: armv6t2_taint/binop2addr.S */
     /*
      * Generic 32-bit "/2addr" binary operation.  Provide an "instr" line
      * that specifies an instruction that performs "result = r0 op r1".
@@ -5440,6 +6003,10 @@ dalvik_inst:
     cmp     r1, #0                      @ is second operand zero?
     beq     common_errDivideByZero
     .endif
+
+// begin WITH_TAINT_TRACKING
+    bl      .LOP_XOR_INT_2ADDR_taint_prop
+// end WITH_TAINT_TRACKING
     FETCH_ADVANCE_INST(1)               @ advance rPC, load rINST
 
                                @ optional op; may set condition codes
@@ -5450,11 +6017,12 @@ dalvik_inst:
     /* 10-13 instructions */
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_SHL_INT_2ADDR: /* 0xb8 */
-/* File: armv6t2/OP_SHL_INT_2ADDR.S */
-/* File: armv6t2/binop2addr.S */
+/* File: armv6t2_taint/OP_SHL_INT_2ADDR.S */
+/* File: armv6t2_taint/binop2addr.S */
     /*
      * Generic 32-bit "/2addr" binary operation.  Provide an "instr" line
      * that specifies an instruction that performs "result = r0 op r1".
@@ -5478,6 +6046,10 @@ dalvik_inst:
     cmp     r1, #0                      @ is second operand zero?
     beq     common_errDivideByZero
     .endif
+
+// begin WITH_TAINT_TRACKING
+    bl      .LOP_SHL_INT_2ADDR_taint_prop
+// end WITH_TAINT_TRACKING
     FETCH_ADVANCE_INST(1)               @ advance rPC, load rINST
 
     and     r1, r1, #31                           @ optional op; may set condition codes
@@ -5488,11 +6060,12 @@ dalvik_inst:
     /* 10-13 instructions */
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_SHR_INT_2ADDR: /* 0xb9 */
-/* File: armv6t2/OP_SHR_INT_2ADDR.S */
-/* File: armv6t2/binop2addr.S */
+/* File: armv6t2_taint/OP_SHR_INT_2ADDR.S */
+/* File: armv6t2_taint/binop2addr.S */
     /*
      * Generic 32-bit "/2addr" binary operation.  Provide an "instr" line
      * that specifies an instruction that performs "result = r0 op r1".
@@ -5516,6 +6089,10 @@ dalvik_inst:
     cmp     r1, #0                      @ is second operand zero?
     beq     common_errDivideByZero
     .endif
+
+// begin WITH_TAINT_TRACKING
+    bl      .LOP_SHR_INT_2ADDR_taint_prop
+// end WITH_TAINT_TRACKING
     FETCH_ADVANCE_INST(1)               @ advance rPC, load rINST
 
     and     r1, r1, #31                           @ optional op; may set condition codes
@@ -5526,11 +6103,12 @@ dalvik_inst:
     /* 10-13 instructions */
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_USHR_INT_2ADDR: /* 0xba */
-/* File: armv6t2/OP_USHR_INT_2ADDR.S */
-/* File: armv6t2/binop2addr.S */
+/* File: armv6t2_taint/OP_USHR_INT_2ADDR.S */
+/* File: armv6t2_taint/binop2addr.S */
     /*
      * Generic 32-bit "/2addr" binary operation.  Provide an "instr" line
      * that specifies an instruction that performs "result = r0 op r1".
@@ -5554,6 +6132,10 @@ dalvik_inst:
     cmp     r1, #0                      @ is second operand zero?
     beq     common_errDivideByZero
     .endif
+
+// begin WITH_TAINT_TRACKING
+    bl      .LOP_USHR_INT_2ADDR_taint_prop
+// end WITH_TAINT_TRACKING
     FETCH_ADVANCE_INST(1)               @ advance rPC, load rINST
 
     and     r1, r1, #31                           @ optional op; may set condition codes
@@ -5564,11 +6146,12 @@ dalvik_inst:
     /* 10-13 instructions */
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_ADD_LONG_2ADDR: /* 0xbb */
-/* File: armv6t2/OP_ADD_LONG_2ADDR.S */
-/* File: armv6t2/binopWide2addr.S */
+/* File: armv6t2_taint/OP_ADD_LONG_2ADDR.S */
+/* File: armv6t2_taint/binopWide2addr.S */
     /*
      * Generic 64-bit "/2addr" binary operation.  Provide an "instr" line
      * that specifies an instruction that performs "result = r0-r1 op r2-r3".
@@ -5586,10 +6169,9 @@ dalvik_inst:
     /* binop/2addr vA, vB */
     mov     r1, rINST, lsr #12          @ r1<- B
     ubfx    r9, rINST, #8, #4           @ r9<- A
-    add     r1, rFP, r1, lsl #2         @ r1<- &fp[B]
-    add     r9, rFP, r9, lsl #2         @ r9<- &fp[A]
-    ldmia   r1, {r2-r3}                 @ r2/r3<- vBB/vBB+1
-    ldmia   r9, {r0-r1}                 @ r0/r1<- vAA/vAA+1
+// begin WITH_TAINT_TRACKING
+    bl     .LOP_ADD_LONG_2ADDR_taint_prop
+// end WITH_TAINT_TRACKING
     .if 0
     orrs    ip, r2, r3                  @ second arg (r2-r3) is zero?
     beq     common_errDivideByZero
@@ -5599,16 +6181,23 @@ dalvik_inst:
     adds    r0, r0, r2                           @ optional op; may set condition codes
     adc     r1, r1, r3                              @ result<- op, r0-r3 changed
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    stmia   r9, {r0,r1}     @ vAA/vAA+1<- r0/r1
+// begin WITH_TAINT_TRACKING
+//    stmia   r9, {r0,r1}     @ vAA/vAA+1<- r0/r1
+    str     r0, [r9, #0]
+    str     r10, [r9, #4]
+    str     r1, [r9, #8]
+    str     r10, [r9, #12]
+// end WITH_TAINT_TRACKING
     GOTO_OPCODE(ip)                     @ jump to next instruction
     /* 12-15 instructions */
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_SUB_LONG_2ADDR: /* 0xbc */
-/* File: armv6t2/OP_SUB_LONG_2ADDR.S */
-/* File: armv6t2/binopWide2addr.S */
+/* File: armv6t2_taint/OP_SUB_LONG_2ADDR.S */
+/* File: armv6t2_taint/binopWide2addr.S */
     /*
      * Generic 64-bit "/2addr" binary operation.  Provide an "instr" line
      * that specifies an instruction that performs "result = r0-r1 op r2-r3".
@@ -5626,10 +6215,9 @@ dalvik_inst:
     /* binop/2addr vA, vB */
     mov     r1, rINST, lsr #12          @ r1<- B
     ubfx    r9, rINST, #8, #4           @ r9<- A
-    add     r1, rFP, r1, lsl #2         @ r1<- &fp[B]
-    add     r9, rFP, r9, lsl #2         @ r9<- &fp[A]
-    ldmia   r1, {r2-r3}                 @ r2/r3<- vBB/vBB+1
-    ldmia   r9, {r0-r1}                 @ r0/r1<- vAA/vAA+1
+// begin WITH_TAINT_TRACKING
+    bl     .LOP_SUB_LONG_2ADDR_taint_prop
+// end WITH_TAINT_TRACKING
     .if 0
     orrs    ip, r2, r3                  @ second arg (r2-r3) is zero?
     beq     common_errDivideByZero
@@ -5639,15 +6227,22 @@ dalvik_inst:
     subs    r0, r0, r2                           @ optional op; may set condition codes
     sbc     r1, r1, r3                              @ result<- op, r0-r3 changed
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    stmia   r9, {r0,r1}     @ vAA/vAA+1<- r0/r1
+// begin WITH_TAINT_TRACKING
+//    stmia   r9, {r0,r1}     @ vAA/vAA+1<- r0/r1
+    str     r0, [r9, #0]
+    str     r10, [r9, #4]
+    str     r1, [r9, #8]
+    str     r10, [r9, #12]
+// end WITH_TAINT_TRACKING
     GOTO_OPCODE(ip)                     @ jump to next instruction
     /* 12-15 instructions */
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_MUL_LONG_2ADDR: /* 0xbd */
-/* File: armv6t2/OP_MUL_LONG_2ADDR.S */
+/* File: armv6t2_taint/OP_MUL_LONG_2ADDR.S */
     /*
      * Signed 64-bit integer multiply, "/2addr" version.
      *
@@ -5658,26 +6253,31 @@ dalvik_inst:
      */
     /* mul-long/2addr vA, vB */
     mov     r1, rINST, lsr #12          @ r1<- B
-    ubfx    r9, rINST, #8, #4           @ r9<- A
-    add     r1, rFP, r1, lsl #2         @ r1<- &fp[B]
-    add     rINST, rFP, r9, lsl #2      @ rINST<- &fp[A]
-    ldmia   r1, {r2-r3}                 @ r2/r3<- vBB/vBB+1
-    ldmia   rINST, {r0-r1}              @ r0/r1<- vAA/vAA+1
-    mul     ip, r2, r1                  @  ip<- ZxW
+// begin WITH_TAINT_TRACKING
+    bl      mul_long_2addr_taint_prop
+// end WITH_TAINT_TRACKING
     umull   r9, r10, r2, r0             @  r9/r10 <- ZxX
     mla     r2, r0, r3, ip              @  r2<- YxX + (ZxW)
     mov     r0, rINST                   @ r0<- &fp[A] (free up rINST)
     FETCH_ADVANCE_INST(1)               @ advance rPC, load rINST
     add     r10, r2, r10                @  r10<- r10 + low(ZxW + (YxX))
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    stmia   r0, {r9-r10}                @ vAA/vAA+1<- r9/r10
+// begin WITH_TAINT_TRACKING
+//    stmia   r0, {r9-r10}                @ vAA/vAA+1<- r9/r10
+    str     r9, [r0, #0]
+    str     r10, [r0, #8]
+    str     r10, [r0, #12]
+    ldmfd   sp!, {r10}
+    str     r10, [r0, #4]
+// end WITH_TAINT_TRACKING
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_DIV_LONG_2ADDR: /* 0xbe */
-/* File: armv6t2/OP_DIV_LONG_2ADDR.S */
-/* File: armv6t2/binopWide2addr.S */
+/* File: armv6t2_taint/OP_DIV_LONG_2ADDR.S */
+/* File: armv6t2_taint/binopWide2addr.S */
     /*
      * Generic 64-bit "/2addr" binary operation.  Provide an "instr" line
      * that specifies an instruction that performs "result = r0-r1 op r2-r3".
@@ -5695,10 +6295,9 @@ dalvik_inst:
     /* binop/2addr vA, vB */
     mov     r1, rINST, lsr #12          @ r1<- B
     ubfx    r9, rINST, #8, #4           @ r9<- A
-    add     r1, rFP, r1, lsl #2         @ r1<- &fp[B]
-    add     r9, rFP, r9, lsl #2         @ r9<- &fp[A]
-    ldmia   r1, {r2-r3}                 @ r2/r3<- vBB/vBB+1
-    ldmia   r9, {r0-r1}                 @ r0/r1<- vAA/vAA+1
+// begin WITH_TAINT_TRACKING
+    bl     .LOP_DIV_LONG_2ADDR_taint_prop
+// end WITH_TAINT_TRACKING
     .if 1
     orrs    ip, r2, r3                  @ second arg (r2-r3) is zero?
     beq     common_errDivideByZero
@@ -5708,17 +6307,24 @@ dalvik_inst:
                                @ optional op; may set condition codes
     bl      __aeabi_ldivmod                              @ result<- op, r0-r3 changed
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    stmia   r9, {r0,r1}     @ vAA/vAA+1<- r0/r1
+// begin WITH_TAINT_TRACKING
+//    stmia   r9, {r0,r1}     @ vAA/vAA+1<- r0/r1
+    str     r0, [r9, #0]
+    str     r10, [r9, #4]
+    str     r1, [r9, #8]
+    str     r10, [r9, #12]
+// end WITH_TAINT_TRACKING
     GOTO_OPCODE(ip)                     @ jump to next instruction
     /* 12-15 instructions */
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_REM_LONG_2ADDR: /* 0xbf */
-/* File: armv6t2/OP_REM_LONG_2ADDR.S */
+/* File: armv6t2_taint/OP_REM_LONG_2ADDR.S */
 /* ldivmod returns quotient in r0/r1 and remainder in r2/r3 */
-/* File: armv6t2/binopWide2addr.S */
+/* File: armv6t2_taint/binopWide2addr.S */
     /*
      * Generic 64-bit "/2addr" binary operation.  Provide an "instr" line
      * that specifies an instruction that performs "result = r0-r1 op r2-r3".
@@ -5736,10 +6342,9 @@ dalvik_inst:
     /* binop/2addr vA, vB */
     mov     r1, rINST, lsr #12          @ r1<- B
     ubfx    r9, rINST, #8, #4           @ r9<- A
-    add     r1, rFP, r1, lsl #2         @ r1<- &fp[B]
-    add     r9, rFP, r9, lsl #2         @ r9<- &fp[A]
-    ldmia   r1, {r2-r3}                 @ r2/r3<- vBB/vBB+1
-    ldmia   r9, {r0-r1}                 @ r0/r1<- vAA/vAA+1
+// begin WITH_TAINT_TRACKING
+    bl     .LOP_REM_LONG_2ADDR_taint_prop
+// end WITH_TAINT_TRACKING
     .if 1
     orrs    ip, r2, r3                  @ second arg (r2-r3) is zero?
     beq     common_errDivideByZero
@@ -5749,16 +6354,23 @@ dalvik_inst:
                                @ optional op; may set condition codes
     bl      __aeabi_ldivmod                              @ result<- op, r0-r3 changed
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    stmia   r9, {r2,r3}     @ vAA/vAA+1<- r2/r3
+// begin WITH_TAINT_TRACKING
+//    stmia   r9, {r2,r3}     @ vAA/vAA+1<- r2/r3
+    str     r2, [r9, #0]
+    str     r10, [r9, #4]
+    str     r3, [r9, #8]
+    str     r10, [r9, #12]
+// end WITH_TAINT_TRACKING
     GOTO_OPCODE(ip)                     @ jump to next instruction
     /* 12-15 instructions */
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_AND_LONG_2ADDR: /* 0xc0 */
-/* File: armv6t2/OP_AND_LONG_2ADDR.S */
-/* File: armv6t2/binopWide2addr.S */
+/* File: armv6t2_taint/OP_AND_LONG_2ADDR.S */
+/* File: armv6t2_taint/binopWide2addr.S */
     /*
      * Generic 64-bit "/2addr" binary operation.  Provide an "instr" line
      * that specifies an instruction that performs "result = r0-r1 op r2-r3".
@@ -5776,10 +6388,9 @@ dalvik_inst:
     /* binop/2addr vA, vB */
     mov     r1, rINST, lsr #12          @ r1<- B
     ubfx    r9, rINST, #8, #4           @ r9<- A
-    add     r1, rFP, r1, lsl #2         @ r1<- &fp[B]
-    add     r9, rFP, r9, lsl #2         @ r9<- &fp[A]
-    ldmia   r1, {r2-r3}                 @ r2/r3<- vBB/vBB+1
-    ldmia   r9, {r0-r1}                 @ r0/r1<- vAA/vAA+1
+// begin WITH_TAINT_TRACKING
+    bl     .LOP_AND_LONG_2ADDR_taint_prop
+// end WITH_TAINT_TRACKING
     .if 0
     orrs    ip, r2, r3                  @ second arg (r2-r3) is zero?
     beq     common_errDivideByZero
@@ -5789,16 +6400,23 @@ dalvik_inst:
     and     r0, r0, r2                           @ optional op; may set condition codes
     and     r1, r1, r3                              @ result<- op, r0-r3 changed
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    stmia   r9, {r0,r1}     @ vAA/vAA+1<- r0/r1
+// begin WITH_TAINT_TRACKING
+//    stmia   r9, {r0,r1}     @ vAA/vAA+1<- r0/r1
+    str     r0, [r9, #0]
+    str     r10, [r9, #4]
+    str     r1, [r9, #8]
+    str     r10, [r9, #12]
+// end WITH_TAINT_TRACKING
     GOTO_OPCODE(ip)                     @ jump to next instruction
     /* 12-15 instructions */
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_OR_LONG_2ADDR: /* 0xc1 */
-/* File: armv6t2/OP_OR_LONG_2ADDR.S */
-/* File: armv6t2/binopWide2addr.S */
+/* File: armv6t2_taint/OP_OR_LONG_2ADDR.S */
+/* File: armv6t2_taint/binopWide2addr.S */
     /*
      * Generic 64-bit "/2addr" binary operation.  Provide an "instr" line
      * that specifies an instruction that performs "result = r0-r1 op r2-r3".
@@ -5816,10 +6434,9 @@ dalvik_inst:
     /* binop/2addr vA, vB */
     mov     r1, rINST, lsr #12          @ r1<- B
     ubfx    r9, rINST, #8, #4           @ r9<- A
-    add     r1, rFP, r1, lsl #2         @ r1<- &fp[B]
-    add     r9, rFP, r9, lsl #2         @ r9<- &fp[A]
-    ldmia   r1, {r2-r3}                 @ r2/r3<- vBB/vBB+1
-    ldmia   r9, {r0-r1}                 @ r0/r1<- vAA/vAA+1
+// begin WITH_TAINT_TRACKING
+    bl     .LOP_OR_LONG_2ADDR_taint_prop
+// end WITH_TAINT_TRACKING
     .if 0
     orrs    ip, r2, r3                  @ second arg (r2-r3) is zero?
     beq     common_errDivideByZero
@@ -5829,16 +6446,23 @@ dalvik_inst:
     orr     r0, r0, r2                           @ optional op; may set condition codes
     orr     r1, r1, r3                              @ result<- op, r0-r3 changed
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    stmia   r9, {r0,r1}     @ vAA/vAA+1<- r0/r1
+// begin WITH_TAINT_TRACKING
+//    stmia   r9, {r0,r1}     @ vAA/vAA+1<- r0/r1
+    str     r0, [r9, #0]
+    str     r10, [r9, #4]
+    str     r1, [r9, #8]
+    str     r10, [r9, #12]
+// end WITH_TAINT_TRACKING
     GOTO_OPCODE(ip)                     @ jump to next instruction
     /* 12-15 instructions */
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_XOR_LONG_2ADDR: /* 0xc2 */
-/* File: armv6t2/OP_XOR_LONG_2ADDR.S */
-/* File: armv6t2/binopWide2addr.S */
+/* File: armv6t2_taint/OP_XOR_LONG_2ADDR.S */
+/* File: armv6t2_taint/binopWide2addr.S */
     /*
      * Generic 64-bit "/2addr" binary operation.  Provide an "instr" line
      * that specifies an instruction that performs "result = r0-r1 op r2-r3".
@@ -5856,10 +6480,9 @@ dalvik_inst:
     /* binop/2addr vA, vB */
     mov     r1, rINST, lsr #12          @ r1<- B
     ubfx    r9, rINST, #8, #4           @ r9<- A
-    add     r1, rFP, r1, lsl #2         @ r1<- &fp[B]
-    add     r9, rFP, r9, lsl #2         @ r9<- &fp[A]
-    ldmia   r1, {r2-r3}                 @ r2/r3<- vBB/vBB+1
-    ldmia   r9, {r0-r1}                 @ r0/r1<- vAA/vAA+1
+// begin WITH_TAINT_TRACKING
+    bl     .LOP_XOR_LONG_2ADDR_taint_prop
+// end WITH_TAINT_TRACKING
     .if 0
     orrs    ip, r2, r3                  @ second arg (r2-r3) is zero?
     beq     common_errDivideByZero
@@ -5869,15 +6492,22 @@ dalvik_inst:
     eor     r0, r0, r2                           @ optional op; may set condition codes
     eor     r1, r1, r3                              @ result<- op, r0-r3 changed
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    stmia   r9, {r0,r1}     @ vAA/vAA+1<- r0/r1
+// begin WITH_TAINT_TRACKING
+//    stmia   r9, {r0,r1}     @ vAA/vAA+1<- r0/r1
+    str     r0, [r9, #0]
+    str     r10, [r9, #4]
+    str     r1, [r9, #8]
+    str     r10, [r9, #12]
+// end WITH_TAINT_TRACKING
     GOTO_OPCODE(ip)                     @ jump to next instruction
     /* 12-15 instructions */
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_SHL_LONG_2ADDR: /* 0xc3 */
-/* File: armv6t2/OP_SHL_LONG_2ADDR.S */
+/* File: armv6t2_taint/OP_SHL_LONG_2ADDR.S */
     /*
      * Long integer shift, 2addr version.  vA is 64-bit value/result, vB is
      * 32-bit shift distance.
@@ -5886,9 +6516,9 @@ dalvik_inst:
     mov     r3, rINST, lsr #12          @ r3<- B
     ubfx    r9, rINST, #8, #4           @ r9<- A
     GET_VREG(r2, r3)                    @ r2<- vB
-    add     r9, rFP, r9, lsl #2         @ r9<- &fp[A]
-    and     r2, r2, #63                 @ r2<- r2 & 0x3f
-    ldmia   r9, {r0-r1}                 @ r0/r1<- vAA/vAA+1
+// begin WITH_TAINT_TRACKING
+    bl      shl_long_2addr_taint_prop
+// end WITH_TAINT_TRACKING
 
     mov     r1, r1, asl r2              @  r1<- r1 << r2
     rsb     r3, r2, #32                 @  r3<- 32 - r2
@@ -5902,7 +6532,7 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_SHR_LONG_2ADDR: /* 0xc4 */
-/* File: armv6t2/OP_SHR_LONG_2ADDR.S */
+/* File: armv6t2_taint/OP_SHR_LONG_2ADDR.S */
     /*
      * Long integer shift, 2addr version.  vA is 64-bit value/result, vB is
      * 32-bit shift distance.
@@ -5911,9 +6541,9 @@ dalvik_inst:
     mov     r3, rINST, lsr #12          @ r3<- B
     ubfx    r9, rINST, #8, #4           @ r9<- A
     GET_VREG(r2, r3)                    @ r2<- vB
-    add     r9, rFP, r9, lsl #2         @ r9<- &fp[A]
-    and     r2, r2, #63                 @ r2<- r2 & 0x3f
-    ldmia   r9, {r0-r1}                 @ r0/r1<- vAA/vAA+1
+// begin WITH_TAINT_TRACKING
+    bl      shr_long_2addr_taint_prop
+// end WITH_TAINT_TRACKING
 
     mov     r0, r0, lsr r2              @  r0<- r2 >> r2
     rsb     r3, r2, #32                 @  r3<- 32 - r2
@@ -5927,7 +6557,7 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_USHR_LONG_2ADDR: /* 0xc5 */
-/* File: armv6t2/OP_USHR_LONG_2ADDR.S */
+/* File: armv6t2_taint/OP_USHR_LONG_2ADDR.S */
     /*
      * Long integer shift, 2addr version.  vA is 64-bit value/result, vB is
      * 32-bit shift distance.
@@ -5936,9 +6566,9 @@ dalvik_inst:
     mov     r3, rINST, lsr #12          @ r3<- B
     ubfx    r9, rINST, #8, #4           @ r9<- A
     GET_VREG(r2, r3)                    @ r2<- vB
-    add     r9, rFP, r9, lsl #2         @ r9<- &fp[A]
-    and     r2, r2, #63                 @ r2<- r2 & 0x3f
-    ldmia   r9, {r0-r1}                 @ r0/r1<- vAA/vAA+1
+// begin WITH_TAINT_TRACKING
+    bl      ushr_long_2addr_taint_prop
+// end WITH_TAINT_TRACKING
 
     mov     r0, r0, lsr r2              @  r0<- r2 >> r2
     rsb     r3, r2, #32                 @  r3<- 32 - r2
@@ -5952,8 +6582,8 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_ADD_FLOAT_2ADDR: /* 0xc6 */
-/* File: arm-vfp/OP_ADD_FLOAT_2ADDR.S */
-/* File: arm-vfp/fbinop2addr.S */
+/* File: arm-vfp_taint/OP_ADD_FLOAT_2ADDR.S */
+/* File: arm-vfp_taint/fbinop2addr.S */
     /*
      * Generic 32-bit floating point "/2addr" binary operation.  Provide
      * an "instr" line that specifies an instruction that performs
@@ -5967,21 +6597,24 @@ dalvik_inst:
     VREG_INDEX_TO_ADDR(r3, r3)          @ r3<- &vB
     and     r9, r9, #15                 @ r9<- A
     flds    s1, [r3]                    @ s1<- vB
+// begin WITH_TAINT_TRACKING
+    ldr     r0, [r3, #4]
+// end WITH_TAINT_TRACKING
     VREG_INDEX_TO_ADDR(r9, r9)          @ r9<- &vA
     FETCH_ADVANCE_INST(1)               @ advance rPC, load rINST
     flds    s0, [r9]                    @ s0<- vA
-
-    fadds   s2, s0, s1                              @ s2<- op
-    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    fsts    s2, [r9]                    @ vAA<- s2
-    GOTO_OPCODE(ip)                     @ jump to next instruction
+// begin WITH_TAINT_TRACKING
+    ldr     r1, [r9, #4]
+    orr     r0, r0, r1
+// end WITH_TAINT_TRACKING
+    b       .LOP_ADD_FLOAT_2ADDR_finish
 
 
 /* ------------------------------ */
     .balign 64
 .L_OP_SUB_FLOAT_2ADDR: /* 0xc7 */
-/* File: arm-vfp/OP_SUB_FLOAT_2ADDR.S */
-/* File: arm-vfp/fbinop2addr.S */
+/* File: arm-vfp_taint/OP_SUB_FLOAT_2ADDR.S */
+/* File: arm-vfp_taint/fbinop2addr.S */
     /*
      * Generic 32-bit floating point "/2addr" binary operation.  Provide
      * an "instr" line that specifies an instruction that performs
@@ -5995,21 +6628,24 @@ dalvik_inst:
     VREG_INDEX_TO_ADDR(r3, r3)          @ r3<- &vB
     and     r9, r9, #15                 @ r9<- A
     flds    s1, [r3]                    @ s1<- vB
+// begin WITH_TAINT_TRACKING
+    ldr     r0, [r3, #4]
+// end WITH_TAINT_TRACKING
     VREG_INDEX_TO_ADDR(r9, r9)          @ r9<- &vA
     FETCH_ADVANCE_INST(1)               @ advance rPC, load rINST
     flds    s0, [r9]                    @ s0<- vA
-
-    fsubs   s2, s0, s1                              @ s2<- op
-    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    fsts    s2, [r9]                    @ vAA<- s2
-    GOTO_OPCODE(ip)                     @ jump to next instruction
+// begin WITH_TAINT_TRACKING
+    ldr     r1, [r9, #4]
+    orr     r0, r0, r1
+// end WITH_TAINT_TRACKING
+    b       .LOP_SUB_FLOAT_2ADDR_finish
 
 
 /* ------------------------------ */
     .balign 64
 .L_OP_MUL_FLOAT_2ADDR: /* 0xc8 */
-/* File: arm-vfp/OP_MUL_FLOAT_2ADDR.S */
-/* File: arm-vfp/fbinop2addr.S */
+/* File: arm-vfp_taint/OP_MUL_FLOAT_2ADDR.S */
+/* File: arm-vfp_taint/fbinop2addr.S */
     /*
      * Generic 32-bit floating point "/2addr" binary operation.  Provide
      * an "instr" line that specifies an instruction that performs
@@ -6023,21 +6659,24 @@ dalvik_inst:
     VREG_INDEX_TO_ADDR(r3, r3)          @ r3<- &vB
     and     r9, r9, #15                 @ r9<- A
     flds    s1, [r3]                    @ s1<- vB
+// begin WITH_TAINT_TRACKING
+    ldr     r0, [r3, #4]
+// end WITH_TAINT_TRACKING
     VREG_INDEX_TO_ADDR(r9, r9)          @ r9<- &vA
     FETCH_ADVANCE_INST(1)               @ advance rPC, load rINST
     flds    s0, [r9]                    @ s0<- vA
-
-    fmuls   s2, s0, s1                              @ s2<- op
-    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    fsts    s2, [r9]                    @ vAA<- s2
-    GOTO_OPCODE(ip)                     @ jump to next instruction
+// begin WITH_TAINT_TRACKING
+    ldr     r1, [r9, #4]
+    orr     r0, r0, r1
+// end WITH_TAINT_TRACKING
+    b       .LOP_MUL_FLOAT_2ADDR_finish
 
 
 /* ------------------------------ */
     .balign 64
 .L_OP_DIV_FLOAT_2ADDR: /* 0xc9 */
-/* File: arm-vfp/OP_DIV_FLOAT_2ADDR.S */
-/* File: arm-vfp/fbinop2addr.S */
+/* File: arm-vfp_taint/OP_DIV_FLOAT_2ADDR.S */
+/* File: arm-vfp_taint/fbinop2addr.S */
     /*
      * Generic 32-bit floating point "/2addr" binary operation.  Provide
      * an "instr" line that specifies an instruction that performs
@@ -6051,22 +6690,25 @@ dalvik_inst:
     VREG_INDEX_TO_ADDR(r3, r3)          @ r3<- &vB
     and     r9, r9, #15                 @ r9<- A
     flds    s1, [r3]                    @ s1<- vB
+// begin WITH_TAINT_TRACKING
+    ldr     r0, [r3, #4]
+// end WITH_TAINT_TRACKING
     VREG_INDEX_TO_ADDR(r9, r9)          @ r9<- &vA
     FETCH_ADVANCE_INST(1)               @ advance rPC, load rINST
     flds    s0, [r9]                    @ s0<- vA
-
-    fdivs   s2, s0, s1                              @ s2<- op
-    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    fsts    s2, [r9]                    @ vAA<- s2
-    GOTO_OPCODE(ip)                     @ jump to next instruction
+// begin WITH_TAINT_TRACKING
+    ldr     r1, [r9, #4]
+    orr     r0, r0, r1
+// end WITH_TAINT_TRACKING
+    b       .LOP_DIV_FLOAT_2ADDR_finish
 
 
 /* ------------------------------ */
     .balign 64
 .L_OP_REM_FLOAT_2ADDR: /* 0xca */
-/* File: armv6t2/OP_REM_FLOAT_2ADDR.S */
+/* File: armv6t2_taint/OP_REM_FLOAT_2ADDR.S */
 /* EABI doesn't define a float remainder function, but libm does */
-/* File: armv6t2/binop2addr.S */
+/* File: armv6t2_taint/binop2addr.S */
     /*
      * Generic 32-bit "/2addr" binary operation.  Provide an "instr" line
      * that specifies an instruction that performs "result = r0 op r1".
@@ -6090,6 +6732,10 @@ dalvik_inst:
     cmp     r1, #0                      @ is second operand zero?
     beq     common_errDivideByZero
     .endif
+
+// begin WITH_TAINT_TRACKING
+    bl      .LOP_REM_FLOAT_2ADDR_taint_prop
+// end WITH_TAINT_TRACKING
     FETCH_ADVANCE_INST(1)               @ advance rPC, load rINST
 
                                @ optional op; may set condition codes
@@ -6100,11 +6746,12 @@ dalvik_inst:
     /* 10-13 instructions */
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_ADD_DOUBLE_2ADDR: /* 0xcb */
-/* File: arm-vfp/OP_ADD_DOUBLE_2ADDR.S */
-/* File: arm-vfp/fbinopWide2addr.S */
+/* File: arm-vfp_taint/OP_ADD_DOUBLE_2ADDR.S */
+/* File: arm-vfp_taint/fbinopWide2addr.S */
     /*
      * Generic 64-bit floating point "/2addr" binary operation.  Provide
      * an "instr" line that specifies an instruction that performs
@@ -6118,22 +6765,28 @@ dalvik_inst:
     mov     r9, rINST, lsr #8           @ r9<- A+
     VREG_INDEX_TO_ADDR(r3, r3)          @ r3<- &vB
     and     r9, r9, #15                 @ r9<- A
-    fldd    d1, [r3]                    @ d1<- vB
+// begin WITH_TAINT_TRACKING
+//    fldd    d1, [r3]                    @ d1<- vB
+    flds    s2, [r3]
+    flds    s3, [r3, #8]
+    ldr     r0, [r3, #4]
+// end WITH_TAINT_TRACKING
     VREG_INDEX_TO_ADDR(r9, r9)          @ r9<- &vA
     FETCH_ADVANCE_INST(1)               @ advance rPC, load rINST
-    fldd    d0, [r9]                    @ d0<- vA
-
-    faddd   d2, d0, d1                              @ d2<- op
-    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    fstd    d2, [r9]                    @ vAA<- d2
-    GOTO_OPCODE(ip)                     @ jump to next instruction
+// begin WITH_TAINT_TRACKING
+//    fldd    d0, [r9]                    @ d0<- vA
+    flds    s0, [r9]
+    flds    s1, [r9, #8]
+    ldr     r1, [r9, #4]
+// end WITH_TAINT_TRACKING
+    b     .LOP_ADD_DOUBLE_2ADDR_finish
 
 
 /* ------------------------------ */
     .balign 64
 .L_OP_SUB_DOUBLE_2ADDR: /* 0xcc */
-/* File: arm-vfp/OP_SUB_DOUBLE_2ADDR.S */
-/* File: arm-vfp/fbinopWide2addr.S */
+/* File: arm-vfp_taint/OP_SUB_DOUBLE_2ADDR.S */
+/* File: arm-vfp_taint/fbinopWide2addr.S */
     /*
      * Generic 64-bit floating point "/2addr" binary operation.  Provide
      * an "instr" line that specifies an instruction that performs
@@ -6147,22 +6800,28 @@ dalvik_inst:
     mov     r9, rINST, lsr #8           @ r9<- A+
     VREG_INDEX_TO_ADDR(r3, r3)          @ r3<- &vB
     and     r9, r9, #15                 @ r9<- A
-    fldd    d1, [r3]                    @ d1<- vB
+// begin WITH_TAINT_TRACKING
+//    fldd    d1, [r3]                    @ d1<- vB
+    flds    s2, [r3]
+    flds    s3, [r3, #8]
+    ldr     r0, [r3, #4]
+// end WITH_TAINT_TRACKING
     VREG_INDEX_TO_ADDR(r9, r9)          @ r9<- &vA
     FETCH_ADVANCE_INST(1)               @ advance rPC, load rINST
-    fldd    d0, [r9]                    @ d0<- vA
-
-    fsubd   d2, d0, d1                              @ d2<- op
-    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    fstd    d2, [r9]                    @ vAA<- d2
-    GOTO_OPCODE(ip)                     @ jump to next instruction
+// begin WITH_TAINT_TRACKING
+//    fldd    d0, [r9]                    @ d0<- vA
+    flds    s0, [r9]
+    flds    s1, [r9, #8]
+    ldr     r1, [r9, #4]
+// end WITH_TAINT_TRACKING
+    b     .LOP_SUB_DOUBLE_2ADDR_finish
 
 
 /* ------------------------------ */
     .balign 64
 .L_OP_MUL_DOUBLE_2ADDR: /* 0xcd */
-/* File: arm-vfp/OP_MUL_DOUBLE_2ADDR.S */
-/* File: arm-vfp/fbinopWide2addr.S */
+/* File: arm-vfp_taint/OP_MUL_DOUBLE_2ADDR.S */
+/* File: arm-vfp_taint/fbinopWide2addr.S */
     /*
      * Generic 64-bit floating point "/2addr" binary operation.  Provide
      * an "instr" line that specifies an instruction that performs
@@ -6176,22 +6835,28 @@ dalvik_inst:
     mov     r9, rINST, lsr #8           @ r9<- A+
     VREG_INDEX_TO_ADDR(r3, r3)          @ r3<- &vB
     and     r9, r9, #15                 @ r9<- A
-    fldd    d1, [r3]                    @ d1<- vB
+// begin WITH_TAINT_TRACKING
+//    fldd    d1, [r3]                    @ d1<- vB
+    flds    s2, [r3]
+    flds    s3, [r3, #8]
+    ldr     r0, [r3, #4]
+// end WITH_TAINT_TRACKING
     VREG_INDEX_TO_ADDR(r9, r9)          @ r9<- &vA
     FETCH_ADVANCE_INST(1)               @ advance rPC, load rINST
-    fldd    d0, [r9]                    @ d0<- vA
-
-    fmuld   d2, d0, d1                              @ d2<- op
-    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    fstd    d2, [r9]                    @ vAA<- d2
-    GOTO_OPCODE(ip)                     @ jump to next instruction
+// begin WITH_TAINT_TRACKING
+//    fldd    d0, [r9]                    @ d0<- vA
+    flds    s0, [r9]
+    flds    s1, [r9, #8]
+    ldr     r1, [r9, #4]
+// end WITH_TAINT_TRACKING
+    b     .LOP_MUL_DOUBLE_2ADDR_finish
 
 
 /* ------------------------------ */
     .balign 64
 .L_OP_DIV_DOUBLE_2ADDR: /* 0xce */
-/* File: arm-vfp/OP_DIV_DOUBLE_2ADDR.S */
-/* File: arm-vfp/fbinopWide2addr.S */
+/* File: arm-vfp_taint/OP_DIV_DOUBLE_2ADDR.S */
+/* File: arm-vfp_taint/fbinopWide2addr.S */
     /*
      * Generic 64-bit floating point "/2addr" binary operation.  Provide
      * an "instr" line that specifies an instruction that performs
@@ -6205,23 +6870,29 @@ dalvik_inst:
     mov     r9, rINST, lsr #8           @ r9<- A+
     VREG_INDEX_TO_ADDR(r3, r3)          @ r3<- &vB
     and     r9, r9, #15                 @ r9<- A
-    fldd    d1, [r3]                    @ d1<- vB
+// begin WITH_TAINT_TRACKING
+//    fldd    d1, [r3]                    @ d1<- vB
+    flds    s2, [r3]
+    flds    s3, [r3, #8]
+    ldr     r0, [r3, #4]
+// end WITH_TAINT_TRACKING
     VREG_INDEX_TO_ADDR(r9, r9)          @ r9<- &vA
     FETCH_ADVANCE_INST(1)               @ advance rPC, load rINST
-    fldd    d0, [r9]                    @ d0<- vA
-
-    fdivd   d2, d0, d1                              @ d2<- op
-    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    fstd    d2, [r9]                    @ vAA<- d2
-    GOTO_OPCODE(ip)                     @ jump to next instruction
+// begin WITH_TAINT_TRACKING
+//    fldd    d0, [r9]                    @ d0<- vA
+    flds    s0, [r9]
+    flds    s1, [r9, #8]
+    ldr     r1, [r9, #4]
+// end WITH_TAINT_TRACKING
+    b     .LOP_DIV_DOUBLE_2ADDR_finish
 
 
 /* ------------------------------ */
     .balign 64
 .L_OP_REM_DOUBLE_2ADDR: /* 0xcf */
-/* File: armv6t2/OP_REM_DOUBLE_2ADDR.S */
+/* File: armv6t2_taint/OP_REM_DOUBLE_2ADDR.S */
 /* EABI doesn't define a double remainder function, but libm does */
-/* File: armv6t2/binopWide2addr.S */
+/* File: armv6t2_taint/binopWide2addr.S */
     /*
      * Generic 64-bit "/2addr" binary operation.  Provide an "instr" line
      * that specifies an instruction that performs "result = r0-r1 op r2-r3".
@@ -6239,10 +6910,9 @@ dalvik_inst:
     /* binop/2addr vA, vB */
     mov     r1, rINST, lsr #12          @ r1<- B
     ubfx    r9, rINST, #8, #4           @ r9<- A
-    add     r1, rFP, r1, lsl #2         @ r1<- &fp[B]
-    add     r9, rFP, r9, lsl #2         @ r9<- &fp[A]
-    ldmia   r1, {r2-r3}                 @ r2/r3<- vBB/vBB+1
-    ldmia   r9, {r0-r1}                 @ r0/r1<- vAA/vAA+1
+// begin WITH_TAINT_TRACKING
+    bl     .LOP_REM_DOUBLE_2ADDR_taint_prop
+// end WITH_TAINT_TRACKING
     .if 0
     orrs    ip, r2, r3                  @ second arg (r2-r3) is zero?
     beq     common_errDivideByZero
@@ -6252,16 +6922,23 @@ dalvik_inst:
                                @ optional op; may set condition codes
     bl      fmod                              @ result<- op, r0-r3 changed
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    stmia   r9, {r0,r1}     @ vAA/vAA+1<- r0/r1
+// begin WITH_TAINT_TRACKING
+//    stmia   r9, {r0,r1}     @ vAA/vAA+1<- r0/r1
+    str     r0, [r9, #0]
+    str     r10, [r9, #4]
+    str     r1, [r9, #8]
+    str     r10, [r9, #12]
+// end WITH_TAINT_TRACKING
     GOTO_OPCODE(ip)                     @ jump to next instruction
     /* 12-15 instructions */
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_ADD_INT_LIT16: /* 0xd0 */
-/* File: armv6t2/OP_ADD_INT_LIT16.S */
-/* File: armv6t2/binopLit16.S */
+/* File: armv6t2_taint/OP_ADD_INT_LIT16.S */
+/* File: armv6t2_taint/binopLit16.S */
     /*
      * Generic 32-bit "lit16" binary operation.  Provide an "instr" line
      * that specifies an instruction that performs "result = r0 op r1".
@@ -6279,6 +6956,11 @@ dalvik_inst:
     mov     r2, rINST, lsr #12          @ r2<- B
     ubfx    r9, rINST, #8, #4           @ r9<- A
     GET_VREG(r0, r2)                    @ r0<- vB
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r3)                    @ r3<- rFP+4
+    GET_VREG_TAINT(r2, r2, r3)          @ r2<- vB.taint
+    SET_VREG_TAINT(r2, r9, r3)
+// end WITH_TAINT_TRACKING
     .if 0
     cmp     r1, #0                      @ is second operand zero?
     beq     common_errDivideByZero
@@ -6292,12 +6974,13 @@ dalvik_inst:
     /* 10-13 instructions */
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_RSUB_INT: /* 0xd1 */
-/* File: armv6t2/OP_RSUB_INT.S */
+/* File: armv6t2_taint/OP_RSUB_INT.S */
 /* this op is "rsub-int", but can be thought of as "rsub-int/lit16" */
-/* File: armv6t2/binopLit16.S */
+/* File: armv6t2_taint/binopLit16.S */
     /*
      * Generic 32-bit "lit16" binary operation.  Provide an "instr" line
      * that specifies an instruction that performs "result = r0 op r1".
@@ -6315,6 +6998,11 @@ dalvik_inst:
     mov     r2, rINST, lsr #12          @ r2<- B
     ubfx    r9, rINST, #8, #4           @ r9<- A
     GET_VREG(r0, r2)                    @ r0<- vB
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r3)                    @ r3<- rFP+4
+    GET_VREG_TAINT(r2, r2, r3)          @ r2<- vB.taint
+    SET_VREG_TAINT(r2, r9, r3)
+// end WITH_TAINT_TRACKING
     .if 0
     cmp     r1, #0                      @ is second operand zero?
     beq     common_errDivideByZero
@@ -6328,12 +7016,13 @@ dalvik_inst:
     /* 10-13 instructions */
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_MUL_INT_LIT16: /* 0xd2 */
-/* File: armv6t2/OP_MUL_INT_LIT16.S */
+/* File: armv6t2_taint/OP_MUL_INT_LIT16.S */
 /* must be "mul r0, r1, r0" -- "r0, r0, r1" is illegal */
-/* File: armv6t2/binopLit16.S */
+/* File: armv6t2_taint/binopLit16.S */
     /*
      * Generic 32-bit "lit16" binary operation.  Provide an "instr" line
      * that specifies an instruction that performs "result = r0 op r1".
@@ -6351,6 +7040,11 @@ dalvik_inst:
     mov     r2, rINST, lsr #12          @ r2<- B
     ubfx    r9, rINST, #8, #4           @ r9<- A
     GET_VREG(r0, r2)                    @ r0<- vB
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r3)                    @ r3<- rFP+4
+    GET_VREG_TAINT(r2, r2, r3)          @ r2<- vB.taint
+    SET_VREG_TAINT(r2, r9, r3)
+// end WITH_TAINT_TRACKING
     .if 0
     cmp     r1, #0                      @ is second operand zero?
     beq     common_errDivideByZero
@@ -6364,11 +7058,12 @@ dalvik_inst:
     /* 10-13 instructions */
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_DIV_INT_LIT16: /* 0xd3 */
-/* File: armv6t2/OP_DIV_INT_LIT16.S */
-/* File: armv6t2/binopLit16.S */
+/* File: armv6t2_taint/OP_DIV_INT_LIT16.S */
+/* File: armv6t2_taint/binopLit16.S */
     /*
      * Generic 32-bit "lit16" binary operation.  Provide an "instr" line
      * that specifies an instruction that performs "result = r0 op r1".
@@ -6386,6 +7081,11 @@ dalvik_inst:
     mov     r2, rINST, lsr #12          @ r2<- B
     ubfx    r9, rINST, #8, #4           @ r9<- A
     GET_VREG(r0, r2)                    @ r0<- vB
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r3)                    @ r3<- rFP+4
+    GET_VREG_TAINT(r2, r2, r3)          @ r2<- vB.taint
+    SET_VREG_TAINT(r2, r9, r3)
+// end WITH_TAINT_TRACKING
     .if 1
     cmp     r1, #0                      @ is second operand zero?
     beq     common_errDivideByZero
@@ -6399,12 +7099,13 @@ dalvik_inst:
     /* 10-13 instructions */
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_REM_INT_LIT16: /* 0xd4 */
-/* File: armv6t2/OP_REM_INT_LIT16.S */
+/* File: armv6t2_taint/OP_REM_INT_LIT16.S */
 /* idivmod returns quotient in r0 and remainder in r1 */
-/* File: armv6t2/binopLit16.S */
+/* File: armv6t2_taint/binopLit16.S */
     /*
      * Generic 32-bit "lit16" binary operation.  Provide an "instr" line
      * that specifies an instruction that performs "result = r0 op r1".
@@ -6422,6 +7123,11 @@ dalvik_inst:
     mov     r2, rINST, lsr #12          @ r2<- B
     ubfx    r9, rINST, #8, #4           @ r9<- A
     GET_VREG(r0, r2)                    @ r0<- vB
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r3)                    @ r3<- rFP+4
+    GET_VREG_TAINT(r2, r2, r3)          @ r2<- vB.taint
+    SET_VREG_TAINT(r2, r9, r3)
+// end WITH_TAINT_TRACKING
     .if 1
     cmp     r1, #0                      @ is second operand zero?
     beq     common_errDivideByZero
@@ -6435,11 +7141,12 @@ dalvik_inst:
     /* 10-13 instructions */
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_AND_INT_LIT16: /* 0xd5 */
-/* File: armv6t2/OP_AND_INT_LIT16.S */
-/* File: armv6t2/binopLit16.S */
+/* File: armv6t2_taint/OP_AND_INT_LIT16.S */
+/* File: armv6t2_taint/binopLit16.S */
     /*
      * Generic 32-bit "lit16" binary operation.  Provide an "instr" line
      * that specifies an instruction that performs "result = r0 op r1".
@@ -6457,6 +7164,11 @@ dalvik_inst:
     mov     r2, rINST, lsr #12          @ r2<- B
     ubfx    r9, rINST, #8, #4           @ r9<- A
     GET_VREG(r0, r2)                    @ r0<- vB
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r3)                    @ r3<- rFP+4
+    GET_VREG_TAINT(r2, r2, r3)          @ r2<- vB.taint
+    SET_VREG_TAINT(r2, r9, r3)
+// end WITH_TAINT_TRACKING
     .if 0
     cmp     r1, #0                      @ is second operand zero?
     beq     common_errDivideByZero
@@ -6470,11 +7182,12 @@ dalvik_inst:
     /* 10-13 instructions */
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_OR_INT_LIT16: /* 0xd6 */
-/* File: armv6t2/OP_OR_INT_LIT16.S */
-/* File: armv6t2/binopLit16.S */
+/* File: armv6t2_taint/OP_OR_INT_LIT16.S */
+/* File: armv6t2_taint/binopLit16.S */
     /*
      * Generic 32-bit "lit16" binary operation.  Provide an "instr" line
      * that specifies an instruction that performs "result = r0 op r1".
@@ -6492,6 +7205,11 @@ dalvik_inst:
     mov     r2, rINST, lsr #12          @ r2<- B
     ubfx    r9, rINST, #8, #4           @ r9<- A
     GET_VREG(r0, r2)                    @ r0<- vB
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r3)                    @ r3<- rFP+4
+    GET_VREG_TAINT(r2, r2, r3)          @ r2<- vB.taint
+    SET_VREG_TAINT(r2, r9, r3)
+// end WITH_TAINT_TRACKING
     .if 0
     cmp     r1, #0                      @ is second operand zero?
     beq     common_errDivideByZero
@@ -6505,11 +7223,12 @@ dalvik_inst:
     /* 10-13 instructions */
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_XOR_INT_LIT16: /* 0xd7 */
-/* File: armv6t2/OP_XOR_INT_LIT16.S */
-/* File: armv6t2/binopLit16.S */
+/* File: armv6t2_taint/OP_XOR_INT_LIT16.S */
+/* File: armv6t2_taint/binopLit16.S */
     /*
      * Generic 32-bit "lit16" binary operation.  Provide an "instr" line
      * that specifies an instruction that performs "result = r0 op r1".
@@ -6527,6 +7246,11 @@ dalvik_inst:
     mov     r2, rINST, lsr #12          @ r2<- B
     ubfx    r9, rINST, #8, #4           @ r9<- A
     GET_VREG(r0, r2)                    @ r0<- vB
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r3)                    @ r3<- rFP+4
+    GET_VREG_TAINT(r2, r2, r3)          @ r2<- vB.taint
+    SET_VREG_TAINT(r2, r9, r3)
+// end WITH_TAINT_TRACKING
     .if 0
     cmp     r1, #0                      @ is second operand zero?
     beq     common_errDivideByZero
@@ -6540,11 +7264,12 @@ dalvik_inst:
     /* 10-13 instructions */
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_ADD_INT_LIT8: /* 0xd8 */
-/* File: armv5te/OP_ADD_INT_LIT8.S */
-/* File: armv5te/binopLit8.S */
+/* File: armv5te_taint/OP_ADD_INT_LIT8.S */
+/* File: armv5te_taint/binopLit8.S */
     /*
      * Generic 32-bit "lit8" binary operation.  Provide an "instr" line
      * that specifies an instruction that performs "result = r0 op r1".
@@ -6568,6 +7293,11 @@ dalvik_inst:
     @cmp     r1, #0                      @ is second operand zero?
     beq     common_errDivideByZero
     .endif
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r10)                   @ r3<- rFP+4
+    GET_VREG_TAINT(r2, r2, r10)         @ r2<- vB.taint
+    SET_VREG_TAINT(r2, r9, r10)
+// end WITH_TAINT_TRACKING
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
 
                                @ optional op; may set condition codes
@@ -6578,11 +7308,12 @@ dalvik_inst:
     /* 10-12 instructions */
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_RSUB_INT_LIT8: /* 0xd9 */
-/* File: armv5te/OP_RSUB_INT_LIT8.S */
-/* File: armv5te/binopLit8.S */
+/* File: armv5te_taint/OP_RSUB_INT_LIT8.S */
+/* File: armv5te_taint/binopLit8.S */
     /*
      * Generic 32-bit "lit8" binary operation.  Provide an "instr" line
      * that specifies an instruction that performs "result = r0 op r1".
@@ -6606,6 +7337,11 @@ dalvik_inst:
     @cmp     r1, #0                      @ is second operand zero?
     beq     common_errDivideByZero
     .endif
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r10)                   @ r3<- rFP+4
+    GET_VREG_TAINT(r2, r2, r10)         @ r2<- vB.taint
+    SET_VREG_TAINT(r2, r9, r10)
+// end WITH_TAINT_TRACKING
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
 
                                @ optional op; may set condition codes
@@ -6616,12 +7352,13 @@ dalvik_inst:
     /* 10-12 instructions */
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_MUL_INT_LIT8: /* 0xda */
-/* File: armv5te/OP_MUL_INT_LIT8.S */
+/* File: armv5te_taint/OP_MUL_INT_LIT8.S */
 /* must be "mul r0, r1, r0" -- "r0, r0, r1" is illegal */
-/* File: armv5te/binopLit8.S */
+/* File: armv5te_taint/binopLit8.S */
     /*
      * Generic 32-bit "lit8" binary operation.  Provide an "instr" line
      * that specifies an instruction that performs "result = r0 op r1".
@@ -6645,6 +7382,11 @@ dalvik_inst:
     @cmp     r1, #0                      @ is second operand zero?
     beq     common_errDivideByZero
     .endif
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r10)                   @ r3<- rFP+4
+    GET_VREG_TAINT(r2, r2, r10)         @ r2<- vB.taint
+    SET_VREG_TAINT(r2, r9, r10)
+// end WITH_TAINT_TRACKING
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
 
                                @ optional op; may set condition codes
@@ -6655,11 +7397,12 @@ dalvik_inst:
     /* 10-12 instructions */
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_DIV_INT_LIT8: /* 0xdb */
-/* File: armv5te/OP_DIV_INT_LIT8.S */
-/* File: armv5te/binopLit8.S */
+/* File: armv5te_taint/OP_DIV_INT_LIT8.S */
+/* File: armv5te_taint/binopLit8.S */
     /*
      * Generic 32-bit "lit8" binary operation.  Provide an "instr" line
      * that specifies an instruction that performs "result = r0 op r1".
@@ -6683,6 +7426,11 @@ dalvik_inst:
     @cmp     r1, #0                      @ is second operand zero?
     beq     common_errDivideByZero
     .endif
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r10)                   @ r3<- rFP+4
+    GET_VREG_TAINT(r2, r2, r10)         @ r2<- vB.taint
+    SET_VREG_TAINT(r2, r9, r10)
+// end WITH_TAINT_TRACKING
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
 
                                @ optional op; may set condition codes
@@ -6693,12 +7441,13 @@ dalvik_inst:
     /* 10-12 instructions */
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_REM_INT_LIT8: /* 0xdc */
-/* File: armv5te/OP_REM_INT_LIT8.S */
+/* File: armv5te_taint/OP_REM_INT_LIT8.S */
 /* idivmod returns quotient in r0 and remainder in r1 */
-/* File: armv5te/binopLit8.S */
+/* File: armv5te_taint/binopLit8.S */
     /*
      * Generic 32-bit "lit8" binary operation.  Provide an "instr" line
      * that specifies an instruction that performs "result = r0 op r1".
@@ -6722,6 +7471,11 @@ dalvik_inst:
     @cmp     r1, #0                      @ is second operand zero?
     beq     common_errDivideByZero
     .endif
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r10)                   @ r3<- rFP+4
+    GET_VREG_TAINT(r2, r2, r10)         @ r2<- vB.taint
+    SET_VREG_TAINT(r2, r9, r10)
+// end WITH_TAINT_TRACKING
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
 
                                @ optional op; may set condition codes
@@ -6732,11 +7486,12 @@ dalvik_inst:
     /* 10-12 instructions */
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_AND_INT_LIT8: /* 0xdd */
-/* File: armv5te/OP_AND_INT_LIT8.S */
-/* File: armv5te/binopLit8.S */
+/* File: armv5te_taint/OP_AND_INT_LIT8.S */
+/* File: armv5te_taint/binopLit8.S */
     /*
      * Generic 32-bit "lit8" binary operation.  Provide an "instr" line
      * that specifies an instruction that performs "result = r0 op r1".
@@ -6760,6 +7515,11 @@ dalvik_inst:
     @cmp     r1, #0                      @ is second operand zero?
     beq     common_errDivideByZero
     .endif
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r10)                   @ r3<- rFP+4
+    GET_VREG_TAINT(r2, r2, r10)         @ r2<- vB.taint
+    SET_VREG_TAINT(r2, r9, r10)
+// end WITH_TAINT_TRACKING
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
 
                                @ optional op; may set condition codes
@@ -6770,11 +7530,12 @@ dalvik_inst:
     /* 10-12 instructions */
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_OR_INT_LIT8: /* 0xde */
-/* File: armv5te/OP_OR_INT_LIT8.S */
-/* File: armv5te/binopLit8.S */
+/* File: armv5te_taint/OP_OR_INT_LIT8.S */
+/* File: armv5te_taint/binopLit8.S */
     /*
      * Generic 32-bit "lit8" binary operation.  Provide an "instr" line
      * that specifies an instruction that performs "result = r0 op r1".
@@ -6798,6 +7559,11 @@ dalvik_inst:
     @cmp     r1, #0                      @ is second operand zero?
     beq     common_errDivideByZero
     .endif
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r10)                   @ r3<- rFP+4
+    GET_VREG_TAINT(r2, r2, r10)         @ r2<- vB.taint
+    SET_VREG_TAINT(r2, r9, r10)
+// end WITH_TAINT_TRACKING
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
 
                                @ optional op; may set condition codes
@@ -6808,11 +7574,12 @@ dalvik_inst:
     /* 10-12 instructions */
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_XOR_INT_LIT8: /* 0xdf */
-/* File: armv5te/OP_XOR_INT_LIT8.S */
-/* File: armv5te/binopLit8.S */
+/* File: armv5te_taint/OP_XOR_INT_LIT8.S */
+/* File: armv5te_taint/binopLit8.S */
     /*
      * Generic 32-bit "lit8" binary operation.  Provide an "instr" line
      * that specifies an instruction that performs "result = r0 op r1".
@@ -6836,6 +7603,11 @@ dalvik_inst:
     @cmp     r1, #0                      @ is second operand zero?
     beq     common_errDivideByZero
     .endif
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r10)                   @ r3<- rFP+4
+    GET_VREG_TAINT(r2, r2, r10)         @ r2<- vB.taint
+    SET_VREG_TAINT(r2, r9, r10)
+// end WITH_TAINT_TRACKING
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
 
                                @ optional op; may set condition codes
@@ -6846,11 +7618,12 @@ dalvik_inst:
     /* 10-12 instructions */
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_SHL_INT_LIT8: /* 0xe0 */
-/* File: armv5te/OP_SHL_INT_LIT8.S */
-/* File: armv5te/binopLit8.S */
+/* File: armv5te_taint/OP_SHL_INT_LIT8.S */
+/* File: armv5te_taint/binopLit8.S */
     /*
      * Generic 32-bit "lit8" binary operation.  Provide an "instr" line
      * that specifies an instruction that performs "result = r0 op r1".
@@ -6874,6 +7647,11 @@ dalvik_inst:
     @cmp     r1, #0                      @ is second operand zero?
     beq     common_errDivideByZero
     .endif
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r10)                   @ r3<- rFP+4
+    GET_VREG_TAINT(r2, r2, r10)         @ r2<- vB.taint
+    SET_VREG_TAINT(r2, r9, r10)
+// end WITH_TAINT_TRACKING
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
 
     and     r1, r1, #31                           @ optional op; may set condition codes
@@ -6884,11 +7662,12 @@ dalvik_inst:
     /* 10-12 instructions */
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_SHR_INT_LIT8: /* 0xe1 */
-/* File: armv5te/OP_SHR_INT_LIT8.S */
-/* File: armv5te/binopLit8.S */
+/* File: armv5te_taint/OP_SHR_INT_LIT8.S */
+/* File: armv5te_taint/binopLit8.S */
     /*
      * Generic 32-bit "lit8" binary operation.  Provide an "instr" line
      * that specifies an instruction that performs "result = r0 op r1".
@@ -6912,6 +7691,11 @@ dalvik_inst:
     @cmp     r1, #0                      @ is second operand zero?
     beq     common_errDivideByZero
     .endif
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r10)                   @ r3<- rFP+4
+    GET_VREG_TAINT(r2, r2, r10)         @ r2<- vB.taint
+    SET_VREG_TAINT(r2, r9, r10)
+// end WITH_TAINT_TRACKING
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
 
     and     r1, r1, #31                           @ optional op; may set condition codes
@@ -6922,11 +7706,12 @@ dalvik_inst:
     /* 10-12 instructions */
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_USHR_INT_LIT8: /* 0xe2 */
-/* File: armv5te/OP_USHR_INT_LIT8.S */
-/* File: armv5te/binopLit8.S */
+/* File: armv5te_taint/OP_USHR_INT_LIT8.S */
+/* File: armv5te_taint/binopLit8.S */
     /*
      * Generic 32-bit "lit8" binary operation.  Provide an "instr" line
      * that specifies an instruction that performs "result = r0 op r1".
@@ -6950,6 +7735,11 @@ dalvik_inst:
     @cmp     r1, #0                      @ is second operand zero?
     beq     common_errDivideByZero
     .endif
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r10)                   @ r3<- rFP+4
+    GET_VREG_TAINT(r2, r2, r10)         @ r2<- vB.taint
+    SET_VREG_TAINT(r2, r9, r10)
+// end WITH_TAINT_TRACKING
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
 
     and     r1, r1, #31                           @ optional op; may set condition codes
@@ -6960,11 +7750,14 @@ dalvik_inst:
     /* 10-12 instructions */
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_IGET_VOLATILE: /* 0xe3 */
-/* File: armv5te/OP_IGET_VOLATILE.S */
-/* File: armv5te/OP_IGET.S */
+/* File: armv5te_taint/OP_IGET_VOLATILE.S */
+/* File: armv5te_taint/OP_IGET.S */
+// begin WITH_TAINT_TRACKING
+// end WITH_TAINT_TRACKING
     /*
      * General 32-bit instance field get.
      *
@@ -6975,8 +7768,9 @@ dalvik_inst:
     ldr     r3, [rSELF, #offThread_methodClassDex]    @ r3<- DvmDex
     FETCH(r1, 1)                        @ r1<- field ref CCCC
     ldr     r2, [r3, #offDvmDex_pResFields] @ r2<- pDvmDex->pResFields
-    GET_VREG(r9, r0)                    @ r9<- fp[B], the object pointer
-    ldr     r0, [r2, r1, lsl #2]        @ r0<- resolved InstField ptr
+// begin WITH_TAINT_TRACKING
+    bl      .LOP_IGET_VOLATILE_taint_prop
+// end WITH_TAINT_TRACKING
     cmp     r0, #0                      @ is resolved entry null?
     bne     .LOP_IGET_VOLATILE_finish          @ no, already resolved
 8:  ldr     r2, [rSELF, #offThread_method]    @ r2<- current method
@@ -6991,8 +7785,10 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_IPUT_VOLATILE: /* 0xe4 */
-/* File: armv5te/OP_IPUT_VOLATILE.S */
-/* File: armv5te/OP_IPUT.S */
+/* File: armv5te_taint/OP_IPUT_VOLATILE.S */
+/* File: armv5te_taint/OP_IPUT.S */
+// begin WITH_TAINT_TRACKING
+// end WITH_TAINT_TRACKING
     /*
      * General 32-bit instance field put.
      *
@@ -7019,8 +7815,10 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_SGET_VOLATILE: /* 0xe5 */
-/* File: armv5te/OP_SGET_VOLATILE.S */
-/* File: armv5te/OP_SGET.S */
+/* File: armv5te_taint/OP_SGET_VOLATILE.S */
+/* File: armv5te_taint/OP_SGET.S */
+// begin WITH_TAINT_TRACKING
+// end WITH_TAINT_TRACKING
     /*
      * General 32-bit SGET handler.
      *
@@ -7034,11 +7832,11 @@ dalvik_inst:
     cmp     r0, #0                      @ is resolved entry null?
     beq     .LOP_SGET_VOLATILE_resolve         @ yes, do resolve
 .LOP_SGET_VOLATILE_finish: @ field ptr in r0
-    ldr     r1, [r0, #offStaticField_value] @ r1<- field value
-    SMP_DMB                            @ acquiring load
-    mov     r2, rINST, lsr #8           @ r2<- AA
+// begin WITH_TAINT_TRACKING
+    bl		.LOP_SGET_VOLATILE_taint_prop
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
-    SET_VREG(r1, r2)                    @ fp[AA]<- r1
+    SET_VREG(r0, r2)                    @ fp[AA]<- r0
+// end WITH_TAINT_TRACKING
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
@@ -7046,8 +7844,10 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_SPUT_VOLATILE: /* 0xe6 */
-/* File: armv5te/OP_SPUT_VOLATILE.S */
-/* File: armv5te/OP_SPUT.S */
+/* File: armv5te_taint/OP_SPUT_VOLATILE.S */
+/* File: armv5te_taint/OP_SPUT.S */
+// begin WITH_TAINT_TRACKING
+// end WITH_TAINT_TRACKING
     /*
      * General 32-bit SPUT handler.
      *
@@ -7065,17 +7865,19 @@ dalvik_inst:
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
     GET_VREG(r1, r2)                    @ r1<- fp[AA]
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    SMP_DMB_ST                        @ releasing store
-    str     r1, [r0, #offStaticField_value] @ field<- vAA
-    SMP_DMB
+// begin WITH_TAINT_TRACKING
+    bl      .LOP_SPUT_VOLATILE_taint_prop
+// end WITH_TAINT_TRACKING
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
 
 /* ------------------------------ */
     .balign 64
 .L_OP_IGET_OBJECT_VOLATILE: /* 0xe7 */
-/* File: armv5te/OP_IGET_OBJECT_VOLATILE.S */
-/* File: armv5te/OP_IGET.S */
+/* File: armv5te_taint/OP_IGET_OBJECT_VOLATILE.S */
+/* File: armv5te_taint/OP_IGET.S */
+// begin WITH_TAINT_TRACKING
+// end WITH_TAINT_TRACKING
     /*
      * General 32-bit instance field get.
      *
@@ -7086,8 +7888,9 @@ dalvik_inst:
     ldr     r3, [rSELF, #offThread_methodClassDex]    @ r3<- DvmDex
     FETCH(r1, 1)                        @ r1<- field ref CCCC
     ldr     r2, [r3, #offDvmDex_pResFields] @ r2<- pDvmDex->pResFields
-    GET_VREG(r9, r0)                    @ r9<- fp[B], the object pointer
-    ldr     r0, [r2, r1, lsl #2]        @ r0<- resolved InstField ptr
+// begin WITH_TAINT_TRACKING
+    bl      .LOP_IGET_OBJECT_VOLATILE_taint_prop
+// end WITH_TAINT_TRACKING
     cmp     r0, #0                      @ is resolved entry null?
     bne     .LOP_IGET_OBJECT_VOLATILE_finish          @ no, already resolved
 8:  ldr     r2, [rSELF, #offThread_method]    @ r2<- current method
@@ -7102,8 +7905,8 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_IGET_WIDE_VOLATILE: /* 0xe8 */
-/* File: armv5te/OP_IGET_WIDE_VOLATILE.S */
-/* File: armv5te/OP_IGET_WIDE.S */
+/* File: armv5te_taint/OP_IGET_WIDE_VOLATILE.S */
+/* File: armv5te_taint/OP_IGET_WIDE.S */
     /*
      * Wide 32-bit instance field get.
      */
@@ -7112,8 +7915,9 @@ dalvik_inst:
     ldr     r3, [rSELF, #offThread_methodClassDex]    @ r3<- DvmDex
     FETCH(r1, 1)                        @ r1<- field ref CCCC
     ldr     r2, [r3, #offDvmDex_pResFields] @ r2<- pResFields
-    GET_VREG(r9, r0)                    @ r9<- fp[B], the object pointer
-    ldr     r0, [r2, r1, lsl #2]        @ r0<- resolved InstField ptr
+// begin WITH_TAINT_TRACKING
+    bl      .LOP_IGET_WIDE_VOLATILE_taint_prop
+// end WITH_TAINT_TRACKING
     cmp     r0, #0                      @ is resolved entry null?
     bne     .LOP_IGET_WIDE_VOLATILE_finish          @ no, already resolved
 8:  ldr     r2, [rSELF, #offThread_method] @ r2<- current method
@@ -7128,8 +7932,8 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_IPUT_WIDE_VOLATILE: /* 0xe9 */
-/* File: armv5te/OP_IPUT_WIDE_VOLATILE.S */
-/* File: armv5te/OP_IPUT_WIDE.S */
+/* File: armv5te_taint/OP_IPUT_WIDE_VOLATILE.S */
+/* File: armv5te_taint/OP_IPUT_WIDE.S */
     /* iput-wide vA, vB, field@CCCC */
     mov     r0, rINST, lsr #12          @ r0<- B
     ldr     r3, [rSELF, #offThread_methodClassDex]    @ r3<- DvmDex
@@ -7151,8 +7955,8 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_SGET_WIDE_VOLATILE: /* 0xea */
-/* File: armv5te/OP_SGET_WIDE_VOLATILE.S */
-/* File: armv5te/OP_SGET_WIDE.S */
+/* File: armv5te_taint/OP_SGET_WIDE_VOLATILE.S */
+/* File: armv5te_taint/OP_SGET_WIDE.S */
     /*
      * 64-bit SGET handler.
      */
@@ -7163,26 +7967,15 @@ dalvik_inst:
     ldr     r0, [r10, r1, lsl #2]       @ r0<- resolved StaticField ptr
     cmp     r0, #0                      @ is resolved entry null?
     beq     .LOP_SGET_WIDE_VOLATILE_resolve         @ yes, do resolve
-.LOP_SGET_WIDE_VOLATILE_finish:
-    mov     r9, rINST, lsr #8           @ r9<- AA
-    .if 1
-    add     r0, r0, #offStaticField_value @ r0<- pointer to data
-    bl      dvmQuasiAtomicRead64        @ r0/r1<- contents of field
-    .else
-    ldrd    r0, [r0, #offStaticField_value] @ r0/r1<- field value (aligned)
-    .endif
-    add     r9, rFP, r9, lsl #2         @ r9<- &fp[AA]
-    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
-    stmia   r9, {r0-r1}                 @ vAA/vAA+1<- r0/r1
-    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    GOTO_OPCODE(ip)                     @ jump to next instruction
+    b		.LOP_SGET_WIDE_VOLATILE_finish
+
 
 
 /* ------------------------------ */
     .balign 64
 .L_OP_SPUT_WIDE_VOLATILE: /* 0xeb */
-/* File: armv5te/OP_SPUT_WIDE_VOLATILE.S */
-/* File: armv5te/OP_SPUT_WIDE.S */
+/* File: armv5te_taint/OP_SPUT_WIDE_VOLATILE.S */
+/* File: armv5te_taint/OP_SPUT_WIDE.S */
     /*
      * 64-bit SPUT handler.
      */
@@ -7192,13 +7985,20 @@ dalvik_inst:
     ldr     r10, [r0, #offDvmDex_pResFields] @ r10<- dvmDex->pResFields
     mov     r9, rINST, lsr #8           @ r9<- AA
     ldr     r2, [r10, r1, lsl #2]        @ r2<- resolved StaticField ptr
-    add     r9, rFP, r9, lsl #2         @ r9<- &fp[AA]
+// begin WITH_TAINT_TRACKING
+    add     r9, rFP, r9, lsl #3         @ r9<- &fp[AA]
+// end WITH_TAINT_TRACKING
     cmp     r2, #0                      @ is resolved entry null?
     beq     .LOP_SPUT_WIDE_VOLATILE_resolve         @ yes, do resolve
 .LOP_SPUT_WIDE_VOLATILE_finish: @ field ptr in r2, AA in r9
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
-    ldmia   r9, {r0-r1}                 @ r0/r1<- vAA/vAA+1
+// begin WITH_TAINT_TRACKING
+    bl		.LOP_SPUT_WIDE_VOLATILE_taint_prop
+// end WITH_TAINT_TRACKING
     GET_INST_OPCODE(r10)                @ extract opcode from rINST
+// begin WITH_TAINT_TRACKING
+    str	    r3, [r2, #offStaticField_taint]
+// end WITH_TAINT_TRACKING
     .if 1
     add     r2, r2, #offStaticField_value @ r2<- pointer to data
     bl      dvmQuasiAtomicSwap64Sync    @ stores r0/r1 into addr r2
@@ -7211,7 +8011,7 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_BREAKPOINT: /* 0xec */
-/* File: armv5te/OP_BREAKPOINT.S */
+/* File: armv5te_taint/OP_BREAKPOINT.S */
     /*
      * Breakpoint handler.
      *
@@ -7230,7 +8030,7 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_THROW_VERIFICATION_ERROR: /* 0xed */
-/* File: armv5te/OP_THROW_VERIFICATION_ERROR.S */
+/* File: armv5te_taint/OP_THROW_VERIFICATION_ERROR.S */
     /*
      * Handle a throw-verification-error instruction.  This throws an
      * exception for an error discovered during verification.  The
@@ -7247,7 +8047,7 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_EXECUTE_INLINE: /* 0xee */
-/* File: armv5te/OP_EXECUTE_INLINE.S */
+/* File: armv5te_taint/OP_EXECUTE_INLINE.S */
     /*
      * Execute a "native inline" instruction.
      *
@@ -7267,23 +8067,13 @@ dalvik_inst:
     EXPORT_PC()                         @ can throw
     ands    r2, #kSubModeDebugProfile   @ Any going on?
     bne     .LOP_EXECUTE_INLINE_debugmode       @ yes - take slow path
-.LOP_EXECUTE_INLINE_resume:
-    add     r1, rSELF, #offThread_retval  @ r1<- &self->retval
-    sub     sp, sp, #8                  @ make room for arg, +64 bit align
-    mov     r0, rINST, lsr #12          @ r0<- B
-    str     r1, [sp]                    @ push &self->retval
-    bl      .LOP_EXECUTE_INLINE_continue        @ make call; will return after
-    add     sp, sp, #8                  @ pop stack
-    cmp     r0, #0                      @ test boolean result of inline
-    beq     common_exceptionThrown      @ returned false, handle exception
-    FETCH_ADVANCE_INST(3)               @ advance rPC, load rINST
-    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    GOTO_OPCODE(ip)                     @ jump to next instruction
+// begin WITH_TAINT_TRACKING
+    b       .LOP_EXECUTE_INLINE_resume
 
 /* ------------------------------ */
     .balign 64
 .L_OP_EXECUTE_INLINE_RANGE: /* 0xef */
-/* File: armv5te/OP_EXECUTE_INLINE_RANGE.S */
+/* File: armv5te_taint/OP_EXECUTE_INLINE_RANGE.S */
     /*
      * Execute a "native inline" instruction, using "/range" semantics.
      * Same idea as execute-inline, but we get the args differently.
@@ -7301,23 +8091,13 @@ dalvik_inst:
     EXPORT_PC()                         @ can throw
     ands    r2, #kSubModeDebugProfile   @ Any going on?
     bne     .LOP_EXECUTE_INLINE_RANGE_debugmode       @ yes - take slow path
-.LOP_EXECUTE_INLINE_RANGE_resume:
-    add     r1, rSELF, #offThread_retval  @ r1<- &self->retval
-    sub     sp, sp, #8                  @ make room for arg, +64 bit align
-    mov     r0, rINST, lsr #8           @ r0<- AA
-    str     r1, [sp]                    @ push &self->retval
-    bl      .LOP_EXECUTE_INLINE_RANGE_continue        @ make call; will return after
-    add     sp, sp, #8                  @ pop stack
-    cmp     r0, #0                      @ test boolean result of inline
-    beq     common_exceptionThrown      @ returned false, handle exception
-    FETCH_ADVANCE_INST(3)               @ advance rPC, load rINST
-    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    GOTO_OPCODE(ip)                     @ jump to next instruction
+// begin WITH_TAINT_TRACKING
+    b       .LOP_EXECUTE_INLINE_RANGE_resume
 
 /* ------------------------------ */
     .balign 64
 .L_OP_INVOKE_OBJECT_INIT_RANGE: /* 0xf0 */
-/* File: armv5te/OP_INVOKE_OBJECT_INIT_RANGE.S */
+/* File: armv5te_taint/OP_INVOKE_OBJECT_INIT_RANGE.S */
     /*
      * Invoke Object.<init> on an object.  In practice we know that
      * Object's nullary constructor doesn't do anything, so we just
@@ -7342,71 +8122,107 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_RETURN_VOID_BARRIER: /* 0xf1 */
-/* File: armv5te/OP_RETURN_VOID_BARRIER.S */
+/* File: armv5te_taint/OP_RETURN_VOID_BARRIER.S */
     SMP_DMB_ST
+    SET_TAINT_CLEAR(r1)
+    str     r1, [rSELF, #offThread_rtaint]
     b       common_returnFromMethod
 
 /* ------------------------------ */
     .balign 64
 .L_OP_IGET_QUICK: /* 0xf2 */
-/* File: armv6t2/OP_IGET_QUICK.S */
+/* File: armv6t2_taint/OP_IGET_QUICK.S */
     /* For: iget-quick, iget-object-quick */
     /* op vA, vB, offset@CCCC */
     mov     r2, rINST, lsr #12          @ r2<- B
     FETCH(r1, 1)                        @ r1<- field byte offset
     GET_VREG(r3, r2)                    @ r3<- object we're operating on
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r0)
+    GET_VREG_TAINT(r9, r2, r0)
+// end WITH_TAINT_TRACKING
     ubfx    r2, rINST, #8, #4           @ r2<- A
     cmp     r3, #0                      @ check object for null
     beq     common_errNullObject        @ object was null
     ldr     r0, [r3, r1]                @ r0<- obj.field (always 32 bits)
-    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
+// begin WITH_TAINT_TRACKING
+    bl      .LOP_IGET_QUICK_taint_prop
+//    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST // in subroutine
+// end WITH_TAINT_TRACKING
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
     SET_VREG(r0, r2)                    @ fp[A]<- r0
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r0)
+    SET_VREG_TAINT(r10, r2, r0)
+// end WITH_TAINT_TRACKING
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_IGET_WIDE_QUICK: /* 0xf3 */
-/* File: armv6t2/OP_IGET_WIDE_QUICK.S */
+/* File: armv6t2_taint/OP_IGET_WIDE_QUICK.S */
     /* iget-wide-quick vA, vB, offset@CCCC */
     mov     r2, rINST, lsr #12          @ r2<- B
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r0)
+    GET_VREG_TAINT(r9, r2, r0)
+// end WITH_TAINT_TRACKING
     FETCH(ip, 1)                        @ ip<- field byte offset
     GET_VREG(r3, r2)                    @ r3<- object we're operating on
     ubfx    r2, rINST, #8, #4           @ r2<- A
     cmp     r3, #0                      @ check object for null
     beq     common_errNullObject        @ object was null
+// begin WITH_TAINT_TRACKING
+    add     r10, ip, #8
     ldrd    r0, [r3, ip]                @ r0<- obj.field (64 bits, aligned)
+    ldr     r10, [r3, r10]
+    orr     r10, r9, r10
+// end WITH_TAINT_TRACKING
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
-    add     r3, rFP, r2, lsl #2         @ r3<- &fp[A]
-    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    stmia   r3, {r0-r1}                 @ fp[A]<- r0/r1
+// begin WITH_TAINT_TRACKING
+    bl      iget_wide_quick_taint_prop
+// end WITH_TAINT_TRACKING
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_IGET_OBJECT_QUICK: /* 0xf4 */
-/* File: armv5te/OP_IGET_OBJECT_QUICK.S */
-/* File: armv5te/OP_IGET_QUICK.S */
+/* File: armv5te_taint/OP_IGET_OBJECT_QUICK.S */
+/* File: armv5te_taint/OP_IGET_QUICK.S */
     /* For: iget-quick, iget-object-quick */
     /* op vA, vB, offset@CCCC */
     mov     r2, rINST, lsr #12          @ r2<- B
     GET_VREG(r3, r2)                    @ r3<- object we're operating on
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r0)
+    GET_VREG_TAINT(r9, r2, r0)
+// end WITH_TAINT_TRACKING
     FETCH(r1, 1)                        @ r1<- field byte offset
     cmp     r3, #0                      @ check object for null
     mov     r2, rINST, lsr #8           @ r2<- A(+)
     beq     common_errNullObject        @ object was null
     ldr     r0, [r3, r1]                @ r0<- obj.field (always 32 bits)
-    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
+// begin WITH_TAINT_TRACKING
+	bl		.LOP_IGET_OBJECT_QUICK_taint_prop
+//    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST // in subroutine
+// end WITH_TAINT_TRACKING
     and     r2, r2, #15
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
     SET_VREG(r0, r2)                    @ fp[A]<- r0
+// begin WITH_TAINT_TRACKING
+	SET_TAINT_FP(r0)
+	SET_VREG_TAINT(r10, r2, r0)
+// end WITH_TAINT_TRACKING
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_IPUT_QUICK: /* 0xf5 */
-/* File: armv6t2/OP_IPUT_QUICK.S */
+/* File: armv6t2_taint/OP_IPUT_QUICK.S */
     /* For: iput-quick, iput-object-quick */
     /* op vA, vB, offset@CCCC */
     mov     r2, rINST, lsr #12          @ r2<- B
@@ -7416,33 +8232,47 @@ dalvik_inst:
     cmp     r3, #0                      @ check object for null
     beq     common_errNullObject        @ object was null
     GET_VREG(r0, r2)                    @ r0<- fp[A]
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r9)
+    GET_VREG_TAINT(r10, r2, r9)
+// end WITH_TAINT_TRACKING
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
     str     r0, [r3, r1]                @ obj.field (always 32 bits)<- r0
+// begin WITH_TAINT_TRACKING
+    add	    r1, r1, #4
+    str     r10, [r3, r1]
+// end WITH_TAINT_TRACKING
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_IPUT_WIDE_QUICK: /* 0xf6 */
-/* File: armv6t2/OP_IPUT_WIDE_QUICK.S */
+/* File: armv6t2_taint/OP_IPUT_WIDE_QUICK.S */
     /* iput-wide-quick vA, vB, offset@CCCC */
     mov     r1, rINST, lsr #12          @ r1<- B
     ubfx    r0, rINST, #8, #4           @ r0<- A
     GET_VREG(r2, r1)                    @ r2<- fp[B], the object pointer
-    add     r3, rFP, r0, lsl #2         @ r3<- &fp[A]
-    cmp     r2, #0                      @ check object for null
-    ldmia   r3, {r0-r1}                 @ r0/r1<- fp[A]
+// begin WITH_TAINT_TRACKING
+    bl iput_wide_quick_taint_prop
+// end WITH_TAINT_TRACKING
     beq     common_errNullObject        @ object was null
     FETCH(r3, 1)                        @ r3<- field byte offset
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
     strd    r0, [r2, r3]                @ obj.field (64 bits, aligned)<- r0/r1
+// begin WITH_TAINT_TRACKING
+    add     r3, r3, #8
+    str     r9, [r2, r3]
+// end WITH_TAINT_TRACKING
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_IPUT_OBJECT_QUICK: /* 0xf7 */
-/* File: armv5te/OP_IPUT_OBJECT_QUICK.S */
+/* File: armv5te_taint/OP_IPUT_OBJECT_QUICK.S */
     /* For: iput-object-quick */
     /* op vA, vB, offset@CCCC */
     mov     r2, rINST, lsr #12          @ r2<- B
@@ -7453,9 +8283,9 @@ dalvik_inst:
     beq     common_errNullObject        @ object was null
     and     r2, r2, #15
     GET_VREG(r0, r2)                    @ r0<- fp[A]
-    ldr     r2, [rSELF, #offThread_cardTable]  @ r2<- card table base
-    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
-    str     r0, [r3, r1]                @ obj.field (always 32 bits)<- r0
+// begin WITH_TAINT_TRACKING
+    bl    .LOP_IPUT_OBJECT_QUICK_taint_prop
+// end WITH_TAINT_TRACKING
     cmp     r0, #0
     strneb  r2, [r2, r3, lsr #GC_CARD_SHIFT] @ mark card based on obj head
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
@@ -7464,7 +8294,7 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_INVOKE_VIRTUAL_QUICK: /* 0xf8 */
-/* File: armv5te/OP_INVOKE_VIRTUAL_QUICK.S */
+/* File: armv5te_taint/OP_INVOKE_VIRTUAL_QUICK.S */
     /*
      * Handle an optimized virtual method call.
      *
@@ -7489,8 +8319,8 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_INVOKE_VIRTUAL_QUICK_RANGE: /* 0xf9 */
-/* File: armv5te/OP_INVOKE_VIRTUAL_QUICK_RANGE.S */
-/* File: armv5te/OP_INVOKE_VIRTUAL_QUICK.S */
+/* File: armv5te_taint/OP_INVOKE_VIRTUAL_QUICK_RANGE.S */
+/* File: armv5te_taint/OP_INVOKE_VIRTUAL_QUICK.S */
     /*
      * Handle an optimized virtual method call.
      *
@@ -7516,7 +8346,7 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_INVOKE_SUPER_QUICK: /* 0xfa */
-/* File: armv5te/OP_INVOKE_SUPER_QUICK.S */
+/* File: armv5te_taint/OP_INVOKE_SUPER_QUICK.S */
     /*
      * Handle an optimized "super" method call.
      *
@@ -7543,8 +8373,8 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_INVOKE_SUPER_QUICK_RANGE: /* 0xfb */
-/* File: armv5te/OP_INVOKE_SUPER_QUICK_RANGE.S */
-/* File: armv5te/OP_INVOKE_SUPER_QUICK.S */
+/* File: armv5te_taint/OP_INVOKE_SUPER_QUICK_RANGE.S */
+/* File: armv5te_taint/OP_INVOKE_SUPER_QUICK.S */
     /*
      * Handle an optimized "super" method call.
      *
@@ -7572,8 +8402,10 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_IPUT_OBJECT_VOLATILE: /* 0xfc */
-/* File: armv5te/OP_IPUT_OBJECT_VOLATILE.S */
-/* File: armv5te/OP_IPUT_OBJECT.S */
+/* File: armv5te_taint/OP_IPUT_OBJECT_VOLATILE.S */
+/* File: armv5te_taint/OP_IPUT_OBJECT.S */
+// begin WITH_TAINT_TRACKING
+// end WITH_TAINT_TRACKING
     /*
      * 32-bit instance field put.
      *
@@ -7600,8 +8432,10 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_SGET_OBJECT_VOLATILE: /* 0xfd */
-/* File: armv5te/OP_SGET_OBJECT_VOLATILE.S */
-/* File: armv5te/OP_SGET.S */
+/* File: armv5te_taint/OP_SGET_OBJECT_VOLATILE.S */
+/* File: armv5te_taint/OP_SGET.S */
+// begin WITH_TAINT_TRACKING
+// end WITH_TAINT_TRACKING
     /*
      * General 32-bit SGET handler.
      *
@@ -7615,11 +8449,11 @@ dalvik_inst:
     cmp     r0, #0                      @ is resolved entry null?
     beq     .LOP_SGET_OBJECT_VOLATILE_resolve         @ yes, do resolve
 .LOP_SGET_OBJECT_VOLATILE_finish: @ field ptr in r0
-    ldr     r1, [r0, #offStaticField_value] @ r1<- field value
-    SMP_DMB                            @ acquiring load
-    mov     r2, rINST, lsr #8           @ r2<- AA
+// begin WITH_TAINT_TRACKING
+    bl		.LOP_SGET_OBJECT_VOLATILE_taint_prop
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
-    SET_VREG(r1, r2)                    @ fp[AA]<- r1
+    SET_VREG(r0, r2)                    @ fp[AA]<- r0
+// end WITH_TAINT_TRACKING
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
@@ -7627,8 +8461,10 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_SPUT_OBJECT_VOLATILE: /* 0xfe */
-/* File: armv5te/OP_SPUT_OBJECT_VOLATILE.S */
-/* File: armv5te/OP_SPUT_OBJECT.S */
+/* File: armv5te_taint/OP_SPUT_OBJECT_VOLATILE.S */
+/* File: armv5te_taint/OP_SPUT_OBJECT.S */
+// begin WITH_TAINT_TRACKING
+// end WITH_TAINT_TRACKING
     /*
      * 32-bit SPUT handler for objects
      *
@@ -7645,21 +8481,27 @@ dalvik_inst:
     mov     r2, rINST, lsr #8           @ r2<- AA
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
     GET_VREG(r1, r2)                    @ r1<- fp[AA]
-    ldr     r2, [rSELF, #offThread_cardTable]  @ r2<- card table base
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r3)
+    GET_VREG_TAINT(r3, r2, r3)          @ r3<- taint
+//    ldr     r2, [rSELF, #offThread_cardTable]  @ r2<- card table base
+    ldr     r10, [rSELF, #offThread_cardTable]  @ r10<- card table base
+// end WITH_TAINT_TRACKING
     ldr     r9, [r0, #offField_clazz]   @ r9<- field->clazz
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    SMP_DMB_ST                        @ releasing store
+    @ no-op                         @ releasing store
     b       .LOP_SPUT_OBJECT_VOLATILE_end
 
 
 /* ------------------------------ */
     .balign 64
 .L_OP_UNUSED_FF: /* 0xff */
-/* File: armv5te/OP_UNUSED_FF.S */
-/* File: armv5te/unused.S */
+/* File: armv5te_taint/OP_UNUSED_FF.S */
+/* File: armv5te_taint/unused.S */
     bl      common_abort
 
 
+
     .balign 64
     .size   dvmAsmInstructionStart, .-dvmAsmInstructionStart
     .global dvmAsmInstructionEnd
@@ -7690,6 +8532,11 @@ dvmAsmSisterStart:
     bl      dvmResolveString            @ r0<- String reference
     cmp     r0, #0                      @ failed?
     beq     common_exceptionThrown      @ yup, handle the exception
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r2)
+    SET_TAINT_CLEAR(r3)
+    SET_VREG_TAINT(r3, r9, r2)
+// end WITH_TAINT_TRACKING
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
     SET_VREG(r0, r9)                    @ vAA<- r0
@@ -7709,6 +8556,11 @@ dvmAsmSisterStart:
     bl      dvmResolveString            @ r0<- String reference
     cmp     r0, #0                      @ failed?
     beq     common_exceptionThrown      @ yup, handle the exception
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r2)
+    SET_TAINT_CLEAR(r3)
+    SET_VREG_TAINT(r3, r9, r2)
+// end WITH_TAINT_TRACKING
     FETCH_ADVANCE_INST(3)               @ advance rPC, load rINST
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
     SET_VREG(r0, r9)                    @ vAA<- r0
@@ -7729,6 +8581,11 @@ dvmAsmSisterStart:
     bl      dvmResolveClass             @ r0<- Class reference
     cmp     r0, #0                      @ failed?
     beq     common_exceptionThrown      @ yup, handle the exception
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r2)
+    SET_TAINT_CLEAR(r3)
+    SET_VREG_TAINT(r3, r9, r2)
+// end WITH_TAINT_TRACKING
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
     SET_VREG(r0, r9)                    @ vAA<- r0
@@ -7792,6 +8649,11 @@ dvmAsmSisterStart:
      */
 .LOP_INSTANCE_OF_store:
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r2)
+    SET_TAINT_CLEAR(r3)
+    SET_VREG_TAINT(r3, r9, r2)
+// end WITH_TAINT_TRACKING
     SET_VREG(r0, r9)                    @ vA<- r0
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
     GOTO_OPCODE(ip)                     @ jump to next instruction
@@ -7804,6 +8666,11 @@ dvmAsmSisterStart:
     mov     r0, #1                      @ indicate success
     @ could b OP_INSTANCE_OF_store, but copying is faster and cheaper
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r2)
+    SET_TAINT_CLEAR(r3)
+    SET_VREG_TAINT(r3, r9, r2)
+// end WITH_TAINT_TRACKING
     SET_VREG(r0, r9)                    @ vA<- r0
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
     GOTO_OPCODE(ip)                     @ jump to next instruction
@@ -7848,6 +8715,11 @@ dvmAsmSisterStart:
     beq     common_exceptionThrown      @ yes, handle the exception
 #endif
 .LOP_NEW_INSTANCE_end:
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r2)
+    SET_TAINT_CLEAR(r1)
+    SET_VREG_TAINT(r1, r3, r2)
+// end WITH_TAINT_TRACKING
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
     SET_VREG(r0, r3)                    @ vAA<- r0
@@ -7868,6 +8740,11 @@ dvmAsmSisterStart:
     mov     r0, rSELF
     mov     r1, rPC
     bl      dvmJitEndTraceSelect        @ (self, pc)
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r2)
+    SET_TAINT_CLEAR(r1)
+    SET_VREG_TAINT(r1, r10, r2)
+// end WITH_TAINT_TRACKING
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
     SET_VREG(r9, r10)                   @ vAA<- new object
@@ -7936,6 +8813,11 @@ dvmAsmSisterStart:
     beq     common_exceptionThrown      @ yes, handle the exception
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
     and     r2, r2, #15                 @ r2<- A
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r1)
+    SET_TAINT_CLEAR(r3)
+    SET_VREG_TAINT(r3, r2, r1)
+// end WITH_TAINT_TRACKING
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
     SET_VREG(r0, r2)                    @ vA<- r0
     GOTO_OPCODE(ip)                     @ jump to next instruction
@@ -7968,6 +8850,9 @@ dvmAsmSisterStart:
     FETCH(r1, 2)                        @ r1<- FEDC or CCCC
     str     r0, [rSELF, #offThread_retval]      @ retval.l <- new array
     str     rINST, [rSELF, #offThread_retval+4] @ retval.h <- type
+// begin WITH_TAINT_TRACKING
+    add     r2, r0, #offArrayObject_taint
+// end WITH_TAINT_TRACKING
     add     r0, r0, #offArrayObject_contents @ r0<- newArray->contents
     subs    r9, r9, #1                  @ length--, check for neg
     FETCH_ADVANCE_INST(3)               @ advance to next instr, load rINST
@@ -7975,6 +8860,11 @@ dvmAsmSisterStart:
 
     @ copy values from registers into the array
     @ r0=array, r1=CCCC/FEDC, r9=length (from AA or B), r10=AA/BA
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_CLEAR(r3)
+    str     r3, [rSELF, #offThread_rtaint]    @ rtaint <- clear
+    str     r3, [r2]
+// end WITH_TAINT_TRACKING
     .if     0
     add     r2, rFP, r1, lsl #2         @ r2<- &fp[CCCC]
 1:  ldr     r3, [r2], #4                @ r3<- *r2++
@@ -8052,6 +8942,9 @@ dvmAsmSisterStart:
     FETCH(r1, 2)                        @ r1<- FEDC or CCCC
     str     r0, [rSELF, #offThread_retval]      @ retval.l <- new array
     str     rINST, [rSELF, #offThread_retval+4] @ retval.h <- type
+// begin WITH_TAINT_TRACKING
+    add     r2, r0, #offArrayObject_taint
+// end WITH_TAINT_TRACKING
     add     r0, r0, #offArrayObject_contents @ r0<- newArray->contents
     subs    r9, r9, #1                  @ length--, check for neg
     FETCH_ADVANCE_INST(3)               @ advance to next instr, load rINST
@@ -8059,6 +8952,11 @@ dvmAsmSisterStart:
 
     @ copy values from registers into the array
     @ r0=array, r1=CCCC/FEDC, r9=length (from AA or B), r10=AA/BA
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_CLEAR(r3)
+    str     r3, [rSELF, #offThread_rtaint]    @ rtaint <- clear
+    str     r3, [r2]
+// end WITH_TAINT_TRACKING
     .if     1
     add     r2, rFP, r1, lsl #2         @ r2<- &fp[CCCC]
 1:  ldr     r3, [r2], #4                @ r3<- *r2++
@@ -8111,23 +9009,53 @@ dvmAsmSisterStart:
 /* continuation for OP_CMPL_FLOAT */
 .LOP_CMPL_FLOAT_finish:
     SET_VREG(r0, r9)                    @ vAA<- r0
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r1)
+    SET_TAINT_CLEAR(r0)
+    SET_VREG_TAINT(r0, r9, r1)
+// end WITH_TAINT_TRACKING
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
+
 /* continuation for OP_CMPG_FLOAT */
 .LOP_CMPG_FLOAT_finish:
     SET_VREG(r0, r9)                    @ vAA<- r0
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r1)
+    SET_TAINT_CLEAR(r0)
+    SET_VREG_TAINT(r0, r9, r1)
+// end WITH_TAINT_TRACKING
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
+
 /* continuation for OP_CMPL_DOUBLE */
 .LOP_CMPL_DOUBLE_finish:
+    fmstat                              @ export status flags
+    movgt   r0, #1                      @ (greater than) r1<- 1
+    moveq   r0, #0                      @ (equal) r1<- 0
     SET_VREG(r0, r9)                    @ vAA<- r0
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r1)
+    SET_TAINT_CLEAR(r0)
+    SET_VREG_TAINT(r0, r9, r1)
+// end WITH_TAINT_TRACKING
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
+
 /* continuation for OP_CMPG_DOUBLE */
 .LOP_CMPG_DOUBLE_finish:
+    fmstat                              @ export status flags
+    mvnmi   r0, #0                      @ (less than) r1<- -1
+    moveq   r0, #0                      @ (equal) r1<- 0
     SET_VREG(r0, r9)                    @ vAA<- r0
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r1)
+    SET_TAINT_CLEAR(r0)
+    SET_VREG_TAINT(r0, r9, r1)
+// end WITH_TAINT_TRACKING
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
+
 /* continuation for OP_CMP_LONG */
 
 .LOP_CMP_LONG_less:
@@ -8136,6 +9064,11 @@ dvmAsmSisterStart:
     @ instead, we just replicate the tail end.
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
     SET_VREG(r1, r9)                    @ vAA<- r1
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r0)
+    SET_TAINT_CLEAR(r1)
+    SET_VREG_TAINT(r1, r9, r0)
+// end WITH_TAINT_TRACKING
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
@@ -8146,28 +9079,177 @@ dvmAsmSisterStart:
 .LOP_CMP_LONG_finish:
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
     SET_VREG(r1, r9)                    @ vAA<- r1
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r0)
+    SET_TAINT_CLEAR(r1)
+    SET_VREG_TAINT(r1, r9, r0)
+// end WITH_TAINT_TRACKING
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
+cmp_long_taint_prop:
+    add     r2, rFP, r2, lsl #3         @ r2<- &fp[BB]
+    add     r3, rFP, r3, lsl #3         @ r3<- &fp[CC]
+//    ldmia   r2, {r0-r1}                 @ r0/r1<- vBB/vBB+1
+    ldr     r0, [r2, #0]
+    ldr     r1, [r2, #8]
+//    ldmia   r3, {r2-r3}                 @ r2/r3<- vCC/vCC+1
+    ldr     r2, [r3, #0]
+    ldr     r3, [r3, #8]
+    bx      lr
+
+/* continuation for OP_AGET */
+
+.LOP_AGET_taint_prop_1:
+    ldr	    r2, [r0, #offArrayObject_taint]
+    SET_TAINT_FP(r10)
+    GET_VREG_TAINT(r3, r3, r10)
+    orr	    r2, r3, r2                  @ r2<- r2 | r1
+    bx	    lr
+
+.LOP_AGET_taint_prop_2:
+    bcs     common_errArrayIndex        @ index >= length, bail
+    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
+    SET_TAINT_FP(r3)
+    SET_VREG_TAINT(r2, r9, r3)
+    bx      lr
+
 /* continuation for OP_AGET_WIDE */
 
 .LOP_AGET_WIDE_finish:
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
-    ldrd    r2, [r0, #offArrayObject_contents]  @ r2/r3<- vBB[vCC]
-    add     r9, rFP, r9, lsl #2         @ r9<- &fp[AA]
+// begin WITH_TAINT_TRACKING
+    ldrd    r0, [r0, #offArrayObject_contents]  @ r0/r1<- vBB[vCC]
+    mov     r2, r1
+    mov     r1, r10
+    mov     r3, r10
+    add     r9, rFP, r9, lsl #3         @ r9<- &fp[AA]
+// end WITH_TAINT_TRACKING
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    stmia   r9, {r2-r3}                 @ vAA/vAA+1<- r2/r3
+// begin WITH_TAINT_TRACKING
+    stmia   r9, {r0-r3}                 @ vAA/vAA+1<- r2/r3
+// begin WITH_TAINT_TRACKING
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
+.LOP_AGET_WIDE_taint_prop:
+    ldr     r2, [r0, #offArrayObject_taint]
+    SET_TAINT_FP(r10)
+    GET_VREG_TAINT(r10, r3, r10)
+    orr     r10, r10, r2                @ r10<- r10 | r1
+    bx      lr
+
+/* continuation for OP_AGET_OBJECT */
+
+.LOP_AGET_OBJECT_taint_prop_1:
+    ldr	    r2, [r0, #offArrayObject_taint]
+    SET_TAINT_FP(r10)
+    GET_VREG_TAINT(r3, r3, r10)
+    orr	    r2, r3, r2                  @ r2<- r2 | r1
+    bx	    lr
+
+.LOP_AGET_OBJECT_taint_prop_2:
+    bcs     common_errArrayIndex        @ index >= length, bail
+    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
+    SET_TAINT_FP(r3)
+    SET_VREG_TAINT(r2, r9, r3)
+    bx      lr
+
+/* continuation for OP_AGET_BOOLEAN */
+
+.LOP_AGET_BOOLEAN_taint_prop_1:
+    ldr	    r2, [r0, #offArrayObject_taint]
+    SET_TAINT_FP(r10)
+    GET_VREG_TAINT(r3, r3, r10)
+    orr	    r2, r3, r2                  @ r2<- r2 | r1
+    bx	    lr
+
+.LOP_AGET_BOOLEAN_taint_prop_2:
+    bcs     common_errArrayIndex        @ index >= length, bail
+    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
+    SET_TAINT_FP(r3)
+    SET_VREG_TAINT(r2, r9, r3)
+    bx      lr
+
+/* continuation for OP_AGET_BYTE */
+
+.LOP_AGET_BYTE_taint_prop_1:
+    ldr	    r2, [r0, #offArrayObject_taint]
+    SET_TAINT_FP(r10)
+    GET_VREG_TAINT(r3, r3, r10)
+    orr	    r2, r3, r2                  @ r2<- r2 | r1
+    bx	    lr
+
+.LOP_AGET_BYTE_taint_prop_2:
+    bcs     common_errArrayIndex        @ index >= length, bail
+    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
+    SET_TAINT_FP(r3)
+    SET_VREG_TAINT(r2, r9, r3)
+    bx      lr
+
+/* continuation for OP_AGET_CHAR */
+
+.LOP_AGET_CHAR_taint_prop_1:
+    ldr	    r2, [r0, #offArrayObject_taint]
+    SET_TAINT_FP(r10)
+    GET_VREG_TAINT(r3, r3, r10)
+    orr	    r2, r3, r2                  @ r2<- r2 | r1
+    bx	    lr
+
+.LOP_AGET_CHAR_taint_prop_2:
+    bcs     common_errArrayIndex        @ index >= length, bail
+    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
+    SET_TAINT_FP(r3)
+    SET_VREG_TAINT(r2, r9, r3)
+    bx      lr
+
+/* continuation for OP_AGET_SHORT */
+
+.LOP_AGET_SHORT_taint_prop_1:
+    ldr	    r2, [r0, #offArrayObject_taint]
+    SET_TAINT_FP(r10)
+    GET_VREG_TAINT(r3, r3, r10)
+    orr	    r2, r3, r2                  @ r2<- r2 | r1
+    bx	    lr
+
+.LOP_AGET_SHORT_taint_prop_2:
+    bcs     common_errArrayIndex        @ index >= length, bail
+    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
+    SET_TAINT_FP(r3)
+    SET_VREG_TAINT(r2, r9, r3)
+    bx      lr
+
+/* continuation for OP_APUT */
+
+.LOP_APUT_taint_prop:
+    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
+    GET_VREG(r1, r2)                    @ r1<- vBB (array object)
+    ldr     r2, [r1, #offArrayObject_taint]
+    SET_TAINT_FP(r3)
+    GET_VREG_TAINT(r3, r9, r3)
+    orr     r2, r2, r3                  @ r2<- r2 | r3
+    str     r2, [r1, #offArrayObject_taint]
+    bx      lr
+
 /* continuation for OP_APUT_WIDE */
 
 .LOP_APUT_WIDE_finish:
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
-    ldmia   r9, {r2-r3}                 @ r2/r3<- vAA/vAA+1
+// begin WITH_TAINT_TRACKING
+//    ldmia   r9, {r2-r3}                 @ r2/r3<- vAA/vAA+1
+    ldr     r2, [r9, #0]
+    ldr     r3, [r9, #8]
+    ldr     r1, [r9, #4]                      @ r1<- array taint
+    ldr     r9, [r10, #offArrayObject_taint]
+    orr     r1, r1, r9                        @ r1<- r1 | r9
+    str     r1, [r10, #offArrayObject_taint]
+// end WITH_TAINT_TRACKING
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+// begin WITH_TAINT_TRACKING
     strd    r2, [r0, #offArrayObject_contents]  @ r2/r3<- vBB[vCC]
+// end WITH_TAINT_TRACKING
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
+
 /* continuation for OP_APUT_OBJECT */
     /*
      * On entry:
@@ -8176,6 +9258,9 @@ dvmAsmSisterStart:
      *  r10 = offset into array (vBB + vCC * width)
      */
 .LOP_APUT_OBJECT_finish:
+// begin WITH_TAINT_TRACKING
+    str     r2, [rINST, #offArrayObject_taint]
+// end WITH_TAINT_TRACKING
     cmp     r9, #0                      @ storing null reference?
     beq     .LOP_APUT_OBJECT_skip_check      @ yes, skip type checks
     ldr     r0, [r9, #offObject_clazz]  @ r0<- obj->clazz
@@ -8204,6 +9289,65 @@ dvmAsmSisterStart:
     bl      dvmThrowArrayStoreExceptionIncompatibleElement
     b       common_exceptionThrown
 
+.LOP_APUT_OBJECT_taint_prop_1:
+    SET_TAINT_FP(r3)
+    GET_VREG_TAINT(r2, r9, r3)
+    bx      lr
+
+.LOP_APUT_OBJECT_taint_prop_2:
+    ldr     r3, [rINST, #offArrayObject_taint]
+    orr     r2, r2, r3                  @ r2<- r2 | r3
+    bx      lr
+
+
+/* continuation for OP_APUT_BOOLEAN */
+
+.LOP_APUT_BOOLEAN_taint_prop:
+    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
+    GET_VREG(r1, r2)                    @ r1<- vBB (array object)
+    ldr     r2, [r1, #offArrayObject_taint]
+    SET_TAINT_FP(r3)
+    GET_VREG_TAINT(r3, r9, r3)
+    orr     r2, r2, r3                  @ r2<- r2 | r3
+    str     r2, [r1, #offArrayObject_taint]
+    bx      lr
+
+/* continuation for OP_APUT_BYTE */
+
+.LOP_APUT_BYTE_taint_prop:
+    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
+    GET_VREG(r1, r2)                    @ r1<- vBB (array object)
+    ldr     r2, [r1, #offArrayObject_taint]
+    SET_TAINT_FP(r3)
+    GET_VREG_TAINT(r3, r9, r3)
+    orr     r2, r2, r3                  @ r2<- r2 | r3
+    str     r2, [r1, #offArrayObject_taint]
+    bx      lr
+
+/* continuation for OP_APUT_CHAR */
+
+.LOP_APUT_CHAR_taint_prop:
+    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
+    GET_VREG(r1, r2)                    @ r1<- vBB (array object)
+    ldr     r2, [r1, #offArrayObject_taint]
+    SET_TAINT_FP(r3)
+    GET_VREG_TAINT(r3, r9, r3)
+    orr     r2, r2, r3                  @ r2<- r2 | r3
+    str     r2, [r1, #offArrayObject_taint]
+    bx      lr
+
+/* continuation for OP_APUT_SHORT */
+
+.LOP_APUT_SHORT_taint_prop:
+    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
+    GET_VREG(r1, r2)                    @ r1<- vBB (array object)
+    ldr     r2, [r1, #offArrayObject_taint]
+    SET_TAINT_FP(r3)
+    GET_VREG_TAINT(r3, r9, r3)
+    orr     r2, r2, r3                  @ r2<- r2 | r3
+    str     r2, [r1, #offArrayObject_taint]
+    bx      lr
+
 /* continuation for OP_IGET */
 
     /*
@@ -8216,13 +9360,29 @@ dvmAsmSisterStart:
     cmp     r9, #0                      @ check object for null
     ldr     r3, [r0, #offInstField_byteOffset]  @ r3<- byte offset of field
     beq     common_errNullObject        @ object was null
+// begin WITH_TAINT_TRACKING
     ldr   r0, [r9, r3]                @ r0<- obj.field (8/16/32 bits)
+    add     r3, r3, #4
+    ldr	    r3, [r9, r3]
+    orr     r3, r3, r10
+// end WITH_TAINT_TRACKING
     ubfx    r2, rINST, #8, #4           @ r2<- A
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
     SET_VREG(r0, r2)                    @ fp[A]<- r0
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r1)
+    SET_VREG_TAINT(r3, r2, r1)
+// end WITH_TAINT_TRACKING
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
+.LOP_IGET_taint_prop:
+    GET_VREG(r9, r0)                    @ r9<- fp[B], the object pointer
+    SET_TAINT_FP(r3)
+    GET_VREG_TAINT(r10, r0, r3)
+    ldr     r0, [r2, r1, lsl #2]        @ r0<- resolved InstField ptr
+    bx      lr
+
 /* continuation for OP_IGET_WIDE */
 
     /*
@@ -8234,14 +9394,32 @@ dvmAsmSisterStart:
     cmp     r9, #0                      @ check object for null
     ldr     r3, [r0, #offInstField_byteOffset]  @ r3<- byte offset of field
     beq     common_errNullObject        @ object was null
+// begin WITH_TAINT_TRACKING
     ldrd    r0, [r9, r3]                @ r0/r1<- obj.field (64-bit align ok)
+    add     r3, r3, #8
+    ldr     r3, [r9, r3]
+    orr	    r10, r3, r10
     ubfx    r2, rINST, #8, #4           @ r2<- A
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
-    add     r3, rFP, r2, lsl #2         @ r3<- &fp[A]
+    add     r3, rFP, r2, lsl #3         @ r3<- &fp[A]
+// end WITH_TAINT_TRACKING
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    stmia   r3, {r0-r1}                 @ fp[A]<- r0/r1
+// begin WITH_TAINT_TRACKING
+//    stmia   r3, {r0-r1}                 @ fp[A]<- r0/r1
+    str    r0, [r3, #0]
+    str    r10, [r3, #4]
+    str    r1, [r3, #8]
+    str    r10, [r3, #12]
+// end WITH_TAINT_TRACKING
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
+.LOP_IGET_WIDE_taint_prop:
+    GET_VREG(r9, r0)                    @ r9<- fp[B], the object pointer
+    SET_TAINT_FP(r3)
+    GET_VREG_TAINT(r10, r0, r3)
+    ldr     r0, [r2, r1, lsl #2]        @ r0<- resolved InstField ptr
+    bx      lr
+
 /* continuation for OP_IGET_OBJECT */
 
     /*
@@ -8254,15 +9432,37 @@ dvmAsmSisterStart:
     cmp     r9, #0                      @ check object for null
     ldr     r3, [r0, #offInstField_byteOffset]  @ r3<- byte offset of field
     beq     common_errNullObject        @ object was null
+// begin WITH_TAINT_TRACKING
+//    .if     0
+//    add     r0, r9, r3                  @ r0<- address of field
+//    bl      dvmQuasiAtomicRead64        @ r0/r1<- value/taint
+//    orr	    r3, r1, r10
+//    .else
     ldr   r0, [r9, r3]                @ r0<- obj.field (8/16/32 bits)
     @ no-op                             @ acquiring load
+    add     r3, r3, #4
+    ldr	    r3, [r9, r3]
+    orr     r3, r3, r10
+//    .endif
+// end WITH_TAINT_TRACKING
     mov     r2, rINST, lsr #8           @ r2<- A+
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
     and     r2, r2, #15                 @ r2<- A
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
     SET_VREG(r0, r2)                    @ fp[A]<- r0
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r1)
+    SET_VREG_TAINT(r3, r2, r1)
+// end WITH_TAINT_TRACKING
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
+.LOP_IGET_OBJECT_taint_prop:
+    GET_VREG(r9, r0)                    @ r9<- fp[B], the object pointer
+    SET_TAINT_FP(r3)
+    GET_VREG_TAINT(r10, r0, r3)
+    ldr     r0, [r2, r1, lsl #2]        @ r0<- resolved InstField ptr
+    bx      lr
+
 /* continuation for OP_IGET_BOOLEAN */
 
     /*
@@ -8275,15 +9475,37 @@ dvmAsmSisterStart:
     cmp     r9, #0                      @ check object for null
     ldr     r3, [r0, #offInstField_byteOffset]  @ r3<- byte offset of field
     beq     common_errNullObject        @ object was null
+// begin WITH_TAINT_TRACKING
+//    .if     0
+//    add     r0, r9, r3                  @ r0<- address of field
+//    bl      dvmQuasiAtomicRead64        @ r0/r1<- value/taint
+//    orr	    r3, r1, r10
+//    .else
     ldr   r0, [r9, r3]                @ r0<- obj.field (8/16/32 bits)
     @ no-op                             @ acquiring load
+    add     r3, r3, #4
+    ldr	    r3, [r9, r3]
+    orr     r3, r3, r10
+//    .endif
+// end WITH_TAINT_TRACKING
     mov     r2, rINST, lsr #8           @ r2<- A+
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
     and     r2, r2, #15                 @ r2<- A
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
     SET_VREG(r0, r2)                    @ fp[A]<- r0
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r1)
+    SET_VREG_TAINT(r3, r2, r1)
+// end WITH_TAINT_TRACKING
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
+.LOP_IGET_BOOLEAN_taint_prop:
+    GET_VREG(r9, r0)                    @ r9<- fp[B], the object pointer
+    SET_TAINT_FP(r3)
+    GET_VREG_TAINT(r10, r0, r3)
+    ldr     r0, [r2, r1, lsl #2]        @ r0<- resolved InstField ptr
+    bx      lr
+
 /* continuation for OP_IGET_BYTE */
 
     /*
@@ -8296,15 +9518,37 @@ dvmAsmSisterStart:
     cmp     r9, #0                      @ check object for null
     ldr     r3, [r0, #offInstField_byteOffset]  @ r3<- byte offset of field
     beq     common_errNullObject        @ object was null
+// begin WITH_TAINT_TRACKING
+//    .if     0
+//    add     r0, r9, r3                  @ r0<- address of field
+//    bl      dvmQuasiAtomicRead64        @ r0/r1<- value/taint
+//    orr	    r3, r1, r10
+//    .else
     ldr   r0, [r9, r3]                @ r0<- obj.field (8/16/32 bits)
     @ no-op                             @ acquiring load
+    add     r3, r3, #4
+    ldr	    r3, [r9, r3]
+    orr     r3, r3, r10
+//    .endif
+// end WITH_TAINT_TRACKING
     mov     r2, rINST, lsr #8           @ r2<- A+
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
     and     r2, r2, #15                 @ r2<- A
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
     SET_VREG(r0, r2)                    @ fp[A]<- r0
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r1)
+    SET_VREG_TAINT(r3, r2, r1)
+// end WITH_TAINT_TRACKING
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
+.LOP_IGET_BYTE_taint_prop:
+    GET_VREG(r9, r0)                    @ r9<- fp[B], the object pointer
+    SET_TAINT_FP(r3)
+    GET_VREG_TAINT(r10, r0, r3)
+    ldr     r0, [r2, r1, lsl #2]        @ r0<- resolved InstField ptr
+    bx      lr
+
 /* continuation for OP_IGET_CHAR */
 
     /*
@@ -8317,15 +9561,37 @@ dvmAsmSisterStart:
     cmp     r9, #0                      @ check object for null
     ldr     r3, [r0, #offInstField_byteOffset]  @ r3<- byte offset of field
     beq     common_errNullObject        @ object was null
+// begin WITH_TAINT_TRACKING
+//    .if     0
+//    add     r0, r9, r3                  @ r0<- address of field
+//    bl      dvmQuasiAtomicRead64        @ r0/r1<- value/taint
+//    orr	    r3, r1, r10
+//    .else
     ldr   r0, [r9, r3]                @ r0<- obj.field (8/16/32 bits)
     @ no-op                             @ acquiring load
+    add     r3, r3, #4
+    ldr	    r3, [r9, r3]
+    orr     r3, r3, r10
+//    .endif
+// end WITH_TAINT_TRACKING
     mov     r2, rINST, lsr #8           @ r2<- A+
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
     and     r2, r2, #15                 @ r2<- A
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
     SET_VREG(r0, r2)                    @ fp[A]<- r0
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r1)
+    SET_VREG_TAINT(r3, r2, r1)
+// end WITH_TAINT_TRACKING
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
+.LOP_IGET_CHAR_taint_prop:
+    GET_VREG(r9, r0)                    @ r9<- fp[B], the object pointer
+    SET_TAINT_FP(r3)
+    GET_VREG_TAINT(r10, r0, r3)
+    ldr     r0, [r2, r1, lsl #2]        @ r0<- resolved InstField ptr
+    bx      lr
+
 /* continuation for OP_IGET_SHORT */
 
     /*
@@ -8338,15 +9604,37 @@ dvmAsmSisterStart:
     cmp     r9, #0                      @ check object for null
     ldr     r3, [r0, #offInstField_byteOffset]  @ r3<- byte offset of field
     beq     common_errNullObject        @ object was null
+// begin WITH_TAINT_TRACKING
+//    .if     0
+//    add     r0, r9, r3                  @ r0<- address of field
+//    bl      dvmQuasiAtomicRead64        @ r0/r1<- value/taint
+//    orr	    r3, r1, r10
+//    .else
     ldr   r0, [r9, r3]                @ r0<- obj.field (8/16/32 bits)
     @ no-op                             @ acquiring load
+    add     r3, r3, #4
+    ldr	    r3, [r9, r3]
+    orr     r3, r3, r10
+//    .endif
+// end WITH_TAINT_TRACKING
     mov     r2, rINST, lsr #8           @ r2<- A+
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
     and     r2, r2, #15                 @ r2<- A
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
     SET_VREG(r0, r2)                    @ fp[A]<- r0
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r1)
+    SET_VREG_TAINT(r3, r2, r1)
+// end WITH_TAINT_TRACKING
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
+.LOP_IGET_SHORT_taint_prop:
+    GET_VREG(r9, r0)                    @ r9<- fp[B], the object pointer
+    SET_TAINT_FP(r3)
+    GET_VREG_TAINT(r10, r0, r3)
+    ldr     r0, [r2, r1, lsl #2]        @ r0<- resolved InstField ptr
+    bx      lr
+
 /* continuation for OP_IPUT */
 
     /*
@@ -8360,12 +9648,21 @@ dvmAsmSisterStart:
     ubfx    r1, rINST, #8, #4           @ r1<- A
     cmp     r9, #0                      @ check object for null
     GET_VREG(r0, r1)                    @ r0<- fp[A]
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r2)
+    GET_VREG_TAINT(r10, r1, r2)
+// end WITH_TAINT_TRACKING
     beq     common_errNullObject        @ object was null
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
     str  r0, [r9, r3]                @ obj.field (8/16/32 bits)<- r0
+// begin WITH_TAINT_TRACKING
+    add	    r3, r3, #4
+    str	    r10, [r9, r3]
+// end WITH_TAINT_TRACKING
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
+
 /* continuation for OP_IPUT_WIDE */
 
     /*
@@ -8377,14 +9674,26 @@ dvmAsmSisterStart:
     ubfx    r2, rINST, #8, #4           @ r2<- A
     cmp     r9, #0                      @ check object for null
     ldr     r3, [r0, #offInstField_byteOffset]  @ r3<- byte offset of field
-    add     r2, rFP, r2, lsl #2         @ r3<- &fp[A]
+// begin WITH_TAINT_TRACKING
+    add     r2, rFP, r2, lsl #3         @ r3<- &fp[A]
+// end WITH_TAINT_TRACKING
     beq     common_errNullObject        @ object was null
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
-    ldmia   r2, {r0-r1}                 @ r0/r1<- fp[A]
+// begin WITH_TAINT_TRACKING
+//    ldmia   r2, {r0-r1}                 @ r0/r1<- fp[A]
+    ldr	    r0, [r2, #0]
+    ldr     r1, [r2, #8]
+    ldr	    r10, [r2, #4]
+// end WITH_TAINT_TRACKING
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    strd    r0, [r9, r3]                @ obj.field (64 bits, aligned)<- r0
+    strd    r0, [r9, r3]                @ obj.field (64 bits, aligned)<- r0/r1
+// begin WITH_TAINT_TRACKING
+    add	    r3, r3, #8
+    str	    r10, [r9, r3]
+// end WITH_TAINT_TRACKING
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
+
 /* continuation for OP_IPUT_OBJECT */
 
     /*
@@ -8399,15 +9708,29 @@ dvmAsmSisterStart:
     and     r1, r1, #15                 @ r1<- A
     cmp     r9, #0                      @ check object for null
     GET_VREG(r0, r1)                    @ r0<- fp[A]
-    ldr     r2, [rSELF, #offThread_cardTable]  @ r2<- card table base
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r2)
+    GET_VREG_TAINT(r10, r1, r2)
+    ldr     r11, [rSELF, #offThread_cardTable]  @ r11<- card table base
+// end WITH_TAINT_TRACKING
     beq     common_errNullObject        @ object was null
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
     @ no-op                         @ releasing store
+// begin WITH_TAINT_TRACKING
+//    .if     0
+//    add     r2, r9, r3                  @ r2<- target address
+//    mov     r1, r10                     @ r1<-taint
+//    bl      dvmQuasiAtomicSwap64        @ stores r0/r1 into addr r2
+//    .else
     str     r0, [r9, r3]                @ obj.field (32 bits)<- r0
+    add     r3, r3, #4
+    str     r10, [r9, r3]
+//    .endif
     @ no-op 
     cmp     r0, #0                      @ stored a null reference?
-    strneb  r2, [r2, r9, lsr #GC_CARD_SHIFT]  @ mark card if not
+    strneb  r11, [r11, r9, lsr #GC_CARD_SHIFT]  @ mark card if not
+// end WITH_TAINT_TRACKING
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
 /* continuation for OP_IPUT_BOOLEAN */
@@ -8424,14 +9747,29 @@ dvmAsmSisterStart:
     and     r1, r1, #15                 @ r1<- A
     cmp     r9, #0                      @ check object for null
     GET_VREG(r0, r1)                    @ r0<- fp[A]
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r2)
+    GET_VREG_TAINT(r10, r1, r2)
+// end WITH_TAINT_TRACKING
     beq     common_errNullObject        @ object was null
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    @ no-op                         @ releasing store
+    @ no-op                          @ releasing store
+// begin WITH_TAINT_TRACKING
+//    .if     0
+//    add     r2, r9, r3                  @ r2<- target address
+//    mov	    r1, r10                     @ r1<-taint
+//    bl      dvmQuasiAtomicSwap64        @ stores r0/r1 into addr r2
+//    .else
     str  r0, [r9, r3]                @ obj.field (8/16/32 bits)<- r0
+    add	    r3, r3, #4
+    str	    r10, [r9, r3]
+//    .endif
+// end WITH_TAINT_TRACKING
     @ no-op 
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
+
 /* continuation for OP_IPUT_BYTE */
 
     /*
@@ -8446,14 +9784,29 @@ dvmAsmSisterStart:
     and     r1, r1, #15                 @ r1<- A
     cmp     r9, #0                      @ check object for null
     GET_VREG(r0, r1)                    @ r0<- fp[A]
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r2)
+    GET_VREG_TAINT(r10, r1, r2)
+// end WITH_TAINT_TRACKING
     beq     common_errNullObject        @ object was null
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    @ no-op                         @ releasing store
+    @ no-op                          @ releasing store
+// begin WITH_TAINT_TRACKING
+//    .if     0
+//    add     r2, r9, r3                  @ r2<- target address
+//    mov	    r1, r10                     @ r1<-taint
+//    bl      dvmQuasiAtomicSwap64        @ stores r0/r1 into addr r2
+//    .else
     str  r0, [r9, r3]                @ obj.field (8/16/32 bits)<- r0
+    add	    r3, r3, #4
+    str	    r10, [r9, r3]
+//    .endif
+// end WITH_TAINT_TRACKING
     @ no-op 
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
+
 /* continuation for OP_IPUT_CHAR */
 
     /*
@@ -8468,14 +9821,29 @@ dvmAsmSisterStart:
     and     r1, r1, #15                 @ r1<- A
     cmp     r9, #0                      @ check object for null
     GET_VREG(r0, r1)                    @ r0<- fp[A]
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r2)
+    GET_VREG_TAINT(r10, r1, r2)
+// end WITH_TAINT_TRACKING
     beq     common_errNullObject        @ object was null
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    @ no-op                         @ releasing store
+    @ no-op                          @ releasing store
+// begin WITH_TAINT_TRACKING
+//    .if     0
+//    add     r2, r9, r3                  @ r2<- target address
+//    mov	    r1, r10                     @ r1<-taint
+//    bl      dvmQuasiAtomicSwap64        @ stores r0/r1 into addr r2
+//    .else
     str  r0, [r9, r3]                @ obj.field (8/16/32 bits)<- r0
+    add	    r3, r3, #4
+    str	    r10, [r9, r3]
+//    .endif
+// end WITH_TAINT_TRACKING
     @ no-op 
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
+
 /* continuation for OP_IPUT_SHORT */
 
     /*
@@ -8490,14 +9858,29 @@ dvmAsmSisterStart:
     and     r1, r1, #15                 @ r1<- A
     cmp     r9, #0                      @ check object for null
     GET_VREG(r0, r1)                    @ r0<- fp[A]
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r2)
+    GET_VREG_TAINT(r10, r1, r2)
+// end WITH_TAINT_TRACKING
     beq     common_errNullObject        @ object was null
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    @ no-op                         @ releasing store
+    @ no-op                          @ releasing store
+// begin WITH_TAINT_TRACKING
+//    .if     0
+//    add     r2, r9, r3                  @ r2<- target address
+//    mov	    r1, r10                     @ r1<-taint
+//    bl      dvmQuasiAtomicSwap64        @ stores r0/r1 into addr r2
+//    .else
     str  r0, [r9, r3]                @ obj.field (8/16/32 bits)<- r0
+    add	    r3, r3, #4
+    str	    r10, [r9, r3]
+//    .endif
+// end WITH_TAINT_TRACKING
     @ no-op 
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
+
 /* continuation for OP_SGET */
 
     /*
@@ -8524,8 +9907,47 @@ dvmAsmSisterStart:
 #endif
     b       .LOP_SGET_finish
 
+.LOP_SGET_taint_prop:
+//    .if     0
+//    add     r0, r0, #offStaticField_value		@ r0<- address of field
+//    bl      dvmQuasiAtomicRead32SfieldTaint		@ r0/r1<- value/taint
+//    .else
+    ldr	    r1, [r0, #offStaticField_taint] @ r1<- taint value
+    ldr     r0, [r0, #offStaticField_value] @ r0<- field value
+    @ no-op                             @ acquiring load
+//    .endif
+    mov     r2, rINST, lsr #8           @ r2<- AA
+    SET_TAINT_FP(r3)
+    SET_VREG_TAINT(r1, r2, r3)
+    bx      lr
+
+
 /* continuation for OP_SGET_WIDE */
 
+.LOP_SGET_WIDE_finish:
+    mov     r9, rINST, lsr #8           @ r9<- AA
+// begin WITH_TAINT_TRACKING
+    ldr	    r3, [r0, #offStaticField_taint] @ r3<- taint value
+    .if 0
+    stmfd   sp!, {r3}    
+    add     r0, r0, #offStaticField_value @ r0<- pointer to data
+    bl      dvmQuasiAtomicRead64        @ r0/r1<- contents of field
+    ldmfd   sp!, {r3}
+    .else
+    ldrd    r0, [r0, #offStaticField_value] @ r0/r1<- field value (aligned)
+    .endif
+    add     r9, rFP, r9, lsl #3         @ r9<- &fp[AA]
+    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
+//    stmia   r9, {r2-r3}                 @ vAA/vAA+1<- r2/r3
+    str	    r0, [r9, #0]
+    str	    r3, [r9, #4]
+    str	    r1, [r9, #8]
+    str	    r3, [r9, #12]
+// end WITH_TAINT_TRACKING
+
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+    GOTO_OPCODE(ip)                     @ jump to next instruction
+
     /*
      * Continuation if the field has not yet been resolved.
      *  r1:  BBBB field ref
@@ -8578,6 +10000,21 @@ dvmAsmSisterStart:
 #endif
     b       .LOP_SGET_OBJECT_finish
 
+.LOP_SGET_OBJECT_taint_prop:
+//    .if     0
+//    add     r0, r0, #offStaticField_value		@ r0<- address of field
+//    bl      dvmQuasiAtomicRead32SfieldTaint		@ r0/r1<- value/taint
+//    .else
+    ldr	    r1, [r0, #offStaticField_taint] @ r1<- taint value
+    ldr     r0, [r0, #offStaticField_value] @ r0<- field value
+    @ no-op                             @ acquiring load
+//    .endif
+    mov     r2, rINST, lsr #8           @ r2<- AA
+    SET_TAINT_FP(r3)
+    SET_VREG_TAINT(r1, r2, r3)
+    bx      lr
+
+
 /* continuation for OP_SGET_BOOLEAN */
 
     /*
@@ -8604,6 +10041,21 @@ dvmAsmSisterStart:
 #endif
     b       .LOP_SGET_BOOLEAN_finish
 
+.LOP_SGET_BOOLEAN_taint_prop:
+//    .if     0
+//    add     r0, r0, #offStaticField_value		@ r0<- address of field
+//    bl      dvmQuasiAtomicRead32SfieldTaint		@ r0/r1<- value/taint
+//    .else
+    ldr	    r1, [r0, #offStaticField_taint] @ r1<- taint value
+    ldr     r0, [r0, #offStaticField_value] @ r0<- field value
+    @ no-op                             @ acquiring load
+//    .endif
+    mov     r2, rINST, lsr #8           @ r2<- AA
+    SET_TAINT_FP(r3)
+    SET_VREG_TAINT(r1, r2, r3)
+    bx      lr
+
+
 /* continuation for OP_SGET_BYTE */
 
     /*
@@ -8630,8 +10082,23 @@ dvmAsmSisterStart:
 #endif
     b       .LOP_SGET_BYTE_finish
 
-/* continuation for OP_SGET_CHAR */
-
+.LOP_SGET_BYTE_taint_prop:
+//    .if     0
+//    add     r0, r0, #offStaticField_value		@ r0<- address of field
+//    bl      dvmQuasiAtomicRead32SfieldTaint		@ r0/r1<- value/taint
+//    .else
+    ldr	    r1, [r0, #offStaticField_taint] @ r1<- taint value
+    ldr     r0, [r0, #offStaticField_value] @ r0<- field value
+    @ no-op                             @ acquiring load
+//    .endif
+    mov     r2, rINST, lsr #8           @ r2<- AA
+    SET_TAINT_FP(r3)
+    SET_VREG_TAINT(r1, r2, r3)
+    bx      lr
+
+
+/* continuation for OP_SGET_CHAR */
+
     /*
      * Continuation if the field has not yet been resolved.
      *  r1:  BBBB field ref
@@ -8656,6 +10123,21 @@ dvmAsmSisterStart:
 #endif
     b       .LOP_SGET_CHAR_finish
 
+.LOP_SGET_CHAR_taint_prop:
+//    .if     0
+//    add     r0, r0, #offStaticField_value		@ r0<- address of field
+//    bl      dvmQuasiAtomicRead32SfieldTaint		@ r0/r1<- value/taint
+//    .else
+    ldr	    r1, [r0, #offStaticField_taint] @ r1<- taint value
+    ldr     r0, [r0, #offStaticField_value] @ r0<- field value
+    @ no-op                             @ acquiring load
+//    .endif
+    mov     r2, rINST, lsr #8           @ r2<- AA
+    SET_TAINT_FP(r3)
+    SET_VREG_TAINT(r1, r2, r3)
+    bx      lr
+
+
 /* continuation for OP_SGET_SHORT */
 
     /*
@@ -8682,6 +10164,21 @@ dvmAsmSisterStart:
 #endif
     b       .LOP_SGET_SHORT_finish
 
+.LOP_SGET_SHORT_taint_prop:
+//    .if     0
+//    add     r0, r0, #offStaticField_value		@ r0<- address of field
+//    bl      dvmQuasiAtomicRead32SfieldTaint		@ r0/r1<- value/taint
+//    .else
+    ldr	    r1, [r0, #offStaticField_taint] @ r1<- taint value
+    ldr     r0, [r0, #offStaticField_value] @ r0<- field value
+    @ no-op                             @ acquiring load
+//    .endif
+    mov     r2, rINST, lsr #8           @ r2<- AA
+    SET_TAINT_FP(r3)
+    SET_VREG_TAINT(r1, r2, r3)
+    bx      lr
+
+
 /* continuation for OP_SPUT */
 
     /*
@@ -8708,6 +10205,25 @@ dvmAsmSisterStart:
 #endif
     b       .LOP_SPUT_finish          @ resume
 
+.LOP_SPUT_taint_prop:
+//    .if     0
+//    add     r3, r0, #offStaticField_value   @ r3<- addr
+//    mov     r0, r1                          @ r0<- val
+//    mov     r1, r3                          @ r1<- addr
+//    SET_TAINT_FP(r3)
+//    GET_VREG_TAINT(r2, r2, r3)              @ r2<- taint
+//    bl      dvmQuasiAtomicSwap32SfieldTaint
+//    .else
+    @ no-op                        	    @ releasing store
+    str     r1, [r0, #offStaticField_value] @ field<- vAA
+    SET_TAINT_FP(r3)
+    GET_VREG_TAINT(r1, r2, r3)
+    str	    r1, [r0, #offStaticField_taint]
+    @ no-op 
+//    .endif
+    bx      lr
+
+
 /* continuation for OP_SPUT_WIDE */
 
     /*
@@ -8738,14 +10254,35 @@ dvmAsmSisterStart:
 #endif
     b       .LOP_SPUT_WIDE_finish          @ resume
 
+.LOP_SPUT_WIDE_taint_prop:
+//    ldmia   r9, {r0-r1}                 @ r0/r1<- vAA/vAA+1
+    ldr r3, [r9, #4]
+    ldr r0, [r9, #0]
+    ldr r1, [r9, #8]
+    bx      lr
+
+
 /* continuation for OP_SPUT_OBJECT */
 
 
 .LOP_SPUT_OBJECT_end:
-    str     r1, [r0, #offStaticField_value]  @ field<- vAA
-    @ no-op 
-    cmp     r1, #0                      @ stored a null object?
-    strneb  r2, [r2, r9, lsr #GC_CARD_SHIFT]  @ mark card based on obj head
+// begin WITH_TAINT_TRACKING
+//    .if     0
+//    add	    r2, r0, #offStaticField_value       @ r2<- addr
+//    mov	    r0, r1                              @ r0<- val
+//    mov	    r1, r2                              @ r1<- addr
+//    mov	    r2, r3                              @ r2<- taint
+//    bl      dvmQuasiAtomicSwap32SfieldTaint
+//    cmp     r0, #0                    	        @ stored a null object?
+//    .else
+    str     r1, [r0, #offStaticField_value] @ field<- vAA
+    str	    r3, [r0, #offStaticField_taint]
+//    @ no-op 
+    cmp     r1, #0                              @ stored a null object?
+//    .endif
+//    strneb  r2, [r2, r9, lsr #GC_CARD_SHIFT]  @ mark card based on obj head
+    strneb  r10, [r10, r9, lsr #GC_CARD_SHIFT]  @ mark card based on obj head
+// end WITH_TAINT_TRACKING
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
     /* Continuation if the field has not yet been resolved.
@@ -8798,6 +10335,25 @@ dvmAsmSisterStart:
 #endif
     b       .LOP_SPUT_BOOLEAN_finish          @ resume
 
+.LOP_SPUT_BOOLEAN_taint_prop:
+//    .if     0
+//    add     r3, r0, #offStaticField_value   @ r3<- addr
+//    mov     r0, r1                          @ r0<- val
+//    mov     r1, r3                          @ r1<- addr
+//    SET_TAINT_FP(r3)
+//    GET_VREG_TAINT(r2, r2, r3)              @ r2<- taint
+//    bl      dvmQuasiAtomicSwap32SfieldTaint
+//    .else
+    @ no-op                        	    @ releasing store
+    str     r1, [r0, #offStaticField_value] @ field<- vAA
+    SET_TAINT_FP(r3)
+    GET_VREG_TAINT(r1, r2, r3)
+    str	    r1, [r0, #offStaticField_taint]
+    @ no-op 
+//    .endif
+    bx      lr
+
+
 /* continuation for OP_SPUT_BYTE */
 
     /*
@@ -8824,6 +10380,25 @@ dvmAsmSisterStart:
 #endif
     b       .LOP_SPUT_BYTE_finish          @ resume
 
+.LOP_SPUT_BYTE_taint_prop:
+//    .if     0
+//    add     r3, r0, #offStaticField_value   @ r3<- addr
+//    mov     r0, r1                          @ r0<- val
+//    mov     r1, r3                          @ r1<- addr
+//    SET_TAINT_FP(r3)
+//    GET_VREG_TAINT(r2, r2, r3)              @ r2<- taint
+//    bl      dvmQuasiAtomicSwap32SfieldTaint
+//    .else
+    @ no-op                        	    @ releasing store
+    str     r1, [r0, #offStaticField_value] @ field<- vAA
+    SET_TAINT_FP(r3)
+    GET_VREG_TAINT(r1, r2, r3)
+    str	    r1, [r0, #offStaticField_taint]
+    @ no-op 
+//    .endif
+    bx      lr
+
+
 /* continuation for OP_SPUT_CHAR */
 
     /*
@@ -8850,6 +10425,25 @@ dvmAsmSisterStart:
 #endif
     b       .LOP_SPUT_CHAR_finish          @ resume
 
+.LOP_SPUT_CHAR_taint_prop:
+//    .if     0
+//    add     r3, r0, #offStaticField_value   @ r3<- addr
+//    mov     r0, r1                          @ r0<- val
+//    mov     r1, r3                          @ r1<- addr
+//    SET_TAINT_FP(r3)
+//    GET_VREG_TAINT(r2, r2, r3)              @ r2<- taint
+//    bl      dvmQuasiAtomicSwap32SfieldTaint
+//    .else
+    @ no-op                        	    @ releasing store
+    str     r1, [r0, #offStaticField_value] @ field<- vAA
+    SET_TAINT_FP(r3)
+    GET_VREG_TAINT(r1, r2, r3)
+    str	    r1, [r0, #offStaticField_taint]
+    @ no-op 
+//    .endif
+    bx      lr
+
+
 /* continuation for OP_SPUT_SHORT */
 
     /*
@@ -8876,6 +10470,25 @@ dvmAsmSisterStart:
 #endif
     b       .LOP_SPUT_SHORT_finish          @ resume
 
+.LOP_SPUT_SHORT_taint_prop:
+//    .if     0
+//    add     r3, r0, #offStaticField_value   @ r3<- addr
+//    mov     r0, r1                          @ r0<- val
+//    mov     r1, r3                          @ r1<- addr
+//    SET_TAINT_FP(r3)
+//    GET_VREG_TAINT(r2, r2, r3)              @ r2<- taint
+//    bl      dvmQuasiAtomicSwap32SfieldTaint
+//    .else
+    @ no-op                        	    @ releasing store
+    str     r1, [r0, #offStaticField_value] @ field<- vAA
+    SET_TAINT_FP(r3)
+    GET_VREG_TAINT(r1, r2, r3)
+    str	    r1, [r0, #offStaticField_taint]
+    @ no-op 
+//    .endif
+    bx      lr
+
+
 /* continuation for OP_INVOKE_VIRTUAL */
 
     /*
@@ -9076,145 +10689,1154 @@ dvmAsmSisterStart:
     b       common_exceptionThrown            @ yes, handle exception
 #endif
 
-/* continuation for OP_FLOAT_TO_LONG */
-/*
- * Convert the float in r0 to a long in r0/r1.
- *
- * We have to clip values to long min/max per the specification.  The
- * expected common case is a "reasonable" value that converts directly
- * to modest integer.  The EABI convert function isn't doing this for us.
- */
-f2l_doconv:
-    stmfd   sp!, {r4, lr}
-    mov     r1, #0x5f000000             @ (float)maxlong
-    mov     r4, r0
-    bl      __aeabi_fcmpge              @ is arg >= maxlong?
-    cmp     r0, #0                      @ nonzero == yes
-    mvnne   r0, #0                      @ return maxlong (7fffffff)
-    mvnne   r1, #0x80000000
-    ldmnefd sp!, {r4, pc}
+/* continuation for OP_NEG_LONG */
+
+.LOP_NEG_LONG_finish:
+// begin WITH_TAINT_TRACKING
+//    stmia   r9, {r0-r1}                 @ vAA<- r0/r1
+    str     r0, [r9, #0]
+    str     r10, [r9, #4]
+    str     r1, [r9, #8]
+    str     r10, [r9, #12]
+// end WITH_TAINT_TRACKING
+    GOTO_OPCODE(ip)                     @ jump to next instruction
+    /* 10-11 instructions */
+
+/* continuation for OP_NOT_LONG */
+
+.LOP_NOT_LONG_finish:
+// begin WITH_TAINT_TRACKING
+//    stmia   r9, {r0-r1}                 @ vAA<- r0/r1
+    str     r0, [r9, #0]
+    str     r10, [r9, #4]
+    str     r1, [r9, #8]
+    str     r10, [r9, #12]
+// end WITH_TAINT_TRACKING
+    GOTO_OPCODE(ip)                     @ jump to next instruction
+    /* 10-11 instructions */
+
+/* continuation for OP_NEG_DOUBLE */
+
+.LOP_NEG_DOUBLE_finish:
+// begin WITH_TAINT_TRACKING
+//    stmia   r9, {r0-r1}                 @ vAA<- r0/r1
+    str     r0, [r9, #0]
+    str     r10, [r9, #4]
+    str     r1, [r9, #8]
+    str     r10, [r9, #12]
+// end WITH_TAINT_TRACKING
+    GOTO_OPCODE(ip)                     @ jump to next instruction
+    /* 10-11 instructions */
+
+/* continuation for OP_INT_TO_LONG */
+
+.LOP_INT_TO_LONG_finish:
+// begin WITH_TAINT_TRACKING
+//    stmia   r9, {r0-r1}                 @ vA/vA+1<- r0/r1
+    str     r0, [r9, #0]
+    str     r10, [r9, #4]
+    str     r1, [r9, #8]
+    str     r10, [r9, #12]
+// end WITH_TAINT_TRACKING
+    GOTO_OPCODE(ip)                     @ jump to next instruction
+    /* 9-10 instructions */
+
+/* continuation for OP_LONG_TO_DOUBLE */
+
+.LOP_LONG_TO_DOUBLE_finish:
+// begin WITH_TAINT_TRACKING
+//    stmia   r9, {r0-r1}                 @ vAA<- r0/r1
+    str     r0, [r9, #0]
+    str     r10, [r9, #4]
+    str     r1, [r9, #8]
+    str     r10, [r9, #12]
+// end WITH_TAINT_TRACKING
+    GOTO_OPCODE(ip)                     @ jump to next instruction
+    /* 10-11 instructions */
+
+/* continuation for OP_FLOAT_TO_LONG */
+
+.LOP_FLOAT_TO_LONG_finish:
+// begin WITH_TAINT_TRACKING
+//    stmia   r9, {r0-r1}                 @ vA/vA+1<- r0/r1
+    str     r0, [r9, #0]
+    str     r10, [r9, #4]
+    str     r1, [r9, #8]
+    str     r10, [r9, #12]
+// end WITH_TAINT_TRACKING
+    GOTO_OPCODE(ip)                     @ jump to next instruction
+    /* 9-10 instructions */
+
+/* continuation for OP_FLOAT_TO_LONG */
+/*
+ * Convert the float in r0 to a long in r0/r1.
+ *
+ * We have to clip values to long min/max per the specification.  The
+ * expected common case is a "reasonable" value that converts directly
+ * to modest integer.  The EABI convert function isn't doing this for us.
+ */
+f2l_doconv:
+    stmfd   sp!, {r4, lr}
+    mov     r1, #0x5f000000             @ (float)maxlong
+    mov     r4, r0
+    bl      __aeabi_fcmpge              @ is arg >= maxlong?
+    cmp     r0, #0                      @ nonzero == yes
+    mvnne   r0, #0                      @ return maxlong (7fffffff)
+    mvnne   r1, #0x80000000
+    ldmnefd sp!, {r4, pc}
+
+    mov     r0, r4                      @ recover arg
+    mov     r1, #0xdf000000             @ (float)minlong
+    bl      __aeabi_fcmple              @ is arg <= minlong?
+    cmp     r0, #0                      @ nonzero == yes
+    movne   r0, #0                      @ return minlong (80000000)
+    movne   r1, #0x80000000
+    ldmnefd sp!, {r4, pc}
+
+    mov     r0, r4                      @ recover arg
+    mov     r1, r4
+    bl      __aeabi_fcmpeq              @ is arg == self?
+    cmp     r0, #0                      @ zero == no
+    moveq   r1, #0                      @ return zero for NaN
+    ldmeqfd sp!, {r4, pc}
+
+    mov     r0, r4                      @ recover arg
+    bl      __aeabi_f2lz                @ convert float to long
+    ldmfd   sp!, {r4, pc}
+
+
+/* continuation for OP_DOUBLE_TO_LONG */
+
+.LOP_DOUBLE_TO_LONG_finish:
+// begin WITH_TAINT_TRACKING
+//    stmia   r9, {r0-r1}                 @ vAA<- r0/r1
+    str     r0, [r9, #0]
+    str     r10, [r9, #4]
+    str     r1, [r9, #8]
+    str     r10, [r9, #12]
+// end WITH_TAINT_TRACKING
+    GOTO_OPCODE(ip)                     @ jump to next instruction
+    /* 10-11 instructions */
+
+/* continuation for OP_DOUBLE_TO_LONG */
+/*
+ * Convert the double in r0/r1 to a long in r0/r1.
+ *
+ * We have to clip values to long min/max per the specification.  The
+ * expected common case is a "reasonable" value that converts directly
+ * to modest integer.  The EABI convert function isn't doing this for us.
+ */
+d2l_doconv:
+    stmfd   sp!, {r4, r5, lr}           @ save regs
+    mov     r3, #0x43000000             @ maxlong, as a double (high word)
+    add     r3, #0x00e00000             @  0x43e00000
+    mov     r2, #0                      @ maxlong, as a double (low word)
+    sub     sp, sp, #4                  @ align for EABI
+    mov     r4, r0                      @ save a copy of r0
+    mov     r5, r1                      @  and r1
+    bl      __aeabi_dcmpge              @ is arg >= maxlong?
+    cmp     r0, #0                      @ nonzero == yes
+    mvnne   r0, #0                      @ return maxlong (7fffffffffffffff)
+    mvnne   r1, #0x80000000
+    bne     1f
+
+    mov     r0, r4                      @ recover arg
+    mov     r1, r5
+    mov     r3, #0xc3000000             @ minlong, as a double (high word)
+    add     r3, #0x00e00000             @  0xc3e00000
+    mov     r2, #0                      @ minlong, as a double (low word)
+    bl      __aeabi_dcmple              @ is arg <= minlong?
+    cmp     r0, #0                      @ nonzero == yes
+    movne   r0, #0                      @ return minlong (8000000000000000)
+    movne   r1, #0x80000000
+    bne     1f
+
+    mov     r0, r4                      @ recover arg
+    mov     r1, r5
+    mov     r2, r4                      @ compare against self
+    mov     r3, r5
+    bl      __aeabi_dcmpeq              @ is arg == self?
+    cmp     r0, #0                      @ zero == no
+    moveq   r1, #0                      @ return zero for NaN
+    beq     1f
+
+    mov     r0, r4                      @ recover arg
+    mov     r1, r5
+    bl      __aeabi_d2lz                @ convert double to long
+
+1:
+    add     sp, sp, #4
+    ldmfd   sp!, {r4, r5, pc}
+
+
+/* continuation for OP_ADD_INT */
+
+.LOP_ADD_INT_taint_prop:
+    SET_TAINT_FP(r10)
+    GET_VREG_TAINT(r3, r3, r10)
+    GET_VREG_TAINT(r2, r2, r10)
+    orr     r2, r3, r2
+    SET_VREG_TAINT(r2, r9, r10)
+    bx      lr
+
+/* continuation for OP_SUB_INT */
+
+.LOP_SUB_INT_taint_prop:
+    SET_TAINT_FP(r10)
+    GET_VREG_TAINT(r3, r3, r10)
+    GET_VREG_TAINT(r2, r2, r10)
+    orr     r2, r3, r2
+    SET_VREG_TAINT(r2, r9, r10)
+    bx      lr
+
+/* continuation for OP_MUL_INT */
+
+.LOP_MUL_INT_taint_prop:
+    SET_TAINT_FP(r10)
+    GET_VREG_TAINT(r3, r3, r10)
+    GET_VREG_TAINT(r2, r2, r10)
+    orr     r2, r3, r2
+    SET_VREG_TAINT(r2, r9, r10)
+    bx      lr
+
+/* continuation for OP_DIV_INT */
+
+.LOP_DIV_INT_taint_prop:
+    SET_TAINT_FP(r10)
+    GET_VREG_TAINT(r3, r3, r10)
+    GET_VREG_TAINT(r2, r2, r10)
+    orr     r2, r3, r2
+    SET_VREG_TAINT(r2, r9, r10)
+    bx      lr
+
+/* continuation for OP_REM_INT */
+
+.LOP_REM_INT_taint_prop:
+    SET_TAINT_FP(r10)
+    GET_VREG_TAINT(r3, r3, r10)
+    GET_VREG_TAINT(r2, r2, r10)
+    orr     r2, r3, r2
+    SET_VREG_TAINT(r2, r9, r10)
+    bx      lr
+
+/* continuation for OP_AND_INT */
+
+.LOP_AND_INT_taint_prop:
+    SET_TAINT_FP(r10)
+    GET_VREG_TAINT(r3, r3, r10)
+    GET_VREG_TAINT(r2, r2, r10)
+    orr     r2, r3, r2
+    SET_VREG_TAINT(r2, r9, r10)
+    bx      lr
+
+/* continuation for OP_OR_INT */
+
+.LOP_OR_INT_taint_prop:
+    SET_TAINT_FP(r10)
+    GET_VREG_TAINT(r3, r3, r10)
+    GET_VREG_TAINT(r2, r2, r10)
+    orr     r2, r3, r2
+    SET_VREG_TAINT(r2, r9, r10)
+    bx      lr
+
+/* continuation for OP_XOR_INT */
+
+.LOP_XOR_INT_taint_prop:
+    SET_TAINT_FP(r10)
+    GET_VREG_TAINT(r3, r3, r10)
+    GET_VREG_TAINT(r2, r2, r10)
+    orr     r2, r3, r2
+    SET_VREG_TAINT(r2, r9, r10)
+    bx      lr
+
+/* continuation for OP_SHL_INT */
+
+.LOP_SHL_INT_taint_prop:
+    SET_TAINT_FP(r10)
+    GET_VREG_TAINT(r3, r3, r10)
+    GET_VREG_TAINT(r2, r2, r10)
+    orr     r2, r3, r2
+    SET_VREG_TAINT(r2, r9, r10)
+    bx      lr
+
+/* continuation for OP_SHR_INT */
+
+.LOP_SHR_INT_taint_prop:
+    SET_TAINT_FP(r10)
+    GET_VREG_TAINT(r3, r3, r10)
+    GET_VREG_TAINT(r2, r2, r10)
+    orr     r2, r3, r2
+    SET_VREG_TAINT(r2, r9, r10)
+    bx      lr
+
+/* continuation for OP_USHR_INT */
+
+.LOP_USHR_INT_taint_prop:
+    SET_TAINT_FP(r10)
+    GET_VREG_TAINT(r3, r3, r10)
+    GET_VREG_TAINT(r2, r2, r10)
+    orr     r2, r3, r2
+    SET_VREG_TAINT(r2, r9, r10)
+    bx      lr
+
+/* continuation for OP_ADD_LONG */
+
+.LOP_ADD_LONG_taint_prop:
+    add     r9, rFP, r9, lsl #3         @ r9<- &fp[AA]
+    stmfd   sp!, {r9}
+    add     r2, rFP, r2, lsl #3         @ r2<- &fp[BB]
+    add     r3, rFP, r3, lsl #3         @ r3<- &fp[CC]
+//    ldmia   r2, {r0-r1}                 @ r0/r1<- vBB/vBB+1
+    ldr     r0, [r2, #0]
+    ldr     r9, [r2, #4]
+    ldr     r1, [r2, #8]
+//    ldmia   r3, {r2-r3}                 @ r2/r3<- vCC/vCC+1
+    ldr     r2, [r3, #0]
+    ldr     r10, [r3, #4]
+    ldr     r3, [r3, #8]
+    orr     r10, r9, r10
+    ldmfd   sp!, {r9}
+    bx      lr
+
+/* continuation for OP_SUB_LONG */
+
+.LOP_SUB_LONG_taint_prop:
+    add     r9, rFP, r9, lsl #3         @ r9<- &fp[AA]
+    stmfd   sp!, {r9}
+    add     r2, rFP, r2, lsl #3         @ r2<- &fp[BB]
+    add     r3, rFP, r3, lsl #3         @ r3<- &fp[CC]
+//    ldmia   r2, {r0-r1}                 @ r0/r1<- vBB/vBB+1
+    ldr     r0, [r2, #0]
+    ldr     r9, [r2, #4]
+    ldr     r1, [r2, #8]
+//    ldmia   r3, {r2-r3}                 @ r2/r3<- vCC/vCC+1
+    ldr     r2, [r3, #0]
+    ldr     r10, [r3, #4]
+    ldr     r3, [r3, #8]
+    orr     r10, r9, r10
+    ldmfd   sp!, {r9}
+    bx      lr
+
+/* continuation for OP_MUL_LONG */
+
+.LOP_MUL_LONG_finish:
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+// begin WITH_TAINT_TRACKING
+//    stmia   r0, {r9-r10}                @ vAA/vAA+1<- r9/r10
+    str     r9, [r0, #0]
+    str     r10, [r0, #8]
+    str     r10, [r0, #12]
+    ldmfd   sp!, {r10}
+    str     r10, [r0, #4]
+// end WITH_TAINT_TRACKING
+    GOTO_OPCODE(ip)                     @ jump to next instruction
+
+mul_long_taint_prop:
+    add     r2, rFP, r2, lsl #3         @ r2<- &fp[BB]
+    add     r3, rFP, r3, lsl #3         @ r3<- &fp[CC]
+//    ldmia   r2, {r0-r1}                 @ r0/r1<- vBB/vBB+1
+    ldr     r0, [r2, #0]
+    ldr     r9, [r2, #4]
+    ldr     r1, [r2, #8]
+//    ldmia   r3, {r2-r3}                 @ r2/r3<- vCC/vCC+1
+    ldr     r2, [r3, #0]
+    ldr     r10, [r3, #4]
+    ldr     r3, [r3, #8]
+    orr     r10, r9, r10
+    stmfd   sp!, {r10}
+    bx      lr
+
+/* continuation for OP_DIV_LONG */
+
+.LOP_DIV_LONG_taint_prop:
+    add     r9, rFP, r9, lsl #3         @ r9<- &fp[AA]
+    stmfd   sp!, {r9}
+    add     r2, rFP, r2, lsl #3         @ r2<- &fp[BB]
+    add     r3, rFP, r3, lsl #3         @ r3<- &fp[CC]
+//    ldmia   r2, {r0-r1}                 @ r0/r1<- vBB/vBB+1
+    ldr     r0, [r2, #0]
+    ldr     r9, [r2, #4]
+    ldr     r1, [r2, #8]
+//    ldmia   r3, {r2-r3}                 @ r2/r3<- vCC/vCC+1
+    ldr     r2, [r3, #0]
+    ldr     r10, [r3, #4]
+    ldr     r3, [r3, #8]
+    orr     r10, r9, r10
+    ldmfd   sp!, {r9}
+    bx      lr
+
+/* continuation for OP_REM_LONG */
+
+.LOP_REM_LONG_taint_prop:
+    add     r9, rFP, r9, lsl #3         @ r9<- &fp[AA]
+    stmfd   sp!, {r9}
+    add     r2, rFP, r2, lsl #3         @ r2<- &fp[BB]
+    add     r3, rFP, r3, lsl #3         @ r3<- &fp[CC]
+//    ldmia   r2, {r0-r1}                 @ r0/r1<- vBB/vBB+1
+    ldr     r0, [r2, #0]
+    ldr     r9, [r2, #4]
+    ldr     r1, [r2, #8]
+//    ldmia   r3, {r2-r3}                 @ r2/r3<- vCC/vCC+1
+    ldr     r2, [r3, #0]
+    ldr     r10, [r3, #4]
+    ldr     r3, [r3, #8]
+    orr     r10, r9, r10
+    ldmfd   sp!, {r9}
+    bx      lr
+
+/* continuation for OP_AND_LONG */
+
+.LOP_AND_LONG_taint_prop:
+    add     r9, rFP, r9, lsl #3         @ r9<- &fp[AA]
+    stmfd   sp!, {r9}
+    add     r2, rFP, r2, lsl #3         @ r2<- &fp[BB]
+    add     r3, rFP, r3, lsl #3         @ r3<- &fp[CC]
+//    ldmia   r2, {r0-r1}                 @ r0/r1<- vBB/vBB+1
+    ldr     r0, [r2, #0]
+    ldr     r9, [r2, #4]
+    ldr     r1, [r2, #8]
+//    ldmia   r3, {r2-r3}                 @ r2/r3<- vCC/vCC+1
+    ldr     r2, [r3, #0]
+    ldr     r10, [r3, #4]
+    ldr     r3, [r3, #8]
+    orr     r10, r9, r10
+    ldmfd   sp!, {r9}
+    bx      lr
+
+/* continuation for OP_OR_LONG */
+
+.LOP_OR_LONG_taint_prop:
+    add     r9, rFP, r9, lsl #3         @ r9<- &fp[AA]
+    stmfd   sp!, {r9}
+    add     r2, rFP, r2, lsl #3         @ r2<- &fp[BB]
+    add     r3, rFP, r3, lsl #3         @ r3<- &fp[CC]
+//    ldmia   r2, {r0-r1}                 @ r0/r1<- vBB/vBB+1
+    ldr     r0, [r2, #0]
+    ldr     r9, [r2, #4]
+    ldr     r1, [r2, #8]
+//    ldmia   r3, {r2-r3}                 @ r2/r3<- vCC/vCC+1
+    ldr     r2, [r3, #0]
+    ldr     r10, [r3, #4]
+    ldr     r3, [r3, #8]
+    orr     r10, r9, r10
+    ldmfd   sp!, {r9}
+    bx      lr
+
+/* continuation for OP_XOR_LONG */
+
+.LOP_XOR_LONG_taint_prop:
+    add     r9, rFP, r9, lsl #3         @ r9<- &fp[AA]
+    stmfd   sp!, {r9}
+    add     r2, rFP, r2, lsl #3         @ r2<- &fp[BB]
+    add     r3, rFP, r3, lsl #3         @ r3<- &fp[CC]
+//    ldmia   r2, {r0-r1}                 @ r0/r1<- vBB/vBB+1
+    ldr     r0, [r2, #0]
+    ldr     r9, [r2, #4]
+    ldr     r1, [r2, #8]
+//    ldmia   r3, {r2-r3}                 @ r2/r3<- vCC/vCC+1
+    ldr     r2, [r3, #0]
+    ldr     r10, [r3, #4]
+    ldr     r3, [r3, #8]
+    orr     r10, r9, r10
+    ldmfd   sp!, {r9}
+    bx      lr
+
+/* continuation for OP_SHL_LONG */
+
+.LOP_SHL_LONG_finish:
+    mov     r0, r0, asl r2              @  r0<- r0 << r2
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+// begin WITH_TAINT_TRACKING
+//    stmia   r9, {r0-r1}                 @ vAA/vAA+1<- r0/r1
+    str     r0, [r9, #0]
+    str     r10, [r9, #4]
+    str     r1, [r9, #8]
+    str     r10, [r9, #12]
+// end WITH_TAINT_TRACKING
+    GOTO_OPCODE(ip)                     @ jump to next instruction
+
+shl_long_taint_prop:
+    add     r3, rFP, r3, lsl #3         @ r3<- &fp[BB]
+    GET_VREG(r2, r0)                    @ r2<- vCC
+    SET_TAINT_FP(r1)
+    GET_VREG_TAINT(r0, r0, r1)
+//    ldmia   r3, {r0-r1}                 @ r0/r1<- vBB/vBB+1
+    ldr     r1, [r3, #4]
+    orr     r10, r0, r1
+    ldr     r0, [r3, #0]
+    ldr     r1, [r3, #8]
+    and     r2, r2, #63                 @ r2<- r2 & 0x3f
+    add     r9, rFP, r9, lsl #3         @ r9<- &fp[AA]
+    bx      lr
+
+/* continuation for OP_SHR_LONG */
+
+.LOP_SHR_LONG_finish:
+    mov     r1, r1, asr r2              @  r1<- r1 >> r2
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+// begin WITH_TAINT_TRACKING
+//    stmia   r9, {r0-r1}                 @ vAA/vAA+1<- r0/r1
+    str     r0, [r9, #0]
+    str     r10, [r9, #4]
+    str     r1, [r9, #8]
+    str     r10, [r9, #12]
+// end WITH_TAINT_TRACKING
+    GOTO_OPCODE(ip)                     @ jump to next instruction
+
+shr_long_taint_prop:
+    add     r3, rFP, r3, lsl #3         @ r3<- &fp[BB]
+    GET_VREG(r2, r0)                    @ r2<- vCC
+    SET_TAINT_FP(r1)
+    GET_VREG_TAINT(r0, r0, r1)
+//    ldmia   r3, {r0-r1}                 @ r0/r1<- vBB/vBB+1
+    ldr     r1, [r3, #4]
+    orr     r10, r0, r1
+    ldr     r0, [r3, #0]
+    ldr     r1, [r3, #8]
+    and     r2, r2, #63                 @ r2<- r2 & 0x3f
+    add     r9, rFP, r9, lsl #3         @ r9<- &fp[AA]
+    bx      lr
+
+/* continuation for OP_USHR_LONG */
+
+.LOP_USHR_LONG_finish:
+    mov     r1, r1, lsr r2              @  r1<- r1 >>> r2
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+// begin WITH_TAINT_TRACKING
+//    stmia   r9, {r0-r1}                 @ vAA/vAA+1<- r0/r1
+    str     r0, [r9, #0]
+    str     r10, [r9, #4]
+    str     r1, [r9, #8]
+    str     r10, [r9, #12]
+// end WITH_TAINT_TRACKING
+    GOTO_OPCODE(ip)                     @ jump to next instruction
+
+ushr_long_taint_prop:
+    add     r3, rFP, r3, lsl #3         @ r3<- &fp[BB]
+    GET_VREG(r2, r0)                    @ r2<- vCC
+    SET_TAINT_FP(r1)
+    GET_VREG_TAINT(r0, r0, r1)
+//    ldmia   r3, {r0-r1}                 @ r0/r1<- vBB/vBB+1
+    ldr     r1, [r3, #4]
+    orr     r10, r0, r1
+    ldr     r0, [r3, #0]
+    ldr     r1, [r3, #8]
+    and     r2, r2, #63                 @ r0<- r0 & 0x3f
+    add     r9, rFP, r9, lsl #3         @ r9<- &fp[AA]
+    bx      lr
+
+/* continuation for OP_ADD_FLOAT */
+
+.LOP_ADD_FLOAT_finish:
+    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
+    fadds   s2, s0, s1                              @ s2<- op
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+    VREG_INDEX_TO_ADDR(r9, r9)          @ r9<- &vAA
+    fsts    s2, [r9]                    @ vAA<- s2
+// begin WITH_TAINT_TRACKING
+    str     r0, [r9, #4]
+// end WITH_TAINT_TRACKING
+    GOTO_OPCODE(ip)                     @ jump to next instruction
+
+
+/* continuation for OP_SUB_FLOAT */
+
+.LOP_SUB_FLOAT_finish:
+    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
+    fsubs   s2, s0, s1                              @ s2<- op
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+    VREG_INDEX_TO_ADDR(r9, r9)          @ r9<- &vAA
+    fsts    s2, [r9]                    @ vAA<- s2
+// begin WITH_TAINT_TRACKING
+    str     r0, [r9, #4]
+// end WITH_TAINT_TRACKING
+    GOTO_OPCODE(ip)                     @ jump to next instruction
+
+
+/* continuation for OP_MUL_FLOAT */
+
+.LOP_MUL_FLOAT_finish:
+    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
+    fmuls   s2, s0, s1                              @ s2<- op
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+    VREG_INDEX_TO_ADDR(r9, r9)          @ r9<- &vAA
+    fsts    s2, [r9]                    @ vAA<- s2
+// begin WITH_TAINT_TRACKING
+    str     r0, [r9, #4]
+// end WITH_TAINT_TRACKING
+    GOTO_OPCODE(ip)                     @ jump to next instruction
+
+
+/* continuation for OP_DIV_FLOAT */
+
+.LOP_DIV_FLOAT_finish:
+    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
+    fdivs   s2, s0, s1                              @ s2<- op
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+    VREG_INDEX_TO_ADDR(r9, r9)          @ r9<- &vAA
+    fsts    s2, [r9]                    @ vAA<- s2
+// begin WITH_TAINT_TRACKING
+    str     r0, [r9, #4]
+// end WITH_TAINT_TRACKING
+    GOTO_OPCODE(ip)                     @ jump to next instruction
+
+
+/* continuation for OP_REM_FLOAT */
+
+.LOP_REM_FLOAT_taint_prop:
+    SET_TAINT_FP(r10)
+    GET_VREG_TAINT(r3, r3, r10)
+    GET_VREG_TAINT(r2, r2, r10)
+    orr     r2, r3, r2
+    SET_VREG_TAINT(r2, r9, r10)
+    bx      lr
+
+/* continuation for OP_ADD_DOUBLE */
+
+.LOP_ADD_DOUBLE_finish:
+    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
+    faddd   d2, d0, d1                              @ s2<- op
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+    VREG_INDEX_TO_ADDR(r9, r9)          @ r9<- &vAA
+// begin WITH_TAINT_TRACKING
+//    fstd    d2, [r9]                    @ vAA<- d2
+    fsts    s4, [r9]
+    fsts    s5, [r9, #8]
+    str     r0, [r9, #4]
+    str     r0, [r9, #12]
+// end WITH_TAINT_TRACKING
+    GOTO_OPCODE(ip)                     @ jump to next instruction
+
+/* continuation for OP_SUB_DOUBLE */
+
+.LOP_SUB_DOUBLE_finish:
+    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
+    fsubd   d2, d0, d1                              @ s2<- op
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+    VREG_INDEX_TO_ADDR(r9, r9)          @ r9<- &vAA
+// begin WITH_TAINT_TRACKING
+//    fstd    d2, [r9]                    @ vAA<- d2
+    fsts    s4, [r9]
+    fsts    s5, [r9, #8]
+    str     r0, [r9, #4]
+    str     r0, [r9, #12]
+// end WITH_TAINT_TRACKING
+    GOTO_OPCODE(ip)                     @ jump to next instruction
+
+/* continuation for OP_MUL_DOUBLE */
+
+.LOP_MUL_DOUBLE_finish:
+    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
+    fmuld   d2, d0, d1                              @ s2<- op
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+    VREG_INDEX_TO_ADDR(r9, r9)          @ r9<- &vAA
+// begin WITH_TAINT_TRACKING
+//    fstd    d2, [r9]                    @ vAA<- d2
+    fsts    s4, [r9]
+    fsts    s5, [r9, #8]
+    str     r0, [r9, #4]
+    str     r0, [r9, #12]
+// end WITH_TAINT_TRACKING
+    GOTO_OPCODE(ip)                     @ jump to next instruction
+
+/* continuation for OP_DIV_DOUBLE */
+
+.LOP_DIV_DOUBLE_finish:
+    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
+    fdivd   d2, d0, d1                              @ s2<- op
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+    VREG_INDEX_TO_ADDR(r9, r9)          @ r9<- &vAA
+// begin WITH_TAINT_TRACKING
+//    fstd    d2, [r9]                    @ vAA<- d2
+    fsts    s4, [r9]
+    fsts    s5, [r9, #8]
+    str     r0, [r9, #4]
+    str     r0, [r9, #12]
+// end WITH_TAINT_TRACKING
+    GOTO_OPCODE(ip)                     @ jump to next instruction
+
+/* continuation for OP_REM_DOUBLE */
+
+.LOP_REM_DOUBLE_taint_prop:
+    add     r9, rFP, r9, lsl #3         @ r9<- &fp[AA]
+    stmfd   sp!, {r9}
+    add     r2, rFP, r2, lsl #3         @ r2<- &fp[BB]
+    add     r3, rFP, r3, lsl #3         @ r3<- &fp[CC]
+//    ldmia   r2, {r0-r1}                 @ r0/r1<- vBB/vBB+1
+    ldr     r0, [r2, #0]
+    ldr     r9, [r2, #4]
+    ldr     r1, [r2, #8]
+//    ldmia   r3, {r2-r3}                 @ r2/r3<- vCC/vCC+1
+    ldr     r2, [r3, #0]
+    ldr     r10, [r3, #4]
+    ldr     r3, [r3, #8]
+    orr     r10, r9, r10
+    ldmfd   sp!, {r9}
+    bx      lr
+
+/* continuation for OP_ADD_INT_2ADDR */
+
+.LOP_ADD_INT_2ADDR_taint_prop:
+    SET_TAINT_FP(r2)
+    GET_VREG_TAINT(r3, r3, r2)
+    GET_VREG_TAINT(r10, r9, r2)
+    orr     r10, r3, r10
+    SET_VREG_TAINT(r10, r9, r2)
+    bx      lr
+
+/* continuation for OP_SUB_INT_2ADDR */
+
+.LOP_SUB_INT_2ADDR_taint_prop:
+    SET_TAINT_FP(r2)
+    GET_VREG_TAINT(r3, r3, r2)
+    GET_VREG_TAINT(r10, r9, r2)
+    orr     r10, r3, r10
+    SET_VREG_TAINT(r10, r9, r2)
+    bx      lr
+
+/* continuation for OP_MUL_INT_2ADDR */
+
+.LOP_MUL_INT_2ADDR_taint_prop:
+    SET_TAINT_FP(r2)
+    GET_VREG_TAINT(r3, r3, r2)
+    GET_VREG_TAINT(r10, r9, r2)
+    orr     r10, r3, r10
+    SET_VREG_TAINT(r10, r9, r2)
+    bx      lr
+
+/* continuation for OP_DIV_INT_2ADDR */
+
+.LOP_DIV_INT_2ADDR_taint_prop:
+    SET_TAINT_FP(r2)
+    GET_VREG_TAINT(r3, r3, r2)
+    GET_VREG_TAINT(r10, r9, r2)
+    orr     r10, r3, r10
+    SET_VREG_TAINT(r10, r9, r2)
+    bx      lr
+
+/* continuation for OP_REM_INT_2ADDR */
+
+.LOP_REM_INT_2ADDR_taint_prop:
+    SET_TAINT_FP(r2)
+    GET_VREG_TAINT(r3, r3, r2)
+    GET_VREG_TAINT(r10, r9, r2)
+    orr     r10, r3, r10
+    SET_VREG_TAINT(r10, r9, r2)
+    bx      lr
+
+/* continuation for OP_AND_INT_2ADDR */
+
+.LOP_AND_INT_2ADDR_taint_prop:
+    SET_TAINT_FP(r2)
+    GET_VREG_TAINT(r3, r3, r2)
+    GET_VREG_TAINT(r10, r9, r2)
+    orr     r10, r3, r10
+    SET_VREG_TAINT(r10, r9, r2)
+    bx      lr
+
+/* continuation for OP_OR_INT_2ADDR */
+
+.LOP_OR_INT_2ADDR_taint_prop:
+    SET_TAINT_FP(r2)
+    GET_VREG_TAINT(r3, r3, r2)
+    GET_VREG_TAINT(r10, r9, r2)
+    orr     r10, r3, r10
+    SET_VREG_TAINT(r10, r9, r2)
+    bx      lr
+
+/* continuation for OP_XOR_INT_2ADDR */
+
+.LOP_XOR_INT_2ADDR_taint_prop:
+    SET_TAINT_FP(r2)
+    GET_VREG_TAINT(r3, r3, r2)
+    GET_VREG_TAINT(r10, r9, r2)
+    orr     r10, r3, r10
+    SET_VREG_TAINT(r10, r9, r2)
+    bx      lr
+
+/* continuation for OP_SHL_INT_2ADDR */
+
+.LOP_SHL_INT_2ADDR_taint_prop:
+    SET_TAINT_FP(r2)
+    GET_VREG_TAINT(r3, r3, r2)
+    GET_VREG_TAINT(r10, r9, r2)
+    orr     r10, r3, r10
+    SET_VREG_TAINT(r10, r9, r2)
+    bx      lr
+
+/* continuation for OP_SHR_INT_2ADDR */
+
+.LOP_SHR_INT_2ADDR_taint_prop:
+    SET_TAINT_FP(r2)
+    GET_VREG_TAINT(r3, r3, r2)
+    GET_VREG_TAINT(r10, r9, r2)
+    orr     r10, r3, r10
+    SET_VREG_TAINT(r10, r9, r2)
+    bx      lr
+
+/* continuation for OP_USHR_INT_2ADDR */
+
+.LOP_USHR_INT_2ADDR_taint_prop:
+    SET_TAINT_FP(r2)
+    GET_VREG_TAINT(r3, r3, r2)
+    GET_VREG_TAINT(r10, r9, r2)
+    orr     r10, r3, r10
+    SET_VREG_TAINT(r10, r9, r2)
+    bx      lr
+
+/* continuation for OP_ADD_LONG_2ADDR */
+
+.LOP_ADD_LONG_2ADDR_taint_prop:
+    add     r1, rFP, r1, lsl #3         @ r1<- &fp[B]
+    add     r9, rFP, r9, lsl #3         @ r9<- &fp[A]
+//    ldmia   r1, {r2-r3}                 @ r2/r3<- vBB/vBB+1
+    ldr     r2, [r1, #0]
+    ldr     r10, [r1, #4]
+    ldr     r3, [r1, #8]
+//    ldmia   r9, {r0-r1}                 @ r0/r1<- vAA/vAA+1
+    ldr     r0, [r9, #0]
+    ldr     r1, [r9, #8]
+    stmfd   sp!, {r9}
+    ldr     r9, [r9, #4]
+    orr     r10, r9, r10
+    ldmfd   sp!, {r9}
+    bx      lr
+
+/* continuation for OP_SUB_LONG_2ADDR */
+
+.LOP_SUB_LONG_2ADDR_taint_prop:
+    add     r1, rFP, r1, lsl #3         @ r1<- &fp[B]
+    add     r9, rFP, r9, lsl #3         @ r9<- &fp[A]
+//    ldmia   r1, {r2-r3}                 @ r2/r3<- vBB/vBB+1
+    ldr     r2, [r1, #0]
+    ldr     r10, [r1, #4]
+    ldr     r3, [r1, #8]
+//    ldmia   r9, {r0-r1}                 @ r0/r1<- vAA/vAA+1
+    ldr     r0, [r9, #0]
+    ldr     r1, [r9, #8]
+    stmfd   sp!, {r9}
+    ldr     r9, [r9, #4]
+    orr     r10, r9, r10
+    ldmfd   sp!, {r9}
+    bx      lr
+
+/* continuation for OP_MUL_LONG_2ADDR */
+
+mul_long_2addr_taint_prop:
+    ubfx    r9, rINST, #8, #4           @ r9<- A
+    add     r1, rFP, r1, lsl #3         @ r1<- &fp[B]
+    add     rINST, rFP, r9, lsl #3      @ rINST<- &fp[A]
+//    ldmia   r1, {r2-r3}                 @ r2/r3<- vBB/vBB+1
+    ldr     r2, [r1, #0]
+    ldr     r9, [r1, #4]
+    ldr     r3, [r1, #8]
+//    ldmia   rINST, {r0-r1}              @ r0/r1<- vAA/vAA+1
+    ldr     r0, [rINST, #0]
+    ldr     r10, [rINST, #4]
+    ldr     r1, [rINST, #8]
+    orr     r10, r9, r10
+    stmfd   sp!, {r10}
+    mul     ip, r2, r1                  @  ip<- ZxW
+    bx      lr
+
+/* continuation for OP_DIV_LONG_2ADDR */
+
+.LOP_DIV_LONG_2ADDR_taint_prop:
+    add     r1, rFP, r1, lsl #3         @ r1<- &fp[B]
+    add     r9, rFP, r9, lsl #3         @ r9<- &fp[A]
+//    ldmia   r1, {r2-r3}                 @ r2/r3<- vBB/vBB+1
+    ldr     r2, [r1, #0]
+    ldr     r10, [r1, #4]
+    ldr     r3, [r1, #8]
+//    ldmia   r9, {r0-r1}                 @ r0/r1<- vAA/vAA+1
+    ldr     r0, [r9, #0]
+    ldr     r1, [r9, #8]
+    stmfd   sp!, {r9}
+    ldr     r9, [r9, #4]
+    orr     r10, r9, r10
+    ldmfd   sp!, {r9}
+    bx      lr
+
+/* continuation for OP_REM_LONG_2ADDR */
+
+.LOP_REM_LONG_2ADDR_taint_prop:
+    add     r1, rFP, r1, lsl #3         @ r1<- &fp[B]
+    add     r9, rFP, r9, lsl #3         @ r9<- &fp[A]
+//    ldmia   r1, {r2-r3}                 @ r2/r3<- vBB/vBB+1
+    ldr     r2, [r1, #0]
+    ldr     r10, [r1, #4]
+    ldr     r3, [r1, #8]
+//    ldmia   r9, {r0-r1}                 @ r0/r1<- vAA/vAA+1
+    ldr     r0, [r9, #0]
+    ldr     r1, [r9, #8]
+    stmfd   sp!, {r9}
+    ldr     r9, [r9, #4]
+    orr     r10, r9, r10
+    ldmfd   sp!, {r9}
+    bx      lr
+
+/* continuation for OP_AND_LONG_2ADDR */
+
+.LOP_AND_LONG_2ADDR_taint_prop:
+    add     r1, rFP, r1, lsl #3         @ r1<- &fp[B]
+    add     r9, rFP, r9, lsl #3         @ r9<- &fp[A]
+//    ldmia   r1, {r2-r3}                 @ r2/r3<- vBB/vBB+1
+    ldr     r2, [r1, #0]
+    ldr     r10, [r1, #4]
+    ldr     r3, [r1, #8]
+//    ldmia   r9, {r0-r1}                 @ r0/r1<- vAA/vAA+1
+    ldr     r0, [r9, #0]
+    ldr     r1, [r9, #8]
+    stmfd   sp!, {r9}
+    ldr     r9, [r9, #4]
+    orr     r10, r9, r10
+    ldmfd   sp!, {r9}
+    bx      lr
+
+/* continuation for OP_OR_LONG_2ADDR */
+
+.LOP_OR_LONG_2ADDR_taint_prop:
+    add     r1, rFP, r1, lsl #3         @ r1<- &fp[B]
+    add     r9, rFP, r9, lsl #3         @ r9<- &fp[A]
+//    ldmia   r1, {r2-r3}                 @ r2/r3<- vBB/vBB+1
+    ldr     r2, [r1, #0]
+    ldr     r10, [r1, #4]
+    ldr     r3, [r1, #8]
+//    ldmia   r9, {r0-r1}                 @ r0/r1<- vAA/vAA+1
+    ldr     r0, [r9, #0]
+    ldr     r1, [r9, #8]
+    stmfd   sp!, {r9}
+    ldr     r9, [r9, #4]
+    orr     r10, r9, r10
+    ldmfd   sp!, {r9}
+    bx      lr
+
+/* continuation for OP_XOR_LONG_2ADDR */
+
+.LOP_XOR_LONG_2ADDR_taint_prop:
+    add     r1, rFP, r1, lsl #3         @ r1<- &fp[B]
+    add     r9, rFP, r9, lsl #3         @ r9<- &fp[A]
+//    ldmia   r1, {r2-r3}                 @ r2/r3<- vBB/vBB+1
+    ldr     r2, [r1, #0]
+    ldr     r10, [r1, #4]
+    ldr     r3, [r1, #8]
+//    ldmia   r9, {r0-r1}                 @ r0/r1<- vAA/vAA+1
+    ldr     r0, [r9, #0]
+    ldr     r1, [r9, #8]
+    stmfd   sp!, {r9}
+    ldr     r9, [r9, #4]
+    orr     r10, r9, r10
+    ldmfd   sp!, {r9}
+    bx      lr
+
+/* continuation for OP_SHL_LONG_2ADDR */
+
+.LOP_SHL_LONG_2ADDR_finish:
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+// begin WITH_TAINT_TRACKING
+//    stmia   r9, {r0-r1}                 @ vAA/vAA+1<- r0/r1
+    str     r0, [r9, #0]
+    str     r10, [r9, #4]
+    str     r1, [r9, #8]
+    str     r10, [r9, #12]
+// end WITH_TAINT_TRACKING
+    GOTO_OPCODE(ip)                     @ jump to next instruction
 
-    mov     r0, r4                      @ recover arg
-    mov     r1, #0xdf000000             @ (float)minlong
-    bl      __aeabi_fcmple              @ is arg <= minlong?
-    cmp     r0, #0                      @ nonzero == yes
-    movne   r0, #0                      @ return minlong (80000000)
-    movne   r1, #0x80000000
-    ldmnefd sp!, {r4, pc}
+shl_long_2addr_taint_prop:
+    SET_TAINT_FP(r0)
+    GET_VREG_TAINT(r0, r3, r0)
+    add     r9, rFP, r9, lsl #3         @ r9<- &fp[A]
+    and     r2, r2, #63                 @ r2<- r2 & 0x3f
+//    ldmia   r9, {r0-r1}                 @ r0/r1<- vAA/vAA+1
+    ldr     r10, [r9, #4]
+    orr     r10, r0, r10
+    ldr     r0, [r9, #0]
+    ldr     r1, [r9, #8]
+    bx      lr
 
-    mov     r0, r4                      @ recover arg
-    mov     r1, r4
-    bl      __aeabi_fcmpeq              @ is arg == self?
-    cmp     r0, #0                      @ zero == no
-    moveq   r1, #0                      @ return zero for NaN
-    ldmeqfd sp!, {r4, pc}
+/* continuation for OP_SHR_LONG_2ADDR */
 
-    mov     r0, r4                      @ recover arg
-    bl      __aeabi_f2lz                @ convert float to long
-    ldmfd   sp!, {r4, pc}
+.LOP_SHR_LONG_2ADDR_finish:
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+// begin WITH_TAINT_TRACKING
+//    stmia   r9, {r0-r1}                 @ vAA/vAA+1<- r0/r1
+    str     r0, [r9, #0]
+    str     r10, [r9, #4]
+    str     r1, [r9, #8]
+    str     r10, [r9, #12]
+// end WITH_TAINT_TRACKING
+    GOTO_OPCODE(ip)                     @ jump to next instruction
 
-/* continuation for OP_DOUBLE_TO_LONG */
-/*
- * Convert the double in r0/r1 to a long in r0/r1.
- *
- * We have to clip values to long min/max per the specification.  The
- * expected common case is a "reasonable" value that converts directly
- * to modest integer.  The EABI convert function isn't doing this for us.
- */
-d2l_doconv:
-    stmfd   sp!, {r4, r5, lr}           @ save regs
-    mov     r3, #0x43000000             @ maxlong, as a double (high word)
-    add     r3, #0x00e00000             @  0x43e00000
-    mov     r2, #0                      @ maxlong, as a double (low word)
-    sub     sp, sp, #4                  @ align for EABI
-    mov     r4, r0                      @ save a copy of r0
-    mov     r5, r1                      @  and r1
-    bl      __aeabi_dcmpge              @ is arg >= maxlong?
-    cmp     r0, #0                      @ nonzero == yes
-    mvnne   r0, #0                      @ return maxlong (7fffffffffffffff)
-    mvnne   r1, #0x80000000
-    bne     1f
+// OP_SHR_LONG_2ADDR.S
+shr_long_2addr_taint_prop:
+    SET_TAINT_FP(r0)
+    GET_VREG_TAINT(r0, r3, r0)
+    add     r9, rFP, r9, lsl #3         @ r9<- &fp[A]
+    and     r2, r2, #63                 @ r2<- r2 & 0x3f
+//    ldmia   r9, {r0-r1}                 @ r0/r1<- vAA/vAA+1
+    ldr     r10, [r9, #4]
+    orr     r10, r0, r10
+    ldr     r0, [r9, #0]
+    ldr     r1, [r9, #8]
+    bx      lr
 
-    mov     r0, r4                      @ recover arg
-    mov     r1, r5
-    mov     r3, #0xc3000000             @ minlong, as a double (high word)
-    add     r3, #0x00e00000             @  0xc3e00000
-    mov     r2, #0                      @ minlong, as a double (low word)
-    bl      __aeabi_dcmple              @ is arg <= minlong?
-    cmp     r0, #0                      @ nonzero == yes
-    movne   r0, #0                      @ return minlong (8000000000000000)
-    movne   r1, #0x80000000
-    bne     1f
+/* continuation for OP_USHR_LONG_2ADDR */
 
-    mov     r0, r4                      @ recover arg
-    mov     r1, r5
-    mov     r2, r4                      @ compare against self
-    mov     r3, r5
-    bl      __aeabi_dcmpeq              @ is arg == self?
-    cmp     r0, #0                      @ zero == no
-    moveq   r1, #0                      @ return zero for NaN
-    beq     1f
+.LOP_USHR_LONG_2ADDR_finish:
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+// begin WITH_TAINT_TRACKING
+//    stmia   r9, {r0-r1}                 @ vAA/vAA+1<- r0/r1
+    str     r0, [r9, #0]
+    str     r10, [r9, #4]
+    str     r1, [r9, #8]
+    str     r10, [r9, #12]
+// end WITH_TAINT_TRACKING
+    GOTO_OPCODE(ip)                     @ jump to next instruction
 
-    mov     r0, r4                      @ recover arg
-    mov     r1, r5
-    bl      __aeabi_d2lz                @ convert double to long
+ushr_long_2addr_taint_prop:
+    SET_TAINT_FP(r0)
+    GET_VREG_TAINT(r0, r3, r0)
+    add     r9, rFP, r9, lsl #3         @ r9<- &fp[A]
+    and     r2, r2, #63                 @ r2<- r2 & 0x3f
+//    ldmia   r9, {r0-r1}                 @ r0/r1<- vAA/vAA+1
+    ldr     r10, [r9, #4]
+    orr     r10, r0, r10
+    ldr     r0, [r9, #0]
+    ldr     r1, [r9, #8]
+    bx      lr
 
-1:
-    add     sp, sp, #4
-    ldmfd   sp!, {r4, r5, pc}
+/* continuation for OP_ADD_FLOAT_2ADDR */
 
-/* continuation for OP_MUL_LONG */
+.LOP_ADD_FLOAT_2ADDR_finish:
+    fadds   s2, s0, s1                              @ s2<- op
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+    fsts    s2, [r9]                    @ vAA<- s2
+// begin WITH_TAINT_TRACKING
+    str     r0, [r9, #4]
+// end WITH_TAINT_TRACKING
+    GOTO_OPCODE(ip)                     @ jump to next instruction
 
-.LOP_MUL_LONG_finish:
+/* continuation for OP_SUB_FLOAT_2ADDR */
+
+.LOP_SUB_FLOAT_2ADDR_finish:
+    fsubs   s2, s0, s1                              @ s2<- op
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    stmia   r0, {r9-r10}                @ vAA/vAA+1<- r9/r10
+    fsts    s2, [r9]                    @ vAA<- s2
+// begin WITH_TAINT_TRACKING
+    str     r0, [r9, #4]
+// end WITH_TAINT_TRACKING
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
-/* continuation for OP_SHL_LONG */
+/* continuation for OP_MUL_FLOAT_2ADDR */
 
-.LOP_SHL_LONG_finish:
-    mov     r0, r0, asl r2              @  r0<- r0 << r2
+.LOP_MUL_FLOAT_2ADDR_finish:
+    fmuls   s2, s0, s1                              @ s2<- op
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    stmia   r9, {r0-r1}                 @ vAA/vAA+1<- r0/r1
+    fsts    s2, [r9]                    @ vAA<- s2
+// begin WITH_TAINT_TRACKING
+    str     r0, [r9, #4]
+// end WITH_TAINT_TRACKING
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
-/* continuation for OP_SHR_LONG */
+/* continuation for OP_DIV_FLOAT_2ADDR */
 
-.LOP_SHR_LONG_finish:
-    mov     r1, r1, asr r2              @  r1<- r1 >> r2
+.LOP_DIV_FLOAT_2ADDR_finish:
+    fdivs   s2, s0, s1                              @ s2<- op
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    stmia   r9, {r0-r1}                 @ vAA/vAA+1<- r0/r1
+    fsts    s2, [r9]                    @ vAA<- s2
+// begin WITH_TAINT_TRACKING
+    str     r0, [r9, #4]
+// end WITH_TAINT_TRACKING
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
-/* continuation for OP_USHR_LONG */
+/* continuation for OP_REM_FLOAT_2ADDR */
 
-.LOP_USHR_LONG_finish:
-    mov     r1, r1, lsr r2              @  r1<- r1 >>> r2
+.LOP_REM_FLOAT_2ADDR_taint_prop:
+    SET_TAINT_FP(r2)
+    GET_VREG_TAINT(r3, r3, r2)
+    GET_VREG_TAINT(r10, r9, r2)
+    orr     r10, r3, r10
+    SET_VREG_TAINT(r10, r9, r2)
+    bx      lr
+
+/* continuation for OP_ADD_DOUBLE_2ADDR */
+
+.LOP_ADD_DOUBLE_2ADDR_finish:
+    faddd   d2, d0, d1                              @ d2<- op
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    stmia   r9, {r0-r1}                 @ vAA/vAA+1<- r0/r1
+// begin WITH_TAINT_TRACKING
+    orr    r0, r0, r1
+//    fstd    d2, [r9]                    @ vAA<- d2
+    fsts    s4, [r9]
+    fsts    s5, [r9, #8]
+    str     r0, [r9, #4]
+    str     r0, [r9, #12]
+// end WITH_TAINT_TRACKING
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
-/* continuation for OP_SHL_LONG_2ADDR */
+/* continuation for OP_SUB_DOUBLE_2ADDR */
 
-.LOP_SHL_LONG_2ADDR_finish:
+.LOP_SUB_DOUBLE_2ADDR_finish:
+    fsubd   d2, d0, d1                              @ d2<- op
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    stmia   r9, {r0-r1}                 @ vAA/vAA+1<- r0/r1
+// begin WITH_TAINT_TRACKING
+    orr    r0, r0, r1
+//    fstd    d2, [r9]                    @ vAA<- d2
+    fsts    s4, [r9]
+    fsts    s5, [r9, #8]
+    str     r0, [r9, #4]
+    str     r0, [r9, #12]
+// end WITH_TAINT_TRACKING
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
-/* continuation for OP_SHR_LONG_2ADDR */
+/* continuation for OP_MUL_DOUBLE_2ADDR */
 
-.LOP_SHR_LONG_2ADDR_finish:
+.LOP_MUL_DOUBLE_2ADDR_finish:
+    fmuld   d2, d0, d1                              @ d2<- op
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    stmia   r9, {r0-r1}                 @ vAA/vAA+1<- r0/r1
+// begin WITH_TAINT_TRACKING
+    orr    r0, r0, r1
+//    fstd    d2, [r9]                    @ vAA<- d2
+    fsts    s4, [r9]
+    fsts    s5, [r9, #8]
+    str     r0, [r9, #4]
+    str     r0, [r9, #12]
+// end WITH_TAINT_TRACKING
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
-/* continuation for OP_USHR_LONG_2ADDR */
+/* continuation for OP_DIV_DOUBLE_2ADDR */
 
-.LOP_USHR_LONG_2ADDR_finish:
+.LOP_DIV_DOUBLE_2ADDR_finish:
+    fdivd   d2, d0, d1                              @ d2<- op
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    stmia   r9, {r0-r1}                 @ vAA/vAA+1<- r0/r1
+// begin WITH_TAINT_TRACKING
+    orr    r0, r0, r1
+//    fstd    d2, [r9]                    @ vAA<- d2
+    fsts    s4, [r9]
+    fsts    s5, [r9, #8]
+    str     r0, [r9, #4]
+    str     r0, [r9, #12]
+// end WITH_TAINT_TRACKING
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
+/* continuation for OP_REM_DOUBLE_2ADDR */
+
+.LOP_REM_DOUBLE_2ADDR_taint_prop:
+    add     r1, rFP, r1, lsl #3         @ r1<- &fp[B]
+    add     r9, rFP, r9, lsl #3         @ r9<- &fp[A]
+//    ldmia   r1, {r2-r3}                 @ r2/r3<- vBB/vBB+1
+    ldr     r2, [r1, #0]
+    ldr     r10, [r1, #4]
+    ldr     r3, [r1, #8]
+//    ldmia   r9, {r0-r1}                 @ r0/r1<- vAA/vAA+1
+    ldr     r0, [r9, #0]
+    ldr     r1, [r9, #8]
+    stmfd   sp!, {r9}
+    ldr     r9, [r9, #4]
+    orr     r10, r9, r10
+    ldmfd   sp!, {r9}
+    bx      lr
+
 /* continuation for OP_IGET_VOLATILE */
 
     /*
@@ -9227,15 +11849,37 @@ d2l_doconv:
     cmp     r9, #0                      @ check object for null
     ldr     r3, [r0, #offInstField_byteOffset]  @ r3<- byte offset of field
     beq     common_errNullObject        @ object was null
+// begin WITH_TAINT_TRACKING
+//    .if     1
+//    add     r0, r9, r3                  @ r0<- address of field
+//    bl      dvmQuasiAtomicRead64        @ r0/r1<- value/taint
+//    orr	    r3, r1, r10
+//    .else
     ldr   r0, [r9, r3]                @ r0<- obj.field (8/16/32 bits)
-    SMP_DMB                            @ acquiring load
+    @ no-op                             @ acquiring load
+    add     r3, r3, #4
+    ldr	    r3, [r9, r3]
+    orr     r3, r3, r10
+//    .endif
+// end WITH_TAINT_TRACKING
     mov     r2, rINST, lsr #8           @ r2<- A+
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
     and     r2, r2, #15                 @ r2<- A
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
     SET_VREG(r0, r2)                    @ fp[A]<- r0
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r1)
+    SET_VREG_TAINT(r3, r2, r1)
+// end WITH_TAINT_TRACKING
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
+.LOP_IGET_VOLATILE_taint_prop:
+    GET_VREG(r9, r0)                    @ r9<- fp[B], the object pointer
+    SET_TAINT_FP(r3)
+    GET_VREG_TAINT(r10, r0, r3)
+    ldr     r0, [r2, r1, lsl #2]        @ r0<- resolved InstField ptr
+    bx      lr
+
 /* continuation for OP_IPUT_VOLATILE */
 
     /*
@@ -9250,14 +11894,29 @@ d2l_doconv:
     and     r1, r1, #15                 @ r1<- A
     cmp     r9, #0                      @ check object for null
     GET_VREG(r0, r1)                    @ r0<- fp[A]
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r2)
+    GET_VREG_TAINT(r10, r1, r2)
+// end WITH_TAINT_TRACKING
     beq     common_errNullObject        @ object was null
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    SMP_DMB_ST                        @ releasing store
+    @ no-op                          @ releasing store
+// begin WITH_TAINT_TRACKING
+//    .if     1
+//    add     r2, r9, r3                  @ r2<- target address
+//    mov	    r1, r10                     @ r1<-taint
+//    bl      dvmQuasiAtomicSwap64        @ stores r0/r1 into addr r2
+//    .else
     str  r0, [r9, r3]                @ obj.field (8/16/32 bits)<- r0
-    SMP_DMB
+    add	    r3, r3, #4
+    str	    r10, [r9, r3]
+//    .endif
+// end WITH_TAINT_TRACKING
+    @ no-op 
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
+
 /* continuation for OP_SGET_VOLATILE */
 
     /*
@@ -9284,6 +11943,21 @@ d2l_doconv:
 #endif
     b       .LOP_SGET_VOLATILE_finish
 
+.LOP_SGET_VOLATILE_taint_prop:
+//    .if     1
+//    add     r0, r0, #offStaticField_value		@ r0<- address of field
+//    bl      dvmQuasiAtomicRead32SfieldTaint		@ r0/r1<- value/taint
+//    .else
+    ldr	    r1, [r0, #offStaticField_taint] @ r1<- taint value
+    ldr     r0, [r0, #offStaticField_value] @ r0<- field value
+    @ no-op                             @ acquiring load
+//    .endif
+    mov     r2, rINST, lsr #8           @ r2<- AA
+    SET_TAINT_FP(r3)
+    SET_VREG_TAINT(r1, r2, r3)
+    bx      lr
+
+
 /* continuation for OP_SPUT_VOLATILE */
 
     /*
@@ -9310,6 +11984,25 @@ d2l_doconv:
 #endif
     b       .LOP_SPUT_VOLATILE_finish          @ resume
 
+.LOP_SPUT_VOLATILE_taint_prop:
+//    .if     1
+//    add     r3, r0, #offStaticField_value   @ r3<- addr
+//    mov     r0, r1                          @ r0<- val
+//    mov     r1, r3                          @ r1<- addr
+//    SET_TAINT_FP(r3)
+//    GET_VREG_TAINT(r2, r2, r3)              @ r2<- taint
+//    bl      dvmQuasiAtomicSwap32SfieldTaint
+//    .else
+    @ no-op                        	    @ releasing store
+    str     r1, [r0, #offStaticField_value] @ field<- vAA
+    SET_TAINT_FP(r3)
+    GET_VREG_TAINT(r1, r2, r3)
+    str	    r1, [r0, #offStaticField_taint]
+    @ no-op 
+//    .endif
+    bx      lr
+
+
 /* continuation for OP_IGET_OBJECT_VOLATILE */
 
     /*
@@ -9322,15 +12015,37 @@ d2l_doconv:
     cmp     r9, #0                      @ check object for null
     ldr     r3, [r0, #offInstField_byteOffset]  @ r3<- byte offset of field
     beq     common_errNullObject        @ object was null
+// begin WITH_TAINT_TRACKING
+//    .if     1
+//    add     r0, r9, r3                  @ r0<- address of field
+//    bl      dvmQuasiAtomicRead64        @ r0/r1<- value/taint
+//    orr	    r3, r1, r10
+//    .else
     ldr   r0, [r9, r3]                @ r0<- obj.field (8/16/32 bits)
-    SMP_DMB                            @ acquiring load
+    @ no-op                             @ acquiring load
+    add     r3, r3, #4
+    ldr	    r3, [r9, r3]
+    orr     r3, r3, r10
+//    .endif
+// end WITH_TAINT_TRACKING
     mov     r2, rINST, lsr #8           @ r2<- A+
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
     and     r2, r2, #15                 @ r2<- A
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
     SET_VREG(r0, r2)                    @ fp[A]<- r0
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r1)
+    SET_VREG_TAINT(r3, r2, r1)
+// end WITH_TAINT_TRACKING
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
+.LOP_IGET_OBJECT_VOLATILE_taint_prop:
+    GET_VREG(r9, r0)                    @ r9<- fp[B], the object pointer
+    SET_TAINT_FP(r3)
+    GET_VREG_TAINT(r10, r0, r3)
+    ldr     r0, [r2, r1, lsl #2]        @ r0<- resolved InstField ptr
+    bx      lr
+
 /* continuation for OP_IGET_WIDE_VOLATILE */
 
     /*
@@ -9343,19 +12058,39 @@ d2l_doconv:
     ldr     r3, [r0, #offInstField_byteOffset]  @ r3<- byte offset of field
     beq     common_errNullObject        @ object was null
     .if     1
-    add     r0, r9, r3                  @ r0<- address of field
+// begin WITH_TAINT_TRACKING
+    stmfd   sp!, {r3}
+    add     r0, r9, r3                  		@ r0<- address of field
     bl      dvmQuasiAtomicRead64        @ r0/r1<- contents of field
+    ldmfd   sp!, {r3}
     .else
     ldrd    r0, [r9, r3]                @ r0/r1<- obj.field (64-bit align ok)
     .endif
+    add     r3, r3, #8
+    ldr     r3, [r9, r3]
+    orr	    r10, r3, r10
     mov     r2, rINST, lsr #8           @ r2<- A+
-    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
     and     r2, r2, #15                 @ r2<- A
-    add     r3, rFP, r2, lsl #2         @ r3<- &fp[A]
+    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
+    add     r3, rFP, r2, lsl #3         @ r3<- &fp[A]
+// end WITH_TAINT_TRACKING
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    stmia   r3, {r0-r1}                 @ fp[A]<- r0/r1
+// begin WITH_TAINT_TRACKING
+//    stmia   r3, {r0-r1}                 @ fp[A]<- r0/r1
+    str    r0, [r3, #0]
+    str    r10, [r3, #4]
+    str    r1, [r3, #8]
+    str    r10, [r3, #12]
+// end WITH_TAINT_TRACKING
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
+.LOP_IGET_WIDE_VOLATILE_taint_prop:
+    GET_VREG(r9, r0)                    @ r9<- fp[B], the object pointer
+    SET_TAINT_FP(r3)
+    GET_VREG_TAINT(r10, r0, r3)
+    ldr     r0, [r2, r1, lsl #2]        @ r0<- resolved InstField ptr
+    bx      lr
+
 /* continuation for OP_IPUT_WIDE_VOLATILE */
 
     /*
@@ -9368,21 +12103,59 @@ d2l_doconv:
     cmp     r9, #0                      @ check object for null
     and     r2, r2, #15                 @ r2<- A
     ldr     r3, [r0, #offInstField_byteOffset]  @ r3<- byte offset of field
-    add     r2, rFP, r2, lsl #2         @ r3<- &fp[A]
+// begin WITH_TAINT_TRACKING
+    add     r2, rFP, r2, lsl #3         @ r3<- &fp[A]
+// end WITH_TAINT_TRACKING
     beq     common_errNullObject        @ object was null
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
-    ldmia   r2, {r0-r1}                 @ r0/r1<- fp[A]
-    GET_INST_OPCODE(r10)                @ extract opcode from rINST
+// begin WITH_TAINT_TRACKING
+//    ldmia   r2, {r0-r1}                 @ r0/r1<- fp[A]
+    ldr	    r0, [r2, #0]
+    ldr     r1, [r2, #8]
+    ldr	    r10, [r2, #4]
+// end WITH_TAINT_TRACKING
     .if     1
+    stmfd   sp!, {r3}
     add     r2, r9, r3                  @ r2<- target address
     bl      dvmQuasiAtomicSwap64Sync    @ stores r0/r1 into addr r2
+    ldmfd   sp!, {r3}
     .else
-    strd    r0, [r9, r3]                @ obj.field (64 bits, aligned)<- r0/r1
+    strd    r0, [r9, r3]                  @ obj.field (64 bits, aligned)<- r0/r1
     .endif
-    GOTO_OPCODE(r10)                    @ jump to next instruction
+// begin WITH_TAINT_TRACKING
+    add	    r3, r3, #8
+    str	    r10, [r9, r3]
+// end WITH_TAINT_TRACKING
+    GET_INST_OPCODE(r10)                 @ extract opcode from rINST
+    GOTO_OPCODE(r10)                     @ jump to next instruction
+
 
 /* continuation for OP_SGET_WIDE_VOLATILE */
 
+.LOP_SGET_WIDE_VOLATILE_finish:
+    mov     r9, rINST, lsr #8           @ r9<- AA
+// begin WITH_TAINT_TRACKING
+    ldr	    r3, [r0, #offStaticField_taint] @ r3<- taint value
+    .if 1
+    stmfd   sp!, {r3}    
+    add     r0, r0, #offStaticField_value @ r0<- pointer to data
+    bl      dvmQuasiAtomicRead64        @ r0/r1<- contents of field
+    ldmfd   sp!, {r3}
+    .else
+    ldrd    r0, [r0, #offStaticField_value] @ r0/r1<- field value (aligned)
+    .endif
+    add     r9, rFP, r9, lsl #3         @ r9<- &fp[AA]
+    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
+//    stmia   r9, {r2-r3}                 @ vAA/vAA+1<- r2/r3
+    str	    r0, [r9, #0]
+    str	    r3, [r9, #4]
+    str	    r1, [r9, #8]
+    str	    r3, [r9, #12]
+// end WITH_TAINT_TRACKING
+
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+    GOTO_OPCODE(ip)                     @ jump to next instruction
+
     /*
      * Continuation if the field has not yet been resolved.
      *  r1:  BBBB field ref
@@ -9439,7 +12212,35 @@ d2l_doconv:
 #endif
     b       .LOP_SPUT_WIDE_VOLATILE_finish          @ resume
 
+.LOP_SPUT_WIDE_VOLATILE_taint_prop:
+//    ldmia   r9, {r0-r1}                 @ r0/r1<- vAA/vAA+1
+    ldr r3, [r9, #4]
+    ldr r0, [r9, #0]
+    ldr r1, [r9, #8]
+    bx      lr
+
+
 /* continuation for OP_EXECUTE_INLINE */
+// end WITH_TAINT_TRACKING
+
+.LOP_EXECUTE_INLINE_resume:
+    add     r1, rSELF, #offThread_retval  @ r1<- &self->retval
+// begin WITH_TAINT_TRACKING
+//    sub     sp, sp, #8                  @ make room for arg, +64 bit align
+    sub     sp, sp, #4                  @ make room for arg, +64 bit align
+    mov     r0, rINST, lsr #12          @ r0<- B
+    str     r1, [sp]                    @ push &self->retval
+    add     r1, rSELF, #offThread_rtaint  @ r1< &self->rtaint
+    sub     sp, sp, #4			@ make room for arg,
+    str     r1, [sp]                    @ push &self->rtaint
+    bl      .LOP_EXECUTE_INLINE_continue        @ make call; will return after
+    add     sp, sp, #16                 @ pop stack 4x
+// end WITH_TAINT_TRACKING
+    cmp     r0, #0                      @ test boolean result of inline
+    beq     common_exceptionThrown      @ returned false, handle exception
+    FETCH_ADVANCE_INST(3)               @ advance rPC, load rINST
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+    GOTO_OPCODE(ip)                     @ jump to next instruction
 
     /*
      * Extract args, call function.
@@ -9458,19 +12259,32 @@ d2l_doconv:
     FETCH(rINST, 2)                     @ rINST<- FEDC
     add     pc, pc, r0, lsl #3          @ computed goto, 2 instrs each
     bl      common_abort                @ (skipped due to ARM prefetch)
+// begin WITH_TAINT_TRACKING
 4:  and     ip, rINST, #0xf000          @ isolate F
-    ldr     r3, [rFP, ip, lsr #10]      @ r3<- vF (shift right 12, left 2)
+    ldr     r3, [rFP, ip, lsr #9]       @ r3<- vF (shift right 12, left 2)
 3:  and     ip, rINST, #0x0f00          @ isolate E
-    ldr     r2, [rFP, ip, lsr #6]       @ r2<- vE
+    ldr     r2, [rFP, ip, lsr #5]       @ r2<- vE
 2:  and     ip, rINST, #0x00f0          @ isolate D
-    ldr     r1, [rFP, ip, lsr #2]       @ r1<- vD
+    ldr     r1, [rFP, ip, lsr #1]       @ r1<- vD
 1:  and     ip, rINST, #0x000f          @ isolate C
-    ldr     r0, [rFP, ip, lsl #2]       @ r0<- vC
+    ldr     r0, [rFP, ip, lsl #3]       @ r0<- vC
 0:
+// push arg0_taint and arg1_taint
+    SET_TAINT_FP(r11)
+    and     ip, rINST, #0x00f0          @ isolate D
+    ldr     ip, [r11, ip, lsr #1]       @ ip<-arg1_taint
+    sub     sp, sp, #4			@ make room for arg
+    str     ip, [sp]                    @ push arg1_taint
+    and     ip, rINST, #0x000f          @ isolate C
+    ldr     ip, [r11, ip, lsl #3]       @ ip<-arg0_taint
+    sub     sp, sp, #4			@ make room for arg
+    str     ip, [sp]                    @ push arg0_taint
+// end WITH_TAINT_TRACKING
     ldr     rINST, .LOP_EXECUTE_INLINE_table    @ table of InlineOperation
     ldr     pc, [rINST, r10, lsl #4]    @ sizeof=16, "func" is first entry
     @ (not reached)
 
+
     /*
      * We're debugging or profiling.
      * r10: opIndex
@@ -9484,12 +12298,21 @@ d2l_doconv:
     mov     r1, rSELF
     bl      dvmFastMethodTraceEnter     @ (method, self)
     add     r1, rSELF, #offThread_retval@ r1<- &self->retval
-    sub     sp, sp, #8                  @ make room for arg, +64 bit align
+// begin WITH_TAINT_TRACKING
+//    sub     sp, sp, #8                  @ make room for arg, +64 bit align
+    sub     sp, sp, #4                  @ make room for arg, +64 bit align
     mov     r0, rINST, lsr #12          @ r0<- B
     str     r1, [sp]                    @ push &self->retval
+    add     r1, rSELF, #offThread_rtaint  @ r1< &self->rtaint
+    sub     sp, sp, #4			@ make room for arg,
+    str     r1, [sp]                    @ push &self->rtaint
+// end WITH_TAINT_TRACKING
     bl      .LOP_EXECUTE_INLINE_continue        @ make call; will return after
     mov     rINST, r0                   @ save result of inline
-    add     sp, sp, #8                  @ pop stack
+// begin WITH_TAINT_TRACKING
+//    add     sp, sp, #8                  @ pop stack
+    add     sp, sp, #16                 @ pop stack 4x
+// end WITH_TAINT_TRACKING
     mov     r0, r9                      @ r0<- method
     mov     r1, rSELF
     bl      dvmFastNativeMethodTraceExit @ (method, self)
@@ -9506,6 +12329,26 @@ d2l_doconv:
     .word   gDvmInlineOpsTable
 
 /* continuation for OP_EXECUTE_INLINE_RANGE */
+// end WITH_TAINT_TRACKING
+
+.LOP_EXECUTE_INLINE_RANGE_resume:
+    add     r1, rSELF, #offThread_retval  @ r1<- &self->retval
+// begin WITH_TAINT_TRACKING
+//    sub     sp, sp, #8                  @ make room for arg, +64 bit align
+    sub     sp, sp, #4                  @ make room for arg, +64 bit align
+    mov     r0, rINST, lsr #8           @ r0<- AA
+    str     r1, [sp]                    @ push &self->retval
+    add     r1, rSELF, #offThread_rtaint  @ r1< &self->rtaint
+    sub     sp, sp, #4			@ make room for arg
+    str     r1, [sp]                    @ push &self->rtaint
+    bl      .LOP_EXECUTE_INLINE_RANGE_continue        @ make call; will return after
+    add     sp, sp, #16                 @ pop stack 4x
+// end WITH_TAINT_TRACKING
+    cmp     r0, #0                      @ test boolean result of inline
+    beq     common_exceptionThrown      @ returned false, handle exception
+    FETCH_ADVANCE_INST(3)               @ advance rPC, load rINST
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+    GOTO_OPCODE(ip)                     @ jump to next instruction
 
     /*
      * Extract args, call function.
@@ -9527,6 +12370,17 @@ d2l_doconv:
 1:  add     ip, r9, #0                  @ (nop)
     GET_VREG(r0, ip)                    @ r0<- vBase[0]
 0:
+// begin WITH_TAINT_TRACKING
+// push arg0_taint and arg1_taint
+    SET_TAINT_FP(r11)
+    add     ip, r9, #1                  
+    GET_VREG_TAINT(ip, ip, r11)
+    sub     sp, sp, #4			@ make room for arg
+    str     ip, [sp]                    @ push arg1_taint
+    GET_VREG_TAINT(ip, r9, r11)
+    sub     sp, sp, #4			@ make room for arg
+    str     ip, [sp]                    @ push arg0_taint
+// end WITH_TAINT_TRACKING
     ldr     r9, .LOP_EXECUTE_INLINE_RANGE_table       @ table of InlineOperation
     ldr     pc, [r9, r10, lsl #4]       @ sizeof=16, "func" is first entry
     @ (not reached)
@@ -9545,13 +12399,21 @@ d2l_doconv:
     mov     r1, rSELF
     bl      dvmFastMethodTraceEnter     @ (method, self)
     add     r1, rSELF, #offThread_retval@ r1<- &self->retval
-    sub     sp, sp, #8                  @ make room for arg, +64 bit align
-    mov     r0, rINST, lsr #8           @ r0<- B
-    mov     rINST, r9                   @ rINST<- method
+// begin WITH_TAINT_TRACKING
+//    sub     sp, sp, #8                  @ make room for arg, +64 bit align
+    sub     sp, sp, #4                  @ make room for arg, +64 bit align
+    mov     r0, rINST, lsr #8           @ r0<- AA
     str     r1, [sp]                    @ push &self->retval
+    add     r1, rSELF, #offThread_rtaint  @ r1< &self->rtaint
+    sub     sp, sp, #4			@ make room for arg
+    str     r1, [sp]                    @ push &self->rtaint
+// end WITH_TAINT_TRACKING
     bl      .LOP_EXECUTE_INLINE_RANGE_continue        @ make call; will return after
     mov     r9, r0                      @ save result of inline
-    add     sp, sp, #8                  @ pop stack
+// begin WITH_TAINT_TRACKING
+//    add     sp, sp, #8                  @ pop stack
+    add     sp, sp, #16                 @ pop stack 4x
+// end WITH_TAINT_TRACKING
     mov     r0, rINST                   @ r0<- method
     mov     r1, rSELF
     bl      dvmFastNativeMethodTraceExit  @ (method, self)
@@ -9590,6 +12452,63 @@ d2l_doconv:
     mov     ip, #OP_INVOKE_DIRECT_RANGE
     GOTO_OPCODE_BASE(r1,ip)             @ execute it
 
+/* continuation for OP_IGET_QUICK */
+
+.LOP_IGET_QUICK_taint_prop:
+    add     r1, r1, #4
+    ldr     r10, [r3, r1]
+    orr     r10, r9, r10
+    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
+    bx      lr
+
+
+/* continuation for OP_IGET_WIDE_QUICK */
+
+iget_wide_quick_taint_prop:
+    add     r3, rFP, r2, lsl #3         @ r3<- &fp[A]
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+//    stmia   r3, {r0-r1}                 @ fp[A]<- r0/r1
+    str     r0, [r3, #0]
+    str     r10, [r3, #4]
+    str     r1, [r3, #8]
+    str     r10, [r3, #12]
+    bx      lr
+
+/* continuation for OP_IGET_OBJECT_QUICK */
+
+.LOP_IGET_OBJECT_QUICK_taint_prop:
+	add		r1, r1, #4
+	ldr		r10, [r3, r1]
+	orr		r10, r9, r10
+	FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
+	bx		lr
+
+/* continuation for OP_IPUT_WIDE_QUICK */
+
+iput_wide_quick_taint_prop:
+    add     r3, rFP, r0, lsl #3         @ r3<- &fp[A]
+    cmp     r2, #0                      @ check object for null
+//    ldmia   r3, {r0-r1}                 @ r0/r1<- fp[A]
+    ldr     r0, [r3, #0]
+    ldr     r1, [r3, #8]
+    ldr     r9, [r3, #4]
+    bx      lr
+
+/* continuation for OP_IPUT_OBJECT_QUICK */
+
+.LOP_IPUT_OBJECT_QUICK_taint_prop:
+    SET_TAINT_FP(r9)
+    GET_VREG_TAINT(r10, r2, r9)
+    ldr     r2, [rSELF, #offThread_cardTable]  @ r2<- card table base
+    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
+    str     r0, [r3, r1]                @ obj.field (always 32 bits)<- r0
+    add	    r1, r1, #4
+    str	    r10, [r3, r1]
+    bx	    lr
+
+
+
+
 /* continuation for OP_IPUT_OBJECT_VOLATILE */
 
     /*
@@ -9604,15 +12523,29 @@ d2l_doconv:
     and     r1, r1, #15                 @ r1<- A
     cmp     r9, #0                      @ check object for null
     GET_VREG(r0, r1)                    @ r0<- fp[A]
-    ldr     r2, [rSELF, #offThread_cardTable]  @ r2<- card table base
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r2)
+    GET_VREG_TAINT(r10, r1, r2)
+    ldr     r11, [rSELF, #offThread_cardTable]  @ r11<- card table base
+// end WITH_TAINT_TRACKING
     beq     common_errNullObject        @ object was null
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    SMP_DMB_ST                        @ releasing store
+    @ no-op                         @ releasing store
+// begin WITH_TAINT_TRACKING
+//    .if     1
+//    add     r2, r9, r3                  @ r2<- target address
+//    mov     r1, r10                     @ r1<-taint
+//    bl      dvmQuasiAtomicSwap64        @ stores r0/r1 into addr r2
+//    .else
     str     r0, [r9, r3]                @ obj.field (32 bits)<- r0
-    SMP_DMB
+    add     r3, r3, #4
+    str     r10, [r9, r3]
+//    .endif
+    @ no-op 
     cmp     r0, #0                      @ stored a null reference?
-    strneb  r2, [r2, r9, lsr #GC_CARD_SHIFT]  @ mark card if not
+    strneb  r11, [r11, r9, lsr #GC_CARD_SHIFT]  @ mark card if not
+// end WITH_TAINT_TRACKING
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
 /* continuation for OP_SGET_OBJECT_VOLATILE */
@@ -9641,14 +12574,42 @@ d2l_doconv:
 #endif
     b       .LOP_SGET_OBJECT_VOLATILE_finish
 
+.LOP_SGET_OBJECT_VOLATILE_taint_prop:
+//    .if     1
+//    add     r0, r0, #offStaticField_value		@ r0<- address of field
+//    bl      dvmQuasiAtomicRead32SfieldTaint		@ r0/r1<- value/taint
+//    .else
+    ldr	    r1, [r0, #offStaticField_taint] @ r1<- taint value
+    ldr     r0, [r0, #offStaticField_value] @ r0<- field value
+    @ no-op                             @ acquiring load
+//    .endif
+    mov     r2, rINST, lsr #8           @ r2<- AA
+    SET_TAINT_FP(r3)
+    SET_VREG_TAINT(r1, r2, r3)
+    bx      lr
+
+
 /* continuation for OP_SPUT_OBJECT_VOLATILE */
 
 
 .LOP_SPUT_OBJECT_VOLATILE_end:
-    str     r1, [r0, #offStaticField_value]  @ field<- vAA
-    SMP_DMB
-    cmp     r1, #0                      @ stored a null object?
-    strneb  r2, [r2, r9, lsr #GC_CARD_SHIFT]  @ mark card based on obj head
+// begin WITH_TAINT_TRACKING
+//    .if     1
+//    add	    r2, r0, #offStaticField_value       @ r2<- addr
+//    mov	    r0, r1                              @ r0<- val
+//    mov	    r1, r2                              @ r1<- addr
+//    mov	    r2, r3                              @ r2<- taint
+//    bl      dvmQuasiAtomicSwap32SfieldTaint
+//    cmp     r0, #0                    	        @ stored a null object?
+//    .else
+    str     r1, [r0, #offStaticField_value] @ field<- vAA
+    str	    r3, [r0, #offStaticField_taint]
+//    @ no-op 
+    cmp     r1, #0                              @ stored a null object?
+//    .endif
+//    strneb  r2, [r2, r9, lsr #GC_CARD_SHIFT]  @ mark card based on obj head
+    strneb  r10, [r10, r9, lsr #GC_CARD_SHIFT]  @ mark card based on obj head
+// end WITH_TAINT_TRACKING
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
     /* Continuation if the field has not yet been resolved.
@@ -9688,7 +12649,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_NOP: /* 0x00 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -9711,7 +12672,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_MOVE: /* 0x01 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -9734,7 +12695,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_MOVE_FROM16: /* 0x02 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -9757,7 +12718,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_MOVE_16: /* 0x03 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -9780,7 +12741,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_MOVE_WIDE: /* 0x04 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -9803,7 +12764,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_MOVE_WIDE_FROM16: /* 0x05 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -9826,7 +12787,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_MOVE_WIDE_16: /* 0x06 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -9849,7 +12810,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_MOVE_OBJECT: /* 0x07 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -9872,7 +12833,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_MOVE_OBJECT_FROM16: /* 0x08 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -9895,7 +12856,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_MOVE_OBJECT_16: /* 0x09 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -9918,7 +12879,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_MOVE_RESULT: /* 0x0a */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -9941,7 +12902,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_MOVE_RESULT_WIDE: /* 0x0b */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -9964,7 +12925,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_MOVE_RESULT_OBJECT: /* 0x0c */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -9987,7 +12948,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_MOVE_EXCEPTION: /* 0x0d */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -10010,7 +12971,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_RETURN_VOID: /* 0x0e */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -10033,7 +12994,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_RETURN: /* 0x0f */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -10056,7 +13017,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_RETURN_WIDE: /* 0x10 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -10079,7 +13040,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_RETURN_OBJECT: /* 0x11 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -10102,7 +13063,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_CONST_4: /* 0x12 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -10125,7 +13086,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_CONST_16: /* 0x13 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -10148,7 +13109,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_CONST: /* 0x14 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -10171,7 +13132,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_CONST_HIGH16: /* 0x15 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -10194,7 +13155,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_CONST_WIDE_16: /* 0x16 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -10217,7 +13178,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_CONST_WIDE_32: /* 0x17 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -10240,7 +13201,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_CONST_WIDE: /* 0x18 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -10263,7 +13224,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_CONST_WIDE_HIGH16: /* 0x19 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -10286,7 +13247,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_CONST_STRING: /* 0x1a */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -10309,7 +13270,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_CONST_STRING_JUMBO: /* 0x1b */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -10332,7 +13293,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_CONST_CLASS: /* 0x1c */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -10355,7 +13316,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_MONITOR_ENTER: /* 0x1d */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -10378,7 +13339,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_MONITOR_EXIT: /* 0x1e */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -10401,7 +13362,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_CHECK_CAST: /* 0x1f */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -10424,7 +13385,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_INSTANCE_OF: /* 0x20 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -10447,7 +13408,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_ARRAY_LENGTH: /* 0x21 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -10470,7 +13431,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_NEW_INSTANCE: /* 0x22 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -10493,7 +13454,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_NEW_ARRAY: /* 0x23 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -10516,7 +13477,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_FILLED_NEW_ARRAY: /* 0x24 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -10539,7 +13500,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_FILLED_NEW_ARRAY_RANGE: /* 0x25 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -10562,7 +13523,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_FILL_ARRAY_DATA: /* 0x26 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -10585,7 +13546,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_THROW: /* 0x27 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -10608,7 +13569,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_GOTO: /* 0x28 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -10631,7 +13592,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_GOTO_16: /* 0x29 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -10654,7 +13615,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_GOTO_32: /* 0x2a */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -10677,7 +13638,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_PACKED_SWITCH: /* 0x2b */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -10700,7 +13661,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_SPARSE_SWITCH: /* 0x2c */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -10723,7 +13684,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_CMPL_FLOAT: /* 0x2d */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -10746,7 +13707,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_CMPG_FLOAT: /* 0x2e */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -10769,7 +13730,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_CMPL_DOUBLE: /* 0x2f */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -10792,7 +13753,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_CMPG_DOUBLE: /* 0x30 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -10815,7 +13776,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_CMP_LONG: /* 0x31 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -10838,7 +13799,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_IF_EQ: /* 0x32 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -10861,7 +13822,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_IF_NE: /* 0x33 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -10884,7 +13845,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_IF_LT: /* 0x34 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -10907,7 +13868,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_IF_GE: /* 0x35 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -10930,7 +13891,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_IF_GT: /* 0x36 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -10953,7 +13914,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_IF_LE: /* 0x37 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -10976,7 +13937,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_IF_EQZ: /* 0x38 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -10999,7 +13960,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_IF_NEZ: /* 0x39 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -11022,7 +13983,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_IF_LTZ: /* 0x3a */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -11045,7 +14006,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_IF_GEZ: /* 0x3b */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -11068,7 +14029,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_IF_GTZ: /* 0x3c */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -11091,7 +14052,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_IF_LEZ: /* 0x3d */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -11114,7 +14075,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_UNUSED_3E: /* 0x3e */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -11137,7 +14098,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_UNUSED_3F: /* 0x3f */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -11160,7 +14121,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_UNUSED_40: /* 0x40 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -11183,7 +14144,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_UNUSED_41: /* 0x41 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -11206,7 +14167,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_UNUSED_42: /* 0x42 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -11229,7 +14190,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_UNUSED_43: /* 0x43 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -11252,7 +14213,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_AGET: /* 0x44 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -11275,7 +14236,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_AGET_WIDE: /* 0x45 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -11298,7 +14259,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_AGET_OBJECT: /* 0x46 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -11321,7 +14282,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_AGET_BOOLEAN: /* 0x47 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -11344,7 +14305,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_AGET_BYTE: /* 0x48 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -11367,7 +14328,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_AGET_CHAR: /* 0x49 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -11390,7 +14351,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_AGET_SHORT: /* 0x4a */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -11413,7 +14374,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_APUT: /* 0x4b */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -11436,7 +14397,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_APUT_WIDE: /* 0x4c */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -11459,7 +14420,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_APUT_OBJECT: /* 0x4d */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -11482,7 +14443,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_APUT_BOOLEAN: /* 0x4e */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -11505,7 +14466,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_APUT_BYTE: /* 0x4f */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -11528,7 +14489,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_APUT_CHAR: /* 0x50 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -11551,7 +14512,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_APUT_SHORT: /* 0x51 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -11574,7 +14535,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_IGET: /* 0x52 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -11597,7 +14558,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_IGET_WIDE: /* 0x53 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -11620,7 +14581,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_IGET_OBJECT: /* 0x54 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -11643,7 +14604,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_IGET_BOOLEAN: /* 0x55 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -11666,7 +14627,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_IGET_BYTE: /* 0x56 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -11689,7 +14650,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_IGET_CHAR: /* 0x57 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -11712,7 +14673,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_IGET_SHORT: /* 0x58 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -11735,7 +14696,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_IPUT: /* 0x59 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -11758,7 +14719,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_IPUT_WIDE: /* 0x5a */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -11781,7 +14742,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_IPUT_OBJECT: /* 0x5b */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -11804,7 +14765,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_IPUT_BOOLEAN: /* 0x5c */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -11827,7 +14788,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_IPUT_BYTE: /* 0x5d */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -11850,7 +14811,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_IPUT_CHAR: /* 0x5e */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -11873,7 +14834,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_IPUT_SHORT: /* 0x5f */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -11896,7 +14857,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_SGET: /* 0x60 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -11919,7 +14880,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_SGET_WIDE: /* 0x61 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -11942,7 +14903,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_SGET_OBJECT: /* 0x62 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -11965,7 +14926,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_SGET_BOOLEAN: /* 0x63 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -11988,7 +14949,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_SGET_BYTE: /* 0x64 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -12011,7 +14972,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_SGET_CHAR: /* 0x65 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -12034,7 +14995,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_SGET_SHORT: /* 0x66 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -12057,7 +15018,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_SPUT: /* 0x67 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -12080,7 +15041,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_SPUT_WIDE: /* 0x68 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -12103,7 +15064,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_SPUT_OBJECT: /* 0x69 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -12126,7 +15087,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_SPUT_BOOLEAN: /* 0x6a */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -12149,7 +15110,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_SPUT_BYTE: /* 0x6b */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -12172,7 +15133,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_SPUT_CHAR: /* 0x6c */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -12195,7 +15156,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_SPUT_SHORT: /* 0x6d */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -12218,7 +15179,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_INVOKE_VIRTUAL: /* 0x6e */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -12241,7 +15202,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_INVOKE_SUPER: /* 0x6f */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -12264,7 +15225,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_INVOKE_DIRECT: /* 0x70 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -12287,7 +15248,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_INVOKE_STATIC: /* 0x71 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -12310,7 +15271,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_INVOKE_INTERFACE: /* 0x72 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -12333,7 +15294,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_UNUSED_73: /* 0x73 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -12356,7 +15317,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_INVOKE_VIRTUAL_RANGE: /* 0x74 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -12379,7 +15340,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_INVOKE_SUPER_RANGE: /* 0x75 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -12402,7 +15363,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_INVOKE_DIRECT_RANGE: /* 0x76 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -12425,7 +15386,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_INVOKE_STATIC_RANGE: /* 0x77 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -12448,7 +15409,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_INVOKE_INTERFACE_RANGE: /* 0x78 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -12471,7 +15432,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_UNUSED_79: /* 0x79 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -12494,7 +15455,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_UNUSED_7A: /* 0x7a */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -12517,7 +15478,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_NEG_INT: /* 0x7b */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -12540,7 +15501,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_NOT_INT: /* 0x7c */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -12563,7 +15524,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_NEG_LONG: /* 0x7d */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -12586,7 +15547,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_NOT_LONG: /* 0x7e */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -12609,7 +15570,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_NEG_FLOAT: /* 0x7f */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -12632,7 +15593,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_NEG_DOUBLE: /* 0x80 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -12655,7 +15616,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_INT_TO_LONG: /* 0x81 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -12678,7 +15639,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_INT_TO_FLOAT: /* 0x82 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -12701,7 +15662,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_INT_TO_DOUBLE: /* 0x83 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -12724,7 +15685,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_LONG_TO_INT: /* 0x84 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -12747,7 +15708,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_LONG_TO_FLOAT: /* 0x85 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -12770,7 +15731,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_LONG_TO_DOUBLE: /* 0x86 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -12793,7 +15754,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_FLOAT_TO_INT: /* 0x87 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -12816,7 +15777,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_FLOAT_TO_LONG: /* 0x88 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -12839,7 +15800,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_FLOAT_TO_DOUBLE: /* 0x89 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -12862,7 +15823,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_DOUBLE_TO_INT: /* 0x8a */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -12885,7 +15846,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_DOUBLE_TO_LONG: /* 0x8b */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -12908,7 +15869,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_DOUBLE_TO_FLOAT: /* 0x8c */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -12931,7 +15892,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_INT_TO_BYTE: /* 0x8d */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -12954,7 +15915,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_INT_TO_CHAR: /* 0x8e */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -12977,7 +15938,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_INT_TO_SHORT: /* 0x8f */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -13000,7 +15961,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_ADD_INT: /* 0x90 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -13023,7 +15984,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_SUB_INT: /* 0x91 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -13046,7 +16007,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_MUL_INT: /* 0x92 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -13069,7 +16030,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_DIV_INT: /* 0x93 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -13092,7 +16053,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_REM_INT: /* 0x94 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -13115,7 +16076,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_AND_INT: /* 0x95 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -13138,7 +16099,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_OR_INT: /* 0x96 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -13161,7 +16122,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_XOR_INT: /* 0x97 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -13184,7 +16145,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_SHL_INT: /* 0x98 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -13207,7 +16168,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_SHR_INT: /* 0x99 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -13230,7 +16191,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_USHR_INT: /* 0x9a */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -13253,7 +16214,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_ADD_LONG: /* 0x9b */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -13276,7 +16237,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_SUB_LONG: /* 0x9c */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -13299,7 +16260,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_MUL_LONG: /* 0x9d */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -13322,7 +16283,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_DIV_LONG: /* 0x9e */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -13345,7 +16306,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_REM_LONG: /* 0x9f */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -13368,7 +16329,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_AND_LONG: /* 0xa0 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -13391,7 +16352,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_OR_LONG: /* 0xa1 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -13414,7 +16375,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_XOR_LONG: /* 0xa2 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -13437,7 +16398,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_SHL_LONG: /* 0xa3 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -13460,7 +16421,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_SHR_LONG: /* 0xa4 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -13483,7 +16444,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_USHR_LONG: /* 0xa5 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -13506,7 +16467,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_ADD_FLOAT: /* 0xa6 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -13529,7 +16490,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_SUB_FLOAT: /* 0xa7 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -13552,7 +16513,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_MUL_FLOAT: /* 0xa8 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -13575,7 +16536,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_DIV_FLOAT: /* 0xa9 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -13598,7 +16559,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_REM_FLOAT: /* 0xaa */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -13621,7 +16582,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_ADD_DOUBLE: /* 0xab */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -13644,7 +16605,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_SUB_DOUBLE: /* 0xac */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -13667,7 +16628,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_MUL_DOUBLE: /* 0xad */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -13690,7 +16651,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_DIV_DOUBLE: /* 0xae */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -13713,7 +16674,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_REM_DOUBLE: /* 0xaf */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -13736,7 +16697,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_ADD_INT_2ADDR: /* 0xb0 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -13759,7 +16720,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_SUB_INT_2ADDR: /* 0xb1 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -13782,7 +16743,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_MUL_INT_2ADDR: /* 0xb2 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -13805,7 +16766,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_DIV_INT_2ADDR: /* 0xb3 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -13828,7 +16789,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_REM_INT_2ADDR: /* 0xb4 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -13851,7 +16812,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_AND_INT_2ADDR: /* 0xb5 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -13874,7 +16835,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_OR_INT_2ADDR: /* 0xb6 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -13897,7 +16858,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_XOR_INT_2ADDR: /* 0xb7 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -13920,7 +16881,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_SHL_INT_2ADDR: /* 0xb8 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -13943,7 +16904,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_SHR_INT_2ADDR: /* 0xb9 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -13966,7 +16927,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_USHR_INT_2ADDR: /* 0xba */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -13989,7 +16950,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_ADD_LONG_2ADDR: /* 0xbb */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -14012,7 +16973,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_SUB_LONG_2ADDR: /* 0xbc */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -14035,7 +16996,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_MUL_LONG_2ADDR: /* 0xbd */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -14058,7 +17019,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_DIV_LONG_2ADDR: /* 0xbe */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -14081,7 +17042,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_REM_LONG_2ADDR: /* 0xbf */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -14104,7 +17065,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_AND_LONG_2ADDR: /* 0xc0 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -14127,7 +17088,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_OR_LONG_2ADDR: /* 0xc1 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -14150,7 +17111,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_XOR_LONG_2ADDR: /* 0xc2 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -14173,7 +17134,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_SHL_LONG_2ADDR: /* 0xc3 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -14196,7 +17157,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_SHR_LONG_2ADDR: /* 0xc4 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -14219,7 +17180,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_USHR_LONG_2ADDR: /* 0xc5 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -14242,7 +17203,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_ADD_FLOAT_2ADDR: /* 0xc6 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -14265,7 +17226,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_SUB_FLOAT_2ADDR: /* 0xc7 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -14288,7 +17249,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_MUL_FLOAT_2ADDR: /* 0xc8 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -14311,7 +17272,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_DIV_FLOAT_2ADDR: /* 0xc9 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -14334,7 +17295,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_REM_FLOAT_2ADDR: /* 0xca */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -14357,7 +17318,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_ADD_DOUBLE_2ADDR: /* 0xcb */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -14380,7 +17341,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_SUB_DOUBLE_2ADDR: /* 0xcc */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -14403,7 +17364,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_MUL_DOUBLE_2ADDR: /* 0xcd */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -14426,7 +17387,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_DIV_DOUBLE_2ADDR: /* 0xce */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -14449,7 +17410,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_REM_DOUBLE_2ADDR: /* 0xcf */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -14472,7 +17433,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_ADD_INT_LIT16: /* 0xd0 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -14495,7 +17456,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_RSUB_INT: /* 0xd1 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -14518,7 +17479,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_MUL_INT_LIT16: /* 0xd2 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -14541,7 +17502,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_DIV_INT_LIT16: /* 0xd3 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -14564,7 +17525,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_REM_INT_LIT16: /* 0xd4 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -14587,7 +17548,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_AND_INT_LIT16: /* 0xd5 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -14610,7 +17571,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_OR_INT_LIT16: /* 0xd6 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -14633,7 +17594,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_XOR_INT_LIT16: /* 0xd7 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -14656,7 +17617,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_ADD_INT_LIT8: /* 0xd8 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -14679,7 +17640,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_RSUB_INT_LIT8: /* 0xd9 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -14702,7 +17663,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_MUL_INT_LIT8: /* 0xda */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -14725,7 +17686,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_DIV_INT_LIT8: /* 0xdb */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -14748,7 +17709,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_REM_INT_LIT8: /* 0xdc */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -14771,7 +17732,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_AND_INT_LIT8: /* 0xdd */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -14794,7 +17755,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_OR_INT_LIT8: /* 0xde */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -14817,7 +17778,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_XOR_INT_LIT8: /* 0xdf */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -14840,7 +17801,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_SHL_INT_LIT8: /* 0xe0 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -14863,7 +17824,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_SHR_INT_LIT8: /* 0xe1 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -14886,7 +17847,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_USHR_INT_LIT8: /* 0xe2 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -14909,7 +17870,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_IGET_VOLATILE: /* 0xe3 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -14932,7 +17893,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_IPUT_VOLATILE: /* 0xe4 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -14955,7 +17916,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_SGET_VOLATILE: /* 0xe5 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -14978,7 +17939,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_SPUT_VOLATILE: /* 0xe6 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -15001,7 +17962,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_IGET_OBJECT_VOLATILE: /* 0xe7 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -15024,7 +17985,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_IGET_WIDE_VOLATILE: /* 0xe8 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -15047,7 +18008,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_IPUT_WIDE_VOLATILE: /* 0xe9 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -15070,7 +18031,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_SGET_WIDE_VOLATILE: /* 0xea */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -15093,7 +18054,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_SPUT_WIDE_VOLATILE: /* 0xeb */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -15116,7 +18077,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_BREAKPOINT: /* 0xec */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -15139,7 +18100,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_THROW_VERIFICATION_ERROR: /* 0xed */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -15162,7 +18123,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_EXECUTE_INLINE: /* 0xee */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -15185,7 +18146,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_EXECUTE_INLINE_RANGE: /* 0xef */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -15208,7 +18169,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_INVOKE_OBJECT_INIT_RANGE: /* 0xf0 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -15231,7 +18192,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_RETURN_VOID_BARRIER: /* 0xf1 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -15254,7 +18215,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_IGET_QUICK: /* 0xf2 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -15277,7 +18238,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_IGET_WIDE_QUICK: /* 0xf3 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -15300,7 +18261,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_IGET_OBJECT_QUICK: /* 0xf4 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -15323,7 +18284,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_IPUT_QUICK: /* 0xf5 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -15346,7 +18307,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_IPUT_WIDE_QUICK: /* 0xf6 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -15369,7 +18330,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_IPUT_OBJECT_QUICK: /* 0xf7 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -15392,7 +18353,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_INVOKE_VIRTUAL_QUICK: /* 0xf8 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -15415,7 +18376,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_INVOKE_VIRTUAL_QUICK_RANGE: /* 0xf9 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -15438,7 +18399,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_INVOKE_SUPER_QUICK: /* 0xfa */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -15461,7 +18422,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_INVOKE_SUPER_QUICK_RANGE: /* 0xfb */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -15484,7 +18445,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_IPUT_OBJECT_VOLATILE: /* 0xfc */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -15507,7 +18468,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_SGET_OBJECT_VOLATILE: /* 0xfd */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -15530,7 +18491,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_SPUT_OBJECT_VOLATILE: /* 0xfe */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -15553,7 +18514,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_UNUSED_FF: /* 0xff */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -15577,7 +18538,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
     .size   dvmAsmAltInstructionStart, .-dvmAsmAltInstructionStart
     .global dvmAsmAltInstructionEnd
 dvmAsmAltInstructionEnd:
-/* File: armv5te/footer.S */
+/* File: armv5te_taint/footer.S */
 /*
  * ===========================================================================
  *  Common subroutines and data
@@ -16059,21 +19020,78 @@ common_invokeMethodRange:
     blne    save_callsiteinfo
 #endif
     @ prepare to copy args to "outs" area of current frame
-    movs    r2, rINST, lsr #8           @ r2<- AA (arg count) -- test for zero
+// begin WITH_TAINT_TRACKING
+//    movs    r2, rINST, lsr #8           @ r2<- AA (arg count) -- test for zero
+    mov     r2, rINST, lsr #8           @ r2<- AA (arg count)
     SAVEAREA_FROM_FP(r10, rFP)          @ r10<- stack save area
-    beq     .LinvokeArgsDone            @ if no args, skip the rest
+//    beq     .LinvokeArgsDone            @ if no args, skip the rest
+    str     r2, [r10, #offStackSaveArea_argCount]	@ save arg count
+// end WITH_TAINT_TRACKING
     FETCH(r1, 2)                        @ r1<- CCCC
 
+// begin WITH_TAINT_TRACKING
+    // is this a native method?
+    stmfd   sp!, {r0}                   @ push methodToCall to stack
+    ldr     r0, [r0, #offMethod_accessFlags] @ r0<- methodToCall->accessFlags
+    tst     r0, #ACC_NATIVE
+    ldmfd   sp!, {r0}                   @ restore methodToCall
+    bne     .LinvokeRangeNative
+
 .LinvokeRangeArgs:
     @ r0=methodToCall, r1=CCCC, r2=count, r10=outs
     @ (very few methods have > 10 args; could unroll for common cases)
-    add     r3, rFP, r1, lsl #2         @ r3<- &fp[CCCC]
-    sub     r10, r10, r2, lsl #2        @ r10<- "outs" area, for call args
-1:  ldr     r1, [r3], #4                @ val = *fp++
+    stmfd   sp!, {r0}                   @ push methodToCall to stack
+    mov	    r9, #0
+    str     r9, [r10, #-4]              @ clear native hack
+    cmp	    r2, #0
+    beq     .LinvokeRangeDone           @ if no args, skip the rest
+    add     r3, rFP, r1, lsl #3         @ r3<- &fp[CCCC]
+    sub     r10, r10, r2, lsl #3        @ r10<- "outs" area, for call args
+    sub	    r10, r10, #4
+    //mov     r9, #0                      @ r9<- slot = 0
+1:  ldrd    r0, [r3, r9]
     subs    r2, r2, #1                  @ count--
-    str     r1, [r10], #4               @ *outs++ = val
+    strd    r0, [r10, r9]               @ *outs++ = val
+    add	    r9, r9, #8
+    bne     1b                          @ ...while count != 0
+.LinvokeRangeDone:
+    ldmfd   sp!, {r0}                   @ restore methodToCall
+    // PJG: moved
+    //ldrh    r9, [r0, #offMethod_registersSize]  @ r9<- methodToCall->regsSize
+    //ldrh    r3, [r0, #offMethod_outsSize]   @ r3<- methodToCall->outsSize
+    b       .LinvokeArgsDone
+
+.LinvokeRangeNative:
+    @ r0=methodToCall, r1=CCCC, r2=count, r10=outs
+    @ (very few methods have > 10 args; could unroll for common cases)
+    stmfd   sp!, {r0}                   @ push methodToCall to stack
+    sub	    r10, r10, #4
+    sub     r10, r10, r2, lsl #3        @ r10<- "outs" area, for call args
+    mov	    r9, #0                      @ r9<- index
+    str     r9, [r10, r2, lsl #2]       @ clear native hack
+    cmp	    r2, #0
+    beq     .LinvokeRangeNativeDone     @ if no args, skip the rest
+    add     r3, rFP, r1, lsl #3         @ r3<- &fp[CCCC]
+    mov	    r0, r2                      @ r0<- count
+    mov	    r2, r2, lsl #2
+    add	    r2, r2, #4                  @ r2<- index (taint)
+1:  stmfd   sp!, {r0}                   @ push count
+    mov	    r0, r9, lsl #3
+    ldrd    r0, [r3, r0]
+    str	    r0, [r10, r9, lsl #2]
+    str	    r1, [r10, r2]
+    add	    r9, r9, #1
+    add	    r2, r2, #4
+    ldmfd   sp!, {r0}                   @ pop count
+    subs    r0, r0, #1                  @ count--
     bne     1b                          @ ...while count != 0
+.LinvokeRangeNativeDone:
+    ldmfd   sp!, {r0}                   @ restore methodToCall
+    // PJG: moved
+    //ldrh    r9, [r0, #offMethod_registersSize]  @ r9<- methodToCall->regsSize
+    //ldrh    r3, [r0, #offMethod_outsSize]   @ r3<- methodToCall->outsSize
     b       .LinvokeArgsDone
+// end WITH_TAINT_TRACKING
 
 /*
  * Common code for method invocation without range.
@@ -16089,37 +19107,107 @@ common_invokeMethodNoRange:
     blne    save_callsiteinfo
 #endif
     @ prepare to copy args to "outs" area of current frame
-    movs    r2, rINST, lsr #12          @ r2<- B (arg count) -- test for zero
+// begin WITH_TAINT_TRACKING
+//    movs    r2, rINST, lsr #12          @ r2<- B (arg count) -- test for zero
+    movs    r2, rINST, lsr #12          @ r2<- B (arg count)
     SAVEAREA_FROM_FP(r10, rFP)          @ r10<- stack save area
+    str     r2, [r10, #offStackSaveArea_argCount]    @ save arg count
     FETCH(r1, 2)                        @ r1<- GFED (load here to hide latency)
-    beq     .LinvokeArgsDone
-
+    // is this a native method?
+    stmfd   sp!, {r0}                   @ push methodToCall to stack
+    ldr     r0, [r0, #offMethod_accessFlags] @ r0<- methodToCall->accessFlags
+    tst     r0, #ACC_NATIVE
+    bne     .LinvokeNonRangeNative
+// end WITH_TAINT_TRACKING
     @ r0=methodToCall, r1=GFED, r2=count, r10=outs
 .LinvokeNonRange:
+// begin WITH_TAINT_TRACKING
+    stmfd   sp!, {r3}                   @ push count, outSize to stack
+    // clear native hack
+    mov	    r3, #0
+    str     r3, [r10, #-4]!
+// end WITH_TAINT_TRACKING
     rsb     r2, r2, #5                  @ r2<- 5-r2
     add     pc, pc, r2, lsl #4          @ computed goto, 4 instrs each
     bl      common_abort                @ (skipped due to ARM prefetch)
+// begin WITH_TAINT_TRACKING
+5:  and     ip, rINST, #0x0f00          @ isolate A
+    mov	    r2, ip, lsr #5
+    ldrd    r2, [rFP, r2]               @ r2/r3<- vA (shift right 8, left 2) / taint
+    strd    r2, [r10, #-8]!             @ *--outs = vA
+4:  and     ip, r1, #0xf000             @ isolate G
+    mov	    r2, ip, lsr #9
+    ldrd    r2, [rFP, r2]               @ r2<- vG (shift right 12, left 2)
+    strd    r2, [r10, #-8]!             @ *--outs = vG
+3:  and     ip, r1, #0x0f00             @ isolate F
+    mov	    r2, ip, lsr #5
+    ldrd    r2, [rFP, r2]               @ r2<- vF
+    strd    r2, [r10, #-8]!             @ *--outs = vF
+2:  and     ip, r1, #0x00f0             @ isolate E
+    mov	    r2, ip, lsr #1
+    ldrd    r2, [rFP, r2]               @ r2<- vE
+    strd    r2, [r10, #-8]!             @ *--outs = vE
+1:  and     ip, r1, #0x000f             @ isolate D
+    mov	    r2, ip, lsl #3
+    ldrd    r2, [rFP, r2]               @ r2<- vD
+    strd    r2, [r10, #-8]!             @ *--outs = vD
+// end WITH_TAINT_TRACKING
+0:  @ fall through to .LinvokeArgsDone
+// begin WITH_TAINT_TRACKING
+    ldmfd   sp!, {r3}                   @ restore outSize
+    ldmfd   sp!, {r0}                   @ restore methodToCall
+    b       .LinvokeArgsDone            @ jump over .LinvokeNonRangeNative
+// end WITH_TAINT_TRACKING
+
+    @ r0=methodToCall, r1=GFED, r2=count, r10=outs
+.LinvokeNonRangeNative:
+// begin WITH_TAINT_TRACKING
+    sub	    r0, r10, r2, lsl #2         @ r0<- outs (no taint)
+    sub	    r0, r0, #4                  @ native hack
+    stmfd   sp!, {r3}                   @ push outSize to stack
+// end WITH_TAINT_TRACKING
+    rsb     r2, r2, #5                  @ r2<- 5-r2
+// begin WITH_TAINT_TRACKING
+    mov	    r3, #5
+    mul	    r2, r2, r3
+    add     pc, pc, r2, lsl #2         	@ computed goto, 5 instrs each, 4-byte instrs
+// end WITH_TAINT_TRACKING
+    bl      common_abort                @ (skipped due to ARM prefetch)
+// begin WITH_TAINT_TRACKING
 5:  and     ip, rINST, #0x0f00          @ isolate A
-    ldr     r2, [rFP, ip, lsr #6]       @ r2<- vA (shift right 8, left 2)
-    mov     r0, r0                      @ nop
-    str     r2, [r10, #-4]!             @ *--outs = vA
+    mov	    r2, ip, lsr #5
+    ldrd    r2, [rFP, r2]               @ r2/r3<- vA (shift right 8, left 2) / taint
+    str     r2, [r0, #-4]!
+    str	    r3, [r10, #-4]!
 4:  and     ip, r1, #0xf000             @ isolate G
-    ldr     r2, [rFP, ip, lsr #10]      @ r2<- vG (shift right 12, left 2)
-    mov     r0, r0                      @ nop
-    str     r2, [r10, #-4]!             @ *--outs = vG
+    mov	    r2, ip, lsr #9
+    ldrd    r2, [rFP, r2]               @ r2<- vG (shift right 12, left 2)
+    str     r2, [r0, #-4]!
+    str	    r3, [r10, #-4]!
 3:  and     ip, r1, #0x0f00             @ isolate F
-    ldr     r2, [rFP, ip, lsr #6]       @ r2<- vF
-    mov     r0, r0                      @ nop
-    str     r2, [r10, #-4]!             @ *--outs = vF
+    mov	    r2, ip, lsr #5
+    ldrd    r2, [rFP, r2]               @ r2<- vF
+    str     r2, [r0, #-4]!
+    str	    r3, [r10, #-4]!
 2:  and     ip, r1, #0x00f0             @ isolate E
-    ldr     r2, [rFP, ip, lsr #2]       @ r2<- vE
-    mov     r0, r0                      @ nop
-    str     r2, [r10, #-4]!             @ *--outs = vE
+    mov	    r2, ip, lsr #1
+    ldrd    r2, [rFP, r2]               @ r2<- vE
+    str     r2, [r0, #-4]!
+    str	    r3, [r10, #-4]!
 1:  and     ip, r1, #0x000f             @ isolate D
-    ldr     r2, [rFP, ip, lsl #2]       @ r2<- vD
-    mov     r0, r0                      @ nop
-    str     r2, [r10, #-4]!             @ *--outs = vD
+    mov	    r2, ip, lsl #3
+    ldrd    r2, [rFP, r2]               @ r2<- vD
+    str     r2, [r0, #-4]!
+    str     r3, [r10, #-4]!
+// end WITH_TAINT_TRACKING
 0:  @ fall through to .LinvokeArgsDone
+// begin WITH_TAINT_TRACKING
+    // clear native hack
+    mov		r3, #0
+    str     r3, [r10, #-4]!
+    ldmfd   sp!, {r3}                   @ restore outSize
+    ldmfd   sp!, {r0}                   @ restore methodToCall
+// end WITH_TAINT_TRACKING
 
 .LinvokeArgsDone: @ r0=methodToCall
     ldrh    r9, [r0, #offMethod_registersSize]  @ r9<- methodToCall->regsSize
@@ -16128,11 +19216,17 @@ common_invokeMethodNoRange:
     ldr     rINST, [r0, #offMethod_clazz]  @ rINST<- method->clazz
     @ find space for the new stack frame, check for overflow
     SAVEAREA_FROM_FP(r1, rFP)           @ r1<- stack save area
-    sub     r1, r1, r9, lsl #2          @ r1<- newFp (old savearea - regsSize)
+// begin WITH_TAINT_TRACKING
+    sub     r1, r1, r9, lsl #3
+    sub	    r1, r1, #4                  @ r1<- newFp (old savearea - 2*regsSize - 4)
+// end WITH_TAINT_TRACKING
     SAVEAREA_FROM_FP(r10, r1)           @ r10<- newSaveArea
 @    bl      common_dumpRegs
     ldr     r9, [rSELF, #offThread_interpStackEnd]    @ r9<- interpStackEnd
-    sub     r3, r10, r3, lsl #2         @ r3<- bottom (newsave - outsSize)
+// begin WITH_TAINT_TRACKING
+    sub     r3, r10, r3, lsl #2
+    sub	    r3, r3, #4                  @ r3<- bottom (newsave - outsSize - 4)
+// end WITH_TAINT_TRACKING
     cmp     r3, r9                      @ bottom < interpStackEnd?
     ldrh    lr, [rSELF, #offThread_subMode]
     ldr     r3, [r0, #offMethod_accessFlags] @ r3<- methodToCall->accessFlags
@@ -16240,6 +19334,16 @@ dalvik_mterp:
 7:
 
     @ native return; r10=newSaveArea
+
+// begin WITH_TAINT_TRACKING
+    // set return taint
+    SAVEAREA_FROM_FP(r0, rFP)           @ r0<- stack save area
+    ldr     r1, [r0, #offStackSaveArea_argCount]    @ r1<- arg count
+    sub     r0, r0, r1, lsl #2
+    ldr     r2, [r0, #-4]               @ r2<- return taint
+    str	    r2, [rSELF, #offThread_rtaint]
+// end WITH_TAINT_TRACKING
+
     @ equivalent to dvmPopJniLocals
     ldr     r0, [r10, #offStackSaveArea_localRefCookie] @ r0<- saved top
     ldr     r1, [rSELF, #offThread_exception] @ check for exception
diff --git a/vm/mterp/out/InterpAsm-armv7-a.S b/vm/mterp/out/InterpAsm-armv7-a.S
index c9ebb1d..b785fcf 100644
--- a/vm/mterp/out/InterpAsm-armv7-a.S
+++ b/vm/mterp/out/InterpAsm-armv7-a.S
@@ -4,7 +4,7 @@
  * --> DO NOT EDIT <--
  */
 
-/* File: armv5te/header.S */
+/* File: armv5te_taint/header.S */
 /*
  * Copyright (C) 2008 The Android Open Source Project
  *
@@ -183,14 +183,28 @@ unspecified registers or condition codes.
 /*
  * Get/set the 32-bit value from a Dalvik register.
  */
+#ifdef WITH_TAINT_TRACKING
+#define SET_TAINT_FP(_reg)      add     _reg, rFP, #4
+#define SET_TAINT_CLEAR(_reg)   mov     _reg, #0
+#define GET_VREG(_reg, _vreg)   ldr     _reg, [rFP, _vreg, lsl #3]
+#define SET_VREG(_reg, _vreg)   str     _reg, [rFP, _vreg, lsl #3]
+#define GET_VREG_TAINT(_reg, _vreg, _rFP)   ldr     _reg, [_rFP, _vreg, lsl #3]
+#define SET_VREG_TAINT(_reg, _vreg, _rFP)   str     _reg, [_rFP, _vreg, lsl #3]
+#else
 #define GET_VREG(_reg, _vreg)   ldr     _reg, [rFP, _vreg, lsl #2]
 #define SET_VREG(_reg, _vreg)   str     _reg, [rFP, _vreg, lsl #2]
+#endif /*WITH_TAINT_TRACKING*/
 
 /*
  * Convert a virtual register index into an address.
  */
+#ifdef WITH_TAINT_TRACKING
+#define VREG_INDEX_TO_ADDR(_reg, _vreg) \
+        add     _reg, rFP, _vreg, lsl #3
+#else
 #define VREG_INDEX_TO_ADDR(_reg, _vreg) \
         add     _reg, rFP, _vreg, lsl #2
+#endif /*WITH_TAINT_TRACKING*/
 
 /*
  * This is a #include, not a %include, because we want the C pre-processor
@@ -235,7 +249,7 @@ unspecified registers or condition codes.
 #endif
 .endm
 
-/* File: armv5te/entry.S */
+/* File: armv5te_taint/entry.S */
 /*
  * Copyright (C) 2008 The Android Open Source Project
  *
@@ -376,7 +390,7 @@ dvmAsmInstructionStart = .L_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_OP_NOP: /* 0x00 */
-/* File: armv5te/OP_NOP.S */
+/* File: armv5te_taint/OP_NOP.S */
     FETCH_ADVANCE_INST(1)               @ advance to next instr, load rINST
     GET_INST_OPCODE(ip)                 @ ip<- opcode from rINST
     GOTO_OPCODE(ip)                     @ execute it
@@ -391,101 +405,135 @@ dalvik_inst:
     .fnend
 #endif
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_MOVE: /* 0x01 */
-/* File: armv6t2/OP_MOVE.S */
+/* File: armv6t2_taint/OP_MOVE.S */
     /* for move, move-object, long-to-int */
     /* op vA, vB */
     mov     r1, rINST, lsr #12          @ r1<- B from 15:12
     ubfx    r0, rINST, #8, #4           @ r0<- A from 11:8
     FETCH_ADVANCE_INST(1)               @ advance rPC, load rINST
     GET_VREG(r2, r1)                    @ r2<- fp[B]
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r3)
+    GET_VREG_TAINT(r1, r1, r3)
+    SET_VREG_TAINT(r1, r0, r3)
+// end WITH_TAINT_TRACKING
     GET_INST_OPCODE(ip)                 @ ip<- opcode from rINST
     SET_VREG(r2, r0)                    @ fp[A]<- r2
     GOTO_OPCODE(ip)                     @ execute next instruction
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_MOVE_FROM16: /* 0x02 */
-/* File: armv5te/OP_MOVE_FROM16.S */
+/* File: armv5te_taint/OP_MOVE_FROM16.S */
     /* for: move/from16, move-object/from16 */
     /* op vAA, vBBBB */
     FETCH(r1, 1)                        @ r1<- BBBB
     mov     r0, rINST, lsr #8           @ r0<- AA
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
     GET_VREG(r2, r1)                    @ r2<- fp[BBBB]
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r3)
+    GET_VREG_TAINT(r1, r1, r3)
+    SET_VREG_TAINT(r1, r0, r3)
+// end WITH_TAINT_TRACKING
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
     SET_VREG(r2, r0)                    @ fp[AA]<- r2
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_MOVE_16: /* 0x03 */
-/* File: armv5te/OP_MOVE_16.S */
+/* File: armv5te_taint/OP_MOVE_16.S */
     /* for: move/16, move-object/16 */
     /* op vAAAA, vBBBB */
     FETCH(r1, 2)                        @ r1<- BBBB
     FETCH(r0, 1)                        @ r0<- AAAA
     FETCH_ADVANCE_INST(3)               @ advance rPC, load rINST
     GET_VREG(r2, r1)                    @ r2<- fp[BBBB]
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r3)
+    GET_VREG_TAINT(r1, r1, r3)
+    SET_VREG_TAINT(r1, r0, r3)
+// end WITH_TAINT_TRACKING
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
     SET_VREG(r2, r0)                    @ fp[AAAA]<- r2
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_MOVE_WIDE: /* 0x04 */
-/* File: armv6t2/OP_MOVE_WIDE.S */
+/* File: armv6t2_taint/OP_MOVE_WIDE.S */
     /* move-wide vA, vB */
     /* NOTE: regs can overlap, e.g. "move v6,v7" or "move v7,v6" */
     mov     r3, rINST, lsr #12          @ r3<- B
     ubfx    r2, rINST, #8, #4           @ r2<- A
-    add     r3, rFP, r3, lsl #2         @ r3<- &fp[B]
-    add     r2, rFP, r2, lsl #2         @ r2<- &fp[A]
-    ldmia   r3, {r0-r1}                 @ r0/r1<- fp[B]
+// begin WITH_TAINT_TRACKING
+    add     r3, rFP, r3, lsl #3         @ r3<- &fp[B]
+    add     r9, rFP, r2, lsl #3         @ r9<- &fp[A]
+    ldmia   r3, {r0-r3}                 @ r0/r1<- fp[B]
+// end WITH_TAINT_TRACKING
     FETCH_ADVANCE_INST(1)               @ advance rPC, load rINST
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    stmia   r2, {r0-r1}                 @ fp[A]<- r0/r1
+// begin WITH_TAINT_TRACKING
+    stmia   r9, {r0-r3}                 @ fp[A]<- r0/r1
+// end WITH_TAINT_TRACKING
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_MOVE_WIDE_FROM16: /* 0x05 */
-/* File: armv5te/OP_MOVE_WIDE_FROM16.S */
+/* File: armv5te_taint/OP_MOVE_WIDE_FROM16.S */
     /* move-wide/from16 vAA, vBBBB */
     /* NOTE: regs can overlap, e.g. "move v6,v7" or "move v7,v6" */
     FETCH(r3, 1)                        @ r3<- BBBB
     mov     r2, rINST, lsr #8           @ r2<- AA
-    add     r3, rFP, r3, lsl #2         @ r3<- &fp[BBBB]
-    add     r2, rFP, r2, lsl #2         @ r2<- &fp[AA]
-    ldmia   r3, {r0-r1}                 @ r0/r1<- fp[BBBB]
+// begin WITH_TAINT_TRACKING
+    add     r3, rFP, r3, lsl #3         @ r3<- &fp[BBBB]
+    add     r9, rFP, r2, lsl #3         @ r9<- &fp[AA]
+    ldmia   r3, {r0-r3}                 @ r0/r1<- fp[BBBB]
+// end WITH_TAINT_TRACKING
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    stmia   r2, {r0-r1}                 @ fp[AA]<- r0/r1
+// begin WITH_TAINT_TRACKING
+    stmia   r9, {r0-r3}                 @ fp[AA]<- r0/r1
+// end WITH_TAINT_TRACKING
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_MOVE_WIDE_16: /* 0x06 */
-/* File: armv5te/OP_MOVE_WIDE_16.S */
+/* File: armv5te_taint/OP_MOVE_WIDE_16.S */
     /* move-wide/16 vAAAA, vBBBB */
     /* NOTE: regs can overlap, e.g. "move v6,v7" or "move v7,v6" */
     FETCH(r3, 2)                        @ r3<- BBBB
     FETCH(r2, 1)                        @ r2<- AAAA
-    add     r3, rFP, r3, lsl #2         @ r3<- &fp[BBBB]
-    add     r2, rFP, r2, lsl #2         @ r2<- &fp[AAAA]
-    ldmia   r3, {r0-r1}                 @ r0/r1<- fp[BBBB]
+// begin WITH_TAINT_TRACKING
+    add     r3, rFP, r3, lsl #3         @ r3<- &fp[BBBB]
+    add     r9, rFP, r2, lsl #3         @ r9<- &fp[AAAA]
+    ldmia   r3, {r0-r3}                 @ r0/r1<- fp[BBBB]
+// end WITH_TAINT_TRACKING
     FETCH_ADVANCE_INST(3)               @ advance rPC, load rINST
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    stmia   r2, {r0-r1}                 @ fp[AAAA]<- r0/r1
+// begin WITH_TAINT_TRACKING
+    stmia   r9, {r0-r3}                 @ fp[AAAA]<- r0/r1
+// end WITH_TAINT_TRACKING
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_MOVE_OBJECT: /* 0x07 */
-/* File: armv5te/OP_MOVE_OBJECT.S */
-/* File: armv5te/OP_MOVE.S */
+/* File: armv5te_taint/OP_MOVE_OBJECT.S */
+/* File: armv5te_taint/OP_MOVE.S */
     /* for move, move-object, long-to-int */
     /* op vA, vB */
     mov     r1, rINST, lsr #12          @ r1<- B from 15:12
@@ -493,47 +541,65 @@ dalvik_inst:
     FETCH_ADVANCE_INST(1)               @ advance rPC, load rINST
     GET_VREG(r2, r1)                    @ r2<- fp[B]
     and     r0, r0, #15
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r3)
+    GET_VREG_TAINT(r1, r1, r3)
+    SET_VREG_TAINT(r1, r0, r3)
+// end WITH_TAINT_TRACKING
     GET_INST_OPCODE(ip)                 @ ip<- opcode from rINST
     SET_VREG(r2, r0)                    @ fp[A]<- r2
     GOTO_OPCODE(ip)                     @ execute next instruction
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_MOVE_OBJECT_FROM16: /* 0x08 */
-/* File: armv5te/OP_MOVE_OBJECT_FROM16.S */
-/* File: armv5te/OP_MOVE_FROM16.S */
+/* File: armv5te_taint/OP_MOVE_OBJECT_FROM16.S */
+/* File: armv5te_taint/OP_MOVE_FROM16.S */
     /* for: move/from16, move-object/from16 */
     /* op vAA, vBBBB */
     FETCH(r1, 1)                        @ r1<- BBBB
     mov     r0, rINST, lsr #8           @ r0<- AA
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
     GET_VREG(r2, r1)                    @ r2<- fp[BBBB]
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r3)
+    GET_VREG_TAINT(r1, r1, r3)
+    SET_VREG_TAINT(r1, r0, r3)
+// end WITH_TAINT_TRACKING
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
     SET_VREG(r2, r0)                    @ fp[AA]<- r2
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_MOVE_OBJECT_16: /* 0x09 */
-/* File: armv5te/OP_MOVE_OBJECT_16.S */
-/* File: armv5te/OP_MOVE_16.S */
+/* File: armv5te_taint/OP_MOVE_OBJECT_16.S */
+/* File: armv5te_taint/OP_MOVE_16.S */
     /* for: move/16, move-object/16 */
     /* op vAAAA, vBBBB */
     FETCH(r1, 2)                        @ r1<- BBBB
     FETCH(r0, 1)                        @ r0<- AAAA
     FETCH_ADVANCE_INST(3)               @ advance rPC, load rINST
     GET_VREG(r2, r1)                    @ r2<- fp[BBBB]
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r3)
+    GET_VREG_TAINT(r1, r1, r3)
+    SET_VREG_TAINT(r1, r0, r3)
+// end WITH_TAINT_TRACKING
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
     SET_VREG(r2, r0)                    @ fp[AAAA]<- r2
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_MOVE_RESULT: /* 0x0a */
-/* File: armv5te/OP_MOVE_RESULT.S */
+/* File: armv5te_taint/OP_MOVE_RESULT.S */
     /* for: move-result, move-result-object */
     /* op vAA */
     mov     r2, rINST, lsr #8           @ r2<- AA
@@ -541,27 +607,42 @@ dalvik_inst:
     ldr     r0, [rSELF, #offThread_retval]    @ r0<- self->retval.i
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
     SET_VREG(r0, r2)                    @ fp[AA]<- r0
+// begin WITH_TAINT_TRACKING
+    ldr     r0, [rSELF, #offThread_rtaint]
+    SET_TAINT_FP(r1)
+    SET_VREG_TAINT(r0, r2, r1)
+// end WITH_TAINT_TRACKING
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
 /* ------------------------------ */
     .balign 64
 .L_OP_MOVE_RESULT_WIDE: /* 0x0b */
-/* File: armv5te/OP_MOVE_RESULT_WIDE.S */
+/* File: armv5te_taint/OP_MOVE_RESULT_WIDE.S */
     /* move-result-wide vAA */
     mov     r2, rINST, lsr #8           @ r2<- AA
     add     r3, rSELF, #offThread_retval  @ r3<- &self->retval
-    add     r2, rFP, r2, lsl #2         @ r2<- &fp[AA]
+// begin WITH_TAINT_TRACKING
+    add     r2, rFP, r2, lsl #3         @ r2<- &fp[AA]
+// end WITH_TAINT_TRACKING
     ldmia   r3, {r0-r1}                 @ r0/r1<- retval.j
     FETCH_ADVANCE_INST(1)               @ advance rPC, load rINST
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    stmia   r2, {r0-r1}                 @ fp[AA]<- r0/r1
+// begin WITH_TAINT_TRACKING
+//    stmia   r2, {r0-r1}                 @ fp[AA]<- r0/r1
+    ldr r3, [rSELF, #offThread_rtaint]
+    str r0, [r2, #0]
+    str r3, [r2, #4]
+    str r1, [r2, #8]
+    str r3, [r2, #12]
+// end WITH_TAINT_TRACKING
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_MOVE_RESULT_OBJECT: /* 0x0c */
-/* File: armv5te/OP_MOVE_RESULT_OBJECT.S */
-/* File: armv5te/OP_MOVE_RESULT.S */
+/* File: armv5te_taint/OP_MOVE_RESULT_OBJECT.S */
+/* File: armv5te_taint/OP_MOVE_RESULT.S */
     /* for: move-result, move-result-object */
     /* op vAA */
     mov     r2, rINST, lsr #8           @ r2<- AA
@@ -569,19 +650,29 @@ dalvik_inst:
     ldr     r0, [rSELF, #offThread_retval]    @ r0<- self->retval.i
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
     SET_VREG(r0, r2)                    @ fp[AA]<- r0
+// begin WITH_TAINT_TRACKING
+    ldr     r0, [rSELF, #offThread_rtaint]
+    SET_TAINT_FP(r1)
+    SET_VREG_TAINT(r0, r2, r1)
+// end WITH_TAINT_TRACKING
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
 
 /* ------------------------------ */
     .balign 64
 .L_OP_MOVE_EXCEPTION: /* 0x0d */
-/* File: armv5te/OP_MOVE_EXCEPTION.S */
+/* File: armv5te_taint/OP_MOVE_EXCEPTION.S */
     /* move-exception vAA */
     mov     r2, rINST, lsr #8           @ r2<- AA
     ldr     r3, [rSELF, #offThread_exception]  @ r3<- dvmGetException bypass
     mov     r1, #0                      @ r1<- 0
     FETCH_ADVANCE_INST(1)               @ advance rPC, load rINST
     SET_VREG(r3, r2)                    @ fp[AA]<- exception obj
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r3)
+    SET_TAINT_CLEAR(r9)
+    SET_VREG_TAINT(r9, r2, r3)
+// end WITH_TAINT_TRACKING
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
     str     r1, [rSELF, #offThread_exception]  @ dvmClearException bypass
     GOTO_OPCODE(ip)                     @ jump to next instruction
@@ -589,13 +680,16 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_RETURN_VOID: /* 0x0e */
-/* File: armv5te/OP_RETURN_VOID.S */
+/* File: armv5te_taint/OP_RETURN_VOID.S */
+    SET_TAINT_CLEAR(r1)
+    str     r1, [rSELF, #offThread_rtaint]
     b       common_returnFromMethod
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_RETURN: /* 0x0f */
-/* File: armv5te/OP_RETURN.S */
+/* File: armv5te_taint/OP_RETURN.S */
     /*
      * Return a 32-bit value.  Copies the return value into the "thread"
      * structure, then jumps to the return handler.
@@ -605,30 +699,43 @@ dalvik_inst:
     /* op vAA */
     mov     r2, rINST, lsr #8           @ r2<- AA
     GET_VREG(r0, r2)                    @ r0<- vAA
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r1)
+    GET_VREG_TAINT(r3, r2, r1)
+    str     r3, [rSELF, #offThread_rtaint]
+// end WITH_TAINT_TRACKING
     str     r0, [rSELF, #offThread_retval] @ retval.i <- vAA
     b       common_returnFromMethod
 
 /* ------------------------------ */
     .balign 64
 .L_OP_RETURN_WIDE: /* 0x10 */
-/* File: armv5te/OP_RETURN_WIDE.S */
+/* File: armv5te_taint/OP_RETURN_WIDE.S */
     /*
      * Return a 64-bit value.  Copies the return value into the "thread"
      * structure, then jumps to the return handler.
      */
     /* return-wide vAA */
     mov     r2, rINST, lsr #8           @ r2<- AA
-    add     r2, rFP, r2, lsl #2         @ r2<- &fp[AA]
+// begin WITH_TAINT_TRACKING
+    add     r2, rFP, r2, lsl #3         @ r2<- &fp[AA]
+// end WITH_TAINT_TRACKING
     add     r3, rSELF, #offThread_retval  @ r3<- &self->retval
-    ldmia   r2, {r0-r1}                 @ r0/r1 <- vAA/vAA+1
+// begin WITH_TAINT_TRACKING
+//    ldmia   r2, {r0-r1}                 @ r0/r1 <- vAA/vAA+1
+    ldr     r0, [r2, #0]
+    ldr     r1, [r2, #8]
+    ldr     r9, [r2, #4]
+    str     r9, [rSELF, #offThread_rtaint]
+// end WITH_TAINT_TRACKING
     stmia   r3, {r0-r1}                 @ retval<- r0/r1
     b       common_returnFromMethod
 
 /* ------------------------------ */
     .balign 64
 .L_OP_RETURN_OBJECT: /* 0x11 */
-/* File: armv5te/OP_RETURN_OBJECT.S */
-/* File: armv5te/OP_RETURN.S */
+/* File: armv5te_taint/OP_RETURN_OBJECT.S */
+/* File: armv5te_taint/OP_RETURN.S */
     /*
      * Return a 32-bit value.  Copies the return value into the "thread"
      * structure, then jumps to the return handler.
@@ -638,6 +745,11 @@ dalvik_inst:
     /* op vAA */
     mov     r2, rINST, lsr #8           @ r2<- AA
     GET_VREG(r0, r2)                    @ r0<- vAA
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r1)
+    GET_VREG_TAINT(r3, r2, r1)
+    str     r3, [rSELF, #offThread_rtaint]
+// end WITH_TAINT_TRACKING
     str     r0, [rSELF, #offThread_retval] @ retval.i <- vAA
     b       common_returnFromMethod
 
@@ -645,12 +757,17 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_CONST_4: /* 0x12 */
-/* File: armv6t2/OP_CONST_4.S */
+/* File: armv6t2_taint/OP_CONST_4.S */
     /* const/4 vA, #+B */
     mov     r1, rINST, lsl #16          @ r1<- Bxxx0000
     ubfx    r0, rINST, #8, #4           @ r0<- A
     FETCH_ADVANCE_INST(1)               @ advance rPC, load rINST
     mov     r1, r1, asr #28             @ r1<- sssssssB (sign-extended)
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r2)
+    SET_TAINT_CLEAR(r3)
+    SET_VREG_TAINT(r3, r0, r2)
+// end WITH_TAINT_TRACKING
     GET_INST_OPCODE(ip)                 @ ip<- opcode from rINST
     SET_VREG(r1, r0)                    @ fp[A]<- r1
     GOTO_OPCODE(ip)                     @ execute next instruction
@@ -658,76 +775,110 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_CONST_16: /* 0x13 */
-/* File: armv5te/OP_CONST_16.S */
+/* File: armv5te_taint/OP_CONST_16.S */
     /* const/16 vAA, #+BBBB */
     FETCH_S(r0, 1)                      @ r0<- ssssBBBB (sign-extended)
     mov     r3, rINST, lsr #8           @ r3<- AA
+// BEGIN WITH_TAINT_TRACKING
+	SET_TAINT_FP(r1)
+	SET_TAINT_CLEAR(r2)
+    SET_VREG_TAINT(r2, r3, r1)
+// END WITH_TAINT_TRACKING
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
     SET_VREG(r0, r3)                    @ vAA<- r0
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_CONST: /* 0x14 */
-/* File: armv5te/OP_CONST.S */
+/* File: armv5te_taint/OP_CONST.S */
     /* const vAA, #+BBBBbbbb */
     mov     r3, rINST, lsr #8           @ r3<- AA
     FETCH(r0, 1)                        @ r0<- bbbb (low)
     FETCH(r1, 2)                        @ r1<- BBBB (high)
     FETCH_ADVANCE_INST(3)               @ advance rPC, load rINST
     orr     r0, r0, r1, lsl #16         @ r0<- BBBBbbbb
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r2)
+    SET_TAINT_CLEAR(r1)
+    SET_VREG_TAINT(r1, r3, r2)
+// end WITH_TAINT_TRACKING
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
     SET_VREG(r0, r3)                    @ vAA<- r0
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_CONST_HIGH16: /* 0x15 */
-/* File: armv5te/OP_CONST_HIGH16.S */
+/* File: armv5te_taint/OP_CONST_HIGH16.S */
     /* const/high16 vAA, #+BBBB0000 */
     FETCH(r0, 1)                        @ r0<- 0000BBBB (zero-extended)
     mov     r3, rINST, lsr #8           @ r3<- AA
     mov     r0, r0, lsl #16             @ r0<- BBBB0000
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r2)
+    SET_TAINT_CLEAR(r1)
+    SET_VREG_TAINT(r1, r3, r2)
+// end WITH_TAINT_TRACKING
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
     SET_VREG(r0, r3)                    @ vAA<- r0
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_CONST_WIDE_16: /* 0x16 */
-/* File: armv5te/OP_CONST_WIDE_16.S */
+/* File: armv5te_taint/OP_CONST_WIDE_16.S */
     /* const-wide/16 vAA, #+BBBB */
     FETCH_S(r0, 1)                      @ r0<- ssssBBBB (sign-extended)
     mov     r3, rINST, lsr #8           @ r3<- AA
-    mov     r1, r0, asr #31             @ r1<- ssssssss
+// begin WITH_TAINT_TRACKING
+    mov     r2, r0, asr #31             @ r1<- ssssssss
+// end WITH_TAINT_TRACKING
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
-    add     r3, rFP, r3, lsl #2         @ r3<- &fp[AA]
+// begin WITH_TAINT_TRACKING
+    add     r9, rFP, r3, lsl #3         @ r3<- &fp[AA]
+// end WITH_TAINT_TRACKING
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    stmia   r3, {r0-r1}                 @ vAA<- r0/r1
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_CLEAR(r1)
+    SET_TAINT_CLEAR(r3)
+    stmia   r9, {r0-r3}                 @ vAA<- r0/r1
+// end WITH_TAINT_TRACKING
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_CONST_WIDE_32: /* 0x17 */
-/* File: armv5te/OP_CONST_WIDE_32.S */
+/* File: armv5te_taint/OP_CONST_WIDE_32.S */
     /* const-wide/32 vAA, #+BBBBbbbb */
     FETCH(r0, 1)                        @ r0<- 0000bbbb (low)
     mov     r3, rINST, lsr #8           @ r3<- AA
     FETCH_S(r2, 2)                      @ r2<- ssssBBBB (high)
     FETCH_ADVANCE_INST(3)               @ advance rPC, load rINST
     orr     r0, r0, r2, lsl #16         @ r0<- BBBBbbbb
-    add     r3, rFP, r3, lsl #2         @ r3<- &fp[AA]
-    mov     r1, r0, asr #31             @ r1<- ssssssss
+// begin WITH_TAINT_TRACKING
+    add     r9, rFP, r3, lsl #3         @ r9<- &fp[AA]
+    mov     r2, r0, asr #31             @ r2<- ssssssss
+// end WITH_TAINT_TRACKING
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    stmia   r3, {r0-r1}                 @ vAA<- r0/r1
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_CLEAR(r1)
+    SET_TAINT_CLEAR(r3)
+    stmia   r9, {r0-r3}                 @ vAA<- r0/r1
+// end WITH_TAINT_TRACKING
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_CONST_WIDE: /* 0x18 */
-/* File: armv5te/OP_CONST_WIDE.S */
+/* File: armv5te_taint/OP_CONST_WIDE.S */
     /* const-wide vAA, #+HHHHhhhhBBBBbbbb */
     FETCH(r0, 1)                        @ r0<- bbbb (low)
     FETCH(r1, 2)                        @ r1<- BBBB (low middle)
@@ -735,32 +886,50 @@ dalvik_inst:
     orr     r0, r0, r1, lsl #16         @ r0<- BBBBbbbb (low word)
     FETCH(r3, 4)                        @ r3<- HHHH (high)
     mov     r9, rINST, lsr #8           @ r9<- AA
-    orr     r1, r2, r3, lsl #16         @ r1<- HHHHhhhh (high word)
+// begin WITH_TAINT_TRACKING
+    orr     r2, r2, r3, lsl #16         @ r2<- HHHHhhhh (high word)
+// end WITH_TAINT_TRACKING
     FETCH_ADVANCE_INST(5)               @ advance rPC, load rINST
-    add     r9, rFP, r9, lsl #2         @ r9<- &fp[AA]
+// begin WITH_TAINT_TRACKING
+    add     r9, rFP, r9, lsl #3         @ r9<- &fp[AA]
+// end WITH_TAINT_TRACKING
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    stmia   r9, {r0-r1}                 @ vAA<- r0/r1
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_CLEAR(r1)
+    SET_TAINT_CLEAR(r3)
+    stmia   r9, {r0-r3}                 @ vAA<- r0/r1
+// end WITH_TAINT_TRACKING
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_CONST_WIDE_HIGH16: /* 0x19 */
-/* File: armv5te/OP_CONST_WIDE_HIGH16.S */
+/* File: armv5te_taint/OP_CONST_WIDE_HIGH16.S */
     /* const-wide/high16 vAA, #+BBBB000000000000 */
     FETCH(r1, 1)                        @ r1<- 0000BBBB (zero-extended)
     mov     r3, rINST, lsr #8           @ r3<- AA
     mov     r0, #0                      @ r0<- 00000000
-    mov     r1, r1, lsl #16             @ r1<- BBBB0000
+// begin WITH_TAINT_TRACKING
+    mov     r2, r1, lsl #16             @ r1<- BBBB0000
+// end WITH_TAINT_TRACKING
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
-    add     r3, rFP, r3, lsl #2         @ r3<- &fp[AA]
+// begin WITH_TAINT_TRACKING
+    add     r9, rFP, r3, lsl #3         @ r3<- &fp[AA]
+// end WITH_TAINT_TRACKING
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    stmia   r3, {r0-r1}                 @ vAA<- r0/r1
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_CLEAR(r1)
+    SET_TAINT_CLEAR(r3)
+    stmia   r9, {r0-r3}                 @ vAA<- r0/r1
+// end WITH_TAINT_TRACKING
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_CONST_STRING: /* 0x1a */
-/* File: armv5te/OP_CONST_STRING.S */
+/* File: armv5te_taint/OP_CONST_STRING.S */
     /* const/string vAA, String@BBBB */
     FETCH(r1, 1)                        @ r1<- BBBB
     ldr     r2, [rSELF, #offThread_methodClassDex]  @ r2<- self->methodClassDex
@@ -769,6 +938,11 @@ dalvik_inst:
     ldr     r0, [r2, r1, lsl #2]        @ r0<- pResStrings[BBBB]
     cmp     r0, #0                      @ not yet resolved?
     beq     .LOP_CONST_STRING_resolve
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r2)
+    SET_TAINT_CLEAR(r3)
+    SET_VREG_TAINT(r3, r9, r2)
+// end WITH_TAINT_TRACKING
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
     SET_VREG(r0, r9)                    @ vAA<- r0
@@ -777,7 +951,7 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_CONST_STRING_JUMBO: /* 0x1b */
-/* File: armv5te/OP_CONST_STRING_JUMBO.S */
+/* File: armv5te_taint/OP_CONST_STRING_JUMBO.S */
     /* const/string vAA, String@BBBBBBBB */
     FETCH(r0, 1)                        @ r0<- bbbb (low)
     FETCH(r1, 2)                        @ r1<- BBBB (high)
@@ -788,6 +962,11 @@ dalvik_inst:
     ldr     r0, [r2, r1, lsl #2]        @ r0<- pResStrings[BBBB]
     cmp     r0, #0
     beq     .LOP_CONST_STRING_JUMBO_resolve
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r2)
+    SET_TAINT_CLEAR(r3)
+    SET_VREG_TAINT(r3, r9, r2)
+// end WITH_TAINT_TRACKING
     FETCH_ADVANCE_INST(3)               @ advance rPC, load rINST
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
     SET_VREG(r0, r9)                    @ vAA<- r0
@@ -796,7 +975,7 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_CONST_CLASS: /* 0x1c */
-/* File: armv5te/OP_CONST_CLASS.S */
+/* File: armv5te_taint/OP_CONST_CLASS.S */
     /* const/class vAA, Class@BBBB */
     FETCH(r1, 1)                        @ r1<- BBBB
     ldr     r2, [rSELF, #offThread_methodClassDex]  @ r2<- self->methodClassDex
@@ -805,6 +984,11 @@ dalvik_inst:
     ldr     r0, [r2, r1, lsl #2]        @ r0<- pResClasses[BBBB]
     cmp     r0, #0                      @ not yet resolved?
     beq     .LOP_CONST_CLASS_resolve
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r2)
+    SET_TAINT_CLEAR(r3)
+    SET_VREG_TAINT(r3, r9, r2)
+// end WITH_TAINT_TRACKING
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
     SET_VREG(r0, r9)                    @ vAA<- r0
@@ -813,7 +997,7 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_MONITOR_ENTER: /* 0x1d */
-/* File: armv5te/OP_MONITOR_ENTER.S */
+/* File: armv5te_taint/OP_MONITOR_ENTER.S */
     /*
      * Synchronize on an object.
      */
@@ -832,7 +1016,7 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_MONITOR_EXIT: /* 0x1e */
-/* File: armv5te/OP_MONITOR_EXIT.S */
+/* File: armv5te_taint/OP_MONITOR_EXIT.S */
     /*
      * Unlock an object.
      *
@@ -860,7 +1044,7 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_CHECK_CAST: /* 0x1f */
-/* File: armv5te/OP_CHECK_CAST.S */
+/* File: armv5te_taint/OP_CHECK_CAST.S */
     /*
      * Check to see if a cast from one class to another is allowed.
      */
@@ -887,7 +1071,7 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_INSTANCE_OF: /* 0x20 */
-/* File: armv5te/OP_INSTANCE_OF.S */
+/* File: armv5te_taint/OP_INSTANCE_OF.S */
     /*
      * Check to see if an object reference is an instance of a class.
      *
@@ -916,7 +1100,7 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_ARRAY_LENGTH: /* 0x21 */
-/* File: armv6t2/OP_ARRAY_LENGTH.S */
+/* File: armv6t2_taint/OP_ARRAY_LENGTH.S */
     /*
      * Return the length of an array.
      */
@@ -925,6 +1109,11 @@ dalvik_inst:
     GET_VREG(r0, r1)                    @ r0<- vB (object ref)
     cmp     r0, #0                      @ is object null?
     beq     common_errNullObject        @ yup, fail
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r1)
+    SET_TAINT_CLEAR(r3)
+    SET_VREG_TAINT(r3, r2, r1)
+// end WITH_TAINT_TRACKING
     FETCH_ADVANCE_INST(1)               @ advance rPC, load rINST
     ldr     r3, [r0, #offArrayObject_length]    @ r3<- array length
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
@@ -934,7 +1123,7 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_NEW_INSTANCE: /* 0x22 */
-/* File: armv5te/OP_NEW_INSTANCE.S */
+/* File: armv5te_taint/OP_NEW_INSTANCE.S */
     /*
      * Create a new instance of a class.
      */
@@ -961,7 +1150,7 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_NEW_ARRAY: /* 0x23 */
-/* File: armv5te/OP_NEW_ARRAY.S */
+/* File: armv5te_taint/OP_NEW_ARRAY.S */
     /*
      * Allocate an array of objects, specified with the array class
      * and a count.
@@ -986,7 +1175,7 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_FILLED_NEW_ARRAY: /* 0x24 */
-/* File: armv5te/OP_FILLED_NEW_ARRAY.S */
+/* File: armv5te_taint/OP_FILLED_NEW_ARRAY.S */
     /*
      * Create a new array with elements filled from registers.
      *
@@ -1013,8 +1202,8 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_FILLED_NEW_ARRAY_RANGE: /* 0x25 */
-/* File: armv5te/OP_FILLED_NEW_ARRAY_RANGE.S */
-/* File: armv5te/OP_FILLED_NEW_ARRAY.S */
+/* File: armv5te_taint/OP_FILLED_NEW_ARRAY_RANGE.S */
+/* File: armv5te_taint/OP_FILLED_NEW_ARRAY.S */
     /*
      * Create a new array with elements filled from registers.
      *
@@ -1042,7 +1231,7 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_FILL_ARRAY_DATA: /* 0x26 */
-/* File: armv5te/OP_FILL_ARRAY_DATA.S */
+/* File: armv5te_taint/OP_FILL_ARRAY_DATA.S */
     /* fill-array-data vAA, +BBBBBBBB */
     FETCH(r0, 1)                        @ r0<- bbbb (lo)
     FETCH(r1, 2)                        @ r1<- BBBB (hi)
@@ -1061,7 +1250,7 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_THROW: /* 0x27 */
-/* File: armv5te/OP_THROW.S */
+/* File: armv5te_taint/OP_THROW.S */
     /*
      * Throw an exception object in the current thread.
      */
@@ -1078,7 +1267,7 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_GOTO: /* 0x28 */
-/* File: armv5te/OP_GOTO.S */
+/* File: armv5te_taint/OP_GOTO.S */
     /*
      * Unconditional branch, 8-bit offset.
      *
@@ -1103,7 +1292,7 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_GOTO_16: /* 0x29 */
-/* File: armv5te/OP_GOTO_16.S */
+/* File: armv5te_taint/OP_GOTO_16.S */
     /*
      * Unconditional branch, 16-bit offset.
      *
@@ -1125,7 +1314,7 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_GOTO_32: /* 0x2a */
-/* File: armv5te/OP_GOTO_32.S */
+/* File: armv5te_taint/OP_GOTO_32.S */
     /*
      * Unconditional branch, 32-bit offset.
      *
@@ -1157,7 +1346,7 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_PACKED_SWITCH: /* 0x2b */
-/* File: armv5te/OP_PACKED_SWITCH.S */
+/* File: armv5te_taint/OP_PACKED_SWITCH.S */
     /*
      * Handle a packed-switch or sparse-switch instruction.  In both cases
      * we decode it and hand it off to a helper function.
@@ -1195,8 +1384,8 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_SPARSE_SWITCH: /* 0x2c */
-/* File: armv5te/OP_SPARSE_SWITCH.S */
-/* File: armv5te/OP_PACKED_SWITCH.S */
+/* File: armv5te_taint/OP_SPARSE_SWITCH.S */
+/* File: armv5te_taint/OP_PACKED_SWITCH.S */
     /*
      * Handle a packed-switch or sparse-switch instruction.  In both cases
      * we decode it and hand it off to a helper function.
@@ -1235,7 +1424,7 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_CMPL_FLOAT: /* 0x2d */
-/* File: arm-vfp/OP_CMPL_FLOAT.S */
+/* File: arm-vfp_taint/OP_CMPL_FLOAT.S */
     /*
      * Compare two floating-point values.  Puts 0, 1, or -1 into the
      * destination register based on the results of the comparison.
@@ -1274,7 +1463,7 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_CMPG_FLOAT: /* 0x2e */
-/* File: arm-vfp/OP_CMPG_FLOAT.S */
+/* File: arm-vfp_taint/OP_CMPG_FLOAT.S */
     /*
      * Compare two floating-point values.  Puts 0, 1, or -1 into the
      * destination register based on the results of the comparison.
@@ -1313,7 +1502,7 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_CMPL_DOUBLE: /* 0x2f */
-/* File: arm-vfp/OP_CMPL_DOUBLE.S */
+/* File: arm-vfp_taint/OP_CMPL_DOUBLE.S */
     /*
      * Compare two floating-point values.  Puts 0, 1, or -1 into the
      * destination register based on the results of the comparison.
@@ -1337,22 +1526,25 @@ dalvik_inst:
     mov     r3, r0, lsr #8              @ r3<- CC
     VREG_INDEX_TO_ADDR(r2, r2)          @ r2<- &vBB
     VREG_INDEX_TO_ADDR(r3, r3)          @ r3<- &vCC
-    fldd    d0, [r2]                    @ d0<- vBB
-    fldd    d1, [r3]                    @ d1<- vCC
+// begin WITH_TAINT_TRACKING
+//    fldd    d0, [r2]                    @ d0<- vBB
+    flds    s0, [r2]
+    flds    s1, [r2, #8]
+//    fldd    d1, [r3]                    @ d1<- vCC
+    flds    s2, [r3]
+    flds    s3, [r3, #8]
+// end WITH_TAINT_TRACKING
     fcmped  d0, d1                      @ compare (vBB, vCC)
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
     mvn     r0, #0                      @ r0<- -1 (default)
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    fmstat                              @ export status flags
-    movgt   r0, #1                      @ (greater than) r1<- 1
-    moveq   r0, #0                      @ (equal) r1<- 0
     b       .LOP_CMPL_DOUBLE_finish          @ argh
 
 
 /* ------------------------------ */
     .balign 64
 .L_OP_CMPG_DOUBLE: /* 0x30 */
-/* File: arm-vfp/OP_CMPG_DOUBLE.S */
+/* File: arm-vfp_taint/OP_CMPG_DOUBLE.S */
     /*
      * Compare two floating-point values.  Puts 0, 1, or -1 into the
      * destination register based on the results of the comparison.
@@ -1376,22 +1568,25 @@ dalvik_inst:
     mov     r3, r0, lsr #8              @ r3<- CC
     VREG_INDEX_TO_ADDR(r2, r2)          @ r2<- &vBB
     VREG_INDEX_TO_ADDR(r3, r3)          @ r3<- &vCC
-    fldd    d0, [r2]                    @ d0<- vBB
-    fldd    d1, [r3]                    @ d1<- vCC
+// begin WITH_TAINT_TRACKING
+//    fldd    d0, [r2]                    @ d0<- vBB
+    flds    s0, [r2]
+    flds    s1, [r2, #8]
+//    fldd    d1, [r3]                    @ d1<- vCC
+    flds    s2, [r3]
+    flds    s3, [r3, #8]
+// end WITH_TAINT_TRACKING
     fcmped  d0, d1                      @ compare (vBB, vCC)
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
     mov     r0, #1                      @ r0<- 1 (default)
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    fmstat                              @ export status flags
-    mvnmi   r0, #0                      @ (less than) r1<- -1
-    moveq   r0, #0                      @ (equal) r1<- 0
     b       .LOP_CMPG_DOUBLE_finish          @ argh
 
 
 /* ------------------------------ */
     .balign 64
 .L_OP_CMP_LONG: /* 0x31 */
-/* File: armv5te/OP_CMP_LONG.S */
+/* File: armv5te_taint/OP_CMP_LONG.S */
     /*
      * Compare two 64-bit values.  Puts 0, 1, or -1 into the destination
      * register based on the results of the comparison.
@@ -1417,10 +1612,9 @@ dalvik_inst:
     mov     r9, rINST, lsr #8           @ r9<- AA
     and     r2, r0, #255                @ r2<- BB
     mov     r3, r0, lsr #8              @ r3<- CC
-    add     r2, rFP, r2, lsl #2         @ r2<- &fp[BB]
-    add     r3, rFP, r3, lsl #2         @ r3<- &fp[CC]
-    ldmia   r2, {r0-r1}                 @ r0/r1<- vBB/vBB+1
-    ldmia   r3, {r2-r3}                 @ r2/r3<- vCC/vCC+1
+// begin WITH_TAINT_TRACKING
+    bl      cmp_long_taint_prop
+// end WITH_TAINT_TRACKING
     cmp     r1, r3                      @ compare (vBB+1, vCC+1)
     blt     .LOP_CMP_LONG_less            @ signed compare on high part
     bgt     .LOP_CMP_LONG_greater
@@ -1432,8 +1626,8 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_IF_EQ: /* 0x32 */
-/* File: armv6t2/OP_IF_EQ.S */
-/* File: armv6t2/bincmp.S */
+/* File: armv6t2_taint/OP_IF_EQ.S */
+/* File: armv6t2_taint/bincmp.S */
     /*
      * Generic two-operand compare-and-branch operation.  Provide a "revcmp"
      * fragment that specifies the *reverse* comparison to perform, e.g.
@@ -1466,8 +1660,8 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_IF_NE: /* 0x33 */
-/* File: armv6t2/OP_IF_NE.S */
-/* File: armv6t2/bincmp.S */
+/* File: armv6t2_taint/OP_IF_NE.S */
+/* File: armv6t2_taint/bincmp.S */
     /*
      * Generic two-operand compare-and-branch operation.  Provide a "revcmp"
      * fragment that specifies the *reverse* comparison to perform, e.g.
@@ -1500,8 +1694,8 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_IF_LT: /* 0x34 */
-/* File: armv6t2/OP_IF_LT.S */
-/* File: armv6t2/bincmp.S */
+/* File: armv6t2_taint/OP_IF_LT.S */
+/* File: armv6t2_taint/bincmp.S */
     /*
      * Generic two-operand compare-and-branch operation.  Provide a "revcmp"
      * fragment that specifies the *reverse* comparison to perform, e.g.
@@ -1534,8 +1728,8 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_IF_GE: /* 0x35 */
-/* File: armv6t2/OP_IF_GE.S */
-/* File: armv6t2/bincmp.S */
+/* File: armv6t2_taint/OP_IF_GE.S */
+/* File: armv6t2_taint/bincmp.S */
     /*
      * Generic two-operand compare-and-branch operation.  Provide a "revcmp"
      * fragment that specifies the *reverse* comparison to perform, e.g.
@@ -1568,8 +1762,8 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_IF_GT: /* 0x36 */
-/* File: armv6t2/OP_IF_GT.S */
-/* File: armv6t2/bincmp.S */
+/* File: armv6t2_taint/OP_IF_GT.S */
+/* File: armv6t2_taint/bincmp.S */
     /*
      * Generic two-operand compare-and-branch operation.  Provide a "revcmp"
      * fragment that specifies the *reverse* comparison to perform, e.g.
@@ -1602,8 +1796,8 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_IF_LE: /* 0x37 */
-/* File: armv6t2/OP_IF_LE.S */
-/* File: armv6t2/bincmp.S */
+/* File: armv6t2_taint/OP_IF_LE.S */
+/* File: armv6t2_taint/bincmp.S */
     /*
      * Generic two-operand compare-and-branch operation.  Provide a "revcmp"
      * fragment that specifies the *reverse* comparison to perform, e.g.
@@ -1636,8 +1830,8 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_IF_EQZ: /* 0x38 */
-/* File: armv5te/OP_IF_EQZ.S */
-/* File: armv5te/zcmp.S */
+/* File: armv5te_taint/OP_IF_EQZ.S */
+/* File: armv5te_taint/zcmp.S */
     /*
      * Generic one-operand compare-and-branch operation.  Provide a "revcmp"
      * fragment that specifies the *reverse* comparison to perform, e.g.
@@ -1668,8 +1862,8 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_IF_NEZ: /* 0x39 */
-/* File: armv5te/OP_IF_NEZ.S */
-/* File: armv5te/zcmp.S */
+/* File: armv5te_taint/OP_IF_NEZ.S */
+/* File: armv5te_taint/zcmp.S */
     /*
      * Generic one-operand compare-and-branch operation.  Provide a "revcmp"
      * fragment that specifies the *reverse* comparison to perform, e.g.
@@ -1700,8 +1894,8 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_IF_LTZ: /* 0x3a */
-/* File: armv5te/OP_IF_LTZ.S */
-/* File: armv5te/zcmp.S */
+/* File: armv5te_taint/OP_IF_LTZ.S */
+/* File: armv5te_taint/zcmp.S */
     /*
      * Generic one-operand compare-and-branch operation.  Provide a "revcmp"
      * fragment that specifies the *reverse* comparison to perform, e.g.
@@ -1732,8 +1926,8 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_IF_GEZ: /* 0x3b */
-/* File: armv5te/OP_IF_GEZ.S */
-/* File: armv5te/zcmp.S */
+/* File: armv5te_taint/OP_IF_GEZ.S */
+/* File: armv5te_taint/zcmp.S */
     /*
      * Generic one-operand compare-and-branch operation.  Provide a "revcmp"
      * fragment that specifies the *reverse* comparison to perform, e.g.
@@ -1764,8 +1958,8 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_IF_GTZ: /* 0x3c */
-/* File: armv5te/OP_IF_GTZ.S */
-/* File: armv5te/zcmp.S */
+/* File: armv5te_taint/OP_IF_GTZ.S */
+/* File: armv5te_taint/zcmp.S */
     /*
      * Generic one-operand compare-and-branch operation.  Provide a "revcmp"
      * fragment that specifies the *reverse* comparison to perform, e.g.
@@ -1796,8 +1990,8 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_IF_LEZ: /* 0x3d */
-/* File: armv5te/OP_IF_LEZ.S */
-/* File: armv5te/zcmp.S */
+/* File: armv5te_taint/OP_IF_LEZ.S */
+/* File: armv5te_taint/zcmp.S */
     /*
      * Generic one-operand compare-and-branch operation.  Provide a "revcmp"
      * fragment that specifies the *reverse* comparison to perform, e.g.
@@ -1828,55 +2022,61 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_UNUSED_3E: /* 0x3e */
-/* File: armv5te/OP_UNUSED_3E.S */
-/* File: armv5te/unused.S */
+/* File: armv5te_taint/OP_UNUSED_3E.S */
+/* File: armv5te_taint/unused.S */
     bl      common_abort
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_UNUSED_3F: /* 0x3f */
-/* File: armv5te/OP_UNUSED_3F.S */
-/* File: armv5te/unused.S */
+/* File: armv5te_taint/OP_UNUSED_3F.S */
+/* File: armv5te_taint/unused.S */
     bl      common_abort
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_UNUSED_40: /* 0x40 */
-/* File: armv5te/OP_UNUSED_40.S */
-/* File: armv5te/unused.S */
+/* File: armv5te_taint/OP_UNUSED_40.S */
+/* File: armv5te_taint/unused.S */
     bl      common_abort
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_UNUSED_41: /* 0x41 */
-/* File: armv5te/OP_UNUSED_41.S */
-/* File: armv5te/unused.S */
+/* File: armv5te_taint/OP_UNUSED_41.S */
+/* File: armv5te_taint/unused.S */
     bl      common_abort
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_UNUSED_42: /* 0x42 */
-/* File: armv5te/OP_UNUSED_42.S */
-/* File: armv5te/unused.S */
+/* File: armv5te_taint/OP_UNUSED_42.S */
+/* File: armv5te_taint/unused.S */
     bl      common_abort
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_UNUSED_43: /* 0x43 */
-/* File: armv5te/OP_UNUSED_43.S */
-/* File: armv5te/unused.S */
+/* File: armv5te_taint/OP_UNUSED_43.S */
+/* File: armv5te_taint/unused.S */
     bl      common_abort
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_AGET: /* 0x44 */
-/* File: armv5te/OP_AGET.S */
+/* File: armv5te_taint/OP_AGET.S */
     /*
      * Array get, 32 bits or less.  vAA <- vBB[vCC].
      *
@@ -1893,20 +2093,27 @@ dalvik_inst:
     GET_VREG(r1, r3)                    @ r1<- vCC (requested index)
     cmp     r0, #0                      @ null array object?
     beq     common_errNullObject        @ yes, bail
+// begin WITH_TAINT_TRACKING
+    bl		.LOP_AGET_taint_prop_1
+// end WITH_TAINT_TRACKING
     ldr     r3, [r0, #offArrayObject_length]    @ r3<- arrayObj->length
     add     r0, r0, r1, lsl #2     @ r0<- arrayObj + index*width
     cmp     r1, r3                      @ compare unsigned index, length
-    bcs     common_errArrayIndex        @ index >= length, bail
-    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
+// begin WITH_TAINT_TRACKING
+//    bcs     common_errArrayIndex        @ index >= length, bail	// in subroutine
+//    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST // in subroutine
+    bl		.LOP_AGET_taint_prop_2
+// end WITH_TAINT_TRACKING
     ldr   r2, [r0, #offArrayObject_contents]  @ r2<- vBB[vCC]
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
     SET_VREG(r2, r9)                    @ vAA<- r2
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_AGET_WIDE: /* 0x45 */
-/* File: armv5te/OP_AGET_WIDE.S */
+/* File: armv5te_taint/OP_AGET_WIDE.S */
     /*
      * Array get, 64 bits.  vAA <- vBB[vCC].
      *
@@ -1921,6 +2128,9 @@ dalvik_inst:
     GET_VREG(r1, r3)                    @ r1<- vCC (requested index)
     cmp     r0, #0                      @ null array object?
     beq     common_errNullObject        @ yes, bail
+// begin WITH_TAINT_TRACKING
+    bl      .LOP_AGET_WIDE_taint_prop      @ r10<- taint
+// end WITH_TAINT_TRACKING
     ldr     r3, [r0, #offArrayObject_length]    @ r3<- arrayObj->length
     add     r0, r0, r1, lsl #3          @ r0<- arrayObj + index*width
     cmp     r1, r3                      @ compare unsigned index, length
@@ -1933,8 +2143,8 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_AGET_OBJECT: /* 0x46 */
-/* File: armv5te/OP_AGET_OBJECT.S */
-/* File: armv5te/OP_AGET.S */
+/* File: armv5te_taint/OP_AGET_OBJECT.S */
+/* File: armv5te_taint/OP_AGET.S */
     /*
      * Array get, 32 bits or less.  vAA <- vBB[vCC].
      *
@@ -1951,22 +2161,29 @@ dalvik_inst:
     GET_VREG(r1, r3)                    @ r1<- vCC (requested index)
     cmp     r0, #0                      @ null array object?
     beq     common_errNullObject        @ yes, bail
+// begin WITH_TAINT_TRACKING
+    bl		.LOP_AGET_OBJECT_taint_prop_1
+// end WITH_TAINT_TRACKING
     ldr     r3, [r0, #offArrayObject_length]    @ r3<- arrayObj->length
     add     r0, r0, r1, lsl #2     @ r0<- arrayObj + index*width
     cmp     r1, r3                      @ compare unsigned index, length
-    bcs     common_errArrayIndex        @ index >= length, bail
-    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
+// begin WITH_TAINT_TRACKING
+//    bcs     common_errArrayIndex        @ index >= length, bail	// in subroutine
+//    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST // in subroutine
+    bl		.LOP_AGET_OBJECT_taint_prop_2
+// end WITH_TAINT_TRACKING
     ldr   r2, [r0, #offArrayObject_contents]  @ r2<- vBB[vCC]
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
     SET_VREG(r2, r9)                    @ vAA<- r2
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_AGET_BOOLEAN: /* 0x47 */
-/* File: armv5te/OP_AGET_BOOLEAN.S */
-/* File: armv5te/OP_AGET.S */
+/* File: armv5te_taint/OP_AGET_BOOLEAN.S */
+/* File: armv5te_taint/OP_AGET.S */
     /*
      * Array get, 32 bits or less.  vAA <- vBB[vCC].
      *
@@ -1983,22 +2200,29 @@ dalvik_inst:
     GET_VREG(r1, r3)                    @ r1<- vCC (requested index)
     cmp     r0, #0                      @ null array object?
     beq     common_errNullObject        @ yes, bail
+// begin WITH_TAINT_TRACKING
+    bl		.LOP_AGET_BOOLEAN_taint_prop_1
+// end WITH_TAINT_TRACKING
     ldr     r3, [r0, #offArrayObject_length]    @ r3<- arrayObj->length
     add     r0, r0, r1, lsl #0     @ r0<- arrayObj + index*width
     cmp     r1, r3                      @ compare unsigned index, length
-    bcs     common_errArrayIndex        @ index >= length, bail
-    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
+// begin WITH_TAINT_TRACKING
+//    bcs     common_errArrayIndex        @ index >= length, bail	// in subroutine
+//    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST // in subroutine
+    bl		.LOP_AGET_BOOLEAN_taint_prop_2
+// end WITH_TAINT_TRACKING
     ldrb   r2, [r0, #offArrayObject_contents]  @ r2<- vBB[vCC]
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
     SET_VREG(r2, r9)                    @ vAA<- r2
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_AGET_BYTE: /* 0x48 */
-/* File: armv5te/OP_AGET_BYTE.S */
-/* File: armv5te/OP_AGET.S */
+/* File: armv5te_taint/OP_AGET_BYTE.S */
+/* File: armv5te_taint/OP_AGET.S */
     /*
      * Array get, 32 bits or less.  vAA <- vBB[vCC].
      *
@@ -2015,22 +2239,29 @@ dalvik_inst:
     GET_VREG(r1, r3)                    @ r1<- vCC (requested index)
     cmp     r0, #0                      @ null array object?
     beq     common_errNullObject        @ yes, bail
+// begin WITH_TAINT_TRACKING
+    bl		.LOP_AGET_BYTE_taint_prop_1
+// end WITH_TAINT_TRACKING
     ldr     r3, [r0, #offArrayObject_length]    @ r3<- arrayObj->length
     add     r0, r0, r1, lsl #0     @ r0<- arrayObj + index*width
     cmp     r1, r3                      @ compare unsigned index, length
-    bcs     common_errArrayIndex        @ index >= length, bail
-    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
+// begin WITH_TAINT_TRACKING
+//    bcs     common_errArrayIndex        @ index >= length, bail	// in subroutine
+//    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST // in subroutine
+    bl		.LOP_AGET_BYTE_taint_prop_2
+// end WITH_TAINT_TRACKING
     ldrsb   r2, [r0, #offArrayObject_contents]  @ r2<- vBB[vCC]
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
     SET_VREG(r2, r9)                    @ vAA<- r2
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_AGET_CHAR: /* 0x49 */
-/* File: armv5te/OP_AGET_CHAR.S */
-/* File: armv5te/OP_AGET.S */
+/* File: armv5te_taint/OP_AGET_CHAR.S */
+/* File: armv5te_taint/OP_AGET.S */
     /*
      * Array get, 32 bits or less.  vAA <- vBB[vCC].
      *
@@ -2047,22 +2278,29 @@ dalvik_inst:
     GET_VREG(r1, r3)                    @ r1<- vCC (requested index)
     cmp     r0, #0                      @ null array object?
     beq     common_errNullObject        @ yes, bail
+// begin WITH_TAINT_TRACKING
+    bl		.LOP_AGET_CHAR_taint_prop_1
+// end WITH_TAINT_TRACKING
     ldr     r3, [r0, #offArrayObject_length]    @ r3<- arrayObj->length
     add     r0, r0, r1, lsl #1     @ r0<- arrayObj + index*width
     cmp     r1, r3                      @ compare unsigned index, length
-    bcs     common_errArrayIndex        @ index >= length, bail
-    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
+// begin WITH_TAINT_TRACKING
+//    bcs     common_errArrayIndex        @ index >= length, bail	// in subroutine
+//    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST // in subroutine
+    bl		.LOP_AGET_CHAR_taint_prop_2
+// end WITH_TAINT_TRACKING
     ldrh   r2, [r0, #offArrayObject_contents]  @ r2<- vBB[vCC]
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
     SET_VREG(r2, r9)                    @ vAA<- r2
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_AGET_SHORT: /* 0x4a */
-/* File: armv5te/OP_AGET_SHORT.S */
-/* File: armv5te/OP_AGET.S */
+/* File: armv5te_taint/OP_AGET_SHORT.S */
+/* File: armv5te_taint/OP_AGET.S */
     /*
      * Array get, 32 bits or less.  vAA <- vBB[vCC].
      *
@@ -2079,21 +2317,28 @@ dalvik_inst:
     GET_VREG(r1, r3)                    @ r1<- vCC (requested index)
     cmp     r0, #0                      @ null array object?
     beq     common_errNullObject        @ yes, bail
+// begin WITH_TAINT_TRACKING
+    bl		.LOP_AGET_SHORT_taint_prop_1
+// end WITH_TAINT_TRACKING
     ldr     r3, [r0, #offArrayObject_length]    @ r3<- arrayObj->length
     add     r0, r0, r1, lsl #1     @ r0<- arrayObj + index*width
     cmp     r1, r3                      @ compare unsigned index, length
-    bcs     common_errArrayIndex        @ index >= length, bail
-    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
+// begin WITH_TAINT_TRACKING
+//    bcs     common_errArrayIndex        @ index >= length, bail	// in subroutine
+//    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST // in subroutine
+    bl		.LOP_AGET_SHORT_taint_prop_2
+// end WITH_TAINT_TRACKING
     ldrsh   r2, [r0, #offArrayObject_contents]  @ r2<- vBB[vCC]
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
     SET_VREG(r2, r9)                    @ vAA<- r2
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_APUT: /* 0x4b */
-/* File: armv5te/OP_APUT.S */
+/* File: armv5te_taint/OP_APUT.S */
     /*
      * Array put, 32 bits or less.  vBB[vCC] <- vAA.
      *
@@ -2114,16 +2359,19 @@ dalvik_inst:
     add     r0, r0, r1, lsl #2     @ r0<- arrayObj + index*width
     cmp     r1, r3                      @ compare unsigned index, length
     bcs     common_errArrayIndex        @ index >= length, bail
-    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
+// begin WITH_TAINT_TRACKING
+    bl	.LOP_APUT_taint_prop
+// end WITH_TAINT_TRACKING
     GET_VREG(r2, r9)                    @ r2<- vAA
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
     str  r2, [r0, #offArrayObject_contents]  @ vBB[vCC]<- r2
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_APUT_WIDE: /* 0x4c */
-/* File: armv5te/OP_APUT_WIDE.S */
+/* File: armv5te_taint/OP_APUT_WIDE.S */
     /*
      * Array put, 64 bits.  vBB[vCC] <- vAA.
      *
@@ -2139,9 +2387,14 @@ dalvik_inst:
     cmp     r0, #0                      @ null array object?
     beq     common_errNullObject        @ yes, bail
     ldr     r3, [r0, #offArrayObject_length]    @ r3<- arrayObj->length
+// begin WITH_TAINT_TRACKING
+    mov     r10, r0
+// end WITH_TAINT_TRACKING
     add     r0, r0, r1, lsl #3          @ r0<- arrayObj + index*width
     cmp     r1, r3                      @ compare unsigned index, length
-    add     r9, rFP, r9, lsl #2         @ r9<- &fp[AA]
+// begin WITH_TAINT_TRACKING
+    add     r9, rFP, r9, lsl #3         @ r9<- &fp[AA]
+// end WITH_TAINT_TRACKING
     bcc     .LOP_APUT_WIDE_finish          @ okay, continue below
     b       common_errArrayIndex        @ index >= length, bail
     @ May want to swap the order of these two branches depending on how the
@@ -2151,7 +2404,7 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_APUT_OBJECT: /* 0x4d */
-/* File: armv5te/OP_APUT_OBJECT.S */
+/* File: armv5te_taint/OP_APUT_OBJECT.S */
     /*
      * Store an object into an array.  vBB[vCC] <- vAA.
      */
@@ -2162,9 +2415,15 @@ dalvik_inst:
     mov     r3, r0, lsr #8              @ r3<- CC
     GET_VREG(rINST, r2)                 @ rINST<- vBB (array object)
     GET_VREG(r1, r3)                    @ r1<- vCC (requested index)
+// begin WITH_TAINT_TRACKING
+    bl      .LOP_APUT_OBJECT_taint_prop_1
+// end WITH_TAINT_TRACKING
     cmp     rINST, #0                   @ null array object?
     GET_VREG(r9, r9)                    @ r9<- vAA
     beq     common_errNullObject        @ yes, bail
+// begin WITH_TAINT_TRACKING
+    bl      .LOP_APUT_OBJECT_taint_prop_2
+// end WITH_TAINT_TRACKING
     ldr     r3, [rINST, #offArrayObject_length]   @ r3<- arrayObj->length
     add     r10, rINST, r1, lsl #2      @ r10<- arrayObj + index*width
     cmp     r1, r3                      @ compare unsigned index, length
@@ -2175,8 +2434,8 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_APUT_BOOLEAN: /* 0x4e */
-/* File: armv5te/OP_APUT_BOOLEAN.S */
-/* File: armv5te/OP_APUT.S */
+/* File: armv5te_taint/OP_APUT_BOOLEAN.S */
+/* File: armv5te_taint/OP_APUT.S */
     /*
      * Array put, 32 bits or less.  vBB[vCC] <- vAA.
      *
@@ -2197,18 +2456,21 @@ dalvik_inst:
     add     r0, r0, r1, lsl #0     @ r0<- arrayObj + index*width
     cmp     r1, r3                      @ compare unsigned index, length
     bcs     common_errArrayIndex        @ index >= length, bail
-    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
+// begin WITH_TAINT_TRACKING
+    bl	.LOP_APUT_BOOLEAN_taint_prop
+// end WITH_TAINT_TRACKING
     GET_VREG(r2, r9)                    @ r2<- vAA
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
     strb  r2, [r0, #offArrayObject_contents]  @ vBB[vCC]<- r2
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_APUT_BYTE: /* 0x4f */
-/* File: armv5te/OP_APUT_BYTE.S */
-/* File: armv5te/OP_APUT.S */
+/* File: armv5te_taint/OP_APUT_BYTE.S */
+/* File: armv5te_taint/OP_APUT.S */
     /*
      * Array put, 32 bits or less.  vBB[vCC] <- vAA.
      *
@@ -2229,18 +2491,21 @@ dalvik_inst:
     add     r0, r0, r1, lsl #0     @ r0<- arrayObj + index*width
     cmp     r1, r3                      @ compare unsigned index, length
     bcs     common_errArrayIndex        @ index >= length, bail
-    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
+// begin WITH_TAINT_TRACKING
+    bl	.LOP_APUT_BYTE_taint_prop
+// end WITH_TAINT_TRACKING
     GET_VREG(r2, r9)                    @ r2<- vAA
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
     strb  r2, [r0, #offArrayObject_contents]  @ vBB[vCC]<- r2
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_APUT_CHAR: /* 0x50 */
-/* File: armv5te/OP_APUT_CHAR.S */
-/* File: armv5te/OP_APUT.S */
+/* File: armv5te_taint/OP_APUT_CHAR.S */
+/* File: armv5te_taint/OP_APUT.S */
     /*
      * Array put, 32 bits or less.  vBB[vCC] <- vAA.
      *
@@ -2261,18 +2526,21 @@ dalvik_inst:
     add     r0, r0, r1, lsl #1     @ r0<- arrayObj + index*width
     cmp     r1, r3                      @ compare unsigned index, length
     bcs     common_errArrayIndex        @ index >= length, bail
-    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
+// begin WITH_TAINT_TRACKING
+    bl	.LOP_APUT_CHAR_taint_prop
+// end WITH_TAINT_TRACKING
     GET_VREG(r2, r9)                    @ r2<- vAA
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
     strh  r2, [r0, #offArrayObject_contents]  @ vBB[vCC]<- r2
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_APUT_SHORT: /* 0x51 */
-/* File: armv5te/OP_APUT_SHORT.S */
-/* File: armv5te/OP_APUT.S */
+/* File: armv5te_taint/OP_APUT_SHORT.S */
+/* File: armv5te_taint/OP_APUT.S */
     /*
      * Array put, 32 bits or less.  vBB[vCC] <- vAA.
      *
@@ -2293,17 +2561,20 @@ dalvik_inst:
     add     r0, r0, r1, lsl #1     @ r0<- arrayObj + index*width
     cmp     r1, r3                      @ compare unsigned index, length
     bcs     common_errArrayIndex        @ index >= length, bail
-    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
+// begin WITH_TAINT_TRACKING
+    bl	.LOP_APUT_SHORT_taint_prop
+// end WITH_TAINT_TRACKING
     GET_VREG(r2, r9)                    @ r2<- vAA
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
     strh  r2, [r0, #offArrayObject_contents]  @ vBB[vCC]<- r2
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_IGET: /* 0x52 */
-/* File: armv6t2/OP_IGET.S */
+/* File: armv6t2_taint/OP_IGET.S */
     /*
      * General 32-bit instance field get.
      *
@@ -2314,8 +2585,9 @@ dalvik_inst:
     ldr     r3, [rSELF, #offThread_methodClassDex]    @ r3<- DvmDex
     FETCH(r1, 1)                        @ r1<- field ref CCCC
     ldr     r2, [r3, #offDvmDex_pResFields] @ r2<- pDvmDex->pResFields
-    GET_VREG(r9, r0)                    @ r9<- fp[B], the object pointer
-    ldr     r0, [r2, r1, lsl #2]        @ r0<- resolved InstField ptr
+// begin WITH_TAINT_TRACKING
+    bl      .LOP_IGET_taint_prop
+// end WITH_TAINT_TRACKING
     cmp     r0, #0                      @ is resolved entry null?
     bne     .LOP_IGET_finish          @ no, already resolved
 8:  ldr     r2, [rSELF, #offThread_method]    @ r2<- current method
@@ -2329,7 +2601,7 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_IGET_WIDE: /* 0x53 */
-/* File: armv6t2/OP_IGET_WIDE.S */
+/* File: armv6t2_taint/OP_IGET_WIDE.S */
     /*
      * Wide 32-bit instance field get.
      */
@@ -2338,8 +2610,9 @@ dalvik_inst:
     ldr     r3, [rSELF, #offThread_methodClassDex]    @ r3<- DvmDex
     FETCH(r1, 1)                        @ r1<- field ref CCCC
     ldr     r2, [r3, #offDvmDex_pResFields] @ r2<- pResFields
-    GET_VREG(r9, r0)                    @ r9<- fp[B], the object pointer
-    ldr     r0, [r2, r1, lsl #2]        @ r0<- resolved InstField ptr
+// begin WITH_TAINT_TRACKING
+    bl      .LOP_IGET_WIDE_taint_prop
+// end WITH_TAINT_TRACKING
     cmp     r0, #0                      @ is resolved entry null?
     bne     .LOP_IGET_WIDE_finish          @ no, already resolved
 8:  ldr     r2, [rSELF, #offThread_method] @ r2<- current method
@@ -2353,8 +2626,10 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_IGET_OBJECT: /* 0x54 */
-/* File: armv5te/OP_IGET_OBJECT.S */
-/* File: armv5te/OP_IGET.S */
+/* File: armv5te_taint/OP_IGET_OBJECT.S */
+/* File: armv5te_taint/OP_IGET.S */
+// begin WITH_TAINT_TRACKING
+// end WITH_TAINT_TRACKING
     /*
      * General 32-bit instance field get.
      *
@@ -2365,8 +2640,9 @@ dalvik_inst:
     ldr     r3, [rSELF, #offThread_methodClassDex]    @ r3<- DvmDex
     FETCH(r1, 1)                        @ r1<- field ref CCCC
     ldr     r2, [r3, #offDvmDex_pResFields] @ r2<- pDvmDex->pResFields
-    GET_VREG(r9, r0)                    @ r9<- fp[B], the object pointer
-    ldr     r0, [r2, r1, lsl #2]        @ r0<- resolved InstField ptr
+// begin WITH_TAINT_TRACKING
+    bl      .LOP_IGET_OBJECT_taint_prop
+// end WITH_TAINT_TRACKING
     cmp     r0, #0                      @ is resolved entry null?
     bne     .LOP_IGET_OBJECT_finish          @ no, already resolved
 8:  ldr     r2, [rSELF, #offThread_method]    @ r2<- current method
@@ -2381,9 +2657,11 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_IGET_BOOLEAN: /* 0x55 */
-/* File: armv5te/OP_IGET_BOOLEAN.S */
-@include "armv5te/OP_IGET.S" { "load":"ldrb", "sqnum":"1" }
-/* File: armv5te/OP_IGET.S */
+/* File: armv5te_taint/OP_IGET_BOOLEAN.S */
+@include "armv5te_taint/OP_IGET.S" { "load":"ldrb", "sqnum":"1" }
+/* File: armv5te_taint/OP_IGET.S */
+// begin WITH_TAINT_TRACKING
+// end WITH_TAINT_TRACKING
     /*
      * General 32-bit instance field get.
      *
@@ -2394,8 +2672,9 @@ dalvik_inst:
     ldr     r3, [rSELF, #offThread_methodClassDex]    @ r3<- DvmDex
     FETCH(r1, 1)                        @ r1<- field ref CCCC
     ldr     r2, [r3, #offDvmDex_pResFields] @ r2<- pDvmDex->pResFields
-    GET_VREG(r9, r0)                    @ r9<- fp[B], the object pointer
-    ldr     r0, [r2, r1, lsl #2]        @ r0<- resolved InstField ptr
+// begin WITH_TAINT_TRACKING
+    bl      .LOP_IGET_BOOLEAN_taint_prop
+// end WITH_TAINT_TRACKING
     cmp     r0, #0                      @ is resolved entry null?
     bne     .LOP_IGET_BOOLEAN_finish          @ no, already resolved
 8:  ldr     r2, [rSELF, #offThread_method]    @ r2<- current method
@@ -2410,9 +2689,11 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_IGET_BYTE: /* 0x56 */
-/* File: armv5te/OP_IGET_BYTE.S */
-@include "armv5te/OP_IGET.S" { "load":"ldrsb", "sqnum":"2" }
-/* File: armv5te/OP_IGET.S */
+/* File: armv5te_taint/OP_IGET_BYTE.S */
+@include "armv5te_taint/OP_IGET.S" { "load":"ldrsb", "sqnum":"2" }
+/* File: armv5te_taint/OP_IGET.S */
+// begin WITH_TAINT_TRACKING
+// end WITH_TAINT_TRACKING
     /*
      * General 32-bit instance field get.
      *
@@ -2423,8 +2704,9 @@ dalvik_inst:
     ldr     r3, [rSELF, #offThread_methodClassDex]    @ r3<- DvmDex
     FETCH(r1, 1)                        @ r1<- field ref CCCC
     ldr     r2, [r3, #offDvmDex_pResFields] @ r2<- pDvmDex->pResFields
-    GET_VREG(r9, r0)                    @ r9<- fp[B], the object pointer
-    ldr     r0, [r2, r1, lsl #2]        @ r0<- resolved InstField ptr
+// begin WITH_TAINT_TRACKING
+    bl      .LOP_IGET_BYTE_taint_prop
+// end WITH_TAINT_TRACKING
     cmp     r0, #0                      @ is resolved entry null?
     bne     .LOP_IGET_BYTE_finish          @ no, already resolved
 8:  ldr     r2, [rSELF, #offThread_method]    @ r2<- current method
@@ -2439,9 +2721,11 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_IGET_CHAR: /* 0x57 */
-/* File: armv5te/OP_IGET_CHAR.S */
-@include "armv5te/OP_IGET.S" { "load":"ldrh", "sqnum":"3" }
-/* File: armv5te/OP_IGET.S */
+/* File: armv5te_taint/OP_IGET_CHAR.S */
+@include "armv5te_taint/OP_IGET.S" { "load":"ldrh", "sqnum":"3" }
+/* File: armv5te_taint/OP_IGET.S */
+// begin WITH_TAINT_TRACKING
+// end WITH_TAINT_TRACKING
     /*
      * General 32-bit instance field get.
      *
@@ -2452,8 +2736,9 @@ dalvik_inst:
     ldr     r3, [rSELF, #offThread_methodClassDex]    @ r3<- DvmDex
     FETCH(r1, 1)                        @ r1<- field ref CCCC
     ldr     r2, [r3, #offDvmDex_pResFields] @ r2<- pDvmDex->pResFields
-    GET_VREG(r9, r0)                    @ r9<- fp[B], the object pointer
-    ldr     r0, [r2, r1, lsl #2]        @ r0<- resolved InstField ptr
+// begin WITH_TAINT_TRACKING
+    bl      .LOP_IGET_CHAR_taint_prop
+// end WITH_TAINT_TRACKING
     cmp     r0, #0                      @ is resolved entry null?
     bne     .LOP_IGET_CHAR_finish          @ no, already resolved
 8:  ldr     r2, [rSELF, #offThread_method]    @ r2<- current method
@@ -2465,12 +2750,15 @@ dalvik_inst:
     b       common_exceptionThrown
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_IGET_SHORT: /* 0x58 */
-/* File: armv5te/OP_IGET_SHORT.S */
-@include "armv5te/OP_IGET.S" { "load":"ldrsh", "sqnum":"4" }
-/* File: armv5te/OP_IGET.S */
+/* File: armv5te_taint/OP_IGET_SHORT.S */
+@include "armv5te_taint/OP_IGET.S" { "load":"ldrsh", "sqnum":"4" }
+/* File: armv5te_taint/OP_IGET.S */
+// begin WITH_TAINT_TRACKING
+// end WITH_TAINT_TRACKING
     /*
      * General 32-bit instance field get.
      *
@@ -2481,8 +2769,9 @@ dalvik_inst:
     ldr     r3, [rSELF, #offThread_methodClassDex]    @ r3<- DvmDex
     FETCH(r1, 1)                        @ r1<- field ref CCCC
     ldr     r2, [r3, #offDvmDex_pResFields] @ r2<- pDvmDex->pResFields
-    GET_VREG(r9, r0)                    @ r9<- fp[B], the object pointer
-    ldr     r0, [r2, r1, lsl #2]        @ r0<- resolved InstField ptr
+// begin WITH_TAINT_TRACKING
+    bl      .LOP_IGET_SHORT_taint_prop
+// end WITH_TAINT_TRACKING
     cmp     r0, #0                      @ is resolved entry null?
     bne     .LOP_IGET_SHORT_finish          @ no, already resolved
 8:  ldr     r2, [rSELF, #offThread_method]    @ r2<- current method
@@ -2497,7 +2786,7 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_IPUT: /* 0x59 */
-/* File: armv6t2/OP_IPUT.S */
+/* File: armv6t2_taint/OP_IPUT.S */
     /*
      * General 32-bit instance field put.
      *
@@ -2523,7 +2812,7 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_IPUT_WIDE: /* 0x5a */
-/* File: armv6t2/OP_IPUT_WIDE.S */
+/* File: armv6t2_taint/OP_IPUT_WIDE.S */
     /* iput-wide vA, vB, field@CCCC */
     mov     r0, rINST, lsr #12          @ r0<- B
     ldr     r3, [rSELF, #offThread_methodClassDex]    @ r3<- DvmDex
@@ -2544,7 +2833,9 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_IPUT_OBJECT: /* 0x5b */
-/* File: armv5te/OP_IPUT_OBJECT.S */
+/* File: armv5te_taint/OP_IPUT_OBJECT.S */
+// begin WITH_TAINT_TRACKING
+// end WITH_TAINT_TRACKING
     /*
      * 32-bit instance field put.
      *
@@ -2570,9 +2861,11 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_IPUT_BOOLEAN: /* 0x5c */
-/* File: armv5te/OP_IPUT_BOOLEAN.S */
-@include "armv5te/OP_IPUT.S" { "store":"strb", "sqnum":"1" }
-/* File: armv5te/OP_IPUT.S */
+/* File: armv5te_taint/OP_IPUT_BOOLEAN.S */
+@include "armv5te_taint/OP_IPUT.S" { "store":"strb", "sqnum":"1" }
+/* File: armv5te_taint/OP_IPUT.S */
+// begin WITH_TAINT_TRACKING
+// end WITH_TAINT_TRACKING
     /*
      * General 32-bit instance field put.
      *
@@ -2599,9 +2892,11 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_IPUT_BYTE: /* 0x5d */
-/* File: armv5te/OP_IPUT_BYTE.S */
-@include "armv5te/OP_IPUT.S" { "store":"strb", "sqnum":"2" }
-/* File: armv5te/OP_IPUT.S */
+/* File: armv5te_taint/OP_IPUT_BYTE.S */
+@include "armv5te_taint/OP_IPUT.S" { "store":"strb", "sqnum":"2" }
+/* File: armv5te_taint/OP_IPUT.S */
+// begin WITH_TAINT_TRACKING
+// end WITH_TAINT_TRACKING
     /*
      * General 32-bit instance field put.
      *
@@ -2628,9 +2923,11 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_IPUT_CHAR: /* 0x5e */
-/* File: armv5te/OP_IPUT_CHAR.S */
-@include "armv5te/OP_IPUT.S" { "store":"strh", "sqnum":"3" }
-/* File: armv5te/OP_IPUT.S */
+/* File: armv5te_taint/OP_IPUT_CHAR.S */
+@include "armv5te_taint/OP_IPUT.S" { "store":"strh", "sqnum":"3" }
+/* File: armv5te_taint/OP_IPUT.S */
+// begin WITH_TAINT_TRACKING
+// end WITH_TAINT_TRACKING
     /*
      * General 32-bit instance field put.
      *
@@ -2657,9 +2954,11 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_IPUT_SHORT: /* 0x5f */
-/* File: armv5te/OP_IPUT_SHORT.S */
-@include "armv5te/OP_IPUT.S" { "store":"strh", "sqnum":"4" }
-/* File: armv5te/OP_IPUT.S */
+/* File: armv5te_taint/OP_IPUT_SHORT.S */
+@include "armv5te_taint/OP_IPUT.S" { "store":"strh", "sqnum":"4" }
+/* File: armv5te_taint/OP_IPUT.S */
+// begin WITH_TAINT_TRACKING
+// end WITH_TAINT_TRACKING
     /*
      * General 32-bit instance field put.
      *
@@ -2686,7 +2985,9 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_SGET: /* 0x60 */
-/* File: armv5te/OP_SGET.S */
+/* File: armv5te_taint/OP_SGET.S */
+// begin WITH_TAINT_TRACKING
+// end WITH_TAINT_TRACKING
     /*
      * General 32-bit SGET handler.
      *
@@ -2700,18 +3001,18 @@ dalvik_inst:
     cmp     r0, #0                      @ is resolved entry null?
     beq     .LOP_SGET_resolve         @ yes, do resolve
 .LOP_SGET_finish: @ field ptr in r0
-    ldr     r1, [r0, #offStaticField_value] @ r1<- field value
-    @ no-op                             @ acquiring load
-    mov     r2, rINST, lsr #8           @ r2<- AA
+// begin WITH_TAINT_TRACKING
+    bl		.LOP_SGET_taint_prop
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
-    SET_VREG(r1, r2)                    @ fp[AA]<- r1
+    SET_VREG(r0, r2)                    @ fp[AA]<- r0
+// end WITH_TAINT_TRACKING
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
 /* ------------------------------ */
     .balign 64
 .L_OP_SGET_WIDE: /* 0x61 */
-/* File: armv5te/OP_SGET_WIDE.S */
+/* File: armv5te_taint/OP_SGET_WIDE.S */
     /*
      * 64-bit SGET handler.
      */
@@ -2722,25 +3023,16 @@ dalvik_inst:
     ldr     r0, [r10, r1, lsl #2]       @ r0<- resolved StaticField ptr
     cmp     r0, #0                      @ is resolved entry null?
     beq     .LOP_SGET_WIDE_resolve         @ yes, do resolve
-.LOP_SGET_WIDE_finish:
-    mov     r9, rINST, lsr #8           @ r9<- AA
-    .if 0
-    add     r0, r0, #offStaticField_value @ r0<- pointer to data
-    bl      dvmQuasiAtomicRead64        @ r0/r1<- contents of field
-    .else
-    ldrd    r0, [r0, #offStaticField_value] @ r0/r1<- field value (aligned)
-    .endif
-    add     r9, rFP, r9, lsl #2         @ r9<- &fp[AA]
-    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
-    stmia   r9, {r0-r1}                 @ vAA/vAA+1<- r0/r1
-    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    GOTO_OPCODE(ip)                     @ jump to next instruction
+    b		.LOP_SGET_WIDE_finish
+
 
 /* ------------------------------ */
     .balign 64
 .L_OP_SGET_OBJECT: /* 0x62 */
-/* File: armv5te/OP_SGET_OBJECT.S */
-/* File: armv5te/OP_SGET.S */
+/* File: armv5te_taint/OP_SGET_OBJECT.S */
+/* File: armv5te_taint/OP_SGET.S */
+// begin WITH_TAINT_TRACKING
+// end WITH_TAINT_TRACKING
     /*
      * General 32-bit SGET handler.
      *
@@ -2754,11 +3046,11 @@ dalvik_inst:
     cmp     r0, #0                      @ is resolved entry null?
     beq     .LOP_SGET_OBJECT_resolve         @ yes, do resolve
 .LOP_SGET_OBJECT_finish: @ field ptr in r0
-    ldr     r1, [r0, #offStaticField_value] @ r1<- field value
-    @ no-op                             @ acquiring load
-    mov     r2, rINST, lsr #8           @ r2<- AA
+// begin WITH_TAINT_TRACKING
+    bl		.LOP_SGET_OBJECT_taint_prop
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
-    SET_VREG(r1, r2)                    @ fp[AA]<- r1
+    SET_VREG(r0, r2)                    @ fp[AA]<- r0
+// end WITH_TAINT_TRACKING
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
@@ -2766,8 +3058,10 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_SGET_BOOLEAN: /* 0x63 */
-/* File: armv5te/OP_SGET_BOOLEAN.S */
-/* File: armv5te/OP_SGET.S */
+/* File: armv5te_taint/OP_SGET_BOOLEAN.S */
+/* File: armv5te_taint/OP_SGET.S */
+// begin WITH_TAINT_TRACKING
+// end WITH_TAINT_TRACKING
     /*
      * General 32-bit SGET handler.
      *
@@ -2781,11 +3075,11 @@ dalvik_inst:
     cmp     r0, #0                      @ is resolved entry null?
     beq     .LOP_SGET_BOOLEAN_resolve         @ yes, do resolve
 .LOP_SGET_BOOLEAN_finish: @ field ptr in r0
-    ldr     r1, [r0, #offStaticField_value] @ r1<- field value
-    @ no-op                             @ acquiring load
-    mov     r2, rINST, lsr #8           @ r2<- AA
+// begin WITH_TAINT_TRACKING
+    bl		.LOP_SGET_BOOLEAN_taint_prop
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
-    SET_VREG(r1, r2)                    @ fp[AA]<- r1
+    SET_VREG(r0, r2)                    @ fp[AA]<- r0
+// end WITH_TAINT_TRACKING
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
@@ -2793,8 +3087,10 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_SGET_BYTE: /* 0x64 */
-/* File: armv5te/OP_SGET_BYTE.S */
-/* File: armv5te/OP_SGET.S */
+/* File: armv5te_taint/OP_SGET_BYTE.S */
+/* File: armv5te_taint/OP_SGET.S */
+// begin WITH_TAINT_TRACKING
+// end WITH_TAINT_TRACKING
     /*
      * General 32-bit SGET handler.
      *
@@ -2808,11 +3104,11 @@ dalvik_inst:
     cmp     r0, #0                      @ is resolved entry null?
     beq     .LOP_SGET_BYTE_resolve         @ yes, do resolve
 .LOP_SGET_BYTE_finish: @ field ptr in r0
-    ldr     r1, [r0, #offStaticField_value] @ r1<- field value
-    @ no-op                             @ acquiring load
-    mov     r2, rINST, lsr #8           @ r2<- AA
+// begin WITH_TAINT_TRACKING
+    bl		.LOP_SGET_BYTE_taint_prop
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
-    SET_VREG(r1, r2)                    @ fp[AA]<- r1
+    SET_VREG(r0, r2)                    @ fp[AA]<- r0
+// end WITH_TAINT_TRACKING
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
@@ -2820,8 +3116,10 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_SGET_CHAR: /* 0x65 */
-/* File: armv5te/OP_SGET_CHAR.S */
-/* File: armv5te/OP_SGET.S */
+/* File: armv5te_taint/OP_SGET_CHAR.S */
+/* File: armv5te_taint/OP_SGET.S */
+// begin WITH_TAINT_TRACKING
+// end WITH_TAINT_TRACKING
     /*
      * General 32-bit SGET handler.
      *
@@ -2835,11 +3133,11 @@ dalvik_inst:
     cmp     r0, #0                      @ is resolved entry null?
     beq     .LOP_SGET_CHAR_resolve         @ yes, do resolve
 .LOP_SGET_CHAR_finish: @ field ptr in r0
-    ldr     r1, [r0, #offStaticField_value] @ r1<- field value
-    @ no-op                             @ acquiring load
-    mov     r2, rINST, lsr #8           @ r2<- AA
+// begin WITH_TAINT_TRACKING
+    bl		.LOP_SGET_CHAR_taint_prop
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
-    SET_VREG(r1, r2)                    @ fp[AA]<- r1
+    SET_VREG(r0, r2)                    @ fp[AA]<- r0
+// end WITH_TAINT_TRACKING
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
@@ -2847,8 +3145,10 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_SGET_SHORT: /* 0x66 */
-/* File: armv5te/OP_SGET_SHORT.S */
-/* File: armv5te/OP_SGET.S */
+/* File: armv5te_taint/OP_SGET_SHORT.S */
+/* File: armv5te_taint/OP_SGET.S */
+// begin WITH_TAINT_TRACKING
+// end WITH_TAINT_TRACKING
     /*
      * General 32-bit SGET handler.
      *
@@ -2862,11 +3162,11 @@ dalvik_inst:
     cmp     r0, #0                      @ is resolved entry null?
     beq     .LOP_SGET_SHORT_resolve         @ yes, do resolve
 .LOP_SGET_SHORT_finish: @ field ptr in r0
-    ldr     r1, [r0, #offStaticField_value] @ r1<- field value
-    @ no-op                             @ acquiring load
-    mov     r2, rINST, lsr #8           @ r2<- AA
+// begin WITH_TAINT_TRACKING
+    bl		.LOP_SGET_SHORT_taint_prop
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
-    SET_VREG(r1, r2)                    @ fp[AA]<- r1
+    SET_VREG(r0, r2)                    @ fp[AA]<- r0
+// end WITH_TAINT_TRACKING
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
@@ -2874,7 +3174,9 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_SPUT: /* 0x67 */
-/* File: armv5te/OP_SPUT.S */
+/* File: armv5te_taint/OP_SPUT.S */
+// begin WITH_TAINT_TRACKING
+// end WITH_TAINT_TRACKING
     /*
      * General 32-bit SPUT handler.
      *
@@ -2892,15 +3194,15 @@ dalvik_inst:
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
     GET_VREG(r1, r2)                    @ r1<- fp[AA]
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    @ no-op                        @ releasing store
-    str     r1, [r0, #offStaticField_value] @ field<- vAA
-    @ no-op 
+// begin WITH_TAINT_TRACKING
+    bl      .LOP_SPUT_taint_prop
+// end WITH_TAINT_TRACKING
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
 /* ------------------------------ */
     .balign 64
 .L_OP_SPUT_WIDE: /* 0x68 */
-/* File: armv5te/OP_SPUT_WIDE.S */
+/* File: armv5te_taint/OP_SPUT_WIDE.S */
     /*
      * 64-bit SPUT handler.
      */
@@ -2910,13 +3212,20 @@ dalvik_inst:
     ldr     r10, [r0, #offDvmDex_pResFields] @ r10<- dvmDex->pResFields
     mov     r9, rINST, lsr #8           @ r9<- AA
     ldr     r2, [r10, r1, lsl #2]        @ r2<- resolved StaticField ptr
-    add     r9, rFP, r9, lsl #2         @ r9<- &fp[AA]
+// begin WITH_TAINT_TRACKING
+    add     r9, rFP, r9, lsl #3         @ r9<- &fp[AA]
+// end WITH_TAINT_TRACKING
     cmp     r2, #0                      @ is resolved entry null?
     beq     .LOP_SPUT_WIDE_resolve         @ yes, do resolve
 .LOP_SPUT_WIDE_finish: @ field ptr in r2, AA in r9
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
-    ldmia   r9, {r0-r1}                 @ r0/r1<- vAA/vAA+1
+// begin WITH_TAINT_TRACKING
+    bl		.LOP_SPUT_WIDE_taint_prop
+// end WITH_TAINT_TRACKING
     GET_INST_OPCODE(r10)                @ extract opcode from rINST
+// begin WITH_TAINT_TRACKING
+    str	    r3, [r2, #offStaticField_taint]
+// end WITH_TAINT_TRACKING
     .if 0
     add     r2, r2, #offStaticField_value @ r2<- pointer to data
     bl      dvmQuasiAtomicSwap64Sync    @ stores r0/r1 into addr r2
@@ -2928,7 +3237,9 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_SPUT_OBJECT: /* 0x69 */
-/* File: armv5te/OP_SPUT_OBJECT.S */
+/* File: armv5te_taint/OP_SPUT_OBJECT.S */
+// begin WITH_TAINT_TRACKING
+// end WITH_TAINT_TRACKING
     /*
      * 32-bit SPUT handler for objects
      *
@@ -2945,7 +3256,12 @@ dalvik_inst:
     mov     r2, rINST, lsr #8           @ r2<- AA
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
     GET_VREG(r1, r2)                    @ r1<- fp[AA]
-    ldr     r2, [rSELF, #offThread_cardTable]  @ r2<- card table base
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r3)
+    GET_VREG_TAINT(r3, r2, r3)          @ r3<- taint
+//    ldr     r2, [rSELF, #offThread_cardTable]  @ r2<- card table base
+    ldr     r10, [rSELF, #offThread_cardTable]  @ r10<- card table base
+// end WITH_TAINT_TRACKING
     ldr     r9, [r0, #offField_clazz]   @ r9<- field->clazz
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
     @ no-op                         @ releasing store
@@ -2954,8 +3270,10 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_SPUT_BOOLEAN: /* 0x6a */
-/* File: armv5te/OP_SPUT_BOOLEAN.S */
-/* File: armv5te/OP_SPUT.S */
+/* File: armv5te_taint/OP_SPUT_BOOLEAN.S */
+/* File: armv5te_taint/OP_SPUT.S */
+// begin WITH_TAINT_TRACKING
+// end WITH_TAINT_TRACKING
     /*
      * General 32-bit SPUT handler.
      *
@@ -2973,17 +3291,19 @@ dalvik_inst:
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
     GET_VREG(r1, r2)                    @ r1<- fp[AA]
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    @ no-op                        @ releasing store
-    str     r1, [r0, #offStaticField_value] @ field<- vAA
-    @ no-op 
+// begin WITH_TAINT_TRACKING
+    bl      .LOP_SPUT_BOOLEAN_taint_prop
+// end WITH_TAINT_TRACKING
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
 
 /* ------------------------------ */
     .balign 64
 .L_OP_SPUT_BYTE: /* 0x6b */
-/* File: armv5te/OP_SPUT_BYTE.S */
-/* File: armv5te/OP_SPUT.S */
+/* File: armv5te_taint/OP_SPUT_BYTE.S */
+/* File: armv5te_taint/OP_SPUT.S */
+// begin WITH_TAINT_TRACKING
+// end WITH_TAINT_TRACKING
     /*
      * General 32-bit SPUT handler.
      *
@@ -3001,17 +3321,19 @@ dalvik_inst:
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
     GET_VREG(r1, r2)                    @ r1<- fp[AA]
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    @ no-op                        @ releasing store
-    str     r1, [r0, #offStaticField_value] @ field<- vAA
-    @ no-op 
+// begin WITH_TAINT_TRACKING
+    bl      .LOP_SPUT_BYTE_taint_prop
+// end WITH_TAINT_TRACKING
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
 
 /* ------------------------------ */
     .balign 64
 .L_OP_SPUT_CHAR: /* 0x6c */
-/* File: armv5te/OP_SPUT_CHAR.S */
-/* File: armv5te/OP_SPUT.S */
+/* File: armv5te_taint/OP_SPUT_CHAR.S */
+/* File: armv5te_taint/OP_SPUT.S */
+// begin WITH_TAINT_TRACKING
+// end WITH_TAINT_TRACKING
     /*
      * General 32-bit SPUT handler.
      *
@@ -3029,17 +3351,19 @@ dalvik_inst:
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
     GET_VREG(r1, r2)                    @ r1<- fp[AA]
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    @ no-op                        @ releasing store
-    str     r1, [r0, #offStaticField_value] @ field<- vAA
-    @ no-op 
+// begin WITH_TAINT_TRACKING
+    bl      .LOP_SPUT_CHAR_taint_prop
+// end WITH_TAINT_TRACKING
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
 
 /* ------------------------------ */
     .balign 64
 .L_OP_SPUT_SHORT: /* 0x6d */
-/* File: armv5te/OP_SPUT_SHORT.S */
-/* File: armv5te/OP_SPUT.S */
+/* File: armv5te_taint/OP_SPUT_SHORT.S */
+/* File: armv5te_taint/OP_SPUT.S */
+// begin WITH_TAINT_TRACKING
+// end WITH_TAINT_TRACKING
     /*
      * General 32-bit SPUT handler.
      *
@@ -3057,16 +3381,16 @@ dalvik_inst:
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
     GET_VREG(r1, r2)                    @ r1<- fp[AA]
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    @ no-op                        @ releasing store
-    str     r1, [r0, #offStaticField_value] @ field<- vAA
-    @ no-op 
+// begin WITH_TAINT_TRACKING
+    bl      .LOP_SPUT_SHORT_taint_prop
+// end WITH_TAINT_TRACKING
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
 
 /* ------------------------------ */
     .balign 64
 .L_OP_INVOKE_VIRTUAL: /* 0x6e */
-/* File: armv5te/OP_INVOKE_VIRTUAL.S */
+/* File: armv5te_taint/OP_INVOKE_VIRTUAL.S */
     /*
      * Handle a virtual method call.
      *
@@ -3096,7 +3420,7 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_INVOKE_SUPER: /* 0x6f */
-/* File: armv5te/OP_INVOKE_SUPER.S */
+/* File: armv5te_taint/OP_INVOKE_SUPER.S */
     /*
      * Handle a "super" method call.
      *
@@ -3125,7 +3449,7 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_INVOKE_DIRECT: /* 0x70 */
-/* File: armv5te/OP_INVOKE_DIRECT.S */
+/* File: armv5te_taint/OP_INVOKE_DIRECT.S */
     /*
      * Handle a direct method call.
      *
@@ -3158,7 +3482,7 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_INVOKE_STATIC: /* 0x71 */
-/* File: armv5te/OP_INVOKE_STATIC.S */
+/* File: armv5te_taint/OP_INVOKE_STATIC.S */
     /*
      * Handle a static method call.
      *
@@ -3182,7 +3506,7 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_INVOKE_INTERFACE: /* 0x72 */
-/* File: armv5te/OP_INVOKE_INTERFACE.S */
+/* File: armv5te_taint/OP_INVOKE_INTERFACE.S */
     /*
      * Handle an interface method call.
      *
@@ -3210,16 +3534,17 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_UNUSED_73: /* 0x73 */
-/* File: armv5te/OP_UNUSED_73.S */
-/* File: armv5te/unused.S */
+/* File: armv5te_taint/OP_UNUSED_73.S */
+/* File: armv5te_taint/unused.S */
     bl      common_abort
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_INVOKE_VIRTUAL_RANGE: /* 0x74 */
-/* File: armv5te/OP_INVOKE_VIRTUAL_RANGE.S */
-/* File: armv5te/OP_INVOKE_VIRTUAL.S */
+/* File: armv5te_taint/OP_INVOKE_VIRTUAL_RANGE.S */
+/* File: armv5te_taint/OP_INVOKE_VIRTUAL.S */
     /*
      * Handle a virtual method call.
      *
@@ -3250,8 +3575,8 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_INVOKE_SUPER_RANGE: /* 0x75 */
-/* File: armv5te/OP_INVOKE_SUPER_RANGE.S */
-/* File: armv5te/OP_INVOKE_SUPER.S */
+/* File: armv5te_taint/OP_INVOKE_SUPER_RANGE.S */
+/* File: armv5te_taint/OP_INVOKE_SUPER.S */
     /*
      * Handle a "super" method call.
      *
@@ -3281,8 +3606,8 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_INVOKE_DIRECT_RANGE: /* 0x76 */
-/* File: armv5te/OP_INVOKE_DIRECT_RANGE.S */
-/* File: armv5te/OP_INVOKE_DIRECT.S */
+/* File: armv5te_taint/OP_INVOKE_DIRECT_RANGE.S */
+/* File: armv5te_taint/OP_INVOKE_DIRECT.S */
     /*
      * Handle a direct method call.
      *
@@ -3316,8 +3641,8 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_INVOKE_STATIC_RANGE: /* 0x77 */
-/* File: armv5te/OP_INVOKE_STATIC_RANGE.S */
-/* File: armv5te/OP_INVOKE_STATIC.S */
+/* File: armv5te_taint/OP_INVOKE_STATIC_RANGE.S */
+/* File: armv5te_taint/OP_INVOKE_STATIC.S */
     /*
      * Handle a static method call.
      *
@@ -3342,8 +3667,8 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_INVOKE_INTERFACE_RANGE: /* 0x78 */
-/* File: armv5te/OP_INVOKE_INTERFACE_RANGE.S */
-/* File: armv5te/OP_INVOKE_INTERFACE.S */
+/* File: armv5te_taint/OP_INVOKE_INTERFACE_RANGE.S */
+/* File: armv5te_taint/OP_INVOKE_INTERFACE.S */
     /*
      * Handle an interface method call.
      *
@@ -3372,24 +3697,26 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_UNUSED_79: /* 0x79 */
-/* File: armv5te/OP_UNUSED_79.S */
-/* File: armv5te/unused.S */
+/* File: armv5te_taint/OP_UNUSED_79.S */
+/* File: armv5te_taint/unused.S */
     bl      common_abort
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_UNUSED_7A: /* 0x7a */
-/* File: armv5te/OP_UNUSED_7A.S */
-/* File: armv5te/unused.S */
+/* File: armv5te_taint/OP_UNUSED_7A.S */
+/* File: armv5te_taint/unused.S */
     bl      common_abort
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_NEG_INT: /* 0x7b */
-/* File: armv6t2/OP_NEG_INT.S */
-/* File: armv6t2/unop.S */
+/* File: armv6t2_taint/OP_NEG_INT.S */
+/* File: armv6t2_taint/unop.S */
     /*
      * Generic 32-bit unary operation.  Provide an "instr" line that
      * specifies an instruction that performs "result = op r0".
@@ -3402,6 +3729,11 @@ dalvik_inst:
     mov     r3, rINST, lsr #12          @ r3<- B
     ubfx    r9, rINST, #8, #4           @ r9<- A
     GET_VREG(r0, r3)                    @ r0<- vB
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r1)
+    GET_VREG_TAINT(r2, r3, r1)          @ r2<- vB.taint
+    SET_VREG_TAINT(r2, r9, r1)
+// end WITH_TAINT_TRACKING
                                @ optional op; may set condition codes
     FETCH_ADVANCE_INST(1)               @ advance rPC, load rINST
     rsb     r0, r0, #0                              @ r0<- op, r0-r3 changed
@@ -3414,8 +3746,8 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_NOT_INT: /* 0x7c */
-/* File: armv6t2/OP_NOT_INT.S */
-/* File: armv6t2/unop.S */
+/* File: armv6t2_taint/OP_NOT_INT.S */
+/* File: armv6t2_taint/unop.S */
     /*
      * Generic 32-bit unary operation.  Provide an "instr" line that
      * specifies an instruction that performs "result = op r0".
@@ -3428,6 +3760,11 @@ dalvik_inst:
     mov     r3, rINST, lsr #12          @ r3<- B
     ubfx    r9, rINST, #8, #4           @ r9<- A
     GET_VREG(r0, r3)                    @ r0<- vB
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r1)
+    GET_VREG_TAINT(r2, r3, r1)          @ r2<- vB.taint
+    SET_VREG_TAINT(r2, r9, r1)
+// end WITH_TAINT_TRACKING
                                @ optional op; may set condition codes
     FETCH_ADVANCE_INST(1)               @ advance rPC, load rINST
     mvn     r0, r0                              @ r0<- op, r0-r3 changed
@@ -3440,8 +3777,8 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_NEG_LONG: /* 0x7d */
-/* File: armv6t2/OP_NEG_LONG.S */
-/* File: armv6t2/unopWide.S */
+/* File: armv6t2_taint/OP_NEG_LONG.S */
+/* File: armv6t2_taint/unopWide.S */
     /*
      * Generic 64-bit unary operation.  Provide an "instr" line that
      * specifies an instruction that performs "result = op r0/r1".
@@ -3452,23 +3789,26 @@ dalvik_inst:
     /* unop vA, vB */
     mov     r3, rINST, lsr #12          @ r3<- B
     ubfx    r9, rINST, #8, #4           @ r9<- A
-    add     r3, rFP, r3, lsl #2         @ r3<- &fp[B]
-    add     r9, rFP, r9, lsl #2         @ r9<- &fp[A]
-    ldmia   r3, {r0-r1}                 @ r0/r1<- vAA
+// begin WITH_TAINT_TRACKING
+    add     r3, rFP, r3, lsl #3         @ r3<- &fp[B]
+    add     r9, rFP, r9, lsl #3         @ r9<- &fp[A]
+//    ldmia   r3, {r0-r1}                 @ r0/r1<- vAA
+    ldr     r0, [r3, #0]
+    ldr     r1, [r3, #8]
+    ldr     r10, [r3, #4]
+// end WITH_TAINT_TRACKING
     FETCH_ADVANCE_INST(1)               @ advance rPC, load rINST
     rsbs    r0, r0, #0                           @ optional op; may set condition codes
     rsc     r1, r1, #0                              @ r0/r1<- op, r2-r3 changed
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    stmia   r9, {r0-r1}                 @ vAA<- r0/r1
-    GOTO_OPCODE(ip)                     @ jump to next instruction
-    /* 10-11 instructions */
+    b       .LOP_NEG_LONG_finish
 
 
 /* ------------------------------ */
     .balign 64
 .L_OP_NOT_LONG: /* 0x7e */
-/* File: armv6t2/OP_NOT_LONG.S */
-/* File: armv6t2/unopWide.S */
+/* File: armv6t2_taint/OP_NOT_LONG.S */
+/* File: armv6t2_taint/unopWide.S */
     /*
      * Generic 64-bit unary operation.  Provide an "instr" line that
      * specifies an instruction that performs "result = op r0/r1".
@@ -3479,23 +3819,26 @@ dalvik_inst:
     /* unop vA, vB */
     mov     r3, rINST, lsr #12          @ r3<- B
     ubfx    r9, rINST, #8, #4           @ r9<- A
-    add     r3, rFP, r3, lsl #2         @ r3<- &fp[B]
-    add     r9, rFP, r9, lsl #2         @ r9<- &fp[A]
-    ldmia   r3, {r0-r1}                 @ r0/r1<- vAA
+// begin WITH_TAINT_TRACKING
+    add     r3, rFP, r3, lsl #3         @ r3<- &fp[B]
+    add     r9, rFP, r9, lsl #3         @ r9<- &fp[A]
+//    ldmia   r3, {r0-r1}                 @ r0/r1<- vAA
+    ldr     r0, [r3, #0]
+    ldr     r1, [r3, #8]
+    ldr     r10, [r3, #4]
+// end WITH_TAINT_TRACKING
     FETCH_ADVANCE_INST(1)               @ advance rPC, load rINST
     mvn     r0, r0                           @ optional op; may set condition codes
     mvn     r1, r1                              @ r0/r1<- op, r2-r3 changed
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    stmia   r9, {r0-r1}                 @ vAA<- r0/r1
-    GOTO_OPCODE(ip)                     @ jump to next instruction
-    /* 10-11 instructions */
+    b       .LOP_NOT_LONG_finish
 
 
 /* ------------------------------ */
     .balign 64
 .L_OP_NEG_FLOAT: /* 0x7f */
-/* File: armv6t2/OP_NEG_FLOAT.S */
-/* File: armv6t2/unop.S */
+/* File: armv6t2_taint/OP_NEG_FLOAT.S */
+/* File: armv6t2_taint/unop.S */
     /*
      * Generic 32-bit unary operation.  Provide an "instr" line that
      * specifies an instruction that performs "result = op r0".
@@ -3508,6 +3851,11 @@ dalvik_inst:
     mov     r3, rINST, lsr #12          @ r3<- B
     ubfx    r9, rINST, #8, #4           @ r9<- A
     GET_VREG(r0, r3)                    @ r0<- vB
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r1)
+    GET_VREG_TAINT(r2, r3, r1)          @ r2<- vB.taint
+    SET_VREG_TAINT(r2, r9, r1)
+// end WITH_TAINT_TRACKING
                                @ optional op; may set condition codes
     FETCH_ADVANCE_INST(1)               @ advance rPC, load rINST
     add     r0, r0, #0x80000000                              @ r0<- op, r0-r3 changed
@@ -3520,8 +3868,8 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_NEG_DOUBLE: /* 0x80 */
-/* File: armv6t2/OP_NEG_DOUBLE.S */
-/* File: armv6t2/unopWide.S */
+/* File: armv6t2_taint/OP_NEG_DOUBLE.S */
+/* File: armv6t2_taint/unopWide.S */
     /*
      * Generic 64-bit unary operation.  Provide an "instr" line that
      * specifies an instruction that performs "result = op r0/r1".
@@ -3532,23 +3880,26 @@ dalvik_inst:
     /* unop vA, vB */
     mov     r3, rINST, lsr #12          @ r3<- B
     ubfx    r9, rINST, #8, #4           @ r9<- A
-    add     r3, rFP, r3, lsl #2         @ r3<- &fp[B]
-    add     r9, rFP, r9, lsl #2         @ r9<- &fp[A]
-    ldmia   r3, {r0-r1}                 @ r0/r1<- vAA
+// begin WITH_TAINT_TRACKING
+    add     r3, rFP, r3, lsl #3         @ r3<- &fp[B]
+    add     r9, rFP, r9, lsl #3         @ r9<- &fp[A]
+//    ldmia   r3, {r0-r1}                 @ r0/r1<- vAA
+    ldr     r0, [r3, #0]
+    ldr     r1, [r3, #8]
+    ldr     r10, [r3, #4]
+// end WITH_TAINT_TRACKING
     FETCH_ADVANCE_INST(1)               @ advance rPC, load rINST
                                @ optional op; may set condition codes
     add     r1, r1, #0x80000000                              @ r0/r1<- op, r2-r3 changed
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    stmia   r9, {r0-r1}                 @ vAA<- r0/r1
-    GOTO_OPCODE(ip)                     @ jump to next instruction
-    /* 10-11 instructions */
+    b       .LOP_NEG_DOUBLE_finish
 
 
 /* ------------------------------ */
     .balign 64
 .L_OP_INT_TO_LONG: /* 0x81 */
-/* File: armv6t2/OP_INT_TO_LONG.S */
-/* File: armv6t2/unopWider.S */
+/* File: armv6t2_taint/OP_INT_TO_LONG.S */
+/* File: armv6t2_taint/unopWider.S */
     /*
      * Generic 32bit-to-64bit unary operation.  Provide an "instr" line
      * that specifies an instruction that performs "result = op r0", where
@@ -3560,21 +3911,23 @@ dalvik_inst:
     mov     r3, rINST, lsr #12          @ r3<- B
     ubfx    r9, rINST, #8, #4           @ r9<- A
     GET_VREG(r0, r3)                    @ r0<- vB
-    add     r9, rFP, r9, lsl #2         @ r9<- &fp[A]
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r2)
+    GET_VREG_TAINT(r10, r3, r2)
+    add     r9, rFP, r9, lsl #3         @ r9<- &fp[A]
+// end WITH_TAINT_TRACKING
                                @ optional op; may set condition codes
     FETCH_ADVANCE_INST(1)               @ advance rPC, load rINST
     mov     r1, r0, asr #31                              @ r0<- op, r0-r3 changed
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    stmia   r9, {r0-r1}                 @ vA/vA+1<- r0/r1
-    GOTO_OPCODE(ip)                     @ jump to next instruction
-    /* 9-10 instructions */
+    b      .LOP_INT_TO_LONG_finish
 
 
 /* ------------------------------ */
     .balign 64
 .L_OP_INT_TO_FLOAT: /* 0x82 */
-/* File: arm-vfp/OP_INT_TO_FLOAT.S */
-/* File: arm-vfp/funop.S */
+/* File: arm-vfp_taint/OP_INT_TO_FLOAT.S */
+/* File: arm-vfp_taint/funop.S */
     /*
      * Generic 32-bit unary floating-point operation.  Provide an "instr"
      * line that specifies an instruction that performs "s1 = op s0".
@@ -3586,20 +3939,26 @@ dalvik_inst:
     mov     r9, rINST, lsr #8           @ r9<- A+
     VREG_INDEX_TO_ADDR(r3, r3)          @ r3<- &vB
     flds    s0, [r3]                    @ s0<- vB
+// begin WITH_TAINT_TRACKING
+    ldr     r0, [r3, #4]
+// end WITH_TAINT_TRACKING
     FETCH_ADVANCE_INST(1)               @ advance rPC, load rINST
     and     r9, r9, #15                 @ r9<- A
     fsitos  s1, s0                              @ s1<- op
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
     VREG_INDEX_TO_ADDR(r9, r9)          @ r9<- &vA
     fsts    s1, [r9]                    @ vA<- s1
+// begin WITH_TAINT_TRACKING
+    str     r0, [r9, #4]
+// end WITH_TAINT_TRACKING
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
 
 /* ------------------------------ */
     .balign 64
 .L_OP_INT_TO_DOUBLE: /* 0x83 */
-/* File: arm-vfp/OP_INT_TO_DOUBLE.S */
-/* File: arm-vfp/funopWider.S */
+/* File: arm-vfp_taint/OP_INT_TO_DOUBLE.S */
+/* File: arm-vfp_taint/funopWider.S */
     /*
      * Generic 32bit-to-64bit floating point unary operation.  Provide an
      * "instr" line that specifies an instruction that performs "d0 = op s0".
@@ -3611,21 +3970,30 @@ dalvik_inst:
     mov     r9, rINST, lsr #8           @ r9<- A+
     VREG_INDEX_TO_ADDR(r3, r3)          @ r3<- &vB
     flds    s0, [r3]                    @ s0<- vB
+// begin WITH_TAINT_TRACKING
+    ldr     r0, [r3, #4]
+// end WITH_TAINT_TRACKING
     FETCH_ADVANCE_INST(1)               @ advance rPC, load rINST
     and     r9, r9, #15                 @ r9<- A
     fsitod  d0, s0                              @ d0<- op
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
     VREG_INDEX_TO_ADDR(r9, r9)          @ r9<- &vA
-    fstd    d0, [r9]                    @ vA<- d0
+// begin WITH_TAINT_TRACKING
+//    fstd    d0, [r9]                    @ vA<- d0
+    fsts    s0, [r9]
+    fsts    s1, [r9, #8]
+    str     r0, [r9, #4]
+    str     r0, [r9, #12]
+// end WITH_TAINT_TRACKING
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
 
 /* ------------------------------ */
     .balign 64
 .L_OP_LONG_TO_INT: /* 0x84 */
-/* File: armv5te/OP_LONG_TO_INT.S */
+/* File: armv5te_taint/OP_LONG_TO_INT.S */
 /* we ignore the high word, making this equivalent to a 32-bit reg move */
-/* File: armv5te/OP_MOVE.S */
+/* File: armv5te_taint/OP_MOVE.S */
     /* for move, move-object, long-to-int */
     /* op vA, vB */
     mov     r1, rINST, lsr #12          @ r1<- B from 15:12
@@ -3633,16 +4001,22 @@ dalvik_inst:
     FETCH_ADVANCE_INST(1)               @ advance rPC, load rINST
     GET_VREG(r2, r1)                    @ r2<- fp[B]
     and     r0, r0, #15
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r3)
+    GET_VREG_TAINT(r1, r1, r3)
+    SET_VREG_TAINT(r1, r0, r3)
+// end WITH_TAINT_TRACKING
     GET_INST_OPCODE(ip)                 @ ip<- opcode from rINST
     SET_VREG(r2, r0)                    @ fp[A]<- r2
     GOTO_OPCODE(ip)                     @ execute next instruction
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_LONG_TO_FLOAT: /* 0x85 */
-/* File: armv6t2/OP_LONG_TO_FLOAT.S */
-/* File: armv6t2/unopNarrower.S */
+/* File: armv6t2_taint/OP_LONG_TO_FLOAT.S */
+/* File: armv6t2_taint/unopNarrower.S */
     /*
      * Generic 64bit-to-32bit unary operation.  Provide an "instr" line
      * that specifies an instruction that performs "result = op r0/r1", where
@@ -3656,13 +4030,22 @@ dalvik_inst:
     /* unop vA, vB */
     mov     r3, rINST, lsr #12          @ r3<- B
     ubfx    r9, rINST, #8, #4           @ r9<- A
-    add     r3, rFP, r3, lsl #2         @ r3<- &fp[B]
-    ldmia   r3, {r0-r1}                 @ r0/r1<- vB/vB+1
+// begin WITH_TAINT_TRACKING
+    add     r3, rFP, r3, lsl #3         @ r3<- &fp[B]
+//    ldmia   r3, {r0-r1}                 @ r0/r1<- vB/vB+1
+    ldr     r0, [r3, #0]
+    ldr     r10, [r3, #4]
+    ldr     r1, [r3, #8]
+// end WITH_TAINT_TRACKING
     FETCH_ADVANCE_INST(1)               @ advance rPC, load rINST
                                @ optional op; may set condition codes
     bl      __aeabi_l2f                              @ r0<- op, r0-r3 changed
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+// begin WITH_TAINT_TRACKING
     SET_VREG(r0, r9)                    @ vA<- r0
+    SET_TAINT_FP(r1)
+    SET_VREG_TAINT(r10, r9, r1)
+// end WITH_TAINT_TRACKING
     GOTO_OPCODE(ip)                     @ jump to next instruction
     /* 9-10 instructions */
 
@@ -3670,8 +4053,8 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_LONG_TO_DOUBLE: /* 0x86 */
-/* File: armv6t2/OP_LONG_TO_DOUBLE.S */
-/* File: armv6t2/unopWide.S */
+/* File: armv6t2_taint/OP_LONG_TO_DOUBLE.S */
+/* File: armv6t2_taint/unopWide.S */
     /*
      * Generic 64-bit unary operation.  Provide an "instr" line that
      * specifies an instruction that performs "result = op r0/r1".
@@ -3682,23 +4065,26 @@ dalvik_inst:
     /* unop vA, vB */
     mov     r3, rINST, lsr #12          @ r3<- B
     ubfx    r9, rINST, #8, #4           @ r9<- A
-    add     r3, rFP, r3, lsl #2         @ r3<- &fp[B]
-    add     r9, rFP, r9, lsl #2         @ r9<- &fp[A]
-    ldmia   r3, {r0-r1}                 @ r0/r1<- vAA
+// begin WITH_TAINT_TRACKING
+    add     r3, rFP, r3, lsl #3         @ r3<- &fp[B]
+    add     r9, rFP, r9, lsl #3         @ r9<- &fp[A]
+//    ldmia   r3, {r0-r1}                 @ r0/r1<- vAA
+    ldr     r0, [r3, #0]
+    ldr     r1, [r3, #8]
+    ldr     r10, [r3, #4]
+// end WITH_TAINT_TRACKING
     FETCH_ADVANCE_INST(1)               @ advance rPC, load rINST
                                @ optional op; may set condition codes
     bl      __aeabi_l2d                              @ r0/r1<- op, r2-r3 changed
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    stmia   r9, {r0-r1}                 @ vAA<- r0/r1
-    GOTO_OPCODE(ip)                     @ jump to next instruction
-    /* 10-11 instructions */
+    b       .LOP_LONG_TO_DOUBLE_finish
 
 
 /* ------------------------------ */
     .balign 64
 .L_OP_FLOAT_TO_INT: /* 0x87 */
-/* File: arm-vfp/OP_FLOAT_TO_INT.S */
-/* File: arm-vfp/funop.S */
+/* File: arm-vfp_taint/OP_FLOAT_TO_INT.S */
+/* File: arm-vfp_taint/funop.S */
     /*
      * Generic 32-bit unary floating-point operation.  Provide an "instr"
      * line that specifies an instruction that performs "s1 = op s0".
@@ -3710,21 +4096,27 @@ dalvik_inst:
     mov     r9, rINST, lsr #8           @ r9<- A+
     VREG_INDEX_TO_ADDR(r3, r3)          @ r3<- &vB
     flds    s0, [r3]                    @ s0<- vB
+// begin WITH_TAINT_TRACKING
+    ldr     r0, [r3, #4]
+// end WITH_TAINT_TRACKING
     FETCH_ADVANCE_INST(1)               @ advance rPC, load rINST
     and     r9, r9, #15                 @ r9<- A
     ftosizs s1, s0                              @ s1<- op
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
     VREG_INDEX_TO_ADDR(r9, r9)          @ r9<- &vA
     fsts    s1, [r9]                    @ vA<- s1
+// begin WITH_TAINT_TRACKING
+    str     r0, [r9, #4]
+// end WITH_TAINT_TRACKING
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
 
 /* ------------------------------ */
     .balign 64
 .L_OP_FLOAT_TO_LONG: /* 0x88 */
-/* File: armv6t2/OP_FLOAT_TO_LONG.S */
-@include "armv6t2/unopWider.S" {"instr":"bl      __aeabi_f2lz"}
-/* File: armv6t2/unopWider.S */
+/* File: armv6t2_taint/OP_FLOAT_TO_LONG.S */
+@include "armv6t2_taint/unopWider.S" {"instr":"bl      __aeabi_f2lz"}
+/* File: armv6t2_taint/unopWider.S */
     /*
      * Generic 32bit-to-64bit unary operation.  Provide an "instr" line
      * that specifies an instruction that performs "result = op r0", where
@@ -3736,22 +4128,24 @@ dalvik_inst:
     mov     r3, rINST, lsr #12          @ r3<- B
     ubfx    r9, rINST, #8, #4           @ r9<- A
     GET_VREG(r0, r3)                    @ r0<- vB
-    add     r9, rFP, r9, lsl #2         @ r9<- &fp[A]
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r2)
+    GET_VREG_TAINT(r10, r3, r2)
+    add     r9, rFP, r9, lsl #3         @ r9<- &fp[A]
+// end WITH_TAINT_TRACKING
                                @ optional op; may set condition codes
     FETCH_ADVANCE_INST(1)               @ advance rPC, load rINST
     bl      f2l_doconv                              @ r0<- op, r0-r3 changed
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    stmia   r9, {r0-r1}                 @ vA/vA+1<- r0/r1
-    GOTO_OPCODE(ip)                     @ jump to next instruction
-    /* 9-10 instructions */
+    b      .LOP_FLOAT_TO_LONG_finish
 
 
 
 /* ------------------------------ */
     .balign 64
 .L_OP_FLOAT_TO_DOUBLE: /* 0x89 */
-/* File: arm-vfp/OP_FLOAT_TO_DOUBLE.S */
-/* File: arm-vfp/funopWider.S */
+/* File: arm-vfp_taint/OP_FLOAT_TO_DOUBLE.S */
+/* File: arm-vfp_taint/funopWider.S */
     /*
      * Generic 32bit-to-64bit floating point unary operation.  Provide an
      * "instr" line that specifies an instruction that performs "d0 = op s0".
@@ -3763,20 +4157,29 @@ dalvik_inst:
     mov     r9, rINST, lsr #8           @ r9<- A+
     VREG_INDEX_TO_ADDR(r3, r3)          @ r3<- &vB
     flds    s0, [r3]                    @ s0<- vB
+// begin WITH_TAINT_TRACKING
+    ldr     r0, [r3, #4]
+// end WITH_TAINT_TRACKING
     FETCH_ADVANCE_INST(1)               @ advance rPC, load rINST
     and     r9, r9, #15                 @ r9<- A
     fcvtds  d0, s0                              @ d0<- op
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
     VREG_INDEX_TO_ADDR(r9, r9)          @ r9<- &vA
-    fstd    d0, [r9]                    @ vA<- d0
+// begin WITH_TAINT_TRACKING
+//    fstd    d0, [r9]                    @ vA<- d0
+    fsts    s0, [r9]
+    fsts    s1, [r9, #8]
+    str     r0, [r9, #4]
+    str     r0, [r9, #12]
+// end WITH_TAINT_TRACKING
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
 
 /* ------------------------------ */
     .balign 64
 .L_OP_DOUBLE_TO_INT: /* 0x8a */
-/* File: arm-vfp/OP_DOUBLE_TO_INT.S */
-/* File: arm-vfp/funopNarrower.S */
+/* File: arm-vfp_taint/OP_DOUBLE_TO_INT.S */
+/* File: arm-vfp_taint/funopNarrower.S */
     /*
      * Generic 64bit-to-32bit unary floating point operation.  Provide an
      * "instr" line that specifies an instruction that performs "s0 = op d0".
@@ -3787,22 +4190,30 @@ dalvik_inst:
     mov     r3, rINST, lsr #12          @ r3<- B
     mov     r9, rINST, lsr #8           @ r9<- A+
     VREG_INDEX_TO_ADDR(r3, r3)          @ r3<- &vB
-    fldd    d0, [r3]                    @ d0<- vB
+// begin WITH_TAINT_TRACKING
+//    fldd    d0, [r3]                    @ d0<- vB
+    flds    s0, [r3]
+    flds    s1, [r3, #8]
+    ldr     r0, [r3, #4]
+// end WITH_TAINT_TRACKING
     FETCH_ADVANCE_INST(1)               @ advance rPC, load rINST
     and     r9, r9, #15                 @ r9<- A
     ftosizd  s0, d0                              @ s0<- op
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
     VREG_INDEX_TO_ADDR(r9, r9)          @ r9<- &vA
     fsts    s0, [r9]                    @ vA<- s0
+// begin WITH_TAINT_TRACKING
+    str     r0, [r9, #4]
+// end WITH_TAINT_TRACKING
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
 
 /* ------------------------------ */
     .balign 64
 .L_OP_DOUBLE_TO_LONG: /* 0x8b */
-/* File: armv6t2/OP_DOUBLE_TO_LONG.S */
-@include "armv6t2/unopWide.S" {"instr":"bl      __aeabi_d2lz"}
-/* File: armv6t2/unopWide.S */
+/* File: armv6t2_taint/OP_DOUBLE_TO_LONG.S */
+@include "armv6t2_taint/unopWide.S" {"instr":"bl      __aeabi_d2lz"}
+/* File: armv6t2_taint/unopWide.S */
     /*
      * Generic 64-bit unary operation.  Provide an "instr" line that
      * specifies an instruction that performs "result = op r0/r1".
@@ -3813,24 +4224,27 @@ dalvik_inst:
     /* unop vA, vB */
     mov     r3, rINST, lsr #12          @ r3<- B
     ubfx    r9, rINST, #8, #4           @ r9<- A
-    add     r3, rFP, r3, lsl #2         @ r3<- &fp[B]
-    add     r9, rFP, r9, lsl #2         @ r9<- &fp[A]
-    ldmia   r3, {r0-r1}                 @ r0/r1<- vAA
+// begin WITH_TAINT_TRACKING
+    add     r3, rFP, r3, lsl #3         @ r3<- &fp[B]
+    add     r9, rFP, r9, lsl #3         @ r9<- &fp[A]
+//    ldmia   r3, {r0-r1}                 @ r0/r1<- vAA
+    ldr     r0, [r3, #0]
+    ldr     r1, [r3, #8]
+    ldr     r10, [r3, #4]
+// end WITH_TAINT_TRACKING
     FETCH_ADVANCE_INST(1)               @ advance rPC, load rINST
                                @ optional op; may set condition codes
     bl      d2l_doconv                              @ r0/r1<- op, r2-r3 changed
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    stmia   r9, {r0-r1}                 @ vAA<- r0/r1
-    GOTO_OPCODE(ip)                     @ jump to next instruction
-    /* 10-11 instructions */
+    b       .LOP_DOUBLE_TO_LONG_finish
 
 
 
 /* ------------------------------ */
     .balign 64
 .L_OP_DOUBLE_TO_FLOAT: /* 0x8c */
-/* File: arm-vfp/OP_DOUBLE_TO_FLOAT.S */
-/* File: arm-vfp/funopNarrower.S */
+/* File: arm-vfp_taint/OP_DOUBLE_TO_FLOAT.S */
+/* File: arm-vfp_taint/funopNarrower.S */
     /*
      * Generic 64bit-to-32bit unary floating point operation.  Provide an
      * "instr" line that specifies an instruction that performs "s0 = op d0".
@@ -3841,21 +4255,29 @@ dalvik_inst:
     mov     r3, rINST, lsr #12          @ r3<- B
     mov     r9, rINST, lsr #8           @ r9<- A+
     VREG_INDEX_TO_ADDR(r3, r3)          @ r3<- &vB
-    fldd    d0, [r3]                    @ d0<- vB
+// begin WITH_TAINT_TRACKING
+//    fldd    d0, [r3]                    @ d0<- vB
+    flds    s0, [r3]
+    flds    s1, [r3, #8]
+    ldr     r0, [r3, #4]
+// end WITH_TAINT_TRACKING
     FETCH_ADVANCE_INST(1)               @ advance rPC, load rINST
     and     r9, r9, #15                 @ r9<- A
     fcvtsd  s0, d0                              @ s0<- op
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
     VREG_INDEX_TO_ADDR(r9, r9)          @ r9<- &vA
     fsts    s0, [r9]                    @ vA<- s0
+// begin WITH_TAINT_TRACKING
+    str     r0, [r9, #4]
+// end WITH_TAINT_TRACKING
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
 
 /* ------------------------------ */
     .balign 64
 .L_OP_INT_TO_BYTE: /* 0x8d */
-/* File: armv6t2/OP_INT_TO_BYTE.S */
-/* File: armv6t2/unop.S */
+/* File: armv6t2_taint/OP_INT_TO_BYTE.S */
+/* File: armv6t2_taint/unop.S */
     /*
      * Generic 32-bit unary operation.  Provide an "instr" line that
      * specifies an instruction that performs "result = op r0".
@@ -3868,6 +4290,11 @@ dalvik_inst:
     mov     r3, rINST, lsr #12          @ r3<- B
     ubfx    r9, rINST, #8, #4           @ r9<- A
     GET_VREG(r0, r3)                    @ r0<- vB
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r1)
+    GET_VREG_TAINT(r2, r3, r1)          @ r2<- vB.taint
+    SET_VREG_TAINT(r2, r9, r1)
+// end WITH_TAINT_TRACKING
                                @ optional op; may set condition codes
     FETCH_ADVANCE_INST(1)               @ advance rPC, load rINST
     sxtb    r0, r0                              @ r0<- op, r0-r3 changed
@@ -3880,8 +4307,8 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_INT_TO_CHAR: /* 0x8e */
-/* File: armv6t2/OP_INT_TO_CHAR.S */
-/* File: armv6t2/unop.S */
+/* File: armv6t2_taint/OP_INT_TO_CHAR.S */
+/* File: armv6t2_taint/unop.S */
     /*
      * Generic 32-bit unary operation.  Provide an "instr" line that
      * specifies an instruction that performs "result = op r0".
@@ -3894,6 +4321,11 @@ dalvik_inst:
     mov     r3, rINST, lsr #12          @ r3<- B
     ubfx    r9, rINST, #8, #4           @ r9<- A
     GET_VREG(r0, r3)                    @ r0<- vB
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r1)
+    GET_VREG_TAINT(r2, r3, r1)          @ r2<- vB.taint
+    SET_VREG_TAINT(r2, r9, r1)
+// end WITH_TAINT_TRACKING
                                @ optional op; may set condition codes
     FETCH_ADVANCE_INST(1)               @ advance rPC, load rINST
     uxth    r0, r0                              @ r0<- op, r0-r3 changed
@@ -3906,8 +4338,8 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_INT_TO_SHORT: /* 0x8f */
-/* File: armv6t2/OP_INT_TO_SHORT.S */
-/* File: armv6t2/unop.S */
+/* File: armv6t2_taint/OP_INT_TO_SHORT.S */
+/* File: armv6t2_taint/unop.S */
     /*
      * Generic 32-bit unary operation.  Provide an "instr" line that
      * specifies an instruction that performs "result = op r0".
@@ -3920,6 +4352,11 @@ dalvik_inst:
     mov     r3, rINST, lsr #12          @ r3<- B
     ubfx    r9, rINST, #8, #4           @ r9<- A
     GET_VREG(r0, r3)                    @ r0<- vB
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r1)
+    GET_VREG_TAINT(r2, r3, r1)          @ r2<- vB.taint
+    SET_VREG_TAINT(r2, r9, r1)
+// end WITH_TAINT_TRACKING
                                @ optional op; may set condition codes
     FETCH_ADVANCE_INST(1)               @ advance rPC, load rINST
     sxth    r0, r0                              @ r0<- op, r0-r3 changed
@@ -3932,8 +4369,8 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_ADD_INT: /* 0x90 */
-/* File: armv5te/OP_ADD_INT.S */
-/* File: armv5te/binop.S */
+/* File: armv5te_taint/OP_ADD_INT.S */
+/* File: armv5te_taint/binop.S */
     /*
      * Generic 32-bit binary operation.  Provide an "instr" line that
      * specifies an instruction that performs "result = r0 op r1".
@@ -3961,6 +4398,9 @@ dalvik_inst:
     beq     common_errDivideByZero
     .endif
 
+// begin WITH_TAINT_TRACKING
+    bl      .LOP_ADD_INT_taint_prop
+// end WITH_TAINT_TRACKING
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
                                @ optional op; may set condition codes
     add     r0, r0, r1                              @ r0<- op, r0-r3 changed
@@ -3970,11 +4410,12 @@ dalvik_inst:
     /* 11-14 instructions */
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_SUB_INT: /* 0x91 */
-/* File: armv5te/OP_SUB_INT.S */
-/* File: armv5te/binop.S */
+/* File: armv5te_taint/OP_SUB_INT.S */
+/* File: armv5te_taint/binop.S */
     /*
      * Generic 32-bit binary operation.  Provide an "instr" line that
      * specifies an instruction that performs "result = r0 op r1".
@@ -4002,6 +4443,9 @@ dalvik_inst:
     beq     common_errDivideByZero
     .endif
 
+// begin WITH_TAINT_TRACKING
+    bl      .LOP_SUB_INT_taint_prop
+// end WITH_TAINT_TRACKING
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
                                @ optional op; may set condition codes
     sub     r0, r0, r1                              @ r0<- op, r0-r3 changed
@@ -4011,12 +4455,13 @@ dalvik_inst:
     /* 11-14 instructions */
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_MUL_INT: /* 0x92 */
-/* File: armv5te/OP_MUL_INT.S */
+/* File: armv5te_taint/OP_MUL_INT.S */
 /* must be "mul r0, r1, r0" -- "r0, r0, r1" is illegal */
-/* File: armv5te/binop.S */
+/* File: armv5te_taint/binop.S */
     /*
      * Generic 32-bit binary operation.  Provide an "instr" line that
      * specifies an instruction that performs "result = r0 op r1".
@@ -4044,6 +4489,9 @@ dalvik_inst:
     beq     common_errDivideByZero
     .endif
 
+// begin WITH_TAINT_TRACKING
+    bl      .LOP_MUL_INT_taint_prop
+// end WITH_TAINT_TRACKING
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
                                @ optional op; may set condition codes
     mul     r0, r1, r0                              @ r0<- op, r0-r3 changed
@@ -4053,11 +4501,12 @@ dalvik_inst:
     /* 11-14 instructions */
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_DIV_INT: /* 0x93 */
-/* File: armv5te/OP_DIV_INT.S */
-/* File: armv5te/binop.S */
+/* File: armv5te_taint/OP_DIV_INT.S */
+/* File: armv5te_taint/binop.S */
     /*
      * Generic 32-bit binary operation.  Provide an "instr" line that
      * specifies an instruction that performs "result = r0 op r1".
@@ -4085,6 +4534,9 @@ dalvik_inst:
     beq     common_errDivideByZero
     .endif
 
+// begin WITH_TAINT_TRACKING
+    bl      .LOP_DIV_INT_taint_prop
+// end WITH_TAINT_TRACKING
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
                                @ optional op; may set condition codes
     bl     __aeabi_idiv                              @ r0<- op, r0-r3 changed
@@ -4094,12 +4546,13 @@ dalvik_inst:
     /* 11-14 instructions */
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_REM_INT: /* 0x94 */
-/* File: armv5te/OP_REM_INT.S */
+/* File: armv5te_taint/OP_REM_INT.S */
 /* idivmod returns quotient in r0 and remainder in r1 */
-/* File: armv5te/binop.S */
+/* File: armv5te_taint/binop.S */
     /*
      * Generic 32-bit binary operation.  Provide an "instr" line that
      * specifies an instruction that performs "result = r0 op r1".
@@ -4127,6 +4580,9 @@ dalvik_inst:
     beq     common_errDivideByZero
     .endif
 
+// begin WITH_TAINT_TRACKING
+    bl      .LOP_REM_INT_taint_prop
+// end WITH_TAINT_TRACKING
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
                                @ optional op; may set condition codes
     bl      __aeabi_idivmod                              @ r1<- op, r0-r3 changed
@@ -4136,11 +4592,12 @@ dalvik_inst:
     /* 11-14 instructions */
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_AND_INT: /* 0x95 */
-/* File: armv5te/OP_AND_INT.S */
-/* File: armv5te/binop.S */
+/* File: armv5te_taint/OP_AND_INT.S */
+/* File: armv5te_taint/binop.S */
     /*
      * Generic 32-bit binary operation.  Provide an "instr" line that
      * specifies an instruction that performs "result = r0 op r1".
@@ -4168,6 +4625,9 @@ dalvik_inst:
     beq     common_errDivideByZero
     .endif
 
+// begin WITH_TAINT_TRACKING
+    bl      .LOP_AND_INT_taint_prop
+// end WITH_TAINT_TRACKING
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
                                @ optional op; may set condition codes
     and     r0, r0, r1                              @ r0<- op, r0-r3 changed
@@ -4177,11 +4637,12 @@ dalvik_inst:
     /* 11-14 instructions */
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_OR_INT: /* 0x96 */
-/* File: armv5te/OP_OR_INT.S */
-/* File: armv5te/binop.S */
+/* File: armv5te_taint/OP_OR_INT.S */
+/* File: armv5te_taint/binop.S */
     /*
      * Generic 32-bit binary operation.  Provide an "instr" line that
      * specifies an instruction that performs "result = r0 op r1".
@@ -4209,6 +4670,9 @@ dalvik_inst:
     beq     common_errDivideByZero
     .endif
 
+// begin WITH_TAINT_TRACKING
+    bl      .LOP_OR_INT_taint_prop
+// end WITH_TAINT_TRACKING
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
                                @ optional op; may set condition codes
     orr     r0, r0, r1                              @ r0<- op, r0-r3 changed
@@ -4218,11 +4682,12 @@ dalvik_inst:
     /* 11-14 instructions */
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_XOR_INT: /* 0x97 */
-/* File: armv5te/OP_XOR_INT.S */
-/* File: armv5te/binop.S */
+/* File: armv5te_taint/OP_XOR_INT.S */
+/* File: armv5te_taint/binop.S */
     /*
      * Generic 32-bit binary operation.  Provide an "instr" line that
      * specifies an instruction that performs "result = r0 op r1".
@@ -4250,6 +4715,9 @@ dalvik_inst:
     beq     common_errDivideByZero
     .endif
 
+// begin WITH_TAINT_TRACKING
+    bl      .LOP_XOR_INT_taint_prop
+// end WITH_TAINT_TRACKING
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
                                @ optional op; may set condition codes
     eor     r0, r0, r1                              @ r0<- op, r0-r3 changed
@@ -4259,11 +4727,12 @@ dalvik_inst:
     /* 11-14 instructions */
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_SHL_INT: /* 0x98 */
-/* File: armv5te/OP_SHL_INT.S */
-/* File: armv5te/binop.S */
+/* File: armv5te_taint/OP_SHL_INT.S */
+/* File: armv5te_taint/binop.S */
     /*
      * Generic 32-bit binary operation.  Provide an "instr" line that
      * specifies an instruction that performs "result = r0 op r1".
@@ -4291,6 +4760,9 @@ dalvik_inst:
     beq     common_errDivideByZero
     .endif
 
+// begin WITH_TAINT_TRACKING
+    bl      .LOP_SHL_INT_taint_prop
+// end WITH_TAINT_TRACKING
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
     and     r1, r1, #31                           @ optional op; may set condition codes
     mov     r0, r0, asl r1                              @ r0<- op, r0-r3 changed
@@ -4300,11 +4772,12 @@ dalvik_inst:
     /* 11-14 instructions */
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_SHR_INT: /* 0x99 */
-/* File: armv5te/OP_SHR_INT.S */
-/* File: armv5te/binop.S */
+/* File: armv5te_taint/OP_SHR_INT.S */
+/* File: armv5te_taint/binop.S */
     /*
      * Generic 32-bit binary operation.  Provide an "instr" line that
      * specifies an instruction that performs "result = r0 op r1".
@@ -4332,6 +4805,9 @@ dalvik_inst:
     beq     common_errDivideByZero
     .endif
 
+// begin WITH_TAINT_TRACKING
+    bl      .LOP_SHR_INT_taint_prop
+// end WITH_TAINT_TRACKING
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
     and     r1, r1, #31                           @ optional op; may set condition codes
     mov     r0, r0, asr r1                              @ r0<- op, r0-r3 changed
@@ -4341,11 +4817,12 @@ dalvik_inst:
     /* 11-14 instructions */
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_USHR_INT: /* 0x9a */
-/* File: armv5te/OP_USHR_INT.S */
-/* File: armv5te/binop.S */
+/* File: armv5te_taint/OP_USHR_INT.S */
+/* File: armv5te_taint/binop.S */
     /*
      * Generic 32-bit binary operation.  Provide an "instr" line that
      * specifies an instruction that performs "result = r0 op r1".
@@ -4373,6 +4850,9 @@ dalvik_inst:
     beq     common_errDivideByZero
     .endif
 
+// begin WITH_TAINT_TRACKING
+    bl      .LOP_USHR_INT_taint_prop
+// end WITH_TAINT_TRACKING
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
     and     r1, r1, #31                           @ optional op; may set condition codes
     mov     r0, r0, lsr r1                              @ r0<- op, r0-r3 changed
@@ -4382,11 +4862,12 @@ dalvik_inst:
     /* 11-14 instructions */
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_ADD_LONG: /* 0x9b */
-/* File: armv5te/OP_ADD_LONG.S */
-/* File: armv5te/binopWide.S */
+/* File: armv5te_taint/OP_ADD_LONG.S */
+/* File: armv5te_taint/binopWide.S */
     /*
      * Generic 64-bit binary operation.  Provide an "instr" line that
      * specifies an instruction that performs "result = r0-r1 op r2-r3".
@@ -4407,11 +4888,9 @@ dalvik_inst:
     mov     r9, rINST, lsr #8           @ r9<- AA
     and     r2, r0, #255                @ r2<- BB
     mov     r3, r0, lsr #8              @ r3<- CC
-    add     r9, rFP, r9, lsl #2         @ r9<- &fp[AA]
-    add     r2, rFP, r2, lsl #2         @ r2<- &fp[BB]
-    add     r3, rFP, r3, lsl #2         @ r3<- &fp[CC]
-    ldmia   r2, {r0-r1}                 @ r0/r1<- vBB/vBB+1
-    ldmia   r3, {r2-r3}                 @ r2/r3<- vCC/vCC+1
+// begin WITH_TAINT_TRACKING
+    bl      .LOP_ADD_LONG_taint_prop
+// end WITH_TAINT_TRACKING
     .if 0
     orrs    ip, r2, r3                  @ second arg (r2-r3) is zero?
     beq     common_errDivideByZero
@@ -4421,16 +4900,23 @@ dalvik_inst:
     adds    r0, r0, r2                           @ optional op; may set condition codes
     adc     r1, r1, r3                              @ result<- op, r0-r3 changed
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    stmia   r9, {r0,r1}     @ vAA/vAA+1<- r0/r1
+// begin WITH_TAINT_TRACKING
+//    stmia   r9, {r0,r1}     @ vAA/vAA+1<- r0/r1
+    str     r0, [r9, #0]
+    str     r10, [r9, #4]
+    str     r1, [r9, #8]
+    str     r10, [r9, #12]
+// end WITH_TAINT_TRACKING
     GOTO_OPCODE(ip)                     @ jump to next instruction
     /* 14-17 instructions */
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_SUB_LONG: /* 0x9c */
-/* File: armv5te/OP_SUB_LONG.S */
-/* File: armv5te/binopWide.S */
+/* File: armv5te_taint/OP_SUB_LONG.S */
+/* File: armv5te_taint/binopWide.S */
     /*
      * Generic 64-bit binary operation.  Provide an "instr" line that
      * specifies an instruction that performs "result = r0-r1 op r2-r3".
@@ -4451,11 +4937,9 @@ dalvik_inst:
     mov     r9, rINST, lsr #8           @ r9<- AA
     and     r2, r0, #255                @ r2<- BB
     mov     r3, r0, lsr #8              @ r3<- CC
-    add     r9, rFP, r9, lsl #2         @ r9<- &fp[AA]
-    add     r2, rFP, r2, lsl #2         @ r2<- &fp[BB]
-    add     r3, rFP, r3, lsl #2         @ r3<- &fp[CC]
-    ldmia   r2, {r0-r1}                 @ r0/r1<- vBB/vBB+1
-    ldmia   r3, {r2-r3}                 @ r2/r3<- vCC/vCC+1
+// begin WITH_TAINT_TRACKING
+    bl      .LOP_SUB_LONG_taint_prop
+// end WITH_TAINT_TRACKING
     .if 0
     orrs    ip, r2, r3                  @ second arg (r2-r3) is zero?
     beq     common_errDivideByZero
@@ -4465,15 +4949,22 @@ dalvik_inst:
     subs    r0, r0, r2                           @ optional op; may set condition codes
     sbc     r1, r1, r3                              @ result<- op, r0-r3 changed
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    stmia   r9, {r0,r1}     @ vAA/vAA+1<- r0/r1
+// begin WITH_TAINT_TRACKING
+//    stmia   r9, {r0,r1}     @ vAA/vAA+1<- r0/r1
+    str     r0, [r9, #0]
+    str     r10, [r9, #4]
+    str     r1, [r9, #8]
+    str     r10, [r9, #12]
+// end WITH_TAINT_TRACKING
     GOTO_OPCODE(ip)                     @ jump to next instruction
     /* 14-17 instructions */
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_MUL_LONG: /* 0x9d */
-/* File: armv5te/OP_MUL_LONG.S */
+/* File: armv5te_taint/OP_MUL_LONG.S */
     /*
      * Signed 64-bit integer multiply.
      *
@@ -4496,24 +4987,25 @@ dalvik_inst:
     FETCH(r0, 1)                        @ r0<- CCBB
     and     r2, r0, #255                @ r2<- BB
     mov     r3, r0, lsr #8              @ r3<- CC
-    add     r2, rFP, r2, lsl #2         @ r2<- &fp[BB]
-    add     r3, rFP, r3, lsl #2         @ r3<- &fp[CC]
-    ldmia   r2, {r0-r1}                 @ r0/r1<- vBB/vBB+1
-    ldmia   r3, {r2-r3}                 @ r2/r3<- vCC/vCC+1
+// begin WITH_TAINT_TRACKING
+    bl		mul_long_taint_prop
+// end WITH_TAINT_TRACKING
     mul     ip, r2, r1                  @  ip<- ZxW
     umull   r9, r10, r2, r0             @  r9/r10 <- ZxX
     mla     r2, r0, r3, ip              @  r2<- YxX + (ZxW)
     mov     r0, rINST, lsr #8           @ r0<- AA
     add     r10, r2, r10                @  r10<- r10 + low(ZxW + (YxX))
-    add     r0, rFP, r0, lsl #2         @ r0<- &fp[AA]
+// begin WITH_TAINT_TRACKING
+    add     r0, rFP, r0, lsl #3         @ r0<- &fp[AA]
+// end WITH_TAINT_TRACKING
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
     b       .LOP_MUL_LONG_finish
 
 /* ------------------------------ */
     .balign 64
 .L_OP_DIV_LONG: /* 0x9e */
-/* File: armv5te/OP_DIV_LONG.S */
-/* File: armv5te/binopWide.S */
+/* File: armv5te_taint/OP_DIV_LONG.S */
+/* File: armv5te_taint/binopWide.S */
     /*
      * Generic 64-bit binary operation.  Provide an "instr" line that
      * specifies an instruction that performs "result = r0-r1 op r2-r3".
@@ -4534,11 +5026,9 @@ dalvik_inst:
     mov     r9, rINST, lsr #8           @ r9<- AA
     and     r2, r0, #255                @ r2<- BB
     mov     r3, r0, lsr #8              @ r3<- CC
-    add     r9, rFP, r9, lsl #2         @ r9<- &fp[AA]
-    add     r2, rFP, r2, lsl #2         @ r2<- &fp[BB]
-    add     r3, rFP, r3, lsl #2         @ r3<- &fp[CC]
-    ldmia   r2, {r0-r1}                 @ r0/r1<- vBB/vBB+1
-    ldmia   r3, {r2-r3}                 @ r2/r3<- vCC/vCC+1
+// begin WITH_TAINT_TRACKING
+    bl      .LOP_DIV_LONG_taint_prop
+// end WITH_TAINT_TRACKING
     .if 1
     orrs    ip, r2, r3                  @ second arg (r2-r3) is zero?
     beq     common_errDivideByZero
@@ -4548,17 +5038,24 @@ dalvik_inst:
                                @ optional op; may set condition codes
     bl      __aeabi_ldivmod                              @ result<- op, r0-r3 changed
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    stmia   r9, {r0,r1}     @ vAA/vAA+1<- r0/r1
+// begin WITH_TAINT_TRACKING
+//    stmia   r9, {r0,r1}     @ vAA/vAA+1<- r0/r1
+    str     r0, [r9, #0]
+    str     r10, [r9, #4]
+    str     r1, [r9, #8]
+    str     r10, [r9, #12]
+// end WITH_TAINT_TRACKING
     GOTO_OPCODE(ip)                     @ jump to next instruction
     /* 14-17 instructions */
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_REM_LONG: /* 0x9f */
-/* File: armv5te/OP_REM_LONG.S */
+/* File: armv5te_taint/OP_REM_LONG.S */
 /* ldivmod returns quotient in r0/r1 and remainder in r2/r3 */
-/* File: armv5te/binopWide.S */
+/* File: armv5te_taint/binopWide.S */
     /*
      * Generic 64-bit binary operation.  Provide an "instr" line that
      * specifies an instruction that performs "result = r0-r1 op r2-r3".
@@ -4579,11 +5076,9 @@ dalvik_inst:
     mov     r9, rINST, lsr #8           @ r9<- AA
     and     r2, r0, #255                @ r2<- BB
     mov     r3, r0, lsr #8              @ r3<- CC
-    add     r9, rFP, r9, lsl #2         @ r9<- &fp[AA]
-    add     r2, rFP, r2, lsl #2         @ r2<- &fp[BB]
-    add     r3, rFP, r3, lsl #2         @ r3<- &fp[CC]
-    ldmia   r2, {r0-r1}                 @ r0/r1<- vBB/vBB+1
-    ldmia   r3, {r2-r3}                 @ r2/r3<- vCC/vCC+1
+// begin WITH_TAINT_TRACKING
+    bl      .LOP_REM_LONG_taint_prop
+// end WITH_TAINT_TRACKING
     .if 1
     orrs    ip, r2, r3                  @ second arg (r2-r3) is zero?
     beq     common_errDivideByZero
@@ -4593,16 +5088,23 @@ dalvik_inst:
                                @ optional op; may set condition codes
     bl      __aeabi_ldivmod                              @ result<- op, r0-r3 changed
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    stmia   r9, {r2,r3}     @ vAA/vAA+1<- r2/r3
+// begin WITH_TAINT_TRACKING
+//    stmia   r9, {r2,r3}     @ vAA/vAA+1<- r2/r3
+    str     r2, [r9, #0]
+    str     r10, [r9, #4]
+    str     r3, [r9, #8]
+    str     r10, [r9, #12]
+// end WITH_TAINT_TRACKING
     GOTO_OPCODE(ip)                     @ jump to next instruction
     /* 14-17 instructions */
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_AND_LONG: /* 0xa0 */
-/* File: armv5te/OP_AND_LONG.S */
-/* File: armv5te/binopWide.S */
+/* File: armv5te_taint/OP_AND_LONG.S */
+/* File: armv5te_taint/binopWide.S */
     /*
      * Generic 64-bit binary operation.  Provide an "instr" line that
      * specifies an instruction that performs "result = r0-r1 op r2-r3".
@@ -4623,11 +5125,9 @@ dalvik_inst:
     mov     r9, rINST, lsr #8           @ r9<- AA
     and     r2, r0, #255                @ r2<- BB
     mov     r3, r0, lsr #8              @ r3<- CC
-    add     r9, rFP, r9, lsl #2         @ r9<- &fp[AA]
-    add     r2, rFP, r2, lsl #2         @ r2<- &fp[BB]
-    add     r3, rFP, r3, lsl #2         @ r3<- &fp[CC]
-    ldmia   r2, {r0-r1}                 @ r0/r1<- vBB/vBB+1
-    ldmia   r3, {r2-r3}                 @ r2/r3<- vCC/vCC+1
+// begin WITH_TAINT_TRACKING
+    bl      .LOP_AND_LONG_taint_prop
+// end WITH_TAINT_TRACKING
     .if 0
     orrs    ip, r2, r3                  @ second arg (r2-r3) is zero?
     beq     common_errDivideByZero
@@ -4637,16 +5137,23 @@ dalvik_inst:
     and     r0, r0, r2                           @ optional op; may set condition codes
     and     r1, r1, r3                              @ result<- op, r0-r3 changed
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    stmia   r9, {r0,r1}     @ vAA/vAA+1<- r0/r1
+// begin WITH_TAINT_TRACKING
+//    stmia   r9, {r0,r1}     @ vAA/vAA+1<- r0/r1
+    str     r0, [r9, #0]
+    str     r10, [r9, #4]
+    str     r1, [r9, #8]
+    str     r10, [r9, #12]
+// end WITH_TAINT_TRACKING
     GOTO_OPCODE(ip)                     @ jump to next instruction
     /* 14-17 instructions */
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_OR_LONG: /* 0xa1 */
-/* File: armv5te/OP_OR_LONG.S */
-/* File: armv5te/binopWide.S */
+/* File: armv5te_taint/OP_OR_LONG.S */
+/* File: armv5te_taint/binopWide.S */
     /*
      * Generic 64-bit binary operation.  Provide an "instr" line that
      * specifies an instruction that performs "result = r0-r1 op r2-r3".
@@ -4667,11 +5174,9 @@ dalvik_inst:
     mov     r9, rINST, lsr #8           @ r9<- AA
     and     r2, r0, #255                @ r2<- BB
     mov     r3, r0, lsr #8              @ r3<- CC
-    add     r9, rFP, r9, lsl #2         @ r9<- &fp[AA]
-    add     r2, rFP, r2, lsl #2         @ r2<- &fp[BB]
-    add     r3, rFP, r3, lsl #2         @ r3<- &fp[CC]
-    ldmia   r2, {r0-r1}                 @ r0/r1<- vBB/vBB+1
-    ldmia   r3, {r2-r3}                 @ r2/r3<- vCC/vCC+1
+// begin WITH_TAINT_TRACKING
+    bl      .LOP_OR_LONG_taint_prop
+// end WITH_TAINT_TRACKING
     .if 0
     orrs    ip, r2, r3                  @ second arg (r2-r3) is zero?
     beq     common_errDivideByZero
@@ -4681,16 +5186,23 @@ dalvik_inst:
     orr     r0, r0, r2                           @ optional op; may set condition codes
     orr     r1, r1, r3                              @ result<- op, r0-r3 changed
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    stmia   r9, {r0,r1}     @ vAA/vAA+1<- r0/r1
+// begin WITH_TAINT_TRACKING
+//    stmia   r9, {r0,r1}     @ vAA/vAA+1<- r0/r1
+    str     r0, [r9, #0]
+    str     r10, [r9, #4]
+    str     r1, [r9, #8]
+    str     r10, [r9, #12]
+// end WITH_TAINT_TRACKING
     GOTO_OPCODE(ip)                     @ jump to next instruction
     /* 14-17 instructions */
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_XOR_LONG: /* 0xa2 */
-/* File: armv5te/OP_XOR_LONG.S */
-/* File: armv5te/binopWide.S */
+/* File: armv5te_taint/OP_XOR_LONG.S */
+/* File: armv5te_taint/binopWide.S */
     /*
      * Generic 64-bit binary operation.  Provide an "instr" line that
      * specifies an instruction that performs "result = r0-r1 op r2-r3".
@@ -4711,11 +5223,9 @@ dalvik_inst:
     mov     r9, rINST, lsr #8           @ r9<- AA
     and     r2, r0, #255                @ r2<- BB
     mov     r3, r0, lsr #8              @ r3<- CC
-    add     r9, rFP, r9, lsl #2         @ r9<- &fp[AA]
-    add     r2, rFP, r2, lsl #2         @ r2<- &fp[BB]
-    add     r3, rFP, r3, lsl #2         @ r3<- &fp[CC]
-    ldmia   r2, {r0-r1}                 @ r0/r1<- vBB/vBB+1
-    ldmia   r3, {r2-r3}                 @ r2/r3<- vCC/vCC+1
+// begin WITH_TAINT_TRACKING
+    bl      .LOP_XOR_LONG_taint_prop
+// end WITH_TAINT_TRACKING
     .if 0
     orrs    ip, r2, r3                  @ second arg (r2-r3) is zero?
     beq     common_errDivideByZero
@@ -4725,15 +5235,22 @@ dalvik_inst:
     eor     r0, r0, r2                           @ optional op; may set condition codes
     eor     r1, r1, r3                              @ result<- op, r0-r3 changed
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    stmia   r9, {r0,r1}     @ vAA/vAA+1<- r0/r1
+// begin WITH_TAINT_TRACKING
+//    stmia   r9, {r0,r1}     @ vAA/vAA+1<- r0/r1
+    str     r0, [r9, #0]
+    str     r10, [r9, #4]
+    str     r1, [r9, #8]
+    str     r10, [r9, #12]
+// end WITH_TAINT_TRACKING
     GOTO_OPCODE(ip)                     @ jump to next instruction
     /* 14-17 instructions */
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_SHL_LONG: /* 0xa3 */
-/* File: armv5te/OP_SHL_LONG.S */
+/* File: armv5te_taint/OP_SHL_LONG.S */
     /*
      * Long integer shift.  This is different from the generic 32/64-bit
      * binary operations because vAA/vBB are 64-bit but vCC (the shift
@@ -4745,11 +5262,9 @@ dalvik_inst:
     mov     r9, rINST, lsr #8           @ r9<- AA
     and     r3, r0, #255                @ r3<- BB
     mov     r0, r0, lsr #8              @ r0<- CC
-    add     r3, rFP, r3, lsl #2         @ r3<- &fp[BB]
-    GET_VREG(r2, r0)                    @ r2<- vCC
-    ldmia   r3, {r0-r1}                 @ r0/r1<- vBB/vBB+1
-    and     r2, r2, #63                 @ r2<- r2 & 0x3f
-    add     r9, rFP, r9, lsl #2         @ r9<- &fp[AA]
+// begin WITH_TAINT_TRACKING
+    bl      shl_long_taint_prop
+// end WITH_TAINT_TRACKING
 
     mov     r1, r1, asl r2              @  r1<- r1 << r2
     rsb     r3, r2, #32                 @  r3<- 32 - r2
@@ -4762,7 +5277,7 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_SHR_LONG: /* 0xa4 */
-/* File: armv5te/OP_SHR_LONG.S */
+/* File: armv5te_taint/OP_SHR_LONG.S */
     /*
      * Long integer shift.  This is different from the generic 32/64-bit
      * binary operations because vAA/vBB are 64-bit but vCC (the shift
@@ -4774,11 +5289,9 @@ dalvik_inst:
     mov     r9, rINST, lsr #8           @ r9<- AA
     and     r3, r0, #255                @ r3<- BB
     mov     r0, r0, lsr #8              @ r0<- CC
-    add     r3, rFP, r3, lsl #2         @ r3<- &fp[BB]
-    GET_VREG(r2, r0)                    @ r2<- vCC
-    ldmia   r3, {r0-r1}                 @ r0/r1<- vBB/vBB+1
-    and     r2, r2, #63                 @ r0<- r0 & 0x3f
-    add     r9, rFP, r9, lsl #2         @ r9<- &fp[AA]
+// begin WITH_TAINT_TRACKING
+    bl      shr_long_taint_prop
+// end WITH_TAINT_TRACKING
 
     mov     r0, r0, lsr r2              @  r0<- r2 >> r2
     rsb     r3, r2, #32                 @  r3<- 32 - r2
@@ -4791,7 +5304,7 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_USHR_LONG: /* 0xa5 */
-/* File: armv5te/OP_USHR_LONG.S */
+/* File: armv5te_taint/OP_USHR_LONG.S */
     /*
      * Long integer shift.  This is different from the generic 32/64-bit
      * binary operations because vAA/vBB are 64-bit but vCC (the shift
@@ -4803,11 +5316,9 @@ dalvik_inst:
     mov     r9, rINST, lsr #8           @ r9<- AA
     and     r3, r0, #255                @ r3<- BB
     mov     r0, r0, lsr #8              @ r0<- CC
-    add     r3, rFP, r3, lsl #2         @ r3<- &fp[BB]
-    GET_VREG(r2, r0)                    @ r2<- vCC
-    ldmia   r3, {r0-r1}                 @ r0/r1<- vBB/vBB+1
-    and     r2, r2, #63                 @ r0<- r0 & 0x3f
-    add     r9, rFP, r9, lsl #2         @ r9<- &fp[AA]
+// begin WITH_TAINT_TRACKING
+    bl      ushr_long_taint_prop
+// end WITH_TAINT_TRACKING
 
     mov     r0, r0, lsr r2              @  r0<- r2 >> r2
     rsb     r3, r2, #32                 @  r3<- 32 - r2
@@ -4820,8 +5331,8 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_ADD_FLOAT: /* 0xa6 */
-/* File: arm-vfp/OP_ADD_FLOAT.S */
-/* File: arm-vfp/fbinop.S */
+/* File: arm-vfp_taint/OP_ADD_FLOAT.S */
+/* File: arm-vfp_taint/fbinop.S */
     /*
      * Generic 32-bit floating-point operation.  Provide an "instr" line that
      * specifies an instruction that performs "s2 = s0 op s1".  Because we
@@ -4838,20 +5349,19 @@ dalvik_inst:
     VREG_INDEX_TO_ADDR(r2, r2)          @ r2<- &vBB
     flds    s1, [r3]                    @ s1<- vCC
     flds    s0, [r2]                    @ s0<- vBB
-
-    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
-    fadds   s2, s0, s1                              @ s2<- op
-    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    VREG_INDEX_TO_ADDR(r9, r9)          @ r9<- &vAA
-    fsts    s2, [r9]                    @ vAA<- s2
-    GOTO_OPCODE(ip)                     @ jump to next instruction
+// begin WITH_TAINT_TRACKING
+    ldr     r0, [r3, #4]
+    ldr     r1, [r2, #4]
+    orr     r0, r0, r1
+// end WITH_TAINT_TRACKING
+    b     .LOP_ADD_FLOAT_finish
 
 
 /* ------------------------------ */
     .balign 64
 .L_OP_SUB_FLOAT: /* 0xa7 */
-/* File: arm-vfp/OP_SUB_FLOAT.S */
-/* File: arm-vfp/fbinop.S */
+/* File: arm-vfp_taint/OP_SUB_FLOAT.S */
+/* File: arm-vfp_taint/fbinop.S */
     /*
      * Generic 32-bit floating-point operation.  Provide an "instr" line that
      * specifies an instruction that performs "s2 = s0 op s1".  Because we
@@ -4868,20 +5378,19 @@ dalvik_inst:
     VREG_INDEX_TO_ADDR(r2, r2)          @ r2<- &vBB
     flds    s1, [r3]                    @ s1<- vCC
     flds    s0, [r2]                    @ s0<- vBB
-
-    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
-    fsubs   s2, s0, s1                              @ s2<- op
-    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    VREG_INDEX_TO_ADDR(r9, r9)          @ r9<- &vAA
-    fsts    s2, [r9]                    @ vAA<- s2
-    GOTO_OPCODE(ip)                     @ jump to next instruction
+// begin WITH_TAINT_TRACKING
+    ldr     r0, [r3, #4]
+    ldr     r1, [r2, #4]
+    orr     r0, r0, r1
+// end WITH_TAINT_TRACKING
+    b     .LOP_SUB_FLOAT_finish
 
 
 /* ------------------------------ */
     .balign 64
 .L_OP_MUL_FLOAT: /* 0xa8 */
-/* File: arm-vfp/OP_MUL_FLOAT.S */
-/* File: arm-vfp/fbinop.S */
+/* File: arm-vfp_taint/OP_MUL_FLOAT.S */
+/* File: arm-vfp_taint/fbinop.S */
     /*
      * Generic 32-bit floating-point operation.  Provide an "instr" line that
      * specifies an instruction that performs "s2 = s0 op s1".  Because we
@@ -4898,20 +5407,19 @@ dalvik_inst:
     VREG_INDEX_TO_ADDR(r2, r2)          @ r2<- &vBB
     flds    s1, [r3]                    @ s1<- vCC
     flds    s0, [r2]                    @ s0<- vBB
-
-    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
-    fmuls   s2, s0, s1                              @ s2<- op
-    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    VREG_INDEX_TO_ADDR(r9, r9)          @ r9<- &vAA
-    fsts    s2, [r9]                    @ vAA<- s2
-    GOTO_OPCODE(ip)                     @ jump to next instruction
+// begin WITH_TAINT_TRACKING
+    ldr     r0, [r3, #4]
+    ldr     r1, [r2, #4]
+    orr     r0, r0, r1
+// end WITH_TAINT_TRACKING
+    b     .LOP_MUL_FLOAT_finish
 
 
 /* ------------------------------ */
     .balign 64
 .L_OP_DIV_FLOAT: /* 0xa9 */
-/* File: arm-vfp/OP_DIV_FLOAT.S */
-/* File: arm-vfp/fbinop.S */
+/* File: arm-vfp_taint/OP_DIV_FLOAT.S */
+/* File: arm-vfp_taint/fbinop.S */
     /*
      * Generic 32-bit floating-point operation.  Provide an "instr" line that
      * specifies an instruction that performs "s2 = s0 op s1".  Because we
@@ -4928,21 +5436,20 @@ dalvik_inst:
     VREG_INDEX_TO_ADDR(r2, r2)          @ r2<- &vBB
     flds    s1, [r3]                    @ s1<- vCC
     flds    s0, [r2]                    @ s0<- vBB
-
-    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
-    fdivs   s2, s0, s1                              @ s2<- op
-    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    VREG_INDEX_TO_ADDR(r9, r9)          @ r9<- &vAA
-    fsts    s2, [r9]                    @ vAA<- s2
-    GOTO_OPCODE(ip)                     @ jump to next instruction
+// begin WITH_TAINT_TRACKING
+    ldr     r0, [r3, #4]
+    ldr     r1, [r2, #4]
+    orr     r0, r0, r1
+// end WITH_TAINT_TRACKING
+    b     .LOP_DIV_FLOAT_finish
 
 
 /* ------------------------------ */
     .balign 64
 .L_OP_REM_FLOAT: /* 0xaa */
-/* File: armv5te/OP_REM_FLOAT.S */
+/* File: armv5te_taint/OP_REM_FLOAT.S */
 /* EABI doesn't define a float remainder function, but libm does */
-/* File: armv5te/binop.S */
+/* File: armv5te_taint/binop.S */
     /*
      * Generic 32-bit binary operation.  Provide an "instr" line that
      * specifies an instruction that performs "result = r0 op r1".
@@ -4970,6 +5477,9 @@ dalvik_inst:
     beq     common_errDivideByZero
     .endif
 
+// begin WITH_TAINT_TRACKING
+    bl      .LOP_REM_FLOAT_taint_prop
+// end WITH_TAINT_TRACKING
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
                                @ optional op; may set condition codes
     bl      fmodf                              @ r0<- op, r0-r3 changed
@@ -4979,11 +5489,12 @@ dalvik_inst:
     /* 11-14 instructions */
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_ADD_DOUBLE: /* 0xab */
-/* File: arm-vfp/OP_ADD_DOUBLE.S */
-/* File: arm-vfp/fbinopWide.S */
+/* File: arm-vfp_taint/OP_ADD_DOUBLE.S */
+/* File: arm-vfp_taint/fbinopWide.S */
     /*
      * Generic 64-bit double-precision floating point binary operation.
      * Provide an "instr" line that specifies an instruction that performs
@@ -4998,22 +5509,25 @@ dalvik_inst:
     and     r2, r0, #255                @ r2<- BB
     VREG_INDEX_TO_ADDR(r3, r3)          @ r3<- &vCC
     VREG_INDEX_TO_ADDR(r2, r2)          @ r2<- &vBB
-    fldd    d1, [r3]                    @ d1<- vCC
-    fldd    d0, [r2]                    @ d0<- vBB
-
-    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
-    faddd   d2, d0, d1                              @ s2<- op
-    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    VREG_INDEX_TO_ADDR(r9, r9)          @ r9<- &vAA
-    fstd    d2, [r9]                    @ vAA<- d2
-    GOTO_OPCODE(ip)                     @ jump to next instruction
+// begin WITH_TAINT_TRACKING
+//    fldd    d1, [r3]                    @ d1<- vCC
+//    fldd    d0, [r2]                    @ d0<- vBB
+    flds    s2, [r3]
+    flds    s3, [r3, #8]
+    flds    s0, [r2]
+    flds    s1, [r2, #8]
+    ldr     r0, [r3, #4]
+    ldr     r1, [r2, #4]
+    orr     r0, r0, r1
+// end WITH_TAINT_TRACKING
+    b     .LOP_ADD_DOUBLE_finish
 
 
 /* ------------------------------ */
     .balign 64
 .L_OP_SUB_DOUBLE: /* 0xac */
-/* File: arm-vfp/OP_SUB_DOUBLE.S */
-/* File: arm-vfp/fbinopWide.S */
+/* File: arm-vfp_taint/OP_SUB_DOUBLE.S */
+/* File: arm-vfp_taint/fbinopWide.S */
     /*
      * Generic 64-bit double-precision floating point binary operation.
      * Provide an "instr" line that specifies an instruction that performs
@@ -5028,22 +5542,25 @@ dalvik_inst:
     and     r2, r0, #255                @ r2<- BB
     VREG_INDEX_TO_ADDR(r3, r3)          @ r3<- &vCC
     VREG_INDEX_TO_ADDR(r2, r2)          @ r2<- &vBB
-    fldd    d1, [r3]                    @ d1<- vCC
-    fldd    d0, [r2]                    @ d0<- vBB
-
-    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
-    fsubd   d2, d0, d1                              @ s2<- op
-    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    VREG_INDEX_TO_ADDR(r9, r9)          @ r9<- &vAA
-    fstd    d2, [r9]                    @ vAA<- d2
-    GOTO_OPCODE(ip)                     @ jump to next instruction
+// begin WITH_TAINT_TRACKING
+//    fldd    d1, [r3]                    @ d1<- vCC
+//    fldd    d0, [r2]                    @ d0<- vBB
+    flds    s2, [r3]
+    flds    s3, [r3, #8]
+    flds    s0, [r2]
+    flds    s1, [r2, #8]
+    ldr     r0, [r3, #4]
+    ldr     r1, [r2, #4]
+    orr     r0, r0, r1
+// end WITH_TAINT_TRACKING
+    b     .LOP_SUB_DOUBLE_finish
 
 
 /* ------------------------------ */
     .balign 64
 .L_OP_MUL_DOUBLE: /* 0xad */
-/* File: arm-vfp/OP_MUL_DOUBLE.S */
-/* File: arm-vfp/fbinopWide.S */
+/* File: arm-vfp_taint/OP_MUL_DOUBLE.S */
+/* File: arm-vfp_taint/fbinopWide.S */
     /*
      * Generic 64-bit double-precision floating point binary operation.
      * Provide an "instr" line that specifies an instruction that performs
@@ -5058,22 +5575,25 @@ dalvik_inst:
     and     r2, r0, #255                @ r2<- BB
     VREG_INDEX_TO_ADDR(r3, r3)          @ r3<- &vCC
     VREG_INDEX_TO_ADDR(r2, r2)          @ r2<- &vBB
-    fldd    d1, [r3]                    @ d1<- vCC
-    fldd    d0, [r2]                    @ d0<- vBB
-
-    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
-    fmuld   d2, d0, d1                              @ s2<- op
-    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    VREG_INDEX_TO_ADDR(r9, r9)          @ r9<- &vAA
-    fstd    d2, [r9]                    @ vAA<- d2
-    GOTO_OPCODE(ip)                     @ jump to next instruction
+// begin WITH_TAINT_TRACKING
+//    fldd    d1, [r3]                    @ d1<- vCC
+//    fldd    d0, [r2]                    @ d0<- vBB
+    flds    s2, [r3]
+    flds    s3, [r3, #8]
+    flds    s0, [r2]
+    flds    s1, [r2, #8]
+    ldr     r0, [r3, #4]
+    ldr     r1, [r2, #4]
+    orr     r0, r0, r1
+// end WITH_TAINT_TRACKING
+    b     .LOP_MUL_DOUBLE_finish
 
 
 /* ------------------------------ */
     .balign 64
 .L_OP_DIV_DOUBLE: /* 0xae */
-/* File: arm-vfp/OP_DIV_DOUBLE.S */
-/* File: arm-vfp/fbinopWide.S */
+/* File: arm-vfp_taint/OP_DIV_DOUBLE.S */
+/* File: arm-vfp_taint/fbinopWide.S */
     /*
      * Generic 64-bit double-precision floating point binary operation.
      * Provide an "instr" line that specifies an instruction that performs
@@ -5088,23 +5608,26 @@ dalvik_inst:
     and     r2, r0, #255                @ r2<- BB
     VREG_INDEX_TO_ADDR(r3, r3)          @ r3<- &vCC
     VREG_INDEX_TO_ADDR(r2, r2)          @ r2<- &vBB
-    fldd    d1, [r3]                    @ d1<- vCC
-    fldd    d0, [r2]                    @ d0<- vBB
-
-    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
-    fdivd   d2, d0, d1                              @ s2<- op
-    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    VREG_INDEX_TO_ADDR(r9, r9)          @ r9<- &vAA
-    fstd    d2, [r9]                    @ vAA<- d2
-    GOTO_OPCODE(ip)                     @ jump to next instruction
+// begin WITH_TAINT_TRACKING
+//    fldd    d1, [r3]                    @ d1<- vCC
+//    fldd    d0, [r2]                    @ d0<- vBB
+    flds    s2, [r3]
+    flds    s3, [r3, #8]
+    flds    s0, [r2]
+    flds    s1, [r2, #8]
+    ldr     r0, [r3, #4]
+    ldr     r1, [r2, #4]
+    orr     r0, r0, r1
+// end WITH_TAINT_TRACKING
+    b     .LOP_DIV_DOUBLE_finish
 
 
 /* ------------------------------ */
     .balign 64
 .L_OP_REM_DOUBLE: /* 0xaf */
-/* File: armv5te/OP_REM_DOUBLE.S */
+/* File: armv5te_taint/OP_REM_DOUBLE.S */
 /* EABI doesn't define a double remainder function, but libm does */
-/* File: armv5te/binopWide.S */
+/* File: armv5te_taint/binopWide.S */
     /*
      * Generic 64-bit binary operation.  Provide an "instr" line that
      * specifies an instruction that performs "result = r0-r1 op r2-r3".
@@ -5125,11 +5648,9 @@ dalvik_inst:
     mov     r9, rINST, lsr #8           @ r9<- AA
     and     r2, r0, #255                @ r2<- BB
     mov     r3, r0, lsr #8              @ r3<- CC
-    add     r9, rFP, r9, lsl #2         @ r9<- &fp[AA]
-    add     r2, rFP, r2, lsl #2         @ r2<- &fp[BB]
-    add     r3, rFP, r3, lsl #2         @ r3<- &fp[CC]
-    ldmia   r2, {r0-r1}                 @ r0/r1<- vBB/vBB+1
-    ldmia   r3, {r2-r3}                 @ r2/r3<- vCC/vCC+1
+// begin WITH_TAINT_TRACKING
+    bl      .LOP_REM_DOUBLE_taint_prop
+// end WITH_TAINT_TRACKING
     .if 0
     orrs    ip, r2, r3                  @ second arg (r2-r3) is zero?
     beq     common_errDivideByZero
@@ -5139,16 +5660,23 @@ dalvik_inst:
                                @ optional op; may set condition codes
     bl      fmod                              @ result<- op, r0-r3 changed
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    stmia   r9, {r0,r1}     @ vAA/vAA+1<- r0/r1
+// begin WITH_TAINT_TRACKING
+//    stmia   r9, {r0,r1}     @ vAA/vAA+1<- r0/r1
+    str     r0, [r9, #0]
+    str     r10, [r9, #4]
+    str     r1, [r9, #8]
+    str     r10, [r9, #12]
+// end WITH_TAINT_TRACKING
     GOTO_OPCODE(ip)                     @ jump to next instruction
     /* 14-17 instructions */
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_ADD_INT_2ADDR: /* 0xb0 */
-/* File: armv6t2/OP_ADD_INT_2ADDR.S */
-/* File: armv6t2/binop2addr.S */
+/* File: armv6t2_taint/OP_ADD_INT_2ADDR.S */
+/* File: armv6t2_taint/binop2addr.S */
     /*
      * Generic 32-bit "/2addr" binary operation.  Provide an "instr" line
      * that specifies an instruction that performs "result = r0 op r1".
@@ -5172,6 +5700,10 @@ dalvik_inst:
     cmp     r1, #0                      @ is second operand zero?
     beq     common_errDivideByZero
     .endif
+
+// begin WITH_TAINT_TRACKING
+    bl      .LOP_ADD_INT_2ADDR_taint_prop
+// end WITH_TAINT_TRACKING
     FETCH_ADVANCE_INST(1)               @ advance rPC, load rINST
 
                                @ optional op; may set condition codes
@@ -5182,11 +5714,12 @@ dalvik_inst:
     /* 10-13 instructions */
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_SUB_INT_2ADDR: /* 0xb1 */
-/* File: armv6t2/OP_SUB_INT_2ADDR.S */
-/* File: armv6t2/binop2addr.S */
+/* File: armv6t2_taint/OP_SUB_INT_2ADDR.S */
+/* File: armv6t2_taint/binop2addr.S */
     /*
      * Generic 32-bit "/2addr" binary operation.  Provide an "instr" line
      * that specifies an instruction that performs "result = r0 op r1".
@@ -5210,6 +5743,10 @@ dalvik_inst:
     cmp     r1, #0                      @ is second operand zero?
     beq     common_errDivideByZero
     .endif
+
+// begin WITH_TAINT_TRACKING
+    bl      .LOP_SUB_INT_2ADDR_taint_prop
+// end WITH_TAINT_TRACKING
     FETCH_ADVANCE_INST(1)               @ advance rPC, load rINST
 
                                @ optional op; may set condition codes
@@ -5220,12 +5757,13 @@ dalvik_inst:
     /* 10-13 instructions */
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_MUL_INT_2ADDR: /* 0xb2 */
-/* File: armv6t2/OP_MUL_INT_2ADDR.S */
+/* File: armv6t2_taint/OP_MUL_INT_2ADDR.S */
 /* must be "mul r0, r1, r0" -- "r0, r0, r1" is illegal */
-/* File: armv6t2/binop2addr.S */
+/* File: armv6t2_taint/binop2addr.S */
     /*
      * Generic 32-bit "/2addr" binary operation.  Provide an "instr" line
      * that specifies an instruction that performs "result = r0 op r1".
@@ -5249,6 +5787,10 @@ dalvik_inst:
     cmp     r1, #0                      @ is second operand zero?
     beq     common_errDivideByZero
     .endif
+
+// begin WITH_TAINT_TRACKING
+    bl      .LOP_MUL_INT_2ADDR_taint_prop
+// end WITH_TAINT_TRACKING
     FETCH_ADVANCE_INST(1)               @ advance rPC, load rINST
 
                                @ optional op; may set condition codes
@@ -5259,11 +5801,12 @@ dalvik_inst:
     /* 10-13 instructions */
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_DIV_INT_2ADDR: /* 0xb3 */
-/* File: armv6t2/OP_DIV_INT_2ADDR.S */
-/* File: armv6t2/binop2addr.S */
+/* File: armv6t2_taint/OP_DIV_INT_2ADDR.S */
+/* File: armv6t2_taint/binop2addr.S */
     /*
      * Generic 32-bit "/2addr" binary operation.  Provide an "instr" line
      * that specifies an instruction that performs "result = r0 op r1".
@@ -5287,6 +5830,10 @@ dalvik_inst:
     cmp     r1, #0                      @ is second operand zero?
     beq     common_errDivideByZero
     .endif
+
+// begin WITH_TAINT_TRACKING
+    bl      .LOP_DIV_INT_2ADDR_taint_prop
+// end WITH_TAINT_TRACKING
     FETCH_ADVANCE_INST(1)               @ advance rPC, load rINST
 
                                @ optional op; may set condition codes
@@ -5297,12 +5844,13 @@ dalvik_inst:
     /* 10-13 instructions */
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_REM_INT_2ADDR: /* 0xb4 */
-/* File: armv6t2/OP_REM_INT_2ADDR.S */
+/* File: armv6t2_taint/OP_REM_INT_2ADDR.S */
 /* idivmod returns quotient in r0 and remainder in r1 */
-/* File: armv6t2/binop2addr.S */
+/* File: armv6t2_taint/binop2addr.S */
     /*
      * Generic 32-bit "/2addr" binary operation.  Provide an "instr" line
      * that specifies an instruction that performs "result = r0 op r1".
@@ -5326,6 +5874,10 @@ dalvik_inst:
     cmp     r1, #0                      @ is second operand zero?
     beq     common_errDivideByZero
     .endif
+
+// begin WITH_TAINT_TRACKING
+    bl      .LOP_REM_INT_2ADDR_taint_prop
+// end WITH_TAINT_TRACKING
     FETCH_ADVANCE_INST(1)               @ advance rPC, load rINST
 
                                @ optional op; may set condition codes
@@ -5336,11 +5888,12 @@ dalvik_inst:
     /* 10-13 instructions */
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_AND_INT_2ADDR: /* 0xb5 */
-/* File: armv6t2/OP_AND_INT_2ADDR.S */
-/* File: armv6t2/binop2addr.S */
+/* File: armv6t2_taint/OP_AND_INT_2ADDR.S */
+/* File: armv6t2_taint/binop2addr.S */
     /*
      * Generic 32-bit "/2addr" binary operation.  Provide an "instr" line
      * that specifies an instruction that performs "result = r0 op r1".
@@ -5364,6 +5917,10 @@ dalvik_inst:
     cmp     r1, #0                      @ is second operand zero?
     beq     common_errDivideByZero
     .endif
+
+// begin WITH_TAINT_TRACKING
+    bl      .LOP_AND_INT_2ADDR_taint_prop
+// end WITH_TAINT_TRACKING
     FETCH_ADVANCE_INST(1)               @ advance rPC, load rINST
 
                                @ optional op; may set condition codes
@@ -5374,11 +5931,12 @@ dalvik_inst:
     /* 10-13 instructions */
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_OR_INT_2ADDR: /* 0xb6 */
-/* File: armv6t2/OP_OR_INT_2ADDR.S */
-/* File: armv6t2/binop2addr.S */
+/* File: armv6t2_taint/OP_OR_INT_2ADDR.S */
+/* File: armv6t2_taint/binop2addr.S */
     /*
      * Generic 32-bit "/2addr" binary operation.  Provide an "instr" line
      * that specifies an instruction that performs "result = r0 op r1".
@@ -5402,6 +5960,10 @@ dalvik_inst:
     cmp     r1, #0                      @ is second operand zero?
     beq     common_errDivideByZero
     .endif
+
+// begin WITH_TAINT_TRACKING
+    bl      .LOP_OR_INT_2ADDR_taint_prop
+// end WITH_TAINT_TRACKING
     FETCH_ADVANCE_INST(1)               @ advance rPC, load rINST
 
                                @ optional op; may set condition codes
@@ -5412,11 +5974,12 @@ dalvik_inst:
     /* 10-13 instructions */
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_XOR_INT_2ADDR: /* 0xb7 */
-/* File: armv6t2/OP_XOR_INT_2ADDR.S */
-/* File: armv6t2/binop2addr.S */
+/* File: armv6t2_taint/OP_XOR_INT_2ADDR.S */
+/* File: armv6t2_taint/binop2addr.S */
     /*
      * Generic 32-bit "/2addr" binary operation.  Provide an "instr" line
      * that specifies an instruction that performs "result = r0 op r1".
@@ -5440,6 +6003,10 @@ dalvik_inst:
     cmp     r1, #0                      @ is second operand zero?
     beq     common_errDivideByZero
     .endif
+
+// begin WITH_TAINT_TRACKING
+    bl      .LOP_XOR_INT_2ADDR_taint_prop
+// end WITH_TAINT_TRACKING
     FETCH_ADVANCE_INST(1)               @ advance rPC, load rINST
 
                                @ optional op; may set condition codes
@@ -5450,11 +6017,12 @@ dalvik_inst:
     /* 10-13 instructions */
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_SHL_INT_2ADDR: /* 0xb8 */
-/* File: armv6t2/OP_SHL_INT_2ADDR.S */
-/* File: armv6t2/binop2addr.S */
+/* File: armv6t2_taint/OP_SHL_INT_2ADDR.S */
+/* File: armv6t2_taint/binop2addr.S */
     /*
      * Generic 32-bit "/2addr" binary operation.  Provide an "instr" line
      * that specifies an instruction that performs "result = r0 op r1".
@@ -5478,6 +6046,10 @@ dalvik_inst:
     cmp     r1, #0                      @ is second operand zero?
     beq     common_errDivideByZero
     .endif
+
+// begin WITH_TAINT_TRACKING
+    bl      .LOP_SHL_INT_2ADDR_taint_prop
+// end WITH_TAINT_TRACKING
     FETCH_ADVANCE_INST(1)               @ advance rPC, load rINST
 
     and     r1, r1, #31                           @ optional op; may set condition codes
@@ -5488,11 +6060,12 @@ dalvik_inst:
     /* 10-13 instructions */
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_SHR_INT_2ADDR: /* 0xb9 */
-/* File: armv6t2/OP_SHR_INT_2ADDR.S */
-/* File: armv6t2/binop2addr.S */
+/* File: armv6t2_taint/OP_SHR_INT_2ADDR.S */
+/* File: armv6t2_taint/binop2addr.S */
     /*
      * Generic 32-bit "/2addr" binary operation.  Provide an "instr" line
      * that specifies an instruction that performs "result = r0 op r1".
@@ -5516,6 +6089,10 @@ dalvik_inst:
     cmp     r1, #0                      @ is second operand zero?
     beq     common_errDivideByZero
     .endif
+
+// begin WITH_TAINT_TRACKING
+    bl      .LOP_SHR_INT_2ADDR_taint_prop
+// end WITH_TAINT_TRACKING
     FETCH_ADVANCE_INST(1)               @ advance rPC, load rINST
 
     and     r1, r1, #31                           @ optional op; may set condition codes
@@ -5526,11 +6103,12 @@ dalvik_inst:
     /* 10-13 instructions */
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_USHR_INT_2ADDR: /* 0xba */
-/* File: armv6t2/OP_USHR_INT_2ADDR.S */
-/* File: armv6t2/binop2addr.S */
+/* File: armv6t2_taint/OP_USHR_INT_2ADDR.S */
+/* File: armv6t2_taint/binop2addr.S */
     /*
      * Generic 32-bit "/2addr" binary operation.  Provide an "instr" line
      * that specifies an instruction that performs "result = r0 op r1".
@@ -5554,6 +6132,10 @@ dalvik_inst:
     cmp     r1, #0                      @ is second operand zero?
     beq     common_errDivideByZero
     .endif
+
+// begin WITH_TAINT_TRACKING
+    bl      .LOP_USHR_INT_2ADDR_taint_prop
+// end WITH_TAINT_TRACKING
     FETCH_ADVANCE_INST(1)               @ advance rPC, load rINST
 
     and     r1, r1, #31                           @ optional op; may set condition codes
@@ -5564,11 +6146,12 @@ dalvik_inst:
     /* 10-13 instructions */
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_ADD_LONG_2ADDR: /* 0xbb */
-/* File: armv6t2/OP_ADD_LONG_2ADDR.S */
-/* File: armv6t2/binopWide2addr.S */
+/* File: armv6t2_taint/OP_ADD_LONG_2ADDR.S */
+/* File: armv6t2_taint/binopWide2addr.S */
     /*
      * Generic 64-bit "/2addr" binary operation.  Provide an "instr" line
      * that specifies an instruction that performs "result = r0-r1 op r2-r3".
@@ -5586,10 +6169,9 @@ dalvik_inst:
     /* binop/2addr vA, vB */
     mov     r1, rINST, lsr #12          @ r1<- B
     ubfx    r9, rINST, #8, #4           @ r9<- A
-    add     r1, rFP, r1, lsl #2         @ r1<- &fp[B]
-    add     r9, rFP, r9, lsl #2         @ r9<- &fp[A]
-    ldmia   r1, {r2-r3}                 @ r2/r3<- vBB/vBB+1
-    ldmia   r9, {r0-r1}                 @ r0/r1<- vAA/vAA+1
+// begin WITH_TAINT_TRACKING
+    bl     .LOP_ADD_LONG_2ADDR_taint_prop
+// end WITH_TAINT_TRACKING
     .if 0
     orrs    ip, r2, r3                  @ second arg (r2-r3) is zero?
     beq     common_errDivideByZero
@@ -5599,16 +6181,23 @@ dalvik_inst:
     adds    r0, r0, r2                           @ optional op; may set condition codes
     adc     r1, r1, r3                              @ result<- op, r0-r3 changed
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    stmia   r9, {r0,r1}     @ vAA/vAA+1<- r0/r1
+// begin WITH_TAINT_TRACKING
+//    stmia   r9, {r0,r1}     @ vAA/vAA+1<- r0/r1
+    str     r0, [r9, #0]
+    str     r10, [r9, #4]
+    str     r1, [r9, #8]
+    str     r10, [r9, #12]
+// end WITH_TAINT_TRACKING
     GOTO_OPCODE(ip)                     @ jump to next instruction
     /* 12-15 instructions */
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_SUB_LONG_2ADDR: /* 0xbc */
-/* File: armv6t2/OP_SUB_LONG_2ADDR.S */
-/* File: armv6t2/binopWide2addr.S */
+/* File: armv6t2_taint/OP_SUB_LONG_2ADDR.S */
+/* File: armv6t2_taint/binopWide2addr.S */
     /*
      * Generic 64-bit "/2addr" binary operation.  Provide an "instr" line
      * that specifies an instruction that performs "result = r0-r1 op r2-r3".
@@ -5626,10 +6215,9 @@ dalvik_inst:
     /* binop/2addr vA, vB */
     mov     r1, rINST, lsr #12          @ r1<- B
     ubfx    r9, rINST, #8, #4           @ r9<- A
-    add     r1, rFP, r1, lsl #2         @ r1<- &fp[B]
-    add     r9, rFP, r9, lsl #2         @ r9<- &fp[A]
-    ldmia   r1, {r2-r3}                 @ r2/r3<- vBB/vBB+1
-    ldmia   r9, {r0-r1}                 @ r0/r1<- vAA/vAA+1
+// begin WITH_TAINT_TRACKING
+    bl     .LOP_SUB_LONG_2ADDR_taint_prop
+// end WITH_TAINT_TRACKING
     .if 0
     orrs    ip, r2, r3                  @ second arg (r2-r3) is zero?
     beq     common_errDivideByZero
@@ -5639,15 +6227,22 @@ dalvik_inst:
     subs    r0, r0, r2                           @ optional op; may set condition codes
     sbc     r1, r1, r3                              @ result<- op, r0-r3 changed
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    stmia   r9, {r0,r1}     @ vAA/vAA+1<- r0/r1
+// begin WITH_TAINT_TRACKING
+//    stmia   r9, {r0,r1}     @ vAA/vAA+1<- r0/r1
+    str     r0, [r9, #0]
+    str     r10, [r9, #4]
+    str     r1, [r9, #8]
+    str     r10, [r9, #12]
+// end WITH_TAINT_TRACKING
     GOTO_OPCODE(ip)                     @ jump to next instruction
     /* 12-15 instructions */
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_MUL_LONG_2ADDR: /* 0xbd */
-/* File: armv6t2/OP_MUL_LONG_2ADDR.S */
+/* File: armv6t2_taint/OP_MUL_LONG_2ADDR.S */
     /*
      * Signed 64-bit integer multiply, "/2addr" version.
      *
@@ -5658,26 +6253,31 @@ dalvik_inst:
      */
     /* mul-long/2addr vA, vB */
     mov     r1, rINST, lsr #12          @ r1<- B
-    ubfx    r9, rINST, #8, #4           @ r9<- A
-    add     r1, rFP, r1, lsl #2         @ r1<- &fp[B]
-    add     rINST, rFP, r9, lsl #2      @ rINST<- &fp[A]
-    ldmia   r1, {r2-r3}                 @ r2/r3<- vBB/vBB+1
-    ldmia   rINST, {r0-r1}              @ r0/r1<- vAA/vAA+1
-    mul     ip, r2, r1                  @  ip<- ZxW
+// begin WITH_TAINT_TRACKING
+    bl      mul_long_2addr_taint_prop
+// end WITH_TAINT_TRACKING
     umull   r9, r10, r2, r0             @  r9/r10 <- ZxX
     mla     r2, r0, r3, ip              @  r2<- YxX + (ZxW)
     mov     r0, rINST                   @ r0<- &fp[A] (free up rINST)
     FETCH_ADVANCE_INST(1)               @ advance rPC, load rINST
     add     r10, r2, r10                @  r10<- r10 + low(ZxW + (YxX))
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    stmia   r0, {r9-r10}                @ vAA/vAA+1<- r9/r10
+// begin WITH_TAINT_TRACKING
+//    stmia   r0, {r9-r10}                @ vAA/vAA+1<- r9/r10
+    str     r9, [r0, #0]
+    str     r10, [r0, #8]
+    str     r10, [r0, #12]
+    ldmfd   sp!, {r10}
+    str     r10, [r0, #4]
+// end WITH_TAINT_TRACKING
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_DIV_LONG_2ADDR: /* 0xbe */
-/* File: armv6t2/OP_DIV_LONG_2ADDR.S */
-/* File: armv6t2/binopWide2addr.S */
+/* File: armv6t2_taint/OP_DIV_LONG_2ADDR.S */
+/* File: armv6t2_taint/binopWide2addr.S */
     /*
      * Generic 64-bit "/2addr" binary operation.  Provide an "instr" line
      * that specifies an instruction that performs "result = r0-r1 op r2-r3".
@@ -5695,10 +6295,9 @@ dalvik_inst:
     /* binop/2addr vA, vB */
     mov     r1, rINST, lsr #12          @ r1<- B
     ubfx    r9, rINST, #8, #4           @ r9<- A
-    add     r1, rFP, r1, lsl #2         @ r1<- &fp[B]
-    add     r9, rFP, r9, lsl #2         @ r9<- &fp[A]
-    ldmia   r1, {r2-r3}                 @ r2/r3<- vBB/vBB+1
-    ldmia   r9, {r0-r1}                 @ r0/r1<- vAA/vAA+1
+// begin WITH_TAINT_TRACKING
+    bl     .LOP_DIV_LONG_2ADDR_taint_prop
+// end WITH_TAINT_TRACKING
     .if 1
     orrs    ip, r2, r3                  @ second arg (r2-r3) is zero?
     beq     common_errDivideByZero
@@ -5708,17 +6307,24 @@ dalvik_inst:
                                @ optional op; may set condition codes
     bl      __aeabi_ldivmod                              @ result<- op, r0-r3 changed
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    stmia   r9, {r0,r1}     @ vAA/vAA+1<- r0/r1
+// begin WITH_TAINT_TRACKING
+//    stmia   r9, {r0,r1}     @ vAA/vAA+1<- r0/r1
+    str     r0, [r9, #0]
+    str     r10, [r9, #4]
+    str     r1, [r9, #8]
+    str     r10, [r9, #12]
+// end WITH_TAINT_TRACKING
     GOTO_OPCODE(ip)                     @ jump to next instruction
     /* 12-15 instructions */
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_REM_LONG_2ADDR: /* 0xbf */
-/* File: armv6t2/OP_REM_LONG_2ADDR.S */
+/* File: armv6t2_taint/OP_REM_LONG_2ADDR.S */
 /* ldivmod returns quotient in r0/r1 and remainder in r2/r3 */
-/* File: armv6t2/binopWide2addr.S */
+/* File: armv6t2_taint/binopWide2addr.S */
     /*
      * Generic 64-bit "/2addr" binary operation.  Provide an "instr" line
      * that specifies an instruction that performs "result = r0-r1 op r2-r3".
@@ -5736,10 +6342,9 @@ dalvik_inst:
     /* binop/2addr vA, vB */
     mov     r1, rINST, lsr #12          @ r1<- B
     ubfx    r9, rINST, #8, #4           @ r9<- A
-    add     r1, rFP, r1, lsl #2         @ r1<- &fp[B]
-    add     r9, rFP, r9, lsl #2         @ r9<- &fp[A]
-    ldmia   r1, {r2-r3}                 @ r2/r3<- vBB/vBB+1
-    ldmia   r9, {r0-r1}                 @ r0/r1<- vAA/vAA+1
+// begin WITH_TAINT_TRACKING
+    bl     .LOP_REM_LONG_2ADDR_taint_prop
+// end WITH_TAINT_TRACKING
     .if 1
     orrs    ip, r2, r3                  @ second arg (r2-r3) is zero?
     beq     common_errDivideByZero
@@ -5749,16 +6354,23 @@ dalvik_inst:
                                @ optional op; may set condition codes
     bl      __aeabi_ldivmod                              @ result<- op, r0-r3 changed
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    stmia   r9, {r2,r3}     @ vAA/vAA+1<- r2/r3
+// begin WITH_TAINT_TRACKING
+//    stmia   r9, {r2,r3}     @ vAA/vAA+1<- r2/r3
+    str     r2, [r9, #0]
+    str     r10, [r9, #4]
+    str     r3, [r9, #8]
+    str     r10, [r9, #12]
+// end WITH_TAINT_TRACKING
     GOTO_OPCODE(ip)                     @ jump to next instruction
     /* 12-15 instructions */
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_AND_LONG_2ADDR: /* 0xc0 */
-/* File: armv6t2/OP_AND_LONG_2ADDR.S */
-/* File: armv6t2/binopWide2addr.S */
+/* File: armv6t2_taint/OP_AND_LONG_2ADDR.S */
+/* File: armv6t2_taint/binopWide2addr.S */
     /*
      * Generic 64-bit "/2addr" binary operation.  Provide an "instr" line
      * that specifies an instruction that performs "result = r0-r1 op r2-r3".
@@ -5776,10 +6388,9 @@ dalvik_inst:
     /* binop/2addr vA, vB */
     mov     r1, rINST, lsr #12          @ r1<- B
     ubfx    r9, rINST, #8, #4           @ r9<- A
-    add     r1, rFP, r1, lsl #2         @ r1<- &fp[B]
-    add     r9, rFP, r9, lsl #2         @ r9<- &fp[A]
-    ldmia   r1, {r2-r3}                 @ r2/r3<- vBB/vBB+1
-    ldmia   r9, {r0-r1}                 @ r0/r1<- vAA/vAA+1
+// begin WITH_TAINT_TRACKING
+    bl     .LOP_AND_LONG_2ADDR_taint_prop
+// end WITH_TAINT_TRACKING
     .if 0
     orrs    ip, r2, r3                  @ second arg (r2-r3) is zero?
     beq     common_errDivideByZero
@@ -5789,16 +6400,23 @@ dalvik_inst:
     and     r0, r0, r2                           @ optional op; may set condition codes
     and     r1, r1, r3                              @ result<- op, r0-r3 changed
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    stmia   r9, {r0,r1}     @ vAA/vAA+1<- r0/r1
+// begin WITH_TAINT_TRACKING
+//    stmia   r9, {r0,r1}     @ vAA/vAA+1<- r0/r1
+    str     r0, [r9, #0]
+    str     r10, [r9, #4]
+    str     r1, [r9, #8]
+    str     r10, [r9, #12]
+// end WITH_TAINT_TRACKING
     GOTO_OPCODE(ip)                     @ jump to next instruction
     /* 12-15 instructions */
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_OR_LONG_2ADDR: /* 0xc1 */
-/* File: armv6t2/OP_OR_LONG_2ADDR.S */
-/* File: armv6t2/binopWide2addr.S */
+/* File: armv6t2_taint/OP_OR_LONG_2ADDR.S */
+/* File: armv6t2_taint/binopWide2addr.S */
     /*
      * Generic 64-bit "/2addr" binary operation.  Provide an "instr" line
      * that specifies an instruction that performs "result = r0-r1 op r2-r3".
@@ -5816,10 +6434,9 @@ dalvik_inst:
     /* binop/2addr vA, vB */
     mov     r1, rINST, lsr #12          @ r1<- B
     ubfx    r9, rINST, #8, #4           @ r9<- A
-    add     r1, rFP, r1, lsl #2         @ r1<- &fp[B]
-    add     r9, rFP, r9, lsl #2         @ r9<- &fp[A]
-    ldmia   r1, {r2-r3}                 @ r2/r3<- vBB/vBB+1
-    ldmia   r9, {r0-r1}                 @ r0/r1<- vAA/vAA+1
+// begin WITH_TAINT_TRACKING
+    bl     .LOP_OR_LONG_2ADDR_taint_prop
+// end WITH_TAINT_TRACKING
     .if 0
     orrs    ip, r2, r3                  @ second arg (r2-r3) is zero?
     beq     common_errDivideByZero
@@ -5829,16 +6446,23 @@ dalvik_inst:
     orr     r0, r0, r2                           @ optional op; may set condition codes
     orr     r1, r1, r3                              @ result<- op, r0-r3 changed
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    stmia   r9, {r0,r1}     @ vAA/vAA+1<- r0/r1
+// begin WITH_TAINT_TRACKING
+//    stmia   r9, {r0,r1}     @ vAA/vAA+1<- r0/r1
+    str     r0, [r9, #0]
+    str     r10, [r9, #4]
+    str     r1, [r9, #8]
+    str     r10, [r9, #12]
+// end WITH_TAINT_TRACKING
     GOTO_OPCODE(ip)                     @ jump to next instruction
     /* 12-15 instructions */
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_XOR_LONG_2ADDR: /* 0xc2 */
-/* File: armv6t2/OP_XOR_LONG_2ADDR.S */
-/* File: armv6t2/binopWide2addr.S */
+/* File: armv6t2_taint/OP_XOR_LONG_2ADDR.S */
+/* File: armv6t2_taint/binopWide2addr.S */
     /*
      * Generic 64-bit "/2addr" binary operation.  Provide an "instr" line
      * that specifies an instruction that performs "result = r0-r1 op r2-r3".
@@ -5856,10 +6480,9 @@ dalvik_inst:
     /* binop/2addr vA, vB */
     mov     r1, rINST, lsr #12          @ r1<- B
     ubfx    r9, rINST, #8, #4           @ r9<- A
-    add     r1, rFP, r1, lsl #2         @ r1<- &fp[B]
-    add     r9, rFP, r9, lsl #2         @ r9<- &fp[A]
-    ldmia   r1, {r2-r3}                 @ r2/r3<- vBB/vBB+1
-    ldmia   r9, {r0-r1}                 @ r0/r1<- vAA/vAA+1
+// begin WITH_TAINT_TRACKING
+    bl     .LOP_XOR_LONG_2ADDR_taint_prop
+// end WITH_TAINT_TRACKING
     .if 0
     orrs    ip, r2, r3                  @ second arg (r2-r3) is zero?
     beq     common_errDivideByZero
@@ -5869,15 +6492,22 @@ dalvik_inst:
     eor     r0, r0, r2                           @ optional op; may set condition codes
     eor     r1, r1, r3                              @ result<- op, r0-r3 changed
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    stmia   r9, {r0,r1}     @ vAA/vAA+1<- r0/r1
+// begin WITH_TAINT_TRACKING
+//    stmia   r9, {r0,r1}     @ vAA/vAA+1<- r0/r1
+    str     r0, [r9, #0]
+    str     r10, [r9, #4]
+    str     r1, [r9, #8]
+    str     r10, [r9, #12]
+// end WITH_TAINT_TRACKING
     GOTO_OPCODE(ip)                     @ jump to next instruction
     /* 12-15 instructions */
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_SHL_LONG_2ADDR: /* 0xc3 */
-/* File: armv6t2/OP_SHL_LONG_2ADDR.S */
+/* File: armv6t2_taint/OP_SHL_LONG_2ADDR.S */
     /*
      * Long integer shift, 2addr version.  vA is 64-bit value/result, vB is
      * 32-bit shift distance.
@@ -5886,9 +6516,9 @@ dalvik_inst:
     mov     r3, rINST, lsr #12          @ r3<- B
     ubfx    r9, rINST, #8, #4           @ r9<- A
     GET_VREG(r2, r3)                    @ r2<- vB
-    add     r9, rFP, r9, lsl #2         @ r9<- &fp[A]
-    and     r2, r2, #63                 @ r2<- r2 & 0x3f
-    ldmia   r9, {r0-r1}                 @ r0/r1<- vAA/vAA+1
+// begin WITH_TAINT_TRACKING
+    bl      shl_long_2addr_taint_prop
+// end WITH_TAINT_TRACKING
 
     mov     r1, r1, asl r2              @  r1<- r1 << r2
     rsb     r3, r2, #32                 @  r3<- 32 - r2
@@ -5902,7 +6532,7 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_SHR_LONG_2ADDR: /* 0xc4 */
-/* File: armv6t2/OP_SHR_LONG_2ADDR.S */
+/* File: armv6t2_taint/OP_SHR_LONG_2ADDR.S */
     /*
      * Long integer shift, 2addr version.  vA is 64-bit value/result, vB is
      * 32-bit shift distance.
@@ -5911,9 +6541,9 @@ dalvik_inst:
     mov     r3, rINST, lsr #12          @ r3<- B
     ubfx    r9, rINST, #8, #4           @ r9<- A
     GET_VREG(r2, r3)                    @ r2<- vB
-    add     r9, rFP, r9, lsl #2         @ r9<- &fp[A]
-    and     r2, r2, #63                 @ r2<- r2 & 0x3f
-    ldmia   r9, {r0-r1}                 @ r0/r1<- vAA/vAA+1
+// begin WITH_TAINT_TRACKING
+    bl      shr_long_2addr_taint_prop
+// end WITH_TAINT_TRACKING
 
     mov     r0, r0, lsr r2              @  r0<- r2 >> r2
     rsb     r3, r2, #32                 @  r3<- 32 - r2
@@ -5927,7 +6557,7 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_USHR_LONG_2ADDR: /* 0xc5 */
-/* File: armv6t2/OP_USHR_LONG_2ADDR.S */
+/* File: armv6t2_taint/OP_USHR_LONG_2ADDR.S */
     /*
      * Long integer shift, 2addr version.  vA is 64-bit value/result, vB is
      * 32-bit shift distance.
@@ -5936,9 +6566,9 @@ dalvik_inst:
     mov     r3, rINST, lsr #12          @ r3<- B
     ubfx    r9, rINST, #8, #4           @ r9<- A
     GET_VREG(r2, r3)                    @ r2<- vB
-    add     r9, rFP, r9, lsl #2         @ r9<- &fp[A]
-    and     r2, r2, #63                 @ r2<- r2 & 0x3f
-    ldmia   r9, {r0-r1}                 @ r0/r1<- vAA/vAA+1
+// begin WITH_TAINT_TRACKING
+    bl      ushr_long_2addr_taint_prop
+// end WITH_TAINT_TRACKING
 
     mov     r0, r0, lsr r2              @  r0<- r2 >> r2
     rsb     r3, r2, #32                 @  r3<- 32 - r2
@@ -5952,8 +6582,8 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_ADD_FLOAT_2ADDR: /* 0xc6 */
-/* File: arm-vfp/OP_ADD_FLOAT_2ADDR.S */
-/* File: arm-vfp/fbinop2addr.S */
+/* File: arm-vfp_taint/OP_ADD_FLOAT_2ADDR.S */
+/* File: arm-vfp_taint/fbinop2addr.S */
     /*
      * Generic 32-bit floating point "/2addr" binary operation.  Provide
      * an "instr" line that specifies an instruction that performs
@@ -5967,21 +6597,24 @@ dalvik_inst:
     VREG_INDEX_TO_ADDR(r3, r3)          @ r3<- &vB
     and     r9, r9, #15                 @ r9<- A
     flds    s1, [r3]                    @ s1<- vB
+// begin WITH_TAINT_TRACKING
+    ldr     r0, [r3, #4]
+// end WITH_TAINT_TRACKING
     VREG_INDEX_TO_ADDR(r9, r9)          @ r9<- &vA
     FETCH_ADVANCE_INST(1)               @ advance rPC, load rINST
     flds    s0, [r9]                    @ s0<- vA
-
-    fadds   s2, s0, s1                              @ s2<- op
-    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    fsts    s2, [r9]                    @ vAA<- s2
-    GOTO_OPCODE(ip)                     @ jump to next instruction
+// begin WITH_TAINT_TRACKING
+    ldr     r1, [r9, #4]
+    orr     r0, r0, r1
+// end WITH_TAINT_TRACKING
+    b       .LOP_ADD_FLOAT_2ADDR_finish
 
 
 /* ------------------------------ */
     .balign 64
 .L_OP_SUB_FLOAT_2ADDR: /* 0xc7 */
-/* File: arm-vfp/OP_SUB_FLOAT_2ADDR.S */
-/* File: arm-vfp/fbinop2addr.S */
+/* File: arm-vfp_taint/OP_SUB_FLOAT_2ADDR.S */
+/* File: arm-vfp_taint/fbinop2addr.S */
     /*
      * Generic 32-bit floating point "/2addr" binary operation.  Provide
      * an "instr" line that specifies an instruction that performs
@@ -5995,21 +6628,24 @@ dalvik_inst:
     VREG_INDEX_TO_ADDR(r3, r3)          @ r3<- &vB
     and     r9, r9, #15                 @ r9<- A
     flds    s1, [r3]                    @ s1<- vB
+// begin WITH_TAINT_TRACKING
+    ldr     r0, [r3, #4]
+// end WITH_TAINT_TRACKING
     VREG_INDEX_TO_ADDR(r9, r9)          @ r9<- &vA
     FETCH_ADVANCE_INST(1)               @ advance rPC, load rINST
     flds    s0, [r9]                    @ s0<- vA
-
-    fsubs   s2, s0, s1                              @ s2<- op
-    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    fsts    s2, [r9]                    @ vAA<- s2
-    GOTO_OPCODE(ip)                     @ jump to next instruction
+// begin WITH_TAINT_TRACKING
+    ldr     r1, [r9, #4]
+    orr     r0, r0, r1
+// end WITH_TAINT_TRACKING
+    b       .LOP_SUB_FLOAT_2ADDR_finish
 
 
 /* ------------------------------ */
     .balign 64
 .L_OP_MUL_FLOAT_2ADDR: /* 0xc8 */
-/* File: arm-vfp/OP_MUL_FLOAT_2ADDR.S */
-/* File: arm-vfp/fbinop2addr.S */
+/* File: arm-vfp_taint/OP_MUL_FLOAT_2ADDR.S */
+/* File: arm-vfp_taint/fbinop2addr.S */
     /*
      * Generic 32-bit floating point "/2addr" binary operation.  Provide
      * an "instr" line that specifies an instruction that performs
@@ -6023,21 +6659,24 @@ dalvik_inst:
     VREG_INDEX_TO_ADDR(r3, r3)          @ r3<- &vB
     and     r9, r9, #15                 @ r9<- A
     flds    s1, [r3]                    @ s1<- vB
+// begin WITH_TAINT_TRACKING
+    ldr     r0, [r3, #4]
+// end WITH_TAINT_TRACKING
     VREG_INDEX_TO_ADDR(r9, r9)          @ r9<- &vA
     FETCH_ADVANCE_INST(1)               @ advance rPC, load rINST
     flds    s0, [r9]                    @ s0<- vA
-
-    fmuls   s2, s0, s1                              @ s2<- op
-    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    fsts    s2, [r9]                    @ vAA<- s2
-    GOTO_OPCODE(ip)                     @ jump to next instruction
+// begin WITH_TAINT_TRACKING
+    ldr     r1, [r9, #4]
+    orr     r0, r0, r1
+// end WITH_TAINT_TRACKING
+    b       .LOP_MUL_FLOAT_2ADDR_finish
 
 
 /* ------------------------------ */
     .balign 64
 .L_OP_DIV_FLOAT_2ADDR: /* 0xc9 */
-/* File: arm-vfp/OP_DIV_FLOAT_2ADDR.S */
-/* File: arm-vfp/fbinop2addr.S */
+/* File: arm-vfp_taint/OP_DIV_FLOAT_2ADDR.S */
+/* File: arm-vfp_taint/fbinop2addr.S */
     /*
      * Generic 32-bit floating point "/2addr" binary operation.  Provide
      * an "instr" line that specifies an instruction that performs
@@ -6051,22 +6690,25 @@ dalvik_inst:
     VREG_INDEX_TO_ADDR(r3, r3)          @ r3<- &vB
     and     r9, r9, #15                 @ r9<- A
     flds    s1, [r3]                    @ s1<- vB
+// begin WITH_TAINT_TRACKING
+    ldr     r0, [r3, #4]
+// end WITH_TAINT_TRACKING
     VREG_INDEX_TO_ADDR(r9, r9)          @ r9<- &vA
     FETCH_ADVANCE_INST(1)               @ advance rPC, load rINST
     flds    s0, [r9]                    @ s0<- vA
-
-    fdivs   s2, s0, s1                              @ s2<- op
-    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    fsts    s2, [r9]                    @ vAA<- s2
-    GOTO_OPCODE(ip)                     @ jump to next instruction
+// begin WITH_TAINT_TRACKING
+    ldr     r1, [r9, #4]
+    orr     r0, r0, r1
+// end WITH_TAINT_TRACKING
+    b       .LOP_DIV_FLOAT_2ADDR_finish
 
 
 /* ------------------------------ */
     .balign 64
 .L_OP_REM_FLOAT_2ADDR: /* 0xca */
-/* File: armv6t2/OP_REM_FLOAT_2ADDR.S */
+/* File: armv6t2_taint/OP_REM_FLOAT_2ADDR.S */
 /* EABI doesn't define a float remainder function, but libm does */
-/* File: armv6t2/binop2addr.S */
+/* File: armv6t2_taint/binop2addr.S */
     /*
      * Generic 32-bit "/2addr" binary operation.  Provide an "instr" line
      * that specifies an instruction that performs "result = r0 op r1".
@@ -6090,6 +6732,10 @@ dalvik_inst:
     cmp     r1, #0                      @ is second operand zero?
     beq     common_errDivideByZero
     .endif
+
+// begin WITH_TAINT_TRACKING
+    bl      .LOP_REM_FLOAT_2ADDR_taint_prop
+// end WITH_TAINT_TRACKING
     FETCH_ADVANCE_INST(1)               @ advance rPC, load rINST
 
                                @ optional op; may set condition codes
@@ -6100,11 +6746,12 @@ dalvik_inst:
     /* 10-13 instructions */
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_ADD_DOUBLE_2ADDR: /* 0xcb */
-/* File: arm-vfp/OP_ADD_DOUBLE_2ADDR.S */
-/* File: arm-vfp/fbinopWide2addr.S */
+/* File: arm-vfp_taint/OP_ADD_DOUBLE_2ADDR.S */
+/* File: arm-vfp_taint/fbinopWide2addr.S */
     /*
      * Generic 64-bit floating point "/2addr" binary operation.  Provide
      * an "instr" line that specifies an instruction that performs
@@ -6118,22 +6765,28 @@ dalvik_inst:
     mov     r9, rINST, lsr #8           @ r9<- A+
     VREG_INDEX_TO_ADDR(r3, r3)          @ r3<- &vB
     and     r9, r9, #15                 @ r9<- A
-    fldd    d1, [r3]                    @ d1<- vB
+// begin WITH_TAINT_TRACKING
+//    fldd    d1, [r3]                    @ d1<- vB
+    flds    s2, [r3]
+    flds    s3, [r3, #8]
+    ldr     r0, [r3, #4]
+// end WITH_TAINT_TRACKING
     VREG_INDEX_TO_ADDR(r9, r9)          @ r9<- &vA
     FETCH_ADVANCE_INST(1)               @ advance rPC, load rINST
-    fldd    d0, [r9]                    @ d0<- vA
-
-    faddd   d2, d0, d1                              @ d2<- op
-    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    fstd    d2, [r9]                    @ vAA<- d2
-    GOTO_OPCODE(ip)                     @ jump to next instruction
+// begin WITH_TAINT_TRACKING
+//    fldd    d0, [r9]                    @ d0<- vA
+    flds    s0, [r9]
+    flds    s1, [r9, #8]
+    ldr     r1, [r9, #4]
+// end WITH_TAINT_TRACKING
+    b     .LOP_ADD_DOUBLE_2ADDR_finish
 
 
 /* ------------------------------ */
     .balign 64
 .L_OP_SUB_DOUBLE_2ADDR: /* 0xcc */
-/* File: arm-vfp/OP_SUB_DOUBLE_2ADDR.S */
-/* File: arm-vfp/fbinopWide2addr.S */
+/* File: arm-vfp_taint/OP_SUB_DOUBLE_2ADDR.S */
+/* File: arm-vfp_taint/fbinopWide2addr.S */
     /*
      * Generic 64-bit floating point "/2addr" binary operation.  Provide
      * an "instr" line that specifies an instruction that performs
@@ -6147,22 +6800,28 @@ dalvik_inst:
     mov     r9, rINST, lsr #8           @ r9<- A+
     VREG_INDEX_TO_ADDR(r3, r3)          @ r3<- &vB
     and     r9, r9, #15                 @ r9<- A
-    fldd    d1, [r3]                    @ d1<- vB
+// begin WITH_TAINT_TRACKING
+//    fldd    d1, [r3]                    @ d1<- vB
+    flds    s2, [r3]
+    flds    s3, [r3, #8]
+    ldr     r0, [r3, #4]
+// end WITH_TAINT_TRACKING
     VREG_INDEX_TO_ADDR(r9, r9)          @ r9<- &vA
     FETCH_ADVANCE_INST(1)               @ advance rPC, load rINST
-    fldd    d0, [r9]                    @ d0<- vA
-
-    fsubd   d2, d0, d1                              @ d2<- op
-    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    fstd    d2, [r9]                    @ vAA<- d2
-    GOTO_OPCODE(ip)                     @ jump to next instruction
+// begin WITH_TAINT_TRACKING
+//    fldd    d0, [r9]                    @ d0<- vA
+    flds    s0, [r9]
+    flds    s1, [r9, #8]
+    ldr     r1, [r9, #4]
+// end WITH_TAINT_TRACKING
+    b     .LOP_SUB_DOUBLE_2ADDR_finish
 
 
 /* ------------------------------ */
     .balign 64
 .L_OP_MUL_DOUBLE_2ADDR: /* 0xcd */
-/* File: arm-vfp/OP_MUL_DOUBLE_2ADDR.S */
-/* File: arm-vfp/fbinopWide2addr.S */
+/* File: arm-vfp_taint/OP_MUL_DOUBLE_2ADDR.S */
+/* File: arm-vfp_taint/fbinopWide2addr.S */
     /*
      * Generic 64-bit floating point "/2addr" binary operation.  Provide
      * an "instr" line that specifies an instruction that performs
@@ -6176,22 +6835,28 @@ dalvik_inst:
     mov     r9, rINST, lsr #8           @ r9<- A+
     VREG_INDEX_TO_ADDR(r3, r3)          @ r3<- &vB
     and     r9, r9, #15                 @ r9<- A
-    fldd    d1, [r3]                    @ d1<- vB
+// begin WITH_TAINT_TRACKING
+//    fldd    d1, [r3]                    @ d1<- vB
+    flds    s2, [r3]
+    flds    s3, [r3, #8]
+    ldr     r0, [r3, #4]
+// end WITH_TAINT_TRACKING
     VREG_INDEX_TO_ADDR(r9, r9)          @ r9<- &vA
     FETCH_ADVANCE_INST(1)               @ advance rPC, load rINST
-    fldd    d0, [r9]                    @ d0<- vA
-
-    fmuld   d2, d0, d1                              @ d2<- op
-    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    fstd    d2, [r9]                    @ vAA<- d2
-    GOTO_OPCODE(ip)                     @ jump to next instruction
+// begin WITH_TAINT_TRACKING
+//    fldd    d0, [r9]                    @ d0<- vA
+    flds    s0, [r9]
+    flds    s1, [r9, #8]
+    ldr     r1, [r9, #4]
+// end WITH_TAINT_TRACKING
+    b     .LOP_MUL_DOUBLE_2ADDR_finish
 
 
 /* ------------------------------ */
     .balign 64
 .L_OP_DIV_DOUBLE_2ADDR: /* 0xce */
-/* File: arm-vfp/OP_DIV_DOUBLE_2ADDR.S */
-/* File: arm-vfp/fbinopWide2addr.S */
+/* File: arm-vfp_taint/OP_DIV_DOUBLE_2ADDR.S */
+/* File: arm-vfp_taint/fbinopWide2addr.S */
     /*
      * Generic 64-bit floating point "/2addr" binary operation.  Provide
      * an "instr" line that specifies an instruction that performs
@@ -6205,23 +6870,29 @@ dalvik_inst:
     mov     r9, rINST, lsr #8           @ r9<- A+
     VREG_INDEX_TO_ADDR(r3, r3)          @ r3<- &vB
     and     r9, r9, #15                 @ r9<- A
-    fldd    d1, [r3]                    @ d1<- vB
+// begin WITH_TAINT_TRACKING
+//    fldd    d1, [r3]                    @ d1<- vB
+    flds    s2, [r3]
+    flds    s3, [r3, #8]
+    ldr     r0, [r3, #4]
+// end WITH_TAINT_TRACKING
     VREG_INDEX_TO_ADDR(r9, r9)          @ r9<- &vA
     FETCH_ADVANCE_INST(1)               @ advance rPC, load rINST
-    fldd    d0, [r9]                    @ d0<- vA
-
-    fdivd   d2, d0, d1                              @ d2<- op
-    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    fstd    d2, [r9]                    @ vAA<- d2
-    GOTO_OPCODE(ip)                     @ jump to next instruction
+// begin WITH_TAINT_TRACKING
+//    fldd    d0, [r9]                    @ d0<- vA
+    flds    s0, [r9]
+    flds    s1, [r9, #8]
+    ldr     r1, [r9, #4]
+// end WITH_TAINT_TRACKING
+    b     .LOP_DIV_DOUBLE_2ADDR_finish
 
 
 /* ------------------------------ */
     .balign 64
 .L_OP_REM_DOUBLE_2ADDR: /* 0xcf */
-/* File: armv6t2/OP_REM_DOUBLE_2ADDR.S */
+/* File: armv6t2_taint/OP_REM_DOUBLE_2ADDR.S */
 /* EABI doesn't define a double remainder function, but libm does */
-/* File: armv6t2/binopWide2addr.S */
+/* File: armv6t2_taint/binopWide2addr.S */
     /*
      * Generic 64-bit "/2addr" binary operation.  Provide an "instr" line
      * that specifies an instruction that performs "result = r0-r1 op r2-r3".
@@ -6239,10 +6910,9 @@ dalvik_inst:
     /* binop/2addr vA, vB */
     mov     r1, rINST, lsr #12          @ r1<- B
     ubfx    r9, rINST, #8, #4           @ r9<- A
-    add     r1, rFP, r1, lsl #2         @ r1<- &fp[B]
-    add     r9, rFP, r9, lsl #2         @ r9<- &fp[A]
-    ldmia   r1, {r2-r3}                 @ r2/r3<- vBB/vBB+1
-    ldmia   r9, {r0-r1}                 @ r0/r1<- vAA/vAA+1
+// begin WITH_TAINT_TRACKING
+    bl     .LOP_REM_DOUBLE_2ADDR_taint_prop
+// end WITH_TAINT_TRACKING
     .if 0
     orrs    ip, r2, r3                  @ second arg (r2-r3) is zero?
     beq     common_errDivideByZero
@@ -6252,16 +6922,23 @@ dalvik_inst:
                                @ optional op; may set condition codes
     bl      fmod                              @ result<- op, r0-r3 changed
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    stmia   r9, {r0,r1}     @ vAA/vAA+1<- r0/r1
+// begin WITH_TAINT_TRACKING
+//    stmia   r9, {r0,r1}     @ vAA/vAA+1<- r0/r1
+    str     r0, [r9, #0]
+    str     r10, [r9, #4]
+    str     r1, [r9, #8]
+    str     r10, [r9, #12]
+// end WITH_TAINT_TRACKING
     GOTO_OPCODE(ip)                     @ jump to next instruction
     /* 12-15 instructions */
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_ADD_INT_LIT16: /* 0xd0 */
-/* File: armv6t2/OP_ADD_INT_LIT16.S */
-/* File: armv6t2/binopLit16.S */
+/* File: armv6t2_taint/OP_ADD_INT_LIT16.S */
+/* File: armv6t2_taint/binopLit16.S */
     /*
      * Generic 32-bit "lit16" binary operation.  Provide an "instr" line
      * that specifies an instruction that performs "result = r0 op r1".
@@ -6279,6 +6956,11 @@ dalvik_inst:
     mov     r2, rINST, lsr #12          @ r2<- B
     ubfx    r9, rINST, #8, #4           @ r9<- A
     GET_VREG(r0, r2)                    @ r0<- vB
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r3)                    @ r3<- rFP+4
+    GET_VREG_TAINT(r2, r2, r3)          @ r2<- vB.taint
+    SET_VREG_TAINT(r2, r9, r3)
+// end WITH_TAINT_TRACKING
     .if 0
     cmp     r1, #0                      @ is second operand zero?
     beq     common_errDivideByZero
@@ -6292,12 +6974,13 @@ dalvik_inst:
     /* 10-13 instructions */
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_RSUB_INT: /* 0xd1 */
-/* File: armv6t2/OP_RSUB_INT.S */
+/* File: armv6t2_taint/OP_RSUB_INT.S */
 /* this op is "rsub-int", but can be thought of as "rsub-int/lit16" */
-/* File: armv6t2/binopLit16.S */
+/* File: armv6t2_taint/binopLit16.S */
     /*
      * Generic 32-bit "lit16" binary operation.  Provide an "instr" line
      * that specifies an instruction that performs "result = r0 op r1".
@@ -6315,6 +6998,11 @@ dalvik_inst:
     mov     r2, rINST, lsr #12          @ r2<- B
     ubfx    r9, rINST, #8, #4           @ r9<- A
     GET_VREG(r0, r2)                    @ r0<- vB
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r3)                    @ r3<- rFP+4
+    GET_VREG_TAINT(r2, r2, r3)          @ r2<- vB.taint
+    SET_VREG_TAINT(r2, r9, r3)
+// end WITH_TAINT_TRACKING
     .if 0
     cmp     r1, #0                      @ is second operand zero?
     beq     common_errDivideByZero
@@ -6328,12 +7016,13 @@ dalvik_inst:
     /* 10-13 instructions */
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_MUL_INT_LIT16: /* 0xd2 */
-/* File: armv6t2/OP_MUL_INT_LIT16.S */
+/* File: armv6t2_taint/OP_MUL_INT_LIT16.S */
 /* must be "mul r0, r1, r0" -- "r0, r0, r1" is illegal */
-/* File: armv6t2/binopLit16.S */
+/* File: armv6t2_taint/binopLit16.S */
     /*
      * Generic 32-bit "lit16" binary operation.  Provide an "instr" line
      * that specifies an instruction that performs "result = r0 op r1".
@@ -6351,6 +7040,11 @@ dalvik_inst:
     mov     r2, rINST, lsr #12          @ r2<- B
     ubfx    r9, rINST, #8, #4           @ r9<- A
     GET_VREG(r0, r2)                    @ r0<- vB
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r3)                    @ r3<- rFP+4
+    GET_VREG_TAINT(r2, r2, r3)          @ r2<- vB.taint
+    SET_VREG_TAINT(r2, r9, r3)
+// end WITH_TAINT_TRACKING
     .if 0
     cmp     r1, #0                      @ is second operand zero?
     beq     common_errDivideByZero
@@ -6364,11 +7058,12 @@ dalvik_inst:
     /* 10-13 instructions */
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_DIV_INT_LIT16: /* 0xd3 */
-/* File: armv6t2/OP_DIV_INT_LIT16.S */
-/* File: armv6t2/binopLit16.S */
+/* File: armv6t2_taint/OP_DIV_INT_LIT16.S */
+/* File: armv6t2_taint/binopLit16.S */
     /*
      * Generic 32-bit "lit16" binary operation.  Provide an "instr" line
      * that specifies an instruction that performs "result = r0 op r1".
@@ -6386,6 +7081,11 @@ dalvik_inst:
     mov     r2, rINST, lsr #12          @ r2<- B
     ubfx    r9, rINST, #8, #4           @ r9<- A
     GET_VREG(r0, r2)                    @ r0<- vB
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r3)                    @ r3<- rFP+4
+    GET_VREG_TAINT(r2, r2, r3)          @ r2<- vB.taint
+    SET_VREG_TAINT(r2, r9, r3)
+// end WITH_TAINT_TRACKING
     .if 1
     cmp     r1, #0                      @ is second operand zero?
     beq     common_errDivideByZero
@@ -6399,12 +7099,13 @@ dalvik_inst:
     /* 10-13 instructions */
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_REM_INT_LIT16: /* 0xd4 */
-/* File: armv6t2/OP_REM_INT_LIT16.S */
+/* File: armv6t2_taint/OP_REM_INT_LIT16.S */
 /* idivmod returns quotient in r0 and remainder in r1 */
-/* File: armv6t2/binopLit16.S */
+/* File: armv6t2_taint/binopLit16.S */
     /*
      * Generic 32-bit "lit16" binary operation.  Provide an "instr" line
      * that specifies an instruction that performs "result = r0 op r1".
@@ -6422,6 +7123,11 @@ dalvik_inst:
     mov     r2, rINST, lsr #12          @ r2<- B
     ubfx    r9, rINST, #8, #4           @ r9<- A
     GET_VREG(r0, r2)                    @ r0<- vB
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r3)                    @ r3<- rFP+4
+    GET_VREG_TAINT(r2, r2, r3)          @ r2<- vB.taint
+    SET_VREG_TAINT(r2, r9, r3)
+// end WITH_TAINT_TRACKING
     .if 1
     cmp     r1, #0                      @ is second operand zero?
     beq     common_errDivideByZero
@@ -6435,11 +7141,12 @@ dalvik_inst:
     /* 10-13 instructions */
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_AND_INT_LIT16: /* 0xd5 */
-/* File: armv6t2/OP_AND_INT_LIT16.S */
-/* File: armv6t2/binopLit16.S */
+/* File: armv6t2_taint/OP_AND_INT_LIT16.S */
+/* File: armv6t2_taint/binopLit16.S */
     /*
      * Generic 32-bit "lit16" binary operation.  Provide an "instr" line
      * that specifies an instruction that performs "result = r0 op r1".
@@ -6457,6 +7164,11 @@ dalvik_inst:
     mov     r2, rINST, lsr #12          @ r2<- B
     ubfx    r9, rINST, #8, #4           @ r9<- A
     GET_VREG(r0, r2)                    @ r0<- vB
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r3)                    @ r3<- rFP+4
+    GET_VREG_TAINT(r2, r2, r3)          @ r2<- vB.taint
+    SET_VREG_TAINT(r2, r9, r3)
+// end WITH_TAINT_TRACKING
     .if 0
     cmp     r1, #0                      @ is second operand zero?
     beq     common_errDivideByZero
@@ -6470,11 +7182,12 @@ dalvik_inst:
     /* 10-13 instructions */
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_OR_INT_LIT16: /* 0xd6 */
-/* File: armv6t2/OP_OR_INT_LIT16.S */
-/* File: armv6t2/binopLit16.S */
+/* File: armv6t2_taint/OP_OR_INT_LIT16.S */
+/* File: armv6t2_taint/binopLit16.S */
     /*
      * Generic 32-bit "lit16" binary operation.  Provide an "instr" line
      * that specifies an instruction that performs "result = r0 op r1".
@@ -6492,6 +7205,11 @@ dalvik_inst:
     mov     r2, rINST, lsr #12          @ r2<- B
     ubfx    r9, rINST, #8, #4           @ r9<- A
     GET_VREG(r0, r2)                    @ r0<- vB
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r3)                    @ r3<- rFP+4
+    GET_VREG_TAINT(r2, r2, r3)          @ r2<- vB.taint
+    SET_VREG_TAINT(r2, r9, r3)
+// end WITH_TAINT_TRACKING
     .if 0
     cmp     r1, #0                      @ is second operand zero?
     beq     common_errDivideByZero
@@ -6505,11 +7223,12 @@ dalvik_inst:
     /* 10-13 instructions */
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_XOR_INT_LIT16: /* 0xd7 */
-/* File: armv6t2/OP_XOR_INT_LIT16.S */
-/* File: armv6t2/binopLit16.S */
+/* File: armv6t2_taint/OP_XOR_INT_LIT16.S */
+/* File: armv6t2_taint/binopLit16.S */
     /*
      * Generic 32-bit "lit16" binary operation.  Provide an "instr" line
      * that specifies an instruction that performs "result = r0 op r1".
@@ -6527,6 +7246,11 @@ dalvik_inst:
     mov     r2, rINST, lsr #12          @ r2<- B
     ubfx    r9, rINST, #8, #4           @ r9<- A
     GET_VREG(r0, r2)                    @ r0<- vB
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r3)                    @ r3<- rFP+4
+    GET_VREG_TAINT(r2, r2, r3)          @ r2<- vB.taint
+    SET_VREG_TAINT(r2, r9, r3)
+// end WITH_TAINT_TRACKING
     .if 0
     cmp     r1, #0                      @ is second operand zero?
     beq     common_errDivideByZero
@@ -6540,11 +7264,12 @@ dalvik_inst:
     /* 10-13 instructions */
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_ADD_INT_LIT8: /* 0xd8 */
-/* File: armv5te/OP_ADD_INT_LIT8.S */
-/* File: armv5te/binopLit8.S */
+/* File: armv5te_taint/OP_ADD_INT_LIT8.S */
+/* File: armv5te_taint/binopLit8.S */
     /*
      * Generic 32-bit "lit8" binary operation.  Provide an "instr" line
      * that specifies an instruction that performs "result = r0 op r1".
@@ -6568,6 +7293,11 @@ dalvik_inst:
     @cmp     r1, #0                      @ is second operand zero?
     beq     common_errDivideByZero
     .endif
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r10)                   @ r3<- rFP+4
+    GET_VREG_TAINT(r2, r2, r10)         @ r2<- vB.taint
+    SET_VREG_TAINT(r2, r9, r10)
+// end WITH_TAINT_TRACKING
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
 
                                @ optional op; may set condition codes
@@ -6578,11 +7308,12 @@ dalvik_inst:
     /* 10-12 instructions */
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_RSUB_INT_LIT8: /* 0xd9 */
-/* File: armv5te/OP_RSUB_INT_LIT8.S */
-/* File: armv5te/binopLit8.S */
+/* File: armv5te_taint/OP_RSUB_INT_LIT8.S */
+/* File: armv5te_taint/binopLit8.S */
     /*
      * Generic 32-bit "lit8" binary operation.  Provide an "instr" line
      * that specifies an instruction that performs "result = r0 op r1".
@@ -6606,6 +7337,11 @@ dalvik_inst:
     @cmp     r1, #0                      @ is second operand zero?
     beq     common_errDivideByZero
     .endif
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r10)                   @ r3<- rFP+4
+    GET_VREG_TAINT(r2, r2, r10)         @ r2<- vB.taint
+    SET_VREG_TAINT(r2, r9, r10)
+// end WITH_TAINT_TRACKING
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
 
                                @ optional op; may set condition codes
@@ -6616,12 +7352,13 @@ dalvik_inst:
     /* 10-12 instructions */
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_MUL_INT_LIT8: /* 0xda */
-/* File: armv5te/OP_MUL_INT_LIT8.S */
+/* File: armv5te_taint/OP_MUL_INT_LIT8.S */
 /* must be "mul r0, r1, r0" -- "r0, r0, r1" is illegal */
-/* File: armv5te/binopLit8.S */
+/* File: armv5te_taint/binopLit8.S */
     /*
      * Generic 32-bit "lit8" binary operation.  Provide an "instr" line
      * that specifies an instruction that performs "result = r0 op r1".
@@ -6645,6 +7382,11 @@ dalvik_inst:
     @cmp     r1, #0                      @ is second operand zero?
     beq     common_errDivideByZero
     .endif
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r10)                   @ r3<- rFP+4
+    GET_VREG_TAINT(r2, r2, r10)         @ r2<- vB.taint
+    SET_VREG_TAINT(r2, r9, r10)
+// end WITH_TAINT_TRACKING
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
 
                                @ optional op; may set condition codes
@@ -6655,11 +7397,12 @@ dalvik_inst:
     /* 10-12 instructions */
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_DIV_INT_LIT8: /* 0xdb */
-/* File: armv5te/OP_DIV_INT_LIT8.S */
-/* File: armv5te/binopLit8.S */
+/* File: armv5te_taint/OP_DIV_INT_LIT8.S */
+/* File: armv5te_taint/binopLit8.S */
     /*
      * Generic 32-bit "lit8" binary operation.  Provide an "instr" line
      * that specifies an instruction that performs "result = r0 op r1".
@@ -6683,6 +7426,11 @@ dalvik_inst:
     @cmp     r1, #0                      @ is second operand zero?
     beq     common_errDivideByZero
     .endif
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r10)                   @ r3<- rFP+4
+    GET_VREG_TAINT(r2, r2, r10)         @ r2<- vB.taint
+    SET_VREG_TAINT(r2, r9, r10)
+// end WITH_TAINT_TRACKING
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
 
                                @ optional op; may set condition codes
@@ -6693,12 +7441,13 @@ dalvik_inst:
     /* 10-12 instructions */
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_REM_INT_LIT8: /* 0xdc */
-/* File: armv5te/OP_REM_INT_LIT8.S */
+/* File: armv5te_taint/OP_REM_INT_LIT8.S */
 /* idivmod returns quotient in r0 and remainder in r1 */
-/* File: armv5te/binopLit8.S */
+/* File: armv5te_taint/binopLit8.S */
     /*
      * Generic 32-bit "lit8" binary operation.  Provide an "instr" line
      * that specifies an instruction that performs "result = r0 op r1".
@@ -6722,6 +7471,11 @@ dalvik_inst:
     @cmp     r1, #0                      @ is second operand zero?
     beq     common_errDivideByZero
     .endif
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r10)                   @ r3<- rFP+4
+    GET_VREG_TAINT(r2, r2, r10)         @ r2<- vB.taint
+    SET_VREG_TAINT(r2, r9, r10)
+// end WITH_TAINT_TRACKING
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
 
                                @ optional op; may set condition codes
@@ -6732,11 +7486,12 @@ dalvik_inst:
     /* 10-12 instructions */
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_AND_INT_LIT8: /* 0xdd */
-/* File: armv5te/OP_AND_INT_LIT8.S */
-/* File: armv5te/binopLit8.S */
+/* File: armv5te_taint/OP_AND_INT_LIT8.S */
+/* File: armv5te_taint/binopLit8.S */
     /*
      * Generic 32-bit "lit8" binary operation.  Provide an "instr" line
      * that specifies an instruction that performs "result = r0 op r1".
@@ -6760,6 +7515,11 @@ dalvik_inst:
     @cmp     r1, #0                      @ is second operand zero?
     beq     common_errDivideByZero
     .endif
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r10)                   @ r3<- rFP+4
+    GET_VREG_TAINT(r2, r2, r10)         @ r2<- vB.taint
+    SET_VREG_TAINT(r2, r9, r10)
+// end WITH_TAINT_TRACKING
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
 
                                @ optional op; may set condition codes
@@ -6770,11 +7530,12 @@ dalvik_inst:
     /* 10-12 instructions */
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_OR_INT_LIT8: /* 0xde */
-/* File: armv5te/OP_OR_INT_LIT8.S */
-/* File: armv5te/binopLit8.S */
+/* File: armv5te_taint/OP_OR_INT_LIT8.S */
+/* File: armv5te_taint/binopLit8.S */
     /*
      * Generic 32-bit "lit8" binary operation.  Provide an "instr" line
      * that specifies an instruction that performs "result = r0 op r1".
@@ -6798,6 +7559,11 @@ dalvik_inst:
     @cmp     r1, #0                      @ is second operand zero?
     beq     common_errDivideByZero
     .endif
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r10)                   @ r3<- rFP+4
+    GET_VREG_TAINT(r2, r2, r10)         @ r2<- vB.taint
+    SET_VREG_TAINT(r2, r9, r10)
+// end WITH_TAINT_TRACKING
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
 
                                @ optional op; may set condition codes
@@ -6808,11 +7574,12 @@ dalvik_inst:
     /* 10-12 instructions */
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_XOR_INT_LIT8: /* 0xdf */
-/* File: armv5te/OP_XOR_INT_LIT8.S */
-/* File: armv5te/binopLit8.S */
+/* File: armv5te_taint/OP_XOR_INT_LIT8.S */
+/* File: armv5te_taint/binopLit8.S */
     /*
      * Generic 32-bit "lit8" binary operation.  Provide an "instr" line
      * that specifies an instruction that performs "result = r0 op r1".
@@ -6836,6 +7603,11 @@ dalvik_inst:
     @cmp     r1, #0                      @ is second operand zero?
     beq     common_errDivideByZero
     .endif
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r10)                   @ r3<- rFP+4
+    GET_VREG_TAINT(r2, r2, r10)         @ r2<- vB.taint
+    SET_VREG_TAINT(r2, r9, r10)
+// end WITH_TAINT_TRACKING
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
 
                                @ optional op; may set condition codes
@@ -6846,11 +7618,12 @@ dalvik_inst:
     /* 10-12 instructions */
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_SHL_INT_LIT8: /* 0xe0 */
-/* File: armv5te/OP_SHL_INT_LIT8.S */
-/* File: armv5te/binopLit8.S */
+/* File: armv5te_taint/OP_SHL_INT_LIT8.S */
+/* File: armv5te_taint/binopLit8.S */
     /*
      * Generic 32-bit "lit8" binary operation.  Provide an "instr" line
      * that specifies an instruction that performs "result = r0 op r1".
@@ -6874,6 +7647,11 @@ dalvik_inst:
     @cmp     r1, #0                      @ is second operand zero?
     beq     common_errDivideByZero
     .endif
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r10)                   @ r3<- rFP+4
+    GET_VREG_TAINT(r2, r2, r10)         @ r2<- vB.taint
+    SET_VREG_TAINT(r2, r9, r10)
+// end WITH_TAINT_TRACKING
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
 
     and     r1, r1, #31                           @ optional op; may set condition codes
@@ -6884,11 +7662,12 @@ dalvik_inst:
     /* 10-12 instructions */
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_SHR_INT_LIT8: /* 0xe1 */
-/* File: armv5te/OP_SHR_INT_LIT8.S */
-/* File: armv5te/binopLit8.S */
+/* File: armv5te_taint/OP_SHR_INT_LIT8.S */
+/* File: armv5te_taint/binopLit8.S */
     /*
      * Generic 32-bit "lit8" binary operation.  Provide an "instr" line
      * that specifies an instruction that performs "result = r0 op r1".
@@ -6912,6 +7691,11 @@ dalvik_inst:
     @cmp     r1, #0                      @ is second operand zero?
     beq     common_errDivideByZero
     .endif
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r10)                   @ r3<- rFP+4
+    GET_VREG_TAINT(r2, r2, r10)         @ r2<- vB.taint
+    SET_VREG_TAINT(r2, r9, r10)
+// end WITH_TAINT_TRACKING
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
 
     and     r1, r1, #31                           @ optional op; may set condition codes
@@ -6922,11 +7706,12 @@ dalvik_inst:
     /* 10-12 instructions */
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_USHR_INT_LIT8: /* 0xe2 */
-/* File: armv5te/OP_USHR_INT_LIT8.S */
-/* File: armv5te/binopLit8.S */
+/* File: armv5te_taint/OP_USHR_INT_LIT8.S */
+/* File: armv5te_taint/binopLit8.S */
     /*
      * Generic 32-bit "lit8" binary operation.  Provide an "instr" line
      * that specifies an instruction that performs "result = r0 op r1".
@@ -6950,6 +7735,11 @@ dalvik_inst:
     @cmp     r1, #0                      @ is second operand zero?
     beq     common_errDivideByZero
     .endif
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r10)                   @ r3<- rFP+4
+    GET_VREG_TAINT(r2, r2, r10)         @ r2<- vB.taint
+    SET_VREG_TAINT(r2, r9, r10)
+// end WITH_TAINT_TRACKING
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
 
     and     r1, r1, #31                           @ optional op; may set condition codes
@@ -6960,11 +7750,14 @@ dalvik_inst:
     /* 10-12 instructions */
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_IGET_VOLATILE: /* 0xe3 */
-/* File: armv5te/OP_IGET_VOLATILE.S */
-/* File: armv5te/OP_IGET.S */
+/* File: armv5te_taint/OP_IGET_VOLATILE.S */
+/* File: armv5te_taint/OP_IGET.S */
+// begin WITH_TAINT_TRACKING
+// end WITH_TAINT_TRACKING
     /*
      * General 32-bit instance field get.
      *
@@ -6975,8 +7768,9 @@ dalvik_inst:
     ldr     r3, [rSELF, #offThread_methodClassDex]    @ r3<- DvmDex
     FETCH(r1, 1)                        @ r1<- field ref CCCC
     ldr     r2, [r3, #offDvmDex_pResFields] @ r2<- pDvmDex->pResFields
-    GET_VREG(r9, r0)                    @ r9<- fp[B], the object pointer
-    ldr     r0, [r2, r1, lsl #2]        @ r0<- resolved InstField ptr
+// begin WITH_TAINT_TRACKING
+    bl      .LOP_IGET_VOLATILE_taint_prop
+// end WITH_TAINT_TRACKING
     cmp     r0, #0                      @ is resolved entry null?
     bne     .LOP_IGET_VOLATILE_finish          @ no, already resolved
 8:  ldr     r2, [rSELF, #offThread_method]    @ r2<- current method
@@ -6991,8 +7785,10 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_IPUT_VOLATILE: /* 0xe4 */
-/* File: armv5te/OP_IPUT_VOLATILE.S */
-/* File: armv5te/OP_IPUT.S */
+/* File: armv5te_taint/OP_IPUT_VOLATILE.S */
+/* File: armv5te_taint/OP_IPUT.S */
+// begin WITH_TAINT_TRACKING
+// end WITH_TAINT_TRACKING
     /*
      * General 32-bit instance field put.
      *
@@ -7019,8 +7815,10 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_SGET_VOLATILE: /* 0xe5 */
-/* File: armv5te/OP_SGET_VOLATILE.S */
-/* File: armv5te/OP_SGET.S */
+/* File: armv5te_taint/OP_SGET_VOLATILE.S */
+/* File: armv5te_taint/OP_SGET.S */
+// begin WITH_TAINT_TRACKING
+// end WITH_TAINT_TRACKING
     /*
      * General 32-bit SGET handler.
      *
@@ -7034,11 +7832,11 @@ dalvik_inst:
     cmp     r0, #0                      @ is resolved entry null?
     beq     .LOP_SGET_VOLATILE_resolve         @ yes, do resolve
 .LOP_SGET_VOLATILE_finish: @ field ptr in r0
-    ldr     r1, [r0, #offStaticField_value] @ r1<- field value
-    SMP_DMB                            @ acquiring load
-    mov     r2, rINST, lsr #8           @ r2<- AA
+// begin WITH_TAINT_TRACKING
+    bl		.LOP_SGET_VOLATILE_taint_prop
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
-    SET_VREG(r1, r2)                    @ fp[AA]<- r1
+    SET_VREG(r0, r2)                    @ fp[AA]<- r0
+// end WITH_TAINT_TRACKING
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
@@ -7046,8 +7844,10 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_SPUT_VOLATILE: /* 0xe6 */
-/* File: armv5te/OP_SPUT_VOLATILE.S */
-/* File: armv5te/OP_SPUT.S */
+/* File: armv5te_taint/OP_SPUT_VOLATILE.S */
+/* File: armv5te_taint/OP_SPUT.S */
+// begin WITH_TAINT_TRACKING
+// end WITH_TAINT_TRACKING
     /*
      * General 32-bit SPUT handler.
      *
@@ -7065,17 +7865,19 @@ dalvik_inst:
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
     GET_VREG(r1, r2)                    @ r1<- fp[AA]
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    SMP_DMB_ST                        @ releasing store
-    str     r1, [r0, #offStaticField_value] @ field<- vAA
-    SMP_DMB
+// begin WITH_TAINT_TRACKING
+    bl      .LOP_SPUT_VOLATILE_taint_prop
+// end WITH_TAINT_TRACKING
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
 
 /* ------------------------------ */
     .balign 64
 .L_OP_IGET_OBJECT_VOLATILE: /* 0xe7 */
-/* File: armv5te/OP_IGET_OBJECT_VOLATILE.S */
-/* File: armv5te/OP_IGET.S */
+/* File: armv5te_taint/OP_IGET_OBJECT_VOLATILE.S */
+/* File: armv5te_taint/OP_IGET.S */
+// begin WITH_TAINT_TRACKING
+// end WITH_TAINT_TRACKING
     /*
      * General 32-bit instance field get.
      *
@@ -7086,8 +7888,9 @@ dalvik_inst:
     ldr     r3, [rSELF, #offThread_methodClassDex]    @ r3<- DvmDex
     FETCH(r1, 1)                        @ r1<- field ref CCCC
     ldr     r2, [r3, #offDvmDex_pResFields] @ r2<- pDvmDex->pResFields
-    GET_VREG(r9, r0)                    @ r9<- fp[B], the object pointer
-    ldr     r0, [r2, r1, lsl #2]        @ r0<- resolved InstField ptr
+// begin WITH_TAINT_TRACKING
+    bl      .LOP_IGET_OBJECT_VOLATILE_taint_prop
+// end WITH_TAINT_TRACKING
     cmp     r0, #0                      @ is resolved entry null?
     bne     .LOP_IGET_OBJECT_VOLATILE_finish          @ no, already resolved
 8:  ldr     r2, [rSELF, #offThread_method]    @ r2<- current method
@@ -7102,8 +7905,8 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_IGET_WIDE_VOLATILE: /* 0xe8 */
-/* File: armv5te/OP_IGET_WIDE_VOLATILE.S */
-/* File: armv5te/OP_IGET_WIDE.S */
+/* File: armv5te_taint/OP_IGET_WIDE_VOLATILE.S */
+/* File: armv5te_taint/OP_IGET_WIDE.S */
     /*
      * Wide 32-bit instance field get.
      */
@@ -7112,8 +7915,9 @@ dalvik_inst:
     ldr     r3, [rSELF, #offThread_methodClassDex]    @ r3<- DvmDex
     FETCH(r1, 1)                        @ r1<- field ref CCCC
     ldr     r2, [r3, #offDvmDex_pResFields] @ r2<- pResFields
-    GET_VREG(r9, r0)                    @ r9<- fp[B], the object pointer
-    ldr     r0, [r2, r1, lsl #2]        @ r0<- resolved InstField ptr
+// begin WITH_TAINT_TRACKING
+    bl      .LOP_IGET_WIDE_VOLATILE_taint_prop
+// end WITH_TAINT_TRACKING
     cmp     r0, #0                      @ is resolved entry null?
     bne     .LOP_IGET_WIDE_VOLATILE_finish          @ no, already resolved
 8:  ldr     r2, [rSELF, #offThread_method] @ r2<- current method
@@ -7128,8 +7932,8 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_IPUT_WIDE_VOLATILE: /* 0xe9 */
-/* File: armv5te/OP_IPUT_WIDE_VOLATILE.S */
-/* File: armv5te/OP_IPUT_WIDE.S */
+/* File: armv5te_taint/OP_IPUT_WIDE_VOLATILE.S */
+/* File: armv5te_taint/OP_IPUT_WIDE.S */
     /* iput-wide vA, vB, field@CCCC */
     mov     r0, rINST, lsr #12          @ r0<- B
     ldr     r3, [rSELF, #offThread_methodClassDex]    @ r3<- DvmDex
@@ -7151,8 +7955,8 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_SGET_WIDE_VOLATILE: /* 0xea */
-/* File: armv5te/OP_SGET_WIDE_VOLATILE.S */
-/* File: armv5te/OP_SGET_WIDE.S */
+/* File: armv5te_taint/OP_SGET_WIDE_VOLATILE.S */
+/* File: armv5te_taint/OP_SGET_WIDE.S */
     /*
      * 64-bit SGET handler.
      */
@@ -7163,26 +7967,15 @@ dalvik_inst:
     ldr     r0, [r10, r1, lsl #2]       @ r0<- resolved StaticField ptr
     cmp     r0, #0                      @ is resolved entry null?
     beq     .LOP_SGET_WIDE_VOLATILE_resolve         @ yes, do resolve
-.LOP_SGET_WIDE_VOLATILE_finish:
-    mov     r9, rINST, lsr #8           @ r9<- AA
-    .if 1
-    add     r0, r0, #offStaticField_value @ r0<- pointer to data
-    bl      dvmQuasiAtomicRead64        @ r0/r1<- contents of field
-    .else
-    ldrd    r0, [r0, #offStaticField_value] @ r0/r1<- field value (aligned)
-    .endif
-    add     r9, rFP, r9, lsl #2         @ r9<- &fp[AA]
-    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
-    stmia   r9, {r0-r1}                 @ vAA/vAA+1<- r0/r1
-    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    GOTO_OPCODE(ip)                     @ jump to next instruction
+    b		.LOP_SGET_WIDE_VOLATILE_finish
+
 
 
 /* ------------------------------ */
     .balign 64
 .L_OP_SPUT_WIDE_VOLATILE: /* 0xeb */
-/* File: armv5te/OP_SPUT_WIDE_VOLATILE.S */
-/* File: armv5te/OP_SPUT_WIDE.S */
+/* File: armv5te_taint/OP_SPUT_WIDE_VOLATILE.S */
+/* File: armv5te_taint/OP_SPUT_WIDE.S */
     /*
      * 64-bit SPUT handler.
      */
@@ -7192,13 +7985,20 @@ dalvik_inst:
     ldr     r10, [r0, #offDvmDex_pResFields] @ r10<- dvmDex->pResFields
     mov     r9, rINST, lsr #8           @ r9<- AA
     ldr     r2, [r10, r1, lsl #2]        @ r2<- resolved StaticField ptr
-    add     r9, rFP, r9, lsl #2         @ r9<- &fp[AA]
+// begin WITH_TAINT_TRACKING
+    add     r9, rFP, r9, lsl #3         @ r9<- &fp[AA]
+// end WITH_TAINT_TRACKING
     cmp     r2, #0                      @ is resolved entry null?
     beq     .LOP_SPUT_WIDE_VOLATILE_resolve         @ yes, do resolve
 .LOP_SPUT_WIDE_VOLATILE_finish: @ field ptr in r2, AA in r9
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
-    ldmia   r9, {r0-r1}                 @ r0/r1<- vAA/vAA+1
+// begin WITH_TAINT_TRACKING
+    bl		.LOP_SPUT_WIDE_VOLATILE_taint_prop
+// end WITH_TAINT_TRACKING
     GET_INST_OPCODE(r10)                @ extract opcode from rINST
+// begin WITH_TAINT_TRACKING
+    str	    r3, [r2, #offStaticField_taint]
+// end WITH_TAINT_TRACKING
     .if 1
     add     r2, r2, #offStaticField_value @ r2<- pointer to data
     bl      dvmQuasiAtomicSwap64Sync    @ stores r0/r1 into addr r2
@@ -7211,7 +8011,7 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_BREAKPOINT: /* 0xec */
-/* File: armv5te/OP_BREAKPOINT.S */
+/* File: armv5te_taint/OP_BREAKPOINT.S */
     /*
      * Breakpoint handler.
      *
@@ -7230,7 +8030,7 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_THROW_VERIFICATION_ERROR: /* 0xed */
-/* File: armv5te/OP_THROW_VERIFICATION_ERROR.S */
+/* File: armv5te_taint/OP_THROW_VERIFICATION_ERROR.S */
     /*
      * Handle a throw-verification-error instruction.  This throws an
      * exception for an error discovered during verification.  The
@@ -7247,7 +8047,7 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_EXECUTE_INLINE: /* 0xee */
-/* File: armv5te/OP_EXECUTE_INLINE.S */
+/* File: armv5te_taint/OP_EXECUTE_INLINE.S */
     /*
      * Execute a "native inline" instruction.
      *
@@ -7267,23 +8067,13 @@ dalvik_inst:
     EXPORT_PC()                         @ can throw
     ands    r2, #kSubModeDebugProfile   @ Any going on?
     bne     .LOP_EXECUTE_INLINE_debugmode       @ yes - take slow path
-.LOP_EXECUTE_INLINE_resume:
-    add     r1, rSELF, #offThread_retval  @ r1<- &self->retval
-    sub     sp, sp, #8                  @ make room for arg, +64 bit align
-    mov     r0, rINST, lsr #12          @ r0<- B
-    str     r1, [sp]                    @ push &self->retval
-    bl      .LOP_EXECUTE_INLINE_continue        @ make call; will return after
-    add     sp, sp, #8                  @ pop stack
-    cmp     r0, #0                      @ test boolean result of inline
-    beq     common_exceptionThrown      @ returned false, handle exception
-    FETCH_ADVANCE_INST(3)               @ advance rPC, load rINST
-    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    GOTO_OPCODE(ip)                     @ jump to next instruction
+// begin WITH_TAINT_TRACKING
+    b       .LOP_EXECUTE_INLINE_resume
 
 /* ------------------------------ */
     .balign 64
 .L_OP_EXECUTE_INLINE_RANGE: /* 0xef */
-/* File: armv5te/OP_EXECUTE_INLINE_RANGE.S */
+/* File: armv5te_taint/OP_EXECUTE_INLINE_RANGE.S */
     /*
      * Execute a "native inline" instruction, using "/range" semantics.
      * Same idea as execute-inline, but we get the args differently.
@@ -7301,23 +8091,13 @@ dalvik_inst:
     EXPORT_PC()                         @ can throw
     ands    r2, #kSubModeDebugProfile   @ Any going on?
     bne     .LOP_EXECUTE_INLINE_RANGE_debugmode       @ yes - take slow path
-.LOP_EXECUTE_INLINE_RANGE_resume:
-    add     r1, rSELF, #offThread_retval  @ r1<- &self->retval
-    sub     sp, sp, #8                  @ make room for arg, +64 bit align
-    mov     r0, rINST, lsr #8           @ r0<- AA
-    str     r1, [sp]                    @ push &self->retval
-    bl      .LOP_EXECUTE_INLINE_RANGE_continue        @ make call; will return after
-    add     sp, sp, #8                  @ pop stack
-    cmp     r0, #0                      @ test boolean result of inline
-    beq     common_exceptionThrown      @ returned false, handle exception
-    FETCH_ADVANCE_INST(3)               @ advance rPC, load rINST
-    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    GOTO_OPCODE(ip)                     @ jump to next instruction
+// begin WITH_TAINT_TRACKING
+    b       .LOP_EXECUTE_INLINE_RANGE_resume
 
 /* ------------------------------ */
     .balign 64
 .L_OP_INVOKE_OBJECT_INIT_RANGE: /* 0xf0 */
-/* File: armv5te/OP_INVOKE_OBJECT_INIT_RANGE.S */
+/* File: armv5te_taint/OP_INVOKE_OBJECT_INIT_RANGE.S */
     /*
      * Invoke Object.<init> on an object.  In practice we know that
      * Object's nullary constructor doesn't do anything, so we just
@@ -7342,71 +8122,107 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_RETURN_VOID_BARRIER: /* 0xf1 */
-/* File: armv5te/OP_RETURN_VOID_BARRIER.S */
+/* File: armv5te_taint/OP_RETURN_VOID_BARRIER.S */
     SMP_DMB_ST
+    SET_TAINT_CLEAR(r1)
+    str     r1, [rSELF, #offThread_rtaint]
     b       common_returnFromMethod
 
 /* ------------------------------ */
     .balign 64
 .L_OP_IGET_QUICK: /* 0xf2 */
-/* File: armv6t2/OP_IGET_QUICK.S */
+/* File: armv6t2_taint/OP_IGET_QUICK.S */
     /* For: iget-quick, iget-object-quick */
     /* op vA, vB, offset@CCCC */
     mov     r2, rINST, lsr #12          @ r2<- B
     FETCH(r1, 1)                        @ r1<- field byte offset
     GET_VREG(r3, r2)                    @ r3<- object we're operating on
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r0)
+    GET_VREG_TAINT(r9, r2, r0)
+// end WITH_TAINT_TRACKING
     ubfx    r2, rINST, #8, #4           @ r2<- A
     cmp     r3, #0                      @ check object for null
     beq     common_errNullObject        @ object was null
     ldr     r0, [r3, r1]                @ r0<- obj.field (always 32 bits)
-    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
+// begin WITH_TAINT_TRACKING
+    bl      .LOP_IGET_QUICK_taint_prop
+//    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST // in subroutine
+// end WITH_TAINT_TRACKING
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
     SET_VREG(r0, r2)                    @ fp[A]<- r0
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r0)
+    SET_VREG_TAINT(r10, r2, r0)
+// end WITH_TAINT_TRACKING
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_IGET_WIDE_QUICK: /* 0xf3 */
-/* File: armv6t2/OP_IGET_WIDE_QUICK.S */
+/* File: armv6t2_taint/OP_IGET_WIDE_QUICK.S */
     /* iget-wide-quick vA, vB, offset@CCCC */
     mov     r2, rINST, lsr #12          @ r2<- B
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r0)
+    GET_VREG_TAINT(r9, r2, r0)
+// end WITH_TAINT_TRACKING
     FETCH(ip, 1)                        @ ip<- field byte offset
     GET_VREG(r3, r2)                    @ r3<- object we're operating on
     ubfx    r2, rINST, #8, #4           @ r2<- A
     cmp     r3, #0                      @ check object for null
     beq     common_errNullObject        @ object was null
+// begin WITH_TAINT_TRACKING
+    add     r10, ip, #8
     ldrd    r0, [r3, ip]                @ r0<- obj.field (64 bits, aligned)
+    ldr     r10, [r3, r10]
+    orr     r10, r9, r10
+// end WITH_TAINT_TRACKING
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
-    add     r3, rFP, r2, lsl #2         @ r3<- &fp[A]
-    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    stmia   r3, {r0-r1}                 @ fp[A]<- r0/r1
+// begin WITH_TAINT_TRACKING
+    bl      iget_wide_quick_taint_prop
+// end WITH_TAINT_TRACKING
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_IGET_OBJECT_QUICK: /* 0xf4 */
-/* File: armv5te/OP_IGET_OBJECT_QUICK.S */
-/* File: armv5te/OP_IGET_QUICK.S */
+/* File: armv5te_taint/OP_IGET_OBJECT_QUICK.S */
+/* File: armv5te_taint/OP_IGET_QUICK.S */
     /* For: iget-quick, iget-object-quick */
     /* op vA, vB, offset@CCCC */
     mov     r2, rINST, lsr #12          @ r2<- B
     GET_VREG(r3, r2)                    @ r3<- object we're operating on
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r0)
+    GET_VREG_TAINT(r9, r2, r0)
+// end WITH_TAINT_TRACKING
     FETCH(r1, 1)                        @ r1<- field byte offset
     cmp     r3, #0                      @ check object for null
     mov     r2, rINST, lsr #8           @ r2<- A(+)
     beq     common_errNullObject        @ object was null
     ldr     r0, [r3, r1]                @ r0<- obj.field (always 32 bits)
-    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
+// begin WITH_TAINT_TRACKING
+	bl		.LOP_IGET_OBJECT_QUICK_taint_prop
+//    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST // in subroutine
+// end WITH_TAINT_TRACKING
     and     r2, r2, #15
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
     SET_VREG(r0, r2)                    @ fp[A]<- r0
+// begin WITH_TAINT_TRACKING
+	SET_TAINT_FP(r0)
+	SET_VREG_TAINT(r10, r2, r0)
+// end WITH_TAINT_TRACKING
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_IPUT_QUICK: /* 0xf5 */
-/* File: armv6t2/OP_IPUT_QUICK.S */
+/* File: armv6t2_taint/OP_IPUT_QUICK.S */
     /* For: iput-quick, iput-object-quick */
     /* op vA, vB, offset@CCCC */
     mov     r2, rINST, lsr #12          @ r2<- B
@@ -7416,33 +8232,47 @@ dalvik_inst:
     cmp     r3, #0                      @ check object for null
     beq     common_errNullObject        @ object was null
     GET_VREG(r0, r2)                    @ r0<- fp[A]
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r9)
+    GET_VREG_TAINT(r10, r2, r9)
+// end WITH_TAINT_TRACKING
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
     str     r0, [r3, r1]                @ obj.field (always 32 bits)<- r0
+// begin WITH_TAINT_TRACKING
+    add	    r1, r1, #4
+    str     r10, [r3, r1]
+// end WITH_TAINT_TRACKING
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_IPUT_WIDE_QUICK: /* 0xf6 */
-/* File: armv6t2/OP_IPUT_WIDE_QUICK.S */
+/* File: armv6t2_taint/OP_IPUT_WIDE_QUICK.S */
     /* iput-wide-quick vA, vB, offset@CCCC */
     mov     r1, rINST, lsr #12          @ r1<- B
     ubfx    r0, rINST, #8, #4           @ r0<- A
     GET_VREG(r2, r1)                    @ r2<- fp[B], the object pointer
-    add     r3, rFP, r0, lsl #2         @ r3<- &fp[A]
-    cmp     r2, #0                      @ check object for null
-    ldmia   r3, {r0-r1}                 @ r0/r1<- fp[A]
+// begin WITH_TAINT_TRACKING
+    bl iput_wide_quick_taint_prop
+// end WITH_TAINT_TRACKING
     beq     common_errNullObject        @ object was null
     FETCH(r3, 1)                        @ r3<- field byte offset
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
     strd    r0, [r2, r3]                @ obj.field (64 bits, aligned)<- r0/r1
+// begin WITH_TAINT_TRACKING
+    add     r3, r3, #8
+    str     r9, [r2, r3]
+// end WITH_TAINT_TRACKING
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
+
 /* ------------------------------ */
     .balign 64
 .L_OP_IPUT_OBJECT_QUICK: /* 0xf7 */
-/* File: armv5te/OP_IPUT_OBJECT_QUICK.S */
+/* File: armv5te_taint/OP_IPUT_OBJECT_QUICK.S */
     /* For: iput-object-quick */
     /* op vA, vB, offset@CCCC */
     mov     r2, rINST, lsr #12          @ r2<- B
@@ -7453,9 +8283,9 @@ dalvik_inst:
     beq     common_errNullObject        @ object was null
     and     r2, r2, #15
     GET_VREG(r0, r2)                    @ r0<- fp[A]
-    ldr     r2, [rSELF, #offThread_cardTable]  @ r2<- card table base
-    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
-    str     r0, [r3, r1]                @ obj.field (always 32 bits)<- r0
+// begin WITH_TAINT_TRACKING
+    bl    .LOP_IPUT_OBJECT_QUICK_taint_prop
+// end WITH_TAINT_TRACKING
     cmp     r0, #0
     strneb  r2, [r2, r3, lsr #GC_CARD_SHIFT] @ mark card based on obj head
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
@@ -7464,7 +8294,7 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_INVOKE_VIRTUAL_QUICK: /* 0xf8 */
-/* File: armv5te/OP_INVOKE_VIRTUAL_QUICK.S */
+/* File: armv5te_taint/OP_INVOKE_VIRTUAL_QUICK.S */
     /*
      * Handle an optimized virtual method call.
      *
@@ -7489,8 +8319,8 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_INVOKE_VIRTUAL_QUICK_RANGE: /* 0xf9 */
-/* File: armv5te/OP_INVOKE_VIRTUAL_QUICK_RANGE.S */
-/* File: armv5te/OP_INVOKE_VIRTUAL_QUICK.S */
+/* File: armv5te_taint/OP_INVOKE_VIRTUAL_QUICK_RANGE.S */
+/* File: armv5te_taint/OP_INVOKE_VIRTUAL_QUICK.S */
     /*
      * Handle an optimized virtual method call.
      *
@@ -7516,7 +8346,7 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_INVOKE_SUPER_QUICK: /* 0xfa */
-/* File: armv5te/OP_INVOKE_SUPER_QUICK.S */
+/* File: armv5te_taint/OP_INVOKE_SUPER_QUICK.S */
     /*
      * Handle an optimized "super" method call.
      *
@@ -7543,8 +8373,8 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_INVOKE_SUPER_QUICK_RANGE: /* 0xfb */
-/* File: armv5te/OP_INVOKE_SUPER_QUICK_RANGE.S */
-/* File: armv5te/OP_INVOKE_SUPER_QUICK.S */
+/* File: armv5te_taint/OP_INVOKE_SUPER_QUICK_RANGE.S */
+/* File: armv5te_taint/OP_INVOKE_SUPER_QUICK.S */
     /*
      * Handle an optimized "super" method call.
      *
@@ -7572,8 +8402,10 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_IPUT_OBJECT_VOLATILE: /* 0xfc */
-/* File: armv5te/OP_IPUT_OBJECT_VOLATILE.S */
-/* File: armv5te/OP_IPUT_OBJECT.S */
+/* File: armv5te_taint/OP_IPUT_OBJECT_VOLATILE.S */
+/* File: armv5te_taint/OP_IPUT_OBJECT.S */
+// begin WITH_TAINT_TRACKING
+// end WITH_TAINT_TRACKING
     /*
      * 32-bit instance field put.
      *
@@ -7600,8 +8432,10 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_SGET_OBJECT_VOLATILE: /* 0xfd */
-/* File: armv5te/OP_SGET_OBJECT_VOLATILE.S */
-/* File: armv5te/OP_SGET.S */
+/* File: armv5te_taint/OP_SGET_OBJECT_VOLATILE.S */
+/* File: armv5te_taint/OP_SGET.S */
+// begin WITH_TAINT_TRACKING
+// end WITH_TAINT_TRACKING
     /*
      * General 32-bit SGET handler.
      *
@@ -7615,11 +8449,11 @@ dalvik_inst:
     cmp     r0, #0                      @ is resolved entry null?
     beq     .LOP_SGET_OBJECT_VOLATILE_resolve         @ yes, do resolve
 .LOP_SGET_OBJECT_VOLATILE_finish: @ field ptr in r0
-    ldr     r1, [r0, #offStaticField_value] @ r1<- field value
-    SMP_DMB                            @ acquiring load
-    mov     r2, rINST, lsr #8           @ r2<- AA
+// begin WITH_TAINT_TRACKING
+    bl		.LOP_SGET_OBJECT_VOLATILE_taint_prop
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
-    SET_VREG(r1, r2)                    @ fp[AA]<- r1
+    SET_VREG(r0, r2)                    @ fp[AA]<- r0
+// end WITH_TAINT_TRACKING
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
@@ -7627,8 +8461,10 @@ dalvik_inst:
 /* ------------------------------ */
     .balign 64
 .L_OP_SPUT_OBJECT_VOLATILE: /* 0xfe */
-/* File: armv5te/OP_SPUT_OBJECT_VOLATILE.S */
-/* File: armv5te/OP_SPUT_OBJECT.S */
+/* File: armv5te_taint/OP_SPUT_OBJECT_VOLATILE.S */
+/* File: armv5te_taint/OP_SPUT_OBJECT.S */
+// begin WITH_TAINT_TRACKING
+// end WITH_TAINT_TRACKING
     /*
      * 32-bit SPUT handler for objects
      *
@@ -7645,21 +8481,27 @@ dalvik_inst:
     mov     r2, rINST, lsr #8           @ r2<- AA
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
     GET_VREG(r1, r2)                    @ r1<- fp[AA]
-    ldr     r2, [rSELF, #offThread_cardTable]  @ r2<- card table base
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r3)
+    GET_VREG_TAINT(r3, r2, r3)          @ r3<- taint
+//    ldr     r2, [rSELF, #offThread_cardTable]  @ r2<- card table base
+    ldr     r10, [rSELF, #offThread_cardTable]  @ r10<- card table base
+// end WITH_TAINT_TRACKING
     ldr     r9, [r0, #offField_clazz]   @ r9<- field->clazz
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    SMP_DMB_ST                        @ releasing store
+    @ no-op                         @ releasing store
     b       .LOP_SPUT_OBJECT_VOLATILE_end
 
 
 /* ------------------------------ */
     .balign 64
 .L_OP_UNUSED_FF: /* 0xff */
-/* File: armv5te/OP_UNUSED_FF.S */
-/* File: armv5te/unused.S */
+/* File: armv5te_taint/OP_UNUSED_FF.S */
+/* File: armv5te_taint/unused.S */
     bl      common_abort
 
 
+
     .balign 64
     .size   dvmAsmInstructionStart, .-dvmAsmInstructionStart
     .global dvmAsmInstructionEnd
@@ -7690,6 +8532,11 @@ dvmAsmSisterStart:
     bl      dvmResolveString            @ r0<- String reference
     cmp     r0, #0                      @ failed?
     beq     common_exceptionThrown      @ yup, handle the exception
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r2)
+    SET_TAINT_CLEAR(r3)
+    SET_VREG_TAINT(r3, r9, r2)
+// end WITH_TAINT_TRACKING
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
     SET_VREG(r0, r9)                    @ vAA<- r0
@@ -7709,6 +8556,11 @@ dvmAsmSisterStart:
     bl      dvmResolveString            @ r0<- String reference
     cmp     r0, #0                      @ failed?
     beq     common_exceptionThrown      @ yup, handle the exception
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r2)
+    SET_TAINT_CLEAR(r3)
+    SET_VREG_TAINT(r3, r9, r2)
+// end WITH_TAINT_TRACKING
     FETCH_ADVANCE_INST(3)               @ advance rPC, load rINST
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
     SET_VREG(r0, r9)                    @ vAA<- r0
@@ -7729,6 +8581,11 @@ dvmAsmSisterStart:
     bl      dvmResolveClass             @ r0<- Class reference
     cmp     r0, #0                      @ failed?
     beq     common_exceptionThrown      @ yup, handle the exception
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r2)
+    SET_TAINT_CLEAR(r3)
+    SET_VREG_TAINT(r3, r9, r2)
+// end WITH_TAINT_TRACKING
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
     SET_VREG(r0, r9)                    @ vAA<- r0
@@ -7792,6 +8649,11 @@ dvmAsmSisterStart:
      */
 .LOP_INSTANCE_OF_store:
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r2)
+    SET_TAINT_CLEAR(r3)
+    SET_VREG_TAINT(r3, r9, r2)
+// end WITH_TAINT_TRACKING
     SET_VREG(r0, r9)                    @ vA<- r0
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
     GOTO_OPCODE(ip)                     @ jump to next instruction
@@ -7804,6 +8666,11 @@ dvmAsmSisterStart:
     mov     r0, #1                      @ indicate success
     @ could b OP_INSTANCE_OF_store, but copying is faster and cheaper
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r2)
+    SET_TAINT_CLEAR(r3)
+    SET_VREG_TAINT(r3, r9, r2)
+// end WITH_TAINT_TRACKING
     SET_VREG(r0, r9)                    @ vA<- r0
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
     GOTO_OPCODE(ip)                     @ jump to next instruction
@@ -7848,6 +8715,11 @@ dvmAsmSisterStart:
     beq     common_exceptionThrown      @ yes, handle the exception
 #endif
 .LOP_NEW_INSTANCE_end:
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r2)
+    SET_TAINT_CLEAR(r1)
+    SET_VREG_TAINT(r1, r3, r2)
+// end WITH_TAINT_TRACKING
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
     SET_VREG(r0, r3)                    @ vAA<- r0
@@ -7868,6 +8740,11 @@ dvmAsmSisterStart:
     mov     r0, rSELF
     mov     r1, rPC
     bl      dvmJitEndTraceSelect        @ (self, pc)
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r2)
+    SET_TAINT_CLEAR(r1)
+    SET_VREG_TAINT(r1, r10, r2)
+// end WITH_TAINT_TRACKING
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
     SET_VREG(r9, r10)                   @ vAA<- new object
@@ -7936,6 +8813,11 @@ dvmAsmSisterStart:
     beq     common_exceptionThrown      @ yes, handle the exception
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
     and     r2, r2, #15                 @ r2<- A
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r1)
+    SET_TAINT_CLEAR(r3)
+    SET_VREG_TAINT(r3, r2, r1)
+// end WITH_TAINT_TRACKING
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
     SET_VREG(r0, r2)                    @ vA<- r0
     GOTO_OPCODE(ip)                     @ jump to next instruction
@@ -7968,6 +8850,9 @@ dvmAsmSisterStart:
     FETCH(r1, 2)                        @ r1<- FEDC or CCCC
     str     r0, [rSELF, #offThread_retval]      @ retval.l <- new array
     str     rINST, [rSELF, #offThread_retval+4] @ retval.h <- type
+// begin WITH_TAINT_TRACKING
+    add     r2, r0, #offArrayObject_taint
+// end WITH_TAINT_TRACKING
     add     r0, r0, #offArrayObject_contents @ r0<- newArray->contents
     subs    r9, r9, #1                  @ length--, check for neg
     FETCH_ADVANCE_INST(3)               @ advance to next instr, load rINST
@@ -7975,6 +8860,11 @@ dvmAsmSisterStart:
 
     @ copy values from registers into the array
     @ r0=array, r1=CCCC/FEDC, r9=length (from AA or B), r10=AA/BA
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_CLEAR(r3)
+    str     r3, [rSELF, #offThread_rtaint]    @ rtaint <- clear
+    str     r3, [r2]
+// end WITH_TAINT_TRACKING
     .if     0
     add     r2, rFP, r1, lsl #2         @ r2<- &fp[CCCC]
 1:  ldr     r3, [r2], #4                @ r3<- *r2++
@@ -8052,6 +8942,9 @@ dvmAsmSisterStart:
     FETCH(r1, 2)                        @ r1<- FEDC or CCCC
     str     r0, [rSELF, #offThread_retval]      @ retval.l <- new array
     str     rINST, [rSELF, #offThread_retval+4] @ retval.h <- type
+// begin WITH_TAINT_TRACKING
+    add     r2, r0, #offArrayObject_taint
+// end WITH_TAINT_TRACKING
     add     r0, r0, #offArrayObject_contents @ r0<- newArray->contents
     subs    r9, r9, #1                  @ length--, check for neg
     FETCH_ADVANCE_INST(3)               @ advance to next instr, load rINST
@@ -8059,6 +8952,11 @@ dvmAsmSisterStart:
 
     @ copy values from registers into the array
     @ r0=array, r1=CCCC/FEDC, r9=length (from AA or B), r10=AA/BA
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_CLEAR(r3)
+    str     r3, [rSELF, #offThread_rtaint]    @ rtaint <- clear
+    str     r3, [r2]
+// end WITH_TAINT_TRACKING
     .if     1
     add     r2, rFP, r1, lsl #2         @ r2<- &fp[CCCC]
 1:  ldr     r3, [r2], #4                @ r3<- *r2++
@@ -8111,23 +9009,53 @@ dvmAsmSisterStart:
 /* continuation for OP_CMPL_FLOAT */
 .LOP_CMPL_FLOAT_finish:
     SET_VREG(r0, r9)                    @ vAA<- r0
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r1)
+    SET_TAINT_CLEAR(r0)
+    SET_VREG_TAINT(r0, r9, r1)
+// end WITH_TAINT_TRACKING
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
+
 /* continuation for OP_CMPG_FLOAT */
 .LOP_CMPG_FLOAT_finish:
     SET_VREG(r0, r9)                    @ vAA<- r0
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r1)
+    SET_TAINT_CLEAR(r0)
+    SET_VREG_TAINT(r0, r9, r1)
+// end WITH_TAINT_TRACKING
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
+
 /* continuation for OP_CMPL_DOUBLE */
 .LOP_CMPL_DOUBLE_finish:
+    fmstat                              @ export status flags
+    movgt   r0, #1                      @ (greater than) r1<- 1
+    moveq   r0, #0                      @ (equal) r1<- 0
     SET_VREG(r0, r9)                    @ vAA<- r0
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r1)
+    SET_TAINT_CLEAR(r0)
+    SET_VREG_TAINT(r0, r9, r1)
+// end WITH_TAINT_TRACKING
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
+
 /* continuation for OP_CMPG_DOUBLE */
 .LOP_CMPG_DOUBLE_finish:
+    fmstat                              @ export status flags
+    mvnmi   r0, #0                      @ (less than) r1<- -1
+    moveq   r0, #0                      @ (equal) r1<- 0
     SET_VREG(r0, r9)                    @ vAA<- r0
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r1)
+    SET_TAINT_CLEAR(r0)
+    SET_VREG_TAINT(r0, r9, r1)
+// end WITH_TAINT_TRACKING
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
+
 /* continuation for OP_CMP_LONG */
 
 .LOP_CMP_LONG_less:
@@ -8136,6 +9064,11 @@ dvmAsmSisterStart:
     @ instead, we just replicate the tail end.
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
     SET_VREG(r1, r9)                    @ vAA<- r1
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r0)
+    SET_TAINT_CLEAR(r1)
+    SET_VREG_TAINT(r1, r9, r0)
+// end WITH_TAINT_TRACKING
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
@@ -8146,28 +9079,177 @@ dvmAsmSisterStart:
 .LOP_CMP_LONG_finish:
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
     SET_VREG(r1, r9)                    @ vAA<- r1
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r0)
+    SET_TAINT_CLEAR(r1)
+    SET_VREG_TAINT(r1, r9, r0)
+// end WITH_TAINT_TRACKING
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
+cmp_long_taint_prop:
+    add     r2, rFP, r2, lsl #3         @ r2<- &fp[BB]
+    add     r3, rFP, r3, lsl #3         @ r3<- &fp[CC]
+//    ldmia   r2, {r0-r1}                 @ r0/r1<- vBB/vBB+1
+    ldr     r0, [r2, #0]
+    ldr     r1, [r2, #8]
+//    ldmia   r3, {r2-r3}                 @ r2/r3<- vCC/vCC+1
+    ldr     r2, [r3, #0]
+    ldr     r3, [r3, #8]
+    bx      lr
+
+/* continuation for OP_AGET */
+
+.LOP_AGET_taint_prop_1:
+    ldr	    r2, [r0, #offArrayObject_taint]
+    SET_TAINT_FP(r10)
+    GET_VREG_TAINT(r3, r3, r10)
+    orr	    r2, r3, r2                  @ r2<- r2 | r1
+    bx	    lr
+
+.LOP_AGET_taint_prop_2:
+    bcs     common_errArrayIndex        @ index >= length, bail
+    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
+    SET_TAINT_FP(r3)
+    SET_VREG_TAINT(r2, r9, r3)
+    bx      lr
+
 /* continuation for OP_AGET_WIDE */
 
 .LOP_AGET_WIDE_finish:
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
-    ldrd    r2, [r0, #offArrayObject_contents]  @ r2/r3<- vBB[vCC]
-    add     r9, rFP, r9, lsl #2         @ r9<- &fp[AA]
+// begin WITH_TAINT_TRACKING
+    ldrd    r0, [r0, #offArrayObject_contents]  @ r0/r1<- vBB[vCC]
+    mov     r2, r1
+    mov     r1, r10
+    mov     r3, r10
+    add     r9, rFP, r9, lsl #3         @ r9<- &fp[AA]
+// end WITH_TAINT_TRACKING
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    stmia   r9, {r2-r3}                 @ vAA/vAA+1<- r2/r3
+// begin WITH_TAINT_TRACKING
+    stmia   r9, {r0-r3}                 @ vAA/vAA+1<- r2/r3
+// begin WITH_TAINT_TRACKING
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
+.LOP_AGET_WIDE_taint_prop:
+    ldr     r2, [r0, #offArrayObject_taint]
+    SET_TAINT_FP(r10)
+    GET_VREG_TAINT(r10, r3, r10)
+    orr     r10, r10, r2                @ r10<- r10 | r1
+    bx      lr
+
+/* continuation for OP_AGET_OBJECT */
+
+.LOP_AGET_OBJECT_taint_prop_1:
+    ldr	    r2, [r0, #offArrayObject_taint]
+    SET_TAINT_FP(r10)
+    GET_VREG_TAINT(r3, r3, r10)
+    orr	    r2, r3, r2                  @ r2<- r2 | r1
+    bx	    lr
+
+.LOP_AGET_OBJECT_taint_prop_2:
+    bcs     common_errArrayIndex        @ index >= length, bail
+    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
+    SET_TAINT_FP(r3)
+    SET_VREG_TAINT(r2, r9, r3)
+    bx      lr
+
+/* continuation for OP_AGET_BOOLEAN */
+
+.LOP_AGET_BOOLEAN_taint_prop_1:
+    ldr	    r2, [r0, #offArrayObject_taint]
+    SET_TAINT_FP(r10)
+    GET_VREG_TAINT(r3, r3, r10)
+    orr	    r2, r3, r2                  @ r2<- r2 | r1
+    bx	    lr
+
+.LOP_AGET_BOOLEAN_taint_prop_2:
+    bcs     common_errArrayIndex        @ index >= length, bail
+    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
+    SET_TAINT_FP(r3)
+    SET_VREG_TAINT(r2, r9, r3)
+    bx      lr
+
+/* continuation for OP_AGET_BYTE */
+
+.LOP_AGET_BYTE_taint_prop_1:
+    ldr	    r2, [r0, #offArrayObject_taint]
+    SET_TAINT_FP(r10)
+    GET_VREG_TAINT(r3, r3, r10)
+    orr	    r2, r3, r2                  @ r2<- r2 | r1
+    bx	    lr
+
+.LOP_AGET_BYTE_taint_prop_2:
+    bcs     common_errArrayIndex        @ index >= length, bail
+    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
+    SET_TAINT_FP(r3)
+    SET_VREG_TAINT(r2, r9, r3)
+    bx      lr
+
+/* continuation for OP_AGET_CHAR */
+
+.LOP_AGET_CHAR_taint_prop_1:
+    ldr	    r2, [r0, #offArrayObject_taint]
+    SET_TAINT_FP(r10)
+    GET_VREG_TAINT(r3, r3, r10)
+    orr	    r2, r3, r2                  @ r2<- r2 | r1
+    bx	    lr
+
+.LOP_AGET_CHAR_taint_prop_2:
+    bcs     common_errArrayIndex        @ index >= length, bail
+    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
+    SET_TAINT_FP(r3)
+    SET_VREG_TAINT(r2, r9, r3)
+    bx      lr
+
+/* continuation for OP_AGET_SHORT */
+
+.LOP_AGET_SHORT_taint_prop_1:
+    ldr	    r2, [r0, #offArrayObject_taint]
+    SET_TAINT_FP(r10)
+    GET_VREG_TAINT(r3, r3, r10)
+    orr	    r2, r3, r2                  @ r2<- r2 | r1
+    bx	    lr
+
+.LOP_AGET_SHORT_taint_prop_2:
+    bcs     common_errArrayIndex        @ index >= length, bail
+    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
+    SET_TAINT_FP(r3)
+    SET_VREG_TAINT(r2, r9, r3)
+    bx      lr
+
+/* continuation for OP_APUT */
+
+.LOP_APUT_taint_prop:
+    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
+    GET_VREG(r1, r2)                    @ r1<- vBB (array object)
+    ldr     r2, [r1, #offArrayObject_taint]
+    SET_TAINT_FP(r3)
+    GET_VREG_TAINT(r3, r9, r3)
+    orr     r2, r2, r3                  @ r2<- r2 | r3
+    str     r2, [r1, #offArrayObject_taint]
+    bx      lr
+
 /* continuation for OP_APUT_WIDE */
 
 .LOP_APUT_WIDE_finish:
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
-    ldmia   r9, {r2-r3}                 @ r2/r3<- vAA/vAA+1
+// begin WITH_TAINT_TRACKING
+//    ldmia   r9, {r2-r3}                 @ r2/r3<- vAA/vAA+1
+    ldr     r2, [r9, #0]
+    ldr     r3, [r9, #8]
+    ldr     r1, [r9, #4]                      @ r1<- array taint
+    ldr     r9, [r10, #offArrayObject_taint]
+    orr     r1, r1, r9                        @ r1<- r1 | r9
+    str     r1, [r10, #offArrayObject_taint]
+// end WITH_TAINT_TRACKING
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+// begin WITH_TAINT_TRACKING
     strd    r2, [r0, #offArrayObject_contents]  @ r2/r3<- vBB[vCC]
+// end WITH_TAINT_TRACKING
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
+
 /* continuation for OP_APUT_OBJECT */
     /*
      * On entry:
@@ -8176,6 +9258,9 @@ dvmAsmSisterStart:
      *  r10 = offset into array (vBB + vCC * width)
      */
 .LOP_APUT_OBJECT_finish:
+// begin WITH_TAINT_TRACKING
+    str     r2, [rINST, #offArrayObject_taint]
+// end WITH_TAINT_TRACKING
     cmp     r9, #0                      @ storing null reference?
     beq     .LOP_APUT_OBJECT_skip_check      @ yes, skip type checks
     ldr     r0, [r9, #offObject_clazz]  @ r0<- obj->clazz
@@ -8204,6 +9289,65 @@ dvmAsmSisterStart:
     bl      dvmThrowArrayStoreExceptionIncompatibleElement
     b       common_exceptionThrown
 
+.LOP_APUT_OBJECT_taint_prop_1:
+    SET_TAINT_FP(r3)
+    GET_VREG_TAINT(r2, r9, r3)
+    bx      lr
+
+.LOP_APUT_OBJECT_taint_prop_2:
+    ldr     r3, [rINST, #offArrayObject_taint]
+    orr     r2, r2, r3                  @ r2<- r2 | r3
+    bx      lr
+
+
+/* continuation for OP_APUT_BOOLEAN */
+
+.LOP_APUT_BOOLEAN_taint_prop:
+    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
+    GET_VREG(r1, r2)                    @ r1<- vBB (array object)
+    ldr     r2, [r1, #offArrayObject_taint]
+    SET_TAINT_FP(r3)
+    GET_VREG_TAINT(r3, r9, r3)
+    orr     r2, r2, r3                  @ r2<- r2 | r3
+    str     r2, [r1, #offArrayObject_taint]
+    bx      lr
+
+/* continuation for OP_APUT_BYTE */
+
+.LOP_APUT_BYTE_taint_prop:
+    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
+    GET_VREG(r1, r2)                    @ r1<- vBB (array object)
+    ldr     r2, [r1, #offArrayObject_taint]
+    SET_TAINT_FP(r3)
+    GET_VREG_TAINT(r3, r9, r3)
+    orr     r2, r2, r3                  @ r2<- r2 | r3
+    str     r2, [r1, #offArrayObject_taint]
+    bx      lr
+
+/* continuation for OP_APUT_CHAR */
+
+.LOP_APUT_CHAR_taint_prop:
+    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
+    GET_VREG(r1, r2)                    @ r1<- vBB (array object)
+    ldr     r2, [r1, #offArrayObject_taint]
+    SET_TAINT_FP(r3)
+    GET_VREG_TAINT(r3, r9, r3)
+    orr     r2, r2, r3                  @ r2<- r2 | r3
+    str     r2, [r1, #offArrayObject_taint]
+    bx      lr
+
+/* continuation for OP_APUT_SHORT */
+
+.LOP_APUT_SHORT_taint_prop:
+    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
+    GET_VREG(r1, r2)                    @ r1<- vBB (array object)
+    ldr     r2, [r1, #offArrayObject_taint]
+    SET_TAINT_FP(r3)
+    GET_VREG_TAINT(r3, r9, r3)
+    orr     r2, r2, r3                  @ r2<- r2 | r3
+    str     r2, [r1, #offArrayObject_taint]
+    bx      lr
+
 /* continuation for OP_IGET */
 
     /*
@@ -8216,13 +9360,29 @@ dvmAsmSisterStart:
     cmp     r9, #0                      @ check object for null
     ldr     r3, [r0, #offInstField_byteOffset]  @ r3<- byte offset of field
     beq     common_errNullObject        @ object was null
+// begin WITH_TAINT_TRACKING
     ldr   r0, [r9, r3]                @ r0<- obj.field (8/16/32 bits)
+    add     r3, r3, #4
+    ldr	    r3, [r9, r3]
+    orr     r3, r3, r10
+// end WITH_TAINT_TRACKING
     ubfx    r2, rINST, #8, #4           @ r2<- A
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
     SET_VREG(r0, r2)                    @ fp[A]<- r0
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r1)
+    SET_VREG_TAINT(r3, r2, r1)
+// end WITH_TAINT_TRACKING
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
+.LOP_IGET_taint_prop:
+    GET_VREG(r9, r0)                    @ r9<- fp[B], the object pointer
+    SET_TAINT_FP(r3)
+    GET_VREG_TAINT(r10, r0, r3)
+    ldr     r0, [r2, r1, lsl #2]        @ r0<- resolved InstField ptr
+    bx      lr
+
 /* continuation for OP_IGET_WIDE */
 
     /*
@@ -8234,14 +9394,32 @@ dvmAsmSisterStart:
     cmp     r9, #0                      @ check object for null
     ldr     r3, [r0, #offInstField_byteOffset]  @ r3<- byte offset of field
     beq     common_errNullObject        @ object was null
+// begin WITH_TAINT_TRACKING
     ldrd    r0, [r9, r3]                @ r0/r1<- obj.field (64-bit align ok)
+    add     r3, r3, #8
+    ldr     r3, [r9, r3]
+    orr	    r10, r3, r10
     ubfx    r2, rINST, #8, #4           @ r2<- A
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
-    add     r3, rFP, r2, lsl #2         @ r3<- &fp[A]
+    add     r3, rFP, r2, lsl #3         @ r3<- &fp[A]
+// end WITH_TAINT_TRACKING
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    stmia   r3, {r0-r1}                 @ fp[A]<- r0/r1
+// begin WITH_TAINT_TRACKING
+//    stmia   r3, {r0-r1}                 @ fp[A]<- r0/r1
+    str    r0, [r3, #0]
+    str    r10, [r3, #4]
+    str    r1, [r3, #8]
+    str    r10, [r3, #12]
+// end WITH_TAINT_TRACKING
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
+.LOP_IGET_WIDE_taint_prop:
+    GET_VREG(r9, r0)                    @ r9<- fp[B], the object pointer
+    SET_TAINT_FP(r3)
+    GET_VREG_TAINT(r10, r0, r3)
+    ldr     r0, [r2, r1, lsl #2]        @ r0<- resolved InstField ptr
+    bx      lr
+
 /* continuation for OP_IGET_OBJECT */
 
     /*
@@ -8254,15 +9432,37 @@ dvmAsmSisterStart:
     cmp     r9, #0                      @ check object for null
     ldr     r3, [r0, #offInstField_byteOffset]  @ r3<- byte offset of field
     beq     common_errNullObject        @ object was null
+// begin WITH_TAINT_TRACKING
+//    .if     0
+//    add     r0, r9, r3                  @ r0<- address of field
+//    bl      dvmQuasiAtomicRead64        @ r0/r1<- value/taint
+//    orr	    r3, r1, r10
+//    .else
     ldr   r0, [r9, r3]                @ r0<- obj.field (8/16/32 bits)
     @ no-op                             @ acquiring load
+    add     r3, r3, #4
+    ldr	    r3, [r9, r3]
+    orr     r3, r3, r10
+//    .endif
+// end WITH_TAINT_TRACKING
     mov     r2, rINST, lsr #8           @ r2<- A+
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
     and     r2, r2, #15                 @ r2<- A
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
     SET_VREG(r0, r2)                    @ fp[A]<- r0
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r1)
+    SET_VREG_TAINT(r3, r2, r1)
+// end WITH_TAINT_TRACKING
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
+.LOP_IGET_OBJECT_taint_prop:
+    GET_VREG(r9, r0)                    @ r9<- fp[B], the object pointer
+    SET_TAINT_FP(r3)
+    GET_VREG_TAINT(r10, r0, r3)
+    ldr     r0, [r2, r1, lsl #2]        @ r0<- resolved InstField ptr
+    bx      lr
+
 /* continuation for OP_IGET_BOOLEAN */
 
     /*
@@ -8275,15 +9475,37 @@ dvmAsmSisterStart:
     cmp     r9, #0                      @ check object for null
     ldr     r3, [r0, #offInstField_byteOffset]  @ r3<- byte offset of field
     beq     common_errNullObject        @ object was null
+// begin WITH_TAINT_TRACKING
+//    .if     0
+//    add     r0, r9, r3                  @ r0<- address of field
+//    bl      dvmQuasiAtomicRead64        @ r0/r1<- value/taint
+//    orr	    r3, r1, r10
+//    .else
     ldr   r0, [r9, r3]                @ r0<- obj.field (8/16/32 bits)
     @ no-op                             @ acquiring load
+    add     r3, r3, #4
+    ldr	    r3, [r9, r3]
+    orr     r3, r3, r10
+//    .endif
+// end WITH_TAINT_TRACKING
     mov     r2, rINST, lsr #8           @ r2<- A+
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
     and     r2, r2, #15                 @ r2<- A
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
     SET_VREG(r0, r2)                    @ fp[A]<- r0
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r1)
+    SET_VREG_TAINT(r3, r2, r1)
+// end WITH_TAINT_TRACKING
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
+.LOP_IGET_BOOLEAN_taint_prop:
+    GET_VREG(r9, r0)                    @ r9<- fp[B], the object pointer
+    SET_TAINT_FP(r3)
+    GET_VREG_TAINT(r10, r0, r3)
+    ldr     r0, [r2, r1, lsl #2]        @ r0<- resolved InstField ptr
+    bx      lr
+
 /* continuation for OP_IGET_BYTE */
 
     /*
@@ -8296,15 +9518,37 @@ dvmAsmSisterStart:
     cmp     r9, #0                      @ check object for null
     ldr     r3, [r0, #offInstField_byteOffset]  @ r3<- byte offset of field
     beq     common_errNullObject        @ object was null
+// begin WITH_TAINT_TRACKING
+//    .if     0
+//    add     r0, r9, r3                  @ r0<- address of field
+//    bl      dvmQuasiAtomicRead64        @ r0/r1<- value/taint
+//    orr	    r3, r1, r10
+//    .else
     ldr   r0, [r9, r3]                @ r0<- obj.field (8/16/32 bits)
     @ no-op                             @ acquiring load
+    add     r3, r3, #4
+    ldr	    r3, [r9, r3]
+    orr     r3, r3, r10
+//    .endif
+// end WITH_TAINT_TRACKING
     mov     r2, rINST, lsr #8           @ r2<- A+
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
     and     r2, r2, #15                 @ r2<- A
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
     SET_VREG(r0, r2)                    @ fp[A]<- r0
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r1)
+    SET_VREG_TAINT(r3, r2, r1)
+// end WITH_TAINT_TRACKING
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
+.LOP_IGET_BYTE_taint_prop:
+    GET_VREG(r9, r0)                    @ r9<- fp[B], the object pointer
+    SET_TAINT_FP(r3)
+    GET_VREG_TAINT(r10, r0, r3)
+    ldr     r0, [r2, r1, lsl #2]        @ r0<- resolved InstField ptr
+    bx      lr
+
 /* continuation for OP_IGET_CHAR */
 
     /*
@@ -8317,15 +9561,37 @@ dvmAsmSisterStart:
     cmp     r9, #0                      @ check object for null
     ldr     r3, [r0, #offInstField_byteOffset]  @ r3<- byte offset of field
     beq     common_errNullObject        @ object was null
+// begin WITH_TAINT_TRACKING
+//    .if     0
+//    add     r0, r9, r3                  @ r0<- address of field
+//    bl      dvmQuasiAtomicRead64        @ r0/r1<- value/taint
+//    orr	    r3, r1, r10
+//    .else
     ldr   r0, [r9, r3]                @ r0<- obj.field (8/16/32 bits)
     @ no-op                             @ acquiring load
+    add     r3, r3, #4
+    ldr	    r3, [r9, r3]
+    orr     r3, r3, r10
+//    .endif
+// end WITH_TAINT_TRACKING
     mov     r2, rINST, lsr #8           @ r2<- A+
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
     and     r2, r2, #15                 @ r2<- A
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
     SET_VREG(r0, r2)                    @ fp[A]<- r0
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r1)
+    SET_VREG_TAINT(r3, r2, r1)
+// end WITH_TAINT_TRACKING
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
+.LOP_IGET_CHAR_taint_prop:
+    GET_VREG(r9, r0)                    @ r9<- fp[B], the object pointer
+    SET_TAINT_FP(r3)
+    GET_VREG_TAINT(r10, r0, r3)
+    ldr     r0, [r2, r1, lsl #2]        @ r0<- resolved InstField ptr
+    bx      lr
+
 /* continuation for OP_IGET_SHORT */
 
     /*
@@ -8338,15 +9604,37 @@ dvmAsmSisterStart:
     cmp     r9, #0                      @ check object for null
     ldr     r3, [r0, #offInstField_byteOffset]  @ r3<- byte offset of field
     beq     common_errNullObject        @ object was null
+// begin WITH_TAINT_TRACKING
+//    .if     0
+//    add     r0, r9, r3                  @ r0<- address of field
+//    bl      dvmQuasiAtomicRead64        @ r0/r1<- value/taint
+//    orr	    r3, r1, r10
+//    .else
     ldr   r0, [r9, r3]                @ r0<- obj.field (8/16/32 bits)
     @ no-op                             @ acquiring load
+    add     r3, r3, #4
+    ldr	    r3, [r9, r3]
+    orr     r3, r3, r10
+//    .endif
+// end WITH_TAINT_TRACKING
     mov     r2, rINST, lsr #8           @ r2<- A+
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
     and     r2, r2, #15                 @ r2<- A
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
     SET_VREG(r0, r2)                    @ fp[A]<- r0
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r1)
+    SET_VREG_TAINT(r3, r2, r1)
+// end WITH_TAINT_TRACKING
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
+.LOP_IGET_SHORT_taint_prop:
+    GET_VREG(r9, r0)                    @ r9<- fp[B], the object pointer
+    SET_TAINT_FP(r3)
+    GET_VREG_TAINT(r10, r0, r3)
+    ldr     r0, [r2, r1, lsl #2]        @ r0<- resolved InstField ptr
+    bx      lr
+
 /* continuation for OP_IPUT */
 
     /*
@@ -8360,12 +9648,21 @@ dvmAsmSisterStart:
     ubfx    r1, rINST, #8, #4           @ r1<- A
     cmp     r9, #0                      @ check object for null
     GET_VREG(r0, r1)                    @ r0<- fp[A]
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r2)
+    GET_VREG_TAINT(r10, r1, r2)
+// end WITH_TAINT_TRACKING
     beq     common_errNullObject        @ object was null
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
     str  r0, [r9, r3]                @ obj.field (8/16/32 bits)<- r0
+// begin WITH_TAINT_TRACKING
+    add	    r3, r3, #4
+    str	    r10, [r9, r3]
+// end WITH_TAINT_TRACKING
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
+
 /* continuation for OP_IPUT_WIDE */
 
     /*
@@ -8377,14 +9674,26 @@ dvmAsmSisterStart:
     ubfx    r2, rINST, #8, #4           @ r2<- A
     cmp     r9, #0                      @ check object for null
     ldr     r3, [r0, #offInstField_byteOffset]  @ r3<- byte offset of field
-    add     r2, rFP, r2, lsl #2         @ r3<- &fp[A]
+// begin WITH_TAINT_TRACKING
+    add     r2, rFP, r2, lsl #3         @ r3<- &fp[A]
+// end WITH_TAINT_TRACKING
     beq     common_errNullObject        @ object was null
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
-    ldmia   r2, {r0-r1}                 @ r0/r1<- fp[A]
+// begin WITH_TAINT_TRACKING
+//    ldmia   r2, {r0-r1}                 @ r0/r1<- fp[A]
+    ldr	    r0, [r2, #0]
+    ldr     r1, [r2, #8]
+    ldr	    r10, [r2, #4]
+// end WITH_TAINT_TRACKING
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    strd    r0, [r9, r3]                @ obj.field (64 bits, aligned)<- r0
+    strd    r0, [r9, r3]                @ obj.field (64 bits, aligned)<- r0/r1
+// begin WITH_TAINT_TRACKING
+    add	    r3, r3, #8
+    str	    r10, [r9, r3]
+// end WITH_TAINT_TRACKING
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
+
 /* continuation for OP_IPUT_OBJECT */
 
     /*
@@ -8399,15 +9708,29 @@ dvmAsmSisterStart:
     and     r1, r1, #15                 @ r1<- A
     cmp     r9, #0                      @ check object for null
     GET_VREG(r0, r1)                    @ r0<- fp[A]
-    ldr     r2, [rSELF, #offThread_cardTable]  @ r2<- card table base
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r2)
+    GET_VREG_TAINT(r10, r1, r2)
+    ldr     r11, [rSELF, #offThread_cardTable]  @ r11<- card table base
+// end WITH_TAINT_TRACKING
     beq     common_errNullObject        @ object was null
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
     @ no-op                         @ releasing store
+// begin WITH_TAINT_TRACKING
+//    .if     0
+//    add     r2, r9, r3                  @ r2<- target address
+//    mov     r1, r10                     @ r1<-taint
+//    bl      dvmQuasiAtomicSwap64        @ stores r0/r1 into addr r2
+//    .else
     str     r0, [r9, r3]                @ obj.field (32 bits)<- r0
+    add     r3, r3, #4
+    str     r10, [r9, r3]
+//    .endif
     @ no-op 
     cmp     r0, #0                      @ stored a null reference?
-    strneb  r2, [r2, r9, lsr #GC_CARD_SHIFT]  @ mark card if not
+    strneb  r11, [r11, r9, lsr #GC_CARD_SHIFT]  @ mark card if not
+// end WITH_TAINT_TRACKING
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
 /* continuation for OP_IPUT_BOOLEAN */
@@ -8424,14 +9747,29 @@ dvmAsmSisterStart:
     and     r1, r1, #15                 @ r1<- A
     cmp     r9, #0                      @ check object for null
     GET_VREG(r0, r1)                    @ r0<- fp[A]
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r2)
+    GET_VREG_TAINT(r10, r1, r2)
+// end WITH_TAINT_TRACKING
     beq     common_errNullObject        @ object was null
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    @ no-op                         @ releasing store
+    @ no-op                          @ releasing store
+// begin WITH_TAINT_TRACKING
+//    .if     0
+//    add     r2, r9, r3                  @ r2<- target address
+//    mov	    r1, r10                     @ r1<-taint
+//    bl      dvmQuasiAtomicSwap64        @ stores r0/r1 into addr r2
+//    .else
     str  r0, [r9, r3]                @ obj.field (8/16/32 bits)<- r0
+    add	    r3, r3, #4
+    str	    r10, [r9, r3]
+//    .endif
+// end WITH_TAINT_TRACKING
     @ no-op 
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
+
 /* continuation for OP_IPUT_BYTE */
 
     /*
@@ -8446,14 +9784,29 @@ dvmAsmSisterStart:
     and     r1, r1, #15                 @ r1<- A
     cmp     r9, #0                      @ check object for null
     GET_VREG(r0, r1)                    @ r0<- fp[A]
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r2)
+    GET_VREG_TAINT(r10, r1, r2)
+// end WITH_TAINT_TRACKING
     beq     common_errNullObject        @ object was null
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    @ no-op                         @ releasing store
+    @ no-op                          @ releasing store
+// begin WITH_TAINT_TRACKING
+//    .if     0
+//    add     r2, r9, r3                  @ r2<- target address
+//    mov	    r1, r10                     @ r1<-taint
+//    bl      dvmQuasiAtomicSwap64        @ stores r0/r1 into addr r2
+//    .else
     str  r0, [r9, r3]                @ obj.field (8/16/32 bits)<- r0
+    add	    r3, r3, #4
+    str	    r10, [r9, r3]
+//    .endif
+// end WITH_TAINT_TRACKING
     @ no-op 
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
+
 /* continuation for OP_IPUT_CHAR */
 
     /*
@@ -8468,14 +9821,29 @@ dvmAsmSisterStart:
     and     r1, r1, #15                 @ r1<- A
     cmp     r9, #0                      @ check object for null
     GET_VREG(r0, r1)                    @ r0<- fp[A]
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r2)
+    GET_VREG_TAINT(r10, r1, r2)
+// end WITH_TAINT_TRACKING
     beq     common_errNullObject        @ object was null
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    @ no-op                         @ releasing store
+    @ no-op                          @ releasing store
+// begin WITH_TAINT_TRACKING
+//    .if     0
+//    add     r2, r9, r3                  @ r2<- target address
+//    mov	    r1, r10                     @ r1<-taint
+//    bl      dvmQuasiAtomicSwap64        @ stores r0/r1 into addr r2
+//    .else
     str  r0, [r9, r3]                @ obj.field (8/16/32 bits)<- r0
+    add	    r3, r3, #4
+    str	    r10, [r9, r3]
+//    .endif
+// end WITH_TAINT_TRACKING
     @ no-op 
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
+
 /* continuation for OP_IPUT_SHORT */
 
     /*
@@ -8490,14 +9858,29 @@ dvmAsmSisterStart:
     and     r1, r1, #15                 @ r1<- A
     cmp     r9, #0                      @ check object for null
     GET_VREG(r0, r1)                    @ r0<- fp[A]
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r2)
+    GET_VREG_TAINT(r10, r1, r2)
+// end WITH_TAINT_TRACKING
     beq     common_errNullObject        @ object was null
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    @ no-op                         @ releasing store
+    @ no-op                          @ releasing store
+// begin WITH_TAINT_TRACKING
+//    .if     0
+//    add     r2, r9, r3                  @ r2<- target address
+//    mov	    r1, r10                     @ r1<-taint
+//    bl      dvmQuasiAtomicSwap64        @ stores r0/r1 into addr r2
+//    .else
     str  r0, [r9, r3]                @ obj.field (8/16/32 bits)<- r0
+    add	    r3, r3, #4
+    str	    r10, [r9, r3]
+//    .endif
+// end WITH_TAINT_TRACKING
     @ no-op 
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
+
 /* continuation for OP_SGET */
 
     /*
@@ -8524,8 +9907,47 @@ dvmAsmSisterStart:
 #endif
     b       .LOP_SGET_finish
 
+.LOP_SGET_taint_prop:
+//    .if     0
+//    add     r0, r0, #offStaticField_value		@ r0<- address of field
+//    bl      dvmQuasiAtomicRead32SfieldTaint		@ r0/r1<- value/taint
+//    .else
+    ldr	    r1, [r0, #offStaticField_taint] @ r1<- taint value
+    ldr     r0, [r0, #offStaticField_value] @ r0<- field value
+    @ no-op                             @ acquiring load
+//    .endif
+    mov     r2, rINST, lsr #8           @ r2<- AA
+    SET_TAINT_FP(r3)
+    SET_VREG_TAINT(r1, r2, r3)
+    bx      lr
+
+
 /* continuation for OP_SGET_WIDE */
 
+.LOP_SGET_WIDE_finish:
+    mov     r9, rINST, lsr #8           @ r9<- AA
+// begin WITH_TAINT_TRACKING
+    ldr	    r3, [r0, #offStaticField_taint] @ r3<- taint value
+    .if 0
+    stmfd   sp!, {r3}    
+    add     r0, r0, #offStaticField_value @ r0<- pointer to data
+    bl      dvmQuasiAtomicRead64        @ r0/r1<- contents of field
+    ldmfd   sp!, {r3}
+    .else
+    ldrd    r0, [r0, #offStaticField_value] @ r0/r1<- field value (aligned)
+    .endif
+    add     r9, rFP, r9, lsl #3         @ r9<- &fp[AA]
+    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
+//    stmia   r9, {r2-r3}                 @ vAA/vAA+1<- r2/r3
+    str	    r0, [r9, #0]
+    str	    r3, [r9, #4]
+    str	    r1, [r9, #8]
+    str	    r3, [r9, #12]
+// end WITH_TAINT_TRACKING
+
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+    GOTO_OPCODE(ip)                     @ jump to next instruction
+
     /*
      * Continuation if the field has not yet been resolved.
      *  r1:  BBBB field ref
@@ -8578,6 +10000,21 @@ dvmAsmSisterStart:
 #endif
     b       .LOP_SGET_OBJECT_finish
 
+.LOP_SGET_OBJECT_taint_prop:
+//    .if     0
+//    add     r0, r0, #offStaticField_value		@ r0<- address of field
+//    bl      dvmQuasiAtomicRead32SfieldTaint		@ r0/r1<- value/taint
+//    .else
+    ldr	    r1, [r0, #offStaticField_taint] @ r1<- taint value
+    ldr     r0, [r0, #offStaticField_value] @ r0<- field value
+    @ no-op                             @ acquiring load
+//    .endif
+    mov     r2, rINST, lsr #8           @ r2<- AA
+    SET_TAINT_FP(r3)
+    SET_VREG_TAINT(r1, r2, r3)
+    bx      lr
+
+
 /* continuation for OP_SGET_BOOLEAN */
 
     /*
@@ -8604,6 +10041,21 @@ dvmAsmSisterStart:
 #endif
     b       .LOP_SGET_BOOLEAN_finish
 
+.LOP_SGET_BOOLEAN_taint_prop:
+//    .if     0
+//    add     r0, r0, #offStaticField_value		@ r0<- address of field
+//    bl      dvmQuasiAtomicRead32SfieldTaint		@ r0/r1<- value/taint
+//    .else
+    ldr	    r1, [r0, #offStaticField_taint] @ r1<- taint value
+    ldr     r0, [r0, #offStaticField_value] @ r0<- field value
+    @ no-op                             @ acquiring load
+//    .endif
+    mov     r2, rINST, lsr #8           @ r2<- AA
+    SET_TAINT_FP(r3)
+    SET_VREG_TAINT(r1, r2, r3)
+    bx      lr
+
+
 /* continuation for OP_SGET_BYTE */
 
     /*
@@ -8630,8 +10082,23 @@ dvmAsmSisterStart:
 #endif
     b       .LOP_SGET_BYTE_finish
 
-/* continuation for OP_SGET_CHAR */
-
+.LOP_SGET_BYTE_taint_prop:
+//    .if     0
+//    add     r0, r0, #offStaticField_value		@ r0<- address of field
+//    bl      dvmQuasiAtomicRead32SfieldTaint		@ r0/r1<- value/taint
+//    .else
+    ldr	    r1, [r0, #offStaticField_taint] @ r1<- taint value
+    ldr     r0, [r0, #offStaticField_value] @ r0<- field value
+    @ no-op                             @ acquiring load
+//    .endif
+    mov     r2, rINST, lsr #8           @ r2<- AA
+    SET_TAINT_FP(r3)
+    SET_VREG_TAINT(r1, r2, r3)
+    bx      lr
+
+
+/* continuation for OP_SGET_CHAR */
+
     /*
      * Continuation if the field has not yet been resolved.
      *  r1:  BBBB field ref
@@ -8656,6 +10123,21 @@ dvmAsmSisterStart:
 #endif
     b       .LOP_SGET_CHAR_finish
 
+.LOP_SGET_CHAR_taint_prop:
+//    .if     0
+//    add     r0, r0, #offStaticField_value		@ r0<- address of field
+//    bl      dvmQuasiAtomicRead32SfieldTaint		@ r0/r1<- value/taint
+//    .else
+    ldr	    r1, [r0, #offStaticField_taint] @ r1<- taint value
+    ldr     r0, [r0, #offStaticField_value] @ r0<- field value
+    @ no-op                             @ acquiring load
+//    .endif
+    mov     r2, rINST, lsr #8           @ r2<- AA
+    SET_TAINT_FP(r3)
+    SET_VREG_TAINT(r1, r2, r3)
+    bx      lr
+
+
 /* continuation for OP_SGET_SHORT */
 
     /*
@@ -8682,6 +10164,21 @@ dvmAsmSisterStart:
 #endif
     b       .LOP_SGET_SHORT_finish
 
+.LOP_SGET_SHORT_taint_prop:
+//    .if     0
+//    add     r0, r0, #offStaticField_value		@ r0<- address of field
+//    bl      dvmQuasiAtomicRead32SfieldTaint		@ r0/r1<- value/taint
+//    .else
+    ldr	    r1, [r0, #offStaticField_taint] @ r1<- taint value
+    ldr     r0, [r0, #offStaticField_value] @ r0<- field value
+    @ no-op                             @ acquiring load
+//    .endif
+    mov     r2, rINST, lsr #8           @ r2<- AA
+    SET_TAINT_FP(r3)
+    SET_VREG_TAINT(r1, r2, r3)
+    bx      lr
+
+
 /* continuation for OP_SPUT */
 
     /*
@@ -8708,6 +10205,25 @@ dvmAsmSisterStart:
 #endif
     b       .LOP_SPUT_finish          @ resume
 
+.LOP_SPUT_taint_prop:
+//    .if     0
+//    add     r3, r0, #offStaticField_value   @ r3<- addr
+//    mov     r0, r1                          @ r0<- val
+//    mov     r1, r3                          @ r1<- addr
+//    SET_TAINT_FP(r3)
+//    GET_VREG_TAINT(r2, r2, r3)              @ r2<- taint
+//    bl      dvmQuasiAtomicSwap32SfieldTaint
+//    .else
+    @ no-op                        	    @ releasing store
+    str     r1, [r0, #offStaticField_value] @ field<- vAA
+    SET_TAINT_FP(r3)
+    GET_VREG_TAINT(r1, r2, r3)
+    str	    r1, [r0, #offStaticField_taint]
+    @ no-op 
+//    .endif
+    bx      lr
+
+
 /* continuation for OP_SPUT_WIDE */
 
     /*
@@ -8738,14 +10254,35 @@ dvmAsmSisterStart:
 #endif
     b       .LOP_SPUT_WIDE_finish          @ resume
 
+.LOP_SPUT_WIDE_taint_prop:
+//    ldmia   r9, {r0-r1}                 @ r0/r1<- vAA/vAA+1
+    ldr r3, [r9, #4]
+    ldr r0, [r9, #0]
+    ldr r1, [r9, #8]
+    bx      lr
+
+
 /* continuation for OP_SPUT_OBJECT */
 
 
 .LOP_SPUT_OBJECT_end:
-    str     r1, [r0, #offStaticField_value]  @ field<- vAA
-    @ no-op 
-    cmp     r1, #0                      @ stored a null object?
-    strneb  r2, [r2, r9, lsr #GC_CARD_SHIFT]  @ mark card based on obj head
+// begin WITH_TAINT_TRACKING
+//    .if     0
+//    add	    r2, r0, #offStaticField_value       @ r2<- addr
+//    mov	    r0, r1                              @ r0<- val
+//    mov	    r1, r2                              @ r1<- addr
+//    mov	    r2, r3                              @ r2<- taint
+//    bl      dvmQuasiAtomicSwap32SfieldTaint
+//    cmp     r0, #0                    	        @ stored a null object?
+//    .else
+    str     r1, [r0, #offStaticField_value] @ field<- vAA
+    str	    r3, [r0, #offStaticField_taint]
+//    @ no-op 
+    cmp     r1, #0                              @ stored a null object?
+//    .endif
+//    strneb  r2, [r2, r9, lsr #GC_CARD_SHIFT]  @ mark card based on obj head
+    strneb  r10, [r10, r9, lsr #GC_CARD_SHIFT]  @ mark card based on obj head
+// end WITH_TAINT_TRACKING
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
     /* Continuation if the field has not yet been resolved.
@@ -8798,6 +10335,25 @@ dvmAsmSisterStart:
 #endif
     b       .LOP_SPUT_BOOLEAN_finish          @ resume
 
+.LOP_SPUT_BOOLEAN_taint_prop:
+//    .if     0
+//    add     r3, r0, #offStaticField_value   @ r3<- addr
+//    mov     r0, r1                          @ r0<- val
+//    mov     r1, r3                          @ r1<- addr
+//    SET_TAINT_FP(r3)
+//    GET_VREG_TAINT(r2, r2, r3)              @ r2<- taint
+//    bl      dvmQuasiAtomicSwap32SfieldTaint
+//    .else
+    @ no-op                        	    @ releasing store
+    str     r1, [r0, #offStaticField_value] @ field<- vAA
+    SET_TAINT_FP(r3)
+    GET_VREG_TAINT(r1, r2, r3)
+    str	    r1, [r0, #offStaticField_taint]
+    @ no-op 
+//    .endif
+    bx      lr
+
+
 /* continuation for OP_SPUT_BYTE */
 
     /*
@@ -8824,6 +10380,25 @@ dvmAsmSisterStart:
 #endif
     b       .LOP_SPUT_BYTE_finish          @ resume
 
+.LOP_SPUT_BYTE_taint_prop:
+//    .if     0
+//    add     r3, r0, #offStaticField_value   @ r3<- addr
+//    mov     r0, r1                          @ r0<- val
+//    mov     r1, r3                          @ r1<- addr
+//    SET_TAINT_FP(r3)
+//    GET_VREG_TAINT(r2, r2, r3)              @ r2<- taint
+//    bl      dvmQuasiAtomicSwap32SfieldTaint
+//    .else
+    @ no-op                        	    @ releasing store
+    str     r1, [r0, #offStaticField_value] @ field<- vAA
+    SET_TAINT_FP(r3)
+    GET_VREG_TAINT(r1, r2, r3)
+    str	    r1, [r0, #offStaticField_taint]
+    @ no-op 
+//    .endif
+    bx      lr
+
+
 /* continuation for OP_SPUT_CHAR */
 
     /*
@@ -8850,6 +10425,25 @@ dvmAsmSisterStart:
 #endif
     b       .LOP_SPUT_CHAR_finish          @ resume
 
+.LOP_SPUT_CHAR_taint_prop:
+//    .if     0
+//    add     r3, r0, #offStaticField_value   @ r3<- addr
+//    mov     r0, r1                          @ r0<- val
+//    mov     r1, r3                          @ r1<- addr
+//    SET_TAINT_FP(r3)
+//    GET_VREG_TAINT(r2, r2, r3)              @ r2<- taint
+//    bl      dvmQuasiAtomicSwap32SfieldTaint
+//    .else
+    @ no-op                        	    @ releasing store
+    str     r1, [r0, #offStaticField_value] @ field<- vAA
+    SET_TAINT_FP(r3)
+    GET_VREG_TAINT(r1, r2, r3)
+    str	    r1, [r0, #offStaticField_taint]
+    @ no-op 
+//    .endif
+    bx      lr
+
+
 /* continuation for OP_SPUT_SHORT */
 
     /*
@@ -8876,6 +10470,25 @@ dvmAsmSisterStart:
 #endif
     b       .LOP_SPUT_SHORT_finish          @ resume
 
+.LOP_SPUT_SHORT_taint_prop:
+//    .if     0
+//    add     r3, r0, #offStaticField_value   @ r3<- addr
+//    mov     r0, r1                          @ r0<- val
+//    mov     r1, r3                          @ r1<- addr
+//    SET_TAINT_FP(r3)
+//    GET_VREG_TAINT(r2, r2, r3)              @ r2<- taint
+//    bl      dvmQuasiAtomicSwap32SfieldTaint
+//    .else
+    @ no-op                        	    @ releasing store
+    str     r1, [r0, #offStaticField_value] @ field<- vAA
+    SET_TAINT_FP(r3)
+    GET_VREG_TAINT(r1, r2, r3)
+    str	    r1, [r0, #offStaticField_taint]
+    @ no-op 
+//    .endif
+    bx      lr
+
+
 /* continuation for OP_INVOKE_VIRTUAL */
 
     /*
@@ -9076,145 +10689,1154 @@ dvmAsmSisterStart:
     b       common_exceptionThrown            @ yes, handle exception
 #endif
 
-/* continuation for OP_FLOAT_TO_LONG */
-/*
- * Convert the float in r0 to a long in r0/r1.
- *
- * We have to clip values to long min/max per the specification.  The
- * expected common case is a "reasonable" value that converts directly
- * to modest integer.  The EABI convert function isn't doing this for us.
- */
-f2l_doconv:
-    stmfd   sp!, {r4, lr}
-    mov     r1, #0x5f000000             @ (float)maxlong
-    mov     r4, r0
-    bl      __aeabi_fcmpge              @ is arg >= maxlong?
-    cmp     r0, #0                      @ nonzero == yes
-    mvnne   r0, #0                      @ return maxlong (7fffffff)
-    mvnne   r1, #0x80000000
-    ldmnefd sp!, {r4, pc}
+/* continuation for OP_NEG_LONG */
+
+.LOP_NEG_LONG_finish:
+// begin WITH_TAINT_TRACKING
+//    stmia   r9, {r0-r1}                 @ vAA<- r0/r1
+    str     r0, [r9, #0]
+    str     r10, [r9, #4]
+    str     r1, [r9, #8]
+    str     r10, [r9, #12]
+// end WITH_TAINT_TRACKING
+    GOTO_OPCODE(ip)                     @ jump to next instruction
+    /* 10-11 instructions */
+
+/* continuation for OP_NOT_LONG */
+
+.LOP_NOT_LONG_finish:
+// begin WITH_TAINT_TRACKING
+//    stmia   r9, {r0-r1}                 @ vAA<- r0/r1
+    str     r0, [r9, #0]
+    str     r10, [r9, #4]
+    str     r1, [r9, #8]
+    str     r10, [r9, #12]
+// end WITH_TAINT_TRACKING
+    GOTO_OPCODE(ip)                     @ jump to next instruction
+    /* 10-11 instructions */
+
+/* continuation for OP_NEG_DOUBLE */
+
+.LOP_NEG_DOUBLE_finish:
+// begin WITH_TAINT_TRACKING
+//    stmia   r9, {r0-r1}                 @ vAA<- r0/r1
+    str     r0, [r9, #0]
+    str     r10, [r9, #4]
+    str     r1, [r9, #8]
+    str     r10, [r9, #12]
+// end WITH_TAINT_TRACKING
+    GOTO_OPCODE(ip)                     @ jump to next instruction
+    /* 10-11 instructions */
+
+/* continuation for OP_INT_TO_LONG */
+
+.LOP_INT_TO_LONG_finish:
+// begin WITH_TAINT_TRACKING
+//    stmia   r9, {r0-r1}                 @ vA/vA+1<- r0/r1
+    str     r0, [r9, #0]
+    str     r10, [r9, #4]
+    str     r1, [r9, #8]
+    str     r10, [r9, #12]
+// end WITH_TAINT_TRACKING
+    GOTO_OPCODE(ip)                     @ jump to next instruction
+    /* 9-10 instructions */
+
+/* continuation for OP_LONG_TO_DOUBLE */
+
+.LOP_LONG_TO_DOUBLE_finish:
+// begin WITH_TAINT_TRACKING
+//    stmia   r9, {r0-r1}                 @ vAA<- r0/r1
+    str     r0, [r9, #0]
+    str     r10, [r9, #4]
+    str     r1, [r9, #8]
+    str     r10, [r9, #12]
+// end WITH_TAINT_TRACKING
+    GOTO_OPCODE(ip)                     @ jump to next instruction
+    /* 10-11 instructions */
+
+/* continuation for OP_FLOAT_TO_LONG */
+
+.LOP_FLOAT_TO_LONG_finish:
+// begin WITH_TAINT_TRACKING
+//    stmia   r9, {r0-r1}                 @ vA/vA+1<- r0/r1
+    str     r0, [r9, #0]
+    str     r10, [r9, #4]
+    str     r1, [r9, #8]
+    str     r10, [r9, #12]
+// end WITH_TAINT_TRACKING
+    GOTO_OPCODE(ip)                     @ jump to next instruction
+    /* 9-10 instructions */
+
+/* continuation for OP_FLOAT_TO_LONG */
+/*
+ * Convert the float in r0 to a long in r0/r1.
+ *
+ * We have to clip values to long min/max per the specification.  The
+ * expected common case is a "reasonable" value that converts directly
+ * to modest integer.  The EABI convert function isn't doing this for us.
+ */
+f2l_doconv:
+    stmfd   sp!, {r4, lr}
+    mov     r1, #0x5f000000             @ (float)maxlong
+    mov     r4, r0
+    bl      __aeabi_fcmpge              @ is arg >= maxlong?
+    cmp     r0, #0                      @ nonzero == yes
+    mvnne   r0, #0                      @ return maxlong (7fffffff)
+    mvnne   r1, #0x80000000
+    ldmnefd sp!, {r4, pc}
+
+    mov     r0, r4                      @ recover arg
+    mov     r1, #0xdf000000             @ (float)minlong
+    bl      __aeabi_fcmple              @ is arg <= minlong?
+    cmp     r0, #0                      @ nonzero == yes
+    movne   r0, #0                      @ return minlong (80000000)
+    movne   r1, #0x80000000
+    ldmnefd sp!, {r4, pc}
+
+    mov     r0, r4                      @ recover arg
+    mov     r1, r4
+    bl      __aeabi_fcmpeq              @ is arg == self?
+    cmp     r0, #0                      @ zero == no
+    moveq   r1, #0                      @ return zero for NaN
+    ldmeqfd sp!, {r4, pc}
+
+    mov     r0, r4                      @ recover arg
+    bl      __aeabi_f2lz                @ convert float to long
+    ldmfd   sp!, {r4, pc}
+
+
+/* continuation for OP_DOUBLE_TO_LONG */
+
+.LOP_DOUBLE_TO_LONG_finish:
+// begin WITH_TAINT_TRACKING
+//    stmia   r9, {r0-r1}                 @ vAA<- r0/r1
+    str     r0, [r9, #0]
+    str     r10, [r9, #4]
+    str     r1, [r9, #8]
+    str     r10, [r9, #12]
+// end WITH_TAINT_TRACKING
+    GOTO_OPCODE(ip)                     @ jump to next instruction
+    /* 10-11 instructions */
+
+/* continuation for OP_DOUBLE_TO_LONG */
+/*
+ * Convert the double in r0/r1 to a long in r0/r1.
+ *
+ * We have to clip values to long min/max per the specification.  The
+ * expected common case is a "reasonable" value that converts directly
+ * to modest integer.  The EABI convert function isn't doing this for us.
+ */
+d2l_doconv:
+    stmfd   sp!, {r4, r5, lr}           @ save regs
+    mov     r3, #0x43000000             @ maxlong, as a double (high word)
+    add     r3, #0x00e00000             @  0x43e00000
+    mov     r2, #0                      @ maxlong, as a double (low word)
+    sub     sp, sp, #4                  @ align for EABI
+    mov     r4, r0                      @ save a copy of r0
+    mov     r5, r1                      @  and r1
+    bl      __aeabi_dcmpge              @ is arg >= maxlong?
+    cmp     r0, #0                      @ nonzero == yes
+    mvnne   r0, #0                      @ return maxlong (7fffffffffffffff)
+    mvnne   r1, #0x80000000
+    bne     1f
+
+    mov     r0, r4                      @ recover arg
+    mov     r1, r5
+    mov     r3, #0xc3000000             @ minlong, as a double (high word)
+    add     r3, #0x00e00000             @  0xc3e00000
+    mov     r2, #0                      @ minlong, as a double (low word)
+    bl      __aeabi_dcmple              @ is arg <= minlong?
+    cmp     r0, #0                      @ nonzero == yes
+    movne   r0, #0                      @ return minlong (8000000000000000)
+    movne   r1, #0x80000000
+    bne     1f
+
+    mov     r0, r4                      @ recover arg
+    mov     r1, r5
+    mov     r2, r4                      @ compare against self
+    mov     r3, r5
+    bl      __aeabi_dcmpeq              @ is arg == self?
+    cmp     r0, #0                      @ zero == no
+    moveq   r1, #0                      @ return zero for NaN
+    beq     1f
+
+    mov     r0, r4                      @ recover arg
+    mov     r1, r5
+    bl      __aeabi_d2lz                @ convert double to long
+
+1:
+    add     sp, sp, #4
+    ldmfd   sp!, {r4, r5, pc}
+
+
+/* continuation for OP_ADD_INT */
+
+.LOP_ADD_INT_taint_prop:
+    SET_TAINT_FP(r10)
+    GET_VREG_TAINT(r3, r3, r10)
+    GET_VREG_TAINT(r2, r2, r10)
+    orr     r2, r3, r2
+    SET_VREG_TAINT(r2, r9, r10)
+    bx      lr
+
+/* continuation for OP_SUB_INT */
+
+.LOP_SUB_INT_taint_prop:
+    SET_TAINT_FP(r10)
+    GET_VREG_TAINT(r3, r3, r10)
+    GET_VREG_TAINT(r2, r2, r10)
+    orr     r2, r3, r2
+    SET_VREG_TAINT(r2, r9, r10)
+    bx      lr
+
+/* continuation for OP_MUL_INT */
+
+.LOP_MUL_INT_taint_prop:
+    SET_TAINT_FP(r10)
+    GET_VREG_TAINT(r3, r3, r10)
+    GET_VREG_TAINT(r2, r2, r10)
+    orr     r2, r3, r2
+    SET_VREG_TAINT(r2, r9, r10)
+    bx      lr
+
+/* continuation for OP_DIV_INT */
+
+.LOP_DIV_INT_taint_prop:
+    SET_TAINT_FP(r10)
+    GET_VREG_TAINT(r3, r3, r10)
+    GET_VREG_TAINT(r2, r2, r10)
+    orr     r2, r3, r2
+    SET_VREG_TAINT(r2, r9, r10)
+    bx      lr
+
+/* continuation for OP_REM_INT */
+
+.LOP_REM_INT_taint_prop:
+    SET_TAINT_FP(r10)
+    GET_VREG_TAINT(r3, r3, r10)
+    GET_VREG_TAINT(r2, r2, r10)
+    orr     r2, r3, r2
+    SET_VREG_TAINT(r2, r9, r10)
+    bx      lr
+
+/* continuation for OP_AND_INT */
+
+.LOP_AND_INT_taint_prop:
+    SET_TAINT_FP(r10)
+    GET_VREG_TAINT(r3, r3, r10)
+    GET_VREG_TAINT(r2, r2, r10)
+    orr     r2, r3, r2
+    SET_VREG_TAINT(r2, r9, r10)
+    bx      lr
+
+/* continuation for OP_OR_INT */
+
+.LOP_OR_INT_taint_prop:
+    SET_TAINT_FP(r10)
+    GET_VREG_TAINT(r3, r3, r10)
+    GET_VREG_TAINT(r2, r2, r10)
+    orr     r2, r3, r2
+    SET_VREG_TAINT(r2, r9, r10)
+    bx      lr
+
+/* continuation for OP_XOR_INT */
+
+.LOP_XOR_INT_taint_prop:
+    SET_TAINT_FP(r10)
+    GET_VREG_TAINT(r3, r3, r10)
+    GET_VREG_TAINT(r2, r2, r10)
+    orr     r2, r3, r2
+    SET_VREG_TAINT(r2, r9, r10)
+    bx      lr
+
+/* continuation for OP_SHL_INT */
+
+.LOP_SHL_INT_taint_prop:
+    SET_TAINT_FP(r10)
+    GET_VREG_TAINT(r3, r3, r10)
+    GET_VREG_TAINT(r2, r2, r10)
+    orr     r2, r3, r2
+    SET_VREG_TAINT(r2, r9, r10)
+    bx      lr
+
+/* continuation for OP_SHR_INT */
+
+.LOP_SHR_INT_taint_prop:
+    SET_TAINT_FP(r10)
+    GET_VREG_TAINT(r3, r3, r10)
+    GET_VREG_TAINT(r2, r2, r10)
+    orr     r2, r3, r2
+    SET_VREG_TAINT(r2, r9, r10)
+    bx      lr
+
+/* continuation for OP_USHR_INT */
+
+.LOP_USHR_INT_taint_prop:
+    SET_TAINT_FP(r10)
+    GET_VREG_TAINT(r3, r3, r10)
+    GET_VREG_TAINT(r2, r2, r10)
+    orr     r2, r3, r2
+    SET_VREG_TAINT(r2, r9, r10)
+    bx      lr
+
+/* continuation for OP_ADD_LONG */
+
+.LOP_ADD_LONG_taint_prop:
+    add     r9, rFP, r9, lsl #3         @ r9<- &fp[AA]
+    stmfd   sp!, {r9}
+    add     r2, rFP, r2, lsl #3         @ r2<- &fp[BB]
+    add     r3, rFP, r3, lsl #3         @ r3<- &fp[CC]
+//    ldmia   r2, {r0-r1}                 @ r0/r1<- vBB/vBB+1
+    ldr     r0, [r2, #0]
+    ldr     r9, [r2, #4]
+    ldr     r1, [r2, #8]
+//    ldmia   r3, {r2-r3}                 @ r2/r3<- vCC/vCC+1
+    ldr     r2, [r3, #0]
+    ldr     r10, [r3, #4]
+    ldr     r3, [r3, #8]
+    orr     r10, r9, r10
+    ldmfd   sp!, {r9}
+    bx      lr
+
+/* continuation for OP_SUB_LONG */
+
+.LOP_SUB_LONG_taint_prop:
+    add     r9, rFP, r9, lsl #3         @ r9<- &fp[AA]
+    stmfd   sp!, {r9}
+    add     r2, rFP, r2, lsl #3         @ r2<- &fp[BB]
+    add     r3, rFP, r3, lsl #3         @ r3<- &fp[CC]
+//    ldmia   r2, {r0-r1}                 @ r0/r1<- vBB/vBB+1
+    ldr     r0, [r2, #0]
+    ldr     r9, [r2, #4]
+    ldr     r1, [r2, #8]
+//    ldmia   r3, {r2-r3}                 @ r2/r3<- vCC/vCC+1
+    ldr     r2, [r3, #0]
+    ldr     r10, [r3, #4]
+    ldr     r3, [r3, #8]
+    orr     r10, r9, r10
+    ldmfd   sp!, {r9}
+    bx      lr
+
+/* continuation for OP_MUL_LONG */
+
+.LOP_MUL_LONG_finish:
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+// begin WITH_TAINT_TRACKING
+//    stmia   r0, {r9-r10}                @ vAA/vAA+1<- r9/r10
+    str     r9, [r0, #0]
+    str     r10, [r0, #8]
+    str     r10, [r0, #12]
+    ldmfd   sp!, {r10}
+    str     r10, [r0, #4]
+// end WITH_TAINT_TRACKING
+    GOTO_OPCODE(ip)                     @ jump to next instruction
+
+mul_long_taint_prop:
+    add     r2, rFP, r2, lsl #3         @ r2<- &fp[BB]
+    add     r3, rFP, r3, lsl #3         @ r3<- &fp[CC]
+//    ldmia   r2, {r0-r1}                 @ r0/r1<- vBB/vBB+1
+    ldr     r0, [r2, #0]
+    ldr     r9, [r2, #4]
+    ldr     r1, [r2, #8]
+//    ldmia   r3, {r2-r3}                 @ r2/r3<- vCC/vCC+1
+    ldr     r2, [r3, #0]
+    ldr     r10, [r3, #4]
+    ldr     r3, [r3, #8]
+    orr     r10, r9, r10
+    stmfd   sp!, {r10}
+    bx      lr
+
+/* continuation for OP_DIV_LONG */
+
+.LOP_DIV_LONG_taint_prop:
+    add     r9, rFP, r9, lsl #3         @ r9<- &fp[AA]
+    stmfd   sp!, {r9}
+    add     r2, rFP, r2, lsl #3         @ r2<- &fp[BB]
+    add     r3, rFP, r3, lsl #3         @ r3<- &fp[CC]
+//    ldmia   r2, {r0-r1}                 @ r0/r1<- vBB/vBB+1
+    ldr     r0, [r2, #0]
+    ldr     r9, [r2, #4]
+    ldr     r1, [r2, #8]
+//    ldmia   r3, {r2-r3}                 @ r2/r3<- vCC/vCC+1
+    ldr     r2, [r3, #0]
+    ldr     r10, [r3, #4]
+    ldr     r3, [r3, #8]
+    orr     r10, r9, r10
+    ldmfd   sp!, {r9}
+    bx      lr
+
+/* continuation for OP_REM_LONG */
+
+.LOP_REM_LONG_taint_prop:
+    add     r9, rFP, r9, lsl #3         @ r9<- &fp[AA]
+    stmfd   sp!, {r9}
+    add     r2, rFP, r2, lsl #3         @ r2<- &fp[BB]
+    add     r3, rFP, r3, lsl #3         @ r3<- &fp[CC]
+//    ldmia   r2, {r0-r1}                 @ r0/r1<- vBB/vBB+1
+    ldr     r0, [r2, #0]
+    ldr     r9, [r2, #4]
+    ldr     r1, [r2, #8]
+//    ldmia   r3, {r2-r3}                 @ r2/r3<- vCC/vCC+1
+    ldr     r2, [r3, #0]
+    ldr     r10, [r3, #4]
+    ldr     r3, [r3, #8]
+    orr     r10, r9, r10
+    ldmfd   sp!, {r9}
+    bx      lr
+
+/* continuation for OP_AND_LONG */
+
+.LOP_AND_LONG_taint_prop:
+    add     r9, rFP, r9, lsl #3         @ r9<- &fp[AA]
+    stmfd   sp!, {r9}
+    add     r2, rFP, r2, lsl #3         @ r2<- &fp[BB]
+    add     r3, rFP, r3, lsl #3         @ r3<- &fp[CC]
+//    ldmia   r2, {r0-r1}                 @ r0/r1<- vBB/vBB+1
+    ldr     r0, [r2, #0]
+    ldr     r9, [r2, #4]
+    ldr     r1, [r2, #8]
+//    ldmia   r3, {r2-r3}                 @ r2/r3<- vCC/vCC+1
+    ldr     r2, [r3, #0]
+    ldr     r10, [r3, #4]
+    ldr     r3, [r3, #8]
+    orr     r10, r9, r10
+    ldmfd   sp!, {r9}
+    bx      lr
+
+/* continuation for OP_OR_LONG */
+
+.LOP_OR_LONG_taint_prop:
+    add     r9, rFP, r9, lsl #3         @ r9<- &fp[AA]
+    stmfd   sp!, {r9}
+    add     r2, rFP, r2, lsl #3         @ r2<- &fp[BB]
+    add     r3, rFP, r3, lsl #3         @ r3<- &fp[CC]
+//    ldmia   r2, {r0-r1}                 @ r0/r1<- vBB/vBB+1
+    ldr     r0, [r2, #0]
+    ldr     r9, [r2, #4]
+    ldr     r1, [r2, #8]
+//    ldmia   r3, {r2-r3}                 @ r2/r3<- vCC/vCC+1
+    ldr     r2, [r3, #0]
+    ldr     r10, [r3, #4]
+    ldr     r3, [r3, #8]
+    orr     r10, r9, r10
+    ldmfd   sp!, {r9}
+    bx      lr
+
+/* continuation for OP_XOR_LONG */
+
+.LOP_XOR_LONG_taint_prop:
+    add     r9, rFP, r9, lsl #3         @ r9<- &fp[AA]
+    stmfd   sp!, {r9}
+    add     r2, rFP, r2, lsl #3         @ r2<- &fp[BB]
+    add     r3, rFP, r3, lsl #3         @ r3<- &fp[CC]
+//    ldmia   r2, {r0-r1}                 @ r0/r1<- vBB/vBB+1
+    ldr     r0, [r2, #0]
+    ldr     r9, [r2, #4]
+    ldr     r1, [r2, #8]
+//    ldmia   r3, {r2-r3}                 @ r2/r3<- vCC/vCC+1
+    ldr     r2, [r3, #0]
+    ldr     r10, [r3, #4]
+    ldr     r3, [r3, #8]
+    orr     r10, r9, r10
+    ldmfd   sp!, {r9}
+    bx      lr
+
+/* continuation for OP_SHL_LONG */
+
+.LOP_SHL_LONG_finish:
+    mov     r0, r0, asl r2              @  r0<- r0 << r2
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+// begin WITH_TAINT_TRACKING
+//    stmia   r9, {r0-r1}                 @ vAA/vAA+1<- r0/r1
+    str     r0, [r9, #0]
+    str     r10, [r9, #4]
+    str     r1, [r9, #8]
+    str     r10, [r9, #12]
+// end WITH_TAINT_TRACKING
+    GOTO_OPCODE(ip)                     @ jump to next instruction
+
+shl_long_taint_prop:
+    add     r3, rFP, r3, lsl #3         @ r3<- &fp[BB]
+    GET_VREG(r2, r0)                    @ r2<- vCC
+    SET_TAINT_FP(r1)
+    GET_VREG_TAINT(r0, r0, r1)
+//    ldmia   r3, {r0-r1}                 @ r0/r1<- vBB/vBB+1
+    ldr     r1, [r3, #4]
+    orr     r10, r0, r1
+    ldr     r0, [r3, #0]
+    ldr     r1, [r3, #8]
+    and     r2, r2, #63                 @ r2<- r2 & 0x3f
+    add     r9, rFP, r9, lsl #3         @ r9<- &fp[AA]
+    bx      lr
+
+/* continuation for OP_SHR_LONG */
+
+.LOP_SHR_LONG_finish:
+    mov     r1, r1, asr r2              @  r1<- r1 >> r2
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+// begin WITH_TAINT_TRACKING
+//    stmia   r9, {r0-r1}                 @ vAA/vAA+1<- r0/r1
+    str     r0, [r9, #0]
+    str     r10, [r9, #4]
+    str     r1, [r9, #8]
+    str     r10, [r9, #12]
+// end WITH_TAINT_TRACKING
+    GOTO_OPCODE(ip)                     @ jump to next instruction
+
+shr_long_taint_prop:
+    add     r3, rFP, r3, lsl #3         @ r3<- &fp[BB]
+    GET_VREG(r2, r0)                    @ r2<- vCC
+    SET_TAINT_FP(r1)
+    GET_VREG_TAINT(r0, r0, r1)
+//    ldmia   r3, {r0-r1}                 @ r0/r1<- vBB/vBB+1
+    ldr     r1, [r3, #4]
+    orr     r10, r0, r1
+    ldr     r0, [r3, #0]
+    ldr     r1, [r3, #8]
+    and     r2, r2, #63                 @ r2<- r2 & 0x3f
+    add     r9, rFP, r9, lsl #3         @ r9<- &fp[AA]
+    bx      lr
+
+/* continuation for OP_USHR_LONG */
+
+.LOP_USHR_LONG_finish:
+    mov     r1, r1, lsr r2              @  r1<- r1 >>> r2
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+// begin WITH_TAINT_TRACKING
+//    stmia   r9, {r0-r1}                 @ vAA/vAA+1<- r0/r1
+    str     r0, [r9, #0]
+    str     r10, [r9, #4]
+    str     r1, [r9, #8]
+    str     r10, [r9, #12]
+// end WITH_TAINT_TRACKING
+    GOTO_OPCODE(ip)                     @ jump to next instruction
+
+ushr_long_taint_prop:
+    add     r3, rFP, r3, lsl #3         @ r3<- &fp[BB]
+    GET_VREG(r2, r0)                    @ r2<- vCC
+    SET_TAINT_FP(r1)
+    GET_VREG_TAINT(r0, r0, r1)
+//    ldmia   r3, {r0-r1}                 @ r0/r1<- vBB/vBB+1
+    ldr     r1, [r3, #4]
+    orr     r10, r0, r1
+    ldr     r0, [r3, #0]
+    ldr     r1, [r3, #8]
+    and     r2, r2, #63                 @ r0<- r0 & 0x3f
+    add     r9, rFP, r9, lsl #3         @ r9<- &fp[AA]
+    bx      lr
+
+/* continuation for OP_ADD_FLOAT */
+
+.LOP_ADD_FLOAT_finish:
+    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
+    fadds   s2, s0, s1                              @ s2<- op
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+    VREG_INDEX_TO_ADDR(r9, r9)          @ r9<- &vAA
+    fsts    s2, [r9]                    @ vAA<- s2
+// begin WITH_TAINT_TRACKING
+    str     r0, [r9, #4]
+// end WITH_TAINT_TRACKING
+    GOTO_OPCODE(ip)                     @ jump to next instruction
+
+
+/* continuation for OP_SUB_FLOAT */
+
+.LOP_SUB_FLOAT_finish:
+    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
+    fsubs   s2, s0, s1                              @ s2<- op
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+    VREG_INDEX_TO_ADDR(r9, r9)          @ r9<- &vAA
+    fsts    s2, [r9]                    @ vAA<- s2
+// begin WITH_TAINT_TRACKING
+    str     r0, [r9, #4]
+// end WITH_TAINT_TRACKING
+    GOTO_OPCODE(ip)                     @ jump to next instruction
+
+
+/* continuation for OP_MUL_FLOAT */
+
+.LOP_MUL_FLOAT_finish:
+    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
+    fmuls   s2, s0, s1                              @ s2<- op
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+    VREG_INDEX_TO_ADDR(r9, r9)          @ r9<- &vAA
+    fsts    s2, [r9]                    @ vAA<- s2
+// begin WITH_TAINT_TRACKING
+    str     r0, [r9, #4]
+// end WITH_TAINT_TRACKING
+    GOTO_OPCODE(ip)                     @ jump to next instruction
+
+
+/* continuation for OP_DIV_FLOAT */
+
+.LOP_DIV_FLOAT_finish:
+    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
+    fdivs   s2, s0, s1                              @ s2<- op
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+    VREG_INDEX_TO_ADDR(r9, r9)          @ r9<- &vAA
+    fsts    s2, [r9]                    @ vAA<- s2
+// begin WITH_TAINT_TRACKING
+    str     r0, [r9, #4]
+// end WITH_TAINT_TRACKING
+    GOTO_OPCODE(ip)                     @ jump to next instruction
+
+
+/* continuation for OP_REM_FLOAT */
+
+.LOP_REM_FLOAT_taint_prop:
+    SET_TAINT_FP(r10)
+    GET_VREG_TAINT(r3, r3, r10)
+    GET_VREG_TAINT(r2, r2, r10)
+    orr     r2, r3, r2
+    SET_VREG_TAINT(r2, r9, r10)
+    bx      lr
+
+/* continuation for OP_ADD_DOUBLE */
+
+.LOP_ADD_DOUBLE_finish:
+    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
+    faddd   d2, d0, d1                              @ s2<- op
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+    VREG_INDEX_TO_ADDR(r9, r9)          @ r9<- &vAA
+// begin WITH_TAINT_TRACKING
+//    fstd    d2, [r9]                    @ vAA<- d2
+    fsts    s4, [r9]
+    fsts    s5, [r9, #8]
+    str     r0, [r9, #4]
+    str     r0, [r9, #12]
+// end WITH_TAINT_TRACKING
+    GOTO_OPCODE(ip)                     @ jump to next instruction
+
+/* continuation for OP_SUB_DOUBLE */
+
+.LOP_SUB_DOUBLE_finish:
+    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
+    fsubd   d2, d0, d1                              @ s2<- op
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+    VREG_INDEX_TO_ADDR(r9, r9)          @ r9<- &vAA
+// begin WITH_TAINT_TRACKING
+//    fstd    d2, [r9]                    @ vAA<- d2
+    fsts    s4, [r9]
+    fsts    s5, [r9, #8]
+    str     r0, [r9, #4]
+    str     r0, [r9, #12]
+// end WITH_TAINT_TRACKING
+    GOTO_OPCODE(ip)                     @ jump to next instruction
+
+/* continuation for OP_MUL_DOUBLE */
+
+.LOP_MUL_DOUBLE_finish:
+    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
+    fmuld   d2, d0, d1                              @ s2<- op
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+    VREG_INDEX_TO_ADDR(r9, r9)          @ r9<- &vAA
+// begin WITH_TAINT_TRACKING
+//    fstd    d2, [r9]                    @ vAA<- d2
+    fsts    s4, [r9]
+    fsts    s5, [r9, #8]
+    str     r0, [r9, #4]
+    str     r0, [r9, #12]
+// end WITH_TAINT_TRACKING
+    GOTO_OPCODE(ip)                     @ jump to next instruction
+
+/* continuation for OP_DIV_DOUBLE */
+
+.LOP_DIV_DOUBLE_finish:
+    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
+    fdivd   d2, d0, d1                              @ s2<- op
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+    VREG_INDEX_TO_ADDR(r9, r9)          @ r9<- &vAA
+// begin WITH_TAINT_TRACKING
+//    fstd    d2, [r9]                    @ vAA<- d2
+    fsts    s4, [r9]
+    fsts    s5, [r9, #8]
+    str     r0, [r9, #4]
+    str     r0, [r9, #12]
+// end WITH_TAINT_TRACKING
+    GOTO_OPCODE(ip)                     @ jump to next instruction
+
+/* continuation for OP_REM_DOUBLE */
+
+.LOP_REM_DOUBLE_taint_prop:
+    add     r9, rFP, r9, lsl #3         @ r9<- &fp[AA]
+    stmfd   sp!, {r9}
+    add     r2, rFP, r2, lsl #3         @ r2<- &fp[BB]
+    add     r3, rFP, r3, lsl #3         @ r3<- &fp[CC]
+//    ldmia   r2, {r0-r1}                 @ r0/r1<- vBB/vBB+1
+    ldr     r0, [r2, #0]
+    ldr     r9, [r2, #4]
+    ldr     r1, [r2, #8]
+//    ldmia   r3, {r2-r3}                 @ r2/r3<- vCC/vCC+1
+    ldr     r2, [r3, #0]
+    ldr     r10, [r3, #4]
+    ldr     r3, [r3, #8]
+    orr     r10, r9, r10
+    ldmfd   sp!, {r9}
+    bx      lr
+
+/* continuation for OP_ADD_INT_2ADDR */
+
+.LOP_ADD_INT_2ADDR_taint_prop:
+    SET_TAINT_FP(r2)
+    GET_VREG_TAINT(r3, r3, r2)
+    GET_VREG_TAINT(r10, r9, r2)
+    orr     r10, r3, r10
+    SET_VREG_TAINT(r10, r9, r2)
+    bx      lr
+
+/* continuation for OP_SUB_INT_2ADDR */
+
+.LOP_SUB_INT_2ADDR_taint_prop:
+    SET_TAINT_FP(r2)
+    GET_VREG_TAINT(r3, r3, r2)
+    GET_VREG_TAINT(r10, r9, r2)
+    orr     r10, r3, r10
+    SET_VREG_TAINT(r10, r9, r2)
+    bx      lr
+
+/* continuation for OP_MUL_INT_2ADDR */
+
+.LOP_MUL_INT_2ADDR_taint_prop:
+    SET_TAINT_FP(r2)
+    GET_VREG_TAINT(r3, r3, r2)
+    GET_VREG_TAINT(r10, r9, r2)
+    orr     r10, r3, r10
+    SET_VREG_TAINT(r10, r9, r2)
+    bx      lr
+
+/* continuation for OP_DIV_INT_2ADDR */
+
+.LOP_DIV_INT_2ADDR_taint_prop:
+    SET_TAINT_FP(r2)
+    GET_VREG_TAINT(r3, r3, r2)
+    GET_VREG_TAINT(r10, r9, r2)
+    orr     r10, r3, r10
+    SET_VREG_TAINT(r10, r9, r2)
+    bx      lr
+
+/* continuation for OP_REM_INT_2ADDR */
+
+.LOP_REM_INT_2ADDR_taint_prop:
+    SET_TAINT_FP(r2)
+    GET_VREG_TAINT(r3, r3, r2)
+    GET_VREG_TAINT(r10, r9, r2)
+    orr     r10, r3, r10
+    SET_VREG_TAINT(r10, r9, r2)
+    bx      lr
+
+/* continuation for OP_AND_INT_2ADDR */
+
+.LOP_AND_INT_2ADDR_taint_prop:
+    SET_TAINT_FP(r2)
+    GET_VREG_TAINT(r3, r3, r2)
+    GET_VREG_TAINT(r10, r9, r2)
+    orr     r10, r3, r10
+    SET_VREG_TAINT(r10, r9, r2)
+    bx      lr
+
+/* continuation for OP_OR_INT_2ADDR */
+
+.LOP_OR_INT_2ADDR_taint_prop:
+    SET_TAINT_FP(r2)
+    GET_VREG_TAINT(r3, r3, r2)
+    GET_VREG_TAINT(r10, r9, r2)
+    orr     r10, r3, r10
+    SET_VREG_TAINT(r10, r9, r2)
+    bx      lr
+
+/* continuation for OP_XOR_INT_2ADDR */
+
+.LOP_XOR_INT_2ADDR_taint_prop:
+    SET_TAINT_FP(r2)
+    GET_VREG_TAINT(r3, r3, r2)
+    GET_VREG_TAINT(r10, r9, r2)
+    orr     r10, r3, r10
+    SET_VREG_TAINT(r10, r9, r2)
+    bx      lr
+
+/* continuation for OP_SHL_INT_2ADDR */
+
+.LOP_SHL_INT_2ADDR_taint_prop:
+    SET_TAINT_FP(r2)
+    GET_VREG_TAINT(r3, r3, r2)
+    GET_VREG_TAINT(r10, r9, r2)
+    orr     r10, r3, r10
+    SET_VREG_TAINT(r10, r9, r2)
+    bx      lr
+
+/* continuation for OP_SHR_INT_2ADDR */
+
+.LOP_SHR_INT_2ADDR_taint_prop:
+    SET_TAINT_FP(r2)
+    GET_VREG_TAINT(r3, r3, r2)
+    GET_VREG_TAINT(r10, r9, r2)
+    orr     r10, r3, r10
+    SET_VREG_TAINT(r10, r9, r2)
+    bx      lr
+
+/* continuation for OP_USHR_INT_2ADDR */
+
+.LOP_USHR_INT_2ADDR_taint_prop:
+    SET_TAINT_FP(r2)
+    GET_VREG_TAINT(r3, r3, r2)
+    GET_VREG_TAINT(r10, r9, r2)
+    orr     r10, r3, r10
+    SET_VREG_TAINT(r10, r9, r2)
+    bx      lr
+
+/* continuation for OP_ADD_LONG_2ADDR */
+
+.LOP_ADD_LONG_2ADDR_taint_prop:
+    add     r1, rFP, r1, lsl #3         @ r1<- &fp[B]
+    add     r9, rFP, r9, lsl #3         @ r9<- &fp[A]
+//    ldmia   r1, {r2-r3}                 @ r2/r3<- vBB/vBB+1
+    ldr     r2, [r1, #0]
+    ldr     r10, [r1, #4]
+    ldr     r3, [r1, #8]
+//    ldmia   r9, {r0-r1}                 @ r0/r1<- vAA/vAA+1
+    ldr     r0, [r9, #0]
+    ldr     r1, [r9, #8]
+    stmfd   sp!, {r9}
+    ldr     r9, [r9, #4]
+    orr     r10, r9, r10
+    ldmfd   sp!, {r9}
+    bx      lr
+
+/* continuation for OP_SUB_LONG_2ADDR */
+
+.LOP_SUB_LONG_2ADDR_taint_prop:
+    add     r1, rFP, r1, lsl #3         @ r1<- &fp[B]
+    add     r9, rFP, r9, lsl #3         @ r9<- &fp[A]
+//    ldmia   r1, {r2-r3}                 @ r2/r3<- vBB/vBB+1
+    ldr     r2, [r1, #0]
+    ldr     r10, [r1, #4]
+    ldr     r3, [r1, #8]
+//    ldmia   r9, {r0-r1}                 @ r0/r1<- vAA/vAA+1
+    ldr     r0, [r9, #0]
+    ldr     r1, [r9, #8]
+    stmfd   sp!, {r9}
+    ldr     r9, [r9, #4]
+    orr     r10, r9, r10
+    ldmfd   sp!, {r9}
+    bx      lr
+
+/* continuation for OP_MUL_LONG_2ADDR */
+
+mul_long_2addr_taint_prop:
+    ubfx    r9, rINST, #8, #4           @ r9<- A
+    add     r1, rFP, r1, lsl #3         @ r1<- &fp[B]
+    add     rINST, rFP, r9, lsl #3      @ rINST<- &fp[A]
+//    ldmia   r1, {r2-r3}                 @ r2/r3<- vBB/vBB+1
+    ldr     r2, [r1, #0]
+    ldr     r9, [r1, #4]
+    ldr     r3, [r1, #8]
+//    ldmia   rINST, {r0-r1}              @ r0/r1<- vAA/vAA+1
+    ldr     r0, [rINST, #0]
+    ldr     r10, [rINST, #4]
+    ldr     r1, [rINST, #8]
+    orr     r10, r9, r10
+    stmfd   sp!, {r10}
+    mul     ip, r2, r1                  @  ip<- ZxW
+    bx      lr
+
+/* continuation for OP_DIV_LONG_2ADDR */
+
+.LOP_DIV_LONG_2ADDR_taint_prop:
+    add     r1, rFP, r1, lsl #3         @ r1<- &fp[B]
+    add     r9, rFP, r9, lsl #3         @ r9<- &fp[A]
+//    ldmia   r1, {r2-r3}                 @ r2/r3<- vBB/vBB+1
+    ldr     r2, [r1, #0]
+    ldr     r10, [r1, #4]
+    ldr     r3, [r1, #8]
+//    ldmia   r9, {r0-r1}                 @ r0/r1<- vAA/vAA+1
+    ldr     r0, [r9, #0]
+    ldr     r1, [r9, #8]
+    stmfd   sp!, {r9}
+    ldr     r9, [r9, #4]
+    orr     r10, r9, r10
+    ldmfd   sp!, {r9}
+    bx      lr
+
+/* continuation for OP_REM_LONG_2ADDR */
+
+.LOP_REM_LONG_2ADDR_taint_prop:
+    add     r1, rFP, r1, lsl #3         @ r1<- &fp[B]
+    add     r9, rFP, r9, lsl #3         @ r9<- &fp[A]
+//    ldmia   r1, {r2-r3}                 @ r2/r3<- vBB/vBB+1
+    ldr     r2, [r1, #0]
+    ldr     r10, [r1, #4]
+    ldr     r3, [r1, #8]
+//    ldmia   r9, {r0-r1}                 @ r0/r1<- vAA/vAA+1
+    ldr     r0, [r9, #0]
+    ldr     r1, [r9, #8]
+    stmfd   sp!, {r9}
+    ldr     r9, [r9, #4]
+    orr     r10, r9, r10
+    ldmfd   sp!, {r9}
+    bx      lr
+
+/* continuation for OP_AND_LONG_2ADDR */
+
+.LOP_AND_LONG_2ADDR_taint_prop:
+    add     r1, rFP, r1, lsl #3         @ r1<- &fp[B]
+    add     r9, rFP, r9, lsl #3         @ r9<- &fp[A]
+//    ldmia   r1, {r2-r3}                 @ r2/r3<- vBB/vBB+1
+    ldr     r2, [r1, #0]
+    ldr     r10, [r1, #4]
+    ldr     r3, [r1, #8]
+//    ldmia   r9, {r0-r1}                 @ r0/r1<- vAA/vAA+1
+    ldr     r0, [r9, #0]
+    ldr     r1, [r9, #8]
+    stmfd   sp!, {r9}
+    ldr     r9, [r9, #4]
+    orr     r10, r9, r10
+    ldmfd   sp!, {r9}
+    bx      lr
+
+/* continuation for OP_OR_LONG_2ADDR */
+
+.LOP_OR_LONG_2ADDR_taint_prop:
+    add     r1, rFP, r1, lsl #3         @ r1<- &fp[B]
+    add     r9, rFP, r9, lsl #3         @ r9<- &fp[A]
+//    ldmia   r1, {r2-r3}                 @ r2/r3<- vBB/vBB+1
+    ldr     r2, [r1, #0]
+    ldr     r10, [r1, #4]
+    ldr     r3, [r1, #8]
+//    ldmia   r9, {r0-r1}                 @ r0/r1<- vAA/vAA+1
+    ldr     r0, [r9, #0]
+    ldr     r1, [r9, #8]
+    stmfd   sp!, {r9}
+    ldr     r9, [r9, #4]
+    orr     r10, r9, r10
+    ldmfd   sp!, {r9}
+    bx      lr
+
+/* continuation for OP_XOR_LONG_2ADDR */
+
+.LOP_XOR_LONG_2ADDR_taint_prop:
+    add     r1, rFP, r1, lsl #3         @ r1<- &fp[B]
+    add     r9, rFP, r9, lsl #3         @ r9<- &fp[A]
+//    ldmia   r1, {r2-r3}                 @ r2/r3<- vBB/vBB+1
+    ldr     r2, [r1, #0]
+    ldr     r10, [r1, #4]
+    ldr     r3, [r1, #8]
+//    ldmia   r9, {r0-r1}                 @ r0/r1<- vAA/vAA+1
+    ldr     r0, [r9, #0]
+    ldr     r1, [r9, #8]
+    stmfd   sp!, {r9}
+    ldr     r9, [r9, #4]
+    orr     r10, r9, r10
+    ldmfd   sp!, {r9}
+    bx      lr
+
+/* continuation for OP_SHL_LONG_2ADDR */
+
+.LOP_SHL_LONG_2ADDR_finish:
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+// begin WITH_TAINT_TRACKING
+//    stmia   r9, {r0-r1}                 @ vAA/vAA+1<- r0/r1
+    str     r0, [r9, #0]
+    str     r10, [r9, #4]
+    str     r1, [r9, #8]
+    str     r10, [r9, #12]
+// end WITH_TAINT_TRACKING
+    GOTO_OPCODE(ip)                     @ jump to next instruction
 
-    mov     r0, r4                      @ recover arg
-    mov     r1, #0xdf000000             @ (float)minlong
-    bl      __aeabi_fcmple              @ is arg <= minlong?
-    cmp     r0, #0                      @ nonzero == yes
-    movne   r0, #0                      @ return minlong (80000000)
-    movne   r1, #0x80000000
-    ldmnefd sp!, {r4, pc}
+shl_long_2addr_taint_prop:
+    SET_TAINT_FP(r0)
+    GET_VREG_TAINT(r0, r3, r0)
+    add     r9, rFP, r9, lsl #3         @ r9<- &fp[A]
+    and     r2, r2, #63                 @ r2<- r2 & 0x3f
+//    ldmia   r9, {r0-r1}                 @ r0/r1<- vAA/vAA+1
+    ldr     r10, [r9, #4]
+    orr     r10, r0, r10
+    ldr     r0, [r9, #0]
+    ldr     r1, [r9, #8]
+    bx      lr
 
-    mov     r0, r4                      @ recover arg
-    mov     r1, r4
-    bl      __aeabi_fcmpeq              @ is arg == self?
-    cmp     r0, #0                      @ zero == no
-    moveq   r1, #0                      @ return zero for NaN
-    ldmeqfd sp!, {r4, pc}
+/* continuation for OP_SHR_LONG_2ADDR */
 
-    mov     r0, r4                      @ recover arg
-    bl      __aeabi_f2lz                @ convert float to long
-    ldmfd   sp!, {r4, pc}
+.LOP_SHR_LONG_2ADDR_finish:
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+// begin WITH_TAINT_TRACKING
+//    stmia   r9, {r0-r1}                 @ vAA/vAA+1<- r0/r1
+    str     r0, [r9, #0]
+    str     r10, [r9, #4]
+    str     r1, [r9, #8]
+    str     r10, [r9, #12]
+// end WITH_TAINT_TRACKING
+    GOTO_OPCODE(ip)                     @ jump to next instruction
 
-/* continuation for OP_DOUBLE_TO_LONG */
-/*
- * Convert the double in r0/r1 to a long in r0/r1.
- *
- * We have to clip values to long min/max per the specification.  The
- * expected common case is a "reasonable" value that converts directly
- * to modest integer.  The EABI convert function isn't doing this for us.
- */
-d2l_doconv:
-    stmfd   sp!, {r4, r5, lr}           @ save regs
-    mov     r3, #0x43000000             @ maxlong, as a double (high word)
-    add     r3, #0x00e00000             @  0x43e00000
-    mov     r2, #0                      @ maxlong, as a double (low word)
-    sub     sp, sp, #4                  @ align for EABI
-    mov     r4, r0                      @ save a copy of r0
-    mov     r5, r1                      @  and r1
-    bl      __aeabi_dcmpge              @ is arg >= maxlong?
-    cmp     r0, #0                      @ nonzero == yes
-    mvnne   r0, #0                      @ return maxlong (7fffffffffffffff)
-    mvnne   r1, #0x80000000
-    bne     1f
+// OP_SHR_LONG_2ADDR.S
+shr_long_2addr_taint_prop:
+    SET_TAINT_FP(r0)
+    GET_VREG_TAINT(r0, r3, r0)
+    add     r9, rFP, r9, lsl #3         @ r9<- &fp[A]
+    and     r2, r2, #63                 @ r2<- r2 & 0x3f
+//    ldmia   r9, {r0-r1}                 @ r0/r1<- vAA/vAA+1
+    ldr     r10, [r9, #4]
+    orr     r10, r0, r10
+    ldr     r0, [r9, #0]
+    ldr     r1, [r9, #8]
+    bx      lr
 
-    mov     r0, r4                      @ recover arg
-    mov     r1, r5
-    mov     r3, #0xc3000000             @ minlong, as a double (high word)
-    add     r3, #0x00e00000             @  0xc3e00000
-    mov     r2, #0                      @ minlong, as a double (low word)
-    bl      __aeabi_dcmple              @ is arg <= minlong?
-    cmp     r0, #0                      @ nonzero == yes
-    movne   r0, #0                      @ return minlong (8000000000000000)
-    movne   r1, #0x80000000
-    bne     1f
+/* continuation for OP_USHR_LONG_2ADDR */
 
-    mov     r0, r4                      @ recover arg
-    mov     r1, r5
-    mov     r2, r4                      @ compare against self
-    mov     r3, r5
-    bl      __aeabi_dcmpeq              @ is arg == self?
-    cmp     r0, #0                      @ zero == no
-    moveq   r1, #0                      @ return zero for NaN
-    beq     1f
+.LOP_USHR_LONG_2ADDR_finish:
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+// begin WITH_TAINT_TRACKING
+//    stmia   r9, {r0-r1}                 @ vAA/vAA+1<- r0/r1
+    str     r0, [r9, #0]
+    str     r10, [r9, #4]
+    str     r1, [r9, #8]
+    str     r10, [r9, #12]
+// end WITH_TAINT_TRACKING
+    GOTO_OPCODE(ip)                     @ jump to next instruction
 
-    mov     r0, r4                      @ recover arg
-    mov     r1, r5
-    bl      __aeabi_d2lz                @ convert double to long
+ushr_long_2addr_taint_prop:
+    SET_TAINT_FP(r0)
+    GET_VREG_TAINT(r0, r3, r0)
+    add     r9, rFP, r9, lsl #3         @ r9<- &fp[A]
+    and     r2, r2, #63                 @ r2<- r2 & 0x3f
+//    ldmia   r9, {r0-r1}                 @ r0/r1<- vAA/vAA+1
+    ldr     r10, [r9, #4]
+    orr     r10, r0, r10
+    ldr     r0, [r9, #0]
+    ldr     r1, [r9, #8]
+    bx      lr
 
-1:
-    add     sp, sp, #4
-    ldmfd   sp!, {r4, r5, pc}
+/* continuation for OP_ADD_FLOAT_2ADDR */
 
-/* continuation for OP_MUL_LONG */
+.LOP_ADD_FLOAT_2ADDR_finish:
+    fadds   s2, s0, s1                              @ s2<- op
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+    fsts    s2, [r9]                    @ vAA<- s2
+// begin WITH_TAINT_TRACKING
+    str     r0, [r9, #4]
+// end WITH_TAINT_TRACKING
+    GOTO_OPCODE(ip)                     @ jump to next instruction
 
-.LOP_MUL_LONG_finish:
+/* continuation for OP_SUB_FLOAT_2ADDR */
+
+.LOP_SUB_FLOAT_2ADDR_finish:
+    fsubs   s2, s0, s1                              @ s2<- op
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    stmia   r0, {r9-r10}                @ vAA/vAA+1<- r9/r10
+    fsts    s2, [r9]                    @ vAA<- s2
+// begin WITH_TAINT_TRACKING
+    str     r0, [r9, #4]
+// end WITH_TAINT_TRACKING
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
-/* continuation for OP_SHL_LONG */
+/* continuation for OP_MUL_FLOAT_2ADDR */
 
-.LOP_SHL_LONG_finish:
-    mov     r0, r0, asl r2              @  r0<- r0 << r2
+.LOP_MUL_FLOAT_2ADDR_finish:
+    fmuls   s2, s0, s1                              @ s2<- op
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    stmia   r9, {r0-r1}                 @ vAA/vAA+1<- r0/r1
+    fsts    s2, [r9]                    @ vAA<- s2
+// begin WITH_TAINT_TRACKING
+    str     r0, [r9, #4]
+// end WITH_TAINT_TRACKING
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
-/* continuation for OP_SHR_LONG */
+/* continuation for OP_DIV_FLOAT_2ADDR */
 
-.LOP_SHR_LONG_finish:
-    mov     r1, r1, asr r2              @  r1<- r1 >> r2
+.LOP_DIV_FLOAT_2ADDR_finish:
+    fdivs   s2, s0, s1                              @ s2<- op
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    stmia   r9, {r0-r1}                 @ vAA/vAA+1<- r0/r1
+    fsts    s2, [r9]                    @ vAA<- s2
+// begin WITH_TAINT_TRACKING
+    str     r0, [r9, #4]
+// end WITH_TAINT_TRACKING
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
-/* continuation for OP_USHR_LONG */
+/* continuation for OP_REM_FLOAT_2ADDR */
 
-.LOP_USHR_LONG_finish:
-    mov     r1, r1, lsr r2              @  r1<- r1 >>> r2
+.LOP_REM_FLOAT_2ADDR_taint_prop:
+    SET_TAINT_FP(r2)
+    GET_VREG_TAINT(r3, r3, r2)
+    GET_VREG_TAINT(r10, r9, r2)
+    orr     r10, r3, r10
+    SET_VREG_TAINT(r10, r9, r2)
+    bx      lr
+
+/* continuation for OP_ADD_DOUBLE_2ADDR */
+
+.LOP_ADD_DOUBLE_2ADDR_finish:
+    faddd   d2, d0, d1                              @ d2<- op
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    stmia   r9, {r0-r1}                 @ vAA/vAA+1<- r0/r1
+// begin WITH_TAINT_TRACKING
+    orr    r0, r0, r1
+//    fstd    d2, [r9]                    @ vAA<- d2
+    fsts    s4, [r9]
+    fsts    s5, [r9, #8]
+    str     r0, [r9, #4]
+    str     r0, [r9, #12]
+// end WITH_TAINT_TRACKING
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
-/* continuation for OP_SHL_LONG_2ADDR */
+/* continuation for OP_SUB_DOUBLE_2ADDR */
 
-.LOP_SHL_LONG_2ADDR_finish:
+.LOP_SUB_DOUBLE_2ADDR_finish:
+    fsubd   d2, d0, d1                              @ d2<- op
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    stmia   r9, {r0-r1}                 @ vAA/vAA+1<- r0/r1
+// begin WITH_TAINT_TRACKING
+    orr    r0, r0, r1
+//    fstd    d2, [r9]                    @ vAA<- d2
+    fsts    s4, [r9]
+    fsts    s5, [r9, #8]
+    str     r0, [r9, #4]
+    str     r0, [r9, #12]
+// end WITH_TAINT_TRACKING
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
-/* continuation for OP_SHR_LONG_2ADDR */
+/* continuation for OP_MUL_DOUBLE_2ADDR */
 
-.LOP_SHR_LONG_2ADDR_finish:
+.LOP_MUL_DOUBLE_2ADDR_finish:
+    fmuld   d2, d0, d1                              @ d2<- op
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    stmia   r9, {r0-r1}                 @ vAA/vAA+1<- r0/r1
+// begin WITH_TAINT_TRACKING
+    orr    r0, r0, r1
+//    fstd    d2, [r9]                    @ vAA<- d2
+    fsts    s4, [r9]
+    fsts    s5, [r9, #8]
+    str     r0, [r9, #4]
+    str     r0, [r9, #12]
+// end WITH_TAINT_TRACKING
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
-/* continuation for OP_USHR_LONG_2ADDR */
+/* continuation for OP_DIV_DOUBLE_2ADDR */
 
-.LOP_USHR_LONG_2ADDR_finish:
+.LOP_DIV_DOUBLE_2ADDR_finish:
+    fdivd   d2, d0, d1                              @ d2<- op
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    stmia   r9, {r0-r1}                 @ vAA/vAA+1<- r0/r1
+// begin WITH_TAINT_TRACKING
+    orr    r0, r0, r1
+//    fstd    d2, [r9]                    @ vAA<- d2
+    fsts    s4, [r9]
+    fsts    s5, [r9, #8]
+    str     r0, [r9, #4]
+    str     r0, [r9, #12]
+// end WITH_TAINT_TRACKING
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
+/* continuation for OP_REM_DOUBLE_2ADDR */
+
+.LOP_REM_DOUBLE_2ADDR_taint_prop:
+    add     r1, rFP, r1, lsl #3         @ r1<- &fp[B]
+    add     r9, rFP, r9, lsl #3         @ r9<- &fp[A]
+//    ldmia   r1, {r2-r3}                 @ r2/r3<- vBB/vBB+1
+    ldr     r2, [r1, #0]
+    ldr     r10, [r1, #4]
+    ldr     r3, [r1, #8]
+//    ldmia   r9, {r0-r1}                 @ r0/r1<- vAA/vAA+1
+    ldr     r0, [r9, #0]
+    ldr     r1, [r9, #8]
+    stmfd   sp!, {r9}
+    ldr     r9, [r9, #4]
+    orr     r10, r9, r10
+    ldmfd   sp!, {r9}
+    bx      lr
+
 /* continuation for OP_IGET_VOLATILE */
 
     /*
@@ -9227,15 +11849,37 @@ d2l_doconv:
     cmp     r9, #0                      @ check object for null
     ldr     r3, [r0, #offInstField_byteOffset]  @ r3<- byte offset of field
     beq     common_errNullObject        @ object was null
+// begin WITH_TAINT_TRACKING
+//    .if     1
+//    add     r0, r9, r3                  @ r0<- address of field
+//    bl      dvmQuasiAtomicRead64        @ r0/r1<- value/taint
+//    orr	    r3, r1, r10
+//    .else
     ldr   r0, [r9, r3]                @ r0<- obj.field (8/16/32 bits)
-    SMP_DMB                            @ acquiring load
+    @ no-op                             @ acquiring load
+    add     r3, r3, #4
+    ldr	    r3, [r9, r3]
+    orr     r3, r3, r10
+//    .endif
+// end WITH_TAINT_TRACKING
     mov     r2, rINST, lsr #8           @ r2<- A+
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
     and     r2, r2, #15                 @ r2<- A
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
     SET_VREG(r0, r2)                    @ fp[A]<- r0
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r1)
+    SET_VREG_TAINT(r3, r2, r1)
+// end WITH_TAINT_TRACKING
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
+.LOP_IGET_VOLATILE_taint_prop:
+    GET_VREG(r9, r0)                    @ r9<- fp[B], the object pointer
+    SET_TAINT_FP(r3)
+    GET_VREG_TAINT(r10, r0, r3)
+    ldr     r0, [r2, r1, lsl #2]        @ r0<- resolved InstField ptr
+    bx      lr
+
 /* continuation for OP_IPUT_VOLATILE */
 
     /*
@@ -9250,14 +11894,29 @@ d2l_doconv:
     and     r1, r1, #15                 @ r1<- A
     cmp     r9, #0                      @ check object for null
     GET_VREG(r0, r1)                    @ r0<- fp[A]
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r2)
+    GET_VREG_TAINT(r10, r1, r2)
+// end WITH_TAINT_TRACKING
     beq     common_errNullObject        @ object was null
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    SMP_DMB_ST                        @ releasing store
+    @ no-op                          @ releasing store
+// begin WITH_TAINT_TRACKING
+//    .if     1
+//    add     r2, r9, r3                  @ r2<- target address
+//    mov	    r1, r10                     @ r1<-taint
+//    bl      dvmQuasiAtomicSwap64        @ stores r0/r1 into addr r2
+//    .else
     str  r0, [r9, r3]                @ obj.field (8/16/32 bits)<- r0
-    SMP_DMB
+    add	    r3, r3, #4
+    str	    r10, [r9, r3]
+//    .endif
+// end WITH_TAINT_TRACKING
+    @ no-op 
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
+
 /* continuation for OP_SGET_VOLATILE */
 
     /*
@@ -9284,6 +11943,21 @@ d2l_doconv:
 #endif
     b       .LOP_SGET_VOLATILE_finish
 
+.LOP_SGET_VOLATILE_taint_prop:
+//    .if     1
+//    add     r0, r0, #offStaticField_value		@ r0<- address of field
+//    bl      dvmQuasiAtomicRead32SfieldTaint		@ r0/r1<- value/taint
+//    .else
+    ldr	    r1, [r0, #offStaticField_taint] @ r1<- taint value
+    ldr     r0, [r0, #offStaticField_value] @ r0<- field value
+    @ no-op                             @ acquiring load
+//    .endif
+    mov     r2, rINST, lsr #8           @ r2<- AA
+    SET_TAINT_FP(r3)
+    SET_VREG_TAINT(r1, r2, r3)
+    bx      lr
+
+
 /* continuation for OP_SPUT_VOLATILE */
 
     /*
@@ -9310,6 +11984,25 @@ d2l_doconv:
 #endif
     b       .LOP_SPUT_VOLATILE_finish          @ resume
 
+.LOP_SPUT_VOLATILE_taint_prop:
+//    .if     1
+//    add     r3, r0, #offStaticField_value   @ r3<- addr
+//    mov     r0, r1                          @ r0<- val
+//    mov     r1, r3                          @ r1<- addr
+//    SET_TAINT_FP(r3)
+//    GET_VREG_TAINT(r2, r2, r3)              @ r2<- taint
+//    bl      dvmQuasiAtomicSwap32SfieldTaint
+//    .else
+    @ no-op                        	    @ releasing store
+    str     r1, [r0, #offStaticField_value] @ field<- vAA
+    SET_TAINT_FP(r3)
+    GET_VREG_TAINT(r1, r2, r3)
+    str	    r1, [r0, #offStaticField_taint]
+    @ no-op 
+//    .endif
+    bx      lr
+
+
 /* continuation for OP_IGET_OBJECT_VOLATILE */
 
     /*
@@ -9322,15 +12015,37 @@ d2l_doconv:
     cmp     r9, #0                      @ check object for null
     ldr     r3, [r0, #offInstField_byteOffset]  @ r3<- byte offset of field
     beq     common_errNullObject        @ object was null
+// begin WITH_TAINT_TRACKING
+//    .if     1
+//    add     r0, r9, r3                  @ r0<- address of field
+//    bl      dvmQuasiAtomicRead64        @ r0/r1<- value/taint
+//    orr	    r3, r1, r10
+//    .else
     ldr   r0, [r9, r3]                @ r0<- obj.field (8/16/32 bits)
-    SMP_DMB                            @ acquiring load
+    @ no-op                             @ acquiring load
+    add     r3, r3, #4
+    ldr	    r3, [r9, r3]
+    orr     r3, r3, r10
+//    .endif
+// end WITH_TAINT_TRACKING
     mov     r2, rINST, lsr #8           @ r2<- A+
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
     and     r2, r2, #15                 @ r2<- A
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
     SET_VREG(r0, r2)                    @ fp[A]<- r0
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r1)
+    SET_VREG_TAINT(r3, r2, r1)
+// end WITH_TAINT_TRACKING
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
+.LOP_IGET_OBJECT_VOLATILE_taint_prop:
+    GET_VREG(r9, r0)                    @ r9<- fp[B], the object pointer
+    SET_TAINT_FP(r3)
+    GET_VREG_TAINT(r10, r0, r3)
+    ldr     r0, [r2, r1, lsl #2]        @ r0<- resolved InstField ptr
+    bx      lr
+
 /* continuation for OP_IGET_WIDE_VOLATILE */
 
     /*
@@ -9343,19 +12058,39 @@ d2l_doconv:
     ldr     r3, [r0, #offInstField_byteOffset]  @ r3<- byte offset of field
     beq     common_errNullObject        @ object was null
     .if     1
-    add     r0, r9, r3                  @ r0<- address of field
+// begin WITH_TAINT_TRACKING
+    stmfd   sp!, {r3}
+    add     r0, r9, r3                  		@ r0<- address of field
     bl      dvmQuasiAtomicRead64        @ r0/r1<- contents of field
+    ldmfd   sp!, {r3}
     .else
     ldrd    r0, [r9, r3]                @ r0/r1<- obj.field (64-bit align ok)
     .endif
+    add     r3, r3, #8
+    ldr     r3, [r9, r3]
+    orr	    r10, r3, r10
     mov     r2, rINST, lsr #8           @ r2<- A+
-    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
     and     r2, r2, #15                 @ r2<- A
-    add     r3, rFP, r2, lsl #2         @ r3<- &fp[A]
+    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
+    add     r3, rFP, r2, lsl #3         @ r3<- &fp[A]
+// end WITH_TAINT_TRACKING
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    stmia   r3, {r0-r1}                 @ fp[A]<- r0/r1
+// begin WITH_TAINT_TRACKING
+//    stmia   r3, {r0-r1}                 @ fp[A]<- r0/r1
+    str    r0, [r3, #0]
+    str    r10, [r3, #4]
+    str    r1, [r3, #8]
+    str    r10, [r3, #12]
+// end WITH_TAINT_TRACKING
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
+.LOP_IGET_WIDE_VOLATILE_taint_prop:
+    GET_VREG(r9, r0)                    @ r9<- fp[B], the object pointer
+    SET_TAINT_FP(r3)
+    GET_VREG_TAINT(r10, r0, r3)
+    ldr     r0, [r2, r1, lsl #2]        @ r0<- resolved InstField ptr
+    bx      lr
+
 /* continuation for OP_IPUT_WIDE_VOLATILE */
 
     /*
@@ -9368,21 +12103,59 @@ d2l_doconv:
     cmp     r9, #0                      @ check object for null
     and     r2, r2, #15                 @ r2<- A
     ldr     r3, [r0, #offInstField_byteOffset]  @ r3<- byte offset of field
-    add     r2, rFP, r2, lsl #2         @ r3<- &fp[A]
+// begin WITH_TAINT_TRACKING
+    add     r2, rFP, r2, lsl #3         @ r3<- &fp[A]
+// end WITH_TAINT_TRACKING
     beq     common_errNullObject        @ object was null
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
-    ldmia   r2, {r0-r1}                 @ r0/r1<- fp[A]
-    GET_INST_OPCODE(r10)                @ extract opcode from rINST
+// begin WITH_TAINT_TRACKING
+//    ldmia   r2, {r0-r1}                 @ r0/r1<- fp[A]
+    ldr	    r0, [r2, #0]
+    ldr     r1, [r2, #8]
+    ldr	    r10, [r2, #4]
+// end WITH_TAINT_TRACKING
     .if     1
+    stmfd   sp!, {r3}
     add     r2, r9, r3                  @ r2<- target address
     bl      dvmQuasiAtomicSwap64Sync    @ stores r0/r1 into addr r2
+    ldmfd   sp!, {r3}
     .else
-    strd    r0, [r9, r3]                @ obj.field (64 bits, aligned)<- r0/r1
+    strd    r0, [r9, r3]                  @ obj.field (64 bits, aligned)<- r0/r1
     .endif
-    GOTO_OPCODE(r10)                    @ jump to next instruction
+// begin WITH_TAINT_TRACKING
+    add	    r3, r3, #8
+    str	    r10, [r9, r3]
+// end WITH_TAINT_TRACKING
+    GET_INST_OPCODE(r10)                 @ extract opcode from rINST
+    GOTO_OPCODE(r10)                     @ jump to next instruction
+
 
 /* continuation for OP_SGET_WIDE_VOLATILE */
 
+.LOP_SGET_WIDE_VOLATILE_finish:
+    mov     r9, rINST, lsr #8           @ r9<- AA
+// begin WITH_TAINT_TRACKING
+    ldr	    r3, [r0, #offStaticField_taint] @ r3<- taint value
+    .if 1
+    stmfd   sp!, {r3}    
+    add     r0, r0, #offStaticField_value @ r0<- pointer to data
+    bl      dvmQuasiAtomicRead64        @ r0/r1<- contents of field
+    ldmfd   sp!, {r3}
+    .else
+    ldrd    r0, [r0, #offStaticField_value] @ r0/r1<- field value (aligned)
+    .endif
+    add     r9, rFP, r9, lsl #3         @ r9<- &fp[AA]
+    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
+//    stmia   r9, {r2-r3}                 @ vAA/vAA+1<- r2/r3
+    str	    r0, [r9, #0]
+    str	    r3, [r9, #4]
+    str	    r1, [r9, #8]
+    str	    r3, [r9, #12]
+// end WITH_TAINT_TRACKING
+
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+    GOTO_OPCODE(ip)                     @ jump to next instruction
+
     /*
      * Continuation if the field has not yet been resolved.
      *  r1:  BBBB field ref
@@ -9439,7 +12212,35 @@ d2l_doconv:
 #endif
     b       .LOP_SPUT_WIDE_VOLATILE_finish          @ resume
 
+.LOP_SPUT_WIDE_VOLATILE_taint_prop:
+//    ldmia   r9, {r0-r1}                 @ r0/r1<- vAA/vAA+1
+    ldr r3, [r9, #4]
+    ldr r0, [r9, #0]
+    ldr r1, [r9, #8]
+    bx      lr
+
+
 /* continuation for OP_EXECUTE_INLINE */
+// end WITH_TAINT_TRACKING
+
+.LOP_EXECUTE_INLINE_resume:
+    add     r1, rSELF, #offThread_retval  @ r1<- &self->retval
+// begin WITH_TAINT_TRACKING
+//    sub     sp, sp, #8                  @ make room for arg, +64 bit align
+    sub     sp, sp, #4                  @ make room for arg, +64 bit align
+    mov     r0, rINST, lsr #12          @ r0<- B
+    str     r1, [sp]                    @ push &self->retval
+    add     r1, rSELF, #offThread_rtaint  @ r1< &self->rtaint
+    sub     sp, sp, #4			@ make room for arg,
+    str     r1, [sp]                    @ push &self->rtaint
+    bl      .LOP_EXECUTE_INLINE_continue        @ make call; will return after
+    add     sp, sp, #16                 @ pop stack 4x
+// end WITH_TAINT_TRACKING
+    cmp     r0, #0                      @ test boolean result of inline
+    beq     common_exceptionThrown      @ returned false, handle exception
+    FETCH_ADVANCE_INST(3)               @ advance rPC, load rINST
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+    GOTO_OPCODE(ip)                     @ jump to next instruction
 
     /*
      * Extract args, call function.
@@ -9458,19 +12259,32 @@ d2l_doconv:
     FETCH(rINST, 2)                     @ rINST<- FEDC
     add     pc, pc, r0, lsl #3          @ computed goto, 2 instrs each
     bl      common_abort                @ (skipped due to ARM prefetch)
+// begin WITH_TAINT_TRACKING
 4:  and     ip, rINST, #0xf000          @ isolate F
-    ldr     r3, [rFP, ip, lsr #10]      @ r3<- vF (shift right 12, left 2)
+    ldr     r3, [rFP, ip, lsr #9]       @ r3<- vF (shift right 12, left 2)
 3:  and     ip, rINST, #0x0f00          @ isolate E
-    ldr     r2, [rFP, ip, lsr #6]       @ r2<- vE
+    ldr     r2, [rFP, ip, lsr #5]       @ r2<- vE
 2:  and     ip, rINST, #0x00f0          @ isolate D
-    ldr     r1, [rFP, ip, lsr #2]       @ r1<- vD
+    ldr     r1, [rFP, ip, lsr #1]       @ r1<- vD
 1:  and     ip, rINST, #0x000f          @ isolate C
-    ldr     r0, [rFP, ip, lsl #2]       @ r0<- vC
+    ldr     r0, [rFP, ip, lsl #3]       @ r0<- vC
 0:
+// push arg0_taint and arg1_taint
+    SET_TAINT_FP(r11)
+    and     ip, rINST, #0x00f0          @ isolate D
+    ldr     ip, [r11, ip, lsr #1]       @ ip<-arg1_taint
+    sub     sp, sp, #4			@ make room for arg
+    str     ip, [sp]                    @ push arg1_taint
+    and     ip, rINST, #0x000f          @ isolate C
+    ldr     ip, [r11, ip, lsl #3]       @ ip<-arg0_taint
+    sub     sp, sp, #4			@ make room for arg
+    str     ip, [sp]                    @ push arg0_taint
+// end WITH_TAINT_TRACKING
     ldr     rINST, .LOP_EXECUTE_INLINE_table    @ table of InlineOperation
     ldr     pc, [rINST, r10, lsl #4]    @ sizeof=16, "func" is first entry
     @ (not reached)
 
+
     /*
      * We're debugging or profiling.
      * r10: opIndex
@@ -9484,12 +12298,21 @@ d2l_doconv:
     mov     r1, rSELF
     bl      dvmFastMethodTraceEnter     @ (method, self)
     add     r1, rSELF, #offThread_retval@ r1<- &self->retval
-    sub     sp, sp, #8                  @ make room for arg, +64 bit align
+// begin WITH_TAINT_TRACKING
+//    sub     sp, sp, #8                  @ make room for arg, +64 bit align
+    sub     sp, sp, #4                  @ make room for arg, +64 bit align
     mov     r0, rINST, lsr #12          @ r0<- B
     str     r1, [sp]                    @ push &self->retval
+    add     r1, rSELF, #offThread_rtaint  @ r1< &self->rtaint
+    sub     sp, sp, #4			@ make room for arg,
+    str     r1, [sp]                    @ push &self->rtaint
+// end WITH_TAINT_TRACKING
     bl      .LOP_EXECUTE_INLINE_continue        @ make call; will return after
     mov     rINST, r0                   @ save result of inline
-    add     sp, sp, #8                  @ pop stack
+// begin WITH_TAINT_TRACKING
+//    add     sp, sp, #8                  @ pop stack
+    add     sp, sp, #16                 @ pop stack 4x
+// end WITH_TAINT_TRACKING
     mov     r0, r9                      @ r0<- method
     mov     r1, rSELF
     bl      dvmFastNativeMethodTraceExit @ (method, self)
@@ -9506,6 +12329,26 @@ d2l_doconv:
     .word   gDvmInlineOpsTable
 
 /* continuation for OP_EXECUTE_INLINE_RANGE */
+// end WITH_TAINT_TRACKING
+
+.LOP_EXECUTE_INLINE_RANGE_resume:
+    add     r1, rSELF, #offThread_retval  @ r1<- &self->retval
+// begin WITH_TAINT_TRACKING
+//    sub     sp, sp, #8                  @ make room for arg, +64 bit align
+    sub     sp, sp, #4                  @ make room for arg, +64 bit align
+    mov     r0, rINST, lsr #8           @ r0<- AA
+    str     r1, [sp]                    @ push &self->retval
+    add     r1, rSELF, #offThread_rtaint  @ r1< &self->rtaint
+    sub     sp, sp, #4			@ make room for arg
+    str     r1, [sp]                    @ push &self->rtaint
+    bl      .LOP_EXECUTE_INLINE_RANGE_continue        @ make call; will return after
+    add     sp, sp, #16                 @ pop stack 4x
+// end WITH_TAINT_TRACKING
+    cmp     r0, #0                      @ test boolean result of inline
+    beq     common_exceptionThrown      @ returned false, handle exception
+    FETCH_ADVANCE_INST(3)               @ advance rPC, load rINST
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+    GOTO_OPCODE(ip)                     @ jump to next instruction
 
     /*
      * Extract args, call function.
@@ -9527,6 +12370,17 @@ d2l_doconv:
 1:  add     ip, r9, #0                  @ (nop)
     GET_VREG(r0, ip)                    @ r0<- vBase[0]
 0:
+// begin WITH_TAINT_TRACKING
+// push arg0_taint and arg1_taint
+    SET_TAINT_FP(r11)
+    add     ip, r9, #1                  
+    GET_VREG_TAINT(ip, ip, r11)
+    sub     sp, sp, #4			@ make room for arg
+    str     ip, [sp]                    @ push arg1_taint
+    GET_VREG_TAINT(ip, r9, r11)
+    sub     sp, sp, #4			@ make room for arg
+    str     ip, [sp]                    @ push arg0_taint
+// end WITH_TAINT_TRACKING
     ldr     r9, .LOP_EXECUTE_INLINE_RANGE_table       @ table of InlineOperation
     ldr     pc, [r9, r10, lsl #4]       @ sizeof=16, "func" is first entry
     @ (not reached)
@@ -9545,13 +12399,21 @@ d2l_doconv:
     mov     r1, rSELF
     bl      dvmFastMethodTraceEnter     @ (method, self)
     add     r1, rSELF, #offThread_retval@ r1<- &self->retval
-    sub     sp, sp, #8                  @ make room for arg, +64 bit align
-    mov     r0, rINST, lsr #8           @ r0<- B
-    mov     rINST, r9                   @ rINST<- method
+// begin WITH_TAINT_TRACKING
+//    sub     sp, sp, #8                  @ make room for arg, +64 bit align
+    sub     sp, sp, #4                  @ make room for arg, +64 bit align
+    mov     r0, rINST, lsr #8           @ r0<- AA
     str     r1, [sp]                    @ push &self->retval
+    add     r1, rSELF, #offThread_rtaint  @ r1< &self->rtaint
+    sub     sp, sp, #4			@ make room for arg
+    str     r1, [sp]                    @ push &self->rtaint
+// end WITH_TAINT_TRACKING
     bl      .LOP_EXECUTE_INLINE_RANGE_continue        @ make call; will return after
     mov     r9, r0                      @ save result of inline
-    add     sp, sp, #8                  @ pop stack
+// begin WITH_TAINT_TRACKING
+//    add     sp, sp, #8                  @ pop stack
+    add     sp, sp, #16                 @ pop stack 4x
+// end WITH_TAINT_TRACKING
     mov     r0, rINST                   @ r0<- method
     mov     r1, rSELF
     bl      dvmFastNativeMethodTraceExit  @ (method, self)
@@ -9590,6 +12452,63 @@ d2l_doconv:
     mov     ip, #OP_INVOKE_DIRECT_RANGE
     GOTO_OPCODE_BASE(r1,ip)             @ execute it
 
+/* continuation for OP_IGET_QUICK */
+
+.LOP_IGET_QUICK_taint_prop:
+    add     r1, r1, #4
+    ldr     r10, [r3, r1]
+    orr     r10, r9, r10
+    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
+    bx      lr
+
+
+/* continuation for OP_IGET_WIDE_QUICK */
+
+iget_wide_quick_taint_prop:
+    add     r3, rFP, r2, lsl #3         @ r3<- &fp[A]
+    GET_INST_OPCODE(ip)                 @ extract opcode from rINST
+//    stmia   r3, {r0-r1}                 @ fp[A]<- r0/r1
+    str     r0, [r3, #0]
+    str     r10, [r3, #4]
+    str     r1, [r3, #8]
+    str     r10, [r3, #12]
+    bx      lr
+
+/* continuation for OP_IGET_OBJECT_QUICK */
+
+.LOP_IGET_OBJECT_QUICK_taint_prop:
+	add		r1, r1, #4
+	ldr		r10, [r3, r1]
+	orr		r10, r9, r10
+	FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
+	bx		lr
+
+/* continuation for OP_IPUT_WIDE_QUICK */
+
+iput_wide_quick_taint_prop:
+    add     r3, rFP, r0, lsl #3         @ r3<- &fp[A]
+    cmp     r2, #0                      @ check object for null
+//    ldmia   r3, {r0-r1}                 @ r0/r1<- fp[A]
+    ldr     r0, [r3, #0]
+    ldr     r1, [r3, #8]
+    ldr     r9, [r3, #4]
+    bx      lr
+
+/* continuation for OP_IPUT_OBJECT_QUICK */
+
+.LOP_IPUT_OBJECT_QUICK_taint_prop:
+    SET_TAINT_FP(r9)
+    GET_VREG_TAINT(r10, r2, r9)
+    ldr     r2, [rSELF, #offThread_cardTable]  @ r2<- card table base
+    FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
+    str     r0, [r3, r1]                @ obj.field (always 32 bits)<- r0
+    add	    r1, r1, #4
+    str	    r10, [r3, r1]
+    bx	    lr
+
+
+
+
 /* continuation for OP_IPUT_OBJECT_VOLATILE */
 
     /*
@@ -9604,15 +12523,29 @@ d2l_doconv:
     and     r1, r1, #15                 @ r1<- A
     cmp     r9, #0                      @ check object for null
     GET_VREG(r0, r1)                    @ r0<- fp[A]
-    ldr     r2, [rSELF, #offThread_cardTable]  @ r2<- card table base
+// begin WITH_TAINT_TRACKING
+    SET_TAINT_FP(r2)
+    GET_VREG_TAINT(r10, r1, r2)
+    ldr     r11, [rSELF, #offThread_cardTable]  @ r11<- card table base
+// end WITH_TAINT_TRACKING
     beq     common_errNullObject        @ object was null
     FETCH_ADVANCE_INST(2)               @ advance rPC, load rINST
     GET_INST_OPCODE(ip)                 @ extract opcode from rINST
-    SMP_DMB_ST                        @ releasing store
+    @ no-op                         @ releasing store
+// begin WITH_TAINT_TRACKING
+//    .if     1
+//    add     r2, r9, r3                  @ r2<- target address
+//    mov     r1, r10                     @ r1<-taint
+//    bl      dvmQuasiAtomicSwap64        @ stores r0/r1 into addr r2
+//    .else
     str     r0, [r9, r3]                @ obj.field (32 bits)<- r0
-    SMP_DMB
+    add     r3, r3, #4
+    str     r10, [r9, r3]
+//    .endif
+    @ no-op 
     cmp     r0, #0                      @ stored a null reference?
-    strneb  r2, [r2, r9, lsr #GC_CARD_SHIFT]  @ mark card if not
+    strneb  r11, [r11, r9, lsr #GC_CARD_SHIFT]  @ mark card if not
+// end WITH_TAINT_TRACKING
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
 /* continuation for OP_SGET_OBJECT_VOLATILE */
@@ -9641,14 +12574,42 @@ d2l_doconv:
 #endif
     b       .LOP_SGET_OBJECT_VOLATILE_finish
 
+.LOP_SGET_OBJECT_VOLATILE_taint_prop:
+//    .if     1
+//    add     r0, r0, #offStaticField_value		@ r0<- address of field
+//    bl      dvmQuasiAtomicRead32SfieldTaint		@ r0/r1<- value/taint
+//    .else
+    ldr	    r1, [r0, #offStaticField_taint] @ r1<- taint value
+    ldr     r0, [r0, #offStaticField_value] @ r0<- field value
+    @ no-op                             @ acquiring load
+//    .endif
+    mov     r2, rINST, lsr #8           @ r2<- AA
+    SET_TAINT_FP(r3)
+    SET_VREG_TAINT(r1, r2, r3)
+    bx      lr
+
+
 /* continuation for OP_SPUT_OBJECT_VOLATILE */
 
 
 .LOP_SPUT_OBJECT_VOLATILE_end:
-    str     r1, [r0, #offStaticField_value]  @ field<- vAA
-    SMP_DMB
-    cmp     r1, #0                      @ stored a null object?
-    strneb  r2, [r2, r9, lsr #GC_CARD_SHIFT]  @ mark card based on obj head
+// begin WITH_TAINT_TRACKING
+//    .if     1
+//    add	    r2, r0, #offStaticField_value       @ r2<- addr
+//    mov	    r0, r1                              @ r0<- val
+//    mov	    r1, r2                              @ r1<- addr
+//    mov	    r2, r3                              @ r2<- taint
+//    bl      dvmQuasiAtomicSwap32SfieldTaint
+//    cmp     r0, #0                    	        @ stored a null object?
+//    .else
+    str     r1, [r0, #offStaticField_value] @ field<- vAA
+    str	    r3, [r0, #offStaticField_taint]
+//    @ no-op 
+    cmp     r1, #0                              @ stored a null object?
+//    .endif
+//    strneb  r2, [r2, r9, lsr #GC_CARD_SHIFT]  @ mark card based on obj head
+    strneb  r10, [r10, r9, lsr #GC_CARD_SHIFT]  @ mark card based on obj head
+// end WITH_TAINT_TRACKING
     GOTO_OPCODE(ip)                     @ jump to next instruction
 
     /* Continuation if the field has not yet been resolved.
@@ -9688,7 +12649,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_NOP: /* 0x00 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -9711,7 +12672,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_MOVE: /* 0x01 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -9734,7 +12695,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_MOVE_FROM16: /* 0x02 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -9757,7 +12718,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_MOVE_16: /* 0x03 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -9780,7 +12741,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_MOVE_WIDE: /* 0x04 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -9803,7 +12764,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_MOVE_WIDE_FROM16: /* 0x05 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -9826,7 +12787,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_MOVE_WIDE_16: /* 0x06 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -9849,7 +12810,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_MOVE_OBJECT: /* 0x07 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -9872,7 +12833,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_MOVE_OBJECT_FROM16: /* 0x08 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -9895,7 +12856,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_MOVE_OBJECT_16: /* 0x09 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -9918,7 +12879,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_MOVE_RESULT: /* 0x0a */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -9941,7 +12902,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_MOVE_RESULT_WIDE: /* 0x0b */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -9964,7 +12925,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_MOVE_RESULT_OBJECT: /* 0x0c */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -9987,7 +12948,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_MOVE_EXCEPTION: /* 0x0d */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -10010,7 +12971,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_RETURN_VOID: /* 0x0e */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -10033,7 +12994,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_RETURN: /* 0x0f */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -10056,7 +13017,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_RETURN_WIDE: /* 0x10 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -10079,7 +13040,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_RETURN_OBJECT: /* 0x11 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -10102,7 +13063,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_CONST_4: /* 0x12 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -10125,7 +13086,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_CONST_16: /* 0x13 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -10148,7 +13109,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_CONST: /* 0x14 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -10171,7 +13132,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_CONST_HIGH16: /* 0x15 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -10194,7 +13155,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_CONST_WIDE_16: /* 0x16 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -10217,7 +13178,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_CONST_WIDE_32: /* 0x17 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -10240,7 +13201,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_CONST_WIDE: /* 0x18 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -10263,7 +13224,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_CONST_WIDE_HIGH16: /* 0x19 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -10286,7 +13247,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_CONST_STRING: /* 0x1a */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -10309,7 +13270,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_CONST_STRING_JUMBO: /* 0x1b */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -10332,7 +13293,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_CONST_CLASS: /* 0x1c */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -10355,7 +13316,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_MONITOR_ENTER: /* 0x1d */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -10378,7 +13339,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_MONITOR_EXIT: /* 0x1e */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -10401,7 +13362,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_CHECK_CAST: /* 0x1f */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -10424,7 +13385,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_INSTANCE_OF: /* 0x20 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -10447,7 +13408,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_ARRAY_LENGTH: /* 0x21 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -10470,7 +13431,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_NEW_INSTANCE: /* 0x22 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -10493,7 +13454,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_NEW_ARRAY: /* 0x23 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -10516,7 +13477,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_FILLED_NEW_ARRAY: /* 0x24 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -10539,7 +13500,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_FILLED_NEW_ARRAY_RANGE: /* 0x25 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -10562,7 +13523,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_FILL_ARRAY_DATA: /* 0x26 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -10585,7 +13546,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_THROW: /* 0x27 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -10608,7 +13569,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_GOTO: /* 0x28 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -10631,7 +13592,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_GOTO_16: /* 0x29 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -10654,7 +13615,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_GOTO_32: /* 0x2a */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -10677,7 +13638,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_PACKED_SWITCH: /* 0x2b */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -10700,7 +13661,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_SPARSE_SWITCH: /* 0x2c */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -10723,7 +13684,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_CMPL_FLOAT: /* 0x2d */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -10746,7 +13707,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_CMPG_FLOAT: /* 0x2e */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -10769,7 +13730,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_CMPL_DOUBLE: /* 0x2f */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -10792,7 +13753,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_CMPG_DOUBLE: /* 0x30 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -10815,7 +13776,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_CMP_LONG: /* 0x31 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -10838,7 +13799,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_IF_EQ: /* 0x32 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -10861,7 +13822,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_IF_NE: /* 0x33 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -10884,7 +13845,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_IF_LT: /* 0x34 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -10907,7 +13868,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_IF_GE: /* 0x35 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -10930,7 +13891,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_IF_GT: /* 0x36 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -10953,7 +13914,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_IF_LE: /* 0x37 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -10976,7 +13937,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_IF_EQZ: /* 0x38 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -10999,7 +13960,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_IF_NEZ: /* 0x39 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -11022,7 +13983,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_IF_LTZ: /* 0x3a */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -11045,7 +14006,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_IF_GEZ: /* 0x3b */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -11068,7 +14029,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_IF_GTZ: /* 0x3c */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -11091,7 +14052,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_IF_LEZ: /* 0x3d */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -11114,7 +14075,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_UNUSED_3E: /* 0x3e */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -11137,7 +14098,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_UNUSED_3F: /* 0x3f */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -11160,7 +14121,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_UNUSED_40: /* 0x40 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -11183,7 +14144,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_UNUSED_41: /* 0x41 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -11206,7 +14167,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_UNUSED_42: /* 0x42 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -11229,7 +14190,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_UNUSED_43: /* 0x43 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -11252,7 +14213,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_AGET: /* 0x44 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -11275,7 +14236,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_AGET_WIDE: /* 0x45 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -11298,7 +14259,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_AGET_OBJECT: /* 0x46 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -11321,7 +14282,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_AGET_BOOLEAN: /* 0x47 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -11344,7 +14305,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_AGET_BYTE: /* 0x48 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -11367,7 +14328,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_AGET_CHAR: /* 0x49 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -11390,7 +14351,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_AGET_SHORT: /* 0x4a */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -11413,7 +14374,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_APUT: /* 0x4b */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -11436,7 +14397,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_APUT_WIDE: /* 0x4c */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -11459,7 +14420,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_APUT_OBJECT: /* 0x4d */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -11482,7 +14443,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_APUT_BOOLEAN: /* 0x4e */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -11505,7 +14466,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_APUT_BYTE: /* 0x4f */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -11528,7 +14489,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_APUT_CHAR: /* 0x50 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -11551,7 +14512,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_APUT_SHORT: /* 0x51 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -11574,7 +14535,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_IGET: /* 0x52 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -11597,7 +14558,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_IGET_WIDE: /* 0x53 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -11620,7 +14581,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_IGET_OBJECT: /* 0x54 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -11643,7 +14604,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_IGET_BOOLEAN: /* 0x55 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -11666,7 +14627,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_IGET_BYTE: /* 0x56 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -11689,7 +14650,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_IGET_CHAR: /* 0x57 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -11712,7 +14673,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_IGET_SHORT: /* 0x58 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -11735,7 +14696,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_IPUT: /* 0x59 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -11758,7 +14719,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_IPUT_WIDE: /* 0x5a */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -11781,7 +14742,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_IPUT_OBJECT: /* 0x5b */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -11804,7 +14765,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_IPUT_BOOLEAN: /* 0x5c */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -11827,7 +14788,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_IPUT_BYTE: /* 0x5d */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -11850,7 +14811,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_IPUT_CHAR: /* 0x5e */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -11873,7 +14834,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_IPUT_SHORT: /* 0x5f */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -11896,7 +14857,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_SGET: /* 0x60 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -11919,7 +14880,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_SGET_WIDE: /* 0x61 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -11942,7 +14903,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_SGET_OBJECT: /* 0x62 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -11965,7 +14926,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_SGET_BOOLEAN: /* 0x63 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -11988,7 +14949,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_SGET_BYTE: /* 0x64 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -12011,7 +14972,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_SGET_CHAR: /* 0x65 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -12034,7 +14995,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_SGET_SHORT: /* 0x66 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -12057,7 +15018,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_SPUT: /* 0x67 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -12080,7 +15041,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_SPUT_WIDE: /* 0x68 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -12103,7 +15064,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_SPUT_OBJECT: /* 0x69 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -12126,7 +15087,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_SPUT_BOOLEAN: /* 0x6a */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -12149,7 +15110,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_SPUT_BYTE: /* 0x6b */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -12172,7 +15133,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_SPUT_CHAR: /* 0x6c */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -12195,7 +15156,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_SPUT_SHORT: /* 0x6d */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -12218,7 +15179,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_INVOKE_VIRTUAL: /* 0x6e */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -12241,7 +15202,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_INVOKE_SUPER: /* 0x6f */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -12264,7 +15225,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_INVOKE_DIRECT: /* 0x70 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -12287,7 +15248,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_INVOKE_STATIC: /* 0x71 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -12310,7 +15271,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_INVOKE_INTERFACE: /* 0x72 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -12333,7 +15294,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_UNUSED_73: /* 0x73 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -12356,7 +15317,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_INVOKE_VIRTUAL_RANGE: /* 0x74 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -12379,7 +15340,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_INVOKE_SUPER_RANGE: /* 0x75 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -12402,7 +15363,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_INVOKE_DIRECT_RANGE: /* 0x76 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -12425,7 +15386,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_INVOKE_STATIC_RANGE: /* 0x77 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -12448,7 +15409,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_INVOKE_INTERFACE_RANGE: /* 0x78 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -12471,7 +15432,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_UNUSED_79: /* 0x79 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -12494,7 +15455,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_UNUSED_7A: /* 0x7a */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -12517,7 +15478,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_NEG_INT: /* 0x7b */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -12540,7 +15501,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_NOT_INT: /* 0x7c */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -12563,7 +15524,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_NEG_LONG: /* 0x7d */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -12586,7 +15547,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_NOT_LONG: /* 0x7e */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -12609,7 +15570,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_NEG_FLOAT: /* 0x7f */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -12632,7 +15593,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_NEG_DOUBLE: /* 0x80 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -12655,7 +15616,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_INT_TO_LONG: /* 0x81 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -12678,7 +15639,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_INT_TO_FLOAT: /* 0x82 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -12701,7 +15662,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_INT_TO_DOUBLE: /* 0x83 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -12724,7 +15685,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_LONG_TO_INT: /* 0x84 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -12747,7 +15708,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_LONG_TO_FLOAT: /* 0x85 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -12770,7 +15731,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_LONG_TO_DOUBLE: /* 0x86 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -12793,7 +15754,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_FLOAT_TO_INT: /* 0x87 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -12816,7 +15777,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_FLOAT_TO_LONG: /* 0x88 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -12839,7 +15800,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_FLOAT_TO_DOUBLE: /* 0x89 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -12862,7 +15823,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_DOUBLE_TO_INT: /* 0x8a */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -12885,7 +15846,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_DOUBLE_TO_LONG: /* 0x8b */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -12908,7 +15869,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_DOUBLE_TO_FLOAT: /* 0x8c */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -12931,7 +15892,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_INT_TO_BYTE: /* 0x8d */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -12954,7 +15915,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_INT_TO_CHAR: /* 0x8e */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -12977,7 +15938,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_INT_TO_SHORT: /* 0x8f */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -13000,7 +15961,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_ADD_INT: /* 0x90 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -13023,7 +15984,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_SUB_INT: /* 0x91 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -13046,7 +16007,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_MUL_INT: /* 0x92 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -13069,7 +16030,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_DIV_INT: /* 0x93 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -13092,7 +16053,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_REM_INT: /* 0x94 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -13115,7 +16076,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_AND_INT: /* 0x95 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -13138,7 +16099,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_OR_INT: /* 0x96 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -13161,7 +16122,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_XOR_INT: /* 0x97 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -13184,7 +16145,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_SHL_INT: /* 0x98 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -13207,7 +16168,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_SHR_INT: /* 0x99 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -13230,7 +16191,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_USHR_INT: /* 0x9a */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -13253,7 +16214,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_ADD_LONG: /* 0x9b */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -13276,7 +16237,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_SUB_LONG: /* 0x9c */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -13299,7 +16260,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_MUL_LONG: /* 0x9d */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -13322,7 +16283,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_DIV_LONG: /* 0x9e */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -13345,7 +16306,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_REM_LONG: /* 0x9f */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -13368,7 +16329,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_AND_LONG: /* 0xa0 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -13391,7 +16352,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_OR_LONG: /* 0xa1 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -13414,7 +16375,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_XOR_LONG: /* 0xa2 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -13437,7 +16398,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_SHL_LONG: /* 0xa3 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -13460,7 +16421,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_SHR_LONG: /* 0xa4 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -13483,7 +16444,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_USHR_LONG: /* 0xa5 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -13506,7 +16467,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_ADD_FLOAT: /* 0xa6 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -13529,7 +16490,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_SUB_FLOAT: /* 0xa7 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -13552,7 +16513,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_MUL_FLOAT: /* 0xa8 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -13575,7 +16536,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_DIV_FLOAT: /* 0xa9 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -13598,7 +16559,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_REM_FLOAT: /* 0xaa */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -13621,7 +16582,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_ADD_DOUBLE: /* 0xab */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -13644,7 +16605,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_SUB_DOUBLE: /* 0xac */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -13667,7 +16628,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_MUL_DOUBLE: /* 0xad */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -13690,7 +16651,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_DIV_DOUBLE: /* 0xae */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -13713,7 +16674,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_REM_DOUBLE: /* 0xaf */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -13736,7 +16697,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_ADD_INT_2ADDR: /* 0xb0 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -13759,7 +16720,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_SUB_INT_2ADDR: /* 0xb1 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -13782,7 +16743,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_MUL_INT_2ADDR: /* 0xb2 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -13805,7 +16766,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_DIV_INT_2ADDR: /* 0xb3 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -13828,7 +16789,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_REM_INT_2ADDR: /* 0xb4 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -13851,7 +16812,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_AND_INT_2ADDR: /* 0xb5 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -13874,7 +16835,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_OR_INT_2ADDR: /* 0xb6 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -13897,7 +16858,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_XOR_INT_2ADDR: /* 0xb7 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -13920,7 +16881,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_SHL_INT_2ADDR: /* 0xb8 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -13943,7 +16904,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_SHR_INT_2ADDR: /* 0xb9 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -13966,7 +16927,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_USHR_INT_2ADDR: /* 0xba */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -13989,7 +16950,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_ADD_LONG_2ADDR: /* 0xbb */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -14012,7 +16973,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_SUB_LONG_2ADDR: /* 0xbc */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -14035,7 +16996,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_MUL_LONG_2ADDR: /* 0xbd */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -14058,7 +17019,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_DIV_LONG_2ADDR: /* 0xbe */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -14081,7 +17042,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_REM_LONG_2ADDR: /* 0xbf */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -14104,7 +17065,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_AND_LONG_2ADDR: /* 0xc0 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -14127,7 +17088,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_OR_LONG_2ADDR: /* 0xc1 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -14150,7 +17111,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_XOR_LONG_2ADDR: /* 0xc2 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -14173,7 +17134,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_SHL_LONG_2ADDR: /* 0xc3 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -14196,7 +17157,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_SHR_LONG_2ADDR: /* 0xc4 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -14219,7 +17180,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_USHR_LONG_2ADDR: /* 0xc5 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -14242,7 +17203,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_ADD_FLOAT_2ADDR: /* 0xc6 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -14265,7 +17226,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_SUB_FLOAT_2ADDR: /* 0xc7 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -14288,7 +17249,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_MUL_FLOAT_2ADDR: /* 0xc8 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -14311,7 +17272,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_DIV_FLOAT_2ADDR: /* 0xc9 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -14334,7 +17295,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_REM_FLOAT_2ADDR: /* 0xca */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -14357,7 +17318,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_ADD_DOUBLE_2ADDR: /* 0xcb */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -14380,7 +17341,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_SUB_DOUBLE_2ADDR: /* 0xcc */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -14403,7 +17364,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_MUL_DOUBLE_2ADDR: /* 0xcd */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -14426,7 +17387,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_DIV_DOUBLE_2ADDR: /* 0xce */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -14449,7 +17410,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_REM_DOUBLE_2ADDR: /* 0xcf */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -14472,7 +17433,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_ADD_INT_LIT16: /* 0xd0 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -14495,7 +17456,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_RSUB_INT: /* 0xd1 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -14518,7 +17479,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_MUL_INT_LIT16: /* 0xd2 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -14541,7 +17502,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_DIV_INT_LIT16: /* 0xd3 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -14564,7 +17525,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_REM_INT_LIT16: /* 0xd4 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -14587,7 +17548,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_AND_INT_LIT16: /* 0xd5 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -14610,7 +17571,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_OR_INT_LIT16: /* 0xd6 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -14633,7 +17594,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_XOR_INT_LIT16: /* 0xd7 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -14656,7 +17617,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_ADD_INT_LIT8: /* 0xd8 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -14679,7 +17640,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_RSUB_INT_LIT8: /* 0xd9 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -14702,7 +17663,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_MUL_INT_LIT8: /* 0xda */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -14725,7 +17686,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_DIV_INT_LIT8: /* 0xdb */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -14748,7 +17709,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_REM_INT_LIT8: /* 0xdc */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -14771,7 +17732,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_AND_INT_LIT8: /* 0xdd */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -14794,7 +17755,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_OR_INT_LIT8: /* 0xde */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -14817,7 +17778,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_XOR_INT_LIT8: /* 0xdf */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -14840,7 +17801,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_SHL_INT_LIT8: /* 0xe0 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -14863,7 +17824,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_SHR_INT_LIT8: /* 0xe1 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -14886,7 +17847,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_USHR_INT_LIT8: /* 0xe2 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -14909,7 +17870,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_IGET_VOLATILE: /* 0xe3 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -14932,7 +17893,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_IPUT_VOLATILE: /* 0xe4 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -14955,7 +17916,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_SGET_VOLATILE: /* 0xe5 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -14978,7 +17939,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_SPUT_VOLATILE: /* 0xe6 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -15001,7 +17962,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_IGET_OBJECT_VOLATILE: /* 0xe7 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -15024,7 +17985,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_IGET_WIDE_VOLATILE: /* 0xe8 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -15047,7 +18008,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_IPUT_WIDE_VOLATILE: /* 0xe9 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -15070,7 +18031,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_SGET_WIDE_VOLATILE: /* 0xea */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -15093,7 +18054,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_SPUT_WIDE_VOLATILE: /* 0xeb */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -15116,7 +18077,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_BREAKPOINT: /* 0xec */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -15139,7 +18100,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_THROW_VERIFICATION_ERROR: /* 0xed */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -15162,7 +18123,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_EXECUTE_INLINE: /* 0xee */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -15185,7 +18146,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_EXECUTE_INLINE_RANGE: /* 0xef */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -15208,7 +18169,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_INVOKE_OBJECT_INIT_RANGE: /* 0xf0 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -15231,7 +18192,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_RETURN_VOID_BARRIER: /* 0xf1 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -15254,7 +18215,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_IGET_QUICK: /* 0xf2 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -15277,7 +18238,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_IGET_WIDE_QUICK: /* 0xf3 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -15300,7 +18261,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_IGET_OBJECT_QUICK: /* 0xf4 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -15323,7 +18284,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_IPUT_QUICK: /* 0xf5 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -15346,7 +18307,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_IPUT_WIDE_QUICK: /* 0xf6 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -15369,7 +18330,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_IPUT_OBJECT_QUICK: /* 0xf7 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -15392,7 +18353,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_INVOKE_VIRTUAL_QUICK: /* 0xf8 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -15415,7 +18376,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_INVOKE_VIRTUAL_QUICK_RANGE: /* 0xf9 */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -15438,7 +18399,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_INVOKE_SUPER_QUICK: /* 0xfa */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -15461,7 +18422,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_INVOKE_SUPER_QUICK_RANGE: /* 0xfb */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -15484,7 +18445,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_IPUT_OBJECT_VOLATILE: /* 0xfc */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -15507,7 +18468,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_SGET_OBJECT_VOLATILE: /* 0xfd */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -15530,7 +18491,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_SPUT_OBJECT_VOLATILE: /* 0xfe */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -15553,7 +18514,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
 /* ------------------------------ */
     .balign 64
 .L_ALT_OP_UNUSED_FF: /* 0xff */
-/* File: armv5te/alt_stub.S */
+/* File: armv5te_taint/alt_stub.S */
 /*
  * Inter-instruction transfer stub.  Call out to dvmCheckBefore to handle
  * any interesting requests and then jump to the real instruction
@@ -15577,7 +18538,7 @@ dvmAsmAltInstructionStart = .L_ALT_OP_NOP
     .size   dvmAsmAltInstructionStart, .-dvmAsmAltInstructionStart
     .global dvmAsmAltInstructionEnd
 dvmAsmAltInstructionEnd:
-/* File: armv5te/footer.S */
+/* File: armv5te_taint/footer.S */
 /*
  * ===========================================================================
  *  Common subroutines and data
@@ -16059,21 +19020,78 @@ common_invokeMethodRange:
     blne    save_callsiteinfo
 #endif
     @ prepare to copy args to "outs" area of current frame
-    movs    r2, rINST, lsr #8           @ r2<- AA (arg count) -- test for zero
+// begin WITH_TAINT_TRACKING
+//    movs    r2, rINST, lsr #8           @ r2<- AA (arg count) -- test for zero
+    mov     r2, rINST, lsr #8           @ r2<- AA (arg count)
     SAVEAREA_FROM_FP(r10, rFP)          @ r10<- stack save area
-    beq     .LinvokeArgsDone            @ if no args, skip the rest
+//    beq     .LinvokeArgsDone            @ if no args, skip the rest
+    str     r2, [r10, #offStackSaveArea_argCount]	@ save arg count
+// end WITH_TAINT_TRACKING
     FETCH(r1, 2)                        @ r1<- CCCC
 
+// begin WITH_TAINT_TRACKING
+    // is this a native method?
+    stmfd   sp!, {r0}                   @ push methodToCall to stack
+    ldr     r0, [r0, #offMethod_accessFlags] @ r0<- methodToCall->accessFlags
+    tst     r0, #ACC_NATIVE
+    ldmfd   sp!, {r0}                   @ restore methodToCall
+    bne     .LinvokeRangeNative
+
 .LinvokeRangeArgs:
     @ r0=methodToCall, r1=CCCC, r2=count, r10=outs
     @ (very few methods have > 10 args; could unroll for common cases)
-    add     r3, rFP, r1, lsl #2         @ r3<- &fp[CCCC]
-    sub     r10, r10, r2, lsl #2        @ r10<- "outs" area, for call args
-1:  ldr     r1, [r3], #4                @ val = *fp++
+    stmfd   sp!, {r0}                   @ push methodToCall to stack
+    mov	    r9, #0
+    str     r9, [r10, #-4]              @ clear native hack
+    cmp	    r2, #0
+    beq     .LinvokeRangeDone           @ if no args, skip the rest
+    add     r3, rFP, r1, lsl #3         @ r3<- &fp[CCCC]
+    sub     r10, r10, r2, lsl #3        @ r10<- "outs" area, for call args
+    sub	    r10, r10, #4
+    //mov     r9, #0                      @ r9<- slot = 0
+1:  ldrd    r0, [r3, r9]
     subs    r2, r2, #1                  @ count--
-    str     r1, [r10], #4               @ *outs++ = val
+    strd    r0, [r10, r9]               @ *outs++ = val
+    add	    r9, r9, #8
+    bne     1b                          @ ...while count != 0
+.LinvokeRangeDone:
+    ldmfd   sp!, {r0}                   @ restore methodToCall
+    // PJG: moved
+    //ldrh    r9, [r0, #offMethod_registersSize]  @ r9<- methodToCall->regsSize
+    //ldrh    r3, [r0, #offMethod_outsSize]   @ r3<- methodToCall->outsSize
+    b       .LinvokeArgsDone
+
+.LinvokeRangeNative:
+    @ r0=methodToCall, r1=CCCC, r2=count, r10=outs
+    @ (very few methods have > 10 args; could unroll for common cases)
+    stmfd   sp!, {r0}                   @ push methodToCall to stack
+    sub	    r10, r10, #4
+    sub     r10, r10, r2, lsl #3        @ r10<- "outs" area, for call args
+    mov	    r9, #0                      @ r9<- index
+    str     r9, [r10, r2, lsl #2]       @ clear native hack
+    cmp	    r2, #0
+    beq     .LinvokeRangeNativeDone     @ if no args, skip the rest
+    add     r3, rFP, r1, lsl #3         @ r3<- &fp[CCCC]
+    mov	    r0, r2                      @ r0<- count
+    mov	    r2, r2, lsl #2
+    add	    r2, r2, #4                  @ r2<- index (taint)
+1:  stmfd   sp!, {r0}                   @ push count
+    mov	    r0, r9, lsl #3
+    ldrd    r0, [r3, r0]
+    str	    r0, [r10, r9, lsl #2]
+    str	    r1, [r10, r2]
+    add	    r9, r9, #1
+    add	    r2, r2, #4
+    ldmfd   sp!, {r0}                   @ pop count
+    subs    r0, r0, #1                  @ count--
     bne     1b                          @ ...while count != 0
+.LinvokeRangeNativeDone:
+    ldmfd   sp!, {r0}                   @ restore methodToCall
+    // PJG: moved
+    //ldrh    r9, [r0, #offMethod_registersSize]  @ r9<- methodToCall->regsSize
+    //ldrh    r3, [r0, #offMethod_outsSize]   @ r3<- methodToCall->outsSize
     b       .LinvokeArgsDone
+// end WITH_TAINT_TRACKING
 
 /*
  * Common code for method invocation without range.
@@ -16089,37 +19107,107 @@ common_invokeMethodNoRange:
     blne    save_callsiteinfo
 #endif
     @ prepare to copy args to "outs" area of current frame
-    movs    r2, rINST, lsr #12          @ r2<- B (arg count) -- test for zero
+// begin WITH_TAINT_TRACKING
+//    movs    r2, rINST, lsr #12          @ r2<- B (arg count) -- test for zero
+    movs    r2, rINST, lsr #12          @ r2<- B (arg count)
     SAVEAREA_FROM_FP(r10, rFP)          @ r10<- stack save area
+    str     r2, [r10, #offStackSaveArea_argCount]    @ save arg count
     FETCH(r1, 2)                        @ r1<- GFED (load here to hide latency)
-    beq     .LinvokeArgsDone
-
+    // is this a native method?
+    stmfd   sp!, {r0}                   @ push methodToCall to stack
+    ldr     r0, [r0, #offMethod_accessFlags] @ r0<- methodToCall->accessFlags
+    tst     r0, #ACC_NATIVE
+    bne     .LinvokeNonRangeNative
+// end WITH_TAINT_TRACKING
     @ r0=methodToCall, r1=GFED, r2=count, r10=outs
 .LinvokeNonRange:
+// begin WITH_TAINT_TRACKING
+    stmfd   sp!, {r3}                   @ push count, outSize to stack
+    // clear native hack
+    mov	    r3, #0
+    str     r3, [r10, #-4]!
+// end WITH_TAINT_TRACKING
     rsb     r2, r2, #5                  @ r2<- 5-r2
     add     pc, pc, r2, lsl #4          @ computed goto, 4 instrs each
     bl      common_abort                @ (skipped due to ARM prefetch)
+// begin WITH_TAINT_TRACKING
+5:  and     ip, rINST, #0x0f00          @ isolate A
+    mov	    r2, ip, lsr #5
+    ldrd    r2, [rFP, r2]               @ r2/r3<- vA (shift right 8, left 2) / taint
+    strd    r2, [r10, #-8]!             @ *--outs = vA
+4:  and     ip, r1, #0xf000             @ isolate G
+    mov	    r2, ip, lsr #9
+    ldrd    r2, [rFP, r2]               @ r2<- vG (shift right 12, left 2)
+    strd    r2, [r10, #-8]!             @ *--outs = vG
+3:  and     ip, r1, #0x0f00             @ isolate F
+    mov	    r2, ip, lsr #5
+    ldrd    r2, [rFP, r2]               @ r2<- vF
+    strd    r2, [r10, #-8]!             @ *--outs = vF
+2:  and     ip, r1, #0x00f0             @ isolate E
+    mov	    r2, ip, lsr #1
+    ldrd    r2, [rFP, r2]               @ r2<- vE
+    strd    r2, [r10, #-8]!             @ *--outs = vE
+1:  and     ip, r1, #0x000f             @ isolate D
+    mov	    r2, ip, lsl #3
+    ldrd    r2, [rFP, r2]               @ r2<- vD
+    strd    r2, [r10, #-8]!             @ *--outs = vD
+// end WITH_TAINT_TRACKING
+0:  @ fall through to .LinvokeArgsDone
+// begin WITH_TAINT_TRACKING
+    ldmfd   sp!, {r3}                   @ restore outSize
+    ldmfd   sp!, {r0}                   @ restore methodToCall
+    b       .LinvokeArgsDone            @ jump over .LinvokeNonRangeNative
+// end WITH_TAINT_TRACKING
+
+    @ r0=methodToCall, r1=GFED, r2=count, r10=outs
+.LinvokeNonRangeNative:
+// begin WITH_TAINT_TRACKING
+    sub	    r0, r10, r2, lsl #2         @ r0<- outs (no taint)
+    sub	    r0, r0, #4                  @ native hack
+    stmfd   sp!, {r3}                   @ push outSize to stack
+// end WITH_TAINT_TRACKING
+    rsb     r2, r2, #5                  @ r2<- 5-r2
+// begin WITH_TAINT_TRACKING
+    mov	    r3, #5
+    mul	    r2, r2, r3
+    add     pc, pc, r2, lsl #2         	@ computed goto, 5 instrs each, 4-byte instrs
+// end WITH_TAINT_TRACKING
+    bl      common_abort                @ (skipped due to ARM prefetch)
+// begin WITH_TAINT_TRACKING
 5:  and     ip, rINST, #0x0f00          @ isolate A
-    ldr     r2, [rFP, ip, lsr #6]       @ r2<- vA (shift right 8, left 2)
-    mov     r0, r0                      @ nop
-    str     r2, [r10, #-4]!             @ *--outs = vA
+    mov	    r2, ip, lsr #5
+    ldrd    r2, [rFP, r2]               @ r2/r3<- vA (shift right 8, left 2) / taint
+    str     r2, [r0, #-4]!
+    str	    r3, [r10, #-4]!
 4:  and     ip, r1, #0xf000             @ isolate G
-    ldr     r2, [rFP, ip, lsr #10]      @ r2<- vG (shift right 12, left 2)
-    mov     r0, r0                      @ nop
-    str     r2, [r10, #-4]!             @ *--outs = vG
+    mov	    r2, ip, lsr #9
+    ldrd    r2, [rFP, r2]               @ r2<- vG (shift right 12, left 2)
+    str     r2, [r0, #-4]!
+    str	    r3, [r10, #-4]!
 3:  and     ip, r1, #0x0f00             @ isolate F
-    ldr     r2, [rFP, ip, lsr #6]       @ r2<- vF
-    mov     r0, r0                      @ nop
-    str     r2, [r10, #-4]!             @ *--outs = vF
+    mov	    r2, ip, lsr #5
+    ldrd    r2, [rFP, r2]               @ r2<- vF
+    str     r2, [r0, #-4]!
+    str	    r3, [r10, #-4]!
 2:  and     ip, r1, #0x00f0             @ isolate E
-    ldr     r2, [rFP, ip, lsr #2]       @ r2<- vE
-    mov     r0, r0                      @ nop
-    str     r2, [r10, #-4]!             @ *--outs = vE
+    mov	    r2, ip, lsr #1
+    ldrd    r2, [rFP, r2]               @ r2<- vE
+    str     r2, [r0, #-4]!
+    str	    r3, [r10, #-4]!
 1:  and     ip, r1, #0x000f             @ isolate D
-    ldr     r2, [rFP, ip, lsl #2]       @ r2<- vD
-    mov     r0, r0                      @ nop
-    str     r2, [r10, #-4]!             @ *--outs = vD
+    mov	    r2, ip, lsl #3
+    ldrd    r2, [rFP, r2]               @ r2<- vD
+    str     r2, [r0, #-4]!
+    str     r3, [r10, #-4]!
+// end WITH_TAINT_TRACKING
 0:  @ fall through to .LinvokeArgsDone
+// begin WITH_TAINT_TRACKING
+    // clear native hack
+    mov		r3, #0
+    str     r3, [r10, #-4]!
+    ldmfd   sp!, {r3}                   @ restore outSize
+    ldmfd   sp!, {r0}                   @ restore methodToCall
+// end WITH_TAINT_TRACKING
 
 .LinvokeArgsDone: @ r0=methodToCall
     ldrh    r9, [r0, #offMethod_registersSize]  @ r9<- methodToCall->regsSize
@@ -16128,11 +19216,17 @@ common_invokeMethodNoRange:
     ldr     rINST, [r0, #offMethod_clazz]  @ rINST<- method->clazz
     @ find space for the new stack frame, check for overflow
     SAVEAREA_FROM_FP(r1, rFP)           @ r1<- stack save area
-    sub     r1, r1, r9, lsl #2          @ r1<- newFp (old savearea - regsSize)
+// begin WITH_TAINT_TRACKING
+    sub     r1, r1, r9, lsl #3
+    sub	    r1, r1, #4                  @ r1<- newFp (old savearea - 2*regsSize - 4)
+// end WITH_TAINT_TRACKING
     SAVEAREA_FROM_FP(r10, r1)           @ r10<- newSaveArea
 @    bl      common_dumpRegs
     ldr     r9, [rSELF, #offThread_interpStackEnd]    @ r9<- interpStackEnd
-    sub     r3, r10, r3, lsl #2         @ r3<- bottom (newsave - outsSize)
+// begin WITH_TAINT_TRACKING
+    sub     r3, r10, r3, lsl #2
+    sub	    r3, r3, #4                  @ r3<- bottom (newsave - outsSize - 4)
+// end WITH_TAINT_TRACKING
     cmp     r3, r9                      @ bottom < interpStackEnd?
     ldrh    lr, [rSELF, #offThread_subMode]
     ldr     r3, [r0, #offMethod_accessFlags] @ r3<- methodToCall->accessFlags
@@ -16240,6 +19334,16 @@ dalvik_mterp:
 7:
 
     @ native return; r10=newSaveArea
+
+// begin WITH_TAINT_TRACKING
+    // set return taint
+    SAVEAREA_FROM_FP(r0, rFP)           @ r0<- stack save area
+    ldr     r1, [r0, #offStackSaveArea_argCount]    @ r1<- arg count
+    sub     r0, r0, r1, lsl #2
+    ldr     r2, [r0, #-4]               @ r2<- return taint
+    str	    r2, [rSELF, #offThread_rtaint]
+// end WITH_TAINT_TRACKING
+
     @ equivalent to dvmPopJniLocals
     ldr     r0, [r10, #offStackSaveArea_localRefCookie] @ r0<- saved top
     ldr     r1, [rSELF, #offThread_exception] @ check for exception
diff --git a/vm/mterp/out/InterpC-allstubs.cpp b/vm/mterp/out/InterpC-allstubs.cpp
index 0fcee85..7474389 100644
--- a/vm/mterp/out/InterpC-allstubs.cpp
+++ b/vm/mterp/out/InterpC-allstubs.cpp
@@ -143,6 +143,31 @@ static const char kSpacing[] = "            ";
 # define DUMP_REGS(_meth, _frame, _inOnly) ((void)0)
 #endif
 
+/*
+ * If enabled, log taint propagation
+ */
+#ifdef WITH_TAINT_TRACKING
+# define TLOGD(...) TLOG(LOG_DEBUG, __VA_ARGS__)
+# define TLOGV(...) TLOG(LOG_VERBOSE, __VA_ARGS__)
+# define TLOGW(...) TLOG(LOG_WARN, __VA_ARGS__)
+# define TLOGE(...) TLOG(LOG_ERROR, __VA_ARGS__)
+# define TLOG(_level, ...) do {                                             \
+        char debugStrBuf[128];                                              \
+        snprintf(debugStrBuf, sizeof(debugStrBuf), __VA_ARGS__);            \
+        if (curMethod != NULL)                                              \
+            ALOG(_level, LOG_TAG"t", "%-2d|%04x|%s.%s:%s\n",                \
+                self->threadId, (int)(pc - curMethod->insns), curMethod->clazz->descriptor, curMethod->name, debugStrBuf); \
+        else                                                                \
+            ALOG(_level, LOG_TAG"t", "%-2d|####%s\n",                       \
+                self->threadId, debugStrBuf);                               \
+    } while(false)
+#else
+# define TLOGD(...) ((void)0)
+# define TLOGV(...) ((void)0)
+# define TLOGW(...) ((void)0)
+# define TLOGE(...) ((void)0)
+#endif
+
 /* get a long from an array of u4 */
 static inline s8 getLongFromArray(const u4* ptr, int idx)
 {
@@ -160,6 +185,20 @@ static inline s8 getLongFromArray(const u4* ptr, int idx)
 #endif
 }
 
+#ifdef WITH_TAINT_TRACKING
+/* get a long from an array of u4 */
+static inline s8 getLongFromArrayTaint(const u4* ptr, int idx)
+{
+    /* Need to use the "union" version for taint tracking */
+    union { s8 ll; u4 parts[2]; } conv;
+
+    ptr += idx;
+    conv.parts[0] = ptr[0];
+    conv.parts[1] = ptr[2];
+    return conv.ll;
+}
+#endif
+
 /* store a long into an array of u4 */
 static inline void putLongToArray(u4* ptr, int idx, s8 val)
 {
@@ -175,6 +214,20 @@ static inline void putLongToArray(u4* ptr, int idx, s8 val)
 #endif
 }
 
+#ifdef WITH_TAINT_TRACKING
+/* store a long into an array of u4 */
+static inline void putLongToArrayTaint(u4* ptr, int idx, s8 val)
+{
+    /* Need to use the "union" version for taint tracking */
+    union { s8 ll; u4 parts[2]; } conv;
+
+    ptr += idx;
+    conv.ll = val;
+    ptr[0] = conv.parts[0];
+    ptr[2] = conv.parts[1];
+}
+#endif
+
 /* get a double from an array of u4 */
 static inline double getDoubleFromArray(const u4* ptr, int idx)
 {
@@ -192,6 +245,20 @@ static inline double getDoubleFromArray(const u4* ptr, int idx)
 #endif
 }
 
+#ifdef WITH_TAINT_TRACKING
+/* get a double from an array of u4 */
+static inline double getDoubleFromArrayTaint(const u4* ptr, int idx)
+{
+    /* Need to use the "union" version for taint tracking */
+    union { double d; u4 parts[2]; } conv;
+
+    ptr += idx;
+    conv.parts[0] = ptr[0];
+    conv.parts[1] = ptr[2];
+    return conv.d;
+}
+#endif
+
 /* store a double into an array of u4 */
 static inline void putDoubleToArray(u4* ptr, int idx, double dval)
 {
@@ -207,6 +274,20 @@ static inline void putDoubleToArray(u4* ptr, int idx, double dval)
 #endif
 }
 
+#ifdef WITH_TAINT_TRACKING
+/* store a double into an array of u4 */
+static inline void putDoubleToArrayTaint(u4* ptr, int idx, double dval)
+{
+    /* Need to use the "union" version for taint tracking */
+    union { double d; u4 parts[2]; } conv;
+
+    ptr += idx;
+    conv.d = dval;
+    ptr[0] = conv.parts[0];
+    ptr[2] = conv.parts[1];
+}
+#endif
+
 /*
  * If enabled, validate the register number on every access.  Otherwise,
  * just do an array access.
@@ -215,6 +296,55 @@ static inline void putDoubleToArray(u4* ptr, int idx, double dval)
  *
  * "_idx" may be referenced more than once.
  */
+#ifdef WITH_TAINT_TRACKING
+/* -- Begin Taint Tracking version ------------------------------- */
+/* Taint tags are interleaved between registers. All indexes must
+ * be multiplied by 2 (i.e., left bit shift by 1) */
+#ifdef CHECK_REGISTER_INDICES
+# define GET_REGISTER(_idx) \
+    ( (_idx) < curMethod->registersSize ? \
+        (fp[(_idx)<<1]) : (assert(!"bad reg"),1969) )
+# define SET_REGISTER(_idx, _val) \
+    ( (_idx) < curMethod->registersSize ? \
+        (fp[(_idx)<<1] = (u4)(_val)) : (assert(!"bad reg"),1969) )
+# define GET_REGISTER_AS_OBJECT(_idx)       ((Object *)GET_REGISTER(_idx))
+# define SET_REGISTER_AS_OBJECT(_idx, _val) SET_REGISTER(_idx, (s4)_val)
+# define GET_REGISTER_INT(_idx) ((s4) GET_REGISTER(_idx))
+# define SET_REGISTER_INT(_idx, _val) SET_REGISTER(_idx, (s4)_val)
+# define GET_REGISTER_WIDE(_idx) \
+    ( (_idx) < curMethod->registersSize-1 ? \
+        getLongFromArrayTaint(fp, ((_idx)<<1)) : (assert(!"bad reg"),1969) )
+# define SET_REGISTER_WIDE(_idx, _val) \
+    ( (_idx) < curMethod->registersSize-1 ? \
+        putLongToArrayTaint(fp, ((_idx)<<1), (_val)) : (assert(!"bad reg"),1969) )
+# define GET_REGISTER_FLOAT(_idx) \
+    ( (_idx) < curMethod->registersSize ? \
+        (*((float*) &fp[(_idx)<<1])) : (assert(!"bad reg"),1969.0f) )
+# define SET_REGISTER_FLOAT(_idx, _val) \
+    ( (_idx) < curMethod->registersSize ? \
+        (*((float*) &fp[(_idx)<<1]) = (_val)) : (assert(!"bad reg"),1969.0f) )
+# define GET_REGISTER_DOUBLE(_idx) \
+    ( (_idx) < curMethod->registersSize-1 ? \
+        getDoubleFromArrayTaint(fp, ((_idx)<<1)) : (assert(!"bad reg"),1969.0) )
+# define SET_REGISTER_DOUBLE(_idx, _val) \
+    ( (_idx) < curMethod->registersSize-1 ? \
+        putDoubleToArrayTaint(fp, ((_idx)<<1), (_val)) : (assert(!"bad reg"),1969.0) )
+#else
+# define GET_REGISTER(_idx)                 (fp[(_idx)<<1])
+# define SET_REGISTER(_idx, _val)           (fp[(_idx)<<1] = (_val))
+# define GET_REGISTER_AS_OBJECT(_idx)       ((Object*) fp[(_idx)<<1])
+# define SET_REGISTER_AS_OBJECT(_idx, _val) (fp[(_idx)<<1] = (u4)(_val))
+# define GET_REGISTER_INT(_idx)             ((s4)GET_REGISTER(_idx))
+# define SET_REGISTER_INT(_idx, _val)       SET_REGISTER(_idx, (s4)_val)
+# define GET_REGISTER_WIDE(_idx)            getLongFromArrayTaint(fp, ((_idx)<<1))
+# define SET_REGISTER_WIDE(_idx, _val)      putLongToArrayTaint(fp, ((_idx)<<1), (_val))
+# define GET_REGISTER_FLOAT(_idx)           (*((float*) &fp[(_idx)<<1]))
+# define SET_REGISTER_FLOAT(_idx, _val)     (*((float*) &fp[(_idx)<<1]) = (_val))
+# define GET_REGISTER_DOUBLE(_idx)          getDoubleFromArrayTaint(fp, ((_idx)<<1))
+# define SET_REGISTER_DOUBLE(_idx, _val)    putDoubleToArrayTaint(fp, ((_idx)<<1), (_val))
+#endif
+/* -- End Taint Tracking version ---------------------------------- */
+#else /* no taint tracking */
 #ifdef CHECK_REGISTER_INDICES
 # define GET_REGISTER(_idx) \
     ( (_idx) < curMethod->registersSize ? \
@@ -258,6 +388,48 @@ static inline void putDoubleToArray(u4* ptr, int idx, double dval)
 # define GET_REGISTER_DOUBLE(_idx)          getDoubleFromArray(fp, (_idx))
 # define SET_REGISTER_DOUBLE(_idx, _val)    putDoubleToArray(fp, (_idx), (_val))
 #endif
+#endif /* end no taint tracking */
+
+#ifdef WITH_TAINT_TRACKING
+/* Core get and set macros */
+# define GET_REGISTER_TAINT(_idx)	     (fp[((_idx)<<1)+1])
+# define SET_REGISTER_TAINT(_idx, _val)	     (fp[((_idx)<<1)+1] = (u4)(_val))
+# define GET_REGISTER_TAINT_WIDE(_idx)       (fp[((_idx)<<1)+1])
+# define SET_REGISTER_TAINT_WIDE(_idx, _val) (fp[((_idx)<<1)+1] = \
+	                                      fp[((_idx)<<1)+3] = (u4)(_val))
+/* Alternate interfaces to help dereference register width */
+# define GET_REGISTER_TAINT_INT(_idx)	          GET_REGISTER_TAINT(_idx)
+# define SET_REGISTER_TAINT_INT(_idx, _val)       SET_REGISTER_TAINT(_idx, _val)
+# define GET_REGISTER_TAINT_FLOAT(_idx)	          GET_REGISTER_TAINT(_idx)
+# define SET_REGISTER_TAINT_FLOAT(_idx, _val)     SET_REGISTER_TAINT(_idx, _val)
+# define GET_REGISTER_TAINT_DOUBLE(_idx)          GET_REGISTER_TAINT_WIDE(_idx)
+# define SET_REGISTER_TAINT_DOUBLE(_idx, _val)    SET_REGISTER_TAINT_WIDE(_idx, _val)
+# define GET_REGISTER_TAINT_AS_OBJECT(_idx)       GET_REGISTER_TAINT(_idx)
+# define SET_REGISTER_TAINT_AS_OBJECT(_idx, _val) SET_REGISTER_TAINT(_idx, _val)
+
+/* Object Taint interface */
+# define GET_ARRAY_TAINT(_arr)		      ((_arr)->taint.tag)
+# define SET_ARRAY_TAINT(_arr, _val)	      ((_arr)->taint.tag = (u4)(_val))
+
+/* Return value taint (assumes rtaint variable is in scope */
+# define GET_RETURN_TAINT()		      (rtaint.tag)
+# define SET_RETURN_TAINT(_val)		      (rtaint.tag = (u4)(_val))
+#else
+# define GET_REGISTER_TAINT(_idx)		    ((void)0)
+# define SET_REGISTER_TAINT(_idx, _val)		    ((void)0)
+# define GET_REGISTER_TAINT_WIDE(_idx)		    ((void)0)
+# define SET_REGISTER_TAINT_WIDE(_idx, _val)	    ((void)0)
+# define GET_REGISTER_TAINT_INT(_idx)		    ((void)0)
+# define SET_REGISTER_TAINT_INT(_idx, _val)	    ((void)0)
+# define GET_REGISTER_TAINT_DOUBLE(_idx)	    ((void)0)
+# define SET_REGISTER_TAINT_DOUBLE(_idx, _val)	    ((void)0)
+# define GET_REGISTER_TAINT_AS_OBJECT(_idx)	    ((void)0)
+# define SET_REGISTER_TAINT_AS_OBJECT(_idx, _val)   ((void)0)
+# define GET_ARRAY_TAINT(_field)                    ((void)0)
+# define SET_ARRAY_TAINT(_field, _val)              ((void)0)
+# define GET_RETURN_TAINT()			    ((void)0)
+# define SET_RETURN_TAINT(_val)			    ((void)0)
+#endif
 
 /*
  * Get 16 bits from the specified offset of the program counter.  We always
@@ -399,6 +571,10 @@ static inline bool checkForNullExportPC(Object* obj, u4* fp, const u2* pc)
 #define methodClassDex          self->interpSave.methodClassDex
 #define debugTrackedRefStart    self->interpSave.debugTrackedRefStart
 
+#ifdef WITH_TAINT_TRACKING
+#define rtaint			self->interpSave.rtaint
+#endif
+
 /* ugh */
 #define STUB_HACK(x) x
 #if defined(WITH_JIT)
@@ -537,6 +713,10 @@ GOTO_TARGET_DECL(exceptionThrown);
         ILOGV("|%s v%d,v%d", (_opname), vdst, vsrc1);                       \
         SET_REGISTER##_totype(vdst,                                         \
             GET_REGISTER##_fromtype(vsrc1));                                \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT##_totype(vdst,                                   \
+	    GET_REGISTER_TAINT##_fromtype(vsrc1));                          \
+/* endif */                                                                 \
         FINISH(1);
 
 #define HANDLE_FLOAT_TO_INT(_opcode, _opname, _fromvtype, _fromrtype,       \
@@ -562,6 +742,10 @@ GOTO_TARGET_DECL(exceptionThrown);
         else                                                                \
             result = (_tovtype) val;                                        \
         SET_REGISTER##_tortype(vdst, result);                               \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT##_tortype(vdst,                                  \
+	    GET_REGISTER_TAINT##_fromrtype(vsrc1));                         \
+/* endif */                                                                 \
     }                                                                       \
     FINISH(1);
 
@@ -571,6 +755,9 @@ GOTO_TARGET_DECL(exceptionThrown);
         vsrc1 = INST_B(inst);                                               \
         ILOGV("|int-to-%s v%d,v%d", (_opname), vdst, vsrc1);                \
         SET_REGISTER(vdst, (_type) GET_REGISTER(vsrc1));                    \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT(vdst, GET_REGISTER_TAINT(vsrc1));                \
+/* endif */                                                                 \
         FINISH(1);
 
 /* NOTE: the comparison result is always a signed 4-byte integer */
@@ -597,6 +784,9 @@ GOTO_TARGET_DECL(exceptionThrown);
             result = (_nanVal);                                             \
         ILOGV("+ result=%d", result);                                       \
         SET_REGISTER(vdst, result);                                         \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT(vdst, TAINT_CLEAR);				    \
+/* endif */                                                                 \
     }                                                                       \
     FINISH(2);
 
@@ -638,6 +828,9 @@ GOTO_TARGET_DECL(exceptionThrown);
         vsrc1 = INST_B(inst);                                               \
         ILOGV("|%s v%d,v%d", (_opname), vdst, vsrc1);                       \
         SET_REGISTER##_type(vdst, _pfx GET_REGISTER##_type(vsrc1) _sfx);    \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT##_type(vdst, GET_REGISTER_TAINT##_type(vsrc1));  \
+/* endif */                                                                 \
         FINISH(1);
 
 #define HANDLE_OP_X_INT(_opcode, _opname, _op, _chkdiv)                     \
@@ -672,6 +865,10 @@ GOTO_TARGET_DECL(exceptionThrown);
             SET_REGISTER(vdst,                                              \
                 (s4) GET_REGISTER(vsrc1) _op (s4) GET_REGISTER(vsrc2));     \
         }                                                                   \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT(vdst,                                            \
+	    (GET_REGISTER_TAINT(vsrc1)|GET_REGISTER_TAINT(vsrc2)) );        \
+/* endif */                                                                 \
     }                                                                       \
     FINISH(2);
 
@@ -686,6 +883,10 @@ GOTO_TARGET_DECL(exceptionThrown);
         ILOGV("|%s-int v%d,v%d", (_opname), vdst, vsrc1);                   \
         SET_REGISTER(vdst,                                                  \
             _cast GET_REGISTER(vsrc1) _op (GET_REGISTER(vsrc2) & 0x1f));    \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT(vdst,                                            \
+	    (GET_REGISTER_TAINT(vsrc1)|GET_REGISTER_TAINT(vsrc2)) );        \
+/* endif */                                                                 \
     }                                                                       \
     FINISH(2);
 
@@ -702,7 +903,7 @@ GOTO_TARGET_DECL(exceptionThrown);
             if ((s2) vsrc2 == 0) {                                          \
                 EXPORT_PC();                                                \
                 dvmThrowArithmeticException("divide by zero");              \
-                GOTO_exceptionThrown();                                     \
+                GOTO_exceptionThrown();                                      \
             }                                                               \
             if ((u4)firstVal == 0x80000000 && ((s2) vsrc2) == -1) {         \
                 /* won't generate /lit16 instr for this; check anyway */    \
@@ -718,6 +919,9 @@ GOTO_TARGET_DECL(exceptionThrown);
             /* non-div/rem case */                                          \
             SET_REGISTER(vdst, GET_REGISTER(vsrc1) _op (s2) vsrc2);         \
         }                                                                   \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT(vdst, GET_REGISTER_TAINT(vsrc1));                \
+/* endif */                                                                 \
         FINISH(2);
 
 #define HANDLE_OP_X_INT_LIT8(_opcode, _opname, _op, _chkdiv)                \
@@ -751,6 +955,9 @@ GOTO_TARGET_DECL(exceptionThrown);
             SET_REGISTER(vdst,                                              \
                 (s4) GET_REGISTER(vsrc1) _op (s1) vsrc2);                   \
         }                                                                   \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT(vdst, GET_REGISTER_TAINT(vsrc1));                \
+/* endif */                                                                 \
     }                                                                       \
     FINISH(2);
 
@@ -766,6 +973,9 @@ GOTO_TARGET_DECL(exceptionThrown);
             (_opname), vdst, vsrc1, vsrc2);                                 \
         SET_REGISTER(vdst,                                                  \
             _cast GET_REGISTER(vsrc1) _op (vsrc2 & 0x1f));                  \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT(vdst, GET_REGISTER_TAINT(vsrc1));                \
+/* endif */                                                                 \
     }                                                                       \
     FINISH(2);
 
@@ -796,6 +1006,10 @@ GOTO_TARGET_DECL(exceptionThrown);
             SET_REGISTER(vdst,                                              \
                 (s4) GET_REGISTER(vdst) _op (s4) GET_REGISTER(vsrc1));      \
         }                                                                   \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT(vdst,                                            \
+	    (GET_REGISTER_TAINT(vdst)|GET_REGISTER_TAINT(vsrc1)) );         \
+/* endif */                                                                 \
         FINISH(1);
 
 #define HANDLE_OP_SHX_INT_2ADDR(_opcode, _opname, _cast, _op)               \
@@ -805,6 +1019,10 @@ GOTO_TARGET_DECL(exceptionThrown);
         ILOGV("|%s-int-2addr v%d,v%d", (_opname), vdst, vsrc1);             \
         SET_REGISTER(vdst,                                                  \
             _cast GET_REGISTER(vdst) _op (GET_REGISTER(vsrc1) & 0x1f));     \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT(vdst,                                            \
+	    (GET_REGISTER_TAINT(vdst)|GET_REGISTER_TAINT(vsrc1)) );         \
+/* endif */                                                                 \
         FINISH(1);
 
 #define HANDLE_OP_X_LONG(_opcode, _opname, _op, _chkdiv)                    \
@@ -840,6 +1058,10 @@ GOTO_TARGET_DECL(exceptionThrown);
             SET_REGISTER_WIDE(vdst,                                         \
                 (s8) GET_REGISTER_WIDE(vsrc1) _op (s8) GET_REGISTER_WIDE(vsrc2)); \
         }                                                                   \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT_WIDE(vdst,                                       \
+	   (GET_REGISTER_TAINT_WIDE(vsrc1)|GET_REGISTER_TAINT_WIDE(vsrc2)));\
+/* endif */                                                                 \
     }                                                                       \
     FINISH(2);
 
@@ -854,6 +1076,10 @@ GOTO_TARGET_DECL(exceptionThrown);
         ILOGV("|%s-long v%d,v%d,v%d", (_opname), vdst, vsrc1, vsrc2);       \
         SET_REGISTER_WIDE(vdst,                                             \
             _cast GET_REGISTER_WIDE(vsrc1) _op (GET_REGISTER(vsrc2) & 0x3f)); \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT_WIDE(vdst,                                       \
+	   (GET_REGISTER_TAINT_WIDE(vsrc1)|GET_REGISTER_TAINT_WIDE(vsrc2)));\
+/* endif */                                                                 \
     }                                                                       \
     FINISH(2);
 
@@ -886,6 +1112,10 @@ GOTO_TARGET_DECL(exceptionThrown);
             SET_REGISTER_WIDE(vdst,                                         \
                 (s8) GET_REGISTER_WIDE(vdst) _op (s8)GET_REGISTER_WIDE(vsrc1));\
         }                                                                   \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT_WIDE(vdst,                                       \
+	    (GET_REGISTER_TAINT_WIDE(vdst)|GET_REGISTER_TAINT_WIDE(vsrc1)));\
+/* endif */                                                                 \
         FINISH(1);
 
 #define HANDLE_OP_SHX_LONG_2ADDR(_opcode, _opname, _cast, _op)              \
@@ -895,6 +1125,10 @@ GOTO_TARGET_DECL(exceptionThrown);
         ILOGV("|%s-long-2addr v%d,v%d", (_opname), vdst, vsrc1);            \
         SET_REGISTER_WIDE(vdst,                                             \
             _cast GET_REGISTER_WIDE(vdst) _op (GET_REGISTER(vsrc1) & 0x3f)); \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT_WIDE(vdst,                                       \
+	    (GET_REGISTER_TAINT_WIDE(vdst)|GET_REGISTER_TAINT_WIDE(vsrc1)));\
+/* endif */                                                                 \
         FINISH(1);
 
 #define HANDLE_OP_X_FLOAT(_opcode, _opname, _op)                            \
@@ -908,6 +1142,10 @@ GOTO_TARGET_DECL(exceptionThrown);
         ILOGV("|%s-float v%d,v%d,v%d", (_opname), vdst, vsrc1, vsrc2);      \
         SET_REGISTER_FLOAT(vdst,                                            \
             GET_REGISTER_FLOAT(vsrc1) _op GET_REGISTER_FLOAT(vsrc2));       \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT_FLOAT(vdst,                                      \
+	    (GET_REGISTER_TAINT_FLOAT(vsrc1)|GET_REGISTER_TAINT_FLOAT(vsrc2)));\
+/* endif */                                                                 \
     }                                                                       \
     FINISH(2);
 
@@ -922,6 +1160,10 @@ GOTO_TARGET_DECL(exceptionThrown);
         ILOGV("|%s-double v%d,v%d,v%d", (_opname), vdst, vsrc1, vsrc2);     \
         SET_REGISTER_DOUBLE(vdst,                                           \
             GET_REGISTER_DOUBLE(vsrc1) _op GET_REGISTER_DOUBLE(vsrc2));     \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT_DOUBLE(vdst,                                     \
+	    (GET_REGISTER_TAINT_DOUBLE(vsrc1)|GET_REGISTER_TAINT_DOUBLE(vsrc2)));\
+/* endif */                                                                 \
     }                                                                       \
     FINISH(2);
 
@@ -932,6 +1174,10 @@ GOTO_TARGET_DECL(exceptionThrown);
         ILOGV("|%s-float-2addr v%d,v%d", (_opname), vdst, vsrc1);           \
         SET_REGISTER_FLOAT(vdst,                                            \
             GET_REGISTER_FLOAT(vdst) _op GET_REGISTER_FLOAT(vsrc1));        \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT_FLOAT(vdst,                                      \
+	    (GET_REGISTER_TAINT_FLOAT(vdst)|GET_REGISTER_TAINT_FLOAT(vsrc1)));\
+/* endif */                                                                 \
         FINISH(1);
 
 #define HANDLE_OP_X_DOUBLE_2ADDR(_opcode, _opname, _op)                     \
@@ -941,6 +1187,10 @@ GOTO_TARGET_DECL(exceptionThrown);
         ILOGV("|%s-double-2addr v%d,v%d", (_opname), vdst, vsrc1);          \
         SET_REGISTER_DOUBLE(vdst,                                           \
             GET_REGISTER_DOUBLE(vdst) _op GET_REGISTER_DOUBLE(vsrc1));      \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT_DOUBLE(vdst,                                     \
+	    (GET_REGISTER_TAINT_DOUBLE(vdst)|GET_REGISTER_TAINT_DOUBLE(vsrc1)));\
+/* endif */                                                                 \
         FINISH(1);
 
 #define HANDLE_OP_AGET(_opcode, _opname, _type, _regsize)                   \
@@ -965,6 +1215,11 @@ GOTO_TARGET_DECL(exceptionThrown);
         SET_REGISTER##_regsize(vdst,                                        \
             ((_type*)(void*)arrayObj->contents)[GET_REGISTER(vsrc2)]);      \
         ILOGV("+ AGET[%d]=%#x", GET_REGISTER(vsrc2), GET_REGISTER(vdst));   \
+/* ifdef WITH_TAINT_TRACKING */						    \
+	SET_REGISTER_TAINT##_regsize(vdst,                                  \
+	    (GET_ARRAY_TAINT(arrayObj)|GET_REGISTER_TAINT(vsrc2)));         \
+/* endif */								    \
+        ILOGV("+ AGET[%d]=0x%x", GET_REGISTER(vsrc2), GET_REGISTER(vdst));  \
     }                                                                       \
     FINISH(2);
 
@@ -990,6 +1245,11 @@ GOTO_TARGET_DECL(exceptionThrown);
         ILOGV("+ APUT[%d]=0x%08x", GET_REGISTER(vsrc2), GET_REGISTER(vdst));\
         ((_type*)(void*)arrayObj->contents)[GET_REGISTER(vsrc2)] =          \
             GET_REGISTER##_regsize(vdst);                                   \
+/* ifdef WITH_TAINT_TRACKING */						    \
+	SET_ARRAY_TAINT(arrayObj,                                           \
+		(GET_ARRAY_TAINT(arrayObj) |                                \
+		 GET_REGISTER_TAINT##_regsize(vdst)) );                     \
+/* endif */								    \
     }                                                                       \
     FINISH(2);
 
@@ -1033,6 +1293,11 @@ GOTO_TARGET_DECL(exceptionThrown);
             dvmGetField##_ftype(obj, ifield->byteOffset));                  \
         ILOGV("+ IGET '%s'=0x%08llx", ifield->field.name,                   \
             (u8) GET_REGISTER##_regsize(vdst));                             \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+	SET_REGISTER_TAINT##_regsize(vdst,                                  \
+	    (GET_REGISTER_TAINT(vsrc1)|                                     \
+	     dvmGetFieldTaint##_ftype(obj,ifield->byteOffset)) );           \
+/* endif */                                                                 \
     }                                                                       \
     FINISH(2);
 
@@ -1051,6 +1316,13 @@ GOTO_TARGET_DECL(exceptionThrown);
         SET_REGISTER##_regsize(vdst, dvmGetField##_ftype(obj, ref));        \
         ILOGV("+ IGETQ %d=0x%08llx", ref,                                   \
             (u8) GET_REGISTER##_regsize(vdst));                             \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+	/*TLOGW("|IGETQ not supported by taint tracking!!!");*/             \
+	/* compile flag WITH_TAINT_ODEX controls this now */                \
+	SET_REGISTER_TAINT##_regsize(vdst,                                  \
+	    (GET_REGISTER_TAINT(vsrc1)|                                     \
+	     dvmGetFieldTaint##_ftype(obj,ref)) );                          \
+/* endif */                                                                 \
     }                                                                       \
     FINISH(2);
 
@@ -1077,6 +1349,10 @@ GOTO_TARGET_DECL(exceptionThrown);
             GET_REGISTER##_regsize(vdst));                                  \
         ILOGV("+ IPUT '%s'=0x%08llx", ifield->field.name,                   \
             (u8) GET_REGISTER##_regsize(vdst));                             \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+	dvmSetFieldTaint##_ftype(obj, ifield->byteOffset,                   \
+		GET_REGISTER_TAINT##_regsize(vdst));                        \
+/* endif */                                                                 \
     }                                                                       \
     FINISH(2);
 
@@ -1095,6 +1371,12 @@ GOTO_TARGET_DECL(exceptionThrown);
         dvmSetField##_ftype(obj, ref, GET_REGISTER##_regsize(vdst));        \
         ILOGV("+ IPUTQ %d=0x%08llx", ref,                                   \
             (u8) GET_REGISTER##_regsize(vdst));                             \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+	/*TLOGW("|IPUTQ not supported by taint tracking!!!");*/             \
+	/* compile flag WITH_TAINT_ODEX controls this now */                \
+	dvmSetFieldTaint##_ftype(obj, ref,                                  \
+		GET_REGISTER_TAINT##_regsize(vdst));                        \
+/* endif */                                                                 \
     }                                                                       \
     FINISH(2);
 
@@ -1126,6 +1408,9 @@ GOTO_TARGET_DECL(exceptionThrown);
         SET_REGISTER##_regsize(vdst, dvmGetStaticField##_ftype(sfield));    \
         ILOGV("+ SGET '%s'=0x%08llx",                                       \
             sfield->field.name, (u8)GET_REGISTER##_regsize(vdst));          \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+	SET_REGISTER_TAINT##_regsize(vdst, dvmGetStaticFieldTaint##_ftype(sfield));\
+/* endif */                                                                 \
     }                                                                       \
     FINISH(2);
 
@@ -1149,9 +1434,14 @@ GOTO_TARGET_DECL(exceptionThrown);
         dvmSetStaticField##_ftype(sfield, GET_REGISTER##_regsize(vdst));    \
         ILOGV("+ SPUT '%s'=0x%08llx",                                       \
             sfield->field.name, (u8)GET_REGISTER##_regsize(vdst));          \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+	dvmSetStaticFieldTaint##_ftype(sfield,                              \
+		GET_REGISTER_TAINT##_regsize(vdst));                        \
+/* endif */                                                                 \
     }                                                                       \
     FINISH(2);
 
+
 /* File: c/OP_NOP.cpp */
 HANDLE_OPCODE(OP_NOP)
     FINISH(1);
@@ -1165,6 +1455,9 @@ HANDLE_OPCODE(OP_MOVE /*vA, vB*/)
         (INST_INST(inst) == OP_MOVE) ? "" : "-object", vdst, vsrc1,
         kSpacing, vdst, GET_REGISTER(vsrc1));
     SET_REGISTER(vdst, GET_REGISTER(vsrc1));
+/* ifdef WITH_TAINT_TRACKING */
+    SET_REGISTER_TAINT(vdst, GET_REGISTER_TAINT(vsrc1));
+/* endif */
     FINISH(1);
 OP_END
 
@@ -1176,6 +1469,9 @@ HANDLE_OPCODE(OP_MOVE_FROM16 /*vAA, vBBBB*/)
         (INST_INST(inst) == OP_MOVE_FROM16) ? "" : "-object", vdst, vsrc1,
         kSpacing, vdst, GET_REGISTER(vsrc1));
     SET_REGISTER(vdst, GET_REGISTER(vsrc1));
+/* ifdef WITH_TAINT_TRACKING */
+    SET_REGISTER_TAINT(vdst, GET_REGISTER_TAINT(vsrc1));
+/* endif */
     FINISH(2);
 OP_END
 
@@ -1187,6 +1483,9 @@ HANDLE_OPCODE(OP_MOVE_16 /*vAAAA, vBBBB*/)
         (INST_INST(inst) == OP_MOVE_16) ? "" : "-object", vdst, vsrc1,
         kSpacing, vdst, GET_REGISTER(vsrc1));
     SET_REGISTER(vdst, GET_REGISTER(vsrc1));
+/* ifdef WITH_TAINT_TRACKING */
+    SET_REGISTER_TAINT(vdst, GET_REGISTER_TAINT(vsrc1));
+/* endif */
     FINISH(3);
 OP_END
 
@@ -1199,6 +1498,9 @@ HANDLE_OPCODE(OP_MOVE_WIDE /*vA, vB*/)
     ILOGV("|move-wide v%d,v%d %s(v%d=0x%08llx)", vdst, vsrc1,
         kSpacing+5, vdst, GET_REGISTER_WIDE(vsrc1));
     SET_REGISTER_WIDE(vdst, GET_REGISTER_WIDE(vsrc1));
+/* ifdef WITH_TAINT_TRACKING */
+    SET_REGISTER_TAINT_WIDE(vdst, GET_REGISTER_TAINT_WIDE(vsrc1));
+/* endif */
     FINISH(1);
 OP_END
 
@@ -1209,6 +1511,9 @@ HANDLE_OPCODE(OP_MOVE_WIDE_FROM16 /*vAA, vBBBB*/)
     ILOGV("|move-wide/from16 v%d,v%d  (v%d=0x%08llx)", vdst, vsrc1,
         vdst, GET_REGISTER_WIDE(vsrc1));
     SET_REGISTER_WIDE(vdst, GET_REGISTER_WIDE(vsrc1));
+/* ifdef WITH_TAINT_TRACKING */
+    SET_REGISTER_TAINT_WIDE(vdst, GET_REGISTER_TAINT_WIDE(vsrc1));
+/* endif */
     FINISH(2);
 OP_END
 
@@ -1219,6 +1524,9 @@ HANDLE_OPCODE(OP_MOVE_WIDE_16 /*vAAAA, vBBBB*/)
     ILOGV("|move-wide/16 v%d,v%d %s(v%d=0x%08llx)", vdst, vsrc1,
         kSpacing+8, vdst, GET_REGISTER_WIDE(vsrc1));
     SET_REGISTER_WIDE(vdst, GET_REGISTER_WIDE(vsrc1));
+/* ifdef WITH_TAINT_TRACKING */
+    SET_REGISTER_TAINT_WIDE(vdst, GET_REGISTER_TAINT_WIDE(vsrc1));
+/* endif */
     FINISH(3);
 OP_END
 
@@ -1231,6 +1539,9 @@ HANDLE_OPCODE(OP_MOVE_OBJECT /*vA, vB*/)
         (INST_INST(inst) == OP_MOVE) ? "" : "-object", vdst, vsrc1,
         kSpacing, vdst, GET_REGISTER(vsrc1));
     SET_REGISTER(vdst, GET_REGISTER(vsrc1));
+/* ifdef WITH_TAINT_TRACKING */
+    SET_REGISTER_TAINT(vdst, GET_REGISTER_TAINT(vsrc1));
+/* endif */
     FINISH(1);
 OP_END
 
@@ -1244,6 +1555,9 @@ HANDLE_OPCODE(OP_MOVE_OBJECT_FROM16 /*vAA, vBBBB*/)
         (INST_INST(inst) == OP_MOVE_FROM16) ? "" : "-object", vdst, vsrc1,
         kSpacing, vdst, GET_REGISTER(vsrc1));
     SET_REGISTER(vdst, GET_REGISTER(vsrc1));
+/* ifdef WITH_TAINT_TRACKING */
+    SET_REGISTER_TAINT(vdst, GET_REGISTER_TAINT(vsrc1));
+/* endif */
     FINISH(2);
 OP_END
 
@@ -1257,6 +1571,9 @@ HANDLE_OPCODE(OP_MOVE_OBJECT_16 /*vAAAA, vBBBB*/)
         (INST_INST(inst) == OP_MOVE_16) ? "" : "-object", vdst, vsrc1,
         kSpacing, vdst, GET_REGISTER(vsrc1));
     SET_REGISTER(vdst, GET_REGISTER(vsrc1));
+/* ifdef WITH_TAINT_TRACKING */
+    SET_REGISTER_TAINT(vdst, GET_REGISTER_TAINT(vsrc1));
+/* endif */
     FINISH(3);
 OP_END
 
@@ -1268,6 +1585,9 @@ HANDLE_OPCODE(OP_MOVE_RESULT /*vAA*/)
          (INST_INST(inst) == OP_MOVE_RESULT) ? "" : "-object",
          vdst, kSpacing+4, vdst,retval.i);
     SET_REGISTER(vdst, retval.i);
+/* ifdef WITH_TAINT_TRACKING */
+    SET_REGISTER_TAINT(vdst, GET_RETURN_TAINT());
+/* endif */
     FINISH(1);
 OP_END
 
@@ -1276,6 +1596,9 @@ HANDLE_OPCODE(OP_MOVE_RESULT_WIDE /*vAA*/)
     vdst = INST_AA(inst);
     ILOGV("|move-result-wide v%d %s(0x%08llx)", vdst, kSpacing, retval.j);
     SET_REGISTER_WIDE(vdst, retval.j);
+/* ifdef WITH_TAINT_TRACKING */
+    SET_REGISTER_TAINT_WIDE(vdst, GET_RETURN_TAINT());
+/* endif */
     FINISH(1);
 OP_END
 
@@ -1287,6 +1610,9 @@ HANDLE_OPCODE(OP_MOVE_RESULT_OBJECT /*vAA*/)
          (INST_INST(inst) == OP_MOVE_RESULT) ? "" : "-object",
          vdst, kSpacing+4, vdst,retval.i);
     SET_REGISTER(vdst, retval.i);
+/* ifdef WITH_TAINT_TRACKING */
+    SET_REGISTER_TAINT(vdst, GET_RETURN_TAINT());
+/* endif */
     FINISH(1);
 OP_END
 
@@ -1297,6 +1623,9 @@ HANDLE_OPCODE(OP_MOVE_EXCEPTION /*vAA*/)
     ILOGV("|move-exception v%d", vdst);
     assert(self->exception != NULL);
     SET_REGISTER(vdst, (u4)self->exception);
+/* ifdef WITH_TAINT_TRACKING */
+    SET_REGISTER_TAINT(vdst, TAINT_CLEAR);
+/* endif */
     dvmClearException(self);
     FINISH(1);
 OP_END
@@ -1307,6 +1636,9 @@ HANDLE_OPCODE(OP_RETURN_VOID /**/)
 #ifndef NDEBUG
     retval.j = 0xababababULL;    // placate valgrind
 #endif
+/* ifdef WITH_TAINT_TRACKING */
+    SET_RETURN_TAINT(TAINT_CLEAR);
+/* endif */
     GOTO_returnFromMethod();
 OP_END
 
@@ -1316,6 +1648,9 @@ HANDLE_OPCODE(OP_RETURN /*vAA*/)
     ILOGV("|return%s v%d",
         (INST_INST(inst) == OP_RETURN) ? "" : "-object", vsrc1);
     retval.i = GET_REGISTER(vsrc1);
+/* ifdef WITH_TAINT_TRACKING */
+    SET_RETURN_TAINT(GET_REGISTER_TAINT(vsrc1));
+/* endif */
     GOTO_returnFromMethod();
 OP_END
 
@@ -1324,6 +1659,9 @@ HANDLE_OPCODE(OP_RETURN_WIDE /*vAA*/)
     vsrc1 = INST_AA(inst);
     ILOGV("|return-wide v%d", vsrc1);
     retval.j = GET_REGISTER_WIDE(vsrc1);
+/* ifdef WITH_TAINT_TRACKING */
+    SET_RETURN_TAINT(GET_REGISTER_TAINT_WIDE(vsrc1));
+/* endif */
     GOTO_returnFromMethod();
 OP_END
 
@@ -1334,6 +1672,9 @@ HANDLE_OPCODE(OP_RETURN_OBJECT /*vAA*/)
     ILOGV("|return%s v%d",
         (INST_INST(inst) == OP_RETURN) ? "" : "-object", vsrc1);
     retval.i = GET_REGISTER(vsrc1);
+/* ifdef WITH_TAINT_TRACKING */
+    SET_RETURN_TAINT(GET_REGISTER_TAINT(vsrc1));
+/* endif */
     GOTO_returnFromMethod();
 OP_END
 
@@ -1347,6 +1688,9 @@ HANDLE_OPCODE(OP_CONST_4 /*vA, #+B*/)
         tmp = (s4) (INST_B(inst) << 28) >> 28;  // sign extend 4-bit value
         ILOGV("|const/4 v%d,#0x%02x", vdst, (s4)tmp);
         SET_REGISTER(vdst, tmp);
+/* ifdef WITH_TAINT_TRACKING */
+	SET_REGISTER_TAINT(vdst, TAINT_CLEAR);
+/* endif */
     }
     FINISH(1);
 OP_END
@@ -1357,6 +1701,9 @@ HANDLE_OPCODE(OP_CONST_16 /*vAA, #+BBBB*/)
     vsrc1 = FETCH(1);
     ILOGV("|const/16 v%d,#0x%04x", vdst, (s2)vsrc1);
     SET_REGISTER(vdst, (s2) vsrc1);
+/* ifdef WITH_TAINT_TRACKING */
+    SET_REGISTER_TAINT(vdst, TAINT_CLEAR);
+/* endif */
     FINISH(2);
 OP_END
 
@@ -1370,6 +1717,9 @@ HANDLE_OPCODE(OP_CONST /*vAA, #+BBBBBBBB*/)
         tmp |= (u4)FETCH(2) << 16;
         ILOGV("|const v%d,#0x%08x", vdst, tmp);
         SET_REGISTER(vdst, tmp);
+/* ifdef WITH_TAINT_TRACKING */
+	SET_REGISTER_TAINT(vdst, TAINT_CLEAR);
+/* endif */
     }
     FINISH(3);
 OP_END
@@ -1380,6 +1730,9 @@ HANDLE_OPCODE(OP_CONST_HIGH16 /*vAA, #+BBBB0000*/)
     vsrc1 = FETCH(1);
     ILOGV("|const/high16 v%d,#0x%04x0000", vdst, vsrc1);
     SET_REGISTER(vdst, vsrc1 << 16);
+/* ifdef WITH_TAINT_TRACKING */
+    SET_REGISTER_TAINT(vdst, TAINT_CLEAR);
+/* endif */
     FINISH(2);
 OP_END
 
@@ -1389,6 +1742,9 @@ HANDLE_OPCODE(OP_CONST_WIDE_16 /*vAA, #+BBBB*/)
     vsrc1 = FETCH(1);
     ILOGV("|const-wide/16 v%d,#0x%04x", vdst, (s2)vsrc1);
     SET_REGISTER_WIDE(vdst, (s2)vsrc1);
+/* ifdef WITH_TAINT_TRACKING */
+    SET_REGISTER_TAINT_WIDE(vdst, TAINT_CLEAR);
+/* endif */
     FINISH(2);
 OP_END
 
@@ -1402,6 +1758,9 @@ HANDLE_OPCODE(OP_CONST_WIDE_32 /*vAA, #+BBBBBBBB*/)
         tmp |= (u4)FETCH(2) << 16;
         ILOGV("|const-wide/32 v%d,#0x%08x", vdst, tmp);
         SET_REGISTER_WIDE(vdst, (s4) tmp);
+/* ifdef WITH_TAINT_TRACKING */
+	SET_REGISTER_TAINT_WIDE(vdst, TAINT_CLEAR);
+/* endif */
     }
     FINISH(3);
 OP_END
@@ -1418,6 +1777,9 @@ HANDLE_OPCODE(OP_CONST_WIDE /*vAA, #+BBBBBBBBBBBBBBBB*/)
         tmp |= (u8)FETCH(4) << 48;
         ILOGV("|const-wide v%d,#0x%08llx", vdst, tmp);
         SET_REGISTER_WIDE(vdst, tmp);
+/* ifdef WITH_TAINT_TRACKING */
+	SET_REGISTER_TAINT_WIDE(vdst, TAINT_CLEAR);
+/* endif */
     }
     FINISH(5);
 OP_END
@@ -1428,6 +1790,9 @@ HANDLE_OPCODE(OP_CONST_WIDE_HIGH16 /*vAA, #+BBBB000000000000*/)
     vsrc1 = FETCH(1);
     ILOGV("|const-wide/high16 v%d,#0x%04x000000000000", vdst, vsrc1);
     SET_REGISTER_WIDE(vdst, ((u8) vsrc1) << 48);
+/* ifdef WITH_TAINT_TRACKING */
+    SET_REGISTER_TAINT_WIDE(vdst, TAINT_CLEAR);
+/* endif */
     FINISH(2);
 OP_END
 
@@ -1447,6 +1812,9 @@ HANDLE_OPCODE(OP_CONST_STRING /*vAA, string@BBBB*/)
                 GOTO_exceptionThrown();
         }
         SET_REGISTER(vdst, (u4) strObj);
+/* ifdef WITH_TAINT_TRACKING */
+	SET_REGISTER_TAINT(vdst, TAINT_CLEAR);
+/* endif */
     }
     FINISH(2);
 OP_END
@@ -1469,6 +1837,9 @@ HANDLE_OPCODE(OP_CONST_STRING_JUMBO /*vAA, string@BBBBBBBB*/)
                 GOTO_exceptionThrown();
         }
         SET_REGISTER(vdst, (u4) strObj);
+/* ifdef WITH_TAINT_TRACKING */
+	SET_REGISTER_TAINT(vdst, TAINT_CLEAR);
+/* endif */
     }
     FINISH(3);
 OP_END
@@ -1489,6 +1860,9 @@ HANDLE_OPCODE(OP_CONST_CLASS /*vAA, class@BBBB*/)
                 GOTO_exceptionThrown();
         }
         SET_REGISTER(vdst, (u4) clazz);
+/* ifdef WITH_TAINT_TRACKING */
+	SET_REGISTER_TAINT(vdst, TAINT_CLEAR);
+/* endif */
     }
     FINISH(2);
 OP_END
@@ -1590,6 +1964,9 @@ HANDLE_OPCODE(OP_INSTANCE_OF /*vA, vB, class@CCCC*/)
         obj = (Object*)GET_REGISTER(vsrc1);
         if (obj == NULL) {
             SET_REGISTER(vdst, 0);
+/* ifdef WITH_TAINT_TRACKING */
+	    SET_REGISTER_TAINT(vdst, TAINT_CLEAR);
+/* endif */
         } else {
 #if defined(WITH_EXTRA_OBJECT_VALIDATION)
             if (!checkForNullExportPC(obj, fp, pc))
@@ -1603,6 +1980,9 @@ HANDLE_OPCODE(OP_INSTANCE_OF /*vA, vB, class@CCCC*/)
                     GOTO_exceptionThrown();
             }
             SET_REGISTER(vdst, dvmInstanceof(obj->clazz, clazz));
+/* ifdef WITH_TAINT_TRACKING */
+	    SET_REGISTER_TAINT(vdst, TAINT_CLEAR);
+/* endif */
         }
     }
     FINISH(2);
@@ -1621,6 +2001,9 @@ HANDLE_OPCODE(OP_ARRAY_LENGTH /*vA, vB*/)
             GOTO_exceptionThrown();
         /* verifier guarantees this is an array reference */
         SET_REGISTER(vdst, arrayObj->length);
+/* ifdef WITH_TAINT_TRACKING */
+	SET_REGISTER_TAINT(vdst, TAINT_CLEAR);
+/* endif */
     }
     FINISH(1);
 OP_END
@@ -1671,6 +2054,9 @@ HANDLE_OPCODE(OP_NEW_INSTANCE /*vAA, class@BBBB*/)
         if (newObj == NULL)
             GOTO_exceptionThrown();
         SET_REGISTER(vdst, (u4) newObj);
+/* ifdef WITH_TAINT_TRACKING */
+        SET_REGISTER_TAINT(vdst, TAINT_CLEAR);
+/* endif */
     }
     FINISH(2);
 OP_END
@@ -1708,6 +2094,9 @@ HANDLE_OPCODE(OP_NEW_ARRAY /*vA, vB, class@CCCC*/)
         if (newArray == NULL)
             GOTO_exceptionThrown();
         SET_REGISTER(vdst, (u4) newArray);
+/* ifdef WITH_TAINT_TRACKING */
+        SET_REGISTER_TAINT(vdst, TAINT_CLEAR);
+/* endif */
     }
     FINISH(2);
 OP_END
@@ -2024,7 +2413,7 @@ HANDLE_OPCODE(OP_APUT_OBJECT /*vAA, vBB, vCC*/)
         arrayInfo = FETCH(1);
         vsrc1 = arrayInfo & 0xff;   /* BB: array ptr */
         vsrc2 = arrayInfo >> 8;     /* CC: index */
-        ILOGV("|aput%s v%d,v%d,v%d", "-object", vdst, vsrc1, vsrc2);
+        ALOGV("|aput%s v%d,v%d,v%d", "-object", vdst, vsrc1, vsrc2);
         arrayObj = (ArrayObject*) GET_REGISTER(vsrc1);
         if (!checkForNull((Object*) arrayObj))
             GOTO_exceptionThrown();
@@ -2049,6 +2438,11 @@ HANDLE_OPCODE(OP_APUT_OBJECT /*vAA, vBB, vCC*/)
         dvmSetObjectArrayElement(arrayObj,
                                  GET_REGISTER(vsrc2),
                                  (Object *)GET_REGISTER(vdst));
+/* ifdef WITH_TAINT_TRACKING */
+	SET_ARRAY_TAINT(arrayObj,
+		(GET_ARRAY_TAINT(arrayObj) |
+		 GET_REGISTER_TAINT(vdst)) );
+/* endif */
     }
     FINISH(2);
 OP_END
@@ -2457,6 +2851,12 @@ HANDLE_OPCODE(OP_REM_FLOAT /*vAA, vBB, vCC*/)
         ILOGV("|%s-float v%d,v%d,v%d", "mod", vdst, vsrc1, vsrc2);
         SET_REGISTER_FLOAT(vdst,
             fmodf(GET_REGISTER_FLOAT(vsrc1), GET_REGISTER_FLOAT(vsrc2)));
+/* ifdef WITH_TAINT_TRACKING */
+#ifdef WITH_TAINT_TRACKING
+        SET_REGISTER_TAINT_FLOAT(vdst,
+	    (GET_REGISTER_TAINT_FLOAT(vsrc1)|GET_REGISTER_TAINT_FLOAT(vsrc2)));
+#endif /*WITH_TAINT_TRACKING*/
+/* endif */
     }
     FINISH(2);
 OP_END
@@ -2488,6 +2888,10 @@ HANDLE_OPCODE(OP_REM_DOUBLE /*vAA, vBB, vCC*/)
         ILOGV("|%s-double v%d,v%d,v%d", "mod", vdst, vsrc1, vsrc2);
         SET_REGISTER_DOUBLE(vdst,
             fmod(GET_REGISTER_DOUBLE(vsrc1), GET_REGISTER_DOUBLE(vsrc2)));
+/* ifdef WITH_TAINT_TRACKING */
+        SET_REGISTER_TAINT_DOUBLE(vdst,
+	    (GET_REGISTER_TAINT_DOUBLE(vsrc1)|GET_REGISTER_TAINT_DOUBLE(vsrc2)));
+/* endif */
     }
     FINISH(2);
 OP_END
@@ -2603,6 +3007,12 @@ HANDLE_OPCODE(OP_REM_FLOAT_2ADDR /*vA, vB*/)
     ILOGV("|%s-float-2addr v%d,v%d", "mod", vdst, vsrc1);
     SET_REGISTER_FLOAT(vdst,
         fmodf(GET_REGISTER_FLOAT(vdst), GET_REGISTER_FLOAT(vsrc1)));
+/* ifdef WITH_TAINT_TRACKING */
+#ifdef WITH_TAINT_TRACKING
+        SET_REGISTER_TAINT_FLOAT(vdst,
+	    (GET_REGISTER_TAINT_FLOAT(vdst)|GET_REGISTER_TAINT_FLOAT(vsrc1)));
+#endif /*WITH_TAINT_TRACKING*/
+/* endif */
     FINISH(1);
 OP_END
 
@@ -2629,6 +3039,10 @@ HANDLE_OPCODE(OP_REM_DOUBLE_2ADDR /*vA, vB*/)
     ILOGV("|%s-double-2addr v%d,v%d", "mod", vdst, vsrc1);
     SET_REGISTER_DOUBLE(vdst,
         fmod(GET_REGISTER_DOUBLE(vdst), GET_REGISTER_DOUBLE(vsrc1)));
+/* ifdef WITH_TAINT_TRACKING */
+        SET_REGISTER_TAINT_DOUBLE(vdst,
+	    (GET_REGISTER_TAINT_DOUBLE(vdst)|GET_REGISTER_TAINT_DOUBLE(vsrc1)));
+/* endif */
     FINISH(1);
 OP_END
 
@@ -2644,6 +3058,9 @@ HANDLE_OPCODE(OP_RSUB_INT /*vA, vB, #+CCCC*/)
         vsrc2 = FETCH(1);
         ILOGV("|rsub-int v%d,v%d,#+0x%04x", vdst, vsrc1, vsrc2);
         SET_REGISTER(vdst, (s2) vsrc2 - (s4) GET_REGISTER(vsrc1));
+/* ifdef WITH_TAINT_TRACKING */
+        SET_REGISTER_TAINT(vdst, GET_REGISTER_TAINT(vsrc1));
+/* endif */
     }
     FINISH(2);
 OP_END
@@ -2686,6 +3103,9 @@ HANDLE_OPCODE(OP_RSUB_INT_LIT8 /*vAA, vBB, #+CC*/)
         vsrc2 = litInfo >> 8;
         ILOGV("|%s-int/lit8 v%d,v%d,#+0x%02x", "rsub", vdst, vsrc1, vsrc2);
         SET_REGISTER(vdst, (s1) vsrc2 - (s4) GET_REGISTER(vsrc1));
+/* ifdef WITH_TAINT_TRACKING */
+        SET_REGISTER_TAINT(vdst, GET_REGISTER_TAINT(vsrc1));
+/* endif */
     }
     FINISH(2);
 OP_END
@@ -2819,6 +3239,11 @@ HANDLE_OPCODE(OP_EXECUTE_INLINE /*vB, {vD, vE, vF, vG}, inline@CCCC*/)
         u4 arg0, arg1, arg2, arg3;
         arg0 = arg1 = arg2 = arg3 = 0;
 
+#ifdef WITH_TAINT_TRACKING
+	u4 arg0_taint, arg1_taint;
+	arg0_taint = arg1_taint = 0;
+#endif /*WITH_TAINT_TRACKING*/
+
         EXPORT_PC();
 
         vsrc1 = INST_B(inst);       /* #of args */
@@ -2839,20 +3264,36 @@ HANDLE_OPCODE(OP_EXECUTE_INLINE /*vB, {vD, vE, vF, vG}, inline@CCCC*/)
             /* fall through */
         case 2:
             arg1 = GET_REGISTER((vdst & 0x00f0) >> 4);
+#ifdef WITH_TAINT_TRACKING
+	    arg1_taint = GET_REGISTER_TAINT((vdst & 0x00f0) >> 4);
+#endif /*WITH_TAINT_TRACKING*/
             /* fall through */
         case 1:
             arg0 = GET_REGISTER(vdst & 0x0f);
+#ifdef WITH_TAINT_TRACKING
+            arg0_taint = GET_REGISTER_TAINT(vdst & 0x0f);
+#endif /*WITH_TAINT_TRACKING*/
             /* fall through */
         default:        // case 0
             ;
         }
 
         if (self->interpBreak.ctl.subMode & kSubModeDebuggerActive) {
+#ifdef WITH_TAINT_TRACKING
+            if (!dvmPerformInlineOp4Dbg(arg0, arg1, arg2, arg3, arg0_taint, arg1_taint, &rtaint, &retval, ref))
+                GOTO_exceptionThrown();
+#else
             if (!dvmPerformInlineOp4Dbg(arg0, arg1, arg2, arg3, &retval, ref))
                 GOTO_exceptionThrown();
+#endif /*WITH_TAINT_TRACKING*/
         } else {
+#ifdef WITH_TAINT_TRACKING
+            if (!dvmPerformInlineOp4Std(arg0, arg1, arg2, arg3, arg0_taint, arg1_taint, &rtaint, &retval, ref))
+                GOTO_exceptionThrown();
+#else
             if (!dvmPerformInlineOp4Std(arg0, arg1, arg2, arg3, &retval, ref))
                 GOTO_exceptionThrown();
+#endif /*WITH_TAINT_TRACKING*/
         }
     }
     FINISH(3);
@@ -2864,6 +3305,11 @@ HANDLE_OPCODE(OP_EXECUTE_INLINE_RANGE /*{vCCCC..v(CCCC+AA-1)}, inline@BBBB*/)
         u4 arg0, arg1, arg2, arg3;
         arg0 = arg1 = arg2 = arg3 = 0;      /* placate gcc */
 
+#ifdef WITH_TAINT_TRACKING
+	u4 arg0_taint, arg1_taint;
+	arg0_taint = arg1_taint = 0;
+#endif /*WITH_TAINT_TRACKING*/
+
         EXPORT_PC();
 
         vsrc1 = INST_AA(inst);      /* #of args */
@@ -2884,20 +3330,36 @@ HANDLE_OPCODE(OP_EXECUTE_INLINE_RANGE /*{vCCCC..v(CCCC+AA-1)}, inline@BBBB*/)
             /* fall through */
         case 2:
             arg1 = GET_REGISTER(vdst+1);
+#ifdef WITH_TAINT_TRACKING
+	    arg1_taint = GET_REGISTER_TAINT(vdst+1);
+#endif /*WITH_TAINT_TRACKING*/
             /* fall through */
         case 1:
             arg0 = GET_REGISTER(vdst+0);
+#ifdef WITH_TAINT_TRACKING
+            arg0_taint = GET_REGISTER_TAINT(vdst+0);
+#endif /*WITH_TAINT_TRACKING*/
             /* fall through */
         default:        // case 0
             ;
         }
 
         if (self->interpBreak.ctl.subMode & kSubModeDebuggerActive) {
+#ifdef WITH_TAINT_TRACKING
+            if (!dvmPerformInlineOp4Dbg(arg0, arg1, arg2, arg3, arg0_taint, arg1_taint, &rtaint, &retval, ref))
+                GOTO_exceptionThrown();
+#else
             if (!dvmPerformInlineOp4Dbg(arg0, arg1, arg2, arg3, &retval, ref))
                 GOTO_exceptionThrown();
+#endif /*WITH_TAINT_TRACKING*/
         } else {
+#ifdef WITH_TAINT_TRACKING
+            if (!dvmPerformInlineOp4Std(arg0, arg1, arg2, arg3, arg0_taint, arg1_taint, &rtaint, &retval, ref))
+                GOTO_exceptionThrown();
+#else
             if (!dvmPerformInlineOp4Std(arg0, arg1, arg2, arg3, &retval, ref))
                 GOTO_exceptionThrown();
+#endif /*WITH_TAINT_TRACKING*/
         }
     }
     FINISH(3);
@@ -2940,6 +3402,9 @@ HANDLE_OPCODE(OP_RETURN_VOID_BARRIER /**/)
 #ifndef NDEBUG
     retval.j = 0xababababULL;   /* placate valgrind */
 #endif
+/* ifdef WITH_TAINT_TRACKING */
+    SET_RETURN_TAINT(TAINT_CLEAR);
+/* endif */
     ANDROID_MEMBAR_STORE();
     GOTO_returnFromMethod();
 OP_END
@@ -3174,6 +3639,9 @@ GOTO_TARGET(filledNewArray, bool methodCallRange, bool)
         }
 
         retval.l = (Object*)newArray;
+/* ifdef WITH_TAINT_TRACKING */
+        SET_RETURN_TAINT(TAINT_CLEAR);
+/* endif */
     }
     FINISH(3);
 GOTO_TARGET_END
@@ -3843,6 +4311,9 @@ GOTO_TARGET(invokeMethod, bool methodCallRange, const Method* _methodToCall,
 
         u4* outs;
         int i;
+#ifdef WITH_TAINT_TRACKING
+        bool nativeTarget = dvmIsNativeMethod(methodToCall);
+#endif
 
         /*
          * Copy args.  This may corrupt vsrc1/vdst.
@@ -3853,8 +4324,31 @@ GOTO_TARGET(invokeMethod, bool methodCallRange, const Method* _methodToCall,
             assert(vsrc1 <= curMethod->outsSize);
             assert(vsrc1 == methodToCall->insSize);
             outs = OUTS_FROM_FP(fp, vsrc1);
+#ifdef WITH_TAINT_TRACKING
+            if (nativeTarget) {
+            	for (i = 0; i < vsrc1; i++) {
+            		outs[i] = GET_REGISTER(vdst+i);
+            	}
+            	/* clear return taint (vsrc1 is the count) */
+            	outs[vsrc1] = TAINT_CLEAR;
+            	/* copy the taint tags (vsrc1 is the count) */
+            	for (i = 0; i < vsrc1; i++) {
+            		outs[vsrc1+1+i] = GET_REGISTER_TAINT(vdst+i);
+            	}
+            } else {
+            	int slot = 0;
+            	for (i = 0; i < vsrc1; i++) {
+            		slot = i << 1;
+            		outs[slot] = GET_REGISTER(vdst+i);
+            		outs[slot+1] = GET_REGISTER_TAINT(vdst+i);
+            	}
+            	/* clear native hack (vsrc1 is the count)*/
+            	outs[vsrc1<<1] = TAINT_CLEAR;
+            }
+#else
             for (i = 0; i < vsrc1; i++)
                 outs[i] = GET_REGISTER(vdst+i);
+#endif
         } else {
             u4 count = vsrc1 >> 4;
 
@@ -3876,6 +4370,53 @@ GOTO_TARGET(invokeMethod, bool methodCallRange, const Method* _methodToCall,
             // This version executes fewer instructions but is larger
             // overall.  Seems to be a teensy bit faster.
             assert((vdst >> 16) == 0);  // 16 bits -or- high 16 bits clear
+#ifdef WITH_TAINT_TRACKING
+            if (nativeTarget) {
+            	switch (count) {
+            	case 5:
+            		outs[4] = GET_REGISTER(vsrc1 & 0x0f);
+            		outs[count+5] = GET_REGISTER_TAINT(vsrc1 & 0x0f);
+            	case 4:
+            		outs[3] = GET_REGISTER(vdst >> 12);
+            		outs[count+4] = GET_REGISTER_TAINT(vdst >> 12);
+            	case 3:
+            		outs[2] = GET_REGISTER((vdst & 0x0f00) >> 8);
+            		outs[count+3] = GET_REGISTER_TAINT((vdst & 0x0f00) >> 8);
+            	case 2:
+            		outs[1] = GET_REGISTER((vdst & 0x00f0) >> 4);
+            		outs[count+2] = GET_REGISTER_TAINT((vdst & 0x00f0) >> 4);
+            	case 1:
+            		outs[0] = GET_REGISTER(vdst & 0x0f);
+            		outs[count+1] = GET_REGISTER_TAINT(vdst & 0x0f);
+            	default:
+            		;
+            	}
+            	/* clear the native hack */
+            	outs[count] = TAINT_CLEAR;
+            } else { /* interpreted target */
+            	switch (count) {
+            	case 5:
+            		outs[8] = GET_REGISTER(vsrc1 & 0x0f);
+            		outs[9] = GET_REGISTER_TAINT(vsrc1 & 0x0f);
+            	case 4:
+            		outs[6] = GET_REGISTER(vdst >> 12);
+            		outs[7] = GET_REGISTER_TAINT(vdst >> 12);
+            	case 3:
+            		outs[4] = GET_REGISTER((vdst & 0x0f00) >> 8);
+            		outs[5] = GET_REGISTER_TAINT((vdst & 0x0f00) >> 8);
+            	case 2:
+            		outs[2] = GET_REGISTER((vdst & 0x00f0) >> 4);
+            		outs[3] = GET_REGISTER_TAINT((vdst & 0x00f0) >> 4);
+            	case 1:
+            		outs[0] = GET_REGISTER(vdst & 0x0f);
+            		outs[1] = GET_REGISTER_TAINT(vdst & 0x0f);
+           	default:
+            		;
+              	}
+            	/* clear the native hack */
+            	outs[count<<1] = TAINT_CLEAR;
+            }
+#else /* ndef WITH_TAINT_TRACKING */
             switch (count) {
             case 5:
                 outs[4] = GET_REGISTER(vsrc1 & 0x0f);
@@ -3890,6 +4431,7 @@ GOTO_TARGET(invokeMethod, bool methodCallRange, const Method* _methodToCall,
             default:
                 ;
             }
+#endif /* WITH_TAINT_TRACKING */
 #endif
         }
     }
@@ -3911,13 +4453,23 @@ GOTO_TARGET(invokeMethod, bool methodCallRange, const Method* _methodToCall,
             methodToCall->clazz->descriptor, methodToCall->name,
             methodToCall->shorty);
 
+#ifdef WITH_TAINT_TRACKING
+        newFp = (u4*) SAVEAREA_FROM_FP(fp) -
+	    ((methodToCall->registersSize << 1) + 1);
+#else
         newFp = (u4*) SAVEAREA_FROM_FP(fp) - methodToCall->registersSize;
+#endif
         newSaveArea = SAVEAREA_FROM_FP(newFp);
 
         /* verify that we have enough space */
         if (true) {
             u1* bottom;
+#ifdef WITH_TAINT_TRACKING
+            bottom = (u1*) newSaveArea -
+            		(methodToCall->outsSize * sizeof(u4) + 4);
+#else
             bottom = (u1*) newSaveArea - methodToCall->outsSize * sizeof(u4);
+#endif
             if (bottom < self->interpStackEnd) {
                 /* stack overflow */
                 ALOGV("Stack overflow on method call (start=%p end=%p newBot=%p(%d) size=%d '%s')",
@@ -3940,8 +4492,15 @@ GOTO_TARGET(invokeMethod, bool methodCallRange, const Method* _methodToCall,
              * messages are disabled -- we want valgrind to report any
              * used-before-initialized issues.
              */
+#ifdef WITH_TAINT_TRACKING
+	    /* Don't need to worry about native target, because if
+	     * native target, registerSize = insSize */
+            memset(newFp, 0xcc,
+                (methodToCall->registersSize - methodToCall->insSize) * 8);
+#else
             memset(newFp, 0xcc,
                 (methodToCall->registersSize - methodToCall->insSize) * 4);
+#endif
         }
 #endif
 
@@ -4006,6 +4565,16 @@ GOTO_TARGET(invokeMethod, bool methodCallRange, const Method* _methodToCall,
              */
             (*methodToCall->nativeFunc)(newFp, &retval, methodToCall, self);
 
+#ifdef WITH_TAINT_TRACKING
+            /* Get the return taint if available */
+            {
+            	/* use same logic as above to calculate count */
+            	u4 count = (methodCallRange) ? vsrc1 : vsrc1 >> 4;
+            	u4* outs = OUTS_FROM_FP(fp, count);
+            	SET_RETURN_TAINT(outs[count]);
+            }
+#endif
+
             if (self->interpBreak.ctl.subMode != 0) {
                 dvmReportPostNativeInvoke(methodToCall, self, fp);
             }
@@ -4056,3 +4625,8 @@ GOTO_TARGET_END
 #undef self
 #undef debugTrackedRefStart
 
+#ifdef WITH_TAINT_TRACKING
+#undef rtaint
+#endif
+
+
diff --git a/vm/mterp/out/InterpC-armv5te-vfp.cpp b/vm/mterp/out/InterpC-armv5te-vfp.cpp
index dde9463..655bf0d 100644
--- a/vm/mterp/out/InterpC-armv5te-vfp.cpp
+++ b/vm/mterp/out/InterpC-armv5te-vfp.cpp
@@ -143,6 +143,31 @@ static const char kSpacing[] = "            ";
 # define DUMP_REGS(_meth, _frame, _inOnly) ((void)0)
 #endif
 
+/*
+ * If enabled, log taint propagation
+ */
+#ifdef WITH_TAINT_TRACKING
+# define TLOGD(...) TLOG(LOG_DEBUG, __VA_ARGS__)
+# define TLOGV(...) TLOG(LOG_VERBOSE, __VA_ARGS__)
+# define TLOGW(...) TLOG(LOG_WARN, __VA_ARGS__)
+# define TLOGE(...) TLOG(LOG_ERROR, __VA_ARGS__)
+# define TLOG(_level, ...) do {                                             \
+        char debugStrBuf[128];                                              \
+        snprintf(debugStrBuf, sizeof(debugStrBuf), __VA_ARGS__);            \
+        if (curMethod != NULL)                                              \
+            ALOG(_level, LOG_TAG"t", "%-2d|%04x|%s.%s:%s\n",                \
+                self->threadId, (int)(pc - curMethod->insns), curMethod->clazz->descriptor, curMethod->name, debugStrBuf); \
+        else                                                                \
+            ALOG(_level, LOG_TAG"t", "%-2d|####%s\n",                       \
+                self->threadId, debugStrBuf);                               \
+    } while(false)
+#else
+# define TLOGD(...) ((void)0)
+# define TLOGV(...) ((void)0)
+# define TLOGW(...) ((void)0)
+# define TLOGE(...) ((void)0)
+#endif
+
 /* get a long from an array of u4 */
 static inline s8 getLongFromArray(const u4* ptr, int idx)
 {
@@ -160,6 +185,20 @@ static inline s8 getLongFromArray(const u4* ptr, int idx)
 #endif
 }
 
+#ifdef WITH_TAINT_TRACKING
+/* get a long from an array of u4 */
+static inline s8 getLongFromArrayTaint(const u4* ptr, int idx)
+{
+    /* Need to use the "union" version for taint tracking */
+    union { s8 ll; u4 parts[2]; } conv;
+
+    ptr += idx;
+    conv.parts[0] = ptr[0];
+    conv.parts[1] = ptr[2];
+    return conv.ll;
+}
+#endif
+
 /* store a long into an array of u4 */
 static inline void putLongToArray(u4* ptr, int idx, s8 val)
 {
@@ -175,6 +214,20 @@ static inline void putLongToArray(u4* ptr, int idx, s8 val)
 #endif
 }
 
+#ifdef WITH_TAINT_TRACKING
+/* store a long into an array of u4 */
+static inline void putLongToArrayTaint(u4* ptr, int idx, s8 val)
+{
+    /* Need to use the "union" version for taint tracking */
+    union { s8 ll; u4 parts[2]; } conv;
+
+    ptr += idx;
+    conv.ll = val;
+    ptr[0] = conv.parts[0];
+    ptr[2] = conv.parts[1];
+}
+#endif
+
 /* get a double from an array of u4 */
 static inline double getDoubleFromArray(const u4* ptr, int idx)
 {
@@ -192,6 +245,20 @@ static inline double getDoubleFromArray(const u4* ptr, int idx)
 #endif
 }
 
+#ifdef WITH_TAINT_TRACKING
+/* get a double from an array of u4 */
+static inline double getDoubleFromArrayTaint(const u4* ptr, int idx)
+{
+    /* Need to use the "union" version for taint tracking */
+    union { double d; u4 parts[2]; } conv;
+
+    ptr += idx;
+    conv.parts[0] = ptr[0];
+    conv.parts[1] = ptr[2];
+    return conv.d;
+}
+#endif
+
 /* store a double into an array of u4 */
 static inline void putDoubleToArray(u4* ptr, int idx, double dval)
 {
@@ -207,6 +274,20 @@ static inline void putDoubleToArray(u4* ptr, int idx, double dval)
 #endif
 }
 
+#ifdef WITH_TAINT_TRACKING
+/* store a double into an array of u4 */
+static inline void putDoubleToArrayTaint(u4* ptr, int idx, double dval)
+{
+    /* Need to use the "union" version for taint tracking */
+    union { double d; u4 parts[2]; } conv;
+
+    ptr += idx;
+    conv.d = dval;
+    ptr[0] = conv.parts[0];
+    ptr[2] = conv.parts[1];
+}
+#endif
+
 /*
  * If enabled, validate the register number on every access.  Otherwise,
  * just do an array access.
@@ -215,6 +296,55 @@ static inline void putDoubleToArray(u4* ptr, int idx, double dval)
  *
  * "_idx" may be referenced more than once.
  */
+#ifdef WITH_TAINT_TRACKING
+/* -- Begin Taint Tracking version ------------------------------- */
+/* Taint tags are interleaved between registers. All indexes must
+ * be multiplied by 2 (i.e., left bit shift by 1) */
+#ifdef CHECK_REGISTER_INDICES
+# define GET_REGISTER(_idx) \
+    ( (_idx) < curMethod->registersSize ? \
+        (fp[(_idx)<<1]) : (assert(!"bad reg"),1969) )
+# define SET_REGISTER(_idx, _val) \
+    ( (_idx) < curMethod->registersSize ? \
+        (fp[(_idx)<<1] = (u4)(_val)) : (assert(!"bad reg"),1969) )
+# define GET_REGISTER_AS_OBJECT(_idx)       ((Object *)GET_REGISTER(_idx))
+# define SET_REGISTER_AS_OBJECT(_idx, _val) SET_REGISTER(_idx, (s4)_val)
+# define GET_REGISTER_INT(_idx) ((s4) GET_REGISTER(_idx))
+# define SET_REGISTER_INT(_idx, _val) SET_REGISTER(_idx, (s4)_val)
+# define GET_REGISTER_WIDE(_idx) \
+    ( (_idx) < curMethod->registersSize-1 ? \
+        getLongFromArrayTaint(fp, ((_idx)<<1)) : (assert(!"bad reg"),1969) )
+# define SET_REGISTER_WIDE(_idx, _val) \
+    ( (_idx) < curMethod->registersSize-1 ? \
+        putLongToArrayTaint(fp, ((_idx)<<1), (_val)) : (assert(!"bad reg"),1969) )
+# define GET_REGISTER_FLOAT(_idx) \
+    ( (_idx) < curMethod->registersSize ? \
+        (*((float*) &fp[(_idx)<<1])) : (assert(!"bad reg"),1969.0f) )
+# define SET_REGISTER_FLOAT(_idx, _val) \
+    ( (_idx) < curMethod->registersSize ? \
+        (*((float*) &fp[(_idx)<<1]) = (_val)) : (assert(!"bad reg"),1969.0f) )
+# define GET_REGISTER_DOUBLE(_idx) \
+    ( (_idx) < curMethod->registersSize-1 ? \
+        getDoubleFromArrayTaint(fp, ((_idx)<<1)) : (assert(!"bad reg"),1969.0) )
+# define SET_REGISTER_DOUBLE(_idx, _val) \
+    ( (_idx) < curMethod->registersSize-1 ? \
+        putDoubleToArrayTaint(fp, ((_idx)<<1), (_val)) : (assert(!"bad reg"),1969.0) )
+#else
+# define GET_REGISTER(_idx)                 (fp[(_idx)<<1])
+# define SET_REGISTER(_idx, _val)           (fp[(_idx)<<1] = (_val))
+# define GET_REGISTER_AS_OBJECT(_idx)       ((Object*) fp[(_idx)<<1])
+# define SET_REGISTER_AS_OBJECT(_idx, _val) (fp[(_idx)<<1] = (u4)(_val))
+# define GET_REGISTER_INT(_idx)             ((s4)GET_REGISTER(_idx))
+# define SET_REGISTER_INT(_idx, _val)       SET_REGISTER(_idx, (s4)_val)
+# define GET_REGISTER_WIDE(_idx)            getLongFromArrayTaint(fp, ((_idx)<<1))
+# define SET_REGISTER_WIDE(_idx, _val)      putLongToArrayTaint(fp, ((_idx)<<1), (_val))
+# define GET_REGISTER_FLOAT(_idx)           (*((float*) &fp[(_idx)<<1]))
+# define SET_REGISTER_FLOAT(_idx, _val)     (*((float*) &fp[(_idx)<<1]) = (_val))
+# define GET_REGISTER_DOUBLE(_idx)          getDoubleFromArrayTaint(fp, ((_idx)<<1))
+# define SET_REGISTER_DOUBLE(_idx, _val)    putDoubleToArrayTaint(fp, ((_idx)<<1), (_val))
+#endif
+/* -- End Taint Tracking version ---------------------------------- */
+#else /* no taint tracking */
 #ifdef CHECK_REGISTER_INDICES
 # define GET_REGISTER(_idx) \
     ( (_idx) < curMethod->registersSize ? \
@@ -258,6 +388,48 @@ static inline void putDoubleToArray(u4* ptr, int idx, double dval)
 # define GET_REGISTER_DOUBLE(_idx)          getDoubleFromArray(fp, (_idx))
 # define SET_REGISTER_DOUBLE(_idx, _val)    putDoubleToArray(fp, (_idx), (_val))
 #endif
+#endif /* end no taint tracking */
+
+#ifdef WITH_TAINT_TRACKING
+/* Core get and set macros */
+# define GET_REGISTER_TAINT(_idx)	     (fp[((_idx)<<1)+1])
+# define SET_REGISTER_TAINT(_idx, _val)	     (fp[((_idx)<<1)+1] = (u4)(_val))
+# define GET_REGISTER_TAINT_WIDE(_idx)       (fp[((_idx)<<1)+1])
+# define SET_REGISTER_TAINT_WIDE(_idx, _val) (fp[((_idx)<<1)+1] = \
+	                                      fp[((_idx)<<1)+3] = (u4)(_val))
+/* Alternate interfaces to help dereference register width */
+# define GET_REGISTER_TAINT_INT(_idx)	          GET_REGISTER_TAINT(_idx)
+# define SET_REGISTER_TAINT_INT(_idx, _val)       SET_REGISTER_TAINT(_idx, _val)
+# define GET_REGISTER_TAINT_FLOAT(_idx)	          GET_REGISTER_TAINT(_idx)
+# define SET_REGISTER_TAINT_FLOAT(_idx, _val)     SET_REGISTER_TAINT(_idx, _val)
+# define GET_REGISTER_TAINT_DOUBLE(_idx)          GET_REGISTER_TAINT_WIDE(_idx)
+# define SET_REGISTER_TAINT_DOUBLE(_idx, _val)    SET_REGISTER_TAINT_WIDE(_idx, _val)
+# define GET_REGISTER_TAINT_AS_OBJECT(_idx)       GET_REGISTER_TAINT(_idx)
+# define SET_REGISTER_TAINT_AS_OBJECT(_idx, _val) SET_REGISTER_TAINT(_idx, _val)
+
+/* Object Taint interface */
+# define GET_ARRAY_TAINT(_arr)		      ((_arr)->taint.tag)
+# define SET_ARRAY_TAINT(_arr, _val)	      ((_arr)->taint.tag = (u4)(_val))
+
+/* Return value taint (assumes rtaint variable is in scope */
+# define GET_RETURN_TAINT()		      (rtaint.tag)
+# define SET_RETURN_TAINT(_val)		      (rtaint.tag = (u4)(_val))
+#else
+# define GET_REGISTER_TAINT(_idx)		    ((void)0)
+# define SET_REGISTER_TAINT(_idx, _val)		    ((void)0)
+# define GET_REGISTER_TAINT_WIDE(_idx)		    ((void)0)
+# define SET_REGISTER_TAINT_WIDE(_idx, _val)	    ((void)0)
+# define GET_REGISTER_TAINT_INT(_idx)		    ((void)0)
+# define SET_REGISTER_TAINT_INT(_idx, _val)	    ((void)0)
+# define GET_REGISTER_TAINT_DOUBLE(_idx)	    ((void)0)
+# define SET_REGISTER_TAINT_DOUBLE(_idx, _val)	    ((void)0)
+# define GET_REGISTER_TAINT_AS_OBJECT(_idx)	    ((void)0)
+# define SET_REGISTER_TAINT_AS_OBJECT(_idx, _val)   ((void)0)
+# define GET_ARRAY_TAINT(_field)                    ((void)0)
+# define SET_ARRAY_TAINT(_field, _val)              ((void)0)
+# define GET_RETURN_TAINT()			    ((void)0)
+# define SET_RETURN_TAINT(_val)			    ((void)0)
+#endif
 
 /*
  * Get 16 bits from the specified offset of the program counter.  We always
@@ -399,6 +571,10 @@ static inline bool checkForNullExportPC(Object* obj, u4* fp, const u2* pc)
 #define methodClassDex          self->interpSave.methodClassDex
 #define debugTrackedRefStart    self->interpSave.debugTrackedRefStart
 
+#ifdef WITH_TAINT_TRACKING
+#define rtaint			self->interpSave.rtaint
+#endif
+
 /* ugh */
 #define STUB_HACK(x) x
 #if defined(WITH_JIT)
@@ -537,6 +713,10 @@ GOTO_TARGET_DECL(exceptionThrown);
         ILOGV("|%s v%d,v%d", (_opname), vdst, vsrc1);                       \
         SET_REGISTER##_totype(vdst,                                         \
             GET_REGISTER##_fromtype(vsrc1));                                \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT##_totype(vdst,                                   \
+	    GET_REGISTER_TAINT##_fromtype(vsrc1));                          \
+/* endif */                                                                 \
         FINISH(1);
 
 #define HANDLE_FLOAT_TO_INT(_opcode, _opname, _fromvtype, _fromrtype,       \
@@ -562,6 +742,10 @@ GOTO_TARGET_DECL(exceptionThrown);
         else                                                                \
             result = (_tovtype) val;                                        \
         SET_REGISTER##_tortype(vdst, result);                               \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT##_tortype(vdst,                                  \
+	    GET_REGISTER_TAINT##_fromrtype(vsrc1));                         \
+/* endif */                                                                 \
     }                                                                       \
     FINISH(1);
 
@@ -571,6 +755,9 @@ GOTO_TARGET_DECL(exceptionThrown);
         vsrc1 = INST_B(inst);                                               \
         ILOGV("|int-to-%s v%d,v%d", (_opname), vdst, vsrc1);                \
         SET_REGISTER(vdst, (_type) GET_REGISTER(vsrc1));                    \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT(vdst, GET_REGISTER_TAINT(vsrc1));                \
+/* endif */                                                                 \
         FINISH(1);
 
 /* NOTE: the comparison result is always a signed 4-byte integer */
@@ -597,6 +784,9 @@ GOTO_TARGET_DECL(exceptionThrown);
             result = (_nanVal);                                             \
         ILOGV("+ result=%d", result);                                       \
         SET_REGISTER(vdst, result);                                         \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT(vdst, TAINT_CLEAR);				    \
+/* endif */                                                                 \
     }                                                                       \
     FINISH(2);
 
@@ -638,6 +828,9 @@ GOTO_TARGET_DECL(exceptionThrown);
         vsrc1 = INST_B(inst);                                               \
         ILOGV("|%s v%d,v%d", (_opname), vdst, vsrc1);                       \
         SET_REGISTER##_type(vdst, _pfx GET_REGISTER##_type(vsrc1) _sfx);    \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT##_type(vdst, GET_REGISTER_TAINT##_type(vsrc1));  \
+/* endif */                                                                 \
         FINISH(1);
 
 #define HANDLE_OP_X_INT(_opcode, _opname, _op, _chkdiv)                     \
@@ -672,6 +865,10 @@ GOTO_TARGET_DECL(exceptionThrown);
             SET_REGISTER(vdst,                                              \
                 (s4) GET_REGISTER(vsrc1) _op (s4) GET_REGISTER(vsrc2));     \
         }                                                                   \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT(vdst,                                            \
+	    (GET_REGISTER_TAINT(vsrc1)|GET_REGISTER_TAINT(vsrc2)) );        \
+/* endif */                                                                 \
     }                                                                       \
     FINISH(2);
 
@@ -686,6 +883,10 @@ GOTO_TARGET_DECL(exceptionThrown);
         ILOGV("|%s-int v%d,v%d", (_opname), vdst, vsrc1);                   \
         SET_REGISTER(vdst,                                                  \
             _cast GET_REGISTER(vsrc1) _op (GET_REGISTER(vsrc2) & 0x1f));    \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT(vdst,                                            \
+	    (GET_REGISTER_TAINT(vsrc1)|GET_REGISTER_TAINT(vsrc2)) );        \
+/* endif */                                                                 \
     }                                                                       \
     FINISH(2);
 
@@ -702,7 +903,7 @@ GOTO_TARGET_DECL(exceptionThrown);
             if ((s2) vsrc2 == 0) {                                          \
                 EXPORT_PC();                                                \
                 dvmThrowArithmeticException("divide by zero");              \
-                GOTO_exceptionThrown();                                     \
+                GOTO_exceptionThrown();                                      \
             }                                                               \
             if ((u4)firstVal == 0x80000000 && ((s2) vsrc2) == -1) {         \
                 /* won't generate /lit16 instr for this; check anyway */    \
@@ -718,6 +919,9 @@ GOTO_TARGET_DECL(exceptionThrown);
             /* non-div/rem case */                                          \
             SET_REGISTER(vdst, GET_REGISTER(vsrc1) _op (s2) vsrc2);         \
         }                                                                   \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT(vdst, GET_REGISTER_TAINT(vsrc1));                \
+/* endif */                                                                 \
         FINISH(2);
 
 #define HANDLE_OP_X_INT_LIT8(_opcode, _opname, _op, _chkdiv)                \
@@ -751,6 +955,9 @@ GOTO_TARGET_DECL(exceptionThrown);
             SET_REGISTER(vdst,                                              \
                 (s4) GET_REGISTER(vsrc1) _op (s1) vsrc2);                   \
         }                                                                   \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT(vdst, GET_REGISTER_TAINT(vsrc1));                \
+/* endif */                                                                 \
     }                                                                       \
     FINISH(2);
 
@@ -766,6 +973,9 @@ GOTO_TARGET_DECL(exceptionThrown);
             (_opname), vdst, vsrc1, vsrc2);                                 \
         SET_REGISTER(vdst,                                                  \
             _cast GET_REGISTER(vsrc1) _op (vsrc2 & 0x1f));                  \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT(vdst, GET_REGISTER_TAINT(vsrc1));                \
+/* endif */                                                                 \
     }                                                                       \
     FINISH(2);
 
@@ -796,6 +1006,10 @@ GOTO_TARGET_DECL(exceptionThrown);
             SET_REGISTER(vdst,                                              \
                 (s4) GET_REGISTER(vdst) _op (s4) GET_REGISTER(vsrc1));      \
         }                                                                   \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT(vdst,                                            \
+	    (GET_REGISTER_TAINT(vdst)|GET_REGISTER_TAINT(vsrc1)) );         \
+/* endif */                                                                 \
         FINISH(1);
 
 #define HANDLE_OP_SHX_INT_2ADDR(_opcode, _opname, _cast, _op)               \
@@ -805,6 +1019,10 @@ GOTO_TARGET_DECL(exceptionThrown);
         ILOGV("|%s-int-2addr v%d,v%d", (_opname), vdst, vsrc1);             \
         SET_REGISTER(vdst,                                                  \
             _cast GET_REGISTER(vdst) _op (GET_REGISTER(vsrc1) & 0x1f));     \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT(vdst,                                            \
+	    (GET_REGISTER_TAINT(vdst)|GET_REGISTER_TAINT(vsrc1)) );         \
+/* endif */                                                                 \
         FINISH(1);
 
 #define HANDLE_OP_X_LONG(_opcode, _opname, _op, _chkdiv)                    \
@@ -840,6 +1058,10 @@ GOTO_TARGET_DECL(exceptionThrown);
             SET_REGISTER_WIDE(vdst,                                         \
                 (s8) GET_REGISTER_WIDE(vsrc1) _op (s8) GET_REGISTER_WIDE(vsrc2)); \
         }                                                                   \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT_WIDE(vdst,                                       \
+	   (GET_REGISTER_TAINT_WIDE(vsrc1)|GET_REGISTER_TAINT_WIDE(vsrc2)));\
+/* endif */                                                                 \
     }                                                                       \
     FINISH(2);
 
@@ -854,6 +1076,10 @@ GOTO_TARGET_DECL(exceptionThrown);
         ILOGV("|%s-long v%d,v%d,v%d", (_opname), vdst, vsrc1, vsrc2);       \
         SET_REGISTER_WIDE(vdst,                                             \
             _cast GET_REGISTER_WIDE(vsrc1) _op (GET_REGISTER(vsrc2) & 0x3f)); \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT_WIDE(vdst,                                       \
+	   (GET_REGISTER_TAINT_WIDE(vsrc1)|GET_REGISTER_TAINT_WIDE(vsrc2)));\
+/* endif */                                                                 \
     }                                                                       \
     FINISH(2);
 
@@ -886,6 +1112,10 @@ GOTO_TARGET_DECL(exceptionThrown);
             SET_REGISTER_WIDE(vdst,                                         \
                 (s8) GET_REGISTER_WIDE(vdst) _op (s8)GET_REGISTER_WIDE(vsrc1));\
         }                                                                   \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT_WIDE(vdst,                                       \
+	    (GET_REGISTER_TAINT_WIDE(vdst)|GET_REGISTER_TAINT_WIDE(vsrc1)));\
+/* endif */                                                                 \
         FINISH(1);
 
 #define HANDLE_OP_SHX_LONG_2ADDR(_opcode, _opname, _cast, _op)              \
@@ -895,6 +1125,10 @@ GOTO_TARGET_DECL(exceptionThrown);
         ILOGV("|%s-long-2addr v%d,v%d", (_opname), vdst, vsrc1);            \
         SET_REGISTER_WIDE(vdst,                                             \
             _cast GET_REGISTER_WIDE(vdst) _op (GET_REGISTER(vsrc1) & 0x3f)); \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT_WIDE(vdst,                                       \
+	    (GET_REGISTER_TAINT_WIDE(vdst)|GET_REGISTER_TAINT_WIDE(vsrc1)));\
+/* endif */                                                                 \
         FINISH(1);
 
 #define HANDLE_OP_X_FLOAT(_opcode, _opname, _op)                            \
@@ -908,6 +1142,10 @@ GOTO_TARGET_DECL(exceptionThrown);
         ILOGV("|%s-float v%d,v%d,v%d", (_opname), vdst, vsrc1, vsrc2);      \
         SET_REGISTER_FLOAT(vdst,                                            \
             GET_REGISTER_FLOAT(vsrc1) _op GET_REGISTER_FLOAT(vsrc2));       \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT_FLOAT(vdst,                                      \
+	    (GET_REGISTER_TAINT_FLOAT(vsrc1)|GET_REGISTER_TAINT_FLOAT(vsrc2)));\
+/* endif */                                                                 \
     }                                                                       \
     FINISH(2);
 
@@ -922,6 +1160,10 @@ GOTO_TARGET_DECL(exceptionThrown);
         ILOGV("|%s-double v%d,v%d,v%d", (_opname), vdst, vsrc1, vsrc2);     \
         SET_REGISTER_DOUBLE(vdst,                                           \
             GET_REGISTER_DOUBLE(vsrc1) _op GET_REGISTER_DOUBLE(vsrc2));     \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT_DOUBLE(vdst,                                     \
+	    (GET_REGISTER_TAINT_DOUBLE(vsrc1)|GET_REGISTER_TAINT_DOUBLE(vsrc2)));\
+/* endif */                                                                 \
     }                                                                       \
     FINISH(2);
 
@@ -932,6 +1174,10 @@ GOTO_TARGET_DECL(exceptionThrown);
         ILOGV("|%s-float-2addr v%d,v%d", (_opname), vdst, vsrc1);           \
         SET_REGISTER_FLOAT(vdst,                                            \
             GET_REGISTER_FLOAT(vdst) _op GET_REGISTER_FLOAT(vsrc1));        \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT_FLOAT(vdst,                                      \
+	    (GET_REGISTER_TAINT_FLOAT(vdst)|GET_REGISTER_TAINT_FLOAT(vsrc1)));\
+/* endif */                                                                 \
         FINISH(1);
 
 #define HANDLE_OP_X_DOUBLE_2ADDR(_opcode, _opname, _op)                     \
@@ -941,6 +1187,10 @@ GOTO_TARGET_DECL(exceptionThrown);
         ILOGV("|%s-double-2addr v%d,v%d", (_opname), vdst, vsrc1);          \
         SET_REGISTER_DOUBLE(vdst,                                           \
             GET_REGISTER_DOUBLE(vdst) _op GET_REGISTER_DOUBLE(vsrc1));      \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT_DOUBLE(vdst,                                     \
+	    (GET_REGISTER_TAINT_DOUBLE(vdst)|GET_REGISTER_TAINT_DOUBLE(vsrc1)));\
+/* endif */                                                                 \
         FINISH(1);
 
 #define HANDLE_OP_AGET(_opcode, _opname, _type, _regsize)                   \
@@ -965,6 +1215,11 @@ GOTO_TARGET_DECL(exceptionThrown);
         SET_REGISTER##_regsize(vdst,                                        \
             ((_type*)(void*)arrayObj->contents)[GET_REGISTER(vsrc2)]);      \
         ILOGV("+ AGET[%d]=%#x", GET_REGISTER(vsrc2), GET_REGISTER(vdst));   \
+/* ifdef WITH_TAINT_TRACKING */						    \
+	SET_REGISTER_TAINT##_regsize(vdst,                                  \
+	    (GET_ARRAY_TAINT(arrayObj)|GET_REGISTER_TAINT(vsrc2)));         \
+/* endif */								    \
+        ILOGV("+ AGET[%d]=0x%x", GET_REGISTER(vsrc2), GET_REGISTER(vdst));  \
     }                                                                       \
     FINISH(2);
 
@@ -990,6 +1245,11 @@ GOTO_TARGET_DECL(exceptionThrown);
         ILOGV("+ APUT[%d]=0x%08x", GET_REGISTER(vsrc2), GET_REGISTER(vdst));\
         ((_type*)(void*)arrayObj->contents)[GET_REGISTER(vsrc2)] =          \
             GET_REGISTER##_regsize(vdst);                                   \
+/* ifdef WITH_TAINT_TRACKING */						    \
+	SET_ARRAY_TAINT(arrayObj,                                           \
+		(GET_ARRAY_TAINT(arrayObj) |                                \
+		 GET_REGISTER_TAINT##_regsize(vdst)) );                     \
+/* endif */								    \
     }                                                                       \
     FINISH(2);
 
@@ -1033,6 +1293,11 @@ GOTO_TARGET_DECL(exceptionThrown);
             dvmGetField##_ftype(obj, ifield->byteOffset));                  \
         ILOGV("+ IGET '%s'=0x%08llx", ifield->field.name,                   \
             (u8) GET_REGISTER##_regsize(vdst));                             \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+	SET_REGISTER_TAINT##_regsize(vdst,                                  \
+	    (GET_REGISTER_TAINT(vsrc1)|                                     \
+	     dvmGetFieldTaint##_ftype(obj,ifield->byteOffset)) );           \
+/* endif */                                                                 \
     }                                                                       \
     FINISH(2);
 
@@ -1051,6 +1316,13 @@ GOTO_TARGET_DECL(exceptionThrown);
         SET_REGISTER##_regsize(vdst, dvmGetField##_ftype(obj, ref));        \
         ILOGV("+ IGETQ %d=0x%08llx", ref,                                   \
             (u8) GET_REGISTER##_regsize(vdst));                             \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+	/*TLOGW("|IGETQ not supported by taint tracking!!!");*/             \
+	/* compile flag WITH_TAINT_ODEX controls this now */                \
+	SET_REGISTER_TAINT##_regsize(vdst,                                  \
+	    (GET_REGISTER_TAINT(vsrc1)|                                     \
+	     dvmGetFieldTaint##_ftype(obj,ref)) );                          \
+/* endif */                                                                 \
     }                                                                       \
     FINISH(2);
 
@@ -1077,6 +1349,10 @@ GOTO_TARGET_DECL(exceptionThrown);
             GET_REGISTER##_regsize(vdst));                                  \
         ILOGV("+ IPUT '%s'=0x%08llx", ifield->field.name,                   \
             (u8) GET_REGISTER##_regsize(vdst));                             \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+	dvmSetFieldTaint##_ftype(obj, ifield->byteOffset,                   \
+		GET_REGISTER_TAINT##_regsize(vdst));                        \
+/* endif */                                                                 \
     }                                                                       \
     FINISH(2);
 
@@ -1095,6 +1371,12 @@ GOTO_TARGET_DECL(exceptionThrown);
         dvmSetField##_ftype(obj, ref, GET_REGISTER##_regsize(vdst));        \
         ILOGV("+ IPUTQ %d=0x%08llx", ref,                                   \
             (u8) GET_REGISTER##_regsize(vdst));                             \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+	/*TLOGW("|IPUTQ not supported by taint tracking!!!");*/             \
+	/* compile flag WITH_TAINT_ODEX controls this now */                \
+	dvmSetFieldTaint##_ftype(obj, ref,                                  \
+		GET_REGISTER_TAINT##_regsize(vdst));                        \
+/* endif */                                                                 \
     }                                                                       \
     FINISH(2);
 
@@ -1126,6 +1408,9 @@ GOTO_TARGET_DECL(exceptionThrown);
         SET_REGISTER##_regsize(vdst, dvmGetStaticField##_ftype(sfield));    \
         ILOGV("+ SGET '%s'=0x%08llx",                                       \
             sfield->field.name, (u8)GET_REGISTER##_regsize(vdst));          \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+	SET_REGISTER_TAINT##_regsize(vdst, dvmGetStaticFieldTaint##_ftype(sfield));\
+/* endif */                                                                 \
     }                                                                       \
     FINISH(2);
 
@@ -1149,9 +1434,14 @@ GOTO_TARGET_DECL(exceptionThrown);
         dvmSetStaticField##_ftype(sfield, GET_REGISTER##_regsize(vdst));    \
         ILOGV("+ SPUT '%s'=0x%08llx",                                       \
             sfield->field.name, (u8)GET_REGISTER##_regsize(vdst));          \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+	dvmSetStaticFieldTaint##_ftype(sfield,                              \
+		GET_REGISTER_TAINT##_regsize(vdst));                        \
+/* endif */                                                                 \
     }                                                                       \
     FINISH(2);
 
+
 /* File: cstubs/enddefs.cpp */
 
 /* undefine "magic" name remapping */
@@ -1163,6 +1453,11 @@ GOTO_TARGET_DECL(exceptionThrown);
 #undef self
 #undef debugTrackedRefStart
 
+#ifdef WITH_TAINT_TRACKING
+#undef rtaint
+#endif
+
+
 /* File: armv5te/debug.cpp */
 #include <inttypes.h>
 
diff --git a/vm/mterp/out/InterpC-armv5te.cpp b/vm/mterp/out/InterpC-armv5te.cpp
index 13c243b..19d1355 100644
--- a/vm/mterp/out/InterpC-armv5te.cpp
+++ b/vm/mterp/out/InterpC-armv5te.cpp
@@ -143,6 +143,31 @@ static const char kSpacing[] = "            ";
 # define DUMP_REGS(_meth, _frame, _inOnly) ((void)0)
 #endif
 
+/*
+ * If enabled, log taint propagation
+ */
+#ifdef WITH_TAINT_TRACKING
+# define TLOGD(...) TLOG(LOG_DEBUG, __VA_ARGS__)
+# define TLOGV(...) TLOG(LOG_VERBOSE, __VA_ARGS__)
+# define TLOGW(...) TLOG(LOG_WARN, __VA_ARGS__)
+# define TLOGE(...) TLOG(LOG_ERROR, __VA_ARGS__)
+# define TLOG(_level, ...) do {                                             \
+        char debugStrBuf[128];                                              \
+        snprintf(debugStrBuf, sizeof(debugStrBuf), __VA_ARGS__);            \
+        if (curMethod != NULL)                                              \
+            ALOG(_level, LOG_TAG"t", "%-2d|%04x|%s.%s:%s\n",                \
+                self->threadId, (int)(pc - curMethod->insns), curMethod->clazz->descriptor, curMethod->name, debugStrBuf); \
+        else                                                                \
+            ALOG(_level, LOG_TAG"t", "%-2d|####%s\n",                       \
+                self->threadId, debugStrBuf);                               \
+    } while(false)
+#else
+# define TLOGD(...) ((void)0)
+# define TLOGV(...) ((void)0)
+# define TLOGW(...) ((void)0)
+# define TLOGE(...) ((void)0)
+#endif
+
 /* get a long from an array of u4 */
 static inline s8 getLongFromArray(const u4* ptr, int idx)
 {
@@ -160,6 +185,20 @@ static inline s8 getLongFromArray(const u4* ptr, int idx)
 #endif
 }
 
+#ifdef WITH_TAINT_TRACKING
+/* get a long from an array of u4 */
+static inline s8 getLongFromArrayTaint(const u4* ptr, int idx)
+{
+    /* Need to use the "union" version for taint tracking */
+    union { s8 ll; u4 parts[2]; } conv;
+
+    ptr += idx;
+    conv.parts[0] = ptr[0];
+    conv.parts[1] = ptr[2];
+    return conv.ll;
+}
+#endif
+
 /* store a long into an array of u4 */
 static inline void putLongToArray(u4* ptr, int idx, s8 val)
 {
@@ -175,6 +214,20 @@ static inline void putLongToArray(u4* ptr, int idx, s8 val)
 #endif
 }
 
+#ifdef WITH_TAINT_TRACKING
+/* store a long into an array of u4 */
+static inline void putLongToArrayTaint(u4* ptr, int idx, s8 val)
+{
+    /* Need to use the "union" version for taint tracking */
+    union { s8 ll; u4 parts[2]; } conv;
+
+    ptr += idx;
+    conv.ll = val;
+    ptr[0] = conv.parts[0];
+    ptr[2] = conv.parts[1];
+}
+#endif
+
 /* get a double from an array of u4 */
 static inline double getDoubleFromArray(const u4* ptr, int idx)
 {
@@ -192,6 +245,20 @@ static inline double getDoubleFromArray(const u4* ptr, int idx)
 #endif
 }
 
+#ifdef WITH_TAINT_TRACKING
+/* get a double from an array of u4 */
+static inline double getDoubleFromArrayTaint(const u4* ptr, int idx)
+{
+    /* Need to use the "union" version for taint tracking */
+    union { double d; u4 parts[2]; } conv;
+
+    ptr += idx;
+    conv.parts[0] = ptr[0];
+    conv.parts[1] = ptr[2];
+    return conv.d;
+}
+#endif
+
 /* store a double into an array of u4 */
 static inline void putDoubleToArray(u4* ptr, int idx, double dval)
 {
@@ -207,6 +274,20 @@ static inline void putDoubleToArray(u4* ptr, int idx, double dval)
 #endif
 }
 
+#ifdef WITH_TAINT_TRACKING
+/* store a double into an array of u4 */
+static inline void putDoubleToArrayTaint(u4* ptr, int idx, double dval)
+{
+    /* Need to use the "union" version for taint tracking */
+    union { double d; u4 parts[2]; } conv;
+
+    ptr += idx;
+    conv.d = dval;
+    ptr[0] = conv.parts[0];
+    ptr[2] = conv.parts[1];
+}
+#endif
+
 /*
  * If enabled, validate the register number on every access.  Otherwise,
  * just do an array access.
@@ -215,6 +296,55 @@ static inline void putDoubleToArray(u4* ptr, int idx, double dval)
  *
  * "_idx" may be referenced more than once.
  */
+#ifdef WITH_TAINT_TRACKING
+/* -- Begin Taint Tracking version ------------------------------- */
+/* Taint tags are interleaved between registers. All indexes must
+ * be multiplied by 2 (i.e., left bit shift by 1) */
+#ifdef CHECK_REGISTER_INDICES
+# define GET_REGISTER(_idx) \
+    ( (_idx) < curMethod->registersSize ? \
+        (fp[(_idx)<<1]) : (assert(!"bad reg"),1969) )
+# define SET_REGISTER(_idx, _val) \
+    ( (_idx) < curMethod->registersSize ? \
+        (fp[(_idx)<<1] = (u4)(_val)) : (assert(!"bad reg"),1969) )
+# define GET_REGISTER_AS_OBJECT(_idx)       ((Object *)GET_REGISTER(_idx))
+# define SET_REGISTER_AS_OBJECT(_idx, _val) SET_REGISTER(_idx, (s4)_val)
+# define GET_REGISTER_INT(_idx) ((s4) GET_REGISTER(_idx))
+# define SET_REGISTER_INT(_idx, _val) SET_REGISTER(_idx, (s4)_val)
+# define GET_REGISTER_WIDE(_idx) \
+    ( (_idx) < curMethod->registersSize-1 ? \
+        getLongFromArrayTaint(fp, ((_idx)<<1)) : (assert(!"bad reg"),1969) )
+# define SET_REGISTER_WIDE(_idx, _val) \
+    ( (_idx) < curMethod->registersSize-1 ? \
+        putLongToArrayTaint(fp, ((_idx)<<1), (_val)) : (assert(!"bad reg"),1969) )
+# define GET_REGISTER_FLOAT(_idx) \
+    ( (_idx) < curMethod->registersSize ? \
+        (*((float*) &fp[(_idx)<<1])) : (assert(!"bad reg"),1969.0f) )
+# define SET_REGISTER_FLOAT(_idx, _val) \
+    ( (_idx) < curMethod->registersSize ? \
+        (*((float*) &fp[(_idx)<<1]) = (_val)) : (assert(!"bad reg"),1969.0f) )
+# define GET_REGISTER_DOUBLE(_idx) \
+    ( (_idx) < curMethod->registersSize-1 ? \
+        getDoubleFromArrayTaint(fp, ((_idx)<<1)) : (assert(!"bad reg"),1969.0) )
+# define SET_REGISTER_DOUBLE(_idx, _val) \
+    ( (_idx) < curMethod->registersSize-1 ? \
+        putDoubleToArrayTaint(fp, ((_idx)<<1), (_val)) : (assert(!"bad reg"),1969.0) )
+#else
+# define GET_REGISTER(_idx)                 (fp[(_idx)<<1])
+# define SET_REGISTER(_idx, _val)           (fp[(_idx)<<1] = (_val))
+# define GET_REGISTER_AS_OBJECT(_idx)       ((Object*) fp[(_idx)<<1])
+# define SET_REGISTER_AS_OBJECT(_idx, _val) (fp[(_idx)<<1] = (u4)(_val))
+# define GET_REGISTER_INT(_idx)             ((s4)GET_REGISTER(_idx))
+# define SET_REGISTER_INT(_idx, _val)       SET_REGISTER(_idx, (s4)_val)
+# define GET_REGISTER_WIDE(_idx)            getLongFromArrayTaint(fp, ((_idx)<<1))
+# define SET_REGISTER_WIDE(_idx, _val)      putLongToArrayTaint(fp, ((_idx)<<1), (_val))
+# define GET_REGISTER_FLOAT(_idx)           (*((float*) &fp[(_idx)<<1]))
+# define SET_REGISTER_FLOAT(_idx, _val)     (*((float*) &fp[(_idx)<<1]) = (_val))
+# define GET_REGISTER_DOUBLE(_idx)          getDoubleFromArrayTaint(fp, ((_idx)<<1))
+# define SET_REGISTER_DOUBLE(_idx, _val)    putDoubleToArrayTaint(fp, ((_idx)<<1), (_val))
+#endif
+/* -- End Taint Tracking version ---------------------------------- */
+#else /* no taint tracking */
 #ifdef CHECK_REGISTER_INDICES
 # define GET_REGISTER(_idx) \
     ( (_idx) < curMethod->registersSize ? \
@@ -258,6 +388,48 @@ static inline void putDoubleToArray(u4* ptr, int idx, double dval)
 # define GET_REGISTER_DOUBLE(_idx)          getDoubleFromArray(fp, (_idx))
 # define SET_REGISTER_DOUBLE(_idx, _val)    putDoubleToArray(fp, (_idx), (_val))
 #endif
+#endif /* end no taint tracking */
+
+#ifdef WITH_TAINT_TRACKING
+/* Core get and set macros */
+# define GET_REGISTER_TAINT(_idx)	     (fp[((_idx)<<1)+1])
+# define SET_REGISTER_TAINT(_idx, _val)	     (fp[((_idx)<<1)+1] = (u4)(_val))
+# define GET_REGISTER_TAINT_WIDE(_idx)       (fp[((_idx)<<1)+1])
+# define SET_REGISTER_TAINT_WIDE(_idx, _val) (fp[((_idx)<<1)+1] = \
+	                                      fp[((_idx)<<1)+3] = (u4)(_val))
+/* Alternate interfaces to help dereference register width */
+# define GET_REGISTER_TAINT_INT(_idx)	          GET_REGISTER_TAINT(_idx)
+# define SET_REGISTER_TAINT_INT(_idx, _val)       SET_REGISTER_TAINT(_idx, _val)
+# define GET_REGISTER_TAINT_FLOAT(_idx)	          GET_REGISTER_TAINT(_idx)
+# define SET_REGISTER_TAINT_FLOAT(_idx, _val)     SET_REGISTER_TAINT(_idx, _val)
+# define GET_REGISTER_TAINT_DOUBLE(_idx)          GET_REGISTER_TAINT_WIDE(_idx)
+# define SET_REGISTER_TAINT_DOUBLE(_idx, _val)    SET_REGISTER_TAINT_WIDE(_idx, _val)
+# define GET_REGISTER_TAINT_AS_OBJECT(_idx)       GET_REGISTER_TAINT(_idx)
+# define SET_REGISTER_TAINT_AS_OBJECT(_idx, _val) SET_REGISTER_TAINT(_idx, _val)
+
+/* Object Taint interface */
+# define GET_ARRAY_TAINT(_arr)		      ((_arr)->taint.tag)
+# define SET_ARRAY_TAINT(_arr, _val)	      ((_arr)->taint.tag = (u4)(_val))
+
+/* Return value taint (assumes rtaint variable is in scope */
+# define GET_RETURN_TAINT()		      (rtaint.tag)
+# define SET_RETURN_TAINT(_val)		      (rtaint.tag = (u4)(_val))
+#else
+# define GET_REGISTER_TAINT(_idx)		    ((void)0)
+# define SET_REGISTER_TAINT(_idx, _val)		    ((void)0)
+# define GET_REGISTER_TAINT_WIDE(_idx)		    ((void)0)
+# define SET_REGISTER_TAINT_WIDE(_idx, _val)	    ((void)0)
+# define GET_REGISTER_TAINT_INT(_idx)		    ((void)0)
+# define SET_REGISTER_TAINT_INT(_idx, _val)	    ((void)0)
+# define GET_REGISTER_TAINT_DOUBLE(_idx)	    ((void)0)
+# define SET_REGISTER_TAINT_DOUBLE(_idx, _val)	    ((void)0)
+# define GET_REGISTER_TAINT_AS_OBJECT(_idx)	    ((void)0)
+# define SET_REGISTER_TAINT_AS_OBJECT(_idx, _val)   ((void)0)
+# define GET_ARRAY_TAINT(_field)                    ((void)0)
+# define SET_ARRAY_TAINT(_field, _val)              ((void)0)
+# define GET_RETURN_TAINT()			    ((void)0)
+# define SET_RETURN_TAINT(_val)			    ((void)0)
+#endif
 
 /*
  * Get 16 bits from the specified offset of the program counter.  We always
@@ -399,6 +571,10 @@ static inline bool checkForNullExportPC(Object* obj, u4* fp, const u2* pc)
 #define methodClassDex          self->interpSave.methodClassDex
 #define debugTrackedRefStart    self->interpSave.debugTrackedRefStart
 
+#ifdef WITH_TAINT_TRACKING
+#define rtaint			self->interpSave.rtaint
+#endif
+
 /* ugh */
 #define STUB_HACK(x) x
 #if defined(WITH_JIT)
@@ -537,6 +713,10 @@ GOTO_TARGET_DECL(exceptionThrown);
         ILOGV("|%s v%d,v%d", (_opname), vdst, vsrc1);                       \
         SET_REGISTER##_totype(vdst,                                         \
             GET_REGISTER##_fromtype(vsrc1));                                \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT##_totype(vdst,                                   \
+	    GET_REGISTER_TAINT##_fromtype(vsrc1));                          \
+/* endif */                                                                 \
         FINISH(1);
 
 #define HANDLE_FLOAT_TO_INT(_opcode, _opname, _fromvtype, _fromrtype,       \
@@ -562,6 +742,10 @@ GOTO_TARGET_DECL(exceptionThrown);
         else                                                                \
             result = (_tovtype) val;                                        \
         SET_REGISTER##_tortype(vdst, result);                               \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT##_tortype(vdst,                                  \
+	    GET_REGISTER_TAINT##_fromrtype(vsrc1));                         \
+/* endif */                                                                 \
     }                                                                       \
     FINISH(1);
 
@@ -571,6 +755,9 @@ GOTO_TARGET_DECL(exceptionThrown);
         vsrc1 = INST_B(inst);                                               \
         ILOGV("|int-to-%s v%d,v%d", (_opname), vdst, vsrc1);                \
         SET_REGISTER(vdst, (_type) GET_REGISTER(vsrc1));                    \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT(vdst, GET_REGISTER_TAINT(vsrc1));                \
+/* endif */                                                                 \
         FINISH(1);
 
 /* NOTE: the comparison result is always a signed 4-byte integer */
@@ -597,6 +784,9 @@ GOTO_TARGET_DECL(exceptionThrown);
             result = (_nanVal);                                             \
         ILOGV("+ result=%d", result);                                       \
         SET_REGISTER(vdst, result);                                         \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT(vdst, TAINT_CLEAR);				    \
+/* endif */                                                                 \
     }                                                                       \
     FINISH(2);
 
@@ -638,6 +828,9 @@ GOTO_TARGET_DECL(exceptionThrown);
         vsrc1 = INST_B(inst);                                               \
         ILOGV("|%s v%d,v%d", (_opname), vdst, vsrc1);                       \
         SET_REGISTER##_type(vdst, _pfx GET_REGISTER##_type(vsrc1) _sfx);    \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT##_type(vdst, GET_REGISTER_TAINT##_type(vsrc1));  \
+/* endif */                                                                 \
         FINISH(1);
 
 #define HANDLE_OP_X_INT(_opcode, _opname, _op, _chkdiv)                     \
@@ -672,6 +865,10 @@ GOTO_TARGET_DECL(exceptionThrown);
             SET_REGISTER(vdst,                                              \
                 (s4) GET_REGISTER(vsrc1) _op (s4) GET_REGISTER(vsrc2));     \
         }                                                                   \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT(vdst,                                            \
+	    (GET_REGISTER_TAINT(vsrc1)|GET_REGISTER_TAINT(vsrc2)) );        \
+/* endif */                                                                 \
     }                                                                       \
     FINISH(2);
 
@@ -686,6 +883,10 @@ GOTO_TARGET_DECL(exceptionThrown);
         ILOGV("|%s-int v%d,v%d", (_opname), vdst, vsrc1);                   \
         SET_REGISTER(vdst,                                                  \
             _cast GET_REGISTER(vsrc1) _op (GET_REGISTER(vsrc2) & 0x1f));    \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT(vdst,                                            \
+	    (GET_REGISTER_TAINT(vsrc1)|GET_REGISTER_TAINT(vsrc2)) );        \
+/* endif */                                                                 \
     }                                                                       \
     FINISH(2);
 
@@ -702,7 +903,7 @@ GOTO_TARGET_DECL(exceptionThrown);
             if ((s2) vsrc2 == 0) {                                          \
                 EXPORT_PC();                                                \
                 dvmThrowArithmeticException("divide by zero");              \
-                GOTO_exceptionThrown();                                     \
+                GOTO_exceptionThrown();                                      \
             }                                                               \
             if ((u4)firstVal == 0x80000000 && ((s2) vsrc2) == -1) {         \
                 /* won't generate /lit16 instr for this; check anyway */    \
@@ -718,6 +919,9 @@ GOTO_TARGET_DECL(exceptionThrown);
             /* non-div/rem case */                                          \
             SET_REGISTER(vdst, GET_REGISTER(vsrc1) _op (s2) vsrc2);         \
         }                                                                   \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT(vdst, GET_REGISTER_TAINT(vsrc1));                \
+/* endif */                                                                 \
         FINISH(2);
 
 #define HANDLE_OP_X_INT_LIT8(_opcode, _opname, _op, _chkdiv)                \
@@ -751,6 +955,9 @@ GOTO_TARGET_DECL(exceptionThrown);
             SET_REGISTER(vdst,                                              \
                 (s4) GET_REGISTER(vsrc1) _op (s1) vsrc2);                   \
         }                                                                   \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT(vdst, GET_REGISTER_TAINT(vsrc1));                \
+/* endif */                                                                 \
     }                                                                       \
     FINISH(2);
 
@@ -766,6 +973,9 @@ GOTO_TARGET_DECL(exceptionThrown);
             (_opname), vdst, vsrc1, vsrc2);                                 \
         SET_REGISTER(vdst,                                                  \
             _cast GET_REGISTER(vsrc1) _op (vsrc2 & 0x1f));                  \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT(vdst, GET_REGISTER_TAINT(vsrc1));                \
+/* endif */                                                                 \
     }                                                                       \
     FINISH(2);
 
@@ -796,6 +1006,10 @@ GOTO_TARGET_DECL(exceptionThrown);
             SET_REGISTER(vdst,                                              \
                 (s4) GET_REGISTER(vdst) _op (s4) GET_REGISTER(vsrc1));      \
         }                                                                   \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT(vdst,                                            \
+	    (GET_REGISTER_TAINT(vdst)|GET_REGISTER_TAINT(vsrc1)) );         \
+/* endif */                                                                 \
         FINISH(1);
 
 #define HANDLE_OP_SHX_INT_2ADDR(_opcode, _opname, _cast, _op)               \
@@ -805,6 +1019,10 @@ GOTO_TARGET_DECL(exceptionThrown);
         ILOGV("|%s-int-2addr v%d,v%d", (_opname), vdst, vsrc1);             \
         SET_REGISTER(vdst,                                                  \
             _cast GET_REGISTER(vdst) _op (GET_REGISTER(vsrc1) & 0x1f));     \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT(vdst,                                            \
+	    (GET_REGISTER_TAINT(vdst)|GET_REGISTER_TAINT(vsrc1)) );         \
+/* endif */                                                                 \
         FINISH(1);
 
 #define HANDLE_OP_X_LONG(_opcode, _opname, _op, _chkdiv)                    \
@@ -840,6 +1058,10 @@ GOTO_TARGET_DECL(exceptionThrown);
             SET_REGISTER_WIDE(vdst,                                         \
                 (s8) GET_REGISTER_WIDE(vsrc1) _op (s8) GET_REGISTER_WIDE(vsrc2)); \
         }                                                                   \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT_WIDE(vdst,                                       \
+	   (GET_REGISTER_TAINT_WIDE(vsrc1)|GET_REGISTER_TAINT_WIDE(vsrc2)));\
+/* endif */                                                                 \
     }                                                                       \
     FINISH(2);
 
@@ -854,6 +1076,10 @@ GOTO_TARGET_DECL(exceptionThrown);
         ILOGV("|%s-long v%d,v%d,v%d", (_opname), vdst, vsrc1, vsrc2);       \
         SET_REGISTER_WIDE(vdst,                                             \
             _cast GET_REGISTER_WIDE(vsrc1) _op (GET_REGISTER(vsrc2) & 0x3f)); \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT_WIDE(vdst,                                       \
+	   (GET_REGISTER_TAINT_WIDE(vsrc1)|GET_REGISTER_TAINT_WIDE(vsrc2)));\
+/* endif */                                                                 \
     }                                                                       \
     FINISH(2);
 
@@ -886,6 +1112,10 @@ GOTO_TARGET_DECL(exceptionThrown);
             SET_REGISTER_WIDE(vdst,                                         \
                 (s8) GET_REGISTER_WIDE(vdst) _op (s8)GET_REGISTER_WIDE(vsrc1));\
         }                                                                   \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT_WIDE(vdst,                                       \
+	    (GET_REGISTER_TAINT_WIDE(vdst)|GET_REGISTER_TAINT_WIDE(vsrc1)));\
+/* endif */                                                                 \
         FINISH(1);
 
 #define HANDLE_OP_SHX_LONG_2ADDR(_opcode, _opname, _cast, _op)              \
@@ -895,6 +1125,10 @@ GOTO_TARGET_DECL(exceptionThrown);
         ILOGV("|%s-long-2addr v%d,v%d", (_opname), vdst, vsrc1);            \
         SET_REGISTER_WIDE(vdst,                                             \
             _cast GET_REGISTER_WIDE(vdst) _op (GET_REGISTER(vsrc1) & 0x3f)); \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT_WIDE(vdst,                                       \
+	    (GET_REGISTER_TAINT_WIDE(vdst)|GET_REGISTER_TAINT_WIDE(vsrc1)));\
+/* endif */                                                                 \
         FINISH(1);
 
 #define HANDLE_OP_X_FLOAT(_opcode, _opname, _op)                            \
@@ -908,6 +1142,10 @@ GOTO_TARGET_DECL(exceptionThrown);
         ILOGV("|%s-float v%d,v%d,v%d", (_opname), vdst, vsrc1, vsrc2);      \
         SET_REGISTER_FLOAT(vdst,                                            \
             GET_REGISTER_FLOAT(vsrc1) _op GET_REGISTER_FLOAT(vsrc2));       \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT_FLOAT(vdst,                                      \
+	    (GET_REGISTER_TAINT_FLOAT(vsrc1)|GET_REGISTER_TAINT_FLOAT(vsrc2)));\
+/* endif */                                                                 \
     }                                                                       \
     FINISH(2);
 
@@ -922,6 +1160,10 @@ GOTO_TARGET_DECL(exceptionThrown);
         ILOGV("|%s-double v%d,v%d,v%d", (_opname), vdst, vsrc1, vsrc2);     \
         SET_REGISTER_DOUBLE(vdst,                                           \
             GET_REGISTER_DOUBLE(vsrc1) _op GET_REGISTER_DOUBLE(vsrc2));     \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT_DOUBLE(vdst,                                     \
+	    (GET_REGISTER_TAINT_DOUBLE(vsrc1)|GET_REGISTER_TAINT_DOUBLE(vsrc2)));\
+/* endif */                                                                 \
     }                                                                       \
     FINISH(2);
 
@@ -932,6 +1174,10 @@ GOTO_TARGET_DECL(exceptionThrown);
         ILOGV("|%s-float-2addr v%d,v%d", (_opname), vdst, vsrc1);           \
         SET_REGISTER_FLOAT(vdst,                                            \
             GET_REGISTER_FLOAT(vdst) _op GET_REGISTER_FLOAT(vsrc1));        \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT_FLOAT(vdst,                                      \
+	    (GET_REGISTER_TAINT_FLOAT(vdst)|GET_REGISTER_TAINT_FLOAT(vsrc1)));\
+/* endif */                                                                 \
         FINISH(1);
 
 #define HANDLE_OP_X_DOUBLE_2ADDR(_opcode, _opname, _op)                     \
@@ -941,6 +1187,10 @@ GOTO_TARGET_DECL(exceptionThrown);
         ILOGV("|%s-double-2addr v%d,v%d", (_opname), vdst, vsrc1);          \
         SET_REGISTER_DOUBLE(vdst,                                           \
             GET_REGISTER_DOUBLE(vdst) _op GET_REGISTER_DOUBLE(vsrc1));      \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT_DOUBLE(vdst,                                     \
+	    (GET_REGISTER_TAINT_DOUBLE(vdst)|GET_REGISTER_TAINT_DOUBLE(vsrc1)));\
+/* endif */                                                                 \
         FINISH(1);
 
 #define HANDLE_OP_AGET(_opcode, _opname, _type, _regsize)                   \
@@ -965,6 +1215,11 @@ GOTO_TARGET_DECL(exceptionThrown);
         SET_REGISTER##_regsize(vdst,                                        \
             ((_type*)(void*)arrayObj->contents)[GET_REGISTER(vsrc2)]);      \
         ILOGV("+ AGET[%d]=%#x", GET_REGISTER(vsrc2), GET_REGISTER(vdst));   \
+/* ifdef WITH_TAINT_TRACKING */						    \
+	SET_REGISTER_TAINT##_regsize(vdst,                                  \
+	    (GET_ARRAY_TAINT(arrayObj)|GET_REGISTER_TAINT(vsrc2)));         \
+/* endif */								    \
+        ILOGV("+ AGET[%d]=0x%x", GET_REGISTER(vsrc2), GET_REGISTER(vdst));  \
     }                                                                       \
     FINISH(2);
 
@@ -990,6 +1245,11 @@ GOTO_TARGET_DECL(exceptionThrown);
         ILOGV("+ APUT[%d]=0x%08x", GET_REGISTER(vsrc2), GET_REGISTER(vdst));\
         ((_type*)(void*)arrayObj->contents)[GET_REGISTER(vsrc2)] =          \
             GET_REGISTER##_regsize(vdst);                                   \
+/* ifdef WITH_TAINT_TRACKING */						    \
+	SET_ARRAY_TAINT(arrayObj,                                           \
+		(GET_ARRAY_TAINT(arrayObj) |                                \
+		 GET_REGISTER_TAINT##_regsize(vdst)) );                     \
+/* endif */								    \
     }                                                                       \
     FINISH(2);
 
@@ -1033,6 +1293,11 @@ GOTO_TARGET_DECL(exceptionThrown);
             dvmGetField##_ftype(obj, ifield->byteOffset));                  \
         ILOGV("+ IGET '%s'=0x%08llx", ifield->field.name,                   \
             (u8) GET_REGISTER##_regsize(vdst));                             \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+	SET_REGISTER_TAINT##_regsize(vdst,                                  \
+	    (GET_REGISTER_TAINT(vsrc1)|                                     \
+	     dvmGetFieldTaint##_ftype(obj,ifield->byteOffset)) );           \
+/* endif */                                                                 \
     }                                                                       \
     FINISH(2);
 
@@ -1051,6 +1316,13 @@ GOTO_TARGET_DECL(exceptionThrown);
         SET_REGISTER##_regsize(vdst, dvmGetField##_ftype(obj, ref));        \
         ILOGV("+ IGETQ %d=0x%08llx", ref,                                   \
             (u8) GET_REGISTER##_regsize(vdst));                             \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+	/*TLOGW("|IGETQ not supported by taint tracking!!!");*/             \
+	/* compile flag WITH_TAINT_ODEX controls this now */                \
+	SET_REGISTER_TAINT##_regsize(vdst,                                  \
+	    (GET_REGISTER_TAINT(vsrc1)|                                     \
+	     dvmGetFieldTaint##_ftype(obj,ref)) );                          \
+/* endif */                                                                 \
     }                                                                       \
     FINISH(2);
 
@@ -1077,6 +1349,10 @@ GOTO_TARGET_DECL(exceptionThrown);
             GET_REGISTER##_regsize(vdst));                                  \
         ILOGV("+ IPUT '%s'=0x%08llx", ifield->field.name,                   \
             (u8) GET_REGISTER##_regsize(vdst));                             \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+	dvmSetFieldTaint##_ftype(obj, ifield->byteOffset,                   \
+		GET_REGISTER_TAINT##_regsize(vdst));                        \
+/* endif */                                                                 \
     }                                                                       \
     FINISH(2);
 
@@ -1095,6 +1371,12 @@ GOTO_TARGET_DECL(exceptionThrown);
         dvmSetField##_ftype(obj, ref, GET_REGISTER##_regsize(vdst));        \
         ILOGV("+ IPUTQ %d=0x%08llx", ref,                                   \
             (u8) GET_REGISTER##_regsize(vdst));                             \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+	/*TLOGW("|IPUTQ not supported by taint tracking!!!");*/             \
+	/* compile flag WITH_TAINT_ODEX controls this now */                \
+	dvmSetFieldTaint##_ftype(obj, ref,                                  \
+		GET_REGISTER_TAINT##_regsize(vdst));                        \
+/* endif */                                                                 \
     }                                                                       \
     FINISH(2);
 
@@ -1126,6 +1408,9 @@ GOTO_TARGET_DECL(exceptionThrown);
         SET_REGISTER##_regsize(vdst, dvmGetStaticField##_ftype(sfield));    \
         ILOGV("+ SGET '%s'=0x%08llx",                                       \
             sfield->field.name, (u8)GET_REGISTER##_regsize(vdst));          \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+	SET_REGISTER_TAINT##_regsize(vdst, dvmGetStaticFieldTaint##_ftype(sfield));\
+/* endif */                                                                 \
     }                                                                       \
     FINISH(2);
 
@@ -1149,9 +1434,14 @@ GOTO_TARGET_DECL(exceptionThrown);
         dvmSetStaticField##_ftype(sfield, GET_REGISTER##_regsize(vdst));    \
         ILOGV("+ SPUT '%s'=0x%08llx",                                       \
             sfield->field.name, (u8)GET_REGISTER##_regsize(vdst));          \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+	dvmSetStaticFieldTaint##_ftype(sfield,                              \
+		GET_REGISTER_TAINT##_regsize(vdst));                        \
+/* endif */                                                                 \
     }                                                                       \
     FINISH(2);
 
+
 /* File: cstubs/enddefs.cpp */
 
 /* undefine "magic" name remapping */
@@ -1163,6 +1453,11 @@ GOTO_TARGET_DECL(exceptionThrown);
 #undef self
 #undef debugTrackedRefStart
 
+#ifdef WITH_TAINT_TRACKING
+#undef rtaint
+#endif
+
+
 /* File: armv5te/debug.cpp */
 #include <inttypes.h>
 
diff --git a/vm/mterp/out/InterpC-armv7-a-neon.cpp b/vm/mterp/out/InterpC-armv7-a-neon.cpp
index ca81a08..3add98f 100644
--- a/vm/mterp/out/InterpC-armv7-a-neon.cpp
+++ b/vm/mterp/out/InterpC-armv7-a-neon.cpp
@@ -143,6 +143,31 @@ static const char kSpacing[] = "            ";
 # define DUMP_REGS(_meth, _frame, _inOnly) ((void)0)
 #endif
 
+/*
+ * If enabled, log taint propagation
+ */
+#ifdef WITH_TAINT_TRACKING
+# define TLOGD(...) TLOG(LOG_DEBUG, __VA_ARGS__)
+# define TLOGV(...) TLOG(LOG_VERBOSE, __VA_ARGS__)
+# define TLOGW(...) TLOG(LOG_WARN, __VA_ARGS__)
+# define TLOGE(...) TLOG(LOG_ERROR, __VA_ARGS__)
+# define TLOG(_level, ...) do {                                             \
+        char debugStrBuf[128];                                              \
+        snprintf(debugStrBuf, sizeof(debugStrBuf), __VA_ARGS__);            \
+        if (curMethod != NULL)                                              \
+            ALOG(_level, LOG_TAG"t", "%-2d|%04x|%s.%s:%s\n",                \
+                self->threadId, (int)(pc - curMethod->insns), curMethod->clazz->descriptor, curMethod->name, debugStrBuf); \
+        else                                                                \
+            ALOG(_level, LOG_TAG"t", "%-2d|####%s\n",                       \
+                self->threadId, debugStrBuf);                               \
+    } while(false)
+#else
+# define TLOGD(...) ((void)0)
+# define TLOGV(...) ((void)0)
+# define TLOGW(...) ((void)0)
+# define TLOGE(...) ((void)0)
+#endif
+
 /* get a long from an array of u4 */
 static inline s8 getLongFromArray(const u4* ptr, int idx)
 {
@@ -160,6 +185,20 @@ static inline s8 getLongFromArray(const u4* ptr, int idx)
 #endif
 }
 
+#ifdef WITH_TAINT_TRACKING
+/* get a long from an array of u4 */
+static inline s8 getLongFromArrayTaint(const u4* ptr, int idx)
+{
+    /* Need to use the "union" version for taint tracking */
+    union { s8 ll; u4 parts[2]; } conv;
+
+    ptr += idx;
+    conv.parts[0] = ptr[0];
+    conv.parts[1] = ptr[2];
+    return conv.ll;
+}
+#endif
+
 /* store a long into an array of u4 */
 static inline void putLongToArray(u4* ptr, int idx, s8 val)
 {
@@ -175,6 +214,20 @@ static inline void putLongToArray(u4* ptr, int idx, s8 val)
 #endif
 }
 
+#ifdef WITH_TAINT_TRACKING
+/* store a long into an array of u4 */
+static inline void putLongToArrayTaint(u4* ptr, int idx, s8 val)
+{
+    /* Need to use the "union" version for taint tracking */
+    union { s8 ll; u4 parts[2]; } conv;
+
+    ptr += idx;
+    conv.ll = val;
+    ptr[0] = conv.parts[0];
+    ptr[2] = conv.parts[1];
+}
+#endif
+
 /* get a double from an array of u4 */
 static inline double getDoubleFromArray(const u4* ptr, int idx)
 {
@@ -192,6 +245,20 @@ static inline double getDoubleFromArray(const u4* ptr, int idx)
 #endif
 }
 
+#ifdef WITH_TAINT_TRACKING
+/* get a double from an array of u4 */
+static inline double getDoubleFromArrayTaint(const u4* ptr, int idx)
+{
+    /* Need to use the "union" version for taint tracking */
+    union { double d; u4 parts[2]; } conv;
+
+    ptr += idx;
+    conv.parts[0] = ptr[0];
+    conv.parts[1] = ptr[2];
+    return conv.d;
+}
+#endif
+
 /* store a double into an array of u4 */
 static inline void putDoubleToArray(u4* ptr, int idx, double dval)
 {
@@ -207,6 +274,20 @@ static inline void putDoubleToArray(u4* ptr, int idx, double dval)
 #endif
 }
 
+#ifdef WITH_TAINT_TRACKING
+/* store a double into an array of u4 */
+static inline void putDoubleToArrayTaint(u4* ptr, int idx, double dval)
+{
+    /* Need to use the "union" version for taint tracking */
+    union { double d; u4 parts[2]; } conv;
+
+    ptr += idx;
+    conv.d = dval;
+    ptr[0] = conv.parts[0];
+    ptr[2] = conv.parts[1];
+}
+#endif
+
 /*
  * If enabled, validate the register number on every access.  Otherwise,
  * just do an array access.
@@ -215,6 +296,55 @@ static inline void putDoubleToArray(u4* ptr, int idx, double dval)
  *
  * "_idx" may be referenced more than once.
  */
+#ifdef WITH_TAINT_TRACKING
+/* -- Begin Taint Tracking version ------------------------------- */
+/* Taint tags are interleaved between registers. All indexes must
+ * be multiplied by 2 (i.e., left bit shift by 1) */
+#ifdef CHECK_REGISTER_INDICES
+# define GET_REGISTER(_idx) \
+    ( (_idx) < curMethod->registersSize ? \
+        (fp[(_idx)<<1]) : (assert(!"bad reg"),1969) )
+# define SET_REGISTER(_idx, _val) \
+    ( (_idx) < curMethod->registersSize ? \
+        (fp[(_idx)<<1] = (u4)(_val)) : (assert(!"bad reg"),1969) )
+# define GET_REGISTER_AS_OBJECT(_idx)       ((Object *)GET_REGISTER(_idx))
+# define SET_REGISTER_AS_OBJECT(_idx, _val) SET_REGISTER(_idx, (s4)_val)
+# define GET_REGISTER_INT(_idx) ((s4) GET_REGISTER(_idx))
+# define SET_REGISTER_INT(_idx, _val) SET_REGISTER(_idx, (s4)_val)
+# define GET_REGISTER_WIDE(_idx) \
+    ( (_idx) < curMethod->registersSize-1 ? \
+        getLongFromArrayTaint(fp, ((_idx)<<1)) : (assert(!"bad reg"),1969) )
+# define SET_REGISTER_WIDE(_idx, _val) \
+    ( (_idx) < curMethod->registersSize-1 ? \
+        putLongToArrayTaint(fp, ((_idx)<<1), (_val)) : (assert(!"bad reg"),1969) )
+# define GET_REGISTER_FLOAT(_idx) \
+    ( (_idx) < curMethod->registersSize ? \
+        (*((float*) &fp[(_idx)<<1])) : (assert(!"bad reg"),1969.0f) )
+# define SET_REGISTER_FLOAT(_idx, _val) \
+    ( (_idx) < curMethod->registersSize ? \
+        (*((float*) &fp[(_idx)<<1]) = (_val)) : (assert(!"bad reg"),1969.0f) )
+# define GET_REGISTER_DOUBLE(_idx) \
+    ( (_idx) < curMethod->registersSize-1 ? \
+        getDoubleFromArrayTaint(fp, ((_idx)<<1)) : (assert(!"bad reg"),1969.0) )
+# define SET_REGISTER_DOUBLE(_idx, _val) \
+    ( (_idx) < curMethod->registersSize-1 ? \
+        putDoubleToArrayTaint(fp, ((_idx)<<1), (_val)) : (assert(!"bad reg"),1969.0) )
+#else
+# define GET_REGISTER(_idx)                 (fp[(_idx)<<1])
+# define SET_REGISTER(_idx, _val)           (fp[(_idx)<<1] = (_val))
+# define GET_REGISTER_AS_OBJECT(_idx)       ((Object*) fp[(_idx)<<1])
+# define SET_REGISTER_AS_OBJECT(_idx, _val) (fp[(_idx)<<1] = (u4)(_val))
+# define GET_REGISTER_INT(_idx)             ((s4)GET_REGISTER(_idx))
+# define SET_REGISTER_INT(_idx, _val)       SET_REGISTER(_idx, (s4)_val)
+# define GET_REGISTER_WIDE(_idx)            getLongFromArrayTaint(fp, ((_idx)<<1))
+# define SET_REGISTER_WIDE(_idx, _val)      putLongToArrayTaint(fp, ((_idx)<<1), (_val))
+# define GET_REGISTER_FLOAT(_idx)           (*((float*) &fp[(_idx)<<1]))
+# define SET_REGISTER_FLOAT(_idx, _val)     (*((float*) &fp[(_idx)<<1]) = (_val))
+# define GET_REGISTER_DOUBLE(_idx)          getDoubleFromArrayTaint(fp, ((_idx)<<1))
+# define SET_REGISTER_DOUBLE(_idx, _val)    putDoubleToArrayTaint(fp, ((_idx)<<1), (_val))
+#endif
+/* -- End Taint Tracking version ---------------------------------- */
+#else /* no taint tracking */
 #ifdef CHECK_REGISTER_INDICES
 # define GET_REGISTER(_idx) \
     ( (_idx) < curMethod->registersSize ? \
@@ -258,6 +388,48 @@ static inline void putDoubleToArray(u4* ptr, int idx, double dval)
 # define GET_REGISTER_DOUBLE(_idx)          getDoubleFromArray(fp, (_idx))
 # define SET_REGISTER_DOUBLE(_idx, _val)    putDoubleToArray(fp, (_idx), (_val))
 #endif
+#endif /* end no taint tracking */
+
+#ifdef WITH_TAINT_TRACKING
+/* Core get and set macros */
+# define GET_REGISTER_TAINT(_idx)	     (fp[((_idx)<<1)+1])
+# define SET_REGISTER_TAINT(_idx, _val)	     (fp[((_idx)<<1)+1] = (u4)(_val))
+# define GET_REGISTER_TAINT_WIDE(_idx)       (fp[((_idx)<<1)+1])
+# define SET_REGISTER_TAINT_WIDE(_idx, _val) (fp[((_idx)<<1)+1] = \
+	                                      fp[((_idx)<<1)+3] = (u4)(_val))
+/* Alternate interfaces to help dereference register width */
+# define GET_REGISTER_TAINT_INT(_idx)	          GET_REGISTER_TAINT(_idx)
+# define SET_REGISTER_TAINT_INT(_idx, _val)       SET_REGISTER_TAINT(_idx, _val)
+# define GET_REGISTER_TAINT_FLOAT(_idx)	          GET_REGISTER_TAINT(_idx)
+# define SET_REGISTER_TAINT_FLOAT(_idx, _val)     SET_REGISTER_TAINT(_idx, _val)
+# define GET_REGISTER_TAINT_DOUBLE(_idx)          GET_REGISTER_TAINT_WIDE(_idx)
+# define SET_REGISTER_TAINT_DOUBLE(_idx, _val)    SET_REGISTER_TAINT_WIDE(_idx, _val)
+# define GET_REGISTER_TAINT_AS_OBJECT(_idx)       GET_REGISTER_TAINT(_idx)
+# define SET_REGISTER_TAINT_AS_OBJECT(_idx, _val) SET_REGISTER_TAINT(_idx, _val)
+
+/* Object Taint interface */
+# define GET_ARRAY_TAINT(_arr)		      ((_arr)->taint.tag)
+# define SET_ARRAY_TAINT(_arr, _val)	      ((_arr)->taint.tag = (u4)(_val))
+
+/* Return value taint (assumes rtaint variable is in scope */
+# define GET_RETURN_TAINT()		      (rtaint.tag)
+# define SET_RETURN_TAINT(_val)		      (rtaint.tag = (u4)(_val))
+#else
+# define GET_REGISTER_TAINT(_idx)		    ((void)0)
+# define SET_REGISTER_TAINT(_idx, _val)		    ((void)0)
+# define GET_REGISTER_TAINT_WIDE(_idx)		    ((void)0)
+# define SET_REGISTER_TAINT_WIDE(_idx, _val)	    ((void)0)
+# define GET_REGISTER_TAINT_INT(_idx)		    ((void)0)
+# define SET_REGISTER_TAINT_INT(_idx, _val)	    ((void)0)
+# define GET_REGISTER_TAINT_DOUBLE(_idx)	    ((void)0)
+# define SET_REGISTER_TAINT_DOUBLE(_idx, _val)	    ((void)0)
+# define GET_REGISTER_TAINT_AS_OBJECT(_idx)	    ((void)0)
+# define SET_REGISTER_TAINT_AS_OBJECT(_idx, _val)   ((void)0)
+# define GET_ARRAY_TAINT(_field)                    ((void)0)
+# define SET_ARRAY_TAINT(_field, _val)              ((void)0)
+# define GET_RETURN_TAINT()			    ((void)0)
+# define SET_RETURN_TAINT(_val)			    ((void)0)
+#endif
 
 /*
  * Get 16 bits from the specified offset of the program counter.  We always
@@ -399,6 +571,10 @@ static inline bool checkForNullExportPC(Object* obj, u4* fp, const u2* pc)
 #define methodClassDex          self->interpSave.methodClassDex
 #define debugTrackedRefStart    self->interpSave.debugTrackedRefStart
 
+#ifdef WITH_TAINT_TRACKING
+#define rtaint			self->interpSave.rtaint
+#endif
+
 /* ugh */
 #define STUB_HACK(x) x
 #if defined(WITH_JIT)
@@ -537,6 +713,10 @@ GOTO_TARGET_DECL(exceptionThrown);
         ILOGV("|%s v%d,v%d", (_opname), vdst, vsrc1);                       \
         SET_REGISTER##_totype(vdst,                                         \
             GET_REGISTER##_fromtype(vsrc1));                                \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT##_totype(vdst,                                   \
+	    GET_REGISTER_TAINT##_fromtype(vsrc1));                          \
+/* endif */                                                                 \
         FINISH(1);
 
 #define HANDLE_FLOAT_TO_INT(_opcode, _opname, _fromvtype, _fromrtype,       \
@@ -562,6 +742,10 @@ GOTO_TARGET_DECL(exceptionThrown);
         else                                                                \
             result = (_tovtype) val;                                        \
         SET_REGISTER##_tortype(vdst, result);                               \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT##_tortype(vdst,                                  \
+	    GET_REGISTER_TAINT##_fromrtype(vsrc1));                         \
+/* endif */                                                                 \
     }                                                                       \
     FINISH(1);
 
@@ -571,6 +755,9 @@ GOTO_TARGET_DECL(exceptionThrown);
         vsrc1 = INST_B(inst);                                               \
         ILOGV("|int-to-%s v%d,v%d", (_opname), vdst, vsrc1);                \
         SET_REGISTER(vdst, (_type) GET_REGISTER(vsrc1));                    \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT(vdst, GET_REGISTER_TAINT(vsrc1));                \
+/* endif */                                                                 \
         FINISH(1);
 
 /* NOTE: the comparison result is always a signed 4-byte integer */
@@ -597,6 +784,9 @@ GOTO_TARGET_DECL(exceptionThrown);
             result = (_nanVal);                                             \
         ILOGV("+ result=%d", result);                                       \
         SET_REGISTER(vdst, result);                                         \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT(vdst, TAINT_CLEAR);				    \
+/* endif */                                                                 \
     }                                                                       \
     FINISH(2);
 
@@ -638,6 +828,9 @@ GOTO_TARGET_DECL(exceptionThrown);
         vsrc1 = INST_B(inst);                                               \
         ILOGV("|%s v%d,v%d", (_opname), vdst, vsrc1);                       \
         SET_REGISTER##_type(vdst, _pfx GET_REGISTER##_type(vsrc1) _sfx);    \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT##_type(vdst, GET_REGISTER_TAINT##_type(vsrc1));  \
+/* endif */                                                                 \
         FINISH(1);
 
 #define HANDLE_OP_X_INT(_opcode, _opname, _op, _chkdiv)                     \
@@ -672,6 +865,10 @@ GOTO_TARGET_DECL(exceptionThrown);
             SET_REGISTER(vdst,                                              \
                 (s4) GET_REGISTER(vsrc1) _op (s4) GET_REGISTER(vsrc2));     \
         }                                                                   \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT(vdst,                                            \
+	    (GET_REGISTER_TAINT(vsrc1)|GET_REGISTER_TAINT(vsrc2)) );        \
+/* endif */                                                                 \
     }                                                                       \
     FINISH(2);
 
@@ -686,6 +883,10 @@ GOTO_TARGET_DECL(exceptionThrown);
         ILOGV("|%s-int v%d,v%d", (_opname), vdst, vsrc1);                   \
         SET_REGISTER(vdst,                                                  \
             _cast GET_REGISTER(vsrc1) _op (GET_REGISTER(vsrc2) & 0x1f));    \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT(vdst,                                            \
+	    (GET_REGISTER_TAINT(vsrc1)|GET_REGISTER_TAINT(vsrc2)) );        \
+/* endif */                                                                 \
     }                                                                       \
     FINISH(2);
 
@@ -702,7 +903,7 @@ GOTO_TARGET_DECL(exceptionThrown);
             if ((s2) vsrc2 == 0) {                                          \
                 EXPORT_PC();                                                \
                 dvmThrowArithmeticException("divide by zero");              \
-                GOTO_exceptionThrown();                                     \
+                GOTO_exceptionThrown();                                      \
             }                                                               \
             if ((u4)firstVal == 0x80000000 && ((s2) vsrc2) == -1) {         \
                 /* won't generate /lit16 instr for this; check anyway */    \
@@ -718,6 +919,9 @@ GOTO_TARGET_DECL(exceptionThrown);
             /* non-div/rem case */                                          \
             SET_REGISTER(vdst, GET_REGISTER(vsrc1) _op (s2) vsrc2);         \
         }                                                                   \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT(vdst, GET_REGISTER_TAINT(vsrc1));                \
+/* endif */                                                                 \
         FINISH(2);
 
 #define HANDLE_OP_X_INT_LIT8(_opcode, _opname, _op, _chkdiv)                \
@@ -751,6 +955,9 @@ GOTO_TARGET_DECL(exceptionThrown);
             SET_REGISTER(vdst,                                              \
                 (s4) GET_REGISTER(vsrc1) _op (s1) vsrc2);                   \
         }                                                                   \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT(vdst, GET_REGISTER_TAINT(vsrc1));                \
+/* endif */                                                                 \
     }                                                                       \
     FINISH(2);
 
@@ -766,6 +973,9 @@ GOTO_TARGET_DECL(exceptionThrown);
             (_opname), vdst, vsrc1, vsrc2);                                 \
         SET_REGISTER(vdst,                                                  \
             _cast GET_REGISTER(vsrc1) _op (vsrc2 & 0x1f));                  \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT(vdst, GET_REGISTER_TAINT(vsrc1));                \
+/* endif */                                                                 \
     }                                                                       \
     FINISH(2);
 
@@ -796,6 +1006,10 @@ GOTO_TARGET_DECL(exceptionThrown);
             SET_REGISTER(vdst,                                              \
                 (s4) GET_REGISTER(vdst) _op (s4) GET_REGISTER(vsrc1));      \
         }                                                                   \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT(vdst,                                            \
+	    (GET_REGISTER_TAINT(vdst)|GET_REGISTER_TAINT(vsrc1)) );         \
+/* endif */                                                                 \
         FINISH(1);
 
 #define HANDLE_OP_SHX_INT_2ADDR(_opcode, _opname, _cast, _op)               \
@@ -805,6 +1019,10 @@ GOTO_TARGET_DECL(exceptionThrown);
         ILOGV("|%s-int-2addr v%d,v%d", (_opname), vdst, vsrc1);             \
         SET_REGISTER(vdst,                                                  \
             _cast GET_REGISTER(vdst) _op (GET_REGISTER(vsrc1) & 0x1f));     \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT(vdst,                                            \
+	    (GET_REGISTER_TAINT(vdst)|GET_REGISTER_TAINT(vsrc1)) );         \
+/* endif */                                                                 \
         FINISH(1);
 
 #define HANDLE_OP_X_LONG(_opcode, _opname, _op, _chkdiv)                    \
@@ -840,6 +1058,10 @@ GOTO_TARGET_DECL(exceptionThrown);
             SET_REGISTER_WIDE(vdst,                                         \
                 (s8) GET_REGISTER_WIDE(vsrc1) _op (s8) GET_REGISTER_WIDE(vsrc2)); \
         }                                                                   \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT_WIDE(vdst,                                       \
+	   (GET_REGISTER_TAINT_WIDE(vsrc1)|GET_REGISTER_TAINT_WIDE(vsrc2)));\
+/* endif */                                                                 \
     }                                                                       \
     FINISH(2);
 
@@ -854,6 +1076,10 @@ GOTO_TARGET_DECL(exceptionThrown);
         ILOGV("|%s-long v%d,v%d,v%d", (_opname), vdst, vsrc1, vsrc2);       \
         SET_REGISTER_WIDE(vdst,                                             \
             _cast GET_REGISTER_WIDE(vsrc1) _op (GET_REGISTER(vsrc2) & 0x3f)); \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT_WIDE(vdst,                                       \
+	   (GET_REGISTER_TAINT_WIDE(vsrc1)|GET_REGISTER_TAINT_WIDE(vsrc2)));\
+/* endif */                                                                 \
     }                                                                       \
     FINISH(2);
 
@@ -886,6 +1112,10 @@ GOTO_TARGET_DECL(exceptionThrown);
             SET_REGISTER_WIDE(vdst,                                         \
                 (s8) GET_REGISTER_WIDE(vdst) _op (s8)GET_REGISTER_WIDE(vsrc1));\
         }                                                                   \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT_WIDE(vdst,                                       \
+	    (GET_REGISTER_TAINT_WIDE(vdst)|GET_REGISTER_TAINT_WIDE(vsrc1)));\
+/* endif */                                                                 \
         FINISH(1);
 
 #define HANDLE_OP_SHX_LONG_2ADDR(_opcode, _opname, _cast, _op)              \
@@ -895,6 +1125,10 @@ GOTO_TARGET_DECL(exceptionThrown);
         ILOGV("|%s-long-2addr v%d,v%d", (_opname), vdst, vsrc1);            \
         SET_REGISTER_WIDE(vdst,                                             \
             _cast GET_REGISTER_WIDE(vdst) _op (GET_REGISTER(vsrc1) & 0x3f)); \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT_WIDE(vdst,                                       \
+	    (GET_REGISTER_TAINT_WIDE(vdst)|GET_REGISTER_TAINT_WIDE(vsrc1)));\
+/* endif */                                                                 \
         FINISH(1);
 
 #define HANDLE_OP_X_FLOAT(_opcode, _opname, _op)                            \
@@ -908,6 +1142,10 @@ GOTO_TARGET_DECL(exceptionThrown);
         ILOGV("|%s-float v%d,v%d,v%d", (_opname), vdst, vsrc1, vsrc2);      \
         SET_REGISTER_FLOAT(vdst,                                            \
             GET_REGISTER_FLOAT(vsrc1) _op GET_REGISTER_FLOAT(vsrc2));       \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT_FLOAT(vdst,                                      \
+	    (GET_REGISTER_TAINT_FLOAT(vsrc1)|GET_REGISTER_TAINT_FLOAT(vsrc2)));\
+/* endif */                                                                 \
     }                                                                       \
     FINISH(2);
 
@@ -922,6 +1160,10 @@ GOTO_TARGET_DECL(exceptionThrown);
         ILOGV("|%s-double v%d,v%d,v%d", (_opname), vdst, vsrc1, vsrc2);     \
         SET_REGISTER_DOUBLE(vdst,                                           \
             GET_REGISTER_DOUBLE(vsrc1) _op GET_REGISTER_DOUBLE(vsrc2));     \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT_DOUBLE(vdst,                                     \
+	    (GET_REGISTER_TAINT_DOUBLE(vsrc1)|GET_REGISTER_TAINT_DOUBLE(vsrc2)));\
+/* endif */                                                                 \
     }                                                                       \
     FINISH(2);
 
@@ -932,6 +1174,10 @@ GOTO_TARGET_DECL(exceptionThrown);
         ILOGV("|%s-float-2addr v%d,v%d", (_opname), vdst, vsrc1);           \
         SET_REGISTER_FLOAT(vdst,                                            \
             GET_REGISTER_FLOAT(vdst) _op GET_REGISTER_FLOAT(vsrc1));        \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT_FLOAT(vdst,                                      \
+	    (GET_REGISTER_TAINT_FLOAT(vdst)|GET_REGISTER_TAINT_FLOAT(vsrc1)));\
+/* endif */                                                                 \
         FINISH(1);
 
 #define HANDLE_OP_X_DOUBLE_2ADDR(_opcode, _opname, _op)                     \
@@ -941,6 +1187,10 @@ GOTO_TARGET_DECL(exceptionThrown);
         ILOGV("|%s-double-2addr v%d,v%d", (_opname), vdst, vsrc1);          \
         SET_REGISTER_DOUBLE(vdst,                                           \
             GET_REGISTER_DOUBLE(vdst) _op GET_REGISTER_DOUBLE(vsrc1));      \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT_DOUBLE(vdst,                                     \
+	    (GET_REGISTER_TAINT_DOUBLE(vdst)|GET_REGISTER_TAINT_DOUBLE(vsrc1)));\
+/* endif */                                                                 \
         FINISH(1);
 
 #define HANDLE_OP_AGET(_opcode, _opname, _type, _regsize)                   \
@@ -965,6 +1215,11 @@ GOTO_TARGET_DECL(exceptionThrown);
         SET_REGISTER##_regsize(vdst,                                        \
             ((_type*)(void*)arrayObj->contents)[GET_REGISTER(vsrc2)]);      \
         ILOGV("+ AGET[%d]=%#x", GET_REGISTER(vsrc2), GET_REGISTER(vdst));   \
+/* ifdef WITH_TAINT_TRACKING */						    \
+	SET_REGISTER_TAINT##_regsize(vdst,                                  \
+	    (GET_ARRAY_TAINT(arrayObj)|GET_REGISTER_TAINT(vsrc2)));         \
+/* endif */								    \
+        ILOGV("+ AGET[%d]=0x%x", GET_REGISTER(vsrc2), GET_REGISTER(vdst));  \
     }                                                                       \
     FINISH(2);
 
@@ -990,6 +1245,11 @@ GOTO_TARGET_DECL(exceptionThrown);
         ILOGV("+ APUT[%d]=0x%08x", GET_REGISTER(vsrc2), GET_REGISTER(vdst));\
         ((_type*)(void*)arrayObj->contents)[GET_REGISTER(vsrc2)] =          \
             GET_REGISTER##_regsize(vdst);                                   \
+/* ifdef WITH_TAINT_TRACKING */						    \
+	SET_ARRAY_TAINT(arrayObj,                                           \
+		(GET_ARRAY_TAINT(arrayObj) |                                \
+		 GET_REGISTER_TAINT##_regsize(vdst)) );                     \
+/* endif */								    \
     }                                                                       \
     FINISH(2);
 
@@ -1033,6 +1293,11 @@ GOTO_TARGET_DECL(exceptionThrown);
             dvmGetField##_ftype(obj, ifield->byteOffset));                  \
         ILOGV("+ IGET '%s'=0x%08llx", ifield->field.name,                   \
             (u8) GET_REGISTER##_regsize(vdst));                             \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+	SET_REGISTER_TAINT##_regsize(vdst,                                  \
+	    (GET_REGISTER_TAINT(vsrc1)|                                     \
+	     dvmGetFieldTaint##_ftype(obj,ifield->byteOffset)) );           \
+/* endif */                                                                 \
     }                                                                       \
     FINISH(2);
 
@@ -1051,6 +1316,13 @@ GOTO_TARGET_DECL(exceptionThrown);
         SET_REGISTER##_regsize(vdst, dvmGetField##_ftype(obj, ref));        \
         ILOGV("+ IGETQ %d=0x%08llx", ref,                                   \
             (u8) GET_REGISTER##_regsize(vdst));                             \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+	/*TLOGW("|IGETQ not supported by taint tracking!!!");*/             \
+	/* compile flag WITH_TAINT_ODEX controls this now */                \
+	SET_REGISTER_TAINT##_regsize(vdst,                                  \
+	    (GET_REGISTER_TAINT(vsrc1)|                                     \
+	     dvmGetFieldTaint##_ftype(obj,ref)) );                          \
+/* endif */                                                                 \
     }                                                                       \
     FINISH(2);
 
@@ -1077,6 +1349,10 @@ GOTO_TARGET_DECL(exceptionThrown);
             GET_REGISTER##_regsize(vdst));                                  \
         ILOGV("+ IPUT '%s'=0x%08llx", ifield->field.name,                   \
             (u8) GET_REGISTER##_regsize(vdst));                             \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+	dvmSetFieldTaint##_ftype(obj, ifield->byteOffset,                   \
+		GET_REGISTER_TAINT##_regsize(vdst));                        \
+/* endif */                                                                 \
     }                                                                       \
     FINISH(2);
 
@@ -1095,6 +1371,12 @@ GOTO_TARGET_DECL(exceptionThrown);
         dvmSetField##_ftype(obj, ref, GET_REGISTER##_regsize(vdst));        \
         ILOGV("+ IPUTQ %d=0x%08llx", ref,                                   \
             (u8) GET_REGISTER##_regsize(vdst));                             \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+	/*TLOGW("|IPUTQ not supported by taint tracking!!!");*/             \
+	/* compile flag WITH_TAINT_ODEX controls this now */                \
+	dvmSetFieldTaint##_ftype(obj, ref,                                  \
+		GET_REGISTER_TAINT##_regsize(vdst));                        \
+/* endif */                                                                 \
     }                                                                       \
     FINISH(2);
 
@@ -1126,6 +1408,9 @@ GOTO_TARGET_DECL(exceptionThrown);
         SET_REGISTER##_regsize(vdst, dvmGetStaticField##_ftype(sfield));    \
         ILOGV("+ SGET '%s'=0x%08llx",                                       \
             sfield->field.name, (u8)GET_REGISTER##_regsize(vdst));          \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+	SET_REGISTER_TAINT##_regsize(vdst, dvmGetStaticFieldTaint##_ftype(sfield));\
+/* endif */                                                                 \
     }                                                                       \
     FINISH(2);
 
@@ -1149,9 +1434,14 @@ GOTO_TARGET_DECL(exceptionThrown);
         dvmSetStaticField##_ftype(sfield, GET_REGISTER##_regsize(vdst));    \
         ILOGV("+ SPUT '%s'=0x%08llx",                                       \
             sfield->field.name, (u8)GET_REGISTER##_regsize(vdst));          \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+	dvmSetStaticFieldTaint##_ftype(sfield,                              \
+		GET_REGISTER_TAINT##_regsize(vdst));                        \
+/* endif */                                                                 \
     }                                                                       \
     FINISH(2);
 
+
 /* File: cstubs/enddefs.cpp */
 
 /* undefine "magic" name remapping */
@@ -1163,7 +1453,12 @@ GOTO_TARGET_DECL(exceptionThrown);
 #undef self
 #undef debugTrackedRefStart
 
-/* File: armv5te/debug.cpp */
+#ifdef WITH_TAINT_TRACKING
+#undef rtaint
+#endif
+
+
+/* File: armv5te_taint/debug.cpp */
 #include <inttypes.h>
 
 /*
diff --git a/vm/mterp/out/InterpC-armv7-a.cpp b/vm/mterp/out/InterpC-armv7-a.cpp
index d90cbdc..6a9c7f2 100644
--- a/vm/mterp/out/InterpC-armv7-a.cpp
+++ b/vm/mterp/out/InterpC-armv7-a.cpp
@@ -143,6 +143,31 @@ static const char kSpacing[] = "            ";
 # define DUMP_REGS(_meth, _frame, _inOnly) ((void)0)
 #endif
 
+/*
+ * If enabled, log taint propagation
+ */
+#ifdef WITH_TAINT_TRACKING
+# define TLOGD(...) TLOG(LOG_DEBUG, __VA_ARGS__)
+# define TLOGV(...) TLOG(LOG_VERBOSE, __VA_ARGS__)
+# define TLOGW(...) TLOG(LOG_WARN, __VA_ARGS__)
+# define TLOGE(...) TLOG(LOG_ERROR, __VA_ARGS__)
+# define TLOG(_level, ...) do {                                             \
+        char debugStrBuf[128];                                              \
+        snprintf(debugStrBuf, sizeof(debugStrBuf), __VA_ARGS__);            \
+        if (curMethod != NULL)                                              \
+            ALOG(_level, LOG_TAG"t", "%-2d|%04x|%s.%s:%s\n",                \
+                self->threadId, (int)(pc - curMethod->insns), curMethod->clazz->descriptor, curMethod->name, debugStrBuf); \
+        else                                                                \
+            ALOG(_level, LOG_TAG"t", "%-2d|####%s\n",                       \
+                self->threadId, debugStrBuf);                               \
+    } while(false)
+#else
+# define TLOGD(...) ((void)0)
+# define TLOGV(...) ((void)0)
+# define TLOGW(...) ((void)0)
+# define TLOGE(...) ((void)0)
+#endif
+
 /* get a long from an array of u4 */
 static inline s8 getLongFromArray(const u4* ptr, int idx)
 {
@@ -160,6 +185,20 @@ static inline s8 getLongFromArray(const u4* ptr, int idx)
 #endif
 }
 
+#ifdef WITH_TAINT_TRACKING
+/* get a long from an array of u4 */
+static inline s8 getLongFromArrayTaint(const u4* ptr, int idx)
+{
+    /* Need to use the "union" version for taint tracking */
+    union { s8 ll; u4 parts[2]; } conv;
+
+    ptr += idx;
+    conv.parts[0] = ptr[0];
+    conv.parts[1] = ptr[2];
+    return conv.ll;
+}
+#endif
+
 /* store a long into an array of u4 */
 static inline void putLongToArray(u4* ptr, int idx, s8 val)
 {
@@ -175,6 +214,20 @@ static inline void putLongToArray(u4* ptr, int idx, s8 val)
 #endif
 }
 
+#ifdef WITH_TAINT_TRACKING
+/* store a long into an array of u4 */
+static inline void putLongToArrayTaint(u4* ptr, int idx, s8 val)
+{
+    /* Need to use the "union" version for taint tracking */
+    union { s8 ll; u4 parts[2]; } conv;
+
+    ptr += idx;
+    conv.ll = val;
+    ptr[0] = conv.parts[0];
+    ptr[2] = conv.parts[1];
+}
+#endif
+
 /* get a double from an array of u4 */
 static inline double getDoubleFromArray(const u4* ptr, int idx)
 {
@@ -192,6 +245,20 @@ static inline double getDoubleFromArray(const u4* ptr, int idx)
 #endif
 }
 
+#ifdef WITH_TAINT_TRACKING
+/* get a double from an array of u4 */
+static inline double getDoubleFromArrayTaint(const u4* ptr, int idx)
+{
+    /* Need to use the "union" version for taint tracking */
+    union { double d; u4 parts[2]; } conv;
+
+    ptr += idx;
+    conv.parts[0] = ptr[0];
+    conv.parts[1] = ptr[2];
+    return conv.d;
+}
+#endif
+
 /* store a double into an array of u4 */
 static inline void putDoubleToArray(u4* ptr, int idx, double dval)
 {
@@ -207,6 +274,20 @@ static inline void putDoubleToArray(u4* ptr, int idx, double dval)
 #endif
 }
 
+#ifdef WITH_TAINT_TRACKING
+/* store a double into an array of u4 */
+static inline void putDoubleToArrayTaint(u4* ptr, int idx, double dval)
+{
+    /* Need to use the "union" version for taint tracking */
+    union { double d; u4 parts[2]; } conv;
+
+    ptr += idx;
+    conv.d = dval;
+    ptr[0] = conv.parts[0];
+    ptr[2] = conv.parts[1];
+}
+#endif
+
 /*
  * If enabled, validate the register number on every access.  Otherwise,
  * just do an array access.
@@ -215,6 +296,55 @@ static inline void putDoubleToArray(u4* ptr, int idx, double dval)
  *
  * "_idx" may be referenced more than once.
  */
+#ifdef WITH_TAINT_TRACKING
+/* -- Begin Taint Tracking version ------------------------------- */
+/* Taint tags are interleaved between registers. All indexes must
+ * be multiplied by 2 (i.e., left bit shift by 1) */
+#ifdef CHECK_REGISTER_INDICES
+# define GET_REGISTER(_idx) \
+    ( (_idx) < curMethod->registersSize ? \
+        (fp[(_idx)<<1]) : (assert(!"bad reg"),1969) )
+# define SET_REGISTER(_idx, _val) \
+    ( (_idx) < curMethod->registersSize ? \
+        (fp[(_idx)<<1] = (u4)(_val)) : (assert(!"bad reg"),1969) )
+# define GET_REGISTER_AS_OBJECT(_idx)       ((Object *)GET_REGISTER(_idx))
+# define SET_REGISTER_AS_OBJECT(_idx, _val) SET_REGISTER(_idx, (s4)_val)
+# define GET_REGISTER_INT(_idx) ((s4) GET_REGISTER(_idx))
+# define SET_REGISTER_INT(_idx, _val) SET_REGISTER(_idx, (s4)_val)
+# define GET_REGISTER_WIDE(_idx) \
+    ( (_idx) < curMethod->registersSize-1 ? \
+        getLongFromArrayTaint(fp, ((_idx)<<1)) : (assert(!"bad reg"),1969) )
+# define SET_REGISTER_WIDE(_idx, _val) \
+    ( (_idx) < curMethod->registersSize-1 ? \
+        putLongToArrayTaint(fp, ((_idx)<<1), (_val)) : (assert(!"bad reg"),1969) )
+# define GET_REGISTER_FLOAT(_idx) \
+    ( (_idx) < curMethod->registersSize ? \
+        (*((float*) &fp[(_idx)<<1])) : (assert(!"bad reg"),1969.0f) )
+# define SET_REGISTER_FLOAT(_idx, _val) \
+    ( (_idx) < curMethod->registersSize ? \
+        (*((float*) &fp[(_idx)<<1]) = (_val)) : (assert(!"bad reg"),1969.0f) )
+# define GET_REGISTER_DOUBLE(_idx) \
+    ( (_idx) < curMethod->registersSize-1 ? \
+        getDoubleFromArrayTaint(fp, ((_idx)<<1)) : (assert(!"bad reg"),1969.0) )
+# define SET_REGISTER_DOUBLE(_idx, _val) \
+    ( (_idx) < curMethod->registersSize-1 ? \
+        putDoubleToArrayTaint(fp, ((_idx)<<1), (_val)) : (assert(!"bad reg"),1969.0) )
+#else
+# define GET_REGISTER(_idx)                 (fp[(_idx)<<1])
+# define SET_REGISTER(_idx, _val)           (fp[(_idx)<<1] = (_val))
+# define GET_REGISTER_AS_OBJECT(_idx)       ((Object*) fp[(_idx)<<1])
+# define SET_REGISTER_AS_OBJECT(_idx, _val) (fp[(_idx)<<1] = (u4)(_val))
+# define GET_REGISTER_INT(_idx)             ((s4)GET_REGISTER(_idx))
+# define SET_REGISTER_INT(_idx, _val)       SET_REGISTER(_idx, (s4)_val)
+# define GET_REGISTER_WIDE(_idx)            getLongFromArrayTaint(fp, ((_idx)<<1))
+# define SET_REGISTER_WIDE(_idx, _val)      putLongToArrayTaint(fp, ((_idx)<<1), (_val))
+# define GET_REGISTER_FLOAT(_idx)           (*((float*) &fp[(_idx)<<1]))
+# define SET_REGISTER_FLOAT(_idx, _val)     (*((float*) &fp[(_idx)<<1]) = (_val))
+# define GET_REGISTER_DOUBLE(_idx)          getDoubleFromArrayTaint(fp, ((_idx)<<1))
+# define SET_REGISTER_DOUBLE(_idx, _val)    putDoubleToArrayTaint(fp, ((_idx)<<1), (_val))
+#endif
+/* -- End Taint Tracking version ---------------------------------- */
+#else /* no taint tracking */
 #ifdef CHECK_REGISTER_INDICES
 # define GET_REGISTER(_idx) \
     ( (_idx) < curMethod->registersSize ? \
@@ -258,6 +388,48 @@ static inline void putDoubleToArray(u4* ptr, int idx, double dval)
 # define GET_REGISTER_DOUBLE(_idx)          getDoubleFromArray(fp, (_idx))
 # define SET_REGISTER_DOUBLE(_idx, _val)    putDoubleToArray(fp, (_idx), (_val))
 #endif
+#endif /* end no taint tracking */
+
+#ifdef WITH_TAINT_TRACKING
+/* Core get and set macros */
+# define GET_REGISTER_TAINT(_idx)	     (fp[((_idx)<<1)+1])
+# define SET_REGISTER_TAINT(_idx, _val)	     (fp[((_idx)<<1)+1] = (u4)(_val))
+# define GET_REGISTER_TAINT_WIDE(_idx)       (fp[((_idx)<<1)+1])
+# define SET_REGISTER_TAINT_WIDE(_idx, _val) (fp[((_idx)<<1)+1] = \
+	                                      fp[((_idx)<<1)+3] = (u4)(_val))
+/* Alternate interfaces to help dereference register width */
+# define GET_REGISTER_TAINT_INT(_idx)	          GET_REGISTER_TAINT(_idx)
+# define SET_REGISTER_TAINT_INT(_idx, _val)       SET_REGISTER_TAINT(_idx, _val)
+# define GET_REGISTER_TAINT_FLOAT(_idx)	          GET_REGISTER_TAINT(_idx)
+# define SET_REGISTER_TAINT_FLOAT(_idx, _val)     SET_REGISTER_TAINT(_idx, _val)
+# define GET_REGISTER_TAINT_DOUBLE(_idx)          GET_REGISTER_TAINT_WIDE(_idx)
+# define SET_REGISTER_TAINT_DOUBLE(_idx, _val)    SET_REGISTER_TAINT_WIDE(_idx, _val)
+# define GET_REGISTER_TAINT_AS_OBJECT(_idx)       GET_REGISTER_TAINT(_idx)
+# define SET_REGISTER_TAINT_AS_OBJECT(_idx, _val) SET_REGISTER_TAINT(_idx, _val)
+
+/* Object Taint interface */
+# define GET_ARRAY_TAINT(_arr)		      ((_arr)->taint.tag)
+# define SET_ARRAY_TAINT(_arr, _val)	      ((_arr)->taint.tag = (u4)(_val))
+
+/* Return value taint (assumes rtaint variable is in scope */
+# define GET_RETURN_TAINT()		      (rtaint.tag)
+# define SET_RETURN_TAINT(_val)		      (rtaint.tag = (u4)(_val))
+#else
+# define GET_REGISTER_TAINT(_idx)		    ((void)0)
+# define SET_REGISTER_TAINT(_idx, _val)		    ((void)0)
+# define GET_REGISTER_TAINT_WIDE(_idx)		    ((void)0)
+# define SET_REGISTER_TAINT_WIDE(_idx, _val)	    ((void)0)
+# define GET_REGISTER_TAINT_INT(_idx)		    ((void)0)
+# define SET_REGISTER_TAINT_INT(_idx, _val)	    ((void)0)
+# define GET_REGISTER_TAINT_DOUBLE(_idx)	    ((void)0)
+# define SET_REGISTER_TAINT_DOUBLE(_idx, _val)	    ((void)0)
+# define GET_REGISTER_TAINT_AS_OBJECT(_idx)	    ((void)0)
+# define SET_REGISTER_TAINT_AS_OBJECT(_idx, _val)   ((void)0)
+# define GET_ARRAY_TAINT(_field)                    ((void)0)
+# define SET_ARRAY_TAINT(_field, _val)              ((void)0)
+# define GET_RETURN_TAINT()			    ((void)0)
+# define SET_RETURN_TAINT(_val)			    ((void)0)
+#endif
 
 /*
  * Get 16 bits from the specified offset of the program counter.  We always
@@ -399,6 +571,10 @@ static inline bool checkForNullExportPC(Object* obj, u4* fp, const u2* pc)
 #define methodClassDex          self->interpSave.methodClassDex
 #define debugTrackedRefStart    self->interpSave.debugTrackedRefStart
 
+#ifdef WITH_TAINT_TRACKING
+#define rtaint			self->interpSave.rtaint
+#endif
+
 /* ugh */
 #define STUB_HACK(x) x
 #if defined(WITH_JIT)
@@ -537,6 +713,10 @@ GOTO_TARGET_DECL(exceptionThrown);
         ILOGV("|%s v%d,v%d", (_opname), vdst, vsrc1);                       \
         SET_REGISTER##_totype(vdst,                                         \
             GET_REGISTER##_fromtype(vsrc1));                                \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT##_totype(vdst,                                   \
+	    GET_REGISTER_TAINT##_fromtype(vsrc1));                          \
+/* endif */                                                                 \
         FINISH(1);
 
 #define HANDLE_FLOAT_TO_INT(_opcode, _opname, _fromvtype, _fromrtype,       \
@@ -562,6 +742,10 @@ GOTO_TARGET_DECL(exceptionThrown);
         else                                                                \
             result = (_tovtype) val;                                        \
         SET_REGISTER##_tortype(vdst, result);                               \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT##_tortype(vdst,                                  \
+	    GET_REGISTER_TAINT##_fromrtype(vsrc1));                         \
+/* endif */                                                                 \
     }                                                                       \
     FINISH(1);
 
@@ -571,6 +755,9 @@ GOTO_TARGET_DECL(exceptionThrown);
         vsrc1 = INST_B(inst);                                               \
         ILOGV("|int-to-%s v%d,v%d", (_opname), vdst, vsrc1);                \
         SET_REGISTER(vdst, (_type) GET_REGISTER(vsrc1));                    \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT(vdst, GET_REGISTER_TAINT(vsrc1));                \
+/* endif */                                                                 \
         FINISH(1);
 
 /* NOTE: the comparison result is always a signed 4-byte integer */
@@ -597,6 +784,9 @@ GOTO_TARGET_DECL(exceptionThrown);
             result = (_nanVal);                                             \
         ILOGV("+ result=%d", result);                                       \
         SET_REGISTER(vdst, result);                                         \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT(vdst, TAINT_CLEAR);				    \
+/* endif */                                                                 \
     }                                                                       \
     FINISH(2);
 
@@ -638,6 +828,9 @@ GOTO_TARGET_DECL(exceptionThrown);
         vsrc1 = INST_B(inst);                                               \
         ILOGV("|%s v%d,v%d", (_opname), vdst, vsrc1);                       \
         SET_REGISTER##_type(vdst, _pfx GET_REGISTER##_type(vsrc1) _sfx);    \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT##_type(vdst, GET_REGISTER_TAINT##_type(vsrc1));  \
+/* endif */                                                                 \
         FINISH(1);
 
 #define HANDLE_OP_X_INT(_opcode, _opname, _op, _chkdiv)                     \
@@ -672,6 +865,10 @@ GOTO_TARGET_DECL(exceptionThrown);
             SET_REGISTER(vdst,                                              \
                 (s4) GET_REGISTER(vsrc1) _op (s4) GET_REGISTER(vsrc2));     \
         }                                                                   \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT(vdst,                                            \
+	    (GET_REGISTER_TAINT(vsrc1)|GET_REGISTER_TAINT(vsrc2)) );        \
+/* endif */                                                                 \
     }                                                                       \
     FINISH(2);
 
@@ -686,6 +883,10 @@ GOTO_TARGET_DECL(exceptionThrown);
         ILOGV("|%s-int v%d,v%d", (_opname), vdst, vsrc1);                   \
         SET_REGISTER(vdst,                                                  \
             _cast GET_REGISTER(vsrc1) _op (GET_REGISTER(vsrc2) & 0x1f));    \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT(vdst,                                            \
+	    (GET_REGISTER_TAINT(vsrc1)|GET_REGISTER_TAINT(vsrc2)) );        \
+/* endif */                                                                 \
     }                                                                       \
     FINISH(2);
 
@@ -702,7 +903,7 @@ GOTO_TARGET_DECL(exceptionThrown);
             if ((s2) vsrc2 == 0) {                                          \
                 EXPORT_PC();                                                \
                 dvmThrowArithmeticException("divide by zero");              \
-                GOTO_exceptionThrown();                                     \
+                GOTO_exceptionThrown();                                      \
             }                                                               \
             if ((u4)firstVal == 0x80000000 && ((s2) vsrc2) == -1) {         \
                 /* won't generate /lit16 instr for this; check anyway */    \
@@ -718,6 +919,9 @@ GOTO_TARGET_DECL(exceptionThrown);
             /* non-div/rem case */                                          \
             SET_REGISTER(vdst, GET_REGISTER(vsrc1) _op (s2) vsrc2);         \
         }                                                                   \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT(vdst, GET_REGISTER_TAINT(vsrc1));                \
+/* endif */                                                                 \
         FINISH(2);
 
 #define HANDLE_OP_X_INT_LIT8(_opcode, _opname, _op, _chkdiv)                \
@@ -751,6 +955,9 @@ GOTO_TARGET_DECL(exceptionThrown);
             SET_REGISTER(vdst,                                              \
                 (s4) GET_REGISTER(vsrc1) _op (s1) vsrc2);                   \
         }                                                                   \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT(vdst, GET_REGISTER_TAINT(vsrc1));                \
+/* endif */                                                                 \
     }                                                                       \
     FINISH(2);
 
@@ -766,6 +973,9 @@ GOTO_TARGET_DECL(exceptionThrown);
             (_opname), vdst, vsrc1, vsrc2);                                 \
         SET_REGISTER(vdst,                                                  \
             _cast GET_REGISTER(vsrc1) _op (vsrc2 & 0x1f));                  \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT(vdst, GET_REGISTER_TAINT(vsrc1));                \
+/* endif */                                                                 \
     }                                                                       \
     FINISH(2);
 
@@ -796,6 +1006,10 @@ GOTO_TARGET_DECL(exceptionThrown);
             SET_REGISTER(vdst,                                              \
                 (s4) GET_REGISTER(vdst) _op (s4) GET_REGISTER(vsrc1));      \
         }                                                                   \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT(vdst,                                            \
+	    (GET_REGISTER_TAINT(vdst)|GET_REGISTER_TAINT(vsrc1)) );         \
+/* endif */                                                                 \
         FINISH(1);
 
 #define HANDLE_OP_SHX_INT_2ADDR(_opcode, _opname, _cast, _op)               \
@@ -805,6 +1019,10 @@ GOTO_TARGET_DECL(exceptionThrown);
         ILOGV("|%s-int-2addr v%d,v%d", (_opname), vdst, vsrc1);             \
         SET_REGISTER(vdst,                                                  \
             _cast GET_REGISTER(vdst) _op (GET_REGISTER(vsrc1) & 0x1f));     \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT(vdst,                                            \
+	    (GET_REGISTER_TAINT(vdst)|GET_REGISTER_TAINT(vsrc1)) );         \
+/* endif */                                                                 \
         FINISH(1);
 
 #define HANDLE_OP_X_LONG(_opcode, _opname, _op, _chkdiv)                    \
@@ -840,6 +1058,10 @@ GOTO_TARGET_DECL(exceptionThrown);
             SET_REGISTER_WIDE(vdst,                                         \
                 (s8) GET_REGISTER_WIDE(vsrc1) _op (s8) GET_REGISTER_WIDE(vsrc2)); \
         }                                                                   \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT_WIDE(vdst,                                       \
+	   (GET_REGISTER_TAINT_WIDE(vsrc1)|GET_REGISTER_TAINT_WIDE(vsrc2)));\
+/* endif */                                                                 \
     }                                                                       \
     FINISH(2);
 
@@ -854,6 +1076,10 @@ GOTO_TARGET_DECL(exceptionThrown);
         ILOGV("|%s-long v%d,v%d,v%d", (_opname), vdst, vsrc1, vsrc2);       \
         SET_REGISTER_WIDE(vdst,                                             \
             _cast GET_REGISTER_WIDE(vsrc1) _op (GET_REGISTER(vsrc2) & 0x3f)); \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT_WIDE(vdst,                                       \
+	   (GET_REGISTER_TAINT_WIDE(vsrc1)|GET_REGISTER_TAINT_WIDE(vsrc2)));\
+/* endif */                                                                 \
     }                                                                       \
     FINISH(2);
 
@@ -886,6 +1112,10 @@ GOTO_TARGET_DECL(exceptionThrown);
             SET_REGISTER_WIDE(vdst,                                         \
                 (s8) GET_REGISTER_WIDE(vdst) _op (s8)GET_REGISTER_WIDE(vsrc1));\
         }                                                                   \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT_WIDE(vdst,                                       \
+	    (GET_REGISTER_TAINT_WIDE(vdst)|GET_REGISTER_TAINT_WIDE(vsrc1)));\
+/* endif */                                                                 \
         FINISH(1);
 
 #define HANDLE_OP_SHX_LONG_2ADDR(_opcode, _opname, _cast, _op)              \
@@ -895,6 +1125,10 @@ GOTO_TARGET_DECL(exceptionThrown);
         ILOGV("|%s-long-2addr v%d,v%d", (_opname), vdst, vsrc1);            \
         SET_REGISTER_WIDE(vdst,                                             \
             _cast GET_REGISTER_WIDE(vdst) _op (GET_REGISTER(vsrc1) & 0x3f)); \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT_WIDE(vdst,                                       \
+	    (GET_REGISTER_TAINT_WIDE(vdst)|GET_REGISTER_TAINT_WIDE(vsrc1)));\
+/* endif */                                                                 \
         FINISH(1);
 
 #define HANDLE_OP_X_FLOAT(_opcode, _opname, _op)                            \
@@ -908,6 +1142,10 @@ GOTO_TARGET_DECL(exceptionThrown);
         ILOGV("|%s-float v%d,v%d,v%d", (_opname), vdst, vsrc1, vsrc2);      \
         SET_REGISTER_FLOAT(vdst,                                            \
             GET_REGISTER_FLOAT(vsrc1) _op GET_REGISTER_FLOAT(vsrc2));       \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT_FLOAT(vdst,                                      \
+	    (GET_REGISTER_TAINT_FLOAT(vsrc1)|GET_REGISTER_TAINT_FLOAT(vsrc2)));\
+/* endif */                                                                 \
     }                                                                       \
     FINISH(2);
 
@@ -922,6 +1160,10 @@ GOTO_TARGET_DECL(exceptionThrown);
         ILOGV("|%s-double v%d,v%d,v%d", (_opname), vdst, vsrc1, vsrc2);     \
         SET_REGISTER_DOUBLE(vdst,                                           \
             GET_REGISTER_DOUBLE(vsrc1) _op GET_REGISTER_DOUBLE(vsrc2));     \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT_DOUBLE(vdst,                                     \
+	    (GET_REGISTER_TAINT_DOUBLE(vsrc1)|GET_REGISTER_TAINT_DOUBLE(vsrc2)));\
+/* endif */                                                                 \
     }                                                                       \
     FINISH(2);
 
@@ -932,6 +1174,10 @@ GOTO_TARGET_DECL(exceptionThrown);
         ILOGV("|%s-float-2addr v%d,v%d", (_opname), vdst, vsrc1);           \
         SET_REGISTER_FLOAT(vdst,                                            \
             GET_REGISTER_FLOAT(vdst) _op GET_REGISTER_FLOAT(vsrc1));        \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT_FLOAT(vdst,                                      \
+	    (GET_REGISTER_TAINT_FLOAT(vdst)|GET_REGISTER_TAINT_FLOAT(vsrc1)));\
+/* endif */                                                                 \
         FINISH(1);
 
 #define HANDLE_OP_X_DOUBLE_2ADDR(_opcode, _opname, _op)                     \
@@ -941,6 +1187,10 @@ GOTO_TARGET_DECL(exceptionThrown);
         ILOGV("|%s-double-2addr v%d,v%d", (_opname), vdst, vsrc1);          \
         SET_REGISTER_DOUBLE(vdst,                                           \
             GET_REGISTER_DOUBLE(vdst) _op GET_REGISTER_DOUBLE(vsrc1));      \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT_DOUBLE(vdst,                                     \
+	    (GET_REGISTER_TAINT_DOUBLE(vdst)|GET_REGISTER_TAINT_DOUBLE(vsrc1)));\
+/* endif */                                                                 \
         FINISH(1);
 
 #define HANDLE_OP_AGET(_opcode, _opname, _type, _regsize)                   \
@@ -965,6 +1215,11 @@ GOTO_TARGET_DECL(exceptionThrown);
         SET_REGISTER##_regsize(vdst,                                        \
             ((_type*)(void*)arrayObj->contents)[GET_REGISTER(vsrc2)]);      \
         ILOGV("+ AGET[%d]=%#x", GET_REGISTER(vsrc2), GET_REGISTER(vdst));   \
+/* ifdef WITH_TAINT_TRACKING */						    \
+	SET_REGISTER_TAINT##_regsize(vdst,                                  \
+	    (GET_ARRAY_TAINT(arrayObj)|GET_REGISTER_TAINT(vsrc2)));         \
+/* endif */								    \
+        ILOGV("+ AGET[%d]=0x%x", GET_REGISTER(vsrc2), GET_REGISTER(vdst));  \
     }                                                                       \
     FINISH(2);
 
@@ -990,6 +1245,11 @@ GOTO_TARGET_DECL(exceptionThrown);
         ILOGV("+ APUT[%d]=0x%08x", GET_REGISTER(vsrc2), GET_REGISTER(vdst));\
         ((_type*)(void*)arrayObj->contents)[GET_REGISTER(vsrc2)] =          \
             GET_REGISTER##_regsize(vdst);                                   \
+/* ifdef WITH_TAINT_TRACKING */						    \
+	SET_ARRAY_TAINT(arrayObj,                                           \
+		(GET_ARRAY_TAINT(arrayObj) |                                \
+		 GET_REGISTER_TAINT##_regsize(vdst)) );                     \
+/* endif */								    \
     }                                                                       \
     FINISH(2);
 
@@ -1033,6 +1293,11 @@ GOTO_TARGET_DECL(exceptionThrown);
             dvmGetField##_ftype(obj, ifield->byteOffset));                  \
         ILOGV("+ IGET '%s'=0x%08llx", ifield->field.name,                   \
             (u8) GET_REGISTER##_regsize(vdst));                             \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+	SET_REGISTER_TAINT##_regsize(vdst,                                  \
+	    (GET_REGISTER_TAINT(vsrc1)|                                     \
+	     dvmGetFieldTaint##_ftype(obj,ifield->byteOffset)) );           \
+/* endif */                                                                 \
     }                                                                       \
     FINISH(2);
 
@@ -1051,6 +1316,13 @@ GOTO_TARGET_DECL(exceptionThrown);
         SET_REGISTER##_regsize(vdst, dvmGetField##_ftype(obj, ref));        \
         ILOGV("+ IGETQ %d=0x%08llx", ref,                                   \
             (u8) GET_REGISTER##_regsize(vdst));                             \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+	/*TLOGW("|IGETQ not supported by taint tracking!!!");*/             \
+	/* compile flag WITH_TAINT_ODEX controls this now */                \
+	SET_REGISTER_TAINT##_regsize(vdst,                                  \
+	    (GET_REGISTER_TAINT(vsrc1)|                                     \
+	     dvmGetFieldTaint##_ftype(obj,ref)) );                          \
+/* endif */                                                                 \
     }                                                                       \
     FINISH(2);
 
@@ -1077,6 +1349,10 @@ GOTO_TARGET_DECL(exceptionThrown);
             GET_REGISTER##_regsize(vdst));                                  \
         ILOGV("+ IPUT '%s'=0x%08llx", ifield->field.name,                   \
             (u8) GET_REGISTER##_regsize(vdst));                             \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+	dvmSetFieldTaint##_ftype(obj, ifield->byteOffset,                   \
+		GET_REGISTER_TAINT##_regsize(vdst));                        \
+/* endif */                                                                 \
     }                                                                       \
     FINISH(2);
 
@@ -1095,6 +1371,12 @@ GOTO_TARGET_DECL(exceptionThrown);
         dvmSetField##_ftype(obj, ref, GET_REGISTER##_regsize(vdst));        \
         ILOGV("+ IPUTQ %d=0x%08llx", ref,                                   \
             (u8) GET_REGISTER##_regsize(vdst));                             \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+	/*TLOGW("|IPUTQ not supported by taint tracking!!!");*/             \
+	/* compile flag WITH_TAINT_ODEX controls this now */                \
+	dvmSetFieldTaint##_ftype(obj, ref,                                  \
+		GET_REGISTER_TAINT##_regsize(vdst));                        \
+/* endif */                                                                 \
     }                                                                       \
     FINISH(2);
 
@@ -1126,6 +1408,9 @@ GOTO_TARGET_DECL(exceptionThrown);
         SET_REGISTER##_regsize(vdst, dvmGetStaticField##_ftype(sfield));    \
         ILOGV("+ SGET '%s'=0x%08llx",                                       \
             sfield->field.name, (u8)GET_REGISTER##_regsize(vdst));          \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+	SET_REGISTER_TAINT##_regsize(vdst, dvmGetStaticFieldTaint##_ftype(sfield));\
+/* endif */                                                                 \
     }                                                                       \
     FINISH(2);
 
@@ -1149,9 +1434,14 @@ GOTO_TARGET_DECL(exceptionThrown);
         dvmSetStaticField##_ftype(sfield, GET_REGISTER##_regsize(vdst));    \
         ILOGV("+ SPUT '%s'=0x%08llx",                                       \
             sfield->field.name, (u8)GET_REGISTER##_regsize(vdst));          \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+	dvmSetStaticFieldTaint##_ftype(sfield,                              \
+		GET_REGISTER_TAINT##_regsize(vdst));                        \
+/* endif */                                                                 \
     }                                                                       \
     FINISH(2);
 
+
 /* File: cstubs/enddefs.cpp */
 
 /* undefine "magic" name remapping */
@@ -1163,7 +1453,12 @@ GOTO_TARGET_DECL(exceptionThrown);
 #undef self
 #undef debugTrackedRefStart
 
-/* File: armv5te/debug.cpp */
+#ifdef WITH_TAINT_TRACKING
+#undef rtaint
+#endif
+
+
+/* File: armv5te_taint/debug.cpp */
 #include <inttypes.h>
 
 /*
diff --git a/vm/mterp/out/InterpC-portable.cpp b/vm/mterp/out/InterpC-portable.cpp
index 2111a98..d71051a 100644
--- a/vm/mterp/out/InterpC-portable.cpp
+++ b/vm/mterp/out/InterpC-portable.cpp
@@ -143,6 +143,31 @@ static const char kSpacing[] = "            ";
 # define DUMP_REGS(_meth, _frame, _inOnly) ((void)0)
 #endif
 
+/*
+ * If enabled, log taint propagation
+ */
+#ifdef WITH_TAINT_TRACKING
+# define TLOGD(...) TLOG(LOG_DEBUG, __VA_ARGS__)
+# define TLOGV(...) TLOG(LOG_VERBOSE, __VA_ARGS__)
+# define TLOGW(...) TLOG(LOG_WARN, __VA_ARGS__)
+# define TLOGE(...) TLOG(LOG_ERROR, __VA_ARGS__)
+# define TLOG(_level, ...) do {                                             \
+        char debugStrBuf[128];                                              \
+        snprintf(debugStrBuf, sizeof(debugStrBuf), __VA_ARGS__);            \
+        if (curMethod != NULL)                                              \
+            ALOG(_level, LOG_TAG"t", "%-2d|%04x|%s.%s:%s\n",                \
+                self->threadId, (int)(pc - curMethod->insns), curMethod->clazz->descriptor, curMethod->name, debugStrBuf); \
+        else                                                                \
+            ALOG(_level, LOG_TAG"t", "%-2d|####%s\n",                       \
+                self->threadId, debugStrBuf);                               \
+    } while(false)
+#else
+# define TLOGD(...) ((void)0)
+# define TLOGV(...) ((void)0)
+# define TLOGW(...) ((void)0)
+# define TLOGE(...) ((void)0)
+#endif
+
 /* get a long from an array of u4 */
 static inline s8 getLongFromArray(const u4* ptr, int idx)
 {
@@ -160,6 +185,20 @@ static inline s8 getLongFromArray(const u4* ptr, int idx)
 #endif
 }
 
+#ifdef WITH_TAINT_TRACKING
+/* get a long from an array of u4 */
+static inline s8 getLongFromArrayTaint(const u4* ptr, int idx)
+{
+    /* Need to use the "union" version for taint tracking */
+    union { s8 ll; u4 parts[2]; } conv;
+
+    ptr += idx;
+    conv.parts[0] = ptr[0];
+    conv.parts[1] = ptr[2];
+    return conv.ll;
+}
+#endif
+
 /* store a long into an array of u4 */
 static inline void putLongToArray(u4* ptr, int idx, s8 val)
 {
@@ -175,6 +214,20 @@ static inline void putLongToArray(u4* ptr, int idx, s8 val)
 #endif
 }
 
+#ifdef WITH_TAINT_TRACKING
+/* store a long into an array of u4 */
+static inline void putLongToArrayTaint(u4* ptr, int idx, s8 val)
+{
+    /* Need to use the "union" version for taint tracking */
+    union { s8 ll; u4 parts[2]; } conv;
+
+    ptr += idx;
+    conv.ll = val;
+    ptr[0] = conv.parts[0];
+    ptr[2] = conv.parts[1];
+}
+#endif
+
 /* get a double from an array of u4 */
 static inline double getDoubleFromArray(const u4* ptr, int idx)
 {
@@ -192,6 +245,20 @@ static inline double getDoubleFromArray(const u4* ptr, int idx)
 #endif
 }
 
+#ifdef WITH_TAINT_TRACKING
+/* get a double from an array of u4 */
+static inline double getDoubleFromArrayTaint(const u4* ptr, int idx)
+{
+    /* Need to use the "union" version for taint tracking */
+    union { double d; u4 parts[2]; } conv;
+
+    ptr += idx;
+    conv.parts[0] = ptr[0];
+    conv.parts[1] = ptr[2];
+    return conv.d;
+}
+#endif
+
 /* store a double into an array of u4 */
 static inline void putDoubleToArray(u4* ptr, int idx, double dval)
 {
@@ -207,6 +274,20 @@ static inline void putDoubleToArray(u4* ptr, int idx, double dval)
 #endif
 }
 
+#ifdef WITH_TAINT_TRACKING
+/* store a double into an array of u4 */
+static inline void putDoubleToArrayTaint(u4* ptr, int idx, double dval)
+{
+    /* Need to use the "union" version for taint tracking */
+    union { double d; u4 parts[2]; } conv;
+
+    ptr += idx;
+    conv.d = dval;
+    ptr[0] = conv.parts[0];
+    ptr[2] = conv.parts[1];
+}
+#endif
+
 /*
  * If enabled, validate the register number on every access.  Otherwise,
  * just do an array access.
@@ -215,6 +296,55 @@ static inline void putDoubleToArray(u4* ptr, int idx, double dval)
  *
  * "_idx" may be referenced more than once.
  */
+#ifdef WITH_TAINT_TRACKING
+/* -- Begin Taint Tracking version ------------------------------- */
+/* Taint tags are interleaved between registers. All indexes must
+ * be multiplied by 2 (i.e., left bit shift by 1) */
+#ifdef CHECK_REGISTER_INDICES
+# define GET_REGISTER(_idx) \
+    ( (_idx) < curMethod->registersSize ? \
+        (fp[(_idx)<<1]) : (assert(!"bad reg"),1969) )
+# define SET_REGISTER(_idx, _val) \
+    ( (_idx) < curMethod->registersSize ? \
+        (fp[(_idx)<<1] = (u4)(_val)) : (assert(!"bad reg"),1969) )
+# define GET_REGISTER_AS_OBJECT(_idx)       ((Object *)GET_REGISTER(_idx))
+# define SET_REGISTER_AS_OBJECT(_idx, _val) SET_REGISTER(_idx, (s4)_val)
+# define GET_REGISTER_INT(_idx) ((s4) GET_REGISTER(_idx))
+# define SET_REGISTER_INT(_idx, _val) SET_REGISTER(_idx, (s4)_val)
+# define GET_REGISTER_WIDE(_idx) \
+    ( (_idx) < curMethod->registersSize-1 ? \
+        getLongFromArrayTaint(fp, ((_idx)<<1)) : (assert(!"bad reg"),1969) )
+# define SET_REGISTER_WIDE(_idx, _val) \
+    ( (_idx) < curMethod->registersSize-1 ? \
+        putLongToArrayTaint(fp, ((_idx)<<1), (_val)) : (assert(!"bad reg"),1969) )
+# define GET_REGISTER_FLOAT(_idx) \
+    ( (_idx) < curMethod->registersSize ? \
+        (*((float*) &fp[(_idx)<<1])) : (assert(!"bad reg"),1969.0f) )
+# define SET_REGISTER_FLOAT(_idx, _val) \
+    ( (_idx) < curMethod->registersSize ? \
+        (*((float*) &fp[(_idx)<<1]) = (_val)) : (assert(!"bad reg"),1969.0f) )
+# define GET_REGISTER_DOUBLE(_idx) \
+    ( (_idx) < curMethod->registersSize-1 ? \
+        getDoubleFromArrayTaint(fp, ((_idx)<<1)) : (assert(!"bad reg"),1969.0) )
+# define SET_REGISTER_DOUBLE(_idx, _val) \
+    ( (_idx) < curMethod->registersSize-1 ? \
+        putDoubleToArrayTaint(fp, ((_idx)<<1), (_val)) : (assert(!"bad reg"),1969.0) )
+#else
+# define GET_REGISTER(_idx)                 (fp[(_idx)<<1])
+# define SET_REGISTER(_idx, _val)           (fp[(_idx)<<1] = (_val))
+# define GET_REGISTER_AS_OBJECT(_idx)       ((Object*) fp[(_idx)<<1])
+# define SET_REGISTER_AS_OBJECT(_idx, _val) (fp[(_idx)<<1] = (u4)(_val))
+# define GET_REGISTER_INT(_idx)             ((s4)GET_REGISTER(_idx))
+# define SET_REGISTER_INT(_idx, _val)       SET_REGISTER(_idx, (s4)_val)
+# define GET_REGISTER_WIDE(_idx)            getLongFromArrayTaint(fp, ((_idx)<<1))
+# define SET_REGISTER_WIDE(_idx, _val)      putLongToArrayTaint(fp, ((_idx)<<1), (_val))
+# define GET_REGISTER_FLOAT(_idx)           (*((float*) &fp[(_idx)<<1]))
+# define SET_REGISTER_FLOAT(_idx, _val)     (*((float*) &fp[(_idx)<<1]) = (_val))
+# define GET_REGISTER_DOUBLE(_idx)          getDoubleFromArrayTaint(fp, ((_idx)<<1))
+# define SET_REGISTER_DOUBLE(_idx, _val)    putDoubleToArrayTaint(fp, ((_idx)<<1), (_val))
+#endif
+/* -- End Taint Tracking version ---------------------------------- */
+#else /* no taint tracking */
 #ifdef CHECK_REGISTER_INDICES
 # define GET_REGISTER(_idx) \
     ( (_idx) < curMethod->registersSize ? \
@@ -258,6 +388,48 @@ static inline void putDoubleToArray(u4* ptr, int idx, double dval)
 # define GET_REGISTER_DOUBLE(_idx)          getDoubleFromArray(fp, (_idx))
 # define SET_REGISTER_DOUBLE(_idx, _val)    putDoubleToArray(fp, (_idx), (_val))
 #endif
+#endif /* end no taint tracking */
+
+#ifdef WITH_TAINT_TRACKING
+/* Core get and set macros */
+# define GET_REGISTER_TAINT(_idx)	     (fp[((_idx)<<1)+1])
+# define SET_REGISTER_TAINT(_idx, _val)	     (fp[((_idx)<<1)+1] = (u4)(_val))
+# define GET_REGISTER_TAINT_WIDE(_idx)       (fp[((_idx)<<1)+1])
+# define SET_REGISTER_TAINT_WIDE(_idx, _val) (fp[((_idx)<<1)+1] = \
+	                                      fp[((_idx)<<1)+3] = (u4)(_val))
+/* Alternate interfaces to help dereference register width */
+# define GET_REGISTER_TAINT_INT(_idx)	          GET_REGISTER_TAINT(_idx)
+# define SET_REGISTER_TAINT_INT(_idx, _val)       SET_REGISTER_TAINT(_idx, _val)
+# define GET_REGISTER_TAINT_FLOAT(_idx)	          GET_REGISTER_TAINT(_idx)
+# define SET_REGISTER_TAINT_FLOAT(_idx, _val)     SET_REGISTER_TAINT(_idx, _val)
+# define GET_REGISTER_TAINT_DOUBLE(_idx)          GET_REGISTER_TAINT_WIDE(_idx)
+# define SET_REGISTER_TAINT_DOUBLE(_idx, _val)    SET_REGISTER_TAINT_WIDE(_idx, _val)
+# define GET_REGISTER_TAINT_AS_OBJECT(_idx)       GET_REGISTER_TAINT(_idx)
+# define SET_REGISTER_TAINT_AS_OBJECT(_idx, _val) SET_REGISTER_TAINT(_idx, _val)
+
+/* Object Taint interface */
+# define GET_ARRAY_TAINT(_arr)		      ((_arr)->taint.tag)
+# define SET_ARRAY_TAINT(_arr, _val)	      ((_arr)->taint.tag = (u4)(_val))
+
+/* Return value taint (assumes rtaint variable is in scope */
+# define GET_RETURN_TAINT()		      (rtaint.tag)
+# define SET_RETURN_TAINT(_val)		      (rtaint.tag = (u4)(_val))
+#else
+# define GET_REGISTER_TAINT(_idx)		    ((void)0)
+# define SET_REGISTER_TAINT(_idx, _val)		    ((void)0)
+# define GET_REGISTER_TAINT_WIDE(_idx)		    ((void)0)
+# define SET_REGISTER_TAINT_WIDE(_idx, _val)	    ((void)0)
+# define GET_REGISTER_TAINT_INT(_idx)		    ((void)0)
+# define SET_REGISTER_TAINT_INT(_idx, _val)	    ((void)0)
+# define GET_REGISTER_TAINT_DOUBLE(_idx)	    ((void)0)
+# define SET_REGISTER_TAINT_DOUBLE(_idx, _val)	    ((void)0)
+# define GET_REGISTER_TAINT_AS_OBJECT(_idx)	    ((void)0)
+# define SET_REGISTER_TAINT_AS_OBJECT(_idx, _val)   ((void)0)
+# define GET_ARRAY_TAINT(_field)                    ((void)0)
+# define SET_ARRAY_TAINT(_field, _val)              ((void)0)
+# define GET_RETURN_TAINT()			    ((void)0)
+# define SET_RETURN_TAINT(_val)			    ((void)0)
+#endif
 
 /*
  * Get 16 bits from the specified offset of the program counter.  We always
@@ -485,6 +657,10 @@ GOTO_TARGET_DECL(exceptionThrown);
         ILOGV("|%s v%d,v%d", (_opname), vdst, vsrc1);                       \
         SET_REGISTER##_totype(vdst,                                         \
             GET_REGISTER##_fromtype(vsrc1));                                \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT##_totype(vdst,                                   \
+	    GET_REGISTER_TAINT##_fromtype(vsrc1));                          \
+/* endif */                                                                 \
         FINISH(1);
 
 #define HANDLE_FLOAT_TO_INT(_opcode, _opname, _fromvtype, _fromrtype,       \
@@ -510,6 +686,10 @@ GOTO_TARGET_DECL(exceptionThrown);
         else                                                                \
             result = (_tovtype) val;                                        \
         SET_REGISTER##_tortype(vdst, result);                               \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT##_tortype(vdst,                                  \
+	    GET_REGISTER_TAINT##_fromrtype(vsrc1));                         \
+/* endif */                                                                 \
     }                                                                       \
     FINISH(1);
 
@@ -519,6 +699,9 @@ GOTO_TARGET_DECL(exceptionThrown);
         vsrc1 = INST_B(inst);                                               \
         ILOGV("|int-to-%s v%d,v%d", (_opname), vdst, vsrc1);                \
         SET_REGISTER(vdst, (_type) GET_REGISTER(vsrc1));                    \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT(vdst, GET_REGISTER_TAINT(vsrc1));                \
+/* endif */                                                                 \
         FINISH(1);
 
 /* NOTE: the comparison result is always a signed 4-byte integer */
@@ -545,6 +728,9 @@ GOTO_TARGET_DECL(exceptionThrown);
             result = (_nanVal);                                             \
         ILOGV("+ result=%d", result);                                       \
         SET_REGISTER(vdst, result);                                         \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT(vdst, TAINT_CLEAR);				    \
+/* endif */                                                                 \
     }                                                                       \
     FINISH(2);
 
@@ -586,6 +772,9 @@ GOTO_TARGET_DECL(exceptionThrown);
         vsrc1 = INST_B(inst);                                               \
         ILOGV("|%s v%d,v%d", (_opname), vdst, vsrc1);                       \
         SET_REGISTER##_type(vdst, _pfx GET_REGISTER##_type(vsrc1) _sfx);    \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT##_type(vdst, GET_REGISTER_TAINT##_type(vsrc1));  \
+/* endif */                                                                 \
         FINISH(1);
 
 #define HANDLE_OP_X_INT(_opcode, _opname, _op, _chkdiv)                     \
@@ -620,6 +809,10 @@ GOTO_TARGET_DECL(exceptionThrown);
             SET_REGISTER(vdst,                                              \
                 (s4) GET_REGISTER(vsrc1) _op (s4) GET_REGISTER(vsrc2));     \
         }                                                                   \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT(vdst,                                            \
+	    (GET_REGISTER_TAINT(vsrc1)|GET_REGISTER_TAINT(vsrc2)) );        \
+/* endif */                                                                 \
     }                                                                       \
     FINISH(2);
 
@@ -634,6 +827,10 @@ GOTO_TARGET_DECL(exceptionThrown);
         ILOGV("|%s-int v%d,v%d", (_opname), vdst, vsrc1);                   \
         SET_REGISTER(vdst,                                                  \
             _cast GET_REGISTER(vsrc1) _op (GET_REGISTER(vsrc2) & 0x1f));    \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT(vdst,                                            \
+	    (GET_REGISTER_TAINT(vsrc1)|GET_REGISTER_TAINT(vsrc2)) );        \
+/* endif */                                                                 \
     }                                                                       \
     FINISH(2);
 
@@ -650,7 +847,7 @@ GOTO_TARGET_DECL(exceptionThrown);
             if ((s2) vsrc2 == 0) {                                          \
                 EXPORT_PC();                                                \
                 dvmThrowArithmeticException("divide by zero");              \
-                GOTO_exceptionThrown();                                     \
+                GOTO_exceptionThrown();                                      \
             }                                                               \
             if ((u4)firstVal == 0x80000000 && ((s2) vsrc2) == -1) {         \
                 /* won't generate /lit16 instr for this; check anyway */    \
@@ -666,6 +863,9 @@ GOTO_TARGET_DECL(exceptionThrown);
             /* non-div/rem case */                                          \
             SET_REGISTER(vdst, GET_REGISTER(vsrc1) _op (s2) vsrc2);         \
         }                                                                   \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT(vdst, GET_REGISTER_TAINT(vsrc1));                \
+/* endif */                                                                 \
         FINISH(2);
 
 #define HANDLE_OP_X_INT_LIT8(_opcode, _opname, _op, _chkdiv)                \
@@ -699,6 +899,9 @@ GOTO_TARGET_DECL(exceptionThrown);
             SET_REGISTER(vdst,                                              \
                 (s4) GET_REGISTER(vsrc1) _op (s1) vsrc2);                   \
         }                                                                   \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT(vdst, GET_REGISTER_TAINT(vsrc1));                \
+/* endif */                                                                 \
     }                                                                       \
     FINISH(2);
 
@@ -714,6 +917,9 @@ GOTO_TARGET_DECL(exceptionThrown);
             (_opname), vdst, vsrc1, vsrc2);                                 \
         SET_REGISTER(vdst,                                                  \
             _cast GET_REGISTER(vsrc1) _op (vsrc2 & 0x1f));                  \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT(vdst, GET_REGISTER_TAINT(vsrc1));                \
+/* endif */                                                                 \
     }                                                                       \
     FINISH(2);
 
@@ -744,6 +950,10 @@ GOTO_TARGET_DECL(exceptionThrown);
             SET_REGISTER(vdst,                                              \
                 (s4) GET_REGISTER(vdst) _op (s4) GET_REGISTER(vsrc1));      \
         }                                                                   \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT(vdst,                                            \
+	    (GET_REGISTER_TAINT(vdst)|GET_REGISTER_TAINT(vsrc1)) );         \
+/* endif */                                                                 \
         FINISH(1);
 
 #define HANDLE_OP_SHX_INT_2ADDR(_opcode, _opname, _cast, _op)               \
@@ -753,6 +963,10 @@ GOTO_TARGET_DECL(exceptionThrown);
         ILOGV("|%s-int-2addr v%d,v%d", (_opname), vdst, vsrc1);             \
         SET_REGISTER(vdst,                                                  \
             _cast GET_REGISTER(vdst) _op (GET_REGISTER(vsrc1) & 0x1f));     \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT(vdst,                                            \
+	    (GET_REGISTER_TAINT(vdst)|GET_REGISTER_TAINT(vsrc1)) );         \
+/* endif */                                                                 \
         FINISH(1);
 
 #define HANDLE_OP_X_LONG(_opcode, _opname, _op, _chkdiv)                    \
@@ -788,6 +1002,10 @@ GOTO_TARGET_DECL(exceptionThrown);
             SET_REGISTER_WIDE(vdst,                                         \
                 (s8) GET_REGISTER_WIDE(vsrc1) _op (s8) GET_REGISTER_WIDE(vsrc2)); \
         }                                                                   \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT_WIDE(vdst,                                       \
+	   (GET_REGISTER_TAINT_WIDE(vsrc1)|GET_REGISTER_TAINT_WIDE(vsrc2)));\
+/* endif */                                                                 \
     }                                                                       \
     FINISH(2);
 
@@ -802,6 +1020,10 @@ GOTO_TARGET_DECL(exceptionThrown);
         ILOGV("|%s-long v%d,v%d,v%d", (_opname), vdst, vsrc1, vsrc2);       \
         SET_REGISTER_WIDE(vdst,                                             \
             _cast GET_REGISTER_WIDE(vsrc1) _op (GET_REGISTER(vsrc2) & 0x3f)); \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT_WIDE(vdst,                                       \
+	   (GET_REGISTER_TAINT_WIDE(vsrc1)|GET_REGISTER_TAINT_WIDE(vsrc2)));\
+/* endif */                                                                 \
     }                                                                       \
     FINISH(2);
 
@@ -834,6 +1056,10 @@ GOTO_TARGET_DECL(exceptionThrown);
             SET_REGISTER_WIDE(vdst,                                         \
                 (s8) GET_REGISTER_WIDE(vdst) _op (s8)GET_REGISTER_WIDE(vsrc1));\
         }                                                                   \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT_WIDE(vdst,                                       \
+	    (GET_REGISTER_TAINT_WIDE(vdst)|GET_REGISTER_TAINT_WIDE(vsrc1)));\
+/* endif */                                                                 \
         FINISH(1);
 
 #define HANDLE_OP_SHX_LONG_2ADDR(_opcode, _opname, _cast, _op)              \
@@ -843,6 +1069,10 @@ GOTO_TARGET_DECL(exceptionThrown);
         ILOGV("|%s-long-2addr v%d,v%d", (_opname), vdst, vsrc1);            \
         SET_REGISTER_WIDE(vdst,                                             \
             _cast GET_REGISTER_WIDE(vdst) _op (GET_REGISTER(vsrc1) & 0x3f)); \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT_WIDE(vdst,                                       \
+	    (GET_REGISTER_TAINT_WIDE(vdst)|GET_REGISTER_TAINT_WIDE(vsrc1)));\
+/* endif */                                                                 \
         FINISH(1);
 
 #define HANDLE_OP_X_FLOAT(_opcode, _opname, _op)                            \
@@ -856,6 +1086,10 @@ GOTO_TARGET_DECL(exceptionThrown);
         ILOGV("|%s-float v%d,v%d,v%d", (_opname), vdst, vsrc1, vsrc2);      \
         SET_REGISTER_FLOAT(vdst,                                            \
             GET_REGISTER_FLOAT(vsrc1) _op GET_REGISTER_FLOAT(vsrc2));       \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT_FLOAT(vdst,                                      \
+	    (GET_REGISTER_TAINT_FLOAT(vsrc1)|GET_REGISTER_TAINT_FLOAT(vsrc2)));\
+/* endif */                                                                 \
     }                                                                       \
     FINISH(2);
 
@@ -870,6 +1104,10 @@ GOTO_TARGET_DECL(exceptionThrown);
         ILOGV("|%s-double v%d,v%d,v%d", (_opname), vdst, vsrc1, vsrc2);     \
         SET_REGISTER_DOUBLE(vdst,                                           \
             GET_REGISTER_DOUBLE(vsrc1) _op GET_REGISTER_DOUBLE(vsrc2));     \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT_DOUBLE(vdst,                                     \
+	    (GET_REGISTER_TAINT_DOUBLE(vsrc1)|GET_REGISTER_TAINT_DOUBLE(vsrc2)));\
+/* endif */                                                                 \
     }                                                                       \
     FINISH(2);
 
@@ -880,6 +1118,10 @@ GOTO_TARGET_DECL(exceptionThrown);
         ILOGV("|%s-float-2addr v%d,v%d", (_opname), vdst, vsrc1);           \
         SET_REGISTER_FLOAT(vdst,                                            \
             GET_REGISTER_FLOAT(vdst) _op GET_REGISTER_FLOAT(vsrc1));        \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT_FLOAT(vdst,                                      \
+	    (GET_REGISTER_TAINT_FLOAT(vdst)|GET_REGISTER_TAINT_FLOAT(vsrc1)));\
+/* endif */                                                                 \
         FINISH(1);
 
 #define HANDLE_OP_X_DOUBLE_2ADDR(_opcode, _opname, _op)                     \
@@ -889,6 +1131,10 @@ GOTO_TARGET_DECL(exceptionThrown);
         ILOGV("|%s-double-2addr v%d,v%d", (_opname), vdst, vsrc1);          \
         SET_REGISTER_DOUBLE(vdst,                                           \
             GET_REGISTER_DOUBLE(vdst) _op GET_REGISTER_DOUBLE(vsrc1));      \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT_DOUBLE(vdst,                                     \
+	    (GET_REGISTER_TAINT_DOUBLE(vdst)|GET_REGISTER_TAINT_DOUBLE(vsrc1)));\
+/* endif */                                                                 \
         FINISH(1);
 
 #define HANDLE_OP_AGET(_opcode, _opname, _type, _regsize)                   \
@@ -913,6 +1159,11 @@ GOTO_TARGET_DECL(exceptionThrown);
         SET_REGISTER##_regsize(vdst,                                        \
             ((_type*)(void*)arrayObj->contents)[GET_REGISTER(vsrc2)]);      \
         ILOGV("+ AGET[%d]=%#x", GET_REGISTER(vsrc2), GET_REGISTER(vdst));   \
+/* ifdef WITH_TAINT_TRACKING */						    \
+	SET_REGISTER_TAINT##_regsize(vdst,                                  \
+	    (GET_ARRAY_TAINT(arrayObj)|GET_REGISTER_TAINT(vsrc2)));         \
+/* endif */								    \
+        ILOGV("+ AGET[%d]=0x%x", GET_REGISTER(vsrc2), GET_REGISTER(vdst));  \
     }                                                                       \
     FINISH(2);
 
@@ -938,6 +1189,11 @@ GOTO_TARGET_DECL(exceptionThrown);
         ILOGV("+ APUT[%d]=0x%08x", GET_REGISTER(vsrc2), GET_REGISTER(vdst));\
         ((_type*)(void*)arrayObj->contents)[GET_REGISTER(vsrc2)] =          \
             GET_REGISTER##_regsize(vdst);                                   \
+/* ifdef WITH_TAINT_TRACKING */						    \
+	SET_ARRAY_TAINT(arrayObj,                                           \
+		(GET_ARRAY_TAINT(arrayObj) |                                \
+		 GET_REGISTER_TAINT##_regsize(vdst)) );                     \
+/* endif */								    \
     }                                                                       \
     FINISH(2);
 
@@ -981,6 +1237,11 @@ GOTO_TARGET_DECL(exceptionThrown);
             dvmGetField##_ftype(obj, ifield->byteOffset));                  \
         ILOGV("+ IGET '%s'=0x%08llx", ifield->field.name,                   \
             (u8) GET_REGISTER##_regsize(vdst));                             \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+	SET_REGISTER_TAINT##_regsize(vdst,                                  \
+	    (GET_REGISTER_TAINT(vsrc1)|                                     \
+	     dvmGetFieldTaint##_ftype(obj,ifield->byteOffset)) );           \
+/* endif */                                                                 \
     }                                                                       \
     FINISH(2);
 
@@ -999,6 +1260,13 @@ GOTO_TARGET_DECL(exceptionThrown);
         SET_REGISTER##_regsize(vdst, dvmGetField##_ftype(obj, ref));        \
         ILOGV("+ IGETQ %d=0x%08llx", ref,                                   \
             (u8) GET_REGISTER##_regsize(vdst));                             \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+	/*TLOGW("|IGETQ not supported by taint tracking!!!");*/             \
+	/* compile flag WITH_TAINT_ODEX controls this now */                \
+	SET_REGISTER_TAINT##_regsize(vdst,                                  \
+	    (GET_REGISTER_TAINT(vsrc1)|                                     \
+	     dvmGetFieldTaint##_ftype(obj,ref)) );                          \
+/* endif */                                                                 \
     }                                                                       \
     FINISH(2);
 
@@ -1025,6 +1293,10 @@ GOTO_TARGET_DECL(exceptionThrown);
             GET_REGISTER##_regsize(vdst));                                  \
         ILOGV("+ IPUT '%s'=0x%08llx", ifield->field.name,                   \
             (u8) GET_REGISTER##_regsize(vdst));                             \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+	dvmSetFieldTaint##_ftype(obj, ifield->byteOffset,                   \
+		GET_REGISTER_TAINT##_regsize(vdst));                        \
+/* endif */                                                                 \
     }                                                                       \
     FINISH(2);
 
@@ -1043,6 +1315,12 @@ GOTO_TARGET_DECL(exceptionThrown);
         dvmSetField##_ftype(obj, ref, GET_REGISTER##_regsize(vdst));        \
         ILOGV("+ IPUTQ %d=0x%08llx", ref,                                   \
             (u8) GET_REGISTER##_regsize(vdst));                             \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+	/*TLOGW("|IPUTQ not supported by taint tracking!!!");*/             \
+	/* compile flag WITH_TAINT_ODEX controls this now */                \
+	dvmSetFieldTaint##_ftype(obj, ref,                                  \
+		GET_REGISTER_TAINT##_regsize(vdst));                        \
+/* endif */                                                                 \
     }                                                                       \
     FINISH(2);
 
@@ -1074,6 +1352,9 @@ GOTO_TARGET_DECL(exceptionThrown);
         SET_REGISTER##_regsize(vdst, dvmGetStaticField##_ftype(sfield));    \
         ILOGV("+ SGET '%s'=0x%08llx",                                       \
             sfield->field.name, (u8)GET_REGISTER##_regsize(vdst));          \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+	SET_REGISTER_TAINT##_regsize(vdst, dvmGetStaticFieldTaint##_ftype(sfield));\
+/* endif */                                                                 \
     }                                                                       \
     FINISH(2);
 
@@ -1097,9 +1378,14 @@ GOTO_TARGET_DECL(exceptionThrown);
         dvmSetStaticField##_ftype(sfield, GET_REGISTER##_regsize(vdst));    \
         ILOGV("+ SPUT '%s'=0x%08llx",                                       \
             sfield->field.name, (u8)GET_REGISTER##_regsize(vdst));          \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+	dvmSetStaticFieldTaint##_ftype(sfield,                              \
+		GET_REGISTER_TAINT##_regsize(vdst));                        \
+/* endif */                                                                 \
     }                                                                       \
     FINISH(2);
 
+
 /* File: portable/entry.cpp */
 /*
  * Main interpreter loop.
@@ -1113,6 +1399,9 @@ void dvmInterpretPortable(Thread* self)
 #endif
     DvmDex* methodClassDex;     // curMethod->clazz->pDvmDex
     JValue retval;
+#ifdef WITH_TAINT_TRACKING
+    Taint rtaint;
+#endif
 
     /* core state */
     const Method* curMethod;    // method we're interpreting
@@ -1134,6 +1423,9 @@ void dvmInterpretPortable(Thread* self)
     pc = self->interpSave.pc;
     fp = self->interpSave.curFrame;
     retval = self->interpSave.retval;   /* only need for kInterpEntryReturn? */
+#ifdef WITH_TAINT_TRACKING
+    rtaint = self->interpSave.rtaint;
+#endif
 
     methodClassDex = curMethod->clazz->pDvmDex;
 
@@ -1178,6 +1470,9 @@ HANDLE_OPCODE(OP_MOVE /*vA, vB*/)
         (INST_INST(inst) == OP_MOVE) ? "" : "-object", vdst, vsrc1,
         kSpacing, vdst, GET_REGISTER(vsrc1));
     SET_REGISTER(vdst, GET_REGISTER(vsrc1));
+/* ifdef WITH_TAINT_TRACKING */
+    SET_REGISTER_TAINT(vdst, GET_REGISTER_TAINT(vsrc1));
+/* endif */
     FINISH(1);
 OP_END
 
@@ -1189,6 +1484,9 @@ HANDLE_OPCODE(OP_MOVE_FROM16 /*vAA, vBBBB*/)
         (INST_INST(inst) == OP_MOVE_FROM16) ? "" : "-object", vdst, vsrc1,
         kSpacing, vdst, GET_REGISTER(vsrc1));
     SET_REGISTER(vdst, GET_REGISTER(vsrc1));
+/* ifdef WITH_TAINT_TRACKING */
+    SET_REGISTER_TAINT(vdst, GET_REGISTER_TAINT(vsrc1));
+/* endif */
     FINISH(2);
 OP_END
 
@@ -1200,6 +1498,9 @@ HANDLE_OPCODE(OP_MOVE_16 /*vAAAA, vBBBB*/)
         (INST_INST(inst) == OP_MOVE_16) ? "" : "-object", vdst, vsrc1,
         kSpacing, vdst, GET_REGISTER(vsrc1));
     SET_REGISTER(vdst, GET_REGISTER(vsrc1));
+/* ifdef WITH_TAINT_TRACKING */
+    SET_REGISTER_TAINT(vdst, GET_REGISTER_TAINT(vsrc1));
+/* endif */
     FINISH(3);
 OP_END
 
@@ -1212,6 +1513,9 @@ HANDLE_OPCODE(OP_MOVE_WIDE /*vA, vB*/)
     ILOGV("|move-wide v%d,v%d %s(v%d=0x%08llx)", vdst, vsrc1,
         kSpacing+5, vdst, GET_REGISTER_WIDE(vsrc1));
     SET_REGISTER_WIDE(vdst, GET_REGISTER_WIDE(vsrc1));
+/* ifdef WITH_TAINT_TRACKING */
+    SET_REGISTER_TAINT_WIDE(vdst, GET_REGISTER_TAINT_WIDE(vsrc1));
+/* endif */
     FINISH(1);
 OP_END
 
@@ -1222,6 +1526,9 @@ HANDLE_OPCODE(OP_MOVE_WIDE_FROM16 /*vAA, vBBBB*/)
     ILOGV("|move-wide/from16 v%d,v%d  (v%d=0x%08llx)", vdst, vsrc1,
         vdst, GET_REGISTER_WIDE(vsrc1));
     SET_REGISTER_WIDE(vdst, GET_REGISTER_WIDE(vsrc1));
+/* ifdef WITH_TAINT_TRACKING */
+    SET_REGISTER_TAINT_WIDE(vdst, GET_REGISTER_TAINT_WIDE(vsrc1));
+/* endif */
     FINISH(2);
 OP_END
 
@@ -1232,6 +1539,9 @@ HANDLE_OPCODE(OP_MOVE_WIDE_16 /*vAAAA, vBBBB*/)
     ILOGV("|move-wide/16 v%d,v%d %s(v%d=0x%08llx)", vdst, vsrc1,
         kSpacing+8, vdst, GET_REGISTER_WIDE(vsrc1));
     SET_REGISTER_WIDE(vdst, GET_REGISTER_WIDE(vsrc1));
+/* ifdef WITH_TAINT_TRACKING */
+    SET_REGISTER_TAINT_WIDE(vdst, GET_REGISTER_TAINT_WIDE(vsrc1));
+/* endif */
     FINISH(3);
 OP_END
 
@@ -1244,6 +1554,9 @@ HANDLE_OPCODE(OP_MOVE_OBJECT /*vA, vB*/)
         (INST_INST(inst) == OP_MOVE) ? "" : "-object", vdst, vsrc1,
         kSpacing, vdst, GET_REGISTER(vsrc1));
     SET_REGISTER(vdst, GET_REGISTER(vsrc1));
+/* ifdef WITH_TAINT_TRACKING */
+    SET_REGISTER_TAINT(vdst, GET_REGISTER_TAINT(vsrc1));
+/* endif */
     FINISH(1);
 OP_END
 
@@ -1257,6 +1570,9 @@ HANDLE_OPCODE(OP_MOVE_OBJECT_FROM16 /*vAA, vBBBB*/)
         (INST_INST(inst) == OP_MOVE_FROM16) ? "" : "-object", vdst, vsrc1,
         kSpacing, vdst, GET_REGISTER(vsrc1));
     SET_REGISTER(vdst, GET_REGISTER(vsrc1));
+/* ifdef WITH_TAINT_TRACKING */
+    SET_REGISTER_TAINT(vdst, GET_REGISTER_TAINT(vsrc1));
+/* endif */
     FINISH(2);
 OP_END
 
@@ -1270,6 +1586,9 @@ HANDLE_OPCODE(OP_MOVE_OBJECT_16 /*vAAAA, vBBBB*/)
         (INST_INST(inst) == OP_MOVE_16) ? "" : "-object", vdst, vsrc1,
         kSpacing, vdst, GET_REGISTER(vsrc1));
     SET_REGISTER(vdst, GET_REGISTER(vsrc1));
+/* ifdef WITH_TAINT_TRACKING */
+    SET_REGISTER_TAINT(vdst, GET_REGISTER_TAINT(vsrc1));
+/* endif */
     FINISH(3);
 OP_END
 
@@ -1281,6 +1600,9 @@ HANDLE_OPCODE(OP_MOVE_RESULT /*vAA*/)
          (INST_INST(inst) == OP_MOVE_RESULT) ? "" : "-object",
          vdst, kSpacing+4, vdst,retval.i);
     SET_REGISTER(vdst, retval.i);
+/* ifdef WITH_TAINT_TRACKING */
+    SET_REGISTER_TAINT(vdst, GET_RETURN_TAINT());
+/* endif */
     FINISH(1);
 OP_END
 
@@ -1289,6 +1611,9 @@ HANDLE_OPCODE(OP_MOVE_RESULT_WIDE /*vAA*/)
     vdst = INST_AA(inst);
     ILOGV("|move-result-wide v%d %s(0x%08llx)", vdst, kSpacing, retval.j);
     SET_REGISTER_WIDE(vdst, retval.j);
+/* ifdef WITH_TAINT_TRACKING */
+    SET_REGISTER_TAINT_WIDE(vdst, GET_RETURN_TAINT());
+/* endif */
     FINISH(1);
 OP_END
 
@@ -1300,6 +1625,9 @@ HANDLE_OPCODE(OP_MOVE_RESULT_OBJECT /*vAA*/)
          (INST_INST(inst) == OP_MOVE_RESULT) ? "" : "-object",
          vdst, kSpacing+4, vdst,retval.i);
     SET_REGISTER(vdst, retval.i);
+/* ifdef WITH_TAINT_TRACKING */
+    SET_REGISTER_TAINT(vdst, GET_RETURN_TAINT());
+/* endif */
     FINISH(1);
 OP_END
 
@@ -1310,6 +1638,9 @@ HANDLE_OPCODE(OP_MOVE_EXCEPTION /*vAA*/)
     ILOGV("|move-exception v%d", vdst);
     assert(self->exception != NULL);
     SET_REGISTER(vdst, (u4)self->exception);
+/* ifdef WITH_TAINT_TRACKING */
+    SET_REGISTER_TAINT(vdst, TAINT_CLEAR);
+/* endif */
     dvmClearException(self);
     FINISH(1);
 OP_END
@@ -1320,6 +1651,9 @@ HANDLE_OPCODE(OP_RETURN_VOID /**/)
 #ifndef NDEBUG
     retval.j = 0xababababULL;    // placate valgrind
 #endif
+/* ifdef WITH_TAINT_TRACKING */
+    SET_RETURN_TAINT(TAINT_CLEAR);
+/* endif */
     GOTO_returnFromMethod();
 OP_END
 
@@ -1329,6 +1663,9 @@ HANDLE_OPCODE(OP_RETURN /*vAA*/)
     ILOGV("|return%s v%d",
         (INST_INST(inst) == OP_RETURN) ? "" : "-object", vsrc1);
     retval.i = GET_REGISTER(vsrc1);
+/* ifdef WITH_TAINT_TRACKING */
+    SET_RETURN_TAINT(GET_REGISTER_TAINT(vsrc1));
+/* endif */
     GOTO_returnFromMethod();
 OP_END
 
@@ -1337,6 +1674,9 @@ HANDLE_OPCODE(OP_RETURN_WIDE /*vAA*/)
     vsrc1 = INST_AA(inst);
     ILOGV("|return-wide v%d", vsrc1);
     retval.j = GET_REGISTER_WIDE(vsrc1);
+/* ifdef WITH_TAINT_TRACKING */
+    SET_RETURN_TAINT(GET_REGISTER_TAINT_WIDE(vsrc1));
+/* endif */
     GOTO_returnFromMethod();
 OP_END
 
@@ -1347,6 +1687,9 @@ HANDLE_OPCODE(OP_RETURN_OBJECT /*vAA*/)
     ILOGV("|return%s v%d",
         (INST_INST(inst) == OP_RETURN) ? "" : "-object", vsrc1);
     retval.i = GET_REGISTER(vsrc1);
+/* ifdef WITH_TAINT_TRACKING */
+    SET_RETURN_TAINT(GET_REGISTER_TAINT(vsrc1));
+/* endif */
     GOTO_returnFromMethod();
 OP_END
 
@@ -1360,6 +1703,9 @@ HANDLE_OPCODE(OP_CONST_4 /*vA, #+B*/)
         tmp = (s4) (INST_B(inst) << 28) >> 28;  // sign extend 4-bit value
         ILOGV("|const/4 v%d,#0x%02x", vdst, (s4)tmp);
         SET_REGISTER(vdst, tmp);
+/* ifdef WITH_TAINT_TRACKING */
+	SET_REGISTER_TAINT(vdst, TAINT_CLEAR);
+/* endif */
     }
     FINISH(1);
 OP_END
@@ -1370,6 +1716,9 @@ HANDLE_OPCODE(OP_CONST_16 /*vAA, #+BBBB*/)
     vsrc1 = FETCH(1);
     ILOGV("|const/16 v%d,#0x%04x", vdst, (s2)vsrc1);
     SET_REGISTER(vdst, (s2) vsrc1);
+/* ifdef WITH_TAINT_TRACKING */
+    SET_REGISTER_TAINT(vdst, TAINT_CLEAR);
+/* endif */
     FINISH(2);
 OP_END
 
@@ -1383,6 +1732,9 @@ HANDLE_OPCODE(OP_CONST /*vAA, #+BBBBBBBB*/)
         tmp |= (u4)FETCH(2) << 16;
         ILOGV("|const v%d,#0x%08x", vdst, tmp);
         SET_REGISTER(vdst, tmp);
+/* ifdef WITH_TAINT_TRACKING */
+	SET_REGISTER_TAINT(vdst, TAINT_CLEAR);
+/* endif */
     }
     FINISH(3);
 OP_END
@@ -1393,6 +1745,9 @@ HANDLE_OPCODE(OP_CONST_HIGH16 /*vAA, #+BBBB0000*/)
     vsrc1 = FETCH(1);
     ILOGV("|const/high16 v%d,#0x%04x0000", vdst, vsrc1);
     SET_REGISTER(vdst, vsrc1 << 16);
+/* ifdef WITH_TAINT_TRACKING */
+    SET_REGISTER_TAINT(vdst, TAINT_CLEAR);
+/* endif */
     FINISH(2);
 OP_END
 
@@ -1402,6 +1757,9 @@ HANDLE_OPCODE(OP_CONST_WIDE_16 /*vAA, #+BBBB*/)
     vsrc1 = FETCH(1);
     ILOGV("|const-wide/16 v%d,#0x%04x", vdst, (s2)vsrc1);
     SET_REGISTER_WIDE(vdst, (s2)vsrc1);
+/* ifdef WITH_TAINT_TRACKING */
+    SET_REGISTER_TAINT_WIDE(vdst, TAINT_CLEAR);
+/* endif */
     FINISH(2);
 OP_END
 
@@ -1415,6 +1773,9 @@ HANDLE_OPCODE(OP_CONST_WIDE_32 /*vAA, #+BBBBBBBB*/)
         tmp |= (u4)FETCH(2) << 16;
         ILOGV("|const-wide/32 v%d,#0x%08x", vdst, tmp);
         SET_REGISTER_WIDE(vdst, (s4) tmp);
+/* ifdef WITH_TAINT_TRACKING */
+	SET_REGISTER_TAINT_WIDE(vdst, TAINT_CLEAR);
+/* endif */
     }
     FINISH(3);
 OP_END
@@ -1431,6 +1792,9 @@ HANDLE_OPCODE(OP_CONST_WIDE /*vAA, #+BBBBBBBBBBBBBBBB*/)
         tmp |= (u8)FETCH(4) << 48;
         ILOGV("|const-wide v%d,#0x%08llx", vdst, tmp);
         SET_REGISTER_WIDE(vdst, tmp);
+/* ifdef WITH_TAINT_TRACKING */
+	SET_REGISTER_TAINT_WIDE(vdst, TAINT_CLEAR);
+/* endif */
     }
     FINISH(5);
 OP_END
@@ -1441,6 +1805,9 @@ HANDLE_OPCODE(OP_CONST_WIDE_HIGH16 /*vAA, #+BBBB000000000000*/)
     vsrc1 = FETCH(1);
     ILOGV("|const-wide/high16 v%d,#0x%04x000000000000", vdst, vsrc1);
     SET_REGISTER_WIDE(vdst, ((u8) vsrc1) << 48);
+/* ifdef WITH_TAINT_TRACKING */
+    SET_REGISTER_TAINT_WIDE(vdst, TAINT_CLEAR);
+/* endif */
     FINISH(2);
 OP_END
 
@@ -1460,6 +1827,9 @@ HANDLE_OPCODE(OP_CONST_STRING /*vAA, string@BBBB*/)
                 GOTO_exceptionThrown();
         }
         SET_REGISTER(vdst, (u4) strObj);
+/* ifdef WITH_TAINT_TRACKING */
+	SET_REGISTER_TAINT(vdst, TAINT_CLEAR);
+/* endif */
     }
     FINISH(2);
 OP_END
@@ -1482,6 +1852,9 @@ HANDLE_OPCODE(OP_CONST_STRING_JUMBO /*vAA, string@BBBBBBBB*/)
                 GOTO_exceptionThrown();
         }
         SET_REGISTER(vdst, (u4) strObj);
+/* ifdef WITH_TAINT_TRACKING */
+	SET_REGISTER_TAINT(vdst, TAINT_CLEAR);
+/* endif */
     }
     FINISH(3);
 OP_END
@@ -1502,6 +1875,9 @@ HANDLE_OPCODE(OP_CONST_CLASS /*vAA, class@BBBB*/)
                 GOTO_exceptionThrown();
         }
         SET_REGISTER(vdst, (u4) clazz);
+/* ifdef WITH_TAINT_TRACKING */
+	SET_REGISTER_TAINT(vdst, TAINT_CLEAR);
+/* endif */
     }
     FINISH(2);
 OP_END
@@ -1603,6 +1979,9 @@ HANDLE_OPCODE(OP_INSTANCE_OF /*vA, vB, class@CCCC*/)
         obj = (Object*)GET_REGISTER(vsrc1);
         if (obj == NULL) {
             SET_REGISTER(vdst, 0);
+/* ifdef WITH_TAINT_TRACKING */
+	    SET_REGISTER_TAINT(vdst, TAINT_CLEAR);
+/* endif */
         } else {
 #if defined(WITH_EXTRA_OBJECT_VALIDATION)
             if (!checkForNullExportPC(obj, fp, pc))
@@ -1616,6 +1995,9 @@ HANDLE_OPCODE(OP_INSTANCE_OF /*vA, vB, class@CCCC*/)
                     GOTO_exceptionThrown();
             }
             SET_REGISTER(vdst, dvmInstanceof(obj->clazz, clazz));
+/* ifdef WITH_TAINT_TRACKING */
+	    SET_REGISTER_TAINT(vdst, TAINT_CLEAR);
+/* endif */
         }
     }
     FINISH(2);
@@ -1634,6 +2016,9 @@ HANDLE_OPCODE(OP_ARRAY_LENGTH /*vA, vB*/)
             GOTO_exceptionThrown();
         /* verifier guarantees this is an array reference */
         SET_REGISTER(vdst, arrayObj->length);
+/* ifdef WITH_TAINT_TRACKING */
+	SET_REGISTER_TAINT(vdst, TAINT_CLEAR);
+/* endif */
     }
     FINISH(1);
 OP_END
@@ -1684,6 +2069,9 @@ HANDLE_OPCODE(OP_NEW_INSTANCE /*vAA, class@BBBB*/)
         if (newObj == NULL)
             GOTO_exceptionThrown();
         SET_REGISTER(vdst, (u4) newObj);
+/* ifdef WITH_TAINT_TRACKING */
+        SET_REGISTER_TAINT(vdst, TAINT_CLEAR);
+/* endif */
     }
     FINISH(2);
 OP_END
@@ -1721,6 +2109,9 @@ HANDLE_OPCODE(OP_NEW_ARRAY /*vA, vB, class@CCCC*/)
         if (newArray == NULL)
             GOTO_exceptionThrown();
         SET_REGISTER(vdst, (u4) newArray);
+/* ifdef WITH_TAINT_TRACKING */
+        SET_REGISTER_TAINT(vdst, TAINT_CLEAR);
+/* endif */
     }
     FINISH(2);
 OP_END
@@ -2037,7 +2428,7 @@ HANDLE_OPCODE(OP_APUT_OBJECT /*vAA, vBB, vCC*/)
         arrayInfo = FETCH(1);
         vsrc1 = arrayInfo & 0xff;   /* BB: array ptr */
         vsrc2 = arrayInfo >> 8;     /* CC: index */
-        ILOGV("|aput%s v%d,v%d,v%d", "-object", vdst, vsrc1, vsrc2);
+        ALOGV("|aput%s v%d,v%d,v%d", "-object", vdst, vsrc1, vsrc2);
         arrayObj = (ArrayObject*) GET_REGISTER(vsrc1);
         if (!checkForNull((Object*) arrayObj))
             GOTO_exceptionThrown();
@@ -2062,6 +2453,11 @@ HANDLE_OPCODE(OP_APUT_OBJECT /*vAA, vBB, vCC*/)
         dvmSetObjectArrayElement(arrayObj,
                                  GET_REGISTER(vsrc2),
                                  (Object *)GET_REGISTER(vdst));
+/* ifdef WITH_TAINT_TRACKING */
+	SET_ARRAY_TAINT(arrayObj,
+		(GET_ARRAY_TAINT(arrayObj) |
+		 GET_REGISTER_TAINT(vdst)) );
+/* endif */
     }
     FINISH(2);
 OP_END
@@ -2470,6 +2866,12 @@ HANDLE_OPCODE(OP_REM_FLOAT /*vAA, vBB, vCC*/)
         ILOGV("|%s-float v%d,v%d,v%d", "mod", vdst, vsrc1, vsrc2);
         SET_REGISTER_FLOAT(vdst,
             fmodf(GET_REGISTER_FLOAT(vsrc1), GET_REGISTER_FLOAT(vsrc2)));
+/* ifdef WITH_TAINT_TRACKING */
+#ifdef WITH_TAINT_TRACKING
+        SET_REGISTER_TAINT_FLOAT(vdst,
+	    (GET_REGISTER_TAINT_FLOAT(vsrc1)|GET_REGISTER_TAINT_FLOAT(vsrc2)));
+#endif /*WITH_TAINT_TRACKING*/
+/* endif */
     }
     FINISH(2);
 OP_END
@@ -2501,6 +2903,10 @@ HANDLE_OPCODE(OP_REM_DOUBLE /*vAA, vBB, vCC*/)
         ILOGV("|%s-double v%d,v%d,v%d", "mod", vdst, vsrc1, vsrc2);
         SET_REGISTER_DOUBLE(vdst,
             fmod(GET_REGISTER_DOUBLE(vsrc1), GET_REGISTER_DOUBLE(vsrc2)));
+/* ifdef WITH_TAINT_TRACKING */
+        SET_REGISTER_TAINT_DOUBLE(vdst,
+	    (GET_REGISTER_TAINT_DOUBLE(vsrc1)|GET_REGISTER_TAINT_DOUBLE(vsrc2)));
+/* endif */
     }
     FINISH(2);
 OP_END
@@ -2616,6 +3022,12 @@ HANDLE_OPCODE(OP_REM_FLOAT_2ADDR /*vA, vB*/)
     ILOGV("|%s-float-2addr v%d,v%d", "mod", vdst, vsrc1);
     SET_REGISTER_FLOAT(vdst,
         fmodf(GET_REGISTER_FLOAT(vdst), GET_REGISTER_FLOAT(vsrc1)));
+/* ifdef WITH_TAINT_TRACKING */
+#ifdef WITH_TAINT_TRACKING
+        SET_REGISTER_TAINT_FLOAT(vdst,
+	    (GET_REGISTER_TAINT_FLOAT(vdst)|GET_REGISTER_TAINT_FLOAT(vsrc1)));
+#endif /*WITH_TAINT_TRACKING*/
+/* endif */
     FINISH(1);
 OP_END
 
@@ -2642,6 +3054,10 @@ HANDLE_OPCODE(OP_REM_DOUBLE_2ADDR /*vA, vB*/)
     ILOGV("|%s-double-2addr v%d,v%d", "mod", vdst, vsrc1);
     SET_REGISTER_DOUBLE(vdst,
         fmod(GET_REGISTER_DOUBLE(vdst), GET_REGISTER_DOUBLE(vsrc1)));
+/* ifdef WITH_TAINT_TRACKING */
+        SET_REGISTER_TAINT_DOUBLE(vdst,
+	    (GET_REGISTER_TAINT_DOUBLE(vdst)|GET_REGISTER_TAINT_DOUBLE(vsrc1)));
+/* endif */
     FINISH(1);
 OP_END
 
@@ -2657,6 +3073,9 @@ HANDLE_OPCODE(OP_RSUB_INT /*vA, vB, #+CCCC*/)
         vsrc2 = FETCH(1);
         ILOGV("|rsub-int v%d,v%d,#+0x%04x", vdst, vsrc1, vsrc2);
         SET_REGISTER(vdst, (s2) vsrc2 - (s4) GET_REGISTER(vsrc1));
+/* ifdef WITH_TAINT_TRACKING */
+        SET_REGISTER_TAINT(vdst, GET_REGISTER_TAINT(vsrc1));
+/* endif */
     }
     FINISH(2);
 OP_END
@@ -2699,6 +3118,9 @@ HANDLE_OPCODE(OP_RSUB_INT_LIT8 /*vAA, vBB, #+CC*/)
         vsrc2 = litInfo >> 8;
         ILOGV("|%s-int/lit8 v%d,v%d,#+0x%02x", "rsub", vdst, vsrc1, vsrc2);
         SET_REGISTER(vdst, (s1) vsrc2 - (s4) GET_REGISTER(vsrc1));
+/* ifdef WITH_TAINT_TRACKING */
+        SET_REGISTER_TAINT(vdst, GET_REGISTER_TAINT(vsrc1));
+/* endif */
     }
     FINISH(2);
 OP_END
@@ -2832,6 +3254,11 @@ HANDLE_OPCODE(OP_EXECUTE_INLINE /*vB, {vD, vE, vF, vG}, inline@CCCC*/)
         u4 arg0, arg1, arg2, arg3;
         arg0 = arg1 = arg2 = arg3 = 0;
 
+#ifdef WITH_TAINT_TRACKING
+	u4 arg0_taint, arg1_taint;
+	arg0_taint = arg1_taint = 0;
+#endif /*WITH_TAINT_TRACKING*/
+
         EXPORT_PC();
 
         vsrc1 = INST_B(inst);       /* #of args */
@@ -2852,20 +3279,36 @@ HANDLE_OPCODE(OP_EXECUTE_INLINE /*vB, {vD, vE, vF, vG}, inline@CCCC*/)
             /* fall through */
         case 2:
             arg1 = GET_REGISTER((vdst & 0x00f0) >> 4);
+#ifdef WITH_TAINT_TRACKING
+	    arg1_taint = GET_REGISTER_TAINT((vdst & 0x00f0) >> 4);
+#endif /*WITH_TAINT_TRACKING*/
             /* fall through */
         case 1:
             arg0 = GET_REGISTER(vdst & 0x0f);
+#ifdef WITH_TAINT_TRACKING
+            arg0_taint = GET_REGISTER_TAINT(vdst & 0x0f);
+#endif /*WITH_TAINT_TRACKING*/
             /* fall through */
         default:        // case 0
             ;
         }
 
         if (self->interpBreak.ctl.subMode & kSubModeDebuggerActive) {
+#ifdef WITH_TAINT_TRACKING
+            if (!dvmPerformInlineOp4Dbg(arg0, arg1, arg2, arg3, arg0_taint, arg1_taint, &rtaint, &retval, ref))
+                GOTO_exceptionThrown();
+#else
             if (!dvmPerformInlineOp4Dbg(arg0, arg1, arg2, arg3, &retval, ref))
                 GOTO_exceptionThrown();
+#endif /*WITH_TAINT_TRACKING*/
         } else {
+#ifdef WITH_TAINT_TRACKING
+            if (!dvmPerformInlineOp4Std(arg0, arg1, arg2, arg3, arg0_taint, arg1_taint, &rtaint, &retval, ref))
+                GOTO_exceptionThrown();
+#else
             if (!dvmPerformInlineOp4Std(arg0, arg1, arg2, arg3, &retval, ref))
                 GOTO_exceptionThrown();
+#endif /*WITH_TAINT_TRACKING*/
         }
     }
     FINISH(3);
@@ -2877,6 +3320,11 @@ HANDLE_OPCODE(OP_EXECUTE_INLINE_RANGE /*{vCCCC..v(CCCC+AA-1)}, inline@BBBB*/)
         u4 arg0, arg1, arg2, arg3;
         arg0 = arg1 = arg2 = arg3 = 0;      /* placate gcc */
 
+#ifdef WITH_TAINT_TRACKING
+	u4 arg0_taint, arg1_taint;
+	arg0_taint = arg1_taint = 0;
+#endif /*WITH_TAINT_TRACKING*/
+
         EXPORT_PC();
 
         vsrc1 = INST_AA(inst);      /* #of args */
@@ -2897,20 +3345,36 @@ HANDLE_OPCODE(OP_EXECUTE_INLINE_RANGE /*{vCCCC..v(CCCC+AA-1)}, inline@BBBB*/)
             /* fall through */
         case 2:
             arg1 = GET_REGISTER(vdst+1);
+#ifdef WITH_TAINT_TRACKING
+	    arg1_taint = GET_REGISTER_TAINT(vdst+1);
+#endif /*WITH_TAINT_TRACKING*/
             /* fall through */
         case 1:
             arg0 = GET_REGISTER(vdst+0);
+#ifdef WITH_TAINT_TRACKING
+            arg0_taint = GET_REGISTER_TAINT(vdst+0);
+#endif /*WITH_TAINT_TRACKING*/
             /* fall through */
         default:        // case 0
             ;
         }
 
         if (self->interpBreak.ctl.subMode & kSubModeDebuggerActive) {
+#ifdef WITH_TAINT_TRACKING
+            if (!dvmPerformInlineOp4Dbg(arg0, arg1, arg2, arg3, arg0_taint, arg1_taint, &rtaint, &retval, ref))
+                GOTO_exceptionThrown();
+#else
             if (!dvmPerformInlineOp4Dbg(arg0, arg1, arg2, arg3, &retval, ref))
                 GOTO_exceptionThrown();
+#endif /*WITH_TAINT_TRACKING*/
         } else {
+#ifdef WITH_TAINT_TRACKING
+            if (!dvmPerformInlineOp4Std(arg0, arg1, arg2, arg3, arg0_taint, arg1_taint, &rtaint, &retval, ref))
+                GOTO_exceptionThrown();
+#else
             if (!dvmPerformInlineOp4Std(arg0, arg1, arg2, arg3, &retval, ref))
                 GOTO_exceptionThrown();
+#endif /*WITH_TAINT_TRACKING*/
         }
     }
     FINISH(3);
@@ -2953,6 +3417,9 @@ HANDLE_OPCODE(OP_RETURN_VOID_BARRIER /**/)
 #ifndef NDEBUG
     retval.j = 0xababababULL;   /* placate valgrind */
 #endif
+/* ifdef WITH_TAINT_TRACKING */
+    SET_RETURN_TAINT(TAINT_CLEAR);
+/* endif */
     ANDROID_MEMBAR_STORE();
     GOTO_returnFromMethod();
 OP_END
@@ -3124,6 +3591,9 @@ GOTO_TARGET(filledNewArray, bool methodCallRange, bool)
         }
 
         retval.l = (Object*)newArray;
+/* ifdef WITH_TAINT_TRACKING */
+        SET_RETURN_TAINT(TAINT_CLEAR);
+/* endif */
     }
     FINISH(3);
 GOTO_TARGET_END
@@ -3793,6 +4263,9 @@ GOTO_TARGET(invokeMethod, bool methodCallRange, const Method* _methodToCall,
 
         u4* outs;
         int i;
+#ifdef WITH_TAINT_TRACKING
+        bool nativeTarget = dvmIsNativeMethod(methodToCall);
+#endif
 
         /*
          * Copy args.  This may corrupt vsrc1/vdst.
@@ -3803,8 +4276,31 @@ GOTO_TARGET(invokeMethod, bool methodCallRange, const Method* _methodToCall,
             assert(vsrc1 <= curMethod->outsSize);
             assert(vsrc1 == methodToCall->insSize);
             outs = OUTS_FROM_FP(fp, vsrc1);
+#ifdef WITH_TAINT_TRACKING
+            if (nativeTarget) {
+            	for (i = 0; i < vsrc1; i++) {
+            		outs[i] = GET_REGISTER(vdst+i);
+            	}
+            	/* clear return taint (vsrc1 is the count) */
+            	outs[vsrc1] = TAINT_CLEAR;
+            	/* copy the taint tags (vsrc1 is the count) */
+            	for (i = 0; i < vsrc1; i++) {
+            		outs[vsrc1+1+i] = GET_REGISTER_TAINT(vdst+i);
+            	}
+            } else {
+            	int slot = 0;
+            	for (i = 0; i < vsrc1; i++) {
+            		slot = i << 1;
+            		outs[slot] = GET_REGISTER(vdst+i);
+            		outs[slot+1] = GET_REGISTER_TAINT(vdst+i);
+            	}
+            	/* clear native hack (vsrc1 is the count)*/
+            	outs[vsrc1<<1] = TAINT_CLEAR;
+            }
+#else
             for (i = 0; i < vsrc1; i++)
                 outs[i] = GET_REGISTER(vdst+i);
+#endif
         } else {
             u4 count = vsrc1 >> 4;
 
@@ -3826,6 +4322,53 @@ GOTO_TARGET(invokeMethod, bool methodCallRange, const Method* _methodToCall,
             // This version executes fewer instructions but is larger
             // overall.  Seems to be a teensy bit faster.
             assert((vdst >> 16) == 0);  // 16 bits -or- high 16 bits clear
+#ifdef WITH_TAINT_TRACKING
+            if (nativeTarget) {
+            	switch (count) {
+            	case 5:
+            		outs[4] = GET_REGISTER(vsrc1 & 0x0f);
+            		outs[count+5] = GET_REGISTER_TAINT(vsrc1 & 0x0f);
+            	case 4:
+            		outs[3] = GET_REGISTER(vdst >> 12);
+            		outs[count+4] = GET_REGISTER_TAINT(vdst >> 12);
+            	case 3:
+            		outs[2] = GET_REGISTER((vdst & 0x0f00) >> 8);
+            		outs[count+3] = GET_REGISTER_TAINT((vdst & 0x0f00) >> 8);
+            	case 2:
+            		outs[1] = GET_REGISTER((vdst & 0x00f0) >> 4);
+            		outs[count+2] = GET_REGISTER_TAINT((vdst & 0x00f0) >> 4);
+            	case 1:
+            		outs[0] = GET_REGISTER(vdst & 0x0f);
+            		outs[count+1] = GET_REGISTER_TAINT(vdst & 0x0f);
+            	default:
+            		;
+            	}
+            	/* clear the native hack */
+            	outs[count] = TAINT_CLEAR;
+            } else { /* interpreted target */
+            	switch (count) {
+            	case 5:
+            		outs[8] = GET_REGISTER(vsrc1 & 0x0f);
+            		outs[9] = GET_REGISTER_TAINT(vsrc1 & 0x0f);
+            	case 4:
+            		outs[6] = GET_REGISTER(vdst >> 12);
+            		outs[7] = GET_REGISTER_TAINT(vdst >> 12);
+            	case 3:
+            		outs[4] = GET_REGISTER((vdst & 0x0f00) >> 8);
+            		outs[5] = GET_REGISTER_TAINT((vdst & 0x0f00) >> 8);
+            	case 2:
+            		outs[2] = GET_REGISTER((vdst & 0x00f0) >> 4);
+            		outs[3] = GET_REGISTER_TAINT((vdst & 0x00f0) >> 4);
+            	case 1:
+            		outs[0] = GET_REGISTER(vdst & 0x0f);
+            		outs[1] = GET_REGISTER_TAINT(vdst & 0x0f);
+           	default:
+            		;
+              	}
+            	/* clear the native hack */
+            	outs[count<<1] = TAINT_CLEAR;
+            }
+#else /* ndef WITH_TAINT_TRACKING */
             switch (count) {
             case 5:
                 outs[4] = GET_REGISTER(vsrc1 & 0x0f);
@@ -3840,6 +4383,7 @@ GOTO_TARGET(invokeMethod, bool methodCallRange, const Method* _methodToCall,
             default:
                 ;
             }
+#endif /* WITH_TAINT_TRACKING */
 #endif
         }
     }
@@ -3861,13 +4405,23 @@ GOTO_TARGET(invokeMethod, bool methodCallRange, const Method* _methodToCall,
             methodToCall->clazz->descriptor, methodToCall->name,
             methodToCall->shorty);
 
+#ifdef WITH_TAINT_TRACKING
+        newFp = (u4*) SAVEAREA_FROM_FP(fp) -
+	    ((methodToCall->registersSize << 1) + 1);
+#else
         newFp = (u4*) SAVEAREA_FROM_FP(fp) - methodToCall->registersSize;
+#endif
         newSaveArea = SAVEAREA_FROM_FP(newFp);
 
         /* verify that we have enough space */
         if (true) {
             u1* bottom;
+#ifdef WITH_TAINT_TRACKING
+            bottom = (u1*) newSaveArea -
+            		(methodToCall->outsSize * sizeof(u4) + 4);
+#else
             bottom = (u1*) newSaveArea - methodToCall->outsSize * sizeof(u4);
+#endif
             if (bottom < self->interpStackEnd) {
                 /* stack overflow */
                 ALOGV("Stack overflow on method call (start=%p end=%p newBot=%p(%d) size=%d '%s')",
@@ -3890,8 +4444,15 @@ GOTO_TARGET(invokeMethod, bool methodCallRange, const Method* _methodToCall,
              * messages are disabled -- we want valgrind to report any
              * used-before-initialized issues.
              */
+#ifdef WITH_TAINT_TRACKING
+	    /* Don't need to worry about native target, because if
+	     * native target, registerSize = insSize */
+            memset(newFp, 0xcc,
+                (methodToCall->registersSize - methodToCall->insSize) * 8);
+#else
             memset(newFp, 0xcc,
                 (methodToCall->registersSize - methodToCall->insSize) * 4);
+#endif
         }
 #endif
 
@@ -3956,6 +4517,16 @@ GOTO_TARGET(invokeMethod, bool methodCallRange, const Method* _methodToCall,
              */
             (*methodToCall->nativeFunc)(newFp, &retval, methodToCall, self);
 
+#ifdef WITH_TAINT_TRACKING
+            /* Get the return taint if available */
+            {
+            	/* use same logic as above to calculate count */
+            	u4 count = (methodCallRange) ? vsrc1 : vsrc1 >> 4;
+            	u4* outs = OUTS_FROM_FP(fp, count);
+            	SET_RETURN_TAINT(outs[count]);
+            }
+#endif
+
             if (self->interpBreak.ctl.subMode != 0) {
                 dvmReportPostNativeInvoke(methodToCall, self, fp);
             }
@@ -4001,6 +4572,9 @@ GOTO_TARGET_END
 bail:
     ILOGD("|-- Leaving interpreter loop");      // note "curMethod" may be NULL
 
+#ifdef WITH_TAINT_TRACKING
+    self->interpSave.rtaint = rtaint;
+#endif
     self->interpSave.retval = retval;
 }
 
diff --git a/vm/mterp/out/InterpC-x86-atom.cpp b/vm/mterp/out/InterpC-x86-atom.cpp
index 1083f8b..d8933ae 100644
--- a/vm/mterp/out/InterpC-x86-atom.cpp
+++ b/vm/mterp/out/InterpC-x86-atom.cpp
@@ -143,6 +143,31 @@ static const char kSpacing[] = "            ";
 # define DUMP_REGS(_meth, _frame, _inOnly) ((void)0)
 #endif
 
+/*
+ * If enabled, log taint propagation
+ */
+#ifdef WITH_TAINT_TRACKING
+# define TLOGD(...) TLOG(LOG_DEBUG, __VA_ARGS__)
+# define TLOGV(...) TLOG(LOG_VERBOSE, __VA_ARGS__)
+# define TLOGW(...) TLOG(LOG_WARN, __VA_ARGS__)
+# define TLOGE(...) TLOG(LOG_ERROR, __VA_ARGS__)
+# define TLOG(_level, ...) do {                                             \
+        char debugStrBuf[128];                                              \
+        snprintf(debugStrBuf, sizeof(debugStrBuf), __VA_ARGS__);            \
+        if (curMethod != NULL)                                              \
+            ALOG(_level, LOG_TAG"t", "%-2d|%04x|%s.%s:%s\n",                \
+                self->threadId, (int)(pc - curMethod->insns), curMethod->clazz->descriptor, curMethod->name, debugStrBuf); \
+        else                                                                \
+            ALOG(_level, LOG_TAG"t", "%-2d|####%s\n",                       \
+                self->threadId, debugStrBuf);                               \
+    } while(false)
+#else
+# define TLOGD(...) ((void)0)
+# define TLOGV(...) ((void)0)
+# define TLOGW(...) ((void)0)
+# define TLOGE(...) ((void)0)
+#endif
+
 /* get a long from an array of u4 */
 static inline s8 getLongFromArray(const u4* ptr, int idx)
 {
@@ -160,6 +185,20 @@ static inline s8 getLongFromArray(const u4* ptr, int idx)
 #endif
 }
 
+#ifdef WITH_TAINT_TRACKING
+/* get a long from an array of u4 */
+static inline s8 getLongFromArrayTaint(const u4* ptr, int idx)
+{
+    /* Need to use the "union" version for taint tracking */
+    union { s8 ll; u4 parts[2]; } conv;
+
+    ptr += idx;
+    conv.parts[0] = ptr[0];
+    conv.parts[1] = ptr[2];
+    return conv.ll;
+}
+#endif
+
 /* store a long into an array of u4 */
 static inline void putLongToArray(u4* ptr, int idx, s8 val)
 {
@@ -175,6 +214,20 @@ static inline void putLongToArray(u4* ptr, int idx, s8 val)
 #endif
 }
 
+#ifdef WITH_TAINT_TRACKING
+/* store a long into an array of u4 */
+static inline void putLongToArrayTaint(u4* ptr, int idx, s8 val)
+{
+    /* Need to use the "union" version for taint tracking */
+    union { s8 ll; u4 parts[2]; } conv;
+
+    ptr += idx;
+    conv.ll = val;
+    ptr[0] = conv.parts[0];
+    ptr[2] = conv.parts[1];
+}
+#endif
+
 /* get a double from an array of u4 */
 static inline double getDoubleFromArray(const u4* ptr, int idx)
 {
@@ -192,6 +245,20 @@ static inline double getDoubleFromArray(const u4* ptr, int idx)
 #endif
 }
 
+#ifdef WITH_TAINT_TRACKING
+/* get a double from an array of u4 */
+static inline double getDoubleFromArrayTaint(const u4* ptr, int idx)
+{
+    /* Need to use the "union" version for taint tracking */
+    union { double d; u4 parts[2]; } conv;
+
+    ptr += idx;
+    conv.parts[0] = ptr[0];
+    conv.parts[1] = ptr[2];
+    return conv.d;
+}
+#endif
+
 /* store a double into an array of u4 */
 static inline void putDoubleToArray(u4* ptr, int idx, double dval)
 {
@@ -207,6 +274,20 @@ static inline void putDoubleToArray(u4* ptr, int idx, double dval)
 #endif
 }
 
+#ifdef WITH_TAINT_TRACKING
+/* store a double into an array of u4 */
+static inline void putDoubleToArrayTaint(u4* ptr, int idx, double dval)
+{
+    /* Need to use the "union" version for taint tracking */
+    union { double d; u4 parts[2]; } conv;
+
+    ptr += idx;
+    conv.d = dval;
+    ptr[0] = conv.parts[0];
+    ptr[2] = conv.parts[1];
+}
+#endif
+
 /*
  * If enabled, validate the register number on every access.  Otherwise,
  * just do an array access.
@@ -215,6 +296,55 @@ static inline void putDoubleToArray(u4* ptr, int idx, double dval)
  *
  * "_idx" may be referenced more than once.
  */
+#ifdef WITH_TAINT_TRACKING
+/* -- Begin Taint Tracking version ------------------------------- */
+/* Taint tags are interleaved between registers. All indexes must
+ * be multiplied by 2 (i.e., left bit shift by 1) */
+#ifdef CHECK_REGISTER_INDICES
+# define GET_REGISTER(_idx) \
+    ( (_idx) < curMethod->registersSize ? \
+        (fp[(_idx)<<1]) : (assert(!"bad reg"),1969) )
+# define SET_REGISTER(_idx, _val) \
+    ( (_idx) < curMethod->registersSize ? \
+        (fp[(_idx)<<1] = (u4)(_val)) : (assert(!"bad reg"),1969) )
+# define GET_REGISTER_AS_OBJECT(_idx)       ((Object *)GET_REGISTER(_idx))
+# define SET_REGISTER_AS_OBJECT(_idx, _val) SET_REGISTER(_idx, (s4)_val)
+# define GET_REGISTER_INT(_idx) ((s4) GET_REGISTER(_idx))
+# define SET_REGISTER_INT(_idx, _val) SET_REGISTER(_idx, (s4)_val)
+# define GET_REGISTER_WIDE(_idx) \
+    ( (_idx) < curMethod->registersSize-1 ? \
+        getLongFromArrayTaint(fp, ((_idx)<<1)) : (assert(!"bad reg"),1969) )
+# define SET_REGISTER_WIDE(_idx, _val) \
+    ( (_idx) < curMethod->registersSize-1 ? \
+        putLongToArrayTaint(fp, ((_idx)<<1), (_val)) : (assert(!"bad reg"),1969) )
+# define GET_REGISTER_FLOAT(_idx) \
+    ( (_idx) < curMethod->registersSize ? \
+        (*((float*) &fp[(_idx)<<1])) : (assert(!"bad reg"),1969.0f) )
+# define SET_REGISTER_FLOAT(_idx, _val) \
+    ( (_idx) < curMethod->registersSize ? \
+        (*((float*) &fp[(_idx)<<1]) = (_val)) : (assert(!"bad reg"),1969.0f) )
+# define GET_REGISTER_DOUBLE(_idx) \
+    ( (_idx) < curMethod->registersSize-1 ? \
+        getDoubleFromArrayTaint(fp, ((_idx)<<1)) : (assert(!"bad reg"),1969.0) )
+# define SET_REGISTER_DOUBLE(_idx, _val) \
+    ( (_idx) < curMethod->registersSize-1 ? \
+        putDoubleToArrayTaint(fp, ((_idx)<<1), (_val)) : (assert(!"bad reg"),1969.0) )
+#else
+# define GET_REGISTER(_idx)                 (fp[(_idx)<<1])
+# define SET_REGISTER(_idx, _val)           (fp[(_idx)<<1] = (_val))
+# define GET_REGISTER_AS_OBJECT(_idx)       ((Object*) fp[(_idx)<<1])
+# define SET_REGISTER_AS_OBJECT(_idx, _val) (fp[(_idx)<<1] = (u4)(_val))
+# define GET_REGISTER_INT(_idx)             ((s4)GET_REGISTER(_idx))
+# define SET_REGISTER_INT(_idx, _val)       SET_REGISTER(_idx, (s4)_val)
+# define GET_REGISTER_WIDE(_idx)            getLongFromArrayTaint(fp, ((_idx)<<1))
+# define SET_REGISTER_WIDE(_idx, _val)      putLongToArrayTaint(fp, ((_idx)<<1), (_val))
+# define GET_REGISTER_FLOAT(_idx)           (*((float*) &fp[(_idx)<<1]))
+# define SET_REGISTER_FLOAT(_idx, _val)     (*((float*) &fp[(_idx)<<1]) = (_val))
+# define GET_REGISTER_DOUBLE(_idx)          getDoubleFromArrayTaint(fp, ((_idx)<<1))
+# define SET_REGISTER_DOUBLE(_idx, _val)    putDoubleToArrayTaint(fp, ((_idx)<<1), (_val))
+#endif
+/* -- End Taint Tracking version ---------------------------------- */
+#else /* no taint tracking */
 #ifdef CHECK_REGISTER_INDICES
 # define GET_REGISTER(_idx) \
     ( (_idx) < curMethod->registersSize ? \
@@ -258,6 +388,48 @@ static inline void putDoubleToArray(u4* ptr, int idx, double dval)
 # define GET_REGISTER_DOUBLE(_idx)          getDoubleFromArray(fp, (_idx))
 # define SET_REGISTER_DOUBLE(_idx, _val)    putDoubleToArray(fp, (_idx), (_val))
 #endif
+#endif /* end no taint tracking */
+
+#ifdef WITH_TAINT_TRACKING
+/* Core get and set macros */
+# define GET_REGISTER_TAINT(_idx)	     (fp[((_idx)<<1)+1])
+# define SET_REGISTER_TAINT(_idx, _val)	     (fp[((_idx)<<1)+1] = (u4)(_val))
+# define GET_REGISTER_TAINT_WIDE(_idx)       (fp[((_idx)<<1)+1])
+# define SET_REGISTER_TAINT_WIDE(_idx, _val) (fp[((_idx)<<1)+1] = \
+	                                      fp[((_idx)<<1)+3] = (u4)(_val))
+/* Alternate interfaces to help dereference register width */
+# define GET_REGISTER_TAINT_INT(_idx)	          GET_REGISTER_TAINT(_idx)
+# define SET_REGISTER_TAINT_INT(_idx, _val)       SET_REGISTER_TAINT(_idx, _val)
+# define GET_REGISTER_TAINT_FLOAT(_idx)	          GET_REGISTER_TAINT(_idx)
+# define SET_REGISTER_TAINT_FLOAT(_idx, _val)     SET_REGISTER_TAINT(_idx, _val)
+# define GET_REGISTER_TAINT_DOUBLE(_idx)          GET_REGISTER_TAINT_WIDE(_idx)
+# define SET_REGISTER_TAINT_DOUBLE(_idx, _val)    SET_REGISTER_TAINT_WIDE(_idx, _val)
+# define GET_REGISTER_TAINT_AS_OBJECT(_idx)       GET_REGISTER_TAINT(_idx)
+# define SET_REGISTER_TAINT_AS_OBJECT(_idx, _val) SET_REGISTER_TAINT(_idx, _val)
+
+/* Object Taint interface */
+# define GET_ARRAY_TAINT(_arr)		      ((_arr)->taint.tag)
+# define SET_ARRAY_TAINT(_arr, _val)	      ((_arr)->taint.tag = (u4)(_val))
+
+/* Return value taint (assumes rtaint variable is in scope */
+# define GET_RETURN_TAINT()		      (rtaint.tag)
+# define SET_RETURN_TAINT(_val)		      (rtaint.tag = (u4)(_val))
+#else
+# define GET_REGISTER_TAINT(_idx)		    ((void)0)
+# define SET_REGISTER_TAINT(_idx, _val)		    ((void)0)
+# define GET_REGISTER_TAINT_WIDE(_idx)		    ((void)0)
+# define SET_REGISTER_TAINT_WIDE(_idx, _val)	    ((void)0)
+# define GET_REGISTER_TAINT_INT(_idx)		    ((void)0)
+# define SET_REGISTER_TAINT_INT(_idx, _val)	    ((void)0)
+# define GET_REGISTER_TAINT_DOUBLE(_idx)	    ((void)0)
+# define SET_REGISTER_TAINT_DOUBLE(_idx, _val)	    ((void)0)
+# define GET_REGISTER_TAINT_AS_OBJECT(_idx)	    ((void)0)
+# define SET_REGISTER_TAINT_AS_OBJECT(_idx, _val)   ((void)0)
+# define GET_ARRAY_TAINT(_field)                    ((void)0)
+# define SET_ARRAY_TAINT(_field, _val)              ((void)0)
+# define GET_RETURN_TAINT()			    ((void)0)
+# define SET_RETURN_TAINT(_val)			    ((void)0)
+#endif
 
 /*
  * Get 16 bits from the specified offset of the program counter.  We always
@@ -399,6 +571,10 @@ static inline bool checkForNullExportPC(Object* obj, u4* fp, const u2* pc)
 #define methodClassDex          self->interpSave.methodClassDex
 #define debugTrackedRefStart    self->interpSave.debugTrackedRefStart
 
+#ifdef WITH_TAINT_TRACKING
+#define rtaint			self->interpSave.rtaint
+#endif
+
 /* ugh */
 #define STUB_HACK(x) x
 #if defined(WITH_JIT)
@@ -537,6 +713,10 @@ GOTO_TARGET_DECL(exceptionThrown);
         ILOGV("|%s v%d,v%d", (_opname), vdst, vsrc1);                       \
         SET_REGISTER##_totype(vdst,                                         \
             GET_REGISTER##_fromtype(vsrc1));                                \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT##_totype(vdst,                                   \
+	    GET_REGISTER_TAINT##_fromtype(vsrc1));                          \
+/* endif */                                                                 \
         FINISH(1);
 
 #define HANDLE_FLOAT_TO_INT(_opcode, _opname, _fromvtype, _fromrtype,       \
@@ -562,6 +742,10 @@ GOTO_TARGET_DECL(exceptionThrown);
         else                                                                \
             result = (_tovtype) val;                                        \
         SET_REGISTER##_tortype(vdst, result);                               \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT##_tortype(vdst,                                  \
+	    GET_REGISTER_TAINT##_fromrtype(vsrc1));                         \
+/* endif */                                                                 \
     }                                                                       \
     FINISH(1);
 
@@ -571,6 +755,9 @@ GOTO_TARGET_DECL(exceptionThrown);
         vsrc1 = INST_B(inst);                                               \
         ILOGV("|int-to-%s v%d,v%d", (_opname), vdst, vsrc1);                \
         SET_REGISTER(vdst, (_type) GET_REGISTER(vsrc1));                    \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT(vdst, GET_REGISTER_TAINT(vsrc1));                \
+/* endif */                                                                 \
         FINISH(1);
 
 /* NOTE: the comparison result is always a signed 4-byte integer */
@@ -597,6 +784,9 @@ GOTO_TARGET_DECL(exceptionThrown);
             result = (_nanVal);                                             \
         ILOGV("+ result=%d", result);                                       \
         SET_REGISTER(vdst, result);                                         \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT(vdst, TAINT_CLEAR);				    \
+/* endif */                                                                 \
     }                                                                       \
     FINISH(2);
 
@@ -638,6 +828,9 @@ GOTO_TARGET_DECL(exceptionThrown);
         vsrc1 = INST_B(inst);                                               \
         ILOGV("|%s v%d,v%d", (_opname), vdst, vsrc1);                       \
         SET_REGISTER##_type(vdst, _pfx GET_REGISTER##_type(vsrc1) _sfx);    \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT##_type(vdst, GET_REGISTER_TAINT##_type(vsrc1));  \
+/* endif */                                                                 \
         FINISH(1);
 
 #define HANDLE_OP_X_INT(_opcode, _opname, _op, _chkdiv)                     \
@@ -672,6 +865,10 @@ GOTO_TARGET_DECL(exceptionThrown);
             SET_REGISTER(vdst,                                              \
                 (s4) GET_REGISTER(vsrc1) _op (s4) GET_REGISTER(vsrc2));     \
         }                                                                   \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT(vdst,                                            \
+	    (GET_REGISTER_TAINT(vsrc1)|GET_REGISTER_TAINT(vsrc2)) );        \
+/* endif */                                                                 \
     }                                                                       \
     FINISH(2);
 
@@ -686,6 +883,10 @@ GOTO_TARGET_DECL(exceptionThrown);
         ILOGV("|%s-int v%d,v%d", (_opname), vdst, vsrc1);                   \
         SET_REGISTER(vdst,                                                  \
             _cast GET_REGISTER(vsrc1) _op (GET_REGISTER(vsrc2) & 0x1f));    \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT(vdst,                                            \
+	    (GET_REGISTER_TAINT(vsrc1)|GET_REGISTER_TAINT(vsrc2)) );        \
+/* endif */                                                                 \
     }                                                                       \
     FINISH(2);
 
@@ -702,7 +903,7 @@ GOTO_TARGET_DECL(exceptionThrown);
             if ((s2) vsrc2 == 0) {                                          \
                 EXPORT_PC();                                                \
                 dvmThrowArithmeticException("divide by zero");              \
-                GOTO_exceptionThrown();                                     \
+                GOTO_exceptionThrown();                                      \
             }                                                               \
             if ((u4)firstVal == 0x80000000 && ((s2) vsrc2) == -1) {         \
                 /* won't generate /lit16 instr for this; check anyway */    \
@@ -718,6 +919,9 @@ GOTO_TARGET_DECL(exceptionThrown);
             /* non-div/rem case */                                          \
             SET_REGISTER(vdst, GET_REGISTER(vsrc1) _op (s2) vsrc2);         \
         }                                                                   \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT(vdst, GET_REGISTER_TAINT(vsrc1));                \
+/* endif */                                                                 \
         FINISH(2);
 
 #define HANDLE_OP_X_INT_LIT8(_opcode, _opname, _op, _chkdiv)                \
@@ -751,6 +955,9 @@ GOTO_TARGET_DECL(exceptionThrown);
             SET_REGISTER(vdst,                                              \
                 (s4) GET_REGISTER(vsrc1) _op (s1) vsrc2);                   \
         }                                                                   \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT(vdst, GET_REGISTER_TAINT(vsrc1));                \
+/* endif */                                                                 \
     }                                                                       \
     FINISH(2);
 
@@ -766,6 +973,9 @@ GOTO_TARGET_DECL(exceptionThrown);
             (_opname), vdst, vsrc1, vsrc2);                                 \
         SET_REGISTER(vdst,                                                  \
             _cast GET_REGISTER(vsrc1) _op (vsrc2 & 0x1f));                  \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT(vdst, GET_REGISTER_TAINT(vsrc1));                \
+/* endif */                                                                 \
     }                                                                       \
     FINISH(2);
 
@@ -796,6 +1006,10 @@ GOTO_TARGET_DECL(exceptionThrown);
             SET_REGISTER(vdst,                                              \
                 (s4) GET_REGISTER(vdst) _op (s4) GET_REGISTER(vsrc1));      \
         }                                                                   \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT(vdst,                                            \
+	    (GET_REGISTER_TAINT(vdst)|GET_REGISTER_TAINT(vsrc1)) );         \
+/* endif */                                                                 \
         FINISH(1);
 
 #define HANDLE_OP_SHX_INT_2ADDR(_opcode, _opname, _cast, _op)               \
@@ -805,6 +1019,10 @@ GOTO_TARGET_DECL(exceptionThrown);
         ILOGV("|%s-int-2addr v%d,v%d", (_opname), vdst, vsrc1);             \
         SET_REGISTER(vdst,                                                  \
             _cast GET_REGISTER(vdst) _op (GET_REGISTER(vsrc1) & 0x1f));     \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT(vdst,                                            \
+	    (GET_REGISTER_TAINT(vdst)|GET_REGISTER_TAINT(vsrc1)) );         \
+/* endif */                                                                 \
         FINISH(1);
 
 #define HANDLE_OP_X_LONG(_opcode, _opname, _op, _chkdiv)                    \
@@ -840,6 +1058,10 @@ GOTO_TARGET_DECL(exceptionThrown);
             SET_REGISTER_WIDE(vdst,                                         \
                 (s8) GET_REGISTER_WIDE(vsrc1) _op (s8) GET_REGISTER_WIDE(vsrc2)); \
         }                                                                   \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT_WIDE(vdst,                                       \
+	   (GET_REGISTER_TAINT_WIDE(vsrc1)|GET_REGISTER_TAINT_WIDE(vsrc2)));\
+/* endif */                                                                 \
     }                                                                       \
     FINISH(2);
 
@@ -854,6 +1076,10 @@ GOTO_TARGET_DECL(exceptionThrown);
         ILOGV("|%s-long v%d,v%d,v%d", (_opname), vdst, vsrc1, vsrc2);       \
         SET_REGISTER_WIDE(vdst,                                             \
             _cast GET_REGISTER_WIDE(vsrc1) _op (GET_REGISTER(vsrc2) & 0x3f)); \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT_WIDE(vdst,                                       \
+	   (GET_REGISTER_TAINT_WIDE(vsrc1)|GET_REGISTER_TAINT_WIDE(vsrc2)));\
+/* endif */                                                                 \
     }                                                                       \
     FINISH(2);
 
@@ -886,6 +1112,10 @@ GOTO_TARGET_DECL(exceptionThrown);
             SET_REGISTER_WIDE(vdst,                                         \
                 (s8) GET_REGISTER_WIDE(vdst) _op (s8)GET_REGISTER_WIDE(vsrc1));\
         }                                                                   \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT_WIDE(vdst,                                       \
+	    (GET_REGISTER_TAINT_WIDE(vdst)|GET_REGISTER_TAINT_WIDE(vsrc1)));\
+/* endif */                                                                 \
         FINISH(1);
 
 #define HANDLE_OP_SHX_LONG_2ADDR(_opcode, _opname, _cast, _op)              \
@@ -895,6 +1125,10 @@ GOTO_TARGET_DECL(exceptionThrown);
         ILOGV("|%s-long-2addr v%d,v%d", (_opname), vdst, vsrc1);            \
         SET_REGISTER_WIDE(vdst,                                             \
             _cast GET_REGISTER_WIDE(vdst) _op (GET_REGISTER(vsrc1) & 0x3f)); \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT_WIDE(vdst,                                       \
+	    (GET_REGISTER_TAINT_WIDE(vdst)|GET_REGISTER_TAINT_WIDE(vsrc1)));\
+/* endif */                                                                 \
         FINISH(1);
 
 #define HANDLE_OP_X_FLOAT(_opcode, _opname, _op)                            \
@@ -908,6 +1142,10 @@ GOTO_TARGET_DECL(exceptionThrown);
         ILOGV("|%s-float v%d,v%d,v%d", (_opname), vdst, vsrc1, vsrc2);      \
         SET_REGISTER_FLOAT(vdst,                                            \
             GET_REGISTER_FLOAT(vsrc1) _op GET_REGISTER_FLOAT(vsrc2));       \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT_FLOAT(vdst,                                      \
+	    (GET_REGISTER_TAINT_FLOAT(vsrc1)|GET_REGISTER_TAINT_FLOAT(vsrc2)));\
+/* endif */                                                                 \
     }                                                                       \
     FINISH(2);
 
@@ -922,6 +1160,10 @@ GOTO_TARGET_DECL(exceptionThrown);
         ILOGV("|%s-double v%d,v%d,v%d", (_opname), vdst, vsrc1, vsrc2);     \
         SET_REGISTER_DOUBLE(vdst,                                           \
             GET_REGISTER_DOUBLE(vsrc1) _op GET_REGISTER_DOUBLE(vsrc2));     \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT_DOUBLE(vdst,                                     \
+	    (GET_REGISTER_TAINT_DOUBLE(vsrc1)|GET_REGISTER_TAINT_DOUBLE(vsrc2)));\
+/* endif */                                                                 \
     }                                                                       \
     FINISH(2);
 
@@ -932,6 +1174,10 @@ GOTO_TARGET_DECL(exceptionThrown);
         ILOGV("|%s-float-2addr v%d,v%d", (_opname), vdst, vsrc1);           \
         SET_REGISTER_FLOAT(vdst,                                            \
             GET_REGISTER_FLOAT(vdst) _op GET_REGISTER_FLOAT(vsrc1));        \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT_FLOAT(vdst,                                      \
+	    (GET_REGISTER_TAINT_FLOAT(vdst)|GET_REGISTER_TAINT_FLOAT(vsrc1)));\
+/* endif */                                                                 \
         FINISH(1);
 
 #define HANDLE_OP_X_DOUBLE_2ADDR(_opcode, _opname, _op)                     \
@@ -941,6 +1187,10 @@ GOTO_TARGET_DECL(exceptionThrown);
         ILOGV("|%s-double-2addr v%d,v%d", (_opname), vdst, vsrc1);          \
         SET_REGISTER_DOUBLE(vdst,                                           \
             GET_REGISTER_DOUBLE(vdst) _op GET_REGISTER_DOUBLE(vsrc1));      \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT_DOUBLE(vdst,                                     \
+	    (GET_REGISTER_TAINT_DOUBLE(vdst)|GET_REGISTER_TAINT_DOUBLE(vsrc1)));\
+/* endif */                                                                 \
         FINISH(1);
 
 #define HANDLE_OP_AGET(_opcode, _opname, _type, _regsize)                   \
@@ -965,6 +1215,11 @@ GOTO_TARGET_DECL(exceptionThrown);
         SET_REGISTER##_regsize(vdst,                                        \
             ((_type*)(void*)arrayObj->contents)[GET_REGISTER(vsrc2)]);      \
         ILOGV("+ AGET[%d]=%#x", GET_REGISTER(vsrc2), GET_REGISTER(vdst));   \
+/* ifdef WITH_TAINT_TRACKING */						    \
+	SET_REGISTER_TAINT##_regsize(vdst,                                  \
+	    (GET_ARRAY_TAINT(arrayObj)|GET_REGISTER_TAINT(vsrc2)));         \
+/* endif */								    \
+        ILOGV("+ AGET[%d]=0x%x", GET_REGISTER(vsrc2), GET_REGISTER(vdst));  \
     }                                                                       \
     FINISH(2);
 
@@ -990,6 +1245,11 @@ GOTO_TARGET_DECL(exceptionThrown);
         ILOGV("+ APUT[%d]=0x%08x", GET_REGISTER(vsrc2), GET_REGISTER(vdst));\
         ((_type*)(void*)arrayObj->contents)[GET_REGISTER(vsrc2)] =          \
             GET_REGISTER##_regsize(vdst);                                   \
+/* ifdef WITH_TAINT_TRACKING */						    \
+	SET_ARRAY_TAINT(arrayObj,                                           \
+		(GET_ARRAY_TAINT(arrayObj) |                                \
+		 GET_REGISTER_TAINT##_regsize(vdst)) );                     \
+/* endif */								    \
     }                                                                       \
     FINISH(2);
 
@@ -1033,6 +1293,11 @@ GOTO_TARGET_DECL(exceptionThrown);
             dvmGetField##_ftype(obj, ifield->byteOffset));                  \
         ILOGV("+ IGET '%s'=0x%08llx", ifield->field.name,                   \
             (u8) GET_REGISTER##_regsize(vdst));                             \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+	SET_REGISTER_TAINT##_regsize(vdst,                                  \
+	    (GET_REGISTER_TAINT(vsrc1)|                                     \
+	     dvmGetFieldTaint##_ftype(obj,ifield->byteOffset)) );           \
+/* endif */                                                                 \
     }                                                                       \
     FINISH(2);
 
@@ -1051,6 +1316,13 @@ GOTO_TARGET_DECL(exceptionThrown);
         SET_REGISTER##_regsize(vdst, dvmGetField##_ftype(obj, ref));        \
         ILOGV("+ IGETQ %d=0x%08llx", ref,                                   \
             (u8) GET_REGISTER##_regsize(vdst));                             \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+	/*TLOGW("|IGETQ not supported by taint tracking!!!");*/             \
+	/* compile flag WITH_TAINT_ODEX controls this now */                \
+	SET_REGISTER_TAINT##_regsize(vdst,                                  \
+	    (GET_REGISTER_TAINT(vsrc1)|                                     \
+	     dvmGetFieldTaint##_ftype(obj,ref)) );                          \
+/* endif */                                                                 \
     }                                                                       \
     FINISH(2);
 
@@ -1077,6 +1349,10 @@ GOTO_TARGET_DECL(exceptionThrown);
             GET_REGISTER##_regsize(vdst));                                  \
         ILOGV("+ IPUT '%s'=0x%08llx", ifield->field.name,                   \
             (u8) GET_REGISTER##_regsize(vdst));                             \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+	dvmSetFieldTaint##_ftype(obj, ifield->byteOffset,                   \
+		GET_REGISTER_TAINT##_regsize(vdst));                        \
+/* endif */                                                                 \
     }                                                                       \
     FINISH(2);
 
@@ -1095,6 +1371,12 @@ GOTO_TARGET_DECL(exceptionThrown);
         dvmSetField##_ftype(obj, ref, GET_REGISTER##_regsize(vdst));        \
         ILOGV("+ IPUTQ %d=0x%08llx", ref,                                   \
             (u8) GET_REGISTER##_regsize(vdst));                             \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+	/*TLOGW("|IPUTQ not supported by taint tracking!!!");*/             \
+	/* compile flag WITH_TAINT_ODEX controls this now */                \
+	dvmSetFieldTaint##_ftype(obj, ref,                                  \
+		GET_REGISTER_TAINT##_regsize(vdst));                        \
+/* endif */                                                                 \
     }                                                                       \
     FINISH(2);
 
@@ -1126,6 +1408,9 @@ GOTO_TARGET_DECL(exceptionThrown);
         SET_REGISTER##_regsize(vdst, dvmGetStaticField##_ftype(sfield));    \
         ILOGV("+ SGET '%s'=0x%08llx",                                       \
             sfield->field.name, (u8)GET_REGISTER##_regsize(vdst));          \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+	SET_REGISTER_TAINT##_regsize(vdst, dvmGetStaticFieldTaint##_ftype(sfield));\
+/* endif */                                                                 \
     }                                                                       \
     FINISH(2);
 
@@ -1149,9 +1434,14 @@ GOTO_TARGET_DECL(exceptionThrown);
         dvmSetStaticField##_ftype(sfield, GET_REGISTER##_regsize(vdst));    \
         ILOGV("+ SPUT '%s'=0x%08llx",                                       \
             sfield->field.name, (u8)GET_REGISTER##_regsize(vdst));          \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+	dvmSetStaticFieldTaint##_ftype(sfield,                              \
+		GET_REGISTER_TAINT##_regsize(vdst));                        \
+/* endif */                                                                 \
     }                                                                       \
     FINISH(2);
 
+
 /* File: c/OP_IGET_VOLATILE.cpp */
 HANDLE_IGET_X(OP_IGET_VOLATILE,         "-volatile", IntVolatile, )
 OP_END
@@ -1220,6 +1510,11 @@ HANDLE_OPCODE(OP_EXECUTE_INLINE_RANGE /*{vCCCC..v(CCCC+AA-1)}, inline@BBBB*/)
         u4 arg0, arg1, arg2, arg3;
         arg0 = arg1 = arg2 = arg3 = 0;      /* placate gcc */
 
+#ifdef WITH_TAINT_TRACKING
+	u4 arg0_taint, arg1_taint;
+	arg0_taint = arg1_taint = 0;
+#endif /*WITH_TAINT_TRACKING*/
+
         EXPORT_PC();
 
         vsrc1 = INST_AA(inst);      /* #of args */
@@ -1240,20 +1535,36 @@ HANDLE_OPCODE(OP_EXECUTE_INLINE_RANGE /*{vCCCC..v(CCCC+AA-1)}, inline@BBBB*/)
             /* fall through */
         case 2:
             arg1 = GET_REGISTER(vdst+1);
+#ifdef WITH_TAINT_TRACKING
+	    arg1_taint = GET_REGISTER_TAINT(vdst+1);
+#endif /*WITH_TAINT_TRACKING*/
             /* fall through */
         case 1:
             arg0 = GET_REGISTER(vdst+0);
+#ifdef WITH_TAINT_TRACKING
+            arg0_taint = GET_REGISTER_TAINT(vdst+0);
+#endif /*WITH_TAINT_TRACKING*/
             /* fall through */
         default:        // case 0
             ;
         }
 
         if (self->interpBreak.ctl.subMode & kSubModeDebuggerActive) {
+#ifdef WITH_TAINT_TRACKING
+            if (!dvmPerformInlineOp4Dbg(arg0, arg1, arg2, arg3, arg0_taint, arg1_taint, &rtaint, &retval, ref))
+                GOTO_exceptionThrown();
+#else
             if (!dvmPerformInlineOp4Dbg(arg0, arg1, arg2, arg3, &retval, ref))
                 GOTO_exceptionThrown();
+#endif /*WITH_TAINT_TRACKING*/
         } else {
+#ifdef WITH_TAINT_TRACKING
+            if (!dvmPerformInlineOp4Std(arg0, arg1, arg2, arg3, arg0_taint, arg1_taint, &rtaint, &retval, ref))
+                GOTO_exceptionThrown();
+#else
             if (!dvmPerformInlineOp4Std(arg0, arg1, arg2, arg3, &retval, ref))
                 GOTO_exceptionThrown();
+#endif /*WITH_TAINT_TRACKING*/
         }
     }
     FINISH(3);
@@ -1296,6 +1607,9 @@ HANDLE_OPCODE(OP_RETURN_VOID_BARRIER /**/)
 #ifndef NDEBUG
     retval.j = 0xababababULL;   /* placate valgrind */
 #endif
+/* ifdef WITH_TAINT_TRACKING */
+    SET_RETURN_TAINT(TAINT_CLEAR);
+/* endif */
     ANDROID_MEMBAR_STORE();
     GOTO_returnFromMethod();
 OP_END
@@ -1413,6 +1727,9 @@ GOTO_TARGET(filledNewArray, bool methodCallRange, bool)
         }
 
         retval.l = (Object*)newArray;
+/* ifdef WITH_TAINT_TRACKING */
+        SET_RETURN_TAINT(TAINT_CLEAR);
+/* endif */
     }
     FINISH(3);
 GOTO_TARGET_END
@@ -2082,6 +2399,9 @@ GOTO_TARGET(invokeMethod, bool methodCallRange, const Method* _methodToCall,
 
         u4* outs;
         int i;
+#ifdef WITH_TAINT_TRACKING
+        bool nativeTarget = dvmIsNativeMethod(methodToCall);
+#endif
 
         /*
          * Copy args.  This may corrupt vsrc1/vdst.
@@ -2092,8 +2412,31 @@ GOTO_TARGET(invokeMethod, bool methodCallRange, const Method* _methodToCall,
             assert(vsrc1 <= curMethod->outsSize);
             assert(vsrc1 == methodToCall->insSize);
             outs = OUTS_FROM_FP(fp, vsrc1);
+#ifdef WITH_TAINT_TRACKING
+            if (nativeTarget) {
+            	for (i = 0; i < vsrc1; i++) {
+            		outs[i] = GET_REGISTER(vdst+i);
+            	}
+            	/* clear return taint (vsrc1 is the count) */
+            	outs[vsrc1] = TAINT_CLEAR;
+            	/* copy the taint tags (vsrc1 is the count) */
+            	for (i = 0; i < vsrc1; i++) {
+            		outs[vsrc1+1+i] = GET_REGISTER_TAINT(vdst+i);
+            	}
+            } else {
+            	int slot = 0;
+            	for (i = 0; i < vsrc1; i++) {
+            		slot = i << 1;
+            		outs[slot] = GET_REGISTER(vdst+i);
+            		outs[slot+1] = GET_REGISTER_TAINT(vdst+i);
+            	}
+            	/* clear native hack (vsrc1 is the count)*/
+            	outs[vsrc1<<1] = TAINT_CLEAR;
+            }
+#else
             for (i = 0; i < vsrc1; i++)
                 outs[i] = GET_REGISTER(vdst+i);
+#endif
         } else {
             u4 count = vsrc1 >> 4;
 
@@ -2115,6 +2458,53 @@ GOTO_TARGET(invokeMethod, bool methodCallRange, const Method* _methodToCall,
             // This version executes fewer instructions but is larger
             // overall.  Seems to be a teensy bit faster.
             assert((vdst >> 16) == 0);  // 16 bits -or- high 16 bits clear
+#ifdef WITH_TAINT_TRACKING
+            if (nativeTarget) {
+            	switch (count) {
+            	case 5:
+            		outs[4] = GET_REGISTER(vsrc1 & 0x0f);
+            		outs[count+5] = GET_REGISTER_TAINT(vsrc1 & 0x0f);
+            	case 4:
+            		outs[3] = GET_REGISTER(vdst >> 12);
+            		outs[count+4] = GET_REGISTER_TAINT(vdst >> 12);
+            	case 3:
+            		outs[2] = GET_REGISTER((vdst & 0x0f00) >> 8);
+            		outs[count+3] = GET_REGISTER_TAINT((vdst & 0x0f00) >> 8);
+            	case 2:
+            		outs[1] = GET_REGISTER((vdst & 0x00f0) >> 4);
+            		outs[count+2] = GET_REGISTER_TAINT((vdst & 0x00f0) >> 4);
+            	case 1:
+            		outs[0] = GET_REGISTER(vdst & 0x0f);
+            		outs[count+1] = GET_REGISTER_TAINT(vdst & 0x0f);
+            	default:
+            		;
+            	}
+            	/* clear the native hack */
+            	outs[count] = TAINT_CLEAR;
+            } else { /* interpreted target */
+            	switch (count) {
+            	case 5:
+            		outs[8] = GET_REGISTER(vsrc1 & 0x0f);
+            		outs[9] = GET_REGISTER_TAINT(vsrc1 & 0x0f);
+            	case 4:
+            		outs[6] = GET_REGISTER(vdst >> 12);
+            		outs[7] = GET_REGISTER_TAINT(vdst >> 12);
+            	case 3:
+            		outs[4] = GET_REGISTER((vdst & 0x0f00) >> 8);
+            		outs[5] = GET_REGISTER_TAINT((vdst & 0x0f00) >> 8);
+            	case 2:
+            		outs[2] = GET_REGISTER((vdst & 0x00f0) >> 4);
+            		outs[3] = GET_REGISTER_TAINT((vdst & 0x00f0) >> 4);
+            	case 1:
+            		outs[0] = GET_REGISTER(vdst & 0x0f);
+            		outs[1] = GET_REGISTER_TAINT(vdst & 0x0f);
+           	default:
+            		;
+              	}
+            	/* clear the native hack */
+            	outs[count<<1] = TAINT_CLEAR;
+            }
+#else /* ndef WITH_TAINT_TRACKING */
             switch (count) {
             case 5:
                 outs[4] = GET_REGISTER(vsrc1 & 0x0f);
@@ -2129,6 +2519,7 @@ GOTO_TARGET(invokeMethod, bool methodCallRange, const Method* _methodToCall,
             default:
                 ;
             }
+#endif /* WITH_TAINT_TRACKING */
 #endif
         }
     }
@@ -2150,13 +2541,23 @@ GOTO_TARGET(invokeMethod, bool methodCallRange, const Method* _methodToCall,
             methodToCall->clazz->descriptor, methodToCall->name,
             methodToCall->shorty);
 
+#ifdef WITH_TAINT_TRACKING
+        newFp = (u4*) SAVEAREA_FROM_FP(fp) -
+	    ((methodToCall->registersSize << 1) + 1);
+#else
         newFp = (u4*) SAVEAREA_FROM_FP(fp) - methodToCall->registersSize;
+#endif
         newSaveArea = SAVEAREA_FROM_FP(newFp);
 
         /* verify that we have enough space */
         if (true) {
             u1* bottom;
+#ifdef WITH_TAINT_TRACKING
+            bottom = (u1*) newSaveArea -
+            		(methodToCall->outsSize * sizeof(u4) + 4);
+#else
             bottom = (u1*) newSaveArea - methodToCall->outsSize * sizeof(u4);
+#endif
             if (bottom < self->interpStackEnd) {
                 /* stack overflow */
                 ALOGV("Stack overflow on method call (start=%p end=%p newBot=%p(%d) size=%d '%s')",
@@ -2179,8 +2580,15 @@ GOTO_TARGET(invokeMethod, bool methodCallRange, const Method* _methodToCall,
              * messages are disabled -- we want valgrind to report any
              * used-before-initialized issues.
              */
+#ifdef WITH_TAINT_TRACKING
+	    /* Don't need to worry about native target, because if
+	     * native target, registerSize = insSize */
+            memset(newFp, 0xcc,
+                (methodToCall->registersSize - methodToCall->insSize) * 8);
+#else
             memset(newFp, 0xcc,
                 (methodToCall->registersSize - methodToCall->insSize) * 4);
+#endif
         }
 #endif
 
@@ -2245,6 +2653,16 @@ GOTO_TARGET(invokeMethod, bool methodCallRange, const Method* _methodToCall,
              */
             (*methodToCall->nativeFunc)(newFp, &retval, methodToCall, self);
 
+#ifdef WITH_TAINT_TRACKING
+            /* Get the return taint if available */
+            {
+            	/* use same logic as above to calculate count */
+            	u4 count = (methodCallRange) ? vsrc1 : vsrc1 >> 4;
+            	u4* outs = OUTS_FROM_FP(fp, count);
+            	SET_RETURN_TAINT(outs[count]);
+            }
+#endif
+
             if (self->interpBreak.ctl.subMode != 0) {
                 dvmReportPostNativeInvoke(methodToCall, self, fp);
             }
@@ -2295,3 +2713,8 @@ GOTO_TARGET_END
 #undef self
 #undef debugTrackedRefStart
 
+#ifdef WITH_TAINT_TRACKING
+#undef rtaint
+#endif
+
+
diff --git a/vm/mterp/out/InterpC-x86.cpp b/vm/mterp/out/InterpC-x86.cpp
index 8d77b94..6c3e012 100644
--- a/vm/mterp/out/InterpC-x86.cpp
+++ b/vm/mterp/out/InterpC-x86.cpp
@@ -143,6 +143,31 @@ static const char kSpacing[] = "            ";
 # define DUMP_REGS(_meth, _frame, _inOnly) ((void)0)
 #endif
 
+/*
+ * If enabled, log taint propagation
+ */
+#ifdef WITH_TAINT_TRACKING
+# define TLOGD(...) TLOG(LOG_DEBUG, __VA_ARGS__)
+# define TLOGV(...) TLOG(LOG_VERBOSE, __VA_ARGS__)
+# define TLOGW(...) TLOG(LOG_WARN, __VA_ARGS__)
+# define TLOGE(...) TLOG(LOG_ERROR, __VA_ARGS__)
+# define TLOG(_level, ...) do {                                             \
+        char debugStrBuf[128];                                              \
+        snprintf(debugStrBuf, sizeof(debugStrBuf), __VA_ARGS__);            \
+        if (curMethod != NULL)                                              \
+            ALOG(_level, LOG_TAG"t", "%-2d|%04x|%s.%s:%s\n",                \
+                self->threadId, (int)(pc - curMethod->insns), curMethod->clazz->descriptor, curMethod->name, debugStrBuf); \
+        else                                                                \
+            ALOG(_level, LOG_TAG"t", "%-2d|####%s\n",                       \
+                self->threadId, debugStrBuf);                               \
+    } while(false)
+#else
+# define TLOGD(...) ((void)0)
+# define TLOGV(...) ((void)0)
+# define TLOGW(...) ((void)0)
+# define TLOGE(...) ((void)0)
+#endif
+
 /* get a long from an array of u4 */
 static inline s8 getLongFromArray(const u4* ptr, int idx)
 {
@@ -160,6 +185,20 @@ static inline s8 getLongFromArray(const u4* ptr, int idx)
 #endif
 }
 
+#ifdef WITH_TAINT_TRACKING
+/* get a long from an array of u4 */
+static inline s8 getLongFromArrayTaint(const u4* ptr, int idx)
+{
+    /* Need to use the "union" version for taint tracking */
+    union { s8 ll; u4 parts[2]; } conv;
+
+    ptr += idx;
+    conv.parts[0] = ptr[0];
+    conv.parts[1] = ptr[2];
+    return conv.ll;
+}
+#endif
+
 /* store a long into an array of u4 */
 static inline void putLongToArray(u4* ptr, int idx, s8 val)
 {
@@ -175,6 +214,20 @@ static inline void putLongToArray(u4* ptr, int idx, s8 val)
 #endif
 }
 
+#ifdef WITH_TAINT_TRACKING
+/* store a long into an array of u4 */
+static inline void putLongToArrayTaint(u4* ptr, int idx, s8 val)
+{
+    /* Need to use the "union" version for taint tracking */
+    union { s8 ll; u4 parts[2]; } conv;
+
+    ptr += idx;
+    conv.ll = val;
+    ptr[0] = conv.parts[0];
+    ptr[2] = conv.parts[1];
+}
+#endif
+
 /* get a double from an array of u4 */
 static inline double getDoubleFromArray(const u4* ptr, int idx)
 {
@@ -192,6 +245,20 @@ static inline double getDoubleFromArray(const u4* ptr, int idx)
 #endif
 }
 
+#ifdef WITH_TAINT_TRACKING
+/* get a double from an array of u4 */
+static inline double getDoubleFromArrayTaint(const u4* ptr, int idx)
+{
+    /* Need to use the "union" version for taint tracking */
+    union { double d; u4 parts[2]; } conv;
+
+    ptr += idx;
+    conv.parts[0] = ptr[0];
+    conv.parts[1] = ptr[2];
+    return conv.d;
+}
+#endif
+
 /* store a double into an array of u4 */
 static inline void putDoubleToArray(u4* ptr, int idx, double dval)
 {
@@ -207,6 +274,20 @@ static inline void putDoubleToArray(u4* ptr, int idx, double dval)
 #endif
 }
 
+#ifdef WITH_TAINT_TRACKING
+/* store a double into an array of u4 */
+static inline void putDoubleToArrayTaint(u4* ptr, int idx, double dval)
+{
+    /* Need to use the "union" version for taint tracking */
+    union { double d; u4 parts[2]; } conv;
+
+    ptr += idx;
+    conv.d = dval;
+    ptr[0] = conv.parts[0];
+    ptr[2] = conv.parts[1];
+}
+#endif
+
 /*
  * If enabled, validate the register number on every access.  Otherwise,
  * just do an array access.
@@ -215,6 +296,55 @@ static inline void putDoubleToArray(u4* ptr, int idx, double dval)
  *
  * "_idx" may be referenced more than once.
  */
+#ifdef WITH_TAINT_TRACKING
+/* -- Begin Taint Tracking version ------------------------------- */
+/* Taint tags are interleaved between registers. All indexes must
+ * be multiplied by 2 (i.e., left bit shift by 1) */
+#ifdef CHECK_REGISTER_INDICES
+# define GET_REGISTER(_idx) \
+    ( (_idx) < curMethod->registersSize ? \
+        (fp[(_idx)<<1]) : (assert(!"bad reg"),1969) )
+# define SET_REGISTER(_idx, _val) \
+    ( (_idx) < curMethod->registersSize ? \
+        (fp[(_idx)<<1] = (u4)(_val)) : (assert(!"bad reg"),1969) )
+# define GET_REGISTER_AS_OBJECT(_idx)       ((Object *)GET_REGISTER(_idx))
+# define SET_REGISTER_AS_OBJECT(_idx, _val) SET_REGISTER(_idx, (s4)_val)
+# define GET_REGISTER_INT(_idx) ((s4) GET_REGISTER(_idx))
+# define SET_REGISTER_INT(_idx, _val) SET_REGISTER(_idx, (s4)_val)
+# define GET_REGISTER_WIDE(_idx) \
+    ( (_idx) < curMethod->registersSize-1 ? \
+        getLongFromArrayTaint(fp, ((_idx)<<1)) : (assert(!"bad reg"),1969) )
+# define SET_REGISTER_WIDE(_idx, _val) \
+    ( (_idx) < curMethod->registersSize-1 ? \
+        putLongToArrayTaint(fp, ((_idx)<<1), (_val)) : (assert(!"bad reg"),1969) )
+# define GET_REGISTER_FLOAT(_idx) \
+    ( (_idx) < curMethod->registersSize ? \
+        (*((float*) &fp[(_idx)<<1])) : (assert(!"bad reg"),1969.0f) )
+# define SET_REGISTER_FLOAT(_idx, _val) \
+    ( (_idx) < curMethod->registersSize ? \
+        (*((float*) &fp[(_idx)<<1]) = (_val)) : (assert(!"bad reg"),1969.0f) )
+# define GET_REGISTER_DOUBLE(_idx) \
+    ( (_idx) < curMethod->registersSize-1 ? \
+        getDoubleFromArrayTaint(fp, ((_idx)<<1)) : (assert(!"bad reg"),1969.0) )
+# define SET_REGISTER_DOUBLE(_idx, _val) \
+    ( (_idx) < curMethod->registersSize-1 ? \
+        putDoubleToArrayTaint(fp, ((_idx)<<1), (_val)) : (assert(!"bad reg"),1969.0) )
+#else
+# define GET_REGISTER(_idx)                 (fp[(_idx)<<1])
+# define SET_REGISTER(_idx, _val)           (fp[(_idx)<<1] = (_val))
+# define GET_REGISTER_AS_OBJECT(_idx)       ((Object*) fp[(_idx)<<1])
+# define SET_REGISTER_AS_OBJECT(_idx, _val) (fp[(_idx)<<1] = (u4)(_val))
+# define GET_REGISTER_INT(_idx)             ((s4)GET_REGISTER(_idx))
+# define SET_REGISTER_INT(_idx, _val)       SET_REGISTER(_idx, (s4)_val)
+# define GET_REGISTER_WIDE(_idx)            getLongFromArrayTaint(fp, ((_idx)<<1))
+# define SET_REGISTER_WIDE(_idx, _val)      putLongToArrayTaint(fp, ((_idx)<<1), (_val))
+# define GET_REGISTER_FLOAT(_idx)           (*((float*) &fp[(_idx)<<1]))
+# define SET_REGISTER_FLOAT(_idx, _val)     (*((float*) &fp[(_idx)<<1]) = (_val))
+# define GET_REGISTER_DOUBLE(_idx)          getDoubleFromArrayTaint(fp, ((_idx)<<1))
+# define SET_REGISTER_DOUBLE(_idx, _val)    putDoubleToArrayTaint(fp, ((_idx)<<1), (_val))
+#endif
+/* -- End Taint Tracking version ---------------------------------- */
+#else /* no taint tracking */
 #ifdef CHECK_REGISTER_INDICES
 # define GET_REGISTER(_idx) \
     ( (_idx) < curMethod->registersSize ? \
@@ -258,6 +388,48 @@ static inline void putDoubleToArray(u4* ptr, int idx, double dval)
 # define GET_REGISTER_DOUBLE(_idx)          getDoubleFromArray(fp, (_idx))
 # define SET_REGISTER_DOUBLE(_idx, _val)    putDoubleToArray(fp, (_idx), (_val))
 #endif
+#endif /* end no taint tracking */
+
+#ifdef WITH_TAINT_TRACKING
+/* Core get and set macros */
+# define GET_REGISTER_TAINT(_idx)	     (fp[((_idx)<<1)+1])
+# define SET_REGISTER_TAINT(_idx, _val)	     (fp[((_idx)<<1)+1] = (u4)(_val))
+# define GET_REGISTER_TAINT_WIDE(_idx)       (fp[((_idx)<<1)+1])
+# define SET_REGISTER_TAINT_WIDE(_idx, _val) (fp[((_idx)<<1)+1] = \
+	                                      fp[((_idx)<<1)+3] = (u4)(_val))
+/* Alternate interfaces to help dereference register width */
+# define GET_REGISTER_TAINT_INT(_idx)	          GET_REGISTER_TAINT(_idx)
+# define SET_REGISTER_TAINT_INT(_idx, _val)       SET_REGISTER_TAINT(_idx, _val)
+# define GET_REGISTER_TAINT_FLOAT(_idx)	          GET_REGISTER_TAINT(_idx)
+# define SET_REGISTER_TAINT_FLOAT(_idx, _val)     SET_REGISTER_TAINT(_idx, _val)
+# define GET_REGISTER_TAINT_DOUBLE(_idx)          GET_REGISTER_TAINT_WIDE(_idx)
+# define SET_REGISTER_TAINT_DOUBLE(_idx, _val)    SET_REGISTER_TAINT_WIDE(_idx, _val)
+# define GET_REGISTER_TAINT_AS_OBJECT(_idx)       GET_REGISTER_TAINT(_idx)
+# define SET_REGISTER_TAINT_AS_OBJECT(_idx, _val) SET_REGISTER_TAINT(_idx, _val)
+
+/* Object Taint interface */
+# define GET_ARRAY_TAINT(_arr)		      ((_arr)->taint.tag)
+# define SET_ARRAY_TAINT(_arr, _val)	      ((_arr)->taint.tag = (u4)(_val))
+
+/* Return value taint (assumes rtaint variable is in scope */
+# define GET_RETURN_TAINT()		      (rtaint.tag)
+# define SET_RETURN_TAINT(_val)		      (rtaint.tag = (u4)(_val))
+#else
+# define GET_REGISTER_TAINT(_idx)		    ((void)0)
+# define SET_REGISTER_TAINT(_idx, _val)		    ((void)0)
+# define GET_REGISTER_TAINT_WIDE(_idx)		    ((void)0)
+# define SET_REGISTER_TAINT_WIDE(_idx, _val)	    ((void)0)
+# define GET_REGISTER_TAINT_INT(_idx)		    ((void)0)
+# define SET_REGISTER_TAINT_INT(_idx, _val)	    ((void)0)
+# define GET_REGISTER_TAINT_DOUBLE(_idx)	    ((void)0)
+# define SET_REGISTER_TAINT_DOUBLE(_idx, _val)	    ((void)0)
+# define GET_REGISTER_TAINT_AS_OBJECT(_idx)	    ((void)0)
+# define SET_REGISTER_TAINT_AS_OBJECT(_idx, _val)   ((void)0)
+# define GET_ARRAY_TAINT(_field)                    ((void)0)
+# define SET_ARRAY_TAINT(_field, _val)              ((void)0)
+# define GET_RETURN_TAINT()			    ((void)0)
+# define SET_RETURN_TAINT(_val)			    ((void)0)
+#endif
 
 /*
  * Get 16 bits from the specified offset of the program counter.  We always
@@ -399,6 +571,10 @@ static inline bool checkForNullExportPC(Object* obj, u4* fp, const u2* pc)
 #define methodClassDex          self->interpSave.methodClassDex
 #define debugTrackedRefStart    self->interpSave.debugTrackedRefStart
 
+#ifdef WITH_TAINT_TRACKING
+#define rtaint			self->interpSave.rtaint
+#endif
+
 /* ugh */
 #define STUB_HACK(x) x
 #if defined(WITH_JIT)
@@ -537,6 +713,10 @@ GOTO_TARGET_DECL(exceptionThrown);
         ILOGV("|%s v%d,v%d", (_opname), vdst, vsrc1);                       \
         SET_REGISTER##_totype(vdst,                                         \
             GET_REGISTER##_fromtype(vsrc1));                                \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT##_totype(vdst,                                   \
+	    GET_REGISTER_TAINT##_fromtype(vsrc1));                          \
+/* endif */                                                                 \
         FINISH(1);
 
 #define HANDLE_FLOAT_TO_INT(_opcode, _opname, _fromvtype, _fromrtype,       \
@@ -562,6 +742,10 @@ GOTO_TARGET_DECL(exceptionThrown);
         else                                                                \
             result = (_tovtype) val;                                        \
         SET_REGISTER##_tortype(vdst, result);                               \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT##_tortype(vdst,                                  \
+	    GET_REGISTER_TAINT##_fromrtype(vsrc1));                         \
+/* endif */                                                                 \
     }                                                                       \
     FINISH(1);
 
@@ -571,6 +755,9 @@ GOTO_TARGET_DECL(exceptionThrown);
         vsrc1 = INST_B(inst);                                               \
         ILOGV("|int-to-%s v%d,v%d", (_opname), vdst, vsrc1);                \
         SET_REGISTER(vdst, (_type) GET_REGISTER(vsrc1));                    \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT(vdst, GET_REGISTER_TAINT(vsrc1));                \
+/* endif */                                                                 \
         FINISH(1);
 
 /* NOTE: the comparison result is always a signed 4-byte integer */
@@ -597,6 +784,9 @@ GOTO_TARGET_DECL(exceptionThrown);
             result = (_nanVal);                                             \
         ILOGV("+ result=%d", result);                                       \
         SET_REGISTER(vdst, result);                                         \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT(vdst, TAINT_CLEAR);				    \
+/* endif */                                                                 \
     }                                                                       \
     FINISH(2);
 
@@ -638,6 +828,9 @@ GOTO_TARGET_DECL(exceptionThrown);
         vsrc1 = INST_B(inst);                                               \
         ILOGV("|%s v%d,v%d", (_opname), vdst, vsrc1);                       \
         SET_REGISTER##_type(vdst, _pfx GET_REGISTER##_type(vsrc1) _sfx);    \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT##_type(vdst, GET_REGISTER_TAINT##_type(vsrc1));  \
+/* endif */                                                                 \
         FINISH(1);
 
 #define HANDLE_OP_X_INT(_opcode, _opname, _op, _chkdiv)                     \
@@ -672,6 +865,10 @@ GOTO_TARGET_DECL(exceptionThrown);
             SET_REGISTER(vdst,                                              \
                 (s4) GET_REGISTER(vsrc1) _op (s4) GET_REGISTER(vsrc2));     \
         }                                                                   \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT(vdst,                                            \
+	    (GET_REGISTER_TAINT(vsrc1)|GET_REGISTER_TAINT(vsrc2)) );        \
+/* endif */                                                                 \
     }                                                                       \
     FINISH(2);
 
@@ -686,6 +883,10 @@ GOTO_TARGET_DECL(exceptionThrown);
         ILOGV("|%s-int v%d,v%d", (_opname), vdst, vsrc1);                   \
         SET_REGISTER(vdst,                                                  \
             _cast GET_REGISTER(vsrc1) _op (GET_REGISTER(vsrc2) & 0x1f));    \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT(vdst,                                            \
+	    (GET_REGISTER_TAINT(vsrc1)|GET_REGISTER_TAINT(vsrc2)) );        \
+/* endif */                                                                 \
     }                                                                       \
     FINISH(2);
 
@@ -702,7 +903,7 @@ GOTO_TARGET_DECL(exceptionThrown);
             if ((s2) vsrc2 == 0) {                                          \
                 EXPORT_PC();                                                \
                 dvmThrowArithmeticException("divide by zero");              \
-                GOTO_exceptionThrown();                                     \
+                GOTO_exceptionThrown();                                      \
             }                                                               \
             if ((u4)firstVal == 0x80000000 && ((s2) vsrc2) == -1) {         \
                 /* won't generate /lit16 instr for this; check anyway */    \
@@ -718,6 +919,9 @@ GOTO_TARGET_DECL(exceptionThrown);
             /* non-div/rem case */                                          \
             SET_REGISTER(vdst, GET_REGISTER(vsrc1) _op (s2) vsrc2);         \
         }                                                                   \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT(vdst, GET_REGISTER_TAINT(vsrc1));                \
+/* endif */                                                                 \
         FINISH(2);
 
 #define HANDLE_OP_X_INT_LIT8(_opcode, _opname, _op, _chkdiv)                \
@@ -751,6 +955,9 @@ GOTO_TARGET_DECL(exceptionThrown);
             SET_REGISTER(vdst,                                              \
                 (s4) GET_REGISTER(vsrc1) _op (s1) vsrc2);                   \
         }                                                                   \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT(vdst, GET_REGISTER_TAINT(vsrc1));                \
+/* endif */                                                                 \
     }                                                                       \
     FINISH(2);
 
@@ -766,6 +973,9 @@ GOTO_TARGET_DECL(exceptionThrown);
             (_opname), vdst, vsrc1, vsrc2);                                 \
         SET_REGISTER(vdst,                                                  \
             _cast GET_REGISTER(vsrc1) _op (vsrc2 & 0x1f));                  \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT(vdst, GET_REGISTER_TAINT(vsrc1));                \
+/* endif */                                                                 \
     }                                                                       \
     FINISH(2);
 
@@ -796,6 +1006,10 @@ GOTO_TARGET_DECL(exceptionThrown);
             SET_REGISTER(vdst,                                              \
                 (s4) GET_REGISTER(vdst) _op (s4) GET_REGISTER(vsrc1));      \
         }                                                                   \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT(vdst,                                            \
+	    (GET_REGISTER_TAINT(vdst)|GET_REGISTER_TAINT(vsrc1)) );         \
+/* endif */                                                                 \
         FINISH(1);
 
 #define HANDLE_OP_SHX_INT_2ADDR(_opcode, _opname, _cast, _op)               \
@@ -805,6 +1019,10 @@ GOTO_TARGET_DECL(exceptionThrown);
         ILOGV("|%s-int-2addr v%d,v%d", (_opname), vdst, vsrc1);             \
         SET_REGISTER(vdst,                                                  \
             _cast GET_REGISTER(vdst) _op (GET_REGISTER(vsrc1) & 0x1f));     \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT(vdst,                                            \
+	    (GET_REGISTER_TAINT(vdst)|GET_REGISTER_TAINT(vsrc1)) );         \
+/* endif */                                                                 \
         FINISH(1);
 
 #define HANDLE_OP_X_LONG(_opcode, _opname, _op, _chkdiv)                    \
@@ -840,6 +1058,10 @@ GOTO_TARGET_DECL(exceptionThrown);
             SET_REGISTER_WIDE(vdst,                                         \
                 (s8) GET_REGISTER_WIDE(vsrc1) _op (s8) GET_REGISTER_WIDE(vsrc2)); \
         }                                                                   \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT_WIDE(vdst,                                       \
+	   (GET_REGISTER_TAINT_WIDE(vsrc1)|GET_REGISTER_TAINT_WIDE(vsrc2)));\
+/* endif */                                                                 \
     }                                                                       \
     FINISH(2);
 
@@ -854,6 +1076,10 @@ GOTO_TARGET_DECL(exceptionThrown);
         ILOGV("|%s-long v%d,v%d,v%d", (_opname), vdst, vsrc1, vsrc2);       \
         SET_REGISTER_WIDE(vdst,                                             \
             _cast GET_REGISTER_WIDE(vsrc1) _op (GET_REGISTER(vsrc2) & 0x3f)); \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT_WIDE(vdst,                                       \
+	   (GET_REGISTER_TAINT_WIDE(vsrc1)|GET_REGISTER_TAINT_WIDE(vsrc2)));\
+/* endif */                                                                 \
     }                                                                       \
     FINISH(2);
 
@@ -886,6 +1112,10 @@ GOTO_TARGET_DECL(exceptionThrown);
             SET_REGISTER_WIDE(vdst,                                         \
                 (s8) GET_REGISTER_WIDE(vdst) _op (s8)GET_REGISTER_WIDE(vsrc1));\
         }                                                                   \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT_WIDE(vdst,                                       \
+	    (GET_REGISTER_TAINT_WIDE(vdst)|GET_REGISTER_TAINT_WIDE(vsrc1)));\
+/* endif */                                                                 \
         FINISH(1);
 
 #define HANDLE_OP_SHX_LONG_2ADDR(_opcode, _opname, _cast, _op)              \
@@ -895,6 +1125,10 @@ GOTO_TARGET_DECL(exceptionThrown);
         ILOGV("|%s-long-2addr v%d,v%d", (_opname), vdst, vsrc1);            \
         SET_REGISTER_WIDE(vdst,                                             \
             _cast GET_REGISTER_WIDE(vdst) _op (GET_REGISTER(vsrc1) & 0x3f)); \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT_WIDE(vdst,                                       \
+	    (GET_REGISTER_TAINT_WIDE(vdst)|GET_REGISTER_TAINT_WIDE(vsrc1)));\
+/* endif */                                                                 \
         FINISH(1);
 
 #define HANDLE_OP_X_FLOAT(_opcode, _opname, _op)                            \
@@ -908,6 +1142,10 @@ GOTO_TARGET_DECL(exceptionThrown);
         ILOGV("|%s-float v%d,v%d,v%d", (_opname), vdst, vsrc1, vsrc2);      \
         SET_REGISTER_FLOAT(vdst,                                            \
             GET_REGISTER_FLOAT(vsrc1) _op GET_REGISTER_FLOAT(vsrc2));       \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT_FLOAT(vdst,                                      \
+	    (GET_REGISTER_TAINT_FLOAT(vsrc1)|GET_REGISTER_TAINT_FLOAT(vsrc2)));\
+/* endif */                                                                 \
     }                                                                       \
     FINISH(2);
 
@@ -922,6 +1160,10 @@ GOTO_TARGET_DECL(exceptionThrown);
         ILOGV("|%s-double v%d,v%d,v%d", (_opname), vdst, vsrc1, vsrc2);     \
         SET_REGISTER_DOUBLE(vdst,                                           \
             GET_REGISTER_DOUBLE(vsrc1) _op GET_REGISTER_DOUBLE(vsrc2));     \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT_DOUBLE(vdst,                                     \
+	    (GET_REGISTER_TAINT_DOUBLE(vsrc1)|GET_REGISTER_TAINT_DOUBLE(vsrc2)));\
+/* endif */                                                                 \
     }                                                                       \
     FINISH(2);
 
@@ -932,6 +1174,10 @@ GOTO_TARGET_DECL(exceptionThrown);
         ILOGV("|%s-float-2addr v%d,v%d", (_opname), vdst, vsrc1);           \
         SET_REGISTER_FLOAT(vdst,                                            \
             GET_REGISTER_FLOAT(vdst) _op GET_REGISTER_FLOAT(vsrc1));        \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT_FLOAT(vdst,                                      \
+	    (GET_REGISTER_TAINT_FLOAT(vdst)|GET_REGISTER_TAINT_FLOAT(vsrc1)));\
+/* endif */                                                                 \
         FINISH(1);
 
 #define HANDLE_OP_X_DOUBLE_2ADDR(_opcode, _opname, _op)                     \
@@ -941,6 +1187,10 @@ GOTO_TARGET_DECL(exceptionThrown);
         ILOGV("|%s-double-2addr v%d,v%d", (_opname), vdst, vsrc1);          \
         SET_REGISTER_DOUBLE(vdst,                                           \
             GET_REGISTER_DOUBLE(vdst) _op GET_REGISTER_DOUBLE(vsrc1));      \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+        SET_REGISTER_TAINT_DOUBLE(vdst,                                     \
+	    (GET_REGISTER_TAINT_DOUBLE(vdst)|GET_REGISTER_TAINT_DOUBLE(vsrc1)));\
+/* endif */                                                                 \
         FINISH(1);
 
 #define HANDLE_OP_AGET(_opcode, _opname, _type, _regsize)                   \
@@ -965,6 +1215,11 @@ GOTO_TARGET_DECL(exceptionThrown);
         SET_REGISTER##_regsize(vdst,                                        \
             ((_type*)(void*)arrayObj->contents)[GET_REGISTER(vsrc2)]);      \
         ILOGV("+ AGET[%d]=%#x", GET_REGISTER(vsrc2), GET_REGISTER(vdst));   \
+/* ifdef WITH_TAINT_TRACKING */						    \
+	SET_REGISTER_TAINT##_regsize(vdst,                                  \
+	    (GET_ARRAY_TAINT(arrayObj)|GET_REGISTER_TAINT(vsrc2)));         \
+/* endif */								    \
+        ILOGV("+ AGET[%d]=0x%x", GET_REGISTER(vsrc2), GET_REGISTER(vdst));  \
     }                                                                       \
     FINISH(2);
 
@@ -990,6 +1245,11 @@ GOTO_TARGET_DECL(exceptionThrown);
         ILOGV("+ APUT[%d]=0x%08x", GET_REGISTER(vsrc2), GET_REGISTER(vdst));\
         ((_type*)(void*)arrayObj->contents)[GET_REGISTER(vsrc2)] =          \
             GET_REGISTER##_regsize(vdst);                                   \
+/* ifdef WITH_TAINT_TRACKING */						    \
+	SET_ARRAY_TAINT(arrayObj,                                           \
+		(GET_ARRAY_TAINT(arrayObj) |                                \
+		 GET_REGISTER_TAINT##_regsize(vdst)) );                     \
+/* endif */								    \
     }                                                                       \
     FINISH(2);
 
@@ -1033,6 +1293,11 @@ GOTO_TARGET_DECL(exceptionThrown);
             dvmGetField##_ftype(obj, ifield->byteOffset));                  \
         ILOGV("+ IGET '%s'=0x%08llx", ifield->field.name,                   \
             (u8) GET_REGISTER##_regsize(vdst));                             \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+	SET_REGISTER_TAINT##_regsize(vdst,                                  \
+	    (GET_REGISTER_TAINT(vsrc1)|                                     \
+	     dvmGetFieldTaint##_ftype(obj,ifield->byteOffset)) );           \
+/* endif */                                                                 \
     }                                                                       \
     FINISH(2);
 
@@ -1051,6 +1316,13 @@ GOTO_TARGET_DECL(exceptionThrown);
         SET_REGISTER##_regsize(vdst, dvmGetField##_ftype(obj, ref));        \
         ILOGV("+ IGETQ %d=0x%08llx", ref,                                   \
             (u8) GET_REGISTER##_regsize(vdst));                             \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+	/*TLOGW("|IGETQ not supported by taint tracking!!!");*/             \
+	/* compile flag WITH_TAINT_ODEX controls this now */                \
+	SET_REGISTER_TAINT##_regsize(vdst,                                  \
+	    (GET_REGISTER_TAINT(vsrc1)|                                     \
+	     dvmGetFieldTaint##_ftype(obj,ref)) );                          \
+/* endif */                                                                 \
     }                                                                       \
     FINISH(2);
 
@@ -1077,6 +1349,10 @@ GOTO_TARGET_DECL(exceptionThrown);
             GET_REGISTER##_regsize(vdst));                                  \
         ILOGV("+ IPUT '%s'=0x%08llx", ifield->field.name,                   \
             (u8) GET_REGISTER##_regsize(vdst));                             \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+	dvmSetFieldTaint##_ftype(obj, ifield->byteOffset,                   \
+		GET_REGISTER_TAINT##_regsize(vdst));                        \
+/* endif */                                                                 \
     }                                                                       \
     FINISH(2);
 
@@ -1095,6 +1371,12 @@ GOTO_TARGET_DECL(exceptionThrown);
         dvmSetField##_ftype(obj, ref, GET_REGISTER##_regsize(vdst));        \
         ILOGV("+ IPUTQ %d=0x%08llx", ref,                                   \
             (u8) GET_REGISTER##_regsize(vdst));                             \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+	/*TLOGW("|IPUTQ not supported by taint tracking!!!");*/             \
+	/* compile flag WITH_TAINT_ODEX controls this now */                \
+	dvmSetFieldTaint##_ftype(obj, ref,                                  \
+		GET_REGISTER_TAINT##_regsize(vdst));                        \
+/* endif */                                                                 \
     }                                                                       \
     FINISH(2);
 
@@ -1126,6 +1408,9 @@ GOTO_TARGET_DECL(exceptionThrown);
         SET_REGISTER##_regsize(vdst, dvmGetStaticField##_ftype(sfield));    \
         ILOGV("+ SGET '%s'=0x%08llx",                                       \
             sfield->field.name, (u8)GET_REGISTER##_regsize(vdst));          \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+	SET_REGISTER_TAINT##_regsize(vdst, dvmGetStaticFieldTaint##_ftype(sfield));\
+/* endif */                                                                 \
     }                                                                       \
     FINISH(2);
 
@@ -1149,9 +1434,14 @@ GOTO_TARGET_DECL(exceptionThrown);
         dvmSetStaticField##_ftype(sfield, GET_REGISTER##_regsize(vdst));    \
         ILOGV("+ SPUT '%s'=0x%08llx",                                       \
             sfield->field.name, (u8)GET_REGISTER##_regsize(vdst));          \
+/* ifdef WITH_TAINT_TRACKING */                                             \
+	dvmSetStaticFieldTaint##_ftype(sfield,                              \
+		GET_REGISTER_TAINT##_regsize(vdst));                        \
+/* endif */                                                                 \
     }                                                                       \
     FINISH(2);
 
+
 /* File: c/OP_IGET_WIDE_VOLATILE.cpp */
 HANDLE_IGET_X(OP_IGET_WIDE_VOLATILE,    "-wide-volatile", LongVolatile, _WIDE)
 OP_END
@@ -1174,6 +1464,11 @@ HANDLE_OPCODE(OP_EXECUTE_INLINE_RANGE /*{vCCCC..v(CCCC+AA-1)}, inline@BBBB*/)
         u4 arg0, arg1, arg2, arg3;
         arg0 = arg1 = arg2 = arg3 = 0;      /* placate gcc */
 
+#ifdef WITH_TAINT_TRACKING
+	u4 arg0_taint, arg1_taint;
+	arg0_taint = arg1_taint = 0;
+#endif /*WITH_TAINT_TRACKING*/
+
         EXPORT_PC();
 
         vsrc1 = INST_AA(inst);      /* #of args */
@@ -1194,20 +1489,36 @@ HANDLE_OPCODE(OP_EXECUTE_INLINE_RANGE /*{vCCCC..v(CCCC+AA-1)}, inline@BBBB*/)
             /* fall through */
         case 2:
             arg1 = GET_REGISTER(vdst+1);
+#ifdef WITH_TAINT_TRACKING
+	    arg1_taint = GET_REGISTER_TAINT(vdst+1);
+#endif /*WITH_TAINT_TRACKING*/
             /* fall through */
         case 1:
             arg0 = GET_REGISTER(vdst+0);
+#ifdef WITH_TAINT_TRACKING
+            arg0_taint = GET_REGISTER_TAINT(vdst+0);
+#endif /*WITH_TAINT_TRACKING*/
             /* fall through */
         default:        // case 0
             ;
         }
 
         if (self->interpBreak.ctl.subMode & kSubModeDebuggerActive) {
+#ifdef WITH_TAINT_TRACKING
+            if (!dvmPerformInlineOp4Dbg(arg0, arg1, arg2, arg3, arg0_taint, arg1_taint, &rtaint, &retval, ref))
+                GOTO_exceptionThrown();
+#else
             if (!dvmPerformInlineOp4Dbg(arg0, arg1, arg2, arg3, &retval, ref))
                 GOTO_exceptionThrown();
+#endif /*WITH_TAINT_TRACKING*/
         } else {
+#ifdef WITH_TAINT_TRACKING
+            if (!dvmPerformInlineOp4Std(arg0, arg1, arg2, arg3, arg0_taint, arg1_taint, &rtaint, &retval, ref))
+                GOTO_exceptionThrown();
+#else
             if (!dvmPerformInlineOp4Std(arg0, arg1, arg2, arg3, &retval, ref))
                 GOTO_exceptionThrown();
+#endif /*WITH_TAINT_TRACKING*/
         }
     }
     FINISH(3);
@@ -1250,6 +1561,9 @@ HANDLE_OPCODE(OP_RETURN_VOID_BARRIER /**/)
 #ifndef NDEBUG
     retval.j = 0xababababULL;   /* placate valgrind */
 #endif
+/* ifdef WITH_TAINT_TRACKING */
+    SET_RETURN_TAINT(TAINT_CLEAR);
+/* endif */
     ANDROID_MEMBAR_STORE();
     GOTO_returnFromMethod();
 OP_END
@@ -1355,6 +1669,9 @@ GOTO_TARGET(filledNewArray, bool methodCallRange, bool)
         }
 
         retval.l = (Object*)newArray;
+/* ifdef WITH_TAINT_TRACKING */
+        SET_RETURN_TAINT(TAINT_CLEAR);
+/* endif */
     }
     FINISH(3);
 GOTO_TARGET_END
@@ -2024,6 +2341,9 @@ GOTO_TARGET(invokeMethod, bool methodCallRange, const Method* _methodToCall,
 
         u4* outs;
         int i;
+#ifdef WITH_TAINT_TRACKING
+        bool nativeTarget = dvmIsNativeMethod(methodToCall);
+#endif
 
         /*
          * Copy args.  This may corrupt vsrc1/vdst.
@@ -2034,8 +2354,31 @@ GOTO_TARGET(invokeMethod, bool methodCallRange, const Method* _methodToCall,
             assert(vsrc1 <= curMethod->outsSize);
             assert(vsrc1 == methodToCall->insSize);
             outs = OUTS_FROM_FP(fp, vsrc1);
+#ifdef WITH_TAINT_TRACKING
+            if (nativeTarget) {
+            	for (i = 0; i < vsrc1; i++) {
+            		outs[i] = GET_REGISTER(vdst+i);
+            	}
+            	/* clear return taint (vsrc1 is the count) */
+            	outs[vsrc1] = TAINT_CLEAR;
+            	/* copy the taint tags (vsrc1 is the count) */
+            	for (i = 0; i < vsrc1; i++) {
+            		outs[vsrc1+1+i] = GET_REGISTER_TAINT(vdst+i);
+            	}
+            } else {
+            	int slot = 0;
+            	for (i = 0; i < vsrc1; i++) {
+            		slot = i << 1;
+            		outs[slot] = GET_REGISTER(vdst+i);
+            		outs[slot+1] = GET_REGISTER_TAINT(vdst+i);
+            	}
+            	/* clear native hack (vsrc1 is the count)*/
+            	outs[vsrc1<<1] = TAINT_CLEAR;
+            }
+#else
             for (i = 0; i < vsrc1; i++)
                 outs[i] = GET_REGISTER(vdst+i);
+#endif
         } else {
             u4 count = vsrc1 >> 4;
 
@@ -2057,6 +2400,53 @@ GOTO_TARGET(invokeMethod, bool methodCallRange, const Method* _methodToCall,
             // This version executes fewer instructions but is larger
             // overall.  Seems to be a teensy bit faster.
             assert((vdst >> 16) == 0);  // 16 bits -or- high 16 bits clear
+#ifdef WITH_TAINT_TRACKING
+            if (nativeTarget) {
+            	switch (count) {
+            	case 5:
+            		outs[4] = GET_REGISTER(vsrc1 & 0x0f);
+            		outs[count+5] = GET_REGISTER_TAINT(vsrc1 & 0x0f);
+            	case 4:
+            		outs[3] = GET_REGISTER(vdst >> 12);
+            		outs[count+4] = GET_REGISTER_TAINT(vdst >> 12);
+            	case 3:
+            		outs[2] = GET_REGISTER((vdst & 0x0f00) >> 8);
+            		outs[count+3] = GET_REGISTER_TAINT((vdst & 0x0f00) >> 8);
+            	case 2:
+            		outs[1] = GET_REGISTER((vdst & 0x00f0) >> 4);
+            		outs[count+2] = GET_REGISTER_TAINT((vdst & 0x00f0) >> 4);
+            	case 1:
+            		outs[0] = GET_REGISTER(vdst & 0x0f);
+            		outs[count+1] = GET_REGISTER_TAINT(vdst & 0x0f);
+            	default:
+            		;
+            	}
+            	/* clear the native hack */
+            	outs[count] = TAINT_CLEAR;
+            } else { /* interpreted target */
+            	switch (count) {
+            	case 5:
+            		outs[8] = GET_REGISTER(vsrc1 & 0x0f);
+            		outs[9] = GET_REGISTER_TAINT(vsrc1 & 0x0f);
+            	case 4:
+            		outs[6] = GET_REGISTER(vdst >> 12);
+            		outs[7] = GET_REGISTER_TAINT(vdst >> 12);
+            	case 3:
+            		outs[4] = GET_REGISTER((vdst & 0x0f00) >> 8);
+            		outs[5] = GET_REGISTER_TAINT((vdst & 0x0f00) >> 8);
+            	case 2:
+            		outs[2] = GET_REGISTER((vdst & 0x00f0) >> 4);
+            		outs[3] = GET_REGISTER_TAINT((vdst & 0x00f0) >> 4);
+            	case 1:
+            		outs[0] = GET_REGISTER(vdst & 0x0f);
+            		outs[1] = GET_REGISTER_TAINT(vdst & 0x0f);
+           	default:
+            		;
+              	}
+            	/* clear the native hack */
+            	outs[count<<1] = TAINT_CLEAR;
+            }
+#else /* ndef WITH_TAINT_TRACKING */
             switch (count) {
             case 5:
                 outs[4] = GET_REGISTER(vsrc1 & 0x0f);
@@ -2071,6 +2461,7 @@ GOTO_TARGET(invokeMethod, bool methodCallRange, const Method* _methodToCall,
             default:
                 ;
             }
+#endif /* WITH_TAINT_TRACKING */
 #endif
         }
     }
@@ -2092,13 +2483,23 @@ GOTO_TARGET(invokeMethod, bool methodCallRange, const Method* _methodToCall,
             methodToCall->clazz->descriptor, methodToCall->name,
             methodToCall->shorty);
 
+#ifdef WITH_TAINT_TRACKING
+        newFp = (u4*) SAVEAREA_FROM_FP(fp) -
+	    ((methodToCall->registersSize << 1) + 1);
+#else
         newFp = (u4*) SAVEAREA_FROM_FP(fp) - methodToCall->registersSize;
+#endif
         newSaveArea = SAVEAREA_FROM_FP(newFp);
 
         /* verify that we have enough space */
         if (true) {
             u1* bottom;
+#ifdef WITH_TAINT_TRACKING
+            bottom = (u1*) newSaveArea -
+            		(methodToCall->outsSize * sizeof(u4) + 4);
+#else
             bottom = (u1*) newSaveArea - methodToCall->outsSize * sizeof(u4);
+#endif
             if (bottom < self->interpStackEnd) {
                 /* stack overflow */
                 ALOGV("Stack overflow on method call (start=%p end=%p newBot=%p(%d) size=%d '%s')",
@@ -2121,8 +2522,15 @@ GOTO_TARGET(invokeMethod, bool methodCallRange, const Method* _methodToCall,
              * messages are disabled -- we want valgrind to report any
              * used-before-initialized issues.
              */
+#ifdef WITH_TAINT_TRACKING
+	    /* Don't need to worry about native target, because if
+	     * native target, registerSize = insSize */
+            memset(newFp, 0xcc,
+                (methodToCall->registersSize - methodToCall->insSize) * 8);
+#else
             memset(newFp, 0xcc,
                 (methodToCall->registersSize - methodToCall->insSize) * 4);
+#endif
         }
 #endif
 
@@ -2187,6 +2595,16 @@ GOTO_TARGET(invokeMethod, bool methodCallRange, const Method* _methodToCall,
              */
             (*methodToCall->nativeFunc)(newFp, &retval, methodToCall, self);
 
+#ifdef WITH_TAINT_TRACKING
+            /* Get the return taint if available */
+            {
+            	/* use same logic as above to calculate count */
+            	u4 count = (methodCallRange) ? vsrc1 : vsrc1 >> 4;
+            	u4* outs = OUTS_FROM_FP(fp, count);
+            	SET_RETURN_TAINT(outs[count]);
+            }
+#endif
+
             if (self->interpBreak.ctl.subMode != 0) {
                 dvmReportPostNativeInvoke(methodToCall, self, fp);
             }
@@ -2237,3 +2655,8 @@ GOTO_TARGET_END
 #undef self
 #undef debugTrackedRefStart
 
+#ifdef WITH_TAINT_TRACKING
+#undef rtaint
+#endif
+
+
diff --git a/vm/mterp/portable/enddefs.cpp b/vm/mterp/portable/enddefs.cpp
index ef28e2f..abdc734 100644
--- a/vm/mterp/portable/enddefs.cpp
+++ b/vm/mterp/portable/enddefs.cpp
@@ -3,5 +3,8 @@
 bail:
     ILOGD("|-- Leaving interpreter loop");      // note "curMethod" may be NULL
 
+#ifdef WITH_TAINT_TRACKING
+    self->interpSave.rtaint = rtaint;
+#endif
     self->interpSave.retval = retval;
 }
diff --git a/vm/mterp/portable/entry.cpp b/vm/mterp/portable/entry.cpp
index f8c01eb..c81413a 100644
--- a/vm/mterp/portable/entry.cpp
+++ b/vm/mterp/portable/entry.cpp
@@ -10,6 +10,9 @@ void dvmInterpretPortable(Thread* self)
 #endif
     DvmDex* methodClassDex;     // curMethod->clazz->pDvmDex
     JValue retval;
+#ifdef WITH_TAINT_TRACKING
+    Taint rtaint;
+#endif
 
     /* core state */
     const Method* curMethod;    // method we're interpreting
@@ -31,6 +34,9 @@ void dvmInterpretPortable(Thread* self)
     pc = self->interpSave.pc;
     fp = self->interpSave.curFrame;
     retval = self->interpSave.retval;   /* only need for kInterpEntryReturn? */
+#ifdef WITH_TAINT_TRACKING
+    rtaint = self->interpSave.rtaint;
+#endif
 
     methodClassDex = curMethod->clazz->pDvmDex;
 
diff --git a/vm/native/InternalNative.cpp b/vm/native/InternalNative.cpp
index 0d06ea7..933b194 100644
--- a/vm/native/InternalNative.cpp
+++ b/vm/native/InternalNative.cpp
@@ -53,6 +53,9 @@ static DalvikNativeClass gDvmNativeMethodSet[] = {
     { "Ldalvik/system/VMRuntime;",        dvm_dalvik_system_VMRuntime, 0 },
     { "Ldalvik/system/Zygote;",           dvm_dalvik_system_Zygote, 0 },
     { "Ldalvik/system/VMStack;",          dvm_dalvik_system_VMStack, 0 },
+#ifdef WITH_TAINT_TRACKING
+    { "Ldalvik/system/Taint;",            dvm_dalvik_system_Taint, 0 },
+#endif
     { "Lorg/apache/harmony/dalvik/ddmc/DdmServer;",
             dvm_org_apache_harmony_dalvik_ddmc_DdmServer, 0 },
     { "Lorg/apache/harmony/dalvik/ddmc/DdmVmInternal;",
diff --git a/vm/native/InternalNativePriv.h b/vm/native/InternalNativePriv.h
index 0925a61..20378e0 100644
--- a/vm/native/InternalNativePriv.h
+++ b/vm/native/InternalNativePriv.h
@@ -35,6 +35,12 @@
 #define RETURN_FLOAT(_val)      do { pResult->f = (_val); return; } while(0)
 #define RETURN_DOUBLE(_val)     do { pResult->d = (_val); return; } while(0)
 #define RETURN_PTR(_val)        do { pResult->l = (Object*)(_val); return; } while(0)
+#ifdef WITH_TAINT_TRACKING
+/* use "->i" instead of "->c" and "->b" because interpreter expects 32-bit
+ * value, as described above */
+#define RETURN_CHAR(_val)       do { pResult->i = (_val); return; } while(0)
+#define RETURN_BYTE(_val)       do { pResult->i = (_val); return; } while(0)
+#endif
 
 /*
  * Normally a method that has an "inline native" will be invoked using
@@ -44,11 +50,19 @@
  *
  * This macro is used to implement the native methods that bridge this gap.
  */
+#ifdef WITH_TAINT_TRACKING
+#define MAKE_INTRINSIC_TRAMPOLINE(INTRINSIC_FN) \
+    extern bool INTRINSIC_FN(u4 arg0, u4 arg1, u4 arg2, u4 arg3, u4 arg0_taint, u4 arg1_taint, struct Taint* rtaint, \
+            JValue* pResult); \
+	Taint rtaint;		\
+	rtaint.tag = args[4]; \
+    INTRINSIC_FN(args[0], args[1], args[2], args[3], args[5], args[6], &rtaint, pResult);
+#else
 #define MAKE_INTRINSIC_TRAMPOLINE(INTRINSIC_FN) \
-    extern bool INTRINSIC_FN(u4 arg0, u4 arg1, u4 arg2, u4 arg3, \
+	extern bool INTRINSIC_FN(u4 arg0, u4 arg1, u4 arg2, u4 arg3, \
             JValue* pResult); \
     INTRINSIC_FN(args[0], args[1], args[2], args[3], pResult);
-
+#endif
 /*
  * Verify that "obj" is non-null and is an instance of "clazz".
  *
@@ -111,5 +125,8 @@ extern const DalvikNativeMethod dvm_org_apache_harmony_dalvik_ddmc_DdmServer[];
 extern const DalvikNativeMethod dvm_org_apache_harmony_dalvik_ddmc_DdmVmInternal[];
 extern const DalvikNativeMethod dvm_org_apache_harmony_dalvik_NativeTestTarget[];
 extern const DalvikNativeMethod dvm_sun_misc_Unsafe[];
+#ifdef WITH_TAINT_TRACKING
+extern const DalvikNativeMethod dvm_dalvik_system_Taint[];
+#endif
 
 #endif  // DALVIK_NATIVE_INTERNALNATIVEPRIV_H_
diff --git a/vm/native/dalvik_system_Taint.cpp b/vm/native/dalvik_system_Taint.cpp
new file mode 100644
index 0000000..8956ec8
--- /dev/null
+++ b/vm/native/dalvik_system_Taint.cpp
@@ -0,0 +1,751 @@
+/*
+ * Copyright (c) 2010 The Pennsylvania State University
+ * Systems and Internet Infrastructure Security Laboratory
+ *
+ * Authors: William Enck <enck@cse.psu.edu>
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+/*
+ * dalvik.system.Taint
+ */
+#include "Dalvik.h"
+#include "native/InternalNativePriv.h"
+#include "attr/xattr.h"
+
+#include <errno.h>
+
+#define TAINT_XATTR_NAME "user.taint"
+
+/*
+ * public static void addTaintString(String str, int tag)
+ */
+static void Dalvik_dalvik_system_Taint_addTaintString(const u4* args,
+    JValue* pResult)
+{
+    StringObject *strObj = (StringObject*) args[0];
+    u4 tag = args[1];
+    ArrayObject *value = NULL;
+
+    if (strObj) {
+    value = strObj->array();
+	value->taint.tag |= tag;
+    }
+    RETURN_VOID();
+}
+
+/*
+ * public static void addTaintObjectArray(Object[] array, int tag)
+ */
+static void Dalvik_dalvik_system_Taint_addTaintObjectArray(const u4* args,
+    JValue* pResult)
+{
+    ArrayObject *arr = (ArrayObject *) args[0];
+    u4 tag = args[1];
+    if (arr) {
+	arr->taint.tag |= tag;
+    }
+    RETURN_VOID();
+}
+
+/*
+ * public static void addTaintBooleanArray(boolean[] array, int tag)
+ */
+static void Dalvik_dalvik_system_Taint_addTaintBooleanArray(const u4* args,
+    JValue* pResult)
+{
+    ArrayObject *arr = (ArrayObject *) args[0];
+    u4 tag = args[1];
+    if (arr) {
+	arr->taint.tag |= tag;
+    }
+    RETURN_VOID();
+}
+
+/*
+ * public static void addTaintCharArray(char[] array, int tag)
+ */
+static void Dalvik_dalvik_system_Taint_addTaintCharArray(const u4* args,
+    JValue* pResult)
+{
+    ArrayObject *arr = (ArrayObject *) args[0];
+    u4 tag = args[1];
+    if (arr) {
+	arr->taint.tag |= tag;
+    }
+    RETURN_VOID();
+}
+
+/*
+ * public static void addTaintByteArray(byte[] array, int tag)
+ */
+static void Dalvik_dalvik_system_Taint_addTaintByteArray(const u4* args,
+    JValue* pResult)
+{
+    ArrayObject *arr = (ArrayObject *) args[0];
+    u4 tag = args[1];
+    if (arr) {
+	arr->taint.tag |= tag;
+    }
+    RETURN_VOID();
+}
+
+/*
+ * public static void addTaintIntArray(int[] array, int tag)
+ */
+static void Dalvik_dalvik_system_Taint_addTaintIntArray(const u4* args,
+    JValue* pResult)
+{
+    ArrayObject *arr = (ArrayObject *) args[0];
+    u4 tag = args[1];
+    if (arr) {
+	arr->taint.tag |= tag;
+    }
+    RETURN_VOID();
+}
+
+/*
+ * public static void addTaintShortArray(short[] array, int tag)
+ */
+static void Dalvik_dalvik_system_Taint_addTaintShortArray(const u4* args,
+    JValue* pResult)
+{
+    ArrayObject *arr = (ArrayObject *) args[0];
+    u4 tag = args[1];
+    if (arr) {
+	arr->taint.tag |= tag;
+    }
+    RETURN_VOID();
+}
+
+/*
+ * public static void addTaintLongArray(long[] array, int tag)
+ */
+static void Dalvik_dalvik_system_Taint_addTaintLongArray(const u4* args,
+    JValue* pResult)
+{
+    ArrayObject *arr = (ArrayObject *) args[0];
+    u4 tag = args[1];
+    if (arr) {
+	arr->taint.tag |= tag;
+    }
+    RETURN_VOID();
+}
+
+/*
+ * public static void addTaintFloatArray(float[] array, int tag)
+ */
+static void Dalvik_dalvik_system_Taint_addTaintFloatArray(const u4* args,
+    JValue* pResult)
+{
+    ArrayObject *arr = (ArrayObject *) args[0];
+    u4 tag = args[1];
+    if (arr) {
+	arr->taint.tag |= tag;
+    }
+    RETURN_VOID();
+}
+
+/*
+ * public static void addTaintDoubleArray(double[] array, int tag)
+ */
+static void Dalvik_dalvik_system_Taint_addTaintDoubleArray(const u4* args,
+    JValue* pResult)
+{
+    ArrayObject *arr = (ArrayObject *) args[0];
+    u4 tag = args[1];
+    if (arr) {
+	arr->taint.tag |= tag;
+    }
+    RETURN_VOID();
+}
+
+/*
+ * public static boolean addTaintBoolean(boolean val, int tag)
+ */
+static void Dalvik_dalvik_system_Taint_addTaintBoolean(const u4* args,
+    JValue* pResult)
+{
+    u4 val     = args[0];
+    u4 tag     = args[1];	 /* the tag to add */
+    u4* rtaint = (u4*) &args[2]; /* pointer to return taint tag */
+    u4 vtaint  = args[3];	 /* the existing taint tag on val */
+    *rtaint = (vtaint | tag);
+    RETURN_BOOLEAN(val);
+}
+
+/*
+ * public static char addTaintChar(char val, int tag)
+ */
+static void Dalvik_dalvik_system_Taint_addTaintChar(const u4* args,
+    JValue* pResult)
+{
+    u4 val     = args[0];
+    u4 tag     = args[1];         /* the tag to add */
+    u4* rtaint = (u4*) &args[2];  /* pointer to return taint tag */
+    u4 vtaint  = args[3];	  /* the existing taint tag on val */
+    *rtaint = (vtaint | tag);
+    RETURN_CHAR(val);
+}
+
+/*
+ * public static char addTaintByte(byte val, int tag)
+ */
+static void Dalvik_dalvik_system_Taint_addTaintByte(const u4* args,
+    JValue* pResult)
+{
+    u4 val     = args[0];
+    u4 tag     = args[1];         /* the tag to add */
+    u4* rtaint = (u4*) &args[2];  /* pointer to return taint tag */
+    u4 vtaint  = args[3];	  /* the existing taint tag on val */
+    *rtaint = (vtaint | tag);
+    RETURN_BYTE(val);
+}
+
+/*
+ * public static int addTaintInt(int val, int tag)
+ */
+static void Dalvik_dalvik_system_Taint_addTaintInt(const u4* args,
+    JValue* pResult)
+{
+    u4 val     = args[0];
+    u4 tag     = args[1];	  /* the tag to add */
+    u4* rtaint = (u4*) &args[2];  /* pointer to return taint tag */
+    u4 vtaint  = args[3];	  /* the existing taint tag on val */
+    *rtaint = (vtaint | tag);
+    RETURN_INT(val);
+}
+
+/*
+ * public static long addTaintLong(long val, int tag)
+ */
+static void Dalvik_dalvik_system_Taint_addTaintLong(const u4* args,
+    JValue* pResult)
+{
+    u8 val;
+    u4 tag     = args[2];	     /* the tag to add */
+    u4* rtaint = (u4*) &args[3];     /* pointer to return taint tag */
+    u4 vtaint  = args[4];	     /* the existing taint tag on val */
+    memcpy(&val, &args[0], 8);	     /* EABI prevents direct store */
+    *rtaint = (vtaint | tag);
+    RETURN_LONG(val);
+}
+
+/*
+ * public static float addTaintFloat(float val, int tag)
+ */
+static void Dalvik_dalvik_system_Taint_addTaintFloat(const u4* args,
+    JValue* pResult)
+{
+    u4 val     = args[0];
+    u4 tag     = args[1];	  /* the tag to add */
+    u4* rtaint = (u4*) &args[2];  /* pointer to return taint tag */
+    u4 vtaint  = args[3];	  /* the existing taint tag on val */
+    *rtaint = (vtaint | tag);
+    RETURN_INT(val);		  /* Be opaque; RETURN_FLOAT doesn't work */
+}
+
+/*
+ * public static double addTaintDouble(double val, int tag)
+ */
+static void Dalvik_dalvik_system_Taint_addTaintDouble(const u4* args,
+    JValue* pResult)
+{
+    u8 val;
+    u4 tag     = args[2];	     /* the tag to add */
+    u4* rtaint = (u4*) &args[3];     /* pointer to return taint tag */
+    u4 vtaint  = args[4];	     /* the existing taint tag on val */
+    memcpy(&val, &args[0], 8);	     /* EABI prevents direct store */
+    *rtaint = (vtaint | tag);
+    RETURN_LONG(val);		     /* Be opaque; RETURN_DOUBLE doesn't work */
+}
+
+/*
+ * public static int getTaintString(String str)
+ */
+static void Dalvik_dalvik_system_Taint_getTaintString(const u4* args,
+    JValue* pResult)
+{
+    StringObject *strObj = (StringObject*) args[0];
+    ArrayObject *value = NULL;
+
+    if (strObj) {
+    value = strObj->array();
+	RETURN_INT(value->taint.tag);
+    } else {
+	RETURN_INT(TAINT_CLEAR);
+    }
+}
+
+/*
+ * public static int getTaintObjectArray(Object[] obj)
+ */
+static void Dalvik_dalvik_system_Taint_getTaintObjectArray(const u4* args,
+    JValue* pResult)
+{
+    ArrayObject *arr = (ArrayObject *) args[0];
+    if (arr) {
+	RETURN_INT(arr->taint.tag);
+    } else {
+	RETURN_INT(TAINT_CLEAR);
+    }
+}
+
+/*
+ * public static int getTaintBooleanArray(boolean[] array)
+ */
+static void Dalvik_dalvik_system_Taint_getTaintBooleanArray(const u4* args,
+    JValue* pResult)
+{
+    ArrayObject *arr = (ArrayObject *) args[0];
+    if (arr) {
+	RETURN_INT(arr->taint.tag);
+    } else {
+	RETURN_INT(TAINT_CLEAR);
+    }
+}
+
+/*
+ * public static int getTaintCharArray(char[] array)
+ */
+static void Dalvik_dalvik_system_Taint_getTaintCharArray(const u4* args,
+    JValue* pResult)
+{
+    ArrayObject *arr = (ArrayObject *) args[0];
+    if (arr) {
+	RETURN_INT(arr->taint.tag);
+    } else {
+	RETURN_INT(TAINT_CLEAR);
+    }
+}
+
+/*
+ * public static int getTaintByteArray(byte[] array)
+ */
+static void Dalvik_dalvik_system_Taint_getTaintByteArray(const u4* args,
+    JValue* pResult)
+{
+    ArrayObject *arr = (ArrayObject *) args[0];
+    if (arr) {
+	RETURN_INT(arr->taint.tag);
+    } else {
+	RETURN_INT(TAINT_CLEAR);
+    }
+}
+
+/*
+ * public static int getTaintIntArray(int[] array)
+ */
+static void Dalvik_dalvik_system_Taint_getTaintIntArray(const u4* args,
+    JValue* pResult)
+{
+    ArrayObject *arr = (ArrayObject *) args[0];
+    if (arr) {
+	RETURN_INT(arr->taint.tag);
+    } else {
+	RETURN_INT(TAINT_CLEAR);
+    }
+}
+
+/*
+ * public static int getTaintShortArray(short[] array)
+ */
+static void Dalvik_dalvik_system_Taint_getTaintShortArray(const u4* args,
+    JValue* pResult)
+{
+    ArrayObject *arr = (ArrayObject *) args[0];
+    if (arr) {
+	RETURN_INT(arr->taint.tag);
+    } else {
+	RETURN_INT(TAINT_CLEAR);
+    }
+}
+
+/*
+ * public static int getTaintLongArray(long[] array)
+ */
+static void Dalvik_dalvik_system_Taint_getTaintLongArray(const u4* args,
+    JValue* pResult)
+{
+    ArrayObject *arr = (ArrayObject *) args[0];
+    if (arr) {
+	RETURN_INT(arr->taint.tag);
+    } else {
+	RETURN_INT(TAINT_CLEAR);
+    }
+}
+
+/*
+ * public static int getTaintFloatArray(float[] array)
+ */
+static void Dalvik_dalvik_system_Taint_getTaintFloatArray(const u4* args,
+    JValue* pResult)
+{
+    ArrayObject *arr = (ArrayObject *) args[0];
+    if (arr) {
+	RETURN_INT(arr->taint.tag);
+    } else {
+	RETURN_INT(TAINT_CLEAR);
+    }
+}
+
+/*
+ * public static int getTaintDoubleArray(double[] array)
+ */
+static void Dalvik_dalvik_system_Taint_getTaintDoubleArray(const u4* args,
+    JValue* pResult)
+{
+    ArrayObject *arr = (ArrayObject *) args[0];
+    if (arr) {
+	RETURN_INT(arr->taint.tag);
+    } else{
+	RETURN_INT(TAINT_CLEAR);
+    }
+}
+
+/*
+ * public static int getTaintBoolean(boolean val)
+ */
+static void Dalvik_dalvik_system_Taint_getTaintBoolean(const u4* args,
+    JValue* pResult)
+{
+    // args[0] = the value
+    // args[1] = the return taint
+    u4 tag = args[2]; /* the existing taint */
+    RETURN_INT(tag);
+}
+
+/*
+ * public static int getTaintChar(char val)
+ */
+static void Dalvik_dalvik_system_Taint_getTaintChar(const u4* args,
+    JValue* pResult)
+{
+    // args[0] = the value
+    // args[1] = the return taint
+    u4 tag = args[2]; /* the existing taint */
+    RETURN_INT(tag);
+}
+
+/*
+ * public static int getTaintByte(byte val)
+ */
+static void Dalvik_dalvik_system_Taint_getTaintByte(const u4* args,
+    JValue* pResult)
+{
+    // args[0] = the value
+    // args[1] = the return taint
+    u4 tag = args[2]; /* the existing taint */
+    RETURN_INT(tag);
+}
+
+/*
+ * public static int getTaintInt(int val)
+ */
+static void Dalvik_dalvik_system_Taint_getTaintInt(const u4* args,
+    JValue* pResult)
+{
+    // args[0] = the value
+    // args[1] = the return taint
+    u4 tag = args[2]; /* the existing taint */
+    RETURN_INT(tag);
+}
+
+/*
+ * public static int getTaintLong(long val)
+ */
+static void Dalvik_dalvik_system_Taint_getTaintLong(const u4* args,
+    JValue* pResult)
+{
+    // args[0:1] = the value
+    // args[2] = the return taint
+    u4 tag = args[3]; /* the existing taint */
+    RETURN_INT(tag);
+}
+
+/*
+ * public static int getTaintFloat(float val)
+ */
+static void Dalvik_dalvik_system_Taint_getTaintFloat(const u4* args,
+    JValue* pResult)
+{
+    // args[0] = the value
+    // args[1] = the return taint
+    u4 tag = args[2]; /* the existing taint */
+    RETURN_INT(tag);
+}
+
+/*
+ * public static int getTaintDouble(long val)
+ */
+static void Dalvik_dalvik_system_Taint_getTaintDouble(const u4* args,
+    JValue* pResult)
+{
+    // args[0:1] = the value
+    // args[2] = the return taint
+    u4 tag = args[3]; /* the existing taint */
+    RETURN_INT(tag);
+}
+
+/*
+ * public static int getTaintRef(Object obj)
+ */
+static void Dalvik_dalvik_system_Taint_getTaintRef(const u4* args,
+    JValue* pResult)
+{
+    // args[0] = the value
+    // args[1] = the return taint
+    u4 tag = args[2]; /* the existing taint */
+    RETURN_INT(tag);
+}
+
+static u4 getTaintXattr(int fd)
+{
+    int ret;
+    u4 buf;
+    u4 tag = TAINT_CLEAR;
+
+    ret = fgetxattr(fd, TAINT_XATTR_NAME, &buf, sizeof(buf));
+    if (ret > 0) {
+	tag = buf;
+    } else {
+	if (errno == ENOATTR) {
+	    /* do nothing */
+	} else if (errno == ERANGE) {
+	    ALOGW("TaintLog: fgetxattr(%d) contents to large", fd);
+	} else if (errno == ENOTSUP) {
+	    /* XATTRs are not supported. No need to spam the logs */
+	} else if (errno == EPERM) {
+	    /* Strange interaction with /dev/log/main. Suppress the log */
+	} else {
+	    ALOGW("TaintLog: fgetxattr(%d): unknown error code %d", fd, errno);
+	}
+    }
+
+    return tag;
+}
+
+static void setTaintXattr(int fd, u4 tag)
+{
+    int ret;
+
+    ret = fsetxattr(fd, TAINT_XATTR_NAME, &tag, sizeof(tag), 0);
+
+    if (ret < 0) {
+	if (errno == ENOSPC || errno == EDQUOT) {
+	    ALOGW("TaintLog: fsetxattr(%d): not enough room to set xattr", fd);
+	} else if (errno == ENOTSUP) {
+	    /* XATTRs are not supported. No need to spam the logs */
+	} else if (errno == EPERM) {
+	    /* Strange interaction with /dev/log/main. Suppress the log */
+	} else {
+	    ALOGW("TaintLog: fsetxattr(%d): unknown error code %d", fd, errno);
+	}
+    }
+
+}
+
+/*
+ * public static int getTaintFile(int fd)
+ */
+static void Dalvik_dalvik_system_Taint_getTaintFile(const u4* args,
+    JValue* pResult)
+{
+    u4 tag;
+    int fd = (int)args[0]; // args[0] = the file descriptor
+    // args[1] = the return taint
+    // args[2] = fd taint
+
+    tag = getTaintXattr(fd);
+
+    if (tag) {
+	ALOGI("TaintLog: getTaintFile(%d) = 0x%08x", fd, tag);
+    }
+
+    RETURN_INT(tag);
+}
+
+/*
+ * public static int addTaintFile(int fd, u4 tag)
+ */
+static void Dalvik_dalvik_system_Taint_addTaintFile(const u4* args,
+    JValue* pResult)
+{
+    u4 otag;
+    int fd = (int)args[0]; // args[0] = the file descriptor
+    u4 tag = args[1];      // args[1] = the taint tag
+    // args[2] = the return taint
+    // args[3] = fd taint
+    // args[4] = tag taint
+
+    otag = getTaintXattr(fd);
+
+    if (tag) {
+	ALOGI("TaintLog: addTaintFile(%d): adding 0x%08x to 0x%08x = 0x%08x",
+		fd, tag, otag, tag | otag);
+    }
+
+    setTaintXattr(fd, tag | otag);
+
+    RETURN_VOID();
+}
+
+/*
+ * public static void log(String msg)
+ */
+static void Dalvik_dalvik_system_Taint_log(const u4* args,
+    JValue* pResult)
+{
+    StringObject* msgObj = (StringObject*) args[0];
+    char *msg;
+
+    if (msgObj == NULL) {
+	dvmThrowNullPointerException("msgObj == NULL");
+	RETURN_VOID();
+    }
+
+	msg = dvmCreateCstrFromString(msgObj);
+	ALOGW("TaintLog: %s", msg);
+	char *curmsg = msg;
+	while(strlen(curmsg) > 1013)
+	{   
+		curmsg = curmsg+1013;
+		ALOGW("%s", curmsg);
+	}   
+	free(msg);
+
+    RETURN_VOID();
+}
+
+/*
+ * public static void logPathFromFd(int fd)
+ */
+static void Dalvik_dalvik_system_Taint_logPathFromFd(const u4* args,
+    JValue* pResult)
+{
+    int fd = (int) args[0];
+    pid_t pid;
+    char ppath[20]; // these path lengths should be enough
+    char rpath[80];
+    int err;
+
+
+    pid = getpid();
+    snprintf(ppath, 20, "/proc/%d/fd/%d", pid, fd);
+    err = readlink(ppath, rpath, 80);
+    if (err >= 0) {
+	ALOGW("TaintLog: fd %d -> %s", fd, rpath);
+    } else {
+	ALOGW("TaintLog: error finding path for fd %d", fd);
+    }
+
+    RETURN_VOID();
+}
+
+/*
+ * public static void logPeerFromFd(int fd)
+ */
+static void Dalvik_dalvik_system_Taint_logPeerFromFd(const u4* args,
+    JValue* pResult)
+{
+    int fd = (int) args[0];
+
+    ALOGW("TaintLog: logPeerFromFd not yet implemented");
+
+    RETURN_VOID();
+}
+
+const DalvikNativeMethod dvm_dalvik_system_Taint[] = {
+    { "addTaintString",  "(Ljava/lang/String;I)V",
+        Dalvik_dalvik_system_Taint_addTaintString},
+    { "addTaintObjectArray",  "([Ljava/lang/Object;I)V",
+        Dalvik_dalvik_system_Taint_addTaintObjectArray},
+    { "addTaintBooleanArray",  "([ZI)V",
+        Dalvik_dalvik_system_Taint_addTaintBooleanArray},
+    { "addTaintCharArray",  "([CI)V",
+        Dalvik_dalvik_system_Taint_addTaintCharArray},
+    { "addTaintByteArray",  "([BI)V",
+        Dalvik_dalvik_system_Taint_addTaintByteArray},
+    { "addTaintIntArray",  "([II)V",
+        Dalvik_dalvik_system_Taint_addTaintIntArray},
+    { "addTaintShortArray",  "([SI)V",
+        Dalvik_dalvik_system_Taint_addTaintShortArray},
+    { "addTaintLongArray",  "([JI)V",
+        Dalvik_dalvik_system_Taint_addTaintLongArray},
+    { "addTaintFloatArray",  "([FI)V",
+        Dalvik_dalvik_system_Taint_addTaintFloatArray},
+    { "addTaintDoubleArray",  "([DI)V",
+        Dalvik_dalvik_system_Taint_addTaintDoubleArray},
+    { "addTaintBoolean",  "(ZI)Z",
+        Dalvik_dalvik_system_Taint_addTaintBoolean},
+    { "addTaintChar",  "(CI)C",
+        Dalvik_dalvik_system_Taint_addTaintChar},
+    { "addTaintByte",  "(BI)B",
+        Dalvik_dalvik_system_Taint_addTaintByte},
+    { "addTaintInt",  "(II)I",
+        Dalvik_dalvik_system_Taint_addTaintInt},
+    { "addTaintLong",  "(JI)J",
+        Dalvik_dalvik_system_Taint_addTaintLong},
+    { "addTaintFloat",  "(FI)F",
+        Dalvik_dalvik_system_Taint_addTaintFloat},
+    { "addTaintDouble",  "(DI)D",
+        Dalvik_dalvik_system_Taint_addTaintDouble},
+    { "getTaintString",  "(Ljava/lang/String;)I",
+        Dalvik_dalvik_system_Taint_getTaintString},
+    { "getTaintObjectArray",  "([Ljava/lang/Object;)I",
+        Dalvik_dalvik_system_Taint_getTaintObjectArray},
+    { "getTaintBooleanArray",  "([Z)I",
+        Dalvik_dalvik_system_Taint_getTaintBooleanArray},
+    { "getTaintCharArray",  "([C)I",
+        Dalvik_dalvik_system_Taint_getTaintCharArray},
+    { "getTaintByteArray",  "([B)I",
+        Dalvik_dalvik_system_Taint_getTaintByteArray},
+    { "getTaintIntArray",  "([I)I",
+        Dalvik_dalvik_system_Taint_getTaintIntArray},
+    { "getTaintShortArray",  "([S)I",
+        Dalvik_dalvik_system_Taint_getTaintShortArray},
+    { "getTaintLongArray",  "([J)I",
+        Dalvik_dalvik_system_Taint_getTaintLongArray},
+    { "getTaintFloatArray",  "([F)I",
+        Dalvik_dalvik_system_Taint_getTaintFloatArray},
+    { "getTaintDoubleArray",  "([D)I",
+        Dalvik_dalvik_system_Taint_getTaintDoubleArray},
+    { "getTaintBoolean",  "(Z)I",
+        Dalvik_dalvik_system_Taint_getTaintBoolean},
+    { "getTaintChar",  "(C)I",
+        Dalvik_dalvik_system_Taint_getTaintChar},
+    { "getTaintByte",  "(B)I",
+        Dalvik_dalvik_system_Taint_getTaintByte},
+    { "getTaintInt",  "(I)I",
+        Dalvik_dalvik_system_Taint_getTaintInt},
+    { "getTaintLong",  "(J)I",
+        Dalvik_dalvik_system_Taint_getTaintLong},
+    { "getTaintFloat",  "(F)I",
+        Dalvik_dalvik_system_Taint_getTaintFloat},
+    { "getTaintDouble",  "(D)I",
+        Dalvik_dalvik_system_Taint_getTaintDouble},
+    { "getTaintRef",  "(Ljava/lang/Object;)I",
+        Dalvik_dalvik_system_Taint_getTaintRef},
+    { "getTaintFile",  "(I)I",
+        Dalvik_dalvik_system_Taint_getTaintFile},
+    { "addTaintFile",  "(II)V",
+        Dalvik_dalvik_system_Taint_addTaintFile},
+    { "log",  "(Ljava/lang/String;)V",
+        Dalvik_dalvik_system_Taint_log},
+    { "logPathFromFd",  "(I)V",
+        Dalvik_dalvik_system_Taint_logPathFromFd},
+    { "logPeerFromFd",  "(I)V",
+        Dalvik_dalvik_system_Taint_logPeerFromFd},
+    { NULL, NULL, NULL },
+};
diff --git a/vm/native/java_lang_Double.cpp b/vm/native/java_lang_Double.cpp
index b019c8c..335117d 100644
--- a/vm/native/java_lang_Double.cpp
+++ b/vm/native/java_lang_Double.cpp
@@ -32,9 +32,18 @@ static void Double_longBitsToDouble(const u4* args, JValue* pResult)
     MAKE_INTRINSIC_TRAMPOLINE(javaLangDouble_longBitsToDouble);
 }
 
+#ifdef WITH_TAINT_TRACKING
+const DalvikNativeMethod dvm_java_lang_Double[] = {
+    { "doubleToLongBits_intrinsic",    "(D)J", Double_doubleToLongBits },
+    { "doubleToRawLongBits_intrinsic", "(D)J", Double_doubleToRawLongBits },
+    { "longBitsToDouble_intrinsic",    "(J)D", Double_longBitsToDouble },
+    { NULL, NULL, NULL },
+};
+#else
 const DalvikNativeMethod dvm_java_lang_Double[] = {
     { "doubleToLongBits",    "(D)J", Double_doubleToLongBits },
     { "doubleToRawLongBits", "(D)J", Double_doubleToRawLongBits },
     { "longBitsToDouble",    "(J)D", Double_longBitsToDouble },
     { NULL, NULL, NULL },
 };
+#endif /*WITH_TAINT_TRACKING*/
diff --git a/vm/native/java_lang_Float.cpp b/vm/native/java_lang_Float.cpp
index e99e4aa..73e451e 100644
--- a/vm/native/java_lang_Float.cpp
+++ b/vm/native/java_lang_Float.cpp
@@ -32,9 +32,18 @@ static void Float_intBitsToFloat(const u4* args, JValue* pResult)
     MAKE_INTRINSIC_TRAMPOLINE(javaLangFloat_intBitsToFloat);
 }
 
+#ifdef WITH_TAINT_TRACKING
+const DalvikNativeMethod dvm_java_lang_Float[] = {
+    { "floatToIntBits_intrinsic",    "(F)I", Float_floatToIntBits },
+    { "floatToRawIntBits_intrinsic", "(F)I", Float_floatToRawIntBits },
+    { "intBitsToFloat_intrinsic",    "(I)F", Float_intBitsToFloat },
+    { NULL, NULL, NULL },
+};
+#else
 const DalvikNativeMethod dvm_java_lang_Float[] = {
     { "floatToIntBits",    "(F)I", Float_floatToIntBits },
     { "floatToRawIntBits", "(F)I", Float_floatToRawIntBits },
     { "intBitsToFloat",    "(I)F", Float_intBitsToFloat },
     { NULL, NULL, NULL },
 };
+#endif /*WITH_TAINT_TRACKING*/
diff --git a/vm/native/java_lang_Math.cpp b/vm/native/java_lang_Math.cpp
index 7c17242..d1341c4 100644
--- a/vm/native/java_lang_Math.cpp
+++ b/vm/native/java_lang_Math.cpp
@@ -62,6 +62,20 @@ static void Math_sqrt(const u4* args, JValue* pResult)
     MAKE_INTRINSIC_TRAMPOLINE(javaLangMath_sqrt);
 }
 
+#ifdef WITH_TAINT_TRACKING
+const DalvikNativeMethod dvm_java_lang_Math[] = {
+    { "abs_intrinsic",  "(D)D",  Math_absD },
+    { "abs_intrinsic",  "(F)F",  Math_absF },
+    { "abs_intrinsic",  "(I)I",  Math_absI },
+    { "abs_intrinsic",  "(J)J",  Math_absJ },
+    { "cos_intrinsic",  "(D)D",  Math_cos },
+    { "max_intrinsic",  "(II)I", Math_maxI },
+    { "min_intrinsic",  "(II)I", Math_minI },
+    { "sin_intrinsic",  "(D)D",  Math_sin },
+    { "sqrt_intrinsic", "(D)D",  Math_sqrt },
+    { NULL, NULL, NULL },
+};
+#else
 const DalvikNativeMethod dvm_java_lang_Math[] = {
     { "abs",  "(D)D",  Math_absD },
     { "abs",  "(F)F",  Math_absF },
@@ -74,3 +88,4 @@ const DalvikNativeMethod dvm_java_lang_Math[] = {
     { "sqrt", "(D)D",  Math_sqrt },
     { NULL, NULL, NULL },
 };
+#endif /*WITH_TAINT_TRACKING*/
diff --git a/vm/native/java_lang_String.cpp b/vm/native/java_lang_String.cpp
index 38f9e31..55fa549 100644
--- a/vm/native/java_lang_String.cpp
+++ b/vm/native/java_lang_String.cpp
@@ -57,6 +57,18 @@ static void String_length(const u4* args, JValue* pResult)
     MAKE_INTRINSIC_TRAMPOLINE(javaLangString_length);
 }
 
+#ifdef WITH_TAINT_TRACKING
+const DalvikNativeMethod dvm_java_lang_String[] = {
+    { "charAt_intrinsic",      "(I)C",                  String_charAt },
+    { "compareTo_intrinsic",   "(Ljava/lang/String;)I", String_compareTo },
+    { "equals_intrinsic",      "(Ljava/lang/Object;)Z", String_equals },
+    { "fastIndexOf_intrinsic", "(II)I",                 String_fastIndexOf },
+    { "intern",      "()Ljava/lang/String;",  String_intern },
+    { "isEmpty_intrinsic",     "()Z",                   String_isEmpty },
+    { "length_intrinsic",      "()I",                   String_length },
+    { NULL, NULL, NULL },
+};
+#else
 const DalvikNativeMethod dvm_java_lang_String[] = {
     { "charAt",      "(I)C",                  String_charAt },
     { "compareTo",   "(Ljava/lang/String;)I", String_compareTo },
@@ -67,3 +79,4 @@ const DalvikNativeMethod dvm_java_lang_String[] = {
     { "length",      "()I",                   String_length },
     { NULL, NULL, NULL },
 };
+#endif /*WITH_TAINT_TRACKING*/
diff --git a/vm/native/java_lang_System.cpp b/vm/native/java_lang_System.cpp
index 6ebf4f3..ff9c301 100644
--- a/vm/native/java_lang_System.cpp
+++ b/vm/native/java_lang_System.cpp
@@ -118,6 +118,9 @@ static void Dalvik_java_lang_System_arraycopy(const u4* args, JValue* pResult)
     ArrayObject* dstArray = (ArrayObject*) args[2];
     int dstPos = args[3];
     int length = args[4];
+#ifdef WITH_TAINT_TRACKING
+    int srcPosTaint = args[7];
+#endif /*WITH_TAINT_TRACKING*/
 
     /* Check for null pointers. */
     if (srcArray == NULL) {
@@ -207,6 +210,14 @@ static void Dalvik_java_lang_System_arraycopy(const u4* args, JValue* pResult)
             ALOGE("Weird array type '%s'", srcClass->descriptor);
             dvmAbort();
         }
+#ifdef WITH_TAINT_TRACKING
+        if (dstPos == 0 && dstArray->length == length) {
+            /* entire array replaced */
+            dstArray->taint.tag = (srcArray->taint.tag | srcPosTaint);
+        } else {
+            dstArray->taint.tag |= (srcArray->taint.tag | srcPosTaint);
+        }
+#endif
     } else {
         /*
          * Neither class is primitive.  See if elements in "src" are instances
@@ -229,6 +240,14 @@ static void Dalvik_java_lang_System_arraycopy(const u4* args, JValue* pResult)
                 (const u1*)srcArray->contents + srcPos * width,
                 length * width);
             dvmWriteBarrierArray(dstArray, dstPos, dstPos+length);
+#ifdef WITH_TAINT_TRACKING
+            if (dstPos == 0 && dstArray->length == length) {
+                /* entire array replaced */
+                dstArray->taint.tag = (srcArray->taint.tag | srcPosTaint);
+            } else {
+                dstArray->taint.tag |= (srcArray->taint.tag | srcPosTaint);
+            }
+#endif
         } else {
             /*
              * The arrays are not fundamentally compatible.  However, we
@@ -274,6 +293,14 @@ static void Dalvik_java_lang_System_arraycopy(const u4* args, JValue* pResult)
                 (const u1*)srcArray->contents + srcPos * width,
                 copyCount * width);
             dvmWriteBarrierArray(dstArray, 0, copyCount);
+#ifdef WITH_TAINT_TRACKING
+            if (dstPos == 0 && dstArray->length == length) {
+                /* entire array replaced */
+                dstArray->taint.tag = (srcArray->taint.tag | srcPosTaint);
+            } else {
+                dstArray->taint.tag |= (srcArray->taint.tag | srcPosTaint);
+            }
+#endif
             if (copyCount != length) {
                 dvmThrowArrayStoreExceptionIncompatibleArrayElement(srcPos + copyCount,
                         srcObj[copyCount]->clazz, dstClass);
diff --git a/vm/native/java_lang_reflect_Field.cpp b/vm/native/java_lang_reflect_Field.cpp
index dac784b..55a20b7 100644
--- a/vm/native/java_lang_reflect_Field.cpp
+++ b/vm/native/java_lang_reflect_Field.cpp
@@ -460,6 +460,9 @@ static void Dalvik_java_lang_reflect_Field_getField(const u4* args,
     ClassObject* fieldType = (ClassObject*) args[3];
     int slot = args[4];
     bool noAccessCheck = (args[5] != 0);
+#ifdef WITH_TAINT_TRACKING
+    u4* rtaint = (u4*) &args[6]; /* return taint tag slot */
+#endif
     Field* field;
     JValue value;
     DataObject* result;
@@ -476,6 +479,31 @@ static void Dalvik_java_lang_reflect_Field_getField(const u4* args,
     /* if it's primitive, box it up */
     result = dvmBoxPrimitive(value, fieldType);
     dvmReleaseTrackedAlloc((Object*) result, NULL);
+
+#ifdef WITH_TAINT_TRACKING
+    /* If we got this far, we know the fields is okay to access and there
+     * will not be a problem getting the field from the slot */
+    {
+    	Field* field = dvmSlotToField(declaringClass, slot);
+    	assert(field != NULL);
+    	if (dvmIsStaticField(field)) {
+    		StaticField* sfield = (StaticField*)field;
+    		*rtaint = dvmGetStaticFieldTaint(sfield);
+    	} else {
+    		/* Note, getFieldDataAddr() already checked that
+    		 * obj is of type declaringClass, so no need to check here
+    		 */
+    		InstField* ifield = (InstField*)field;
+    		if (fieldType->primitiveType == PRIM_LONG ||
+    				fieldType->primitiveType == PRIM_DOUBLE) {
+    			*rtaint = dvmGetFieldTaintWide(obj, ifield->byteOffset);
+    		} else {
+    			*rtaint = dvmGetFieldTaint(obj, ifield->byteOffset);
+    		}
+    	}
+    }
+#endif
+
     RETURN_PTR(result);
 }
 
@@ -496,6 +524,17 @@ static void Dalvik_java_lang_reflect_Field_setField(const u4* args,
     int slot = args[4];
     bool noAccessCheck = (args[5] != 0);
     Object* valueObj = (Object*) args[6];
+#ifdef WITH_TAINT_TRACKING
+    /* rtaint = args[7]
+     * thisPtr taint = args[8]
+     * obj taint = args[9]
+     * declaringClass taint = args[10]
+     * fieldType taint = args[11]
+     * slot taint = args[12]
+     * noAccessCheck taint = args[13]
+     */
+    u4 valueTaint = args[14];
+#endif
     Field* field;
     JValue value;
 
@@ -511,6 +550,31 @@ static void Dalvik_java_lang_reflect_Field_setField(const u4* args,
     if (field != NULL) {
         setFieldValue(field, obj, &value);
     }
+    
+#ifdef WITH_TAINT_TRACKING
+    /* If we got this far, we know the fields is okay to access and there
+     * will not be a problem getting the field from the slot */
+    {
+    	Field* field = dvmSlotToField(declaringClass, slot);
+    	assert(field != NULL);
+    	if (dvmIsStaticField(field)) {
+    		StaticField* sfield = (StaticField*)field;
+    		dvmSetStaticFieldTaint(sfield, valueTaint);
+    	} else {
+    		/* Note, getFieldDataAddr() already checked that
+    		 * obj is of type declaringClass, so no need to check here
+    		 */
+    		InstField* ifield = (InstField*)field;
+    		if (fieldType->primitiveType == PRIM_LONG ||
+    				fieldType->primitiveType == PRIM_DOUBLE) {
+    			dvmSetFieldTaintWide(obj, ifield->byteOffset, valueTaint);
+    		} else {
+    			dvmSetFieldTaint(obj, ifield->byteOffset, valueTaint);
+    		}
+    	}
+    }
+#endif
+
     RETURN_VOID();
 }
 
@@ -529,6 +593,9 @@ static void Dalvik_java_lang_reflect_Field_getPrimitiveField(const u4* args,
     int slot = args[4];
     bool noAccessCheck = (args[5] != 0);
     jchar descriptor = args[6];
+#ifdef WITH_TAINT_TRACKING
+    u4* rtaint = (u4*) &args[7]; /* return taint tag slot */
+#endif
     PrimitiveType targetType = dexGetPrimitiveTypeFromDescriptorChar(descriptor);
     const Field* field;
     JValue value;
@@ -552,6 +619,30 @@ static void Dalvik_java_lang_reflect_Field_getPrimitiveField(const u4* args,
         dvmThrowIllegalArgumentException("invalid primitive conversion");
         RETURN_VOID();
     }
+
+#ifdef WITH_TAINT_TRACKING
+    /* If we got this far, we know the fields is okay to access and there
+     * will not be a problem getting the field from the slot */
+    {
+    	Field* field = dvmSlotToField(declaringClass, slot);
+    	assert(field != NULL);
+    	if (dvmIsStaticField(field)) {
+    		StaticField* sfield = (StaticField*)field;
+    		*rtaint = dvmGetStaticFieldTaint(sfield);
+    	} else {
+    		/* Note, getFieldDataAddr() already checked that
+    		 * obj is of type declaringClass, so no need to check here
+    		 */
+    		InstField* ifield = (InstField*)field;
+    		if (fieldType->primitiveType == PRIM_LONG ||
+    				fieldType->primitiveType == PRIM_DOUBLE) {
+    			*rtaint = dvmGetFieldTaintWide(obj, ifield->byteOffset);
+    		} else {
+    			*rtaint = dvmGetFieldTaint(obj, ifield->byteOffset);
+    		}
+    	}
+    }
+#endif
 }
 
 /*
@@ -570,6 +661,18 @@ static void Dalvik_java_lang_reflect_Field_setPrimitiveField(const u4* args,
     bool noAccessCheck = (args[5] != 0);
     jchar descriptor = args[6];
     const s4* valuePtr = (s4*) &args[7];    /* 64-bit vars spill into args[8] */
+#ifdef WITH_TAINT_TRACKING
+    /* rtaint = args[8]
+     * thisPtr taint = args[9]
+     * obj taint = args[10]
+     * declaringClass taint = args[11]
+     * fieldType taint = args[12]
+     * slot taint = args[13]
+     * noAccessCheck taint = args[14]
+     * typeNum taint = args[15]
+     */
+    u4 valueTaint = args[16];
+#endif
     PrimitiveType srcType = dexGetPrimitiveTypeFromDescriptorChar(descriptor);
     Field* field;
     JValue value;
@@ -593,6 +696,32 @@ static void Dalvik_java_lang_reflect_Field_setPrimitiveField(const u4* args,
     if (field != NULL) {
         setFieldValue(field, obj, &value);
     }
+    
+
+#ifdef WITH_TAINT_TRACKING
+    /* If we got this far, we know the fields is okay to access and there
+     * will not be a problem getting the field from the slot */
+    {
+    	Field* field = dvmSlotToField(declaringClass, slot);
+    	assert(field != NULL);
+    	if (dvmIsStaticField(field)) {
+    		StaticField* sfield = (StaticField*)field;
+    		dvmSetStaticFieldTaint(sfield, valueTaint);
+    	} else {
+    		/* Note, getFieldDataAddr() already checked that
+    		 * obj is of type declaringClass, so no need to check here
+    		 */
+    		InstField* ifield = (InstField*)field;
+    		if (fieldType->primitiveType == PRIM_LONG ||
+    				fieldType->primitiveType == PRIM_DOUBLE) {
+    			dvmSetFieldTaintWide(obj, ifield->byteOffset, valueTaint);
+    		} else {
+    			dvmSetFieldTaint(obj, ifield->byteOffset, valueTaint);
+    		}
+    	}
+    }
+#endif
+
     RETURN_VOID();
 }
 
diff --git a/vm/oo/Array.cpp b/vm/oo/Array.cpp
index 00ec6d9..034eac9 100644
--- a/vm/oo/Array.cpp
+++ b/vm/oo/Array.cpp
@@ -59,6 +59,9 @@ static ArrayObject* allocArray(ClassObject* arrayClass, size_t length,
     if (newArray != NULL) {
         DVM_OBJECT_INIT(newArray, arrayClass);
         newArray->length = length;
+#ifdef WITH_TAINT_TRACKING
+        newArray->taint.tag = TAINT_CLEAR;
+#endif
         dvmTrackAllocation(arrayClass, totalSize);
     }
     return newArray;
diff --git a/vm/oo/Class.cpp b/vm/oo/Class.cpp
index 3a721b6..97cc8f3 100644
--- a/vm/oo/Class.cpp
+++ b/vm/oo/Class.cpp
@@ -2351,6 +2351,10 @@ static void loadSFieldFromDex(ClassObject* clazz,
      */
     //sfield->value.j = 0;
     assert(sfield->value.j == 0LL);     // cleared earlier with calloc
+
+#ifdef WITH_TAINT_TRACKING
+    sfield->taint.tag = TAINT_CLEAR;
+#endif
 }
 
 /*
@@ -3602,7 +3606,11 @@ static bool computeFieldOffsets(ClassObject* clazz)
             break;
 
         pField->byteOffset = fieldOffset;
+#ifdef WITH_TAINT_TRACKING
+        fieldOffset += sizeof(u4) + sizeof(u4); /* interleaved tag */
+#else
         fieldOffset += sizeof(u4);
+#endif
         LOGVV("  --- offset1 '%s'=%d", pField->name,pField->byteOffset);
     }
 
@@ -3614,6 +3622,11 @@ static bool computeFieldOffsets(ClassObject* clazz)
     if (i != clazz->ifieldCount && (fieldOffset & 0x04) != 0) {
         LOGVV("  +++ not aligned");
 
+#ifdef WITH_TAINT_TRACKING
+        /* Technically, this never occurs, but it doesn't hurt to add */
+        ALOGV("  +++ inserting pad field in '%s'\n", clazz->descriptor);
+        fieldOffset += sizeof(u4);
+#else
         InstField* pField = &clazz->ifields[i];
         char c = pField->signature[0];
 
@@ -3657,6 +3670,7 @@ static bool computeFieldOffsets(ClassObject* clazz)
                 fieldOffset += sizeof(u4);
             }
         }
+#endif /* ndef WITH_TAINT_TRACKING */
     }
 
     /*
@@ -3699,9 +3713,15 @@ static bool computeFieldOffsets(ClassObject* clazz)
 
         pField->byteOffset = fieldOffset;
         LOGVV("  --- offset4 '%s'=%d", pField->name,pField->byteOffset);
-        fieldOffset += sizeof(u4);
+#ifdef WITH_TAINT_TRACKING
+        fieldOffset += sizeof(u4) + sizeof(u4); /* room for tag */
+        if (c == 'J' || c == 'D')
+            fieldOffset += sizeof(u4) + sizeof(u4); /* keep 64-bit aligned */
+#else
+	fieldOffset += sizeof(u4);
         if (c == 'J' || c == 'D')
             fieldOffset += sizeof(u4);
+#endif /* ndef WITH_TAINT_TRACKING */
     }
 
 #ifndef NDEBUG
diff --git a/vm/oo/Object.h b/vm/oo/Object.h
index 4e6103a..c9993bd 100644
--- a/vm/oo/Object.h
+++ b/vm/oo/Object.h
@@ -24,6 +24,10 @@
 #include <stddef.h>
 #include "Atomic.h"
 
+#ifdef WITH_TAINT_TRACKING
+#include "interp/Taint.h"
+#endif
+
 /* fwd decl */
 struct DataObject;
 struct InitiatingLoaderList;
@@ -274,6 +278,9 @@ struct ArrayObject : Object {
     /* number of elements; immutable after init */
     u4              length;
 
+#ifdef WITH_TAINT_TRACKING
+    Taint           taint;
+#endif
     /*
      * Array contents; actual size is (length * sizeof(type)).  This is
      * declared as u8 so that the compiler inserts any necessary padding
@@ -311,6 +318,9 @@ struct Field {
  */
 struct StaticField : Field {
     JValue          value;          /* initially set from DEX for primitives */
+#ifdef WITH_TAINT_TRACKING
+    Taint           taint;
+#endif
 };
 
 /*
@@ -350,7 +360,12 @@ struct InstField : Field {
 struct ClassObject : Object {
     /* leave space for instance data; we could access fields directly if we
        freeze the definition of java/lang/Class */
+#ifdef WITH_TAINT_TRACKING
+    // x2 space for interleaved taint tags
+    u4              instanceData[CLASS_FIELD_SLOTS*2];
+#else
     u4              instanceData[CLASS_FIELD_SLOTS];
+#endif /*WITH_TAINT_TRACKING*/
 
     /* UTF-8 descriptor for the class; from constant pool, or on heap
        if generated ("[C") */
diff --git a/vm/oo/ObjectInlines.h b/vm/oo/ObjectInlines.h
index eb2e962..b63dc6a 100644
--- a/vm/oo/ObjectInlines.h
+++ b/vm/oo/ObjectInlines.h
@@ -122,6 +122,65 @@ INLINE Object* dvmGetFieldObjectVolatile(const Object* obj, int offset) {
     return (Object*)android_atomic_acquire_load((int32_t*)ptr);
 }
 
+#ifdef WITH_TAINT_TRACKING
+INLINE u4 dvmGetFieldTaint(const Object* obj, int offset) {
+    return (*(u4*)BYTE_OFFSET(obj, offset+sizeof(u4)));
+}
+INLINE u4 dvmGetFieldTaintWide(const Object* obj, int offset) {
+    return (*(u4*)BYTE_OFFSET(obj, offset+sizeof(u4)+sizeof(u4)));
+}
+INLINE u4 dvmGetFieldTaintVolatile(const Object* obj, int offset) {
+    s4* ptr = &(*(s4*)(BYTE_OFFSET(obj, offset+sizeof(u4))));
+    return (u4)android_atomic_acquire_load(ptr);
+}
+INLINE u4 dvmGetFieldTaintWideVolatile(const Object* obj, int offset) {
+    s4* ptr = &(*(s4*)BYTE_OFFSET(obj, offset+sizeof(u4)+sizeof(u4)));
+    return (u4)android_atomic_acquire_load(ptr);
+}
+#define dvmGetFieldTaintBoolean(_obj, _offset) dvmGetFieldTaint(_obj, _offset)
+#define dvmGetFieldTaintByte(_obj, _offset)    dvmGetFieldTaint(_obj, _offset)
+#define dvmGetFieldTaintShort(_obj, _offset)   dvmGetFieldTaint(_obj, _offset)
+#define dvmGetFieldTaintChar(_obj, _offset)    dvmGetFieldTaint(_obj, _offset)
+#define dvmGetFieldTaintInt(_obj, _offset)     dvmGetFieldTaint(_obj, _offset)
+#define dvmGetFieldTaintLong(_obj, _offset)    dvmGetFieldTaintWide(_obj, _offset)
+#define dvmGetFieldTaintFloat(_obj, _offset)   dvmGetFieldTaint(_obj, _offset)
+#define dvmGetFieldTaintDouble(_obj, _offset)  dvmGetFieldTaintWide(_obj, _offset)
+#define dvmGetFieldTaintObject(_obj, _offset)  dvmGetFieldTaint(_obj, _offset)
+
+#define dvmGetFieldTaintBooleanVolatile(_obj, _offset) dvmGetFieldTaintVolatile(_obj, _offset)
+#define dvmGetFieldTaintByteVolatile(_obj, _offset)    dvmGetFieldTaintVolatile(_obj, _offset)
+#define dvmGetFieldTaintShortVolatile(_obj, _offset)   dvmGetFieldTaintVolatile(_obj, _offset)
+#define dvmGetFieldTaintCharVolatile(_obj, _offset)    dvmGetFieldTaintVolatile(_obj, _offset)
+#define dvmGetFieldTaintIntVolatile(_obj, _offset)     dvmGetFieldTaintVolatile(_obj, _offset)
+#define dvmGetFieldTaintLongVolatile(_obj, _offset)    dvmGetFieldTaintWideVolatile(_obj, _offset)
+#define dvmGetFieldTaintFloatVolatile(_obj, _offset)   dvmGetFieldTaintVolatile(_obj, _offset)
+#define dvmGetFieldTaintDoubleVolatile(_obj, _offset)  dvmGetFieldTaintWideVolatile(_obj, _offset)
+#define dvmGetFieldTaintObjectVolatile(_obj, _offset)  dvmGetFieldTaintVolatile(_obj, _offset)
+#else
+#define dvmGetFieldTaint(_obj, _offset)        ((void)0)
+#define dvmGetFieldTaintWide(_obj, _offset)    ((void)0)
+#define dvmGetFieldTaintBoolean(_obj, _offset) ((void)0)
+#define dvmGetFieldTaintByte(_obj, _offset)    ((void)0)
+#define dvmGetFieldTaintShort(_obj, _offset)   ((void)0)
+#define dvmGetFieldTaintChar(_obj, _offset)    ((void)0)
+#define dvmGetFieldTaintInt(_obj, _offset)     ((void)0)
+#define dvmGetFieldTaintLong(_obj, _offset)    ((void)0)
+#define dvmGetFieldTaintFloat(_obj, _offset)   ((void)0)
+#define dvmGetFieldTaintDouble(_obj, _offset)  ((void)0)
+#define dvmGetFieldTaintObject(_obj, _offset)  ((void)0)
+
+#define dvmGetFieldTaintBooleanVolatile(_obj, _offset) ((void)0)
+#define dvmGetFieldTaintByteVolatile(_obj, _offset)    ((void)0)
+#define dvmGetFieldTaintShortVolatile(_obj, _offset)   ((void)0)
+#define dvmGetFieldTaintCharVolatile(_obj, _offset)    ((void)0)
+#define dvmGetFieldTaintIntVolatile(_obj, _offset)     ((void)0)
+#define dvmGetFieldTaintLongVolatile(_obj, _offset)    ((void)0)
+#define dvmGetFieldTaintFloatVolatile(_obj, _offset)   ((void)0)
+#define dvmGetFieldTaintDoubleVolatile(_obj, _offset)  ((void)0)
+#define dvmGetFieldTaintObjectVolatile(_obj, _offset)  ((void)0)
+#endif
+
+
 INLINE void dvmSetFieldBoolean(Object* obj, int offset, bool val) {
     ((JValue*)BYTE_OFFSET(obj, offset))->i = val;
 }
@@ -200,6 +259,64 @@ INLINE void dvmSetFieldObjectVolatile(Object* obj, int offset, Object* val) {
     }
 }
 
+#ifdef WITH_TAINT_TRACKING
+INLINE void dvmSetFieldTaint(Object* obj, int offset, u4 tag) {
+    (*(u4*)BYTE_OFFSET(obj, offset+sizeof(u4))) = tag;
+}
+INLINE void dvmSetFieldTaintWide(Object* obj, int offset, u4 tag) {
+    (*(u4*)BYTE_OFFSET(obj, offset+sizeof(u4)+sizeof(u4))) = tag;
+}
+INLINE void dvmSetFieldTaintVolatile(Object* obj, int offset, u4 tag) {
+    s4* ptr = &(*(s4*)BYTE_OFFSET(obj, offset+sizeof(u4)));
+    android_atomic_release_store(tag, ptr);
+}
+INLINE void dvmSetFieldTaintWideVolatile(Object* obj, int offset, u4 tag) {
+    s4* ptr = &(*(s4*)BYTE_OFFSET(obj, offset+sizeof(u4)+sizeof(u4)));
+    android_atomic_release_store(tag, ptr);
+}
+#define dvmSetFieldTaintBoolean(_obj, _offset, _tag) dvmSetFieldTaint(_obj, _offset, _tag)
+#define dvmSetFieldTaintByte(_obj, _offset, _tag)    dvmSetFieldTaint(_obj, _offset, _tag)
+#define dvmSetFieldTaintShort(_obj, _offset, _tag)   dvmSetFieldTaint(_obj, _offset, _tag)
+#define dvmSetFieldTaintChar(_obj, _offset, _tag)    dvmSetFieldTaint(_obj, _offset, _tag)
+#define dvmSetFieldTaintInt(_obj, _offset, _tag)     dvmSetFieldTaint(_obj, _offset, _tag)
+#define dvmSetFieldTaintLong(_obj, _offset, _tag)    dvmSetFieldTaintWide(_obj, _offset, _tag)
+#define dvmSetFieldTaintFloat(_obj, _offset, _tag)   dvmSetFieldTaint(_obj, _offset, _tag)
+#define dvmSetFieldTaintDouble(_obj, _offset, _tag)  dvmSetFieldTaintWide(_obj, _offset, _tag)
+#define dvmSetFieldTaintObject(_obj, _offset, _tag)  dvmSetFieldTaint(_obj, _offset, _tag)
+
+#define dvmSetFieldTaintBooleanVolatile(_obj, _offset, _tag) dvmSetFieldTaintVolatile(_obj, _offset, _tag)
+#define dvmSetFieldTaintByteVolatile(_obj, _offset, _tag)    dvmSetFieldTaintVolatile(_obj, _offset, _tag)
+#define dvmSetFieldTaintShortVolatile(_obj, _offset, _tag)   dvmSetFieldTaintVolatile(_obj, _offset, _tag)
+#define dvmSetFieldTaintCharVolatile(_obj, _offset, _tag)    dvmSetFieldTaintVolatile(_obj, _offset, _tag)
+#define dvmSetFieldTaintIntVolatile(_obj, _offset, _tag)     dvmSetFieldTaintVolatile(_obj, _offset, _tag)
+#define dvmSetFieldTaintLongVolatile(_obj, _offset, _tag)    dvmSetFieldTaintWideVolatile(_obj, _offset, _tag)
+#define dvmSetFieldTaintFloatVolatile(_obj, _offset, _tag)   dvmSetFieldTaintVolatile(_obj, _offset, _tag)
+#define dvmSetFieldTaintDoubleVolatile(_obj, _offset, _tag)  dvmSetFieldTaintWideVolatile(_obj, _offset, _tag)
+#define dvmSetFieldTaintObjectVolatile(_obj, _offset, _tag)  dvmSetFieldTaintVolatile(_obj, _offset, _tag)
+#else
+#define dvmSetFieldTaint(_obj, _offset, _tag)        ((void)0)
+#define dvmSetFieldTaintWide(_obj, _offset, _tag)    ((void)0)
+#define dvmSetFieldTaintBoolean(_obj, _offset, _tag) ((void)0)
+#define dvmSetFieldTaintByte(_obj, _offset, _tag)    ((void)0)
+#define dvmSetFieldTaintShort(_obj, _offset, _tag)   ((void)0)
+#define dvmSetFieldTaintChar(_obj, _offset, _tag)    ((void)0)
+#define dvmSetFieldTaintInt(_obj, _offset, _tag)     ((void)0)
+#define dvmSetFieldTaintLong(_obj, _offset, _tag)    ((void)0)
+#define dvmSetFieldTaintFloat(_obj, _offset, _tag)   ((void)0)
+#define dvmSetFieldTaintDouble(_obj, _offset, _tag)  ((void)0)
+#define dvmSetFieldTaintObject(_obj, _offset, _tag)  ((void)0)
+
+#define dvmSetFieldTaintBooleanVolatile(_obj, _offset, _tag) ((void)0)
+#define dvmSetFieldTaintByteVolatile(_obj, _offset, _tag)    ((void)0)
+#define dvmSetFieldTaintShortVolatile(_obj, _offset, _tag)   ((void)0)
+#define dvmSetFieldTaintCharVolatile(_obj, _offset, _tag)    ((void)0)
+#define dvmSetFieldTaintIntVolatile(_obj, _offset, _tag)     ((void)0)
+#define dvmSetFieldTaintLongVolatile(_obj, _offset, _tag)    ((void)0)
+#define dvmSetFieldTaintFloatVolatile(_obj, _offset, _tag)   ((void)0)
+#define dvmSetFieldTaintDoubleVolatile(_obj, _offset, _tag)  ((void)0)
+#define dvmSetFieldTaintObjectVolatile(_obj, _offset, _tag)  ((void)0)
+#endif
+
 /*
  * Static field access functions.
  */
@@ -278,6 +395,56 @@ INLINE Object* dvmGetStaticFieldObjectVolatile(const StaticField* sfield) {
     return (Object*)android_atomic_acquire_load((int32_t*)ptr);
 }
 
+#ifdef WITH_TAINT_TRACKING
+INLINE u4 dvmGetStaticFieldTaint(const StaticField* sfield) {
+    return sfield->taint.tag;
+}
+INLINE u4 dvmGetStaticFieldTaintVolatile(const StaticField* sfield) {
+    const u4* ptr = &(sfield->taint.tag);
+    return (u4)android_atomic_acquire_load((s4*)ptr);
+}
+#define dvmGetStaticFieldTaintBoolean(_sfield) dvmGetStaticFieldTaint(_sfield)
+#define dvmGetStaticFieldTaintByte(_sfield)    dvmGetStaticFieldTaint(_sfield)
+#define dvmGetStaticFieldTaintShort(_sfield)   dvmGetStaticFieldTaint(_sfield)
+#define dvmGetStaticFieldTaintChar(_sfield)    dvmGetStaticFieldTaint(_sfield)
+#define dvmGetStaticFieldTaintInt(_sfield)     dvmGetStaticFieldTaint(_sfield)
+#define dvmGetStaticFieldTaintLong(_sfield)    dvmGetStaticFieldTaint(_sfield)
+#define dvmGetStaticFieldTaintFloat(_sfield)   dvmGetStaticFieldTaint(_sfield)
+#define dvmGetStaticFieldTaintDouble(_sfield)  dvmGetStaticFieldTaint(_sfield)
+#define dvmGetStaticFieldTaintObject(_sfield)  dvmGetStaticFieldTaint(_sfield)
+
+#define dvmGetStaticFieldTaintBooleanVolatile(_sfield) dvmGetStaticFieldTaintVolatile(_sfield)
+#define dvmGetStaticFieldTaintByteVolatile(_sfield)    dvmGetStaticFieldTaintVolatile(_sfield)
+#define dvmGetStaticFieldTaintShortVolatile(_sfield)   dvmGetStaticFieldTaintVolatile(_sfield)
+#define dvmGetStaticFieldTaintCharVolatile(_sfield)    dvmGetStaticFieldTaintVolatile(_sfield)
+#define dvmGetStaticFieldTaintIntVolatile(_sfield)     dvmGetStaticFieldTaintVolatile(_sfield)
+#define dvmGetStaticFieldTaintLongVolatile(_sfield)    dvmGetStaticFieldTaintVolatile(_sfield)
+#define dvmGetStaticFieldTaintFloatVolatile(_sfield)   dvmGetStaticFieldTaintVolatile(_sfield)
+#define dvmGetStaticFieldTaintDoubleVolatile(_sfield)  dvmGetStaticFieldTaintVolatile(_sfield)
+#define dvmGetStaticFieldTaintObjectVolatile(_sfield)  dvmGetStaticFieldTaintVolatile(_sfield)
+#else
+#define dvmGetStaticFieldTaint(_sfield)        ((void)0)
+#define dvmGetStaticFieldTaintBoolean(_sfield) ((void)0)
+#define dvmGetStaticFieldTaintByte(_sfield)    ((void)0)
+#define dvmGetStaticFieldTaintShort(_sfield)   ((void)0)
+#define dvmGetStaticFieldTaintChar(_sfield)    ((void)0)
+#define dvmGetStaticFieldTaintInt(_sfield)     ((void)0)
+#define dvmGetStaticFieldTaintLong(_sfield)    ((void)0)
+#define dvmGetStaticFieldTaintFloat(_sfield)   ((void)0)
+#define dvmGetStaticFieldTaintDouble(_sfield)  ((void)0)
+#define dvmGetStaticFieldTaintObject(_sfield)  ((void)0)
+
+#define dvmGetStaticFieldTaintBooleanVolatile(_sfield) ((void)0)
+#define dvmGetStaticFieldTaintByteVolatile(_sfield)    ((void)0)
+#define dvmGetStaticFieldTaintShortVolatile(_sfield)   ((void)0)
+#define dvmGetStaticFieldTaintCharVolatile(_sfield)    ((void)0)
+#define dvmGetStaticFieldTaintIntVolatile(_sfield)     ((void)0)
+#define dvmGetStaticFieldTaintLongVolatile(_sfield)    ((void)0)
+#define dvmGetStaticFieldTaintFloatVolatile(_sfield)   ((void)0)
+#define dvmGetStaticFieldTaintDoubleVolatile(_sfield)  ((void)0)
+#define dvmGetStaticFieldTaintObjectVolatile(_sfield)  ((void)0)
+#endif
+
 INLINE void dvmSetStaticFieldBoolean(StaticField* sfield, bool val) {
     sfield->value.i = val;
 }
@@ -350,4 +517,44 @@ INLINE void dvmSetStaticFieldObjectVolatile(StaticField* sfield, Object* val) {
     }
 }
 
+#ifdef WITH_TAINT_TRACKING
+INLINE void dvmSetStaticFieldTaint(StaticField* sfield, u4 tag) {
+    sfield->taint.tag = tag;
+}
+INLINE void dvmSetStaticFieldTaintVolatile(StaticField* sfield, u4 tag) {
+    u4* ptr = &sfield->taint.tag;
+    android_atomic_release_store(tag, (s4*)ptr);
+}
+#define dvmSetStaticFieldTaintBoolean(_sfield, _tag) dvmSetStaticFieldTaint(_sfield, _tag)
+#define dvmSetStaticFieldTaintByte(_sfield, _tag)    dvmSetStaticFieldTaint(_sfield, _tag)
+#define dvmSetStaticFieldTaintShort(_sfield, _tag)   dvmSetStaticFieldTaint(_sfield, _tag)
+#define dvmSetStaticFieldTaintChar(_sfield, _tag)    dvmSetStaticFieldTaint(_sfield, _tag)
+#define dvmSetStaticFieldTaintInt(_sfield, _tag)     dvmSetStaticFieldTaint(_sfield, _tag)
+#define dvmSetStaticFieldTaintLong(_sfield, _tag)    dvmSetStaticFieldTaint(_sfield, _tag)
+#define dvmSetStaticFieldTaintFloat(_sfield, _tag)   dvmSetStaticFieldTaint(_sfield, _tag)
+#define dvmSetStaticFieldTaintDouble(_sfield, _tag)  dvmSetStaticFieldTaint(_sfield, _tag)
+#define dvmSetStaticFieldTaintObject(_sfield, _tag)  dvmSetStaticFieldTaint(_sfield, _tag)
+
+#define dvmSetStaticFieldTaintBooleanVolatile(_sfield, _tag) dvmSetStaticFieldTaintVolatile(_sfield, _tag)
+#define dvmSetStaticFieldTaintByteVolatile(_sfield, _tag)    dvmSetStaticFieldTaintVolatile(_sfield, _tag)
+#define dvmSetStaticFieldTaintShortVolatile(_sfield, _tag)   dvmSetStaticFieldTaintVolatile(_sfield, _tag)
+#define dvmSetStaticFieldTaintCharVolatile(_sfield, _tag)    dvmSetStaticFieldTaintVolatile(_sfield, _tag)
+#define dvmSetStaticFieldTaintIntVolatile(_sfield, _tag)     dvmSetStaticFieldTaintVolatile(_sfield, _tag)
+#define dvmSetStaticFieldTaintLongVolatile(_sfield, _tag)    dvmSetStaticFieldTaintVolatile(_sfield, _tag)
+#define dvmSetStaticFieldTaintFloatVolatile(_sfield, _tag)   dvmSetStaticFieldTaintVolatile(_sfield, _tag)
+#define dvmSetStaticFieldTaintDoubleVolatile(_sfield, _tag)  dvmSetStaticFieldTaintVolatile(_sfield, _tag)
+#define dvmSetStaticFieldTaintObjectVolatile(_sfield, _tag)  dvmSetStaticFieldTaintVolatile(_sfield, _tag)
+#else
+#define dvmSetStaticFieldTaint(_sfield, _tag)        ((void)0)
+#define dvmSetStaticFieldTaintBoolean(_sfield, _tag) ((void)0)
+#define dvmSetStaticFieldTaintByte(_sfield, _tag)    ((void)0)
+#define dvmSetStaticFieldTaintShort(_sfield, _tag)   ((void)0)
+#define dvmSetStaticFieldTaintChar(_sfield, _tag)    ((void)0)
+#define dvmSetStaticFieldTaintInt(_sfield, _tag)     ((void)0)
+#define dvmSetStaticFieldTaintLong(_sfield, _tag)    ((void)0)
+#define dvmSetStaticFieldTaintFloat(_sfield, _tag)   ((void)0)
+#define dvmSetStaticFieldTaintDouble(_sfield, _tag)  ((void)0)
+#define dvmSetStaticFieldTaintObject(_sfield, _tag)  ((void)0)
+#endif
+
 #endif  // DALVIK_OO_OBJECTINLINES_H_
diff --git a/vm/reflect/Reflect.cpp b/vm/reflect/Reflect.cpp
index c5d7fbe..ade44ec 100644
--- a/vm/reflect/Reflect.cpp
+++ b/vm/reflect/Reflect.cpp
@@ -1038,6 +1038,69 @@ int dvmConvertArgument(DataObject* arg, ClassObject* type, s4* destPtr)
     return retVal;
 }
 
+#ifdef WITH_TAINT_TRACKING
+/* Returns the width corresponding to a type
+ * returns -1 if type isn't a primitive type
+ */
+int getTypeWidth(PrimitiveType type)
+{
+    int width = -1;
+
+    switch (type) {
+	case PRIM_BOOLEAN:
+	case PRIM_CHAR:
+	case PRIM_FLOAT:
+	case PRIM_BYTE:
+	case PRIM_SHORT:
+	case PRIM_INT:
+	    width = 1;
+	    break;
+	case PRIM_DOUBLE:
+	case PRIM_LONG:
+	    width = 2;
+	    break;
+	default:
+	    break;
+    }
+
+    return width;
+}
+
+/* Returns the taint tag for a boxed primitive.
+ * If the object is not a boxed primitive, TAINT_CLEAR
+ * is returned
+ */
+u4 dvmGetPrimitiveTaint(DataObject* arg, ClassObject* type)
+{
+    u4 tag = TAINT_CLEAR;
+    int width = getTypeWidth(type->primitiveType);
+
+    if (width > 0) { /* non-primitives have width -1 */
+	/* the tag is store right after the variable */
+	/* see dvmConvertArgument(): for primitives, the value is first */
+	tag = *(u4*)(arg->instanceData+width);
+
+    } /* else, don't worry about it */
+
+    return tag;
+}
+
+/* Set the taint tag for a boxed primitive.
+ * If the object is not a boxed primitive, does nothing
+ */
+void dvmSetPrimitiveTaint(DataObject* arg, ClassObject* type, u4 tag)
+{
+	int width = getTypeWidth(type->primitiveType);
+
+    if (width > 0) { /* non-primitives have width -1 */
+    	/* the tag is store right after the variable */
+    	/* see dvmConvertArgument(): for primitives, the value is first */
+    	*(u4*)(arg->instanceData+width) = tag;
+
+    } /* else, don't worry about it */
+}
+#endif
+
 /*
  * Create a wrapper object for a primitive data type.  If "returnType" is
  * not primitive, this just casts "value" to an object and returns it.
diff --git a/vm/reflect/Reflect.h b/vm/reflect/Reflect.h
index 21bb08d..c7feda3 100644
--- a/vm/reflect/Reflect.h
+++ b/vm/reflect/Reflect.h
@@ -82,6 +82,19 @@ int dvmConvertPrimitiveValue(PrimitiveType srcType,
  */
 int dvmConvertArgument(DataObject* arg, ClassObject* type, s4* ins);
 
+#ifdef WITH_TAINT_TRACKING
+/* Returns the taint tag for a boxed primitive.
+ * If the object is not a boxed primitive, TAINT_CLEAR
+ * is returned
+ */
+u4 dvmGetPrimitiveTaint(DataObject* arg, ClassObject* type);
+
+/* Set the taint tag for a boxed primitive.
+ * If the object is not a boxed primitive, does nothing
+ */
+void dvmSetPrimitiveTaint(DataObject* arg, ClassObject* type, u4 tag);
+#endif
+
 /*
  * Box a primitive value into an object.  If "returnType" is
  * not primitive, this just returns "value" cast to an object.
diff --git a/vm/tprop/TaintPolicy.cpp b/vm/tprop/TaintPolicy.cpp
new file mode 100644
index 0000000..69197c3
--- /dev/null
+++ b/vm/tprop/TaintPolicy.cpp
@@ -0,0 +1,74 @@
+
+#include "tprop/TaintPolicyPriv.h"
+
+/* Constext free grammar for profile entries:
+ *
+ * <entry> ::= <etype> "." <var> | "return"
+ * <etype> ::= "class" | "param" <num> | "return"
+ * <var> ::= <signature> "%" <vname> | <var> "." <var>
+ *
+ * Where:
+ * <signature> is the java type signature
+ * <vname> is a valid java variable name
+ *
+ * Variable naming conv
+ */
+
+
+/* Policy for com.ibm.icu4jni.charset.NativeConverter **************/
+
+TaintProfileEntry libcore_icu_NativeConverter_convertByteToChar_profile[] = {
+    {"param1", "param3"}, /* byte[] input -> char[] output */
+    {NULL, NULL}
+};
+
+TaintProfileEntry libcore_icu_NativeConverter_decode_profile[] = {
+    {"param1", "param3"}, /* byte[] input -> char[] output */
+    {NULL, NULL}
+};
+
+TaintProfileEntry libcore_icu_NativeConverter_convertCharToByte_profile[] = {
+    {"param1", "param3"}, /* char[] input -> byte[] output */
+    {NULL, NULL}
+};
+
+TaintProfileEntry libcore_icu_NativeConverter_encode_profile[] = {
+    {"param1", "param3"}, /* char[] input -> byte[] output */
+    {NULL, NULL}
+};
+
+TaintProfile libcore_icu_NativeConverter_methods[] = {
+    {"convertByteToChar", libcore_icu_NativeConverter_convertByteToChar_profile},
+    {"decode", libcore_icu_NativeConverter_decode_profile},
+    {"convertCharToByte", libcore_icu_NativeConverter_convertCharToByte_profile},
+    {"encode", libcore_icu_NativeConverter_encode_profile},
+    {NULL, NULL}
+};
+
+/* Policy for foo.bar.name2 ****************************************/
+
+TaintProfileEntry foo_bar_name2_method1_profile[] = {
+    {"class.foo", "return"},
+    {"param1.bar", "class.bar"},
+    {NULL, NULL}
+};
+
+TaintProfileEntry foo_bar_name2_method2_profile[] = {
+    {"class.foo", "return"},
+    {"param1.bar", "class.bar"},
+    {NULL, NULL}
+};
+
+TaintProfile foo_bar_name2_methods[] = {
+    {"method1", foo_bar_name2_method1_profile},
+    {"method2", foo_bar_name2_method2_profile},
+    {NULL, NULL}
+};
+
+/* Class list ******************************************************/
+
+TaintPolicy gDvmJniTaintPolicy[] = {
+    {"Llibcore/icu/NativeConverter;", libcore_icu_NativeConverter_methods, NULL},
+    {"Lfoo/bar/name2;", foo_bar_name2_methods, NULL},
+    {NULL, NULL, NULL}
+};
diff --git a/vm/tprop/TaintPolicyPriv.h b/vm/tprop/TaintPolicyPriv.h
new file mode 100644
index 0000000..6a2612f
--- /dev/null
+++ b/vm/tprop/TaintPolicyPriv.h
@@ -0,0 +1,69 @@
+
+#ifndef _DALVIK_TPROP_TAINT_PROP_PRIV
+#define _DALVIK_TPROP_TAINT_PROP_PRIV
+
+#include "Dalvik.h"
+
+typedef enum {
+    kTaintProfileUnknown = 0,
+    kTaintProfileClass,
+    kTaintProfileParam,
+    kTaintProfileReturn
+} TaintProfileEntryType;
+
+typedef struct {
+    const char* from;
+    const char* to;
+} TaintProfileEntry;
+
+#define TAINT_PROFILE_TABLE_SIZE 8 /* per class */
+#define TAINT_POLICY_TABLE_SIZE 32 /* number of classes */
+
+typedef struct {
+    const char* methodName;
+    const TaintProfileEntry* entries;
+} TaintProfile;
+
+typedef struct {
+    const char* classDescriptor;
+    const TaintProfile* profiles;
+    HashTable* methodTable; /* created on startup */
+} TaintPolicy;
+
+extern TaintPolicy gDvmJniTaintPolicy[];
+
+/* function of type HashCompareFunc */
+static int hashcmpTaintPolicy(const void* ptr1, const void* ptr2)
+{
+    TaintPolicy* p1 = (TaintPolicy*) ptr1;
+    TaintPolicy* p2 = (TaintPolicy*) ptr2;
+
+    return strcmp(p1->classDescriptor, p2->classDescriptor);
+}
+
+/* function of type HashCompareFunc */
+static int hashcmpTaintProfile(const void* ptr1, const void* ptr2)
+{
+    TaintProfile* m1 = (TaintProfile*) ptr1;
+    TaintProfile* m2 = (TaintProfile*) ptr2;
+
+    return strcmp(m1->methodName, m2->methodName);
+}
+
+/* function of type HashFreeFunc */
+static void freeTaintPolicy(void* p)
+{
+    TaintPolicy* pol = (TaintPolicy*) p;
+    if (pol != NULL) {
+	dvmHashTableFree(pol->methodTable);
+    }
+}
+
+/* function of type HashFreeFunc */
+static void freeTaintProfile(void* p)
+{
+    /* nothing to free */
+    return;
+}
+
+#endif
diff --git a/vm/tprop/TaintProp.cpp b/vm/tprop/TaintProp.cpp
new file mode 100644
index 0000000..70605cd
--- /dev/null
+++ b/vm/tprop/TaintProp.cpp
@@ -0,0 +1,774 @@
+
+#include "Dalvik.h"
+#include "tprop/TaintPolicyPriv.h"
+
+/* Wrapper to bundle a Field and an Object instance 
+ * - needed when dealing with nested instance field entries
+ */
+typedef struct {
+    Field *field;
+    Object *obj;
+} FieldRef;
+
+HashTable *gPolicyTable = NULL;
+
+#ifdef TAINT_JNI_LOG
+/* JNI logging for debugging purposes 
+ * -- used to only print methods once (quites things down a bit)
+ */
+HashTable *gJniLogSeen = NULL;
+bool gJniLog = true;
+#endif
+
+/* Code called from dvmJniStartup()
+ * Initializes the gPolicyTable for fast lookup of taint policy 
+ * profiles for methods.
+ */
+void dvmTaintPropJniStartup()
+{
+    TaintPolicy* policy;
+    u4 hash;
+    
+    /* Create the policy table (perfect size) */
+    gPolicyTable = dvmHashTableCreate(
+	    dvmHashSize(TAINT_POLICY_TABLE_SIZE), 
+	    freeTaintPolicy);
+
+    for (policy = gDvmJniTaintPolicy; policy->classDescriptor != NULL; policy++) {
+	const TaintProfile *profile;
+    
+	/* Create the method table for this class */
+	policy->methodTable = dvmHashTableCreate(
+		TAINT_PROFILE_TABLE_SIZE, freeTaintProfile);
+
+	/* Add all of the methods */
+	for (profile = &policy->profiles[0]; profile->methodName != NULL; profile++) {
+	    hash = dvmComputeUtf8Hash(profile->methodName);
+	    dvmHashTableLookup(policy->methodTable, hash,(void *) profile,
+		    hashcmpTaintProfile, true);
+	}
+
+	/* Add this class to gPolicyTable */
+	hash = dvmComputeUtf8Hash(policy->classDescriptor);
+	dvmHashTableLookup(gPolicyTable, hash, policy, 
+		hashcmpTaintPolicy, true);
+    }
+
+#ifdef TAINT_JNI_LOG
+    /* JNI logging for debugging purposes */
+    gJniLogSeen = dvmHashTableCreate(dvmHashSize(50), free);
+#endif
+}
+
+/* Code called from dvmJniShutdown()
+ * deallocates the gPolicyTable
+ */
+void dvmTaintPropJniShutdown()
+{
+    dvmHashTableFree(gPolicyTable);
+#ifdef TAINT_JNI_LOG
+    /* JNI logging for debugging purposes */
+    dvmHashTableFree(gJniLogSeen);
+#endif
+}
+
+/* Returns the taint on an object.
+ * - Currently only arrays and java.lang.String is supported
+ */
+u4 getObjectTaint(Object* obj, const char* descriptor)
+{
+    ArrayObject *arrObj = NULL;
+    if (obj == NULL) {
+	return TAINT_CLEAR;
+    }
+
+    if (descriptor[0] == '[') {
+	/* Get the taint from the array */
+	arrObj = (ArrayObject*) obj;
+	if (arrObj != NULL) {
+	    return arrObj->taint.tag;
+	}
+    } 
+    
+    if (strcmp(descriptor, "Ljava/lang/String;") == 0) {
+    StringObject * strObj = (StringObject*) obj;
+	arrObj = strObj->array();
+	if (arrObj != NULL) {
+	    return arrObj->taint.tag;
+	} /* else, empty string? don't worry about it */
+    } 
+
+    /* TODO: What about classes derived from String? */
+
+    /* Don't worry about other object types */
+    return TAINT_CLEAR;
+}
+
+/* Adds taint to a known object.
+ * - Currently only arrays and java.lang.String is supported
+ */
+void addObjectTaint(Object* obj, const char* descriptor, u4 tag)
+{
+    ArrayObject *arrObj = NULL;
+
+    if (obj == NULL) {
+	return;
+    }
+
+    if (descriptor[0] == '[') {
+	/* Get the taint from the array */
+	arrObj = (ArrayObject*) obj;
+	if (arrObj != NULL) {
+	    arrObj->taint.tag |= tag;
+	}
+    } 
+    
+    if (strcmp(descriptor, "Ljava/lang/String;") == 0) {
+	arrObj = ((StringObject*) obj)->array();
+	if (arrObj != NULL) {
+	    arrObj->taint.tag |= tag;
+	} /* else, empty string? don't worry about it */
+    } 
+
+    /* TODO: What about classes derived from String? */
+
+    /* Don't worry about other object types */
+    return;
+}
+
+/* Sets the taint on the return value
+ * - rtaint points to an address in the args array
+ * - descriptor is the return type
+ * - for return objects, only arrays and java.lang.String supported
+ *   (will taint object reference returned otherwise)
+ */
+void setReturnTaint(u4 tag, u4* rtaint, JValue* pResult, 
+	const char* descriptor)
+{
+    Object* obj = NULL;
+    ArrayObject* arrObj = NULL;
+
+    switch (descriptor[0]) {
+	case 'V':
+	    /* void, do nothing */
+	    break;
+	case 'Z':
+	case 'B':
+	case 'C':
+	case 'S':
+	case 'I':
+	case 'J':
+	case 'F':
+	case 'D':
+	    /* Easy case */
+	    *rtaint |= tag;
+	    break;
+	case '[':
+	    /* Best we can do is taint the array, however
+	     * this is not right for "[[" or "[L" */
+	    arrObj = (ArrayObject*) pResult->l;
+	    if (arrObj != NULL) {
+		arrObj->taint.tag |= tag;
+	    } /* else, method returning null pointer */
+	    break;
+	case 'L':
+	    obj = (Object*) pResult->l;
+
+	    if (obj != NULL) {
+		if (strcmp(descriptor, "Ljava/lang/String;") == 0) {
+		    arrObj = ((StringObject*) obj)->array();
+		    if (arrObj != NULL) {
+			arrObj->taint.tag |= tag;
+		    } /* else, empty string?, don't worry about it */
+		} else {
+		    /* TODO: What about classes derived from String? */
+		    /* Best we can do is to taint the object ref */
+		    *rtaint |= tag;
+		}
+	    }
+	    break;
+    }
+}
+
+/* Returns the TaintPolicyProfile associated with this method
+ * - returns NULL if not found
+ */
+TaintProfile* getPolicyProfile(const Method* method)
+{
+    TaintPolicy* policy = NULL;
+    TaintProfile* profile = NULL;
+    u4 hash;
+
+    /* temporary variables for the search */
+    TaintPolicy tPol = {NULL, NULL, NULL};
+    TaintProfile tProf = {NULL, NULL};
+
+    dvmHashTableLock(gPolicyTable);
+
+    /* Find the class */
+    hash = dvmComputeUtf8Hash(method->clazz->descriptor);
+    tPol.classDescriptor = method->clazz->descriptor;
+    policy = (TaintPolicy*) dvmHashTableLookup(gPolicyTable,
+	    hash, &tPol, hashcmpTaintPolicy, false);
+
+    if (policy != NULL) {
+	dvmHashTableLock(policy->methodTable);
+
+	/* Find the Method */
+	hash = dvmComputeUtf8Hash(method->name);
+	tProf.methodName = method->name;
+	profile = (TaintProfile*) dvmHashTableLookup(policy->methodTable,
+		hash, &tProf, hashcmpTaintProfile, false);
+
+	dvmHashTableUnlock(policy->methodTable);
+    }
+
+    dvmHashTableUnlock(gPolicyTable);
+
+    return profile;
+}
+
+
+/* utility to determine the type of entry string
+ */
+TaintProfileEntryType getEntryType(const char* entry)
+{
+    TaintProfileEntryType type = kTaintProfileUnknown;
+
+    if (strncmp(entry, "class", 5) == 0) {
+	type = kTaintProfileClass;
+    } else if (strncmp(entry, "param", 5) == 0) {
+	type = kTaintProfileParam;
+    } else if (strncmp(entry, "return", 6) == 0) {
+	type = kTaintProfileReturn;
+    }
+
+    return type;
+}
+
+/* returns the field structure corresponding to the profile entry
+ * variable in the form: <signature> % <name> 
+ */
+Field* getFieldFromProfileVar(const char* var, const ClassObject* clazz)
+{
+    char* pos;
+    char* sig;
+    char* name;
+    InstField* ifield;
+    StaticField* sfield;
+    Field* field = NULL;
+
+    // TODO: Can we avoid the allocation if we replace the '%'?
+    // Need to make sure there isn't a locking problem if that route
+    // is taken.
+    pos = index((char *)var, '%');
+    sig = strndup(var, pos-var);
+    name = strdup(pos+1);
+
+    /* Try both static and instance fields */
+    ifield = dvmFindInstanceFieldHier(clazz, name, sig);
+    if (ifield != NULL) {
+	field = (Field*) ifield;
+    } else {
+	sfield = dvmFindStaticFieldHier(clazz, name, sig);
+	if (sfield != NULL) {
+	    field = (Field*) sfield;
+	}
+    }
+
+    free(sig);
+    free(name);
+
+    return field;
+}
+
+/* Returns the taint tag for a field
+ * - obj only used if the field is not static
+ */
+u4 getTaintFromField(Field* field, Object* obj)
+{
+    u4 tag = TAINT_CLEAR;
+
+    if (dvmIsStaticField(field)) {
+		StaticField* sfield = (StaticField*) field;
+		tag = dvmGetStaticFieldTaint(sfield);
+    } else {
+	InstField* ifield = (InstField*) field;
+	if (field->signature[0] == 'J' || field->signature[0] == 'D') {
+	    tag = dvmGetFieldTaintWide(obj, ifield->byteOffset);
+	} else {
+	    tag = dvmGetFieldTaint(obj, ifield->byteOffset);
+	}
+    }
+
+    return tag;
+}
+
+/* add tag to a field
+ * - obj only used if the field is not static
+ */
+void addTaintToField(Field* field, Object* obj, u4 tag)
+{
+    if (dvmIsStaticField(field)) {
+	StaticField* sfield = (StaticField*) field;
+	tag |= dvmGetStaticFieldTaint(sfield);
+	dvmSetStaticFieldTaint(sfield, tag);
+    } else {
+	InstField* ifield = (InstField*) field;
+	if (field->signature[0] == 'J' || field->signature[0] == 'D') {
+	    tag |= dvmGetFieldTaintWide(obj, ifield->byteOffset);
+	    dvmSetFieldTaintWide(obj, ifield->byteOffset, tag);
+	} else {
+	    tag |= dvmGetFieldTaint(obj, ifield->byteOffset);
+	    dvmSetFieldTaint(obj, ifield->byteOffset, tag);
+	}
+    }
+}
+
+/* Returns the object pointer for a field
+ * - obj only used if the field is not static
+ * - Note: will not return an array object
+ */
+Object* getObjectFromField(Field* field, Object* obj)
+{
+    if (field->signature[0] != 'L') {
+	return NULL;
+    }
+
+    if (dvmIsStaticField(field)) {
+	StaticField* sfield = (StaticField*) field;
+	return dvmGetStaticFieldObject(sfield);
+    } else {
+	InstField* ifield = (InstField*) field;
+	return dvmGetFieldObject(obj, ifield->byteOffset);
+    }
+}
+
+/* Gets the field associated with an entry string that has the
+ * "class.", "argX.", or "return." stripped
+ * - recursively finds the end field
+ * - obj is ignored if field is static
+ */
+FieldRef getFieldFromEntry(const char* entry, ClassObject* clazz, Object* obj)
+{
+    FieldRef fRef;
+    char* split;
+
+    memset(&fRef, 0, sizeof(fRef));
+
+    split = index((char *) entry, '.');
+    if (split == NULL) { /* This is the last part */
+	fRef.field = getFieldFromProfileVar(entry, clazz);
+	fRef.obj = obj;
+	if (fRef.field == NULL) {
+	    ALOGW("TaintPolicy: variable doesn't exist: %s", entry);
+	}
+
+    } else if (entry[0] != 'L') {
+	/* recursion is required, but target isn't an Object */
+	ALOGW("TaintPolicy: expected object variable: %s", entry);
+
+    } else { /* recursion is required */
+	char* var = strndup(entry, split-entry);
+	fRef.field = getFieldFromProfileVar(var, clazz);
+	fRef.obj = obj;
+	free(var);
+
+	if (fRef.field == NULL) {
+	    ALOGW("TaintPolicy: variable doesn't exist: %s", entry);
+	} else {
+	    Object* obj2 = getObjectFromField(fRef.field, fRef.obj);
+	    if (obj2 != NULL) { 
+		/* recurse */
+		fRef = getFieldFromEntry(split+1, fRef.field->clazz, obj2);
+	    } else {
+		ALOGW("TaintPolicy: error getting object for %s", entry);
+	    }
+	}
+    }
+
+    return fRef;
+}
+
+/* Gets the taint tag associated with a field.
+ *  - Here, we assume any "class." has been stripped.
+ *  - We recursively dereference the field name if multiple levels
+ *  - obj is ignored if field is static
+ */
+u4 getFieldEntryTaint(const char* entry, ClassObject* clazz, Object* obj)
+{
+    u4 tag = TAINT_CLEAR;
+    FieldRef fRef;
+
+    fRef = getFieldFromEntry(entry, clazz, obj);
+    if (fRef.field != NULL) {
+	tag = getTaintFromField(fRef.field, fRef.obj);
+    }
+
+    return tag;
+}
+
+/* Returns the index in args[] corresponding to the parameter
+ * string entry.
+ * - It doesn't matter if the entry has multiple parts, e.g.,
+ *   "param1.foo.bar", as long as the variable name after the first
+ *   "." is not a number. Since the signature comes next, we can 
+ *   safely assume this is the case.
+ * - returns -1 on parsing error
+ * - If descriptor is not NULL, it will point to a newly allocated 
+ *   descriptor that needs to be free()'d (unless there was an error)
+ */
+int paramToArgIndex(const char* entry, const Method* method, char** descriptor) {
+    int pIdx, aIdx, i;
+    char* endptr;
+    const char* num = entry + 5; /* "param" is the first 5 characters */
+    const DexProto* proto = &method->prototype;
+    DexParameterIterator pIterator;
+
+    /* Step 1: determine the parameter index (pIdx) */
+    pIdx = strtol(num, &endptr, 10);
+    if (num == endptr) {
+	/* error parsing */
+	return -1;
+    } 
+
+    /* Step 2: translate parameter index into args array index */
+    dexParameterIteratorInit(&pIterator, proto);
+    aIdx = (dvmIsStaticMethod(method)?0:1); /* index where params start */
+    for (i=0; i<=pIdx ; i++) {
+	const char* desc = dexParameterIteratorNextDescriptor(&pIterator);
+
+	if (desc == NULL) {
+	    /* This index doesn't exist, error */
+	    return -1;
+	} 
+
+	if (i == pIdx) {
+	    /* This is the index */
+	    if (descriptor != NULL) {
+		*descriptor = strdup(desc);
+	    }
+	    break;
+	}
+
+	/* increment the args array index */
+	aIdx++;
+
+	if (desc[0] == 'J' || desc[0] == 'D') {
+	    /* wide argument, increment index one more */
+	    aIdx++;
+	}
+    }
+
+    return aIdx;
+}
+
+u4 getParamEntryTaint(const char* entry, const u4* args, const Method* method)
+{
+    u4 tag = TAINT_CLEAR;
+    int aIdx;
+    char* pos;
+    char* pDesc = NULL; /* parameter descriptor */
+
+    /* Determine corresponding args[] index */
+    aIdx = paramToArgIndex(entry, method, &pDesc);
+    if (aIdx == -1) {
+	ALOGW("TaintPolicy: error parsing %s", entry);
+	return tag;
+    }
+
+    /* Determine if entry requres field search */
+    pos = index((char *) entry, '.');
+    if (pos == NULL ) { /* just need parameter taint */
+	switch (pDesc[0]) {
+	    case 'Z':
+	    case 'B':
+	    case 'C':
+	    case 'S':
+	    case 'I':
+	    case 'J':
+	    case 'F':
+	    case 'D':
+		/* assume args array length (insSize) = 3
+		 * and aIdx = 1 (second index)
+		 * 0 1 2 [3] 4 5 6
+		 *	       ^-- the taint value we want
+		 */
+		tag = args[aIdx+method->insSize+1];
+		break;
+	    case '[':
+	    case 'L':
+		/* use both the object reference taint and Object taint */
+		tag = args[aIdx+method->insSize+1];
+		tag |= getObjectTaint((Object*)args[aIdx], pDesc);
+		break;
+	    default:
+		ALOGW("TaintPolicy: unknown parameter type for %s", entry);
+	}
+
+    } else { /* need to get the parameter object for field search */
+	if (pDesc[0] != 'L') {
+	    ALOGW("TaintPolicy: param not object in %s", entry);
+	} else {
+	    Object* obj = (Object*)args[aIdx];
+	    tag = getFieldEntryTaint(pos+1, obj->clazz, obj);
+	}
+    }
+
+    if (pDesc) {
+	free(pDesc);
+    }
+    
+    return tag;
+}
+
+u4 getEntryTaint(const char* entry, const u4* args, const Method* method)
+{
+    u4 tag = TAINT_CLEAR;
+    char *pos;
+
+    /* Determine split point if any */
+    pos = index((char *) entry, '.');
+
+    switch (getEntryType(entry)) {
+	case kTaintProfileClass:
+	    if (dvmIsStaticMethod(method)) {
+		tag = getFieldEntryTaint(pos+1, method->clazz, NULL);
+	    } else {
+		tag = getFieldEntryTaint(pos+1, method->clazz, (Object*)args[0]);
+	    }
+	    break;
+
+	case kTaintProfileParam:
+	    tag = getParamEntryTaint(entry, args, method);
+	    break;
+
+	default:
+	    ALOGW("TaintPolicy: Invalid from type: [%s]", entry);
+    }
+    
+    return tag;
+}
+
+/* adds the taint tag associated with a field.
+ *  - Here, we assume any "class." has been stripped.
+ *  - We recursively dereference the field name if multiple levels
+ *  - obj is ignored if field is static
+ */
+void addFieldEntryTaint(u4 tag, const char* entry, ClassObject* clazz, Object* obj)
+{
+    FieldRef field;
+
+    field = getFieldFromEntry(entry, clazz, obj);
+    if (field.field != NULL) {
+	addTaintToField(field.field, field.obj, tag);
+    }
+}
+
+void addParamEntryTaint(u4 tag, const char* entry, const u4* args, const Method* method)
+{
+    int aIdx;
+    char* pos;
+    char* pDesc = NULL; /* parameter descriptor */
+    
+    pos = index((char *) entry, '.');
+
+    /* Determine corresponding args[] index */
+    aIdx = paramToArgIndex(entry, method, &pDesc);
+    if (aIdx == -1) {
+	ALOGW("TaintPolicy: error parsing %s", entry);
+	return;
+    }
+
+    if (pos == NULL && (pDesc[0] == '[' || pDesc[0] == 'L')) {
+	/* target is a parameter that we can taint directly */
+	Object* obj = (Object*)args[aIdx];
+	addObjectTaint(obj, pDesc, tag);
+    } else if (pDesc[0] == 'L') {
+	Object* obj = (Object*)args[aIdx];
+	addFieldEntryTaint(tag, pos+1, obj->clazz, obj);
+    } else {
+	ALOGW("TaintPolicy: param not object or array in %s (%s)", 
+		entry, pDesc);
+    }
+
+    if (pDesc) {
+	free(pDesc);
+    }
+}
+
+u4 addEntryTaint(u4 tag, const char* entry, const u4* args, const Method* method)
+{
+    u4 rtaint = TAINT_CLEAR;
+
+    switch (getEntryType(entry)) {
+	case kTaintProfileClass:
+	    if (dvmIsStaticMethod(method)) {
+		addFieldEntryTaint(tag, entry, method->clazz, NULL);
+	    } else {
+		addFieldEntryTaint(tag, entry, method->clazz, (Object*)args[0]);
+	    }
+	    break;
+
+	case kTaintProfileParam:
+	    addParamEntryTaint(tag, entry, args, method);
+	    break;
+
+	case kTaintProfileReturn:
+	    if (entry[7] == '\0') { /* taint the return itself */
+		rtaint = tag;
+	    } else {
+		// TODO: implement return field tainting (need pResult)
+		ALOGW("TaintPolicy: tainting return fields not supported");
+	    }
+	    break;
+
+	default:
+	    ALOGW("TaintPolicy: Invalid from type: [%s]", entry);
+    }
+
+    return rtaint;
+}
+
+/* Returns a taint if the profile policy indicates propagation
+ * to the return
+ */
+u4 propMethodProfile(const u4* args, const Method* method)
+{
+    u4 rtaint = TAINT_CLEAR;
+    TaintProfile* profile = NULL;
+    const TaintProfileEntry* entry = NULL;
+
+    profile = getPolicyProfile(method);
+    if (profile == NULL) {
+	return rtaint;
+    }
+
+    //LOGD("TaintPolicy: applying policy for %s.%s",
+    //	    method->clazz->descriptor, method->name);
+
+    /* Cycle through the profile entries */
+    for (entry = &profile->entries[0]; entry->from != NULL; entry++) {
+	u4 tag = TAINT_CLEAR;
+
+	tag = getEntryTaint(entry->from, args, method);
+	if (tag) {
+	    //LOGD("TaintPolicy: tag = %d %s -> %s",
+	    //	    tag, entry->from, entry->to);
+	    rtaint |= addEntryTaint(tag, entry->to, args, method);
+	}
+
+    }
+
+    return rtaint;
+}
+
+/* Used to propagate taint for JNI methods
+ * Two types of propagation:
+ *  1) simple conservative propagation based on parameters
+ *  2) propagation based on function profile policies
+ */
+void dvmTaintPropJniMethod(const u4* args, JValue* pResult, const Method* method)
+{
+    const DexProto* proto = &method->prototype;
+    DexParameterIterator pIterator;
+    int nParams = dexProtoGetParameterCount(proto);
+    int pStart = (dvmIsStaticMethod(method)?0:1); /* index where params start */
+
+    /* Consider 3 arguments. [x] indicates return taint index
+     * 0 1 2 [3] 4 5 6
+     */
+    int nArgs = method->insSize;
+    u4* rtaint = (u4*) &args[nArgs]; /* The return taint value */
+    int tStart = nArgs+1; /* index of args[] where taint values start */
+    int tEnd   = nArgs*2; /* index of args[] where taint values end */
+    u4	tag = TAINT_CLEAR;
+    int i;
+
+#if 0
+    {
+	char *desc = dexProtoCopyMethodDescriptor(proto);
+	LOGW("Jni: %s.%s%s, descriptor: %s", 
+		method->clazz->descriptor, method->name, 
+		(dvmIsStaticMethod(method)?"[static]":"", desc)
+		);
+	free(desc);
+    }
+#endif
+
+#ifdef TAINT_JNI_LOG
+    /* JNI logging for debugging purposes */
+    if (gJniLog) {
+	u4 hash;
+	int len;
+	char *inStr, *outStr;
+
+	len = strlen(method->clazz->descriptor) + 1 + strlen(method->name);
+	inStr = (char*) malloc(len+1);
+	strcpy(inStr, method->clazz->descriptor);
+	strcat(inStr, ".");
+	strcat(inStr, method->name);
+	hash = dvmComputeUtf8Hash(inStr);
+
+	dvmHashTableLock(gJniLogSeen);
+
+	outStr = (char*) dvmHashTableLookup(gJniLogSeen, hash, inStr, 
+		(HashCompareFunc) strcmp, false);
+
+	if (outStr == NULL) {
+	    /* New method! */
+	    /* add it */
+	    dvmHashTableLookup(gJniLogSeen, hash, inStr, 
+		(HashCompareFunc) strcmp, true);
+	} else {
+	    free(inStr); /* don't need this anymore */
+	}
+
+	dvmHashTableUnlock(gJniLogSeen);
+    }
+#endif
+
+    /* Union the taint tags, this includes object ref tags 
+     * - we don't need to worry about static vs. not static, because getting
+     *	 the taint tag on the "this" object reference is a good
+     * - we don't need to worry about wide registers, because the stack
+     *	 interleaving of taint tags makes it transparent
+     */
+    for (i = tStart; i <= tEnd; i++) {
+	tag |= args[i];
+    }
+
+    /* If not static, pull any taint from the "this" object */
+    if (!dvmIsStaticMethod(method)) {
+	tag |= getObjectTaint((Object*)args[0], method->clazz->descriptor);
+    }
+
+    /* Union taint from Objects we care about */
+    dexParameterIteratorInit(&pIterator, proto);
+    for (i=pStart; ; i++) {
+	const char* desc = dexParameterIteratorNextDescriptor(&pIterator);
+
+	if (desc == NULL) {
+	    break;
+	} 
+	
+	if (desc[0] == '[' || desc[0] == 'L') {
+	    tag |= getObjectTaint((Object*) args[i], desc);
+	}
+
+	if (desc[0] == 'J' || desc[0] == 'D') {
+	    /* wide argument, increment index one more */
+	    i++;
+	}
+    }
+
+    /* Look at the taint policy profiles (may have return taint) */
+    tag |= propMethodProfile(args, method);
+
+    /* Update return taint according to the return type */
+    if (tag) {
+	const char* desc = dexProtoGetReturnType(proto);
+	setReturnTaint(tag, rtaint, pResult, desc);
+    }
+}
+
diff --git a/vm/tprop/TaintProp.h b/vm/tprop/TaintProp.h
new file mode 100644
index 0000000..5797b22
--- /dev/null
+++ b/vm/tprop/TaintProp.h
@@ -0,0 +1,15 @@
+/* Note, this file should be included near the end of Dalvik.h */
+
+#ifndef _DALVIK_TPROP_TAINT_PROP
+#define _DALVIK_TPROP_TAINT_PROP
+
+/* Called from dvmJniStartup() */
+void dvmTaintPropJniStartup();
+
+/* Called from dvmJniShutdown() */
+void dvmTaintPropJniShutdown();
+
+/* Main propagation */
+void dvmTaintPropJniMethod(const u4* args, JValue* pResult, const Method* method);
+
+#endif
-- 
1.7.9.5


From 44e052d2c5d1c3ffb531cfdb9edfc59cd562151d Mon Sep 17 00:00:00 2001
From: Peter Gilbert <petergilbert@gmail.com>
Date: Tue, 2 Oct 2012 09:18:40 -0400
Subject: [PATCH 02/15] TaintLog format

---
 vm/native/dalvik_system_Taint.cpp |    6 +++---
 1 file changed, 3 insertions(+), 3 deletions(-)

diff --git a/vm/native/dalvik_system_Taint.cpp b/vm/native/dalvik_system_Taint.cpp
index 8956ec8..c88636f 100644
--- a/vm/native/dalvik_system_Taint.cpp
+++ b/vm/native/dalvik_system_Taint.cpp
@@ -616,13 +616,13 @@ static void Dalvik_dalvik_system_Taint_log(const u4* args,
     }
 
 	msg = dvmCreateCstrFromString(msgObj);
-	ALOGW("TaintLog: %s", msg);
+	ALOG(LOG_WARN, "TaintLog", "%s", msg);
 	char *curmsg = msg;
 	while(strlen(curmsg) > 1013)
 	{   
 		curmsg = curmsg+1013;
-		ALOGW("%s", curmsg);
-	}   
+		ALOG(LOG_WARN, "TaintLog", "%s", curmsg);
+	}
 	free(msg);
 
     RETURN_VOID();
-- 
1.7.9.5


From 3b13d349151eceec4b1d4d04ed8f82344c7c8c64 Mon Sep 17 00:00:00 2001
From: Peter Gilbert <petergilbert@gmail.com>
Date: Tue, 2 Oct 2012 18:43:52 -0400
Subject: [PATCH 03/15] TaintDroid readme

---
 README_TAINTDROID.txt |   49 +++++++++++++++++++++++++++++++++++++++++++++++++
 1 file changed, 49 insertions(+)
 create mode 100644 README_TAINTDROID.txt

diff --git a/README_TAINTDROID.txt b/README_TAINTDROID.txt
new file mode 100644
index 0000000..32fcf5c
--- /dev/null
+++ b/README_TAINTDROID.txt
@@ -0,0 +1,49 @@
+The TaintDroid additions are ...
+
+ Copyright (c) 2010 The Pennsylvania State University
+ Systems and Internet Infrastructure Security Laboratory
+
+ and
+ 
+ Copyright (c) 2010 University of Washington
+ (which funded the initial development)
+
+they were implemented by:
+
+ William Enck <enck@cse.psu.edu>
+
+The ARM assembly ("fast interpreter") and JIT implementations of the
+TaintDroid propagation rules were implemented by:
+
+ Peter Gilbert <gilbert@cs.duke.edu>
+
+Byte-level IPC parcel tracking was implemented by:
+
+ Seungyeop Han <syhan@cs.washington.edu>
+ 
+The port of TaintDroid to Android 4.1 and taint propagation for
+ByteBuffers were implemented by:
+
+ Minh Tuan Pham <mpham@ncsu.edu>
+  
+
+Unless otherwise noted, all code additions are ...
+
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+
+Note that libattr was obtained from:
+
+ ftp://oss.sgi.com/projects/xfs/cmd_tars/attr_2.4.43-1.tar.gz
+
+and is licensed under GPLv2.
+
-- 
1.7.9.5


From 85cbd5d380aeaa8d5a7e80afb213433f8944750f Mon Sep 17 00:00:00 2001
From: Peter Gilbert <petergilbert@gmail.com>
Date: Thu, 4 Oct 2012 13:35:04 -0400
Subject: [PATCH 04/15] taintdroid readme updated

---
 README_TAINTDROID.txt |    6 +++++-
 1 file changed, 5 insertions(+), 1 deletion(-)

diff --git a/README_TAINTDROID.txt b/README_TAINTDROID.txt
index 32fcf5c..6ba09fd 100644
--- a/README_TAINTDROID.txt
+++ b/README_TAINTDROID.txt
@@ -25,7 +25,11 @@ The port of TaintDroid to Android 4.1 and taint propagation for
 ByteBuffers were implemented by:
 
  Minh Tuan Pham <mpham@ncsu.edu>
-  
+
+The TaintDroidNotify app was originally written by:
+
+ Gabriel Maganis <maganis@cs.ucdavis.edu>
+
 
 Unless otherwise noted, all code additions are ...
 
-- 
1.7.9.5


From d607b9f9cb24c8d75030a02543d114ff09057de7 Mon Sep 17 00:00:00 2001
From: Peter Gilbert <petergilbert@gmail.com>
Date: Tue, 13 Nov 2012 21:13:37 -0500
Subject: [PATCH 05/15] fixed bug in System.arraycopy

---
 vm/native/java_lang_System.cpp |    2 +-
 vm/tprop/TaintProp.cpp         |   13 ++++++-------
 2 files changed, 7 insertions(+), 8 deletions(-)

diff --git a/vm/native/java_lang_System.cpp b/vm/native/java_lang_System.cpp
index ff9c301..cbcd8e0 100644
--- a/vm/native/java_lang_System.cpp
+++ b/vm/native/java_lang_System.cpp
@@ -294,7 +294,7 @@ static void Dalvik_java_lang_System_arraycopy(const u4* args, JValue* pResult)
                 copyCount * width);
             dvmWriteBarrierArray(dstArray, 0, copyCount);
 #ifdef WITH_TAINT_TRACKING
-            if (dstPos == 0 && dstArray->length == length) {
+            if (dstPos == 0 && dstArray->length == copyCount) {
                 /* entire array replaced */
                 dstArray->taint.tag = (srcArray->taint.tag | srcPosTaint);
             } else {
diff --git a/vm/tprop/TaintProp.cpp b/vm/tprop/TaintProp.cpp
index 70605cd..e74a208 100644
--- a/vm/tprop/TaintProp.cpp
+++ b/vm/tprop/TaintProp.cpp
@@ -14,7 +14,7 @@ HashTable *gPolicyTable = NULL;
 
 #ifdef TAINT_JNI_LOG
 /* JNI logging for debugging purposes 
- * -- used to only print methods once (quites things down a bit)
+ * -- used to only print methods once (quiets things down a bit)
  */
 HashTable *gJniLogSeen = NULL;
 bool gJniLog = true;
@@ -687,12 +687,11 @@ void dvmTaintPropJniMethod(const u4* args, JValue* pResult, const Method* method
 
 #if 0
     {
-	char *desc = dexProtoCopyMethodDescriptor(proto);
-	LOGW("Jni: %s.%s%s, descriptor: %s", 
-		method->clazz->descriptor, method->name, 
-		(dvmIsStaticMethod(method)?"[static]":"", desc)
-		);
-	free(desc);
+        char *desc = dexProtoCopyMethodDescriptor(proto);
+        ALOGW("Jni: %s.%s%s, descriptor: %s", 
+            method->clazz->descriptor, method->name, 
+            dvmIsStaticMethod(method)?"[static]":"", desc);
+        free(desc);
     }
 #endif
 
-- 
1.7.9.5


From 70249f8f3e6721f6e3437f4f86b46277f81c34ae Mon Sep 17 00:00:00 2001
From: Peter Gilbert <petergilbert@gmail.com>
Date: Mon, 19 Nov 2012 10:40:18 -0500
Subject: [PATCH 06/15] taint propagation in JIT for inlined min/max

---
 vm/compiler/codegen/arm/CodegenDriver.cpp |    4 ++--
 vm/compiler/codegen/arm/Thumb2/Gen.cpp    |   12 ++++++++++++
 2 files changed, 14 insertions(+), 2 deletions(-)

diff --git a/vm/compiler/codegen/arm/CodegenDriver.cpp b/vm/compiler/codegen/arm/CodegenDriver.cpp
index e3e350b..3fa2ee2 100644
--- a/vm/compiler/codegen/arm/CodegenDriver.cpp
+++ b/vm/compiler/codegen/arm/CodegenDriver.cpp
@@ -879,8 +879,8 @@ static bool genArithOpLong(CompilationUnit *cUnit, MIR *mir,
         genLong3Addr(cUnit, mir, firstOp, secondOp, rlDest, rlSrc1, rlSrc2);
 #ifdef WITH_TAINT_TRACKING
         // taint(dest) <- taint(src1) | taint(src2)
-    	int taint1 = dvmCompilerAllocTemp(cUnit);
-    	int taint2 = dvmCompilerAllocTemp(cUnit);
+        int taint1 = dvmCompilerAllocTemp(cUnit);
+        int taint2 = dvmCompilerAllocTemp(cUnit);
         loadTaintDirectWide(cUnit, rlSrc1, taint1);
         loadTaintDirectWide(cUnit, rlSrc2, taint2);
         opRegRegReg(cUnit, kOpOr, taint1, taint1, taint2);
diff --git a/vm/compiler/codegen/arm/Thumb2/Gen.cpp b/vm/compiler/codegen/arm/Thumb2/Gen.cpp
index 6a8989f..b8f370a 100644
--- a/vm/compiler/codegen/arm/Thumb2/Gen.cpp
+++ b/vm/compiler/codegen/arm/Thumb2/Gen.cpp
@@ -444,6 +444,13 @@ static bool genInlinedMinMaxInt(CompilationUnit *cUnit, MIR *mir, bool isMin)
     RegLocation rlSrc2 = dvmCompilerGetSrc(cUnit, mir, 1);
     rlSrc1 = loadValue(cUnit, rlSrc1, kCoreReg);
     rlSrc2 = loadValue(cUnit, rlSrc2, kCoreReg);
+#ifdef WITH_TAINT_TRACKING
+    int taint1 = dvmCompilerAllocTemp(cUnit);
+    int taint2 = dvmCompilerAllocTemp(cUnit);
+    loadTaintDirect(cUnit, rlSrc1, taint1);
+    loadTaintDirect(cUnit, rlSrc2, taint2);
+    opRegRegReg(cUnit, kOpOr, taint1, taint1, taint2);
+#endif /*WITH_TAINT_TRACKING*/
     RegLocation rlDest = inlinedTarget(cUnit, mir, false);
     RegLocation rlResult = dvmCompilerEvalLoc(cUnit, rlDest, kCoreReg, true);
     opRegReg(cUnit, kOpCmp, rlSrc1.lowReg, rlSrc2.lowReg);
@@ -452,6 +459,11 @@ static bool genInlinedMinMaxInt(CompilationUnit *cUnit, MIR *mir, bool isMin)
     opRegReg(cUnit, kOpMov, rlResult.lowReg, rlSrc1.lowReg);
     genBarrier(cUnit);
     storeValue(cUnit, rlDest, rlResult);
+#ifdef WITH_TAINT_TRACKING
+    storeTaintDirect(cUnit, rlDest, taint1);
+    dvmCompilerFreeTemp(cUnit, taint1);
+    dvmCompilerFreeTemp(cUnit, taint2);
+#endif /*WITH_TAINT_TRACKING*/
     return false;
 }
 
-- 
1.7.9.5


From 93a429df044d958834c593b7e7900097387f42f6 Mon Sep 17 00:00:00 2001
From: Peter Gilbert <petergilbert@gmail.com>
Date: Thu, 29 Nov 2012 13:17:28 -0500
Subject: [PATCH 07/15] adjusting asm constants for x86

---
 vm/mterp/common/asm-constants.h |   22 +++++++++++++++++++++-
 1 file changed, 21 insertions(+), 1 deletion(-)

diff --git a/vm/mterp/common/asm-constants.h b/vm/mterp/common/asm-constants.h
index db1a6ca..baaa215 100644
--- a/vm/mterp/common/asm-constants.h
+++ b/vm/mterp/common/asm-constants.h
@@ -209,7 +209,26 @@ MTERP_OFFSET(offThread_rtaint,		Thread, interpSave.rtaint, 24)
 MTERP_OFFSET(offThread_bailPtr,           Thread, interpSave.bailPtr, 28)
 MTERP_OFFSET(offThread_threadId,          Thread, threadId, 40)
 
-//40
+#ifdef TAINT_IS_86
+//44
+MTERP_OFFSET(offThread_subMode, \
+                               Thread, interpBreak.ctl.subMode, 44)
+MTERP_OFFSET(offThread_breakFlags, \
+                               Thread, interpBreak.ctl.breakFlags, 46)
+MTERP_OFFSET(offThread_curHandlerTable, \
+                               Thread, interpBreak.ctl.curHandlerTable, 48)
+MTERP_OFFSET(offThread_suspendCount,      Thread, suspendCount, 52);
+MTERP_OFFSET(offThread_dbgSuspendCount,   Thread, dbgSuspendCount, 56);
+MTERP_OFFSET(offThread_cardTable,         Thread, cardTable, 60)
+MTERP_OFFSET(offThread_interpStackEnd,    Thread, interpStackEnd, 64)
+MTERP_OFFSET(offThread_exception,         Thread, exception, 72)
+MTERP_OFFSET(offThread_debugIsMethodEntry, Thread, debugIsMethodEntry, 76)
+MTERP_OFFSET(offThread_interpStackSize,   Thread, interpStackSize, 80)
+MTERP_OFFSET(offThread_stackOverflowed,   Thread, stackOverflowed, 84)
+MTERP_OFFSET(offThread_mainHandlerTable,  Thread, mainHandlerTable, 92)
+MTERP_OFFSET(offThread_singleStepCount,   Thread, singleStepCount, 100)
+#else
+//48
 MTERP_OFFSET(offThread_subMode, \
                                Thread, interpBreak.ctl.subMode, 48)
 MTERP_OFFSET(offThread_breakFlags, \
@@ -226,6 +245,7 @@ MTERP_OFFSET(offThread_interpStackSize,   Thread, interpStackSize, 84)
 MTERP_OFFSET(offThread_stackOverflowed,   Thread, stackOverflowed, 88)
 MTERP_OFFSET(offThread_mainHandlerTable,  Thread, mainHandlerTable, 96)
 MTERP_OFFSET(offThread_singleStepCount,   Thread, singleStepCount, 104)
+#endif /*TAINT_IS_86*/
 
 #ifdef WITH_JIT
 MTERP_OFFSET(offThread_jitToInterpEntries,Thread, jitToInterpEntries, 108)
-- 
1.7.9.5


From 4e66e9bbcae574c9a902f8a942cd2bd5b27f11f4 Mon Sep 17 00:00:00 2001
From: Peter Gilbert <petergilbert@gmail.com>
Date: Sat, 1 Dec 2012 16:36:10 -0500
Subject: [PATCH 08/15] code formatting

---
 vm/compiler/codegen/arm/CodegenDriver.cpp |    8 ++++----
 1 file changed, 4 insertions(+), 4 deletions(-)

diff --git a/vm/compiler/codegen/arm/CodegenDriver.cpp b/vm/compiler/codegen/arm/CodegenDriver.cpp
index 3fa2ee2..8b35d27 100644
--- a/vm/compiler/codegen/arm/CodegenDriver.cpp
+++ b/vm/compiler/codegen/arm/CodegenDriver.cpp
@@ -1027,10 +1027,10 @@ static bool genArithOpInt(CompilationUnit *cUnit, MIR *mir,
                             rlSrc1.lowReg, rlSrc2.lowReg);
             }
 #ifdef WITH_TAINT_TRACKING
-	    int taint2 = dvmCompilerAllocTemp(cUnit);
-	    loadTaintDirect(cUnit, rlSrc1, taint);
-	    loadTaintDirect(cUnit, rlSrc2, taint2);
-	    opRegRegReg(cUnit, kOpOr, taint, taint, taint2);
+            int taint2 = dvmCompilerAllocTemp(cUnit);
+            loadTaintDirect(cUnit, rlSrc1, taint);
+            loadTaintDirect(cUnit, rlSrc2, taint2);
+            opRegRegReg(cUnit, kOpOr, taint, taint, taint2);
             dvmCompilerFreeTemp(cUnit, taint2);
 #endif /*WITH_TAINT_TRACKING*/
         }
-- 
1.7.9.5


From 3bfa9f6ba43da950ccd211f9dd2220a6cf35893f Mon Sep 17 00:00:00 2001
From: Peter Gilbert <petergilbert@gmail.com>
Date: Thu, 6 Dec 2012 11:33:51 -0500
Subject: [PATCH 09/15] fix 'ftaint s <filename> 0' bug

---
 tools/tprop/ftaint.c |   67 +++++++++++++++++++++++++-------------------------
 1 file changed, 33 insertions(+), 34 deletions(-)

diff --git a/tools/tprop/ftaint.c b/tools/tprop/ftaint.c
index 6a68292..3670e18 100644
--- a/tools/tprop/ftaint.c
+++ b/tools/tprop/ftaint.c
@@ -39,17 +39,17 @@ static u4 getTaintXattr(const char *path)
 
     ret = getxattr(path, TAINT_XATTR_NAME, &buf, sizeof(buf)); 
     if (ret > 0) {
-	tag = buf;
+        tag = buf;
     } else {
-	if (errno == ENOATTR) {
-	    fprintf(stdout, "getxattr(%s): no taint tag\n", path);
-	} else if (errno == ERANGE) {
-	    fprintf(stderr, "Error: getxattr(%s) contents to large\n", path);
-	} else if (errno == ENOTSUP) {
-	    fprintf(stderr, "Error: getxattr(%s) not supported\n", path);
-	} else {
-	    fprintf(stderr, "Errro: getxattr(%s): unknown error code %d\n", path, errno);
-	}
+        if (errno == ENOATTR) {
+            fprintf(stdout, "getxattr(%s): no taint tag\n", path);
+        } else if (errno == ERANGE) {
+            fprintf(stderr, "Error: getxattr(%s) contents to large\n", path);
+        } else if (errno == ENOTSUP) {
+            fprintf(stderr, "Error: getxattr(%s) not supported\n", path);
+        } else {
+            fprintf(stderr, "Errro: getxattr(%s): unknown error code %d\n", path, errno);
+        }
     }
 
     return tag;
@@ -62,15 +62,14 @@ static void setTaintXattr(const char *path, u4 tag)
     ret = setxattr(path, TAINT_XATTR_NAME, &tag, sizeof(tag), 0);
 
     if (ret < 0) {
-	if (errno == ENOSPC || errno == EDQUOT) {
-	    fprintf(stderr, "Error: setxattr(%s): not enough room to set xattr\n", path);
-	} else if (errno == ENOTSUP) {
-	    fprintf(stderr, "Error: setxattr(%s) not supported\n", path);
-	} else {
-	    fprintf(stderr, "Errro: setxattr(%s): unknown error code %d\n", path, errno);
-	}
+        if (errno == ENOSPC || errno == EDQUOT) {
+            fprintf(stderr, "Error: setxattr(%s): not enough room to set xattr\n", path);
+        } else if (errno == ENOTSUP) {
+            fprintf(stderr, "Error: setxattr(%s) not supported\n", path);
+        } else {
+            fprintf(stderr, "Errro: setxattr(%s): unknown error code %d\n", path, errno);
+        }
     }
-
 }
 
 void usage(const char *prog)
@@ -84,37 +83,37 @@ int main(int argc, char *argv[])
     u4 tag;
 
     if (argc != 3 && argc != 4) {
-	usage(argv[0]);
+        usage(argv[0]);
     }
-
+    
     if (strlen(argv[1]) != 1) {
-	usage(argv[0]);
+        usage(argv[0]);
     }
 
     // Get the taint
     if (argc == 3) {
-	if (argv[1][0] == 'g') {
-	    tag = getTaintXattr(argv[2]);
-	    fprintf(stdout, "0x%08x\n", tag);
-	    return 0;
-	} else {
-	    usage(argv[0]);
-	}
+        if (argv[1][0] == 'g') {
+            tag = getTaintXattr(argv[2]);
+            fprintf(stdout, "0x%08x\n", tag);
+            return 0;
+        } else {
+            usage(argv[0]);
+        }
     }
 
     // Set the taint
     tag = strtol(argv[3], NULL, 16);
-    if (tag == 0 && errno == EINVAL) {
-	usage(argv[0]);
+    if (tag == 0 && errno == ERANGE) {
+        usage(argv[0]);
     }
 
     if (argv[1][0] == 's') {
-	setTaintXattr(argv[2], tag);
+        setTaintXattr(argv[2], tag);
     } else if (argv[1][0] == 'a') {
-	u4 old = getTaintXattr(argv[2]);
-	setTaintXattr(argv[2], tag | old);
+        u4 old = getTaintXattr(argv[2]);
+        setTaintXattr(argv[2], tag | old);
     } else {
-	usage(argv[0]);
+        usage(argv[0]);
     }
 
     return 0;
-- 
1.7.9.5


From d4b27adf65de4ba6c879451252edec4b186963c6 Mon Sep 17 00:00:00 2001
From: Peter Gilbert <petergilbert@gmail.com>
Date: Fri, 7 Dec 2012 15:54:48 -0500
Subject: [PATCH 10/15] fixed bug in dvmCallJNIMethod when nArgs>20
 (https://groups.google.com/group/taintdroid/msg/a5ef7432bc4b171a)

---
 vm/Jni.cpp |   21 +++++++--------------
 1 file changed, 7 insertions(+), 14 deletions(-)

diff --git a/vm/Jni.cpp b/vm/Jni.cpp
index ab62e30..2b814d8 100644
--- a/vm/Jni.cpp
+++ b/vm/Jni.cpp
@@ -1093,19 +1093,11 @@ static inline void convertReferenceResult(JNIEnv* env, JValue* pResult,
  */
 void dvmCallJNIMethod(const u4* args, JValue* pResult, const Method* method, Thread* self) {
 #ifdef WITH_TAINT_TRACKING
-    // Copy the list of args in another array, to avoid any change in args which can cause the problem in taint propagation
-    u4 oldArgs[20];
-    int j = 0;
+    // Copy args to another array, to ensure correct taint propagation in case args change
     int nArgs = method->insSize * 2 + 1;
-    while (j < nArgs) {
-        oldArgs[j] = (u4) args[j];
-        j++;
-    }
-    while (j < 20) {
-        oldArgs[j] = 0;
-        j++;
-    }
-#endif
+    u4* oldArgs = (u4*)malloc(sizeof(u4)*nArgs);
+    memcpy(oldArgs, args, sizeof(u4)*nArgs);
+#endif /*WITH_TAINT_TRACKING*/
     u4* modArgs = (u4*) args;
     jclass staticMethodClass = NULL;
 
@@ -1178,8 +1170,9 @@ void dvmCallJNIMethod(const u4* args, JValue* pResult, const Method* method, Thr
     convertReferenceResult(env, pResult, method, self);
 
 #ifdef WITH_TAINT_TRACKING
-     dvmTaintPropJniMethod(oldArgs, pResult, method);
-#endif
+    dvmTaintPropJniMethod(oldArgs, pResult, method);
+    free(oldArgs);
+#endif /*WITH_TAINT_TRACKING*/
 
     if (UNLIKELY(isSynchronized)) {
         dvmUnlockObject(self, lockObj);
-- 
1.7.9.5


From 50c27618a3790ac532edcfa08112d5c250f73840 Mon Sep 17 00:00:00 2001
From: Peter Gilbert <petergilbert@gmail.com>
Date: Thu, 13 Dec 2012 11:23:38 -0500
Subject: [PATCH 11/15] added Taint.[get/add]TaintShort

---
 vm/native/InternalNativePriv.h    |    1 +
 vm/native/dalvik_system_Taint.cpp |   30 ++++++++++++++++++++++++++++++
 2 files changed, 31 insertions(+)

diff --git a/vm/native/InternalNativePriv.h b/vm/native/InternalNativePriv.h
index 20378e0..4ae7c3f 100644
--- a/vm/native/InternalNativePriv.h
+++ b/vm/native/InternalNativePriv.h
@@ -40,6 +40,7 @@
  * value, as described above */
 #define RETURN_CHAR(_val)       do { pResult->i = (_val); return; } while(0)
 #define RETURN_BYTE(_val)       do { pResult->i = (_val); return; } while(0)
+#define RETURN_SHORT(_val)      do { pResult->i = (_val); return; } while(0)
 #endif
 
 /*
diff --git a/vm/native/dalvik_system_Taint.cpp b/vm/native/dalvik_system_Taint.cpp
index c88636f..3554e18 100644
--- a/vm/native/dalvik_system_Taint.cpp
+++ b/vm/native/dalvik_system_Taint.cpp
@@ -228,6 +228,20 @@ static void Dalvik_dalvik_system_Taint_addTaintInt(const u4* args,
 }
 
 /*
+ * public static int addTaintShort(short val, int tag)
+ */
+static void Dalvik_dalvik_system_Taint_addTaintShort(const u4* args,
+    JValue* pResult)
+{
+    u4 val     = args[0];
+    u4 tag     = args[1];	  /* the tag to add */
+    u4* rtaint = (u4*) &args[2];  /* pointer to return taint tag */
+    u4 vtaint  = args[3];	  /* the existing taint tag on val */
+    *rtaint = (vtaint | tag);
+    RETURN_SHORT(val);
+}
+
+/*
  * public static long addTaintLong(long val, int tag)
  */
 static void Dalvik_dalvik_system_Taint_addTaintLong(const u4* args,
@@ -463,6 +477,18 @@ static void Dalvik_dalvik_system_Taint_getTaintInt(const u4* args,
 }
 
 /*
+ * public static int getTaintShort(int val)
+ */
+static void Dalvik_dalvik_system_Taint_getTaintShort(const u4* args,
+    JValue* pResult)
+{
+    // args[0] = the value
+    // args[1] = the return taint
+    u4 tag = args[2]; /* the existing taint */
+    RETURN_INT(tag);
+}
+
+/*
  * public static int getTaintLong(long val)
  */
 static void Dalvik_dalvik_system_Taint_getTaintLong(const u4* args,
@@ -695,6 +721,8 @@ const DalvikNativeMethod dvm_dalvik_system_Taint[] = {
         Dalvik_dalvik_system_Taint_addTaintByte},
     { "addTaintInt",  "(II)I",
         Dalvik_dalvik_system_Taint_addTaintInt},
+    { "addTaintShort",  "(SI)S",
+        Dalvik_dalvik_system_Taint_addTaintShort},
     { "addTaintLong",  "(JI)J",
         Dalvik_dalvik_system_Taint_addTaintLong},
     { "addTaintFloat",  "(FI)F",
@@ -729,6 +757,8 @@ const DalvikNativeMethod dvm_dalvik_system_Taint[] = {
         Dalvik_dalvik_system_Taint_getTaintByte},
     { "getTaintInt",  "(I)I",
         Dalvik_dalvik_system_Taint_getTaintInt},
+    { "getTaintShort",  "(S)I",
+        Dalvik_dalvik_system_Taint_getTaintShort},
     { "getTaintLong",  "(J)I",
         Dalvik_dalvik_system_Taint_getTaintLong},
     { "getTaintFloat",  "(F)I",
-- 
1.7.9.5


From bb637bdfd1716ad6b830c2d39b4f129bafe7d53b Mon Sep 17 00:00:00 2001
From: ldelosieres <ldelosieres@hispasec.com>
Date: Wed, 24 Apr 2013 12:05:25 +0200
Subject: [PATCH 12/15] DroidBox: dalvik patched

---
 vm/native/dalvik_system_Taint.cpp |   43 ++++++++++++++++++++++++++++---------
 1 file changed, 33 insertions(+), 10 deletions(-)

diff --git a/vm/native/dalvik_system_Taint.cpp b/vm/native/dalvik_system_Taint.cpp
index 3554e18..4745697 100644
--- a/vm/native/dalvik_system_Taint.cpp
+++ b/vm/native/dalvik_system_Taint.cpp
@@ -549,13 +549,13 @@ static u4 getTaintXattr(int fd)
 	if (errno == ENOATTR) {
 	    /* do nothing */
 	} else if (errno == ERANGE) {
-	    ALOGW("TaintLog: fgetxattr(%d) contents to large", fd);
+	    ALOGW("DroidBox: fgetxattr(%d) contents to large", fd);
 	} else if (errno == ENOTSUP) {
 	    /* XATTRs are not supported. No need to spam the logs */
 	} else if (errno == EPERM) {
 	    /* Strange interaction with /dev/log/main. Suppress the log */
 	} else {
-	    ALOGW("TaintLog: fgetxattr(%d): unknown error code %d", fd, errno);
+	    ALOGW("DroidBox: fgetxattr(%d): unknown error code %d", fd, errno);
 	}
     }
 
@@ -570,13 +570,13 @@ static void setTaintXattr(int fd, u4 tag)
 
     if (ret < 0) {
 	if (errno == ENOSPC || errno == EDQUOT) {
-	    ALOGW("TaintLog: fsetxattr(%d): not enough room to set xattr", fd);
+	    ALOGW("DroidBox: fsetxattr(%d): not enough room to set xattr", fd);
 	} else if (errno == ENOTSUP) {
 	    /* XATTRs are not supported. No need to spam the logs */
 	} else if (errno == EPERM) {
 	    /* Strange interaction with /dev/log/main. Suppress the log */
 	} else {
-	    ALOGW("TaintLog: fsetxattr(%d): unknown error code %d", fd, errno);
+	    ALOGW("DroidBox: fsetxattr(%d): unknown error code %d", fd, errno);
 	}
     }
 
@@ -661,22 +661,44 @@ static void Dalvik_dalvik_system_Taint_logPathFromFd(const u4* args,
     JValue* pResult)
 {
     int fd = (int) args[0];
+    int id = (int) args[1];
+
     pid_t pid;
     char ppath[20]; // these path lengths should be enough
     char rpath[80];
+    char buffer[(2*80)+1] = "";
+    char *pbuffer = buffer;
+
     int err;
+    int output = 0;
 
+    int len, i;
 
     pid = getpid();
     snprintf(ppath, 20, "/proc/%d/fd/%d", pid, fd);
     err = readlink(ppath, rpath, 80);
-    if (err >= 0) {
-	ALOGW("TaintLog: fd %d -> %s", fd, rpath);
+    /*if (err >= 0) {
+	ALOGW("DroidBox: fd %d -> %s", fd, rpath);
     } else {
-	ALOGW("TaintLog: error finding path for fd %d", fd);
+	ALOGW("DroidBox: error finding path for fd %d", fd);
+    }*/
+
+    //we are not interested in files /dev/pts, and in files inside the folders /system" and "/data/app"
+    if (strstr(rpath, "/dev/pts") == NULL && strstr(rpath, "/system/") == NULL && strstr(rpath, "/data/app/") == NULL) {
+
+	output = 1;
+	len = strlen(rpath);
+
+	for (i = 0; i < len; i++) {
+		sprintf(pbuffer, "%x", rpath[i]);
+		pbuffer += 2;	
+	}
+
+	ALOGW("DroidBox: { \"FdAccess\": { \"path\": \"%s\", \"id\": \"%d\" } }", buffer, id);
     }
 
-    RETURN_VOID();
+    //RETURN_VOID();
+    RETURN_INT(output);
 }
 
 /*
@@ -687,7 +709,7 @@ static void Dalvik_dalvik_system_Taint_logPeerFromFd(const u4* args,
 {
     int fd = (int) args[0];
 
-    ALOGW("TaintLog: logPeerFromFd not yet implemented");
+    ALOGW("DroidBox: logPeerFromFd not yet implemented");
 
     RETURN_VOID();
 }
@@ -773,7 +795,8 @@ const DalvikNativeMethod dvm_dalvik_system_Taint[] = {
         Dalvik_dalvik_system_Taint_addTaintFile},
     { "log",  "(Ljava/lang/String;)V",
         Dalvik_dalvik_system_Taint_log},
-    { "logPathFromFd",  "(I)V",
+    //{ "logPathFromFd",  "(I)V",
+    { "logPathFromFd",  "(II)I",
         Dalvik_dalvik_system_Taint_logPathFromFd},
     { "logPeerFromFd",  "(I)V",
         Dalvik_dalvik_system_Taint_logPeerFromFd},
-- 
1.7.9.5


From ab0598e92946d99ea1d1b02bd1382e88810a1718 Mon Sep 17 00:00:00 2001
From: ldelosieres <ldelosieres@hispasec.com>
Date: Thu, 2 May 2013 18:59:05 +0200
Subject: [PATCH 13/15] DroidBox modified

---
 vm/native/dalvik_system_Taint.cpp |    7 +++++--
 1 file changed, 5 insertions(+), 2 deletions(-)

diff --git a/vm/native/dalvik_system_Taint.cpp b/vm/native/dalvik_system_Taint.cpp
index 4745697..601073f 100644
--- a/vm/native/dalvik_system_Taint.cpp
+++ b/vm/native/dalvik_system_Taint.cpp
@@ -642,12 +642,15 @@ static void Dalvik_dalvik_system_Taint_log(const u4* args,
     }
 
 	msg = dvmCreateCstrFromString(msgObj);
-	ALOG(LOG_WARN, "TaintLog", "%s", msg);
+	//ALOG(LOG_WARN, "TaintLog", "%s", msg);
+	ALOG(LOG_WARN, "DroidBox", "%s", msg);
+
 	char *curmsg = msg;
 	while(strlen(curmsg) > 1013)
 	{   
 		curmsg = curmsg+1013;
-		ALOG(LOG_WARN, "TaintLog", "%s", curmsg);
+		//ALOG(LOG_WARN, "TaintLog", "%s", curmsg);
+		ALOG(LOG_WARN, "DroidBox", "%s", curmsg);
 	}
 	free(msg);
 
-- 
1.7.9.5


From 3f9c0ea7507eeddf968f799fd29fab630bca44da Mon Sep 17 00:00:00 2001
From: ldelosieres <ldelosieres@hispasec.com>
Date: Mon, 3 Jun 2013 10:16:35 +0200
Subject: [PATCH 14/15] dalvik_system_Taint.cpp: filter /sys/kernel files

---
 vm/native/dalvik_system_Taint.cpp |    2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

diff --git a/vm/native/dalvik_system_Taint.cpp b/vm/native/dalvik_system_Taint.cpp
index 601073f..0b30f39 100644
--- a/vm/native/dalvik_system_Taint.cpp
+++ b/vm/native/dalvik_system_Taint.cpp
@@ -687,7 +687,7 @@ static void Dalvik_dalvik_system_Taint_logPathFromFd(const u4* args,
     }*/
 
     //we are not interested in files /dev/pts, and in files inside the folders /system" and "/data/app"
-    if (strstr(rpath, "/dev/pts") == NULL && strstr(rpath, "/system/") == NULL && strstr(rpath, "/data/app/") == NULL) {
+    if (strstr(rpath, "/dev/pts") == NULL && strstr(rpath, "/system/") == NULL && strstr(rpath, "/data/app/") == NULL && strstr(rpath, "/sys/kernel/") == NULL) {
 
 	output = 1;
 	len = strlen(rpath);
-- 
1.7.9.5


From 50fb78eda8b8488c961237e482ca8ffeb40aac6b Mon Sep 17 00:00:00 2001
From: ldelosieres <ldelosieres@hispasec.com>
Date: Thu, 26 Sep 2013 16:51:40 +0200
Subject: [PATCH 15/15] Null byte added at the end of the filename

---
 vm/native/dalvik_system_Taint.cpp |   40 ++++++++++++++++++++-----------------
 1 file changed, 22 insertions(+), 18 deletions(-)

diff --git a/vm/native/dalvik_system_Taint.cpp b/vm/native/dalvik_system_Taint.cpp
index 0b30f39..facb5f4 100644
--- a/vm/native/dalvik_system_Taint.cpp
+++ b/vm/native/dalvik_system_Taint.cpp
@@ -668,10 +668,10 @@ static void Dalvik_dalvik_system_Taint_logPathFromFd(const u4* args,
 
     pid_t pid;
     char ppath[20]; // these path lengths should be enough
-    char rpath[80];
-    char buffer[(2*80)+1] = "";
+    char rpath[120];
+    char buffer[(2*120)+1] = "";
     char *pbuffer = buffer;
-
+   
     int err;
     int output = 0;
 
@@ -679,25 +679,29 @@ static void Dalvik_dalvik_system_Taint_logPathFromFd(const u4* args,
 
     pid = getpid();
     snprintf(ppath, 20, "/proc/%d/fd/%d", pid, fd);
-    err = readlink(ppath, rpath, 80);
-    /*if (err >= 0) {
-	ALOGW("DroidBox: fd %d -> %s", fd, rpath);
-    } else {
-	ALOGW("DroidBox: error finding path for fd %d", fd);
-    }*/
+    err = readlink(ppath, rpath, sizeof(rpath));
 
-    //we are not interested in files /dev/pts, and in files inside the folders /system" and "/data/app"
-    if (strstr(rpath, "/dev/pts") == NULL && strstr(rpath, "/system/") == NULL && strstr(rpath, "/data/app/") == NULL && strstr(rpath, "/sys/kernel/") == NULL) {
+    if (err>=0)
+    {
+            int pos = (err < sizeof(rpath))?err:sizeof(rpath)-1;
+            rpath[pos] = '\0';
 
-	output = 1;
-	len = strlen(rpath);
+            //we are not interested in files /dev/pts, and in files inside the folders /system" and "/data/app"
+            if (strstr(rpath, "/dev/pts") == NULL && strstr(rpath, "/system/") == NULL && strstr(rpath, "/data/app/") == NULL && strstr(rpath, "/sys/kernel/") == NULL) {
 
-	for (i = 0; i < len; i++) {
-		sprintf(pbuffer, "%x", rpath[i]);
-		pbuffer += 2;	
-	}
+                output = 1;
+                len = strlen(rpath);
+
+                for (i = 0; i < len; i++) {
+                        sprintf(pbuffer, "%x", rpath[i]);
+                        pbuffer += 2;
+                }
+
+                ALOGW("DroidBox: { \"FdAccess\": { \"path\": \"%s\", \"id\": \"%d\" } }", buffer, id);
+             }
 
-	ALOGW("DroidBox: { \"FdAccess\": { \"path\": \"%s\", \"id\": \"%d\" } }", buffer, id);
+    }else{
+                ALOGW("DroidBox: error finding path for fd %d", fd);
     }
 
     //RETURN_VOID();
-- 
1.7.9.5

